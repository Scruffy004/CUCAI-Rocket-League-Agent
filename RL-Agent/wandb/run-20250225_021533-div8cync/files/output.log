Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.72194
Policy Entropy: 3.65583
Value Function Loss: 0.11345

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.03021
Policy Update Magnitude: 0.22528
Value Function Update Magnitude: 0.18229

Collected Steps per Second: 20,117.30360
Overall Steps per Second: 13,198.12126

Timestep Collection Time: 2.48572
Timestep Consumption Time: 1.30315
PPO Batch Consumption Time: 0.34265
Total Iteration Time: 3.78887

Cumulative Model Updates: 40,700
Cumulative Timesteps: 339,457,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.03590
Policy Entropy: 3.63925
Value Function Loss: 0.09266

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04521
Policy Update Magnitude: 0.23287
Value Function Update Magnitude: 0.22919

Collected Steps per Second: 21,365.65581
Overall Steps per Second: 13,643.14975

Timestep Collection Time: 2.34114
Timestep Consumption Time: 1.32517
PPO Batch Consumption Time: 0.32257
Total Iteration Time: 3.66631

Cumulative Model Updates: 40,702
Cumulative Timesteps: 339,507,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 339507960...
Checkpoint 339507960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180.47221
Policy Entropy: 3.65772
Value Function Loss: 0.11499

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06850
Policy Update Magnitude: 0.46333
Value Function Update Magnitude: 0.32023

Collected Steps per Second: 21,819.13801
Overall Steps per Second: 11,997.90218

Timestep Collection Time: 2.29166
Timestep Consumption Time: 1.87590
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.16756

Cumulative Model Updates: 40,706
Cumulative Timesteps: 339,557,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,772.36391
Policy Entropy: 3.65674
Value Function Loss: 0.09647

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.64366
Value Function Update Magnitude: 0.42908

Collected Steps per Second: 22,117.64344
Overall Steps per Second: 10,622.91620

Timestep Collection Time: 2.26181
Timestep Consumption Time: 2.44744
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.70925

Cumulative Model Updates: 40,712
Cumulative Timesteps: 339,607,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 339607988...
Checkpoint 339607988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.38765
Policy Entropy: 3.67823
Value Function Loss: 0.07890

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.57745
Value Function Update Magnitude: 0.40550

Collected Steps per Second: 21,666.49853
Overall Steps per Second: 10,552.91405

Timestep Collection Time: 2.30863
Timestep Consumption Time: 2.43129
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.73992

Cumulative Model Updates: 40,718
Cumulative Timesteps: 339,658,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,418.59990
Policy Entropy: 3.68904
Value Function Loss: 0.06757

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.55819

Collected Steps per Second: 21,862.22568
Overall Steps per Second: 10,444.56174

Timestep Collection Time: 2.28833
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.78986

Cumulative Model Updates: 40,724
Cumulative Timesteps: 339,708,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 339708036...
Checkpoint 339708036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,993.27498
Policy Entropy: 3.69232
Value Function Loss: 0.05868

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.56155
Value Function Update Magnitude: 0.57612

Collected Steps per Second: 22,414.78517
Overall Steps per Second: 10,600.44789

Timestep Collection Time: 2.23201
Timestep Consumption Time: 2.48760
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.71961

Cumulative Model Updates: 40,730
Cumulative Timesteps: 339,758,066

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,728.24895
Policy Entropy: 3.70088
Value Function Loss: 0.05534

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.55716
Value Function Update Magnitude: 0.53337

Collected Steps per Second: 22,675.19511
Overall Steps per Second: 10,812.55691

Timestep Collection Time: 2.20541
Timestep Consumption Time: 2.41959
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.62499

Cumulative Model Updates: 40,736
Cumulative Timesteps: 339,808,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 339808074...
Checkpoint 339808074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,911.94357
Policy Entropy: 3.71066
Value Function Loss: 0.05421

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.52960
Value Function Update Magnitude: 0.55739

Collected Steps per Second: 22,455.51199
Overall Steps per Second: 10,687.69045

Timestep Collection Time: 2.22689
Timestep Consumption Time: 2.45195
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.67884

Cumulative Model Updates: 40,742
Cumulative Timesteps: 339,858,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,178.38630
Policy Entropy: 3.71478
Value Function Loss: 0.05345

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.51669
Value Function Update Magnitude: 0.55788

Collected Steps per Second: 22,249.15261
Overall Steps per Second: 10,547.28989

Timestep Collection Time: 2.24827
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.74264

Cumulative Model Updates: 40,748
Cumulative Timesteps: 339,908,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 339908102...
Checkpoint 339908102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,641.80620
Policy Entropy: 3.72251
Value Function Loss: 0.05152

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.49823
Value Function Update Magnitude: 0.51410

Collected Steps per Second: 22,522.03150
Overall Steps per Second: 10,659.03173

Timestep Collection Time: 2.22005
Timestep Consumption Time: 2.47081
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.69086

Cumulative Model Updates: 40,754
Cumulative Timesteps: 339,958,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,366.17989
Policy Entropy: 3.73593
Value Function Loss: 0.04875

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.48683
Value Function Update Magnitude: 0.54858

Collected Steps per Second: 22,782.84180
Overall Steps per Second: 10,808.16223

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.43306
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.62909

Cumulative Model Updates: 40,760
Cumulative Timesteps: 340,008,134

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 340008134...
Checkpoint 340008134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.45312
Policy Entropy: 3.73345
Value Function Loss: 0.04885

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05542
Policy Update Magnitude: 0.52352
Value Function Update Magnitude: 0.57204

Collected Steps per Second: 22,400.45819
Overall Steps per Second: 10,627.69302

Timestep Collection Time: 2.23210
Timestep Consumption Time: 2.47259
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.70469

Cumulative Model Updates: 40,766
Cumulative Timesteps: 340,058,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,003.48788
Policy Entropy: 3.74100
Value Function Loss: 0.04882

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05512
Policy Update Magnitude: 0.56443
Value Function Update Magnitude: 0.63913

Collected Steps per Second: 22,626.28500
Overall Steps per Second: 10,616.31180

Timestep Collection Time: 2.21035
Timestep Consumption Time: 2.50051
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.71086

Cumulative Model Updates: 40,772
Cumulative Timesteps: 340,108,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 340108146...
Checkpoint 340108146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,418.26710
Policy Entropy: 3.74782
Value Function Loss: 0.04821

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05547
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.66167

Collected Steps per Second: 21,976.47392
Overall Steps per Second: 10,452.38029

Timestep Collection Time: 2.27580
Timestep Consumption Time: 2.50914
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.78494

Cumulative Model Updates: 40,778
Cumulative Timesteps: 340,158,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,023.93998
Policy Entropy: 3.74952
Value Function Loss: 0.04443

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05546
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.73979

Collected Steps per Second: 22,796.58676
Overall Steps per Second: 10,649.31542

Timestep Collection Time: 2.19357
Timestep Consumption Time: 2.50213
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.69570

Cumulative Model Updates: 40,784
Cumulative Timesteps: 340,208,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 340208166...
Checkpoint 340208166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,987.62001
Policy Entropy: 3.74475
Value Function Loss: 0.04272

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05254
Policy Update Magnitude: 0.55756
Value Function Update Magnitude: 0.76005

Collected Steps per Second: 22,347.73067
Overall Steps per Second: 10,466.56469

Timestep Collection Time: 2.23799
Timestep Consumption Time: 2.54046
PPO Batch Consumption Time: 0.29979
Total Iteration Time: 4.77845

Cumulative Model Updates: 40,790
Cumulative Timesteps: 340,258,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,750.19173
Policy Entropy: 3.75937
Value Function Loss: 0.04098

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07582
Policy Update Magnitude: 0.52462
Value Function Update Magnitude: 0.74853

Collected Steps per Second: 22,172.95392
Overall Steps per Second: 10,288.91720

Timestep Collection Time: 2.25590
Timestep Consumption Time: 2.60564
PPO Batch Consumption Time: 0.30642
Total Iteration Time: 4.86154

Cumulative Model Updates: 40,796
Cumulative Timesteps: 340,308,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 340308200...
Checkpoint 340308200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,593.25620
Policy Entropy: 3.77220
Value Function Loss: 0.04282

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.47606
Value Function Update Magnitude: 0.79415

Collected Steps per Second: 22,235.66982
Overall Steps per Second: 10,493.01340

Timestep Collection Time: 2.24873
Timestep Consumption Time: 2.51654
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.76527

Cumulative Model Updates: 40,802
Cumulative Timesteps: 340,358,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,060.83321
Policy Entropy: 3.78611
Value Function Loss: 0.03998

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.46976
Value Function Update Magnitude: 0.81243

Collected Steps per Second: 22,356.24564
Overall Steps per Second: 10,706.51776

Timestep Collection Time: 2.23669
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.67043

Cumulative Model Updates: 40,808
Cumulative Timesteps: 340,408,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 340408206...
Checkpoint 340408206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,708.18183
Policy Entropy: 3.78653
Value Function Loss: 0.03828

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07298
Policy Update Magnitude: 0.48052
Value Function Update Magnitude: 0.81840

Collected Steps per Second: 22,369.24668
Overall Steps per Second: 10,743.16153

Timestep Collection Time: 2.23611
Timestep Consumption Time: 2.41988
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.65599

Cumulative Model Updates: 40,814
Cumulative Timesteps: 340,458,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,656.99708
Policy Entropy: 3.79450
Value Function Loss: 0.03690

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05962
Policy Update Magnitude: 0.48173
Value Function Update Magnitude: 0.81566

Collected Steps per Second: 21,652.13336
Overall Steps per Second: 10,554.55227

Timestep Collection Time: 2.31007
Timestep Consumption Time: 2.42893
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.73900

Cumulative Model Updates: 40,820
Cumulative Timesteps: 340,508,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 340508244...
Checkpoint 340508244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,568.82327
Policy Entropy: 3.78949
Value Function Loss: 0.03765

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04954
Policy Update Magnitude: 0.51127
Value Function Update Magnitude: 0.82376

Collected Steps per Second: 21,784.66322
Overall Steps per Second: 10,587.18228

Timestep Collection Time: 2.29639
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.72515

Cumulative Model Updates: 40,826
Cumulative Timesteps: 340,558,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,067.11960
Policy Entropy: 3.79644
Value Function Loss: 0.03891

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04723
Policy Update Magnitude: 0.52811
Value Function Update Magnitude: 0.84516

Collected Steps per Second: 21,935.67873
Overall Steps per Second: 10,760.76589

Timestep Collection Time: 2.28058
Timestep Consumption Time: 2.36835
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.64893

Cumulative Model Updates: 40,832
Cumulative Timesteps: 340,608,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 340608296...
Checkpoint 340608296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,246.56806
Policy Entropy: 3.78532
Value Function Loss: 0.04036

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05092
Policy Update Magnitude: 0.52937
Value Function Update Magnitude: 0.85920

Collected Steps per Second: 21,663.67591
Overall Steps per Second: 10,723.07290

Timestep Collection Time: 2.30940
Timestep Consumption Time: 2.35624
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.66564

Cumulative Model Updates: 40,838
Cumulative Timesteps: 340,658,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,652.52376
Policy Entropy: 3.79334
Value Function Loss: 0.04066

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05322
Policy Update Magnitude: 0.52461
Value Function Update Magnitude: 0.84980

Collected Steps per Second: 21,951.18825
Overall Steps per Second: 10,766.36480

Timestep Collection Time: 2.27842
Timestep Consumption Time: 2.36697
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.64539

Cumulative Model Updates: 40,844
Cumulative Timesteps: 340,708,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 340708340...
Checkpoint 340708340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,530.31838
Policy Entropy: 3.79212
Value Function Loss: 0.03928

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06237
Policy Update Magnitude: 0.51440
Value Function Update Magnitude: 0.85685

Collected Steps per Second: 21,825.15452
Overall Steps per Second: 10,510.62899

Timestep Collection Time: 2.29112
Timestep Consumption Time: 2.46635
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.75747

Cumulative Model Updates: 40,850
Cumulative Timesteps: 340,758,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,311.68984
Policy Entropy: 3.79297
Value Function Loss: 0.03633

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.47114
Value Function Update Magnitude: 0.87712

Collected Steps per Second: 22,632.99873
Overall Steps per Second: 10,712.10441

Timestep Collection Time: 2.21031
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.67004

Cumulative Model Updates: 40,856
Cumulative Timesteps: 340,808,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 340808370...
Checkpoint 340808370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,931.15784
Policy Entropy: 3.78926
Value Function Loss: 0.03613

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04606
Policy Update Magnitude: 0.47762
Value Function Update Magnitude: 0.89177

Collected Steps per Second: 22,536.42595
Overall Steps per Second: 10,635.48840

Timestep Collection Time: 2.21978
Timestep Consumption Time: 2.48390
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.70369

Cumulative Model Updates: 40,862
Cumulative Timesteps: 340,858,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,400.52011
Policy Entropy: 3.78899
Value Function Loss: 0.03661

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05105
Policy Update Magnitude: 0.51411
Value Function Update Magnitude: 0.89700

Collected Steps per Second: 22,698.75343
Overall Steps per Second: 10,817.73063

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.41986
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.62315

Cumulative Model Updates: 40,868
Cumulative Timesteps: 340,908,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 340908408...
Checkpoint 340908408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,654.14051
Policy Entropy: 3.79652
Value Function Loss: 0.03695

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07259
Policy Update Magnitude: 0.48946
Value Function Update Magnitude: 0.90042

Collected Steps per Second: 22,300.36835
Overall Steps per Second: 10,582.41436

Timestep Collection Time: 2.24229
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.72520

Cumulative Model Updates: 40,874
Cumulative Timesteps: 340,958,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,660.63931
Policy Entropy: 3.79469
Value Function Loss: 0.03653

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.43979
Value Function Update Magnitude: 0.87990

Collected Steps per Second: 22,361.53415
Overall Steps per Second: 10,596.70098

Timestep Collection Time: 2.23634
Timestep Consumption Time: 2.48286
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.71920

Cumulative Model Updates: 40,880
Cumulative Timesteps: 341,008,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 341008420...
Checkpoint 341008420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,669.54562
Policy Entropy: 3.80506
Value Function Loss: 0.03759

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.43055
Value Function Update Magnitude: 0.88854

Collected Steps per Second: 22,374.19069
Overall Steps per Second: 10,634.95359

Timestep Collection Time: 2.23552
Timestep Consumption Time: 2.46765
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.70317

Cumulative Model Updates: 40,886
Cumulative Timesteps: 341,058,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.96182
Policy Entropy: 3.82196
Value Function Loss: 0.03707

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.46383
Value Function Update Magnitude: 0.91982

Collected Steps per Second: 22,270.42532
Overall Steps per Second: 10,503.34111

Timestep Collection Time: 2.24513
Timestep Consumption Time: 2.51526
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.76039

Cumulative Model Updates: 40,892
Cumulative Timesteps: 341,108,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 341108438...
Checkpoint 341108438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,402.92039
Policy Entropy: 3.82791
Value Function Loss: 0.03762

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06879
Policy Update Magnitude: 0.50790
Value Function Update Magnitude: 0.94238

Collected Steps per Second: 22,350.54631
Overall Steps per Second: 10,567.50324

Timestep Collection Time: 2.23753
Timestep Consumption Time: 2.49490
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.73243

Cumulative Model Updates: 40,898
Cumulative Timesteps: 341,158,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,165.16510
Policy Entropy: 3.81866
Value Function Loss: 0.03619

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05005
Policy Update Magnitude: 0.52530
Value Function Update Magnitude: 0.95676

Collected Steps per Second: 22,487.65488
Overall Steps per Second: 10,549.69498

Timestep Collection Time: 2.22353
Timestep Consumption Time: 2.51613
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.73966

Cumulative Model Updates: 40,904
Cumulative Timesteps: 341,208,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 341208450...
Checkpoint 341208450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,020.45068
Policy Entropy: 3.80744
Value Function Loss: 0.03654

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05088
Policy Update Magnitude: 0.52096
Value Function Update Magnitude: 0.94518

Collected Steps per Second: 22,529.45885
Overall Steps per Second: 10,561.54760

Timestep Collection Time: 2.22162
Timestep Consumption Time: 2.51745
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.73908

Cumulative Model Updates: 40,910
Cumulative Timesteps: 341,258,502

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,047.63356
Policy Entropy: 3.80598
Value Function Loss: 0.03601

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05838
Policy Update Magnitude: 0.51194
Value Function Update Magnitude: 0.93089

Collected Steps per Second: 22,554.14974
Overall Steps per Second: 10,551.46479

Timestep Collection Time: 2.21884
Timestep Consumption Time: 2.52401
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74285

Cumulative Model Updates: 40,916
Cumulative Timesteps: 341,308,546

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 341308546...
Checkpoint 341308546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,503.90905
Policy Entropy: 3.81244
Value Function Loss: 0.03501

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05512
Policy Update Magnitude: 0.50478
Value Function Update Magnitude: 0.92458

Collected Steps per Second: 22,203.06114
Overall Steps per Second: 10,532.47060

Timestep Collection Time: 2.25248
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.74836

Cumulative Model Updates: 40,922
Cumulative Timesteps: 341,358,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,905.36425
Policy Entropy: 3.82349
Value Function Loss: 0.03572

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05043
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.94327

Collected Steps per Second: 22,887.47474
Overall Steps per Second: 10,642.00608

Timestep Collection Time: 2.18565
Timestep Consumption Time: 2.51497
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.70062

Cumulative Model Updates: 40,928
Cumulative Timesteps: 341,408,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 341408582...
Checkpoint 341408582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.01419
Policy Entropy: 3.81591
Value Function Loss: 0.03604

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05021
Policy Update Magnitude: 0.50911
Value Function Update Magnitude: 0.94621

Collected Steps per Second: 22,490.98773
Overall Steps per Second: 10,605.85856

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.49216
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.71607

Cumulative Model Updates: 40,934
Cumulative Timesteps: 341,458,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.66633
Policy Entropy: 3.80474
Value Function Loss: 0.03683

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05348
Policy Update Magnitude: 0.51570
Value Function Update Magnitude: 0.94860

Collected Steps per Second: 22,835.98855
Overall Steps per Second: 10,740.30024

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.46692
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.65741

Cumulative Model Updates: 40,940
Cumulative Timesteps: 341,508,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 341508622...
Checkpoint 341508622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,657.93105
Policy Entropy: 3.79932
Value Function Loss: 0.03588

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05567
Policy Update Magnitude: 0.50766
Value Function Update Magnitude: 0.92346

Collected Steps per Second: 22,550.70155
Overall Steps per Second: 10,664.37600

Timestep Collection Time: 2.21820
Timestep Consumption Time: 2.47237
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.69057

Cumulative Model Updates: 40,946
Cumulative Timesteps: 341,558,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,511.17535
Policy Entropy: 3.79201
Value Function Loss: 0.03618

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04689
Policy Update Magnitude: 0.50793
Value Function Update Magnitude: 0.90746

Collected Steps per Second: 22,223.57200
Overall Steps per Second: 10,473.78288

Timestep Collection Time: 2.25058
Timestep Consumption Time: 2.52477
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.77535

Cumulative Model Updates: 40,952
Cumulative Timesteps: 341,608,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 341608660...
Checkpoint 341608660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,746.07110
Policy Entropy: 3.79061
Value Function Loss: 0.03745

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05096
Policy Update Magnitude: 0.51369
Value Function Update Magnitude: 0.88490

Collected Steps per Second: 22,114.54043
Overall Steps per Second: 10,653.84422

Timestep Collection Time: 2.26150
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.69427

Cumulative Model Updates: 40,958
Cumulative Timesteps: 341,658,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,857.06864
Policy Entropy: 3.78622
Value Function Loss: 0.03924

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05145
Policy Update Magnitude: 0.51301
Value Function Update Magnitude: 0.86082

Collected Steps per Second: 22,512.73745
Overall Steps per Second: 10,594.75372

Timestep Collection Time: 2.22185
Timestep Consumption Time: 2.49935
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.72120

Cumulative Model Updates: 40,964
Cumulative Timesteps: 341,708,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 341708692...
Checkpoint 341708692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,269.76967
Policy Entropy: 3.79053
Value Function Loss: 0.03891

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06761
Policy Update Magnitude: 0.48697
Value Function Update Magnitude: 0.85793

Collected Steps per Second: 22,630.68701
Overall Steps per Second: 10,605.22266

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.71466

Cumulative Model Updates: 40,970
Cumulative Timesteps: 341,758,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,809.49867
Policy Entropy: 3.78325
Value Function Loss: 0.03897

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.42634
Value Function Update Magnitude: 0.85655

Collected Steps per Second: 22,732.48941
Overall Steps per Second: 10,742.17395

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.45574
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.65585

Cumulative Model Updates: 40,976
Cumulative Timesteps: 341,808,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 341808706...
Checkpoint 341808706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,809.93090
Policy Entropy: 3.78844
Value Function Loss: 0.03865

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.40224
Value Function Update Magnitude: 0.86683

Collected Steps per Second: 22,271.95489
Overall Steps per Second: 10,709.10071

Timestep Collection Time: 2.24605
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.67117

Cumulative Model Updates: 40,982
Cumulative Timesteps: 341,858,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.06836
Policy Entropy: 3.78878
Value Function Loss: 0.04019

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.43340
Value Function Update Magnitude: 0.89130

Collected Steps per Second: 22,540.44940
Overall Steps per Second: 10,608.78428

Timestep Collection Time: 2.21948
Timestep Consumption Time: 2.49624
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.71571

Cumulative Model Updates: 40,988
Cumulative Timesteps: 341,908,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 341908758...
Checkpoint 341908758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,780.09797
Policy Entropy: 3.78902
Value Function Loss: 0.04003

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.46928
Value Function Update Magnitude: 0.88521

Collected Steps per Second: 22,568.17841
Overall Steps per Second: 10,599.29534

Timestep Collection Time: 2.21684
Timestep Consumption Time: 2.50329
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.72013

Cumulative Model Updates: 40,994
Cumulative Timesteps: 341,958,788

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,961.46386
Policy Entropy: 3.77957
Value Function Loss: 0.04009

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06202
Policy Update Magnitude: 0.48006
Value Function Update Magnitude: 0.85154

Collected Steps per Second: 22,470.15656
Overall Steps per Second: 10,701.86730

Timestep Collection Time: 2.22597
Timestep Consumption Time: 2.44779
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.67376

Cumulative Model Updates: 41,000
Cumulative Timesteps: 342,008,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 342008806...
Checkpoint 342008806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,249.09775
Policy Entropy: 3.76970
Value Function Loss: 0.04054

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.48001
Value Function Update Magnitude: 0.84279

Collected Steps per Second: 22,497.83636
Overall Steps per Second: 10,756.40827

Timestep Collection Time: 2.22368
Timestep Consumption Time: 2.42731
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.65099

Cumulative Model Updates: 41,006
Cumulative Timesteps: 342,058,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,185.71909
Policy Entropy: 3.76241
Value Function Loss: 0.03982

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06345
Policy Update Magnitude: 0.45533
Value Function Update Magnitude: 0.84143

Collected Steps per Second: 22,577.31922
Overall Steps per Second: 10,573.18461

Timestep Collection Time: 2.21523
Timestep Consumption Time: 2.51504
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.73027

Cumulative Model Updates: 41,012
Cumulative Timesteps: 342,108,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 342108848...
Checkpoint 342108848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,857.44428
Policy Entropy: 3.77131
Value Function Loss: 0.03956

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.43354
Value Function Update Magnitude: 0.82430

Collected Steps per Second: 22,345.68370
Overall Steps per Second: 10,529.37271

Timestep Collection Time: 2.23784
Timestep Consumption Time: 2.51135
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.74919

Cumulative Model Updates: 41,018
Cumulative Timesteps: 342,158,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.54266
Policy Entropy: 3.78068
Value Function Loss: 0.03938

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.44437
Value Function Update Magnitude: 0.80868

Collected Steps per Second: 22,896.94424
Overall Steps per Second: 10,892.92038

Timestep Collection Time: 2.18387
Timestep Consumption Time: 2.40663
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.59050

Cumulative Model Updates: 41,024
Cumulative Timesteps: 342,208,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 342208858...
Checkpoint 342208858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.09855
Policy Entropy: 3.78805
Value Function Loss: 0.03825

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.44446
Value Function Update Magnitude: 0.82097

Collected Steps per Second: 22,531.70176
Overall Steps per Second: 10,506.00280

Timestep Collection Time: 2.21981
Timestep Consumption Time: 2.54090
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.76071

Cumulative Model Updates: 41,030
Cumulative Timesteps: 342,258,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,024.64107
Policy Entropy: 3.78377
Value Function Loss: 0.03988

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.42917
Value Function Update Magnitude: 0.81813

Collected Steps per Second: 22,499.62339
Overall Steps per Second: 10,543.82335

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.52006
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.74249

Cumulative Model Updates: 41,036
Cumulative Timesteps: 342,308,878

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 342308878...
Checkpoint 342308878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,901.84939
Policy Entropy: 3.76605
Value Function Loss: 0.04086

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.43211
Value Function Update Magnitude: 0.80990

Collected Steps per Second: 22,458.08147
Overall Steps per Second: 10,633.88567

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.47657
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.70383

Cumulative Model Updates: 41,042
Cumulative Timesteps: 342,358,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,842.47079
Policy Entropy: 3.75079
Value Function Loss: 0.04135

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.42387
Value Function Update Magnitude: 0.82550

Collected Steps per Second: 22,842.06196
Overall Steps per Second: 10,682.62285

Timestep Collection Time: 2.18903
Timestep Consumption Time: 2.49165
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.68069

Cumulative Model Updates: 41,048
Cumulative Timesteps: 342,408,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 342408900...
Checkpoint 342408900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,558.77923
Policy Entropy: 3.75066
Value Function Loss: 0.04191

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.38428
Value Function Update Magnitude: 0.83260

Collected Steps per Second: 22,598.00202
Overall Steps per Second: 10,808.17567

Timestep Collection Time: 2.21294
Timestep Consumption Time: 2.41393
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.62687

Cumulative Model Updates: 41,054
Cumulative Timesteps: 342,458,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,863.27944
Policy Entropy: 3.74194
Value Function Loss: 0.04224

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.40855
Value Function Update Magnitude: 0.83397

Collected Steps per Second: 22,683.00892
Overall Steps per Second: 10,684.74966

Timestep Collection Time: 2.20491
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.68088

Cumulative Model Updates: 41,060
Cumulative Timesteps: 342,508,922

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 342508922...
Checkpoint 342508922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,443.88679
Policy Entropy: 3.74403
Value Function Loss: 0.04101

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08185
Policy Update Magnitude: 0.39642
Value Function Update Magnitude: 0.83824

Collected Steps per Second: 22,742.15725
Overall Steps per Second: 10,677.61996

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.68569

Cumulative Model Updates: 41,066
Cumulative Timesteps: 342,558,954

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,487.29373
Policy Entropy: 3.74405
Value Function Loss: 0.03947

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.40878
Value Function Update Magnitude: 0.84166

Collected Steps per Second: 22,817.47227
Overall Steps per Second: 10,710.26217

Timestep Collection Time: 2.19130
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.66842

Cumulative Model Updates: 41,072
Cumulative Timesteps: 342,608,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 342608954...
Checkpoint 342608954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,612.56593
Policy Entropy: 3.75477
Value Function Loss: 0.03913

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05929
Policy Update Magnitude: 0.43525
Value Function Update Magnitude: 0.83326

Collected Steps per Second: 22,486.27117
Overall Steps per Second: 10,639.94651

Timestep Collection Time: 2.22402
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.70021

Cumulative Model Updates: 41,078
Cumulative Timesteps: 342,658,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,627.77287
Policy Entropy: 3.74858
Value Function Loss: 0.04057

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05372
Policy Update Magnitude: 0.48366
Value Function Update Magnitude: 0.81558

Collected Steps per Second: 22,799.94297
Overall Steps per Second: 10,647.27109

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.69660

Cumulative Model Updates: 41,084
Cumulative Timesteps: 342,708,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 342708970...
Checkpoint 342708970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,194.30523
Policy Entropy: 3.73903
Value Function Loss: 0.04161

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05708
Policy Update Magnitude: 0.50391
Value Function Update Magnitude: 0.78665

Collected Steps per Second: 22,748.13122
Overall Steps per Second: 10,797.66364

Timestep Collection Time: 2.19913
Timestep Consumption Time: 2.43391
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.63304

Cumulative Model Updates: 41,090
Cumulative Timesteps: 342,758,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,841.12603
Policy Entropy: 3.74463
Value Function Loss: 0.04143

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.45899
Value Function Update Magnitude: 0.79619

Collected Steps per Second: 22,812.94959
Overall Steps per Second: 10,631.00953

Timestep Collection Time: 2.19297
Timestep Consumption Time: 2.51289
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.70586

Cumulative Model Updates: 41,096
Cumulative Timesteps: 342,809,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 342809024...
Checkpoint 342809024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,210.73496
Policy Entropy: 3.74941
Value Function Loss: 0.03977

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06307
Policy Update Magnitude: 0.41488
Value Function Update Magnitude: 0.81256

Collected Steps per Second: 22,735.77453
Overall Steps per Second: 10,584.80172

Timestep Collection Time: 2.19927
Timestep Consumption Time: 2.52468
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.72394

Cumulative Model Updates: 41,102
Cumulative Timesteps: 342,859,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,952.71377
Policy Entropy: 3.75881
Value Function Loss: 0.03879

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05540
Policy Update Magnitude: 0.45022
Value Function Update Magnitude: 0.78850

Collected Steps per Second: 22,460.21962
Overall Steps per Second: 10,545.49307

Timestep Collection Time: 2.22634
Timestep Consumption Time: 2.51541
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.74174

Cumulative Model Updates: 41,108
Cumulative Timesteps: 342,909,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 342909030...
Checkpoint 342909030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,499.28509
Policy Entropy: 3.74823
Value Function Loss: 0.03972

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07430
Policy Update Magnitude: 0.41962
Value Function Update Magnitude: 0.76414

Collected Steps per Second: 22,716.61136
Overall Steps per Second: 10,624.89208

Timestep Collection Time: 2.20209
Timestep Consumption Time: 2.50610
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.70819

Cumulative Model Updates: 41,114
Cumulative Timesteps: 342,959,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,125.42786
Policy Entropy: 3.74025
Value Function Loss: 0.03964

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.40154
Value Function Update Magnitude: 0.76023

Collected Steps per Second: 22,595.86845
Overall Steps per Second: 10,770.81626

Timestep Collection Time: 2.21350
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.64366

Cumulative Model Updates: 41,120
Cumulative Timesteps: 343,009,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 343009070...
Checkpoint 343009070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,799.88949
Policy Entropy: 3.74371
Value Function Loss: 0.04027

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07486
Policy Update Magnitude: 0.43743
Value Function Update Magnitude: 0.75484

Collected Steps per Second: 22,261.70482
Overall Steps per Second: 10,695.33559

Timestep Collection Time: 2.24673
Timestep Consumption Time: 2.42970
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.67643

Cumulative Model Updates: 41,126
Cumulative Timesteps: 343,059,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,237.18438
Policy Entropy: 3.75109
Value Function Loss: 0.04094

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06586
Policy Update Magnitude: 0.48179
Value Function Update Magnitude: 0.75510

Collected Steps per Second: 22,627.54748
Overall Steps per Second: 10,609.22490

Timestep Collection Time: 2.21005
Timestep Consumption Time: 2.50358
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.71363

Cumulative Model Updates: 41,132
Cumulative Timesteps: 343,109,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 343109094...
Checkpoint 343109094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,461.44829
Policy Entropy: 3.74242
Value Function Loss: 0.04042

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05715
Policy Update Magnitude: 0.50907
Value Function Update Magnitude: 0.75967

Collected Steps per Second: 22,564.62422
Overall Steps per Second: 10,629.50099

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.48843
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.70464

Cumulative Model Updates: 41,138
Cumulative Timesteps: 343,159,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,076.90280
Policy Entropy: 3.72814
Value Function Loss: 0.04340

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06407
Policy Update Magnitude: 0.50725
Value Function Update Magnitude: 0.67476

Collected Steps per Second: 22,918.90018
Overall Steps per Second: 10,750.67271

Timestep Collection Time: 2.18248
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.65273

Cumulative Model Updates: 41,144
Cumulative Timesteps: 343,209,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 343209122...
Checkpoint 343209122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,121.04849
Policy Entropy: 3.72340
Value Function Loss: 0.04413

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05785
Policy Update Magnitude: 0.49967
Value Function Update Magnitude: 0.64094

Collected Steps per Second: 22,386.70022
Overall Steps per Second: 10,626.20095

Timestep Collection Time: 2.23472
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.70799

Cumulative Model Updates: 41,150
Cumulative Timesteps: 343,259,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,203.48484
Policy Entropy: 3.71533
Value Function Loss: 0.04385

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05224
Policy Update Magnitude: 0.48698
Value Function Update Magnitude: 0.62459

Collected Steps per Second: 22,663.57636
Overall Steps per Second: 10,623.17239

Timestep Collection Time: 2.20742
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.70933

Cumulative Model Updates: 41,156
Cumulative Timesteps: 343,309,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 343309178...
Checkpoint 343309178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,074.12952
Policy Entropy: 3.72213
Value Function Loss: 0.04456

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05571
Policy Update Magnitude: 0.49063
Value Function Update Magnitude: 0.64778

Collected Steps per Second: 22,579.19694
Overall Steps per Second: 10,650.14660

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.48094
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.69590

Cumulative Model Updates: 41,162
Cumulative Timesteps: 343,359,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,804.65118
Policy Entropy: 3.71968
Value Function Loss: 0.04519

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.44921
Value Function Update Magnitude: 0.62416

Collected Steps per Second: 23,143.54445
Overall Steps per Second: 10,724.36589

Timestep Collection Time: 2.16060
Timestep Consumption Time: 2.50205
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.66265

Cumulative Model Updates: 41,168
Cumulative Timesteps: 343,409,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 343409194...
Checkpoint 343409194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,492.66186
Policy Entropy: 3.71146
Value Function Loss: 0.04623

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.40129
Value Function Update Magnitude: 0.69822

Collected Steps per Second: 22,615.80564
Overall Steps per Second: 10,637.72665

Timestep Collection Time: 2.21190
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.70251

Cumulative Model Updates: 41,174
Cumulative Timesteps: 343,459,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,257.57911
Policy Entropy: 3.70527
Value Function Loss: 0.04711

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.40294
Value Function Update Magnitude: 0.63849

Collected Steps per Second: 22,796.68100
Overall Steps per Second: 10,789.81283

Timestep Collection Time: 2.19348
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.63437

Cumulative Model Updates: 41,180
Cumulative Timesteps: 343,509,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 343509222...
Checkpoint 343509222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,151.72813
Policy Entropy: 3.70676
Value Function Loss: 0.04810

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.45615
Value Function Update Magnitude: 0.62331

Collected Steps per Second: 22,306.91712
Overall Steps per Second: 10,692.10886

Timestep Collection Time: 2.24253
Timestep Consumption Time: 2.43606
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.67859

Cumulative Model Updates: 41,186
Cumulative Timesteps: 343,559,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,643.95245
Policy Entropy: 3.71242
Value Function Loss: 0.04856

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.41341
Value Function Update Magnitude: 0.65807

Collected Steps per Second: 22,808.31817
Overall Steps per Second: 10,639.25193

Timestep Collection Time: 2.19341
Timestep Consumption Time: 2.50880
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.70221

Cumulative Model Updates: 41,192
Cumulative Timesteps: 343,609,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 343609274...
Checkpoint 343609274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,630.11805
Policy Entropy: 3.70343
Value Function Loss: 0.04881

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.39046
Value Function Update Magnitude: 0.64664

Collected Steps per Second: 22,749.33709
Overall Steps per Second: 10,669.53646

Timestep Collection Time: 2.19822
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.68699

Cumulative Model Updates: 41,198
Cumulative Timesteps: 343,659,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,526.00476
Policy Entropy: 3.72425
Value Function Loss: 0.04821

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.15428
Policy Update Magnitude: 0.33808
Value Function Update Magnitude: 0.65396

Collected Steps per Second: 22,738.36077
Overall Steps per Second: 10,817.52749

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.42388
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.62342

Cumulative Model Updates: 41,204
Cumulative Timesteps: 343,709,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 343709296...
Checkpoint 343709296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,923.10398
Policy Entropy: 3.73502
Value Function Loss: 0.04693

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.32813
Value Function Update Magnitude: 0.69193

Collected Steps per Second: 22,507.85368
Overall Steps per Second: 10,548.94722

Timestep Collection Time: 2.22234
Timestep Consumption Time: 2.51937
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.74171

Cumulative Model Updates: 41,210
Cumulative Timesteps: 343,759,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,878.54788
Policy Entropy: 3.73922
Value Function Loss: 0.04762

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.38945
Value Function Update Magnitude: 0.71572

Collected Steps per Second: 22,942.26763
Overall Steps per Second: 10,869.43320

Timestep Collection Time: 2.18052
Timestep Consumption Time: 2.42193
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.60245

Cumulative Model Updates: 41,216
Cumulative Timesteps: 343,809,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 343809342...
Checkpoint 343809342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,203.87959
Policy Entropy: 3.72493
Value Function Loss: 0.05059

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07684
Policy Update Magnitude: 0.45166
Value Function Update Magnitude: 0.68388

Collected Steps per Second: 22,441.04325
Overall Steps per Second: 10,743.52721

Timestep Collection Time: 2.22922
Timestep Consumption Time: 2.42717
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.65639

Cumulative Model Updates: 41,222
Cumulative Timesteps: 343,859,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,362.96244
Policy Entropy: 3.71790
Value Function Loss: 0.04884

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.46892
Value Function Update Magnitude: 0.76618

Collected Steps per Second: 22,010.40063
Overall Steps per Second: 10,782.28533

Timestep Collection Time: 2.27202
Timestep Consumption Time: 2.36596
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.63798

Cumulative Model Updates: 41,228
Cumulative Timesteps: 343,909,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 343909376...
Checkpoint 343909376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,272.05961
Policy Entropy: 3.71974
Value Function Loss: 0.04780

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.40681
Value Function Update Magnitude: 0.81826

Collected Steps per Second: 21,820.07168
Overall Steps per Second: 10,790.14089

Timestep Collection Time: 2.29165
Timestep Consumption Time: 2.34258
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.63423

Cumulative Model Updates: 41,234
Cumulative Timesteps: 343,959,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910.99658
Policy Entropy: 3.72268
Value Function Loss: 0.04787

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.40175
Value Function Update Magnitude: 0.80205

Collected Steps per Second: 22,330.67176
Overall Steps per Second: 10,878.18160

Timestep Collection Time: 2.23934
Timestep Consumption Time: 2.35757
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.59691

Cumulative Model Updates: 41,240
Cumulative Timesteps: 344,009,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 344009386...
Checkpoint 344009386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,609.20919
Policy Entropy: 3.72752
Value Function Loss: 0.04933

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.43594
Value Function Update Magnitude: 0.69755

Collected Steps per Second: 21,893.01741
Overall Steps per Second: 10,611.78432

Timestep Collection Time: 2.28520
Timestep Consumption Time: 2.42937
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.71457

Cumulative Model Updates: 41,246
Cumulative Timesteps: 344,059,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,222.67145
Policy Entropy: 3.72140
Value Function Loss: 0.04943

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.42831
Value Function Update Magnitude: 0.71040

Collected Steps per Second: 22,481.73522
Overall Steps per Second: 10,896.54823

Timestep Collection Time: 2.22429
Timestep Consumption Time: 2.36487
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.58916

Cumulative Model Updates: 41,252
Cumulative Timesteps: 344,109,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 344109422...
Checkpoint 344109422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,883.43868
Policy Entropy: 3.73528
Value Function Loss: 0.04778

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.44825
Value Function Update Magnitude: 0.75736

Collected Steps per Second: 22,004.29799
Overall Steps per Second: 10,686.54012

Timestep Collection Time: 2.27283
Timestep Consumption Time: 2.40708
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.67991

Cumulative Model Updates: 41,258
Cumulative Timesteps: 344,159,434

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,904.61985
Policy Entropy: 3.72494
Value Function Loss: 0.04474

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07567
Policy Update Magnitude: 0.47364
Value Function Update Magnitude: 0.81546

Collected Steps per Second: 22,965.18778
Overall Steps per Second: 10,901.44284

Timestep Collection Time: 2.17730
Timestep Consumption Time: 2.40944
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.58673

Cumulative Model Updates: 41,264
Cumulative Timesteps: 344,209,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 344209436...
Checkpoint 344209436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,199.02625
Policy Entropy: 3.73643
Value Function Loss: 0.04355

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06743
Policy Update Magnitude: 0.49832
Value Function Update Magnitude: 0.80375

Collected Steps per Second: 22,452.27556
Overall Steps per Second: 10,590.49563

Timestep Collection Time: 2.22721
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.72178

Cumulative Model Updates: 41,270
Cumulative Timesteps: 344,259,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,963.26967
Policy Entropy: 3.72830
Value Function Loss: 0.04365

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.45429
Value Function Update Magnitude: 0.80025

Collected Steps per Second: 22,738.42233
Overall Steps per Second: 10,855.77180

Timestep Collection Time: 2.20024
Timestep Consumption Time: 2.40837
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.60861

Cumulative Model Updates: 41,276
Cumulative Timesteps: 344,309,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 344309472...
Checkpoint 344309472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,222.56194
Policy Entropy: 3.72421
Value Function Loss: 0.04399

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.40031
Value Function Update Magnitude: 0.79895

Collected Steps per Second: 22,473.43870
Overall Steps per Second: 10,724.02475

Timestep Collection Time: 2.22574
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.66429

Cumulative Model Updates: 41,282
Cumulative Timesteps: 344,359,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.53322
Policy Entropy: 3.72155
Value Function Loss: 0.04360

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.38493
Value Function Update Magnitude: 0.76306

Collected Steps per Second: 22,881.56876
Overall Steps per Second: 10,808.94160

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.44122
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.62691

Cumulative Model Updates: 41,288
Cumulative Timesteps: 344,409,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 344409504...
Checkpoint 344409504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,723.69740
Policy Entropy: 3.71922
Value Function Loss: 0.04342

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 0.47188
Value Function Update Magnitude: 0.75333

Collected Steps per Second: 22,566.34599
Overall Steps per Second: 10,760.31631

Timestep Collection Time: 2.21666
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.64875

Cumulative Model Updates: 41,294
Cumulative Timesteps: 344,459,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,148.69456
Policy Entropy: 3.72764
Value Function Loss: 0.04427

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05828
Policy Update Magnitude: 0.52124
Value Function Update Magnitude: 0.79864

Collected Steps per Second: 22,588.25987
Overall Steps per Second: 10,621.18624

Timestep Collection Time: 2.21363
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.70776

Cumulative Model Updates: 41,300
Cumulative Timesteps: 344,509,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 344509528...
Checkpoint 344509528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,984.11340
Policy Entropy: 3.72010
Value Function Loss: 0.04702

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.47231
Value Function Update Magnitude: 0.84214

Collected Steps per Second: 22,698.90662
Overall Steps per Second: 10,634.17231

Timestep Collection Time: 2.20301
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.70239

Cumulative Model Updates: 41,306
Cumulative Timesteps: 344,559,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,628.83019
Policy Entropy: 3.71744
Value Function Loss: 0.04556

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.40382
Value Function Update Magnitude: 0.79746

Collected Steps per Second: 23,199.17947
Overall Steps per Second: 10,796.84503

Timestep Collection Time: 2.15577
Timestep Consumption Time: 2.47633
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.63209

Cumulative Model Updates: 41,312
Cumulative Timesteps: 344,609,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 344609546...
Checkpoint 344609546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,581.62097
Policy Entropy: 3.71744
Value Function Loss: 0.04421

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.36998
Value Function Update Magnitude: 0.77915

Collected Steps per Second: 22,643.43161
Overall Steps per Second: 10,602.78137

Timestep Collection Time: 2.20859
Timestep Consumption Time: 2.50810
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.71669

Cumulative Model Updates: 41,318
Cumulative Timesteps: 344,659,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.72496
Policy Entropy: 3.72401
Value Function Loss: 0.04312

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05356
Policy Update Magnitude: 0.43727
Value Function Update Magnitude: 0.80818

Collected Steps per Second: 22,824.72333
Overall Steps per Second: 10,793.63818

Timestep Collection Time: 2.19148
Timestep Consumption Time: 2.44273
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.63421

Cumulative Model Updates: 41,324
Cumulative Timesteps: 344,709,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 344709576...
Checkpoint 344709576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,589.21351
Policy Entropy: 3.72263
Value Function Loss: 0.04697

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.43302
Value Function Update Magnitude: 0.75559

Collected Steps per Second: 22,657.44366
Overall Steps per Second: 10,708.03756

Timestep Collection Time: 2.20705
Timestep Consumption Time: 2.46290
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.66995

Cumulative Model Updates: 41,330
Cumulative Timesteps: 344,759,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,212.37867
Policy Entropy: 3.72078
Value Function Loss: 0.05073

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.36867
Value Function Update Magnitude: 0.65310

Collected Steps per Second: 22,866.53220
Overall Steps per Second: 10,798.46148

Timestep Collection Time: 2.18704
Timestep Consumption Time: 2.44418
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.63122

Cumulative Model Updates: 41,336
Cumulative Timesteps: 344,809,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 344809592...
Checkpoint 344809592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,492.35483
Policy Entropy: 3.71679
Value Function Loss: 0.04945

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.32492
Value Function Update Magnitude: 0.62829

Collected Steps per Second: 22,541.22859
Overall Steps per Second: 10,770.22666

Timestep Collection Time: 2.21913
Timestep Consumption Time: 2.42534
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.64447

Cumulative Model Updates: 41,342
Cumulative Timesteps: 344,859,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,799.73767
Policy Entropy: 3.71076
Value Function Loss: 0.04682

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.36450
Value Function Update Magnitude: 0.64095

Collected Steps per Second: 22,916.10322
Overall Steps per Second: 10,804.58313

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.44707
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63007

Cumulative Model Updates: 41,348
Cumulative Timesteps: 344,909,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 344909640...
Checkpoint 344909640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.97995
Policy Entropy: 3.71086
Value Function Loss: 0.04556

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.40345
Value Function Update Magnitude: 0.64303

Collected Steps per Second: 22,360.03329
Overall Steps per Second: 10,521.99328

Timestep Collection Time: 2.23667
Timestep Consumption Time: 2.51642
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.75309

Cumulative Model Updates: 41,354
Cumulative Timesteps: 344,959,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,369.29766
Policy Entropy: 3.70941
Value Function Loss: 0.04725

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.41353
Value Function Update Magnitude: 0.62877

Collected Steps per Second: 22,618.15370
Overall Steps per Second: 10,656.08088

Timestep Collection Time: 2.21176
Timestep Consumption Time: 2.48283
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.69460

Cumulative Model Updates: 41,360
Cumulative Timesteps: 345,009,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 345009678...
Checkpoint 345009678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,453.17854
Policy Entropy: 3.71027
Value Function Loss: 0.04663

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.40087
Value Function Update Magnitude: 0.68175

Collected Steps per Second: 22,061.92264
Overall Steps per Second: 10,589.30835

Timestep Collection Time: 2.26725
Timestep Consumption Time: 2.45638
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.72363

Cumulative Model Updates: 41,366
Cumulative Timesteps: 345,059,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,642.91667
Policy Entropy: 3.71706
Value Function Loss: 0.04587

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.44590
Value Function Update Magnitude: 0.65214

Collected Steps per Second: 22,670.83183
Overall Steps per Second: 10,590.23926

Timestep Collection Time: 2.20557
Timestep Consumption Time: 2.51595
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.72152

Cumulative Model Updates: 41,372
Cumulative Timesteps: 345,109,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 345109700...
Checkpoint 345109700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,448.30837
Policy Entropy: 3.71629
Value Function Loss: 0.04402

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.46407
Value Function Update Magnitude: 0.71678

Collected Steps per Second: 22,496.15468
Overall Steps per Second: 10,553.37952

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.73915

Cumulative Model Updates: 41,378
Cumulative Timesteps: 345,159,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,187.74992
Policy Entropy: 3.71428
Value Function Loss: 0.04371

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.43308
Value Function Update Magnitude: 0.75936

Collected Steps per Second: 22,760.12154
Overall Steps per Second: 10,646.75391

Timestep Collection Time: 2.19788
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.69852

Cumulative Model Updates: 41,384
Cumulative Timesteps: 345,209,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 345209738...
Checkpoint 345209738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,700.27197
Policy Entropy: 3.71834
Value Function Loss: 0.04345

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.42856
Value Function Update Magnitude: 0.77785

Collected Steps per Second: 22,617.29596
Overall Steps per Second: 10,632.81268

Timestep Collection Time: 2.21096
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.70299

Cumulative Model Updates: 41,390
Cumulative Timesteps: 345,259,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,713.82443
Policy Entropy: 3.70650
Value Function Loss: 0.04416

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06118
Policy Update Magnitude: 0.47217
Value Function Update Magnitude: 0.79702

Collected Steps per Second: 22,884.78685
Overall Steps per Second: 10,798.53188

Timestep Collection Time: 2.18608
Timestep Consumption Time: 2.44677
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.63285

Cumulative Model Updates: 41,396
Cumulative Timesteps: 345,309,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 345309772...
Checkpoint 345309772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,947.71816
Policy Entropy: 3.69844
Value Function Loss: 0.04665

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.46816
Value Function Update Magnitude: 0.80389

Collected Steps per Second: 22,638.18342
Overall Steps per Second: 10,594.37633

Timestep Collection Time: 2.20945
Timestep Consumption Time: 2.51173
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.72118

Cumulative Model Updates: 41,402
Cumulative Timesteps: 345,359,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,310.61845
Policy Entropy: 3.70222
Value Function Loss: 0.04786

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.40654
Value Function Update Magnitude: 0.78141

Collected Steps per Second: 22,826.72739
Overall Steps per Second: 10,772.64472

Timestep Collection Time: 2.19077
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.64213

Cumulative Model Updates: 41,408
Cumulative Timesteps: 345,409,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 345409798...
Checkpoint 345409798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.83920
Policy Entropy: 3.71397
Value Function Loss: 0.04859

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.36586
Value Function Update Magnitude: 0.78939

Collected Steps per Second: 22,058.25163
Overall Steps per Second: 10,669.47546

Timestep Collection Time: 2.26799
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.68889

Cumulative Model Updates: 41,414
Cumulative Timesteps: 345,459,826

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,594.53135
Policy Entropy: 3.74535
Value Function Loss: 0.04485

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.38600
Value Function Update Magnitude: 0.83360

Collected Steps per Second: 22,747.17539
Overall Steps per Second: 10,601.70506

Timestep Collection Time: 2.19843
Timestep Consumption Time: 2.51855
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.71698

Cumulative Model Updates: 41,420
Cumulative Timesteps: 345,509,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 345509834...
Checkpoint 345509834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,367.35275
Policy Entropy: 3.74146
Value Function Loss: 0.04238

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06774
Policy Update Magnitude: 0.46118
Value Function Update Magnitude: 0.83234

Collected Steps per Second: 22,603.77833
Overall Steps per Second: 10,568.94149

Timestep Collection Time: 2.21326
Timestep Consumption Time: 2.52023
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.73349

Cumulative Model Updates: 41,426
Cumulative Timesteps: 345,559,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,864.77633
Policy Entropy: 3.72837
Value Function Loss: 0.04395

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.46600
Value Function Update Magnitude: 0.79824

Collected Steps per Second: 22,283.68613
Overall Steps per Second: 10,383.61871

Timestep Collection Time: 2.24406
Timestep Consumption Time: 2.57179
PPO Batch Consumption Time: 0.30234
Total Iteration Time: 4.81585

Cumulative Model Updates: 41,432
Cumulative Timesteps: 345,609,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 345609868...
Checkpoint 345609868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,089.61315
Policy Entropy: 3.71100
Value Function Loss: 0.04342

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.38851
Value Function Update Magnitude: 0.78630

Collected Steps per Second: 22,282.44140
Overall Steps per Second: 10,646.94023

Timestep Collection Time: 2.24410
Timestep Consumption Time: 2.45246
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.69656

Cumulative Model Updates: 41,438
Cumulative Timesteps: 345,659,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,445.45324
Policy Entropy: 3.72415
Value Function Loss: 0.04304

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12073
Policy Update Magnitude: 0.36739
Value Function Update Magnitude: 0.78294

Collected Steps per Second: 22,524.14638
Overall Steps per Second: 10,516.48392

Timestep Collection Time: 2.22055
Timestep Consumption Time: 2.53541
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.75596

Cumulative Model Updates: 41,444
Cumulative Timesteps: 345,709,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 345709888...
Checkpoint 345709888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,960.08336
Policy Entropy: 3.73921
Value Function Loss: 0.04194

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.35957
Value Function Update Magnitude: 0.78387

Collected Steps per Second: 22,336.44524
Overall Steps per Second: 10,678.56217

Timestep Collection Time: 2.23858
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.68247

Cumulative Model Updates: 41,450
Cumulative Timesteps: 345,759,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.05603
Policy Entropy: 3.73993
Value Function Loss: 0.04353

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.39908
Value Function Update Magnitude: 0.65587

Collected Steps per Second: 22,817.87736
Overall Steps per Second: 10,781.31087

Timestep Collection Time: 2.19161
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.63840

Cumulative Model Updates: 41,456
Cumulative Timesteps: 345,809,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 345809898...
Checkpoint 345809898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,795.52266
Policy Entropy: 3.74391
Value Function Loss: 0.04052

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.42977
Value Function Update Magnitude: 0.64229

Collected Steps per Second: 22,225.79555
Overall Steps per Second: 10,705.68992

Timestep Collection Time: 2.25063
Timestep Consumption Time: 2.42184
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.67247

Cumulative Model Updates: 41,462
Cumulative Timesteps: 345,859,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,234.64784
Policy Entropy: 3.73188
Value Function Loss: 0.03838

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.46865
Value Function Update Magnitude: 0.72435

Collected Steps per Second: 22,717.17140
Overall Steps per Second: 10,595.63854

Timestep Collection Time: 2.20133
Timestep Consumption Time: 2.51835
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.71968

Cumulative Model Updates: 41,468
Cumulative Timesteps: 345,909,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 345909928...
Checkpoint 345909928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,642.17495
Policy Entropy: 3.73127
Value Function Loss: 0.03616

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.44858
Value Function Update Magnitude: 0.73446

Collected Steps per Second: 22,363.75149
Overall Steps per Second: 10,528.46383

Timestep Collection Time: 2.23621
Timestep Consumption Time: 2.51377
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.74998

Cumulative Model Updates: 41,474
Cumulative Timesteps: 345,959,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,388.44575
Policy Entropy: 3.73404
Value Function Loss: 0.03992

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.42123
Value Function Update Magnitude: 0.72157

Collected Steps per Second: 22,603.09954
Overall Steps per Second: 10,614.08290

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.71411

Cumulative Model Updates: 41,480
Cumulative Timesteps: 346,009,974

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 346009974...
Checkpoint 346009974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,989.60242
Policy Entropy: 3.74144
Value Function Loss: 0.04032

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.39123
Value Function Update Magnitude: 0.74471

Collected Steps per Second: 22,425.21841
Overall Steps per Second: 10,524.25508

Timestep Collection Time: 2.23017
Timestep Consumption Time: 2.52190
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.75207

Cumulative Model Updates: 41,486
Cumulative Timesteps: 346,059,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,148.90204
Policy Entropy: 3.74795
Value Function Loss: 0.04137

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.39342
Value Function Update Magnitude: 0.76897

Collected Steps per Second: 22,551.54450
Overall Steps per Second: 10,609.80029

Timestep Collection Time: 2.21803
Timestep Consumption Time: 2.49648
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.71451

Cumulative Model Updates: 41,492
Cumulative Timesteps: 346,110,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 346110006...
Checkpoint 346110006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,924.80394
Policy Entropy: 3.75250
Value Function Loss: 0.04204

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.42509
Value Function Update Magnitude: 0.79003

Collected Steps per Second: 22,752.59658
Overall Steps per Second: 10,587.93006

Timestep Collection Time: 2.19843
Timestep Consumption Time: 2.52582
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.72425

Cumulative Model Updates: 41,498
Cumulative Timesteps: 346,160,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,535.01193
Policy Entropy: 3.74823
Value Function Loss: 0.04264

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.42114
Value Function Update Magnitude: 0.76361

Collected Steps per Second: 22,692.52160
Overall Steps per Second: 10,748.83770

Timestep Collection Time: 2.20372
Timestep Consumption Time: 2.44869
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.65241

Cumulative Model Updates: 41,504
Cumulative Timesteps: 346,210,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 346210034...
Checkpoint 346210034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,320.06404
Policy Entropy: 3.74557
Value Function Loss: 0.04090

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.40851
Value Function Update Magnitude: 0.76127

Collected Steps per Second: 21,910.40647
Overall Steps per Second: 10,632.28109

Timestep Collection Time: 2.28321
Timestep Consumption Time: 2.42190
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.70511

Cumulative Model Updates: 41,510
Cumulative Timesteps: 346,260,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.80207
Policy Entropy: 3.74392
Value Function Loss: 0.04105

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.41288
Value Function Update Magnitude: 0.76915

Collected Steps per Second: 23,041.15941
Overall Steps per Second: 10,857.22099

Timestep Collection Time: 2.17081
Timestep Consumption Time: 2.43608
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60689

Cumulative Model Updates: 41,516
Cumulative Timesteps: 346,310,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 346310078...
Checkpoint 346310078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,599.62407
Policy Entropy: 3.75951
Value Function Loss: 0.04148

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.43497
Value Function Update Magnitude: 0.75771

Collected Steps per Second: 22,451.85015
Overall Steps per Second: 10,755.33598

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.42216
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.64941

Cumulative Model Updates: 41,522
Cumulative Timesteps: 346,360,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.98072
Policy Entropy: 3.76230
Value Function Loss: 0.04165

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.43001
Value Function Update Magnitude: 0.76423

Collected Steps per Second: 23,144.54255
Overall Steps per Second: 10,822.01406

Timestep Collection Time: 2.16163
Timestep Consumption Time: 2.46135
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.62298

Cumulative Model Updates: 41,528
Cumulative Timesteps: 346,410,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 346410114...
Checkpoint 346410114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,526.65575
Policy Entropy: 3.77412
Value Function Loss: 0.04033

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07918
Policy Update Magnitude: 0.43397
Value Function Update Magnitude: 0.78519

Collected Steps per Second: 22,518.07672
Overall Steps per Second: 10,749.67410

Timestep Collection Time: 2.22044
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.65130

Cumulative Model Updates: 41,534
Cumulative Timesteps: 346,460,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,365.58462
Policy Entropy: 3.76701
Value Function Loss: 0.04065

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.45944
Value Function Update Magnitude: 0.74620

Collected Steps per Second: 22,900.05846
Overall Steps per Second: 10,820.41807

Timestep Collection Time: 2.18427
Timestep Consumption Time: 2.43847
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.62274

Cumulative Model Updates: 41,540
Cumulative Timesteps: 346,510,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 346510134...
Checkpoint 346510134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,230.99565
Policy Entropy: 3.75827
Value Function Loss: 0.04288

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07883
Policy Update Magnitude: 0.45618
Value Function Update Magnitude: 0.63139

Collected Steps per Second: 22,222.24789
Overall Steps per Second: 10,671.39673

Timestep Collection Time: 2.25117
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.68786

Cumulative Model Updates: 41,546
Cumulative Timesteps: 346,560,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,191.14810
Policy Entropy: 3.75451
Value Function Loss: 0.04510

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.46963
Value Function Update Magnitude: 0.62236

Collected Steps per Second: 22,878.69389
Overall Steps per Second: 10,848.07819

Timestep Collection Time: 2.18623
Timestep Consumption Time: 2.42454
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.61077

Cumulative Model Updates: 41,552
Cumulative Timesteps: 346,610,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 346610178...
Checkpoint 346610178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,380.83791
Policy Entropy: 3.75015
Value Function Loss: 0.04673

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05701
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.64443

Collected Steps per Second: 22,344.79330
Overall Steps per Second: 10,714.62590

Timestep Collection Time: 2.23972
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.67081

Cumulative Model Updates: 41,558
Cumulative Timesteps: 346,660,224

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,217.89413
Policy Entropy: 3.74513
Value Function Loss: 0.04618

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05092
Policy Update Magnitude: 0.55795
Value Function Update Magnitude: 0.62268

Collected Steps per Second: 22,748.61268
Overall Steps per Second: 10,620.71482

Timestep Collection Time: 2.19829
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.70853

Cumulative Model Updates: 41,564
Cumulative Timesteps: 346,710,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 346710232...
Checkpoint 346710232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,600.93140
Policy Entropy: 3.74058
Value Function Loss: 0.04291

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05610
Policy Update Magnitude: 0.55865
Value Function Update Magnitude: 0.63940

Collected Steps per Second: 22,609.40812
Overall Steps per Second: 10,617.72001

Timestep Collection Time: 2.21226
Timestep Consumption Time: 2.49854
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.71080

Cumulative Model Updates: 41,570
Cumulative Timesteps: 346,760,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,414.83900
Policy Entropy: 3.73570
Value Function Loss: 0.04245

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.50875
Value Function Update Magnitude: 0.68537

Collected Steps per Second: 23,010.03347
Overall Steps per Second: 10,794.16971

Timestep Collection Time: 2.17383
Timestep Consumption Time: 2.46015
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.63398

Cumulative Model Updates: 41,576
Cumulative Timesteps: 346,810,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 346810270...
Checkpoint 346810270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,816.39645
Policy Entropy: 3.72934
Value Function Loss: 0.04183

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.43430
Value Function Update Magnitude: 0.70522

Collected Steps per Second: 22,422.27936
Overall Steps per Second: 10,583.95269

Timestep Collection Time: 2.23117
Timestep Consumption Time: 2.49560
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.72678

Cumulative Model Updates: 41,582
Cumulative Timesteps: 346,860,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,538.55703
Policy Entropy: 3.72381
Value Function Loss: 0.04173

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.43377
Value Function Update Magnitude: 0.71149

Collected Steps per Second: 22,741.84591
Overall Steps per Second: 10,661.74907

Timestep Collection Time: 2.19956
Timestep Consumption Time: 2.49217
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.69173

Cumulative Model Updates: 41,588
Cumulative Timesteps: 346,910,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 346910320...
Checkpoint 346910320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,672.61224
Policy Entropy: 3.72949
Value Function Loss: 0.04340

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.43650
Value Function Update Magnitude: 0.71483

Collected Steps per Second: 22,549.95383
Overall Steps per Second: 10,616.46688

Timestep Collection Time: 2.21774
Timestep Consumption Time: 2.49286
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.71061

Cumulative Model Updates: 41,594
Cumulative Timesteps: 346,960,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,828.26540
Policy Entropy: 3.73028
Value Function Loss: 0.04357

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.42349
Value Function Update Magnitude: 0.74293

Collected Steps per Second: 23,077.80753
Overall Steps per Second: 10,765.57375

Timestep Collection Time: 2.16736
Timestep Consumption Time: 2.47874
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.64611

Cumulative Model Updates: 41,600
Cumulative Timesteps: 347,010,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 347010348...
Checkpoint 347010348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,774.71129
Policy Entropy: 3.72215
Value Function Loss: 0.04386

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.43840
Value Function Update Magnitude: 0.73979

Collected Steps per Second: 22,352.70914
Overall Steps per Second: 10,635.19750

Timestep Collection Time: 2.23695
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.70156

Cumulative Model Updates: 41,606
Cumulative Timesteps: 347,060,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,111.73568
Policy Entropy: 3.73471
Value Function Loss: 0.04264

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.44351
Value Function Update Magnitude: 0.73504

Collected Steps per Second: 22,933.31866
Overall Steps per Second: 10,837.17302

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.43400
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.61467

Cumulative Model Updates: 41,612
Cumulative Timesteps: 347,110,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 347110360...
Checkpoint 347110360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.44748
Policy Entropy: 3.73112
Value Function Loss: 0.04152

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08536
Policy Update Magnitude: 0.42937
Value Function Update Magnitude: 0.74413

Collected Steps per Second: 22,408.28902
Overall Steps per Second: 10,760.19056

Timestep Collection Time: 2.23239
Timestep Consumption Time: 2.41660
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.64899

Cumulative Model Updates: 41,618
Cumulative Timesteps: 347,160,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,807.87619
Policy Entropy: 3.73162
Value Function Loss: 0.04247

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.43009
Value Function Update Magnitude: 0.74873

Collected Steps per Second: 23,097.52764
Overall Steps per Second: 10,834.95892

Timestep Collection Time: 2.16517
Timestep Consumption Time: 2.45045
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.61562

Cumulative Model Updates: 41,624
Cumulative Timesteps: 347,210,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 347210394...
Checkpoint 347210394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,157.81578
Policy Entropy: 3.72323
Value Function Loss: 0.04298

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.45749
Value Function Update Magnitude: 0.78005

Collected Steps per Second: 22,066.79811
Overall Steps per Second: 10,618.21809

Timestep Collection Time: 2.26630
Timestep Consumption Time: 2.44353
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.70983

Cumulative Model Updates: 41,630
Cumulative Timesteps: 347,260,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,631.52768
Policy Entropy: 3.71984
Value Function Loss: 0.04251

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.43282
Value Function Update Magnitude: 0.76694

Collected Steps per Second: 23,108.91627
Overall Steps per Second: 10,860.64439

Timestep Collection Time: 2.16419
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.60488

Cumulative Model Updates: 41,636
Cumulative Timesteps: 347,310,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 347310416...
Checkpoint 347310416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,263.44200
Policy Entropy: 3.72466
Value Function Loss: 0.04246

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.44288
Value Function Update Magnitude: 0.72562

Collected Steps per Second: 22,303.85930
Overall Steps per Second: 10,696.85679

Timestep Collection Time: 2.24176
Timestep Consumption Time: 2.43251
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.67427

Cumulative Model Updates: 41,642
Cumulative Timesteps: 347,360,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.14674
Policy Entropy: 3.73108
Value Function Loss: 0.04406

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.44053
Value Function Update Magnitude: 0.71379

Collected Steps per Second: 22,935.32220
Overall Steps per Second: 10,817.47899

Timestep Collection Time: 2.18022
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.62252

Cumulative Model Updates: 41,648
Cumulative Timesteps: 347,410,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 347410420...
Checkpoint 347410420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,426.45235
Policy Entropy: 3.74717
Value Function Loss: 0.04371

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.44300
Value Function Update Magnitude: 0.75422

Collected Steps per Second: 22,262.15475
Overall Steps per Second: 10,666.68965

Timestep Collection Time: 2.24623
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.68805

Cumulative Model Updates: 41,654
Cumulative Timesteps: 347,460,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,544.67857
Policy Entropy: 3.75718
Value Function Loss: 0.04330

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.44001
Value Function Update Magnitude: 0.75861

Collected Steps per Second: 22,684.50169
Overall Steps per Second: 10,721.07238

Timestep Collection Time: 2.20529
Timestep Consumption Time: 2.46084
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.66614

Cumulative Model Updates: 41,660
Cumulative Timesteps: 347,510,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 347510452...
Checkpoint 347510452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.08864
Policy Entropy: 3.75524
Value Function Loss: 0.04214

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.45625
Value Function Update Magnitude: 0.74678

Collected Steps per Second: 22,613.58235
Overall Steps per Second: 10,620.73798

Timestep Collection Time: 2.21115
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.70796

Cumulative Model Updates: 41,666
Cumulative Timesteps: 347,560,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,279.28950
Policy Entropy: 3.74766
Value Function Loss: 0.04285

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.44894
Value Function Update Magnitude: 0.75401

Collected Steps per Second: 23,259.25186
Overall Steps per Second: 10,724.93316

Timestep Collection Time: 2.14977
Timestep Consumption Time: 2.51245
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.66222

Cumulative Model Updates: 41,672
Cumulative Timesteps: 347,610,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 347610456...
Checkpoint 347610456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,914.98469
Policy Entropy: 3.74504
Value Function Loss: 0.04116

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.42376
Value Function Update Magnitude: 0.77016

Collected Steps per Second: 22,690.89491
Overall Steps per Second: 10,626.16241

Timestep Collection Time: 2.20370
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.70574

Cumulative Model Updates: 41,678
Cumulative Timesteps: 347,660,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,163.98425
Policy Entropy: 3.73962
Value Function Loss: 0.04199

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.45287
Value Function Update Magnitude: 0.75432

Collected Steps per Second: 22,730.48561
Overall Steps per Second: 10,843.59092

Timestep Collection Time: 2.20066
Timestep Consumption Time: 2.41239
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.61305

Cumulative Model Updates: 41,684
Cumulative Timesteps: 347,710,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 347710482...
Checkpoint 347710482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,303.04210
Policy Entropy: 3.73546
Value Function Loss: 0.04189

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.44704
Value Function Update Magnitude: 0.73594

Collected Steps per Second: 22,232.08220
Overall Steps per Second: 10,681.87743

Timestep Collection Time: 2.24927
Timestep Consumption Time: 2.43211
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.68139

Cumulative Model Updates: 41,690
Cumulative Timesteps: 347,760,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,810.08813
Policy Entropy: 3.73150
Value Function Loss: 0.04478

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.44953
Value Function Update Magnitude: 0.69546

Collected Steps per Second: 23,226.41107
Overall Steps per Second: 10,890.64123

Timestep Collection Time: 2.15332
Timestep Consumption Time: 2.43906
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.59238

Cumulative Model Updates: 41,696
Cumulative Timesteps: 347,810,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 347810502...
Checkpoint 347810502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,247.43056
Policy Entropy: 3.73791
Value Function Loss: 0.04457

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.44291
Value Function Update Magnitude: 0.59340

Collected Steps per Second: 22,283.20490
Overall Steps per Second: 10,692.98316

Timestep Collection Time: 2.24501
Timestep Consumption Time: 2.43339
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.67840

Cumulative Model Updates: 41,702
Cumulative Timesteps: 347,860,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,595.45358
Policy Entropy: 3.73864
Value Function Loss: 0.04550

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.45967
Value Function Update Magnitude: 0.57814

Collected Steps per Second: 22,929.05449
Overall Steps per Second: 10,837.37256

Timestep Collection Time: 2.18195
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.61643

Cumulative Model Updates: 41,708
Cumulative Timesteps: 347,910,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 347910558...
Checkpoint 347910558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,646.61264
Policy Entropy: 3.74449
Value Function Loss: 0.04372

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.45008
Value Function Update Magnitude: 0.61477

Collected Steps per Second: 22,456.54409
Overall Steps per Second: 10,747.48842

Timestep Collection Time: 2.22759
Timestep Consumption Time: 2.42689
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.65448

Cumulative Model Updates: 41,714
Cumulative Timesteps: 347,960,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,448.00775
Policy Entropy: 3.74672
Value Function Loss: 0.04177

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.48591
Value Function Update Magnitude: 0.61935

Collected Steps per Second: 22,947.19506
Overall Steps per Second: 10,809.96288

Timestep Collection Time: 2.17900
Timestep Consumption Time: 2.44655
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.62555

Cumulative Model Updates: 41,720
Cumulative Timesteps: 348,010,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 348010584...
Checkpoint 348010584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,537.19042
Policy Entropy: 3.74757
Value Function Loss: 0.04182

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.50055
Value Function Update Magnitude: 0.57182

Collected Steps per Second: 22,464.59067
Overall Steps per Second: 10,727.67609

Timestep Collection Time: 2.22679
Timestep Consumption Time: 2.43629
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.66308

Cumulative Model Updates: 41,726
Cumulative Timesteps: 348,060,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,480.96621
Policy Entropy: 3.74295
Value Function Loss: 0.04256

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.47294
Value Function Update Magnitude: 0.54404

Collected Steps per Second: 23,045.45929
Overall Steps per Second: 10,857.90878

Timestep Collection Time: 2.16962
Timestep Consumption Time: 2.43531
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.60494

Cumulative Model Updates: 41,732
Cumulative Timesteps: 348,110,608

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 348110608...
Checkpoint 348110608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,553.23275
Policy Entropy: 3.73625
Value Function Loss: 0.04572

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05971
Policy Update Magnitude: 0.50458
Value Function Update Magnitude: 0.52679

Collected Steps per Second: 22,455.45784
Overall Steps per Second: 10,740.31526

Timestep Collection Time: 2.22708
Timestep Consumption Time: 2.42921
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.65629

Cumulative Model Updates: 41,738
Cumulative Timesteps: 348,160,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,058.39465
Policy Entropy: 3.72741
Value Function Loss: 0.04726

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.53064

Collected Steps per Second: 22,967.15210
Overall Steps per Second: 10,807.97480

Timestep Collection Time: 2.17702
Timestep Consumption Time: 2.44919
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.62621

Cumulative Model Updates: 41,744
Cumulative Timesteps: 348,210,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 348210618...
Checkpoint 348210618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,979.11133
Policy Entropy: 3.72767
Value Function Loss: 0.04748

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.56945
Value Function Update Magnitude: 0.60715

Collected Steps per Second: 22,404.80644
Overall Steps per Second: 10,725.06751

Timestep Collection Time: 2.23300
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.66477

Cumulative Model Updates: 41,750
Cumulative Timesteps: 348,260,648

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,424.08096
Policy Entropy: 3.73185
Value Function Loss: 0.04398

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.49070
Value Function Update Magnitude: 0.73211

Collected Steps per Second: 23,101.19877
Overall Steps per Second: 10,819.85751

Timestep Collection Time: 2.16526
Timestep Consumption Time: 2.45773
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.62298

Cumulative Model Updates: 41,756
Cumulative Timesteps: 348,310,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 348310668...
Checkpoint 348310668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,984.15249
Policy Entropy: 3.74674
Value Function Loss: 0.04387

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.44832
Value Function Update Magnitude: 0.75445

Collected Steps per Second: 22,144.76505
Overall Steps per Second: 10,628.55521

Timestep Collection Time: 2.25805
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.70468

Cumulative Model Updates: 41,762
Cumulative Timesteps: 348,360,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,853.21879
Policy Entropy: 3.75223
Value Function Loss: 0.04299

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.43948
Value Function Update Magnitude: 0.76900

Collected Steps per Second: 23,089.64297
Overall Steps per Second: 10,863.27195

Timestep Collection Time: 2.16608
Timestep Consumption Time: 2.43787
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.60395

Cumulative Model Updates: 41,768
Cumulative Timesteps: 348,410,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 348410686...
Checkpoint 348410686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,264.31377
Policy Entropy: 3.74774
Value Function Loss: 0.04431

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.42037
Value Function Update Magnitude: 0.76868

Collected Steps per Second: 22,245.24893
Overall Steps per Second: 10,641.31792

Timestep Collection Time: 2.24821
Timestep Consumption Time: 2.45158
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.69979

Cumulative Model Updates: 41,774
Cumulative Timesteps: 348,460,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,575.51561
Policy Entropy: 3.74626
Value Function Loss: 0.04214

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.43323
Value Function Update Magnitude: 0.77568

Collected Steps per Second: 22,983.55497
Overall Steps per Second: 10,713.67341

Timestep Collection Time: 2.17730
Timestep Consumption Time: 2.49356
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.67085

Cumulative Model Updates: 41,780
Cumulative Timesteps: 348,510,740

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 348510740...
Checkpoint 348510740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,049.67181
Policy Entropy: 3.74306
Value Function Loss: 0.04337

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.43350
Value Function Update Magnitude: 0.76957

Collected Steps per Second: 22,776.09446
Overall Steps per Second: 10,886.98950

Timestep Collection Time: 2.19616
Timestep Consumption Time: 2.39831
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.59447

Cumulative Model Updates: 41,786
Cumulative Timesteps: 348,560,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.61920
Policy Entropy: 3.74456
Value Function Loss: 0.04291

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.46373
Value Function Update Magnitude: 0.74988

Collected Steps per Second: 22,898.53950
Overall Steps per Second: 10,661.69135

Timestep Collection Time: 2.18381
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.69025

Cumulative Model Updates: 41,792
Cumulative Timesteps: 348,610,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 348610766...
Checkpoint 348610766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,388.94947
Policy Entropy: 3.75059
Value Function Loss: 0.04378

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.45094
Value Function Update Magnitude: 0.75723

Collected Steps per Second: 22,641.74107
Overall Steps per Second: 10,612.56049

Timestep Collection Time: 2.20902
Timestep Consumption Time: 2.50389
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.71291

Cumulative Model Updates: 41,798
Cumulative Timesteps: 348,660,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,422.82462
Policy Entropy: 3.75166
Value Function Loss: 0.04438

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.43125
Value Function Update Magnitude: 0.73904

Collected Steps per Second: 22,912.83715
Overall Steps per Second: 10,784.69260

Timestep Collection Time: 2.18244
Timestep Consumption Time: 2.45431
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.63676

Cumulative Model Updates: 41,804
Cumulative Timesteps: 348,710,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 348710788...
Checkpoint 348710788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,248.81240
Policy Entropy: 3.76348
Value Function Loss: 0.04544

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.46531
Value Function Update Magnitude: 0.69651

Collected Steps per Second: 22,267.23189
Overall Steps per Second: 10,654.12366

Timestep Collection Time: 2.24653
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.69527

Cumulative Model Updates: 41,810
Cumulative Timesteps: 348,760,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,111.02078
Policy Entropy: 3.76799
Value Function Loss: 0.04609

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.46649
Value Function Update Magnitude: 0.62458

Collected Steps per Second: 23,146.76915
Overall Steps per Second: 10,850.74827

Timestep Collection Time: 2.16039
Timestep Consumption Time: 2.44814
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.60853

Cumulative Model Updates: 41,816
Cumulative Timesteps: 348,810,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 348810818...
Checkpoint 348810818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,404.86642
Policy Entropy: 3.76828
Value Function Loss: 0.04521

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.44884
Value Function Update Magnitude: 0.68096

Collected Steps per Second: 22,382.10105
Overall Steps per Second: 10,695.31776

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.44170
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.67625

Cumulative Model Updates: 41,822
Cumulative Timesteps: 348,860,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,899.90286
Policy Entropy: 3.75125
Value Function Loss: 0.04492

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.46217
Value Function Update Magnitude: 0.77428

Collected Steps per Second: 22,861.98965
Overall Steps per Second: 10,823.67313

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.43480
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.62394

Cumulative Model Updates: 41,828
Cumulative Timesteps: 348,910,880

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 348910880...
Checkpoint 348910880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,279.65574
Policy Entropy: 3.74368
Value Function Loss: 0.04422

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.47265
Value Function Update Magnitude: 0.79513

Collected Steps per Second: 22,314.31361
Overall Steps per Second: 10,656.23549

Timestep Collection Time: 2.24125
Timestep Consumption Time: 2.45196
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.69321

Cumulative Model Updates: 41,834
Cumulative Timesteps: 348,960,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,162.99884
Policy Entropy: 3.73406
Value Function Loss: 0.04659

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.48377
Value Function Update Magnitude: 0.74268

Collected Steps per Second: 23,088.97974
Overall Steps per Second: 10,736.07018

Timestep Collection Time: 2.16606
Timestep Consumption Time: 2.49226
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.65832

Cumulative Model Updates: 41,840
Cumulative Timesteps: 349,010,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 349010904...
Checkpoint 349010904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,594.39393
Policy Entropy: 3.74913
Value Function Loss: 0.04674

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.45804
Value Function Update Magnitude: 0.68832

Collected Steps per Second: 22,224.41622
Overall Steps per Second: 10,517.03558

Timestep Collection Time: 2.25059
Timestep Consumption Time: 2.50532
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.75590

Cumulative Model Updates: 41,846
Cumulative Timesteps: 349,060,922

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,557.83294
Policy Entropy: 3.75946
Value Function Loss: 0.04488

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08108
Policy Update Magnitude: 0.47523
Value Function Update Magnitude: 0.67605

Collected Steps per Second: 23,124.10110
Overall Steps per Second: 10,829.59664

Timestep Collection Time: 2.16320
Timestep Consumption Time: 2.45581
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.61901

Cumulative Model Updates: 41,852
Cumulative Timesteps: 349,110,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 349110944...
Checkpoint 349110944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.46180
Policy Entropy: 3.75651
Value Function Loss: 0.04433

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.49395
Value Function Update Magnitude: 0.69850

Collected Steps per Second: 22,507.18482
Overall Steps per Second: 10,629.79540

Timestep Collection Time: 2.22205
Timestep Consumption Time: 2.48284
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.70489

Cumulative Model Updates: 41,858
Cumulative Timesteps: 349,160,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,352.73123
Policy Entropy: 3.76479
Value Function Loss: 0.04411

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.45954
Value Function Update Magnitude: 0.59541

Collected Steps per Second: 22,902.13777
Overall Steps per Second: 10,781.26153

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.45585
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.64027

Cumulative Model Updates: 41,864
Cumulative Timesteps: 349,210,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 349210984...
Checkpoint 349210984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,842.98676
Policy Entropy: 3.76217
Value Function Loss: 0.04517

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06961
Policy Update Magnitude: 0.49307
Value Function Update Magnitude: 0.60861

Collected Steps per Second: 22,266.59796
Overall Steps per Second: 10,658.91564

Timestep Collection Time: 2.24677
Timestep Consumption Time: 2.44676
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.69354

Cumulative Model Updates: 41,870
Cumulative Timesteps: 349,261,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,997.20601
Policy Entropy: 3.75293
Value Function Loss: 0.04503

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.49296
Value Function Update Magnitude: 0.69063

Collected Steps per Second: 23,207.84460
Overall Steps per Second: 10,767.67271

Timestep Collection Time: 2.15496
Timestep Consumption Time: 2.48968
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.64464

Cumulative Model Updates: 41,876
Cumulative Timesteps: 349,311,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 349311024...
Checkpoint 349311024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,962.97080
Policy Entropy: 3.74497
Value Function Loss: 0.04436

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.47023
Value Function Update Magnitude: 0.72652

Collected Steps per Second: 22,585.78233
Overall Steps per Second: 10,653.96786

Timestep Collection Time: 2.21573
Timestep Consumption Time: 2.48149
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.69722

Cumulative Model Updates: 41,882
Cumulative Timesteps: 349,361,068

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,655.87183
Policy Entropy: 3.76246
Value Function Loss: 0.04284

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.44954
Value Function Update Magnitude: 0.72491

Collected Steps per Second: 22,639.12683
Overall Steps per Second: 10,677.60041

Timestep Collection Time: 2.20910
Timestep Consumption Time: 2.47473
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.68382

Cumulative Model Updates: 41,888
Cumulative Timesteps: 349,411,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 349411080...
Checkpoint 349411080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,508.81246
Policy Entropy: 3.76087
Value Function Loss: 0.04092

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.50259
Value Function Update Magnitude: 0.77185

Collected Steps per Second: 22,383.16118
Overall Steps per Second: 10,648.55188

Timestep Collection Time: 2.23552
Timestep Consumption Time: 2.46352
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.69904

Cumulative Model Updates: 41,894
Cumulative Timesteps: 349,461,118

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,490.58619
Policy Entropy: 3.75913
Value Function Loss: 0.04244

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.48756
Value Function Update Magnitude: 0.76389

Collected Steps per Second: 22,794.75909
Overall Steps per Second: 10,680.15582

Timestep Collection Time: 2.19357
Timestep Consumption Time: 2.48819
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.68177

Cumulative Model Updates: 41,900
Cumulative Timesteps: 349,511,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 349511120...
Checkpoint 349511120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,142.87445
Policy Entropy: 3.74800
Value Function Loss: 0.04376

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.45030
Value Function Update Magnitude: 0.76469

Collected Steps per Second: 22,679.23090
Overall Steps per Second: 10,798.09078

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.42579
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.63045

Cumulative Model Updates: 41,906
Cumulative Timesteps: 349,561,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,895.24507
Policy Entropy: 3.75415
Value Function Loss: 0.04434

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08941
Policy Update Magnitude: 0.44375
Value Function Update Magnitude: 0.75895

Collected Steps per Second: 22,885.31116
Overall Steps per Second: 10,647.76985

Timestep Collection Time: 2.18507
Timestep Consumption Time: 2.51131
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.69638

Cumulative Model Updates: 41,912
Cumulative Timesteps: 349,611,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 349611126...
Checkpoint 349611126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,809.50851
Policy Entropy: 3.75533
Value Function Loss: 0.04399

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.45371
Value Function Update Magnitude: 0.72327

Collected Steps per Second: 22,356.58962
Overall Steps per Second: 10,527.13041

Timestep Collection Time: 2.23728
Timestep Consumption Time: 2.51406
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.75134

Cumulative Model Updates: 41,918
Cumulative Timesteps: 349,661,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.69720
Policy Entropy: 3.76131
Value Function Loss: 0.04442

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.45215
Value Function Update Magnitude: 0.67509

Collected Steps per Second: 22,965.67175
Overall Steps per Second: 10,838.24561

Timestep Collection Time: 2.17864
Timestep Consumption Time: 2.43779
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.61643

Cumulative Model Updates: 41,924
Cumulative Timesteps: 349,711,178

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 349711178...
Checkpoint 349711178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,951.19447
Policy Entropy: 3.74693
Value Function Loss: 0.04437

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.49422
Value Function Update Magnitude: 0.67563

Collected Steps per Second: 22,584.31153
Overall Steps per Second: 10,704.84596

Timestep Collection Time: 2.21525
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.67358

Cumulative Model Updates: 41,930
Cumulative Timesteps: 349,761,208

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,969.08793
Policy Entropy: 3.74235
Value Function Loss: 0.04474

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.48968
Value Function Update Magnitude: 0.74147

Collected Steps per Second: 23,297.78671
Overall Steps per Second: 10,880.50019

Timestep Collection Time: 2.14630
Timestep Consumption Time: 2.44945
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.59574

Cumulative Model Updates: 41,936
Cumulative Timesteps: 349,811,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 349811212...
Checkpoint 349811212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,384.75420
Policy Entropy: 3.73105
Value Function Loss: 0.04374

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.44035
Value Function Update Magnitude: 0.77202

Collected Steps per Second: 22,206.32758
Overall Steps per Second: 10,668.46522

Timestep Collection Time: 2.25233
Timestep Consumption Time: 2.43588
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.68821

Cumulative Model Updates: 41,942
Cumulative Timesteps: 349,861,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,069.97878
Policy Entropy: 3.73549
Value Function Loss: 0.04450

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.41144
Value Function Update Magnitude: 0.78552

Collected Steps per Second: 23,003.49288
Overall Steps per Second: 10,851.68759

Timestep Collection Time: 2.17428
Timestep Consumption Time: 2.43477
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.60905

Cumulative Model Updates: 41,948
Cumulative Timesteps: 349,911,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 349911244...
Checkpoint 349911244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,558.58388
Policy Entropy: 3.72710
Value Function Loss: 0.04402

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.43086
Value Function Update Magnitude: 0.80932

Collected Steps per Second: 22,399.52995
Overall Steps per Second: 10,703.71356

Timestep Collection Time: 2.23433
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.67576

Cumulative Model Updates: 41,954
Cumulative Timesteps: 349,961,292

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,228.42808
Policy Entropy: 3.72577
Value Function Loss: 0.04486

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.46491
Value Function Update Magnitude: 0.81942

Collected Steps per Second: 23,011.64515
Overall Steps per Second: 10,876.60648

Timestep Collection Time: 2.17403
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.59960

Cumulative Model Updates: 41,960
Cumulative Timesteps: 350,011,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 350011320...
Checkpoint 350011320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,258.91238
Policy Entropy: 3.72315
Value Function Loss: 0.04423

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.41978
Value Function Update Magnitude: 0.82316

Collected Steps per Second: 22,175.79883
Overall Steps per Second: 10,641.91940

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.44545
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.70178

Cumulative Model Updates: 41,966
Cumulative Timesteps: 350,061,356

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,869.10573
Policy Entropy: 3.73211
Value Function Loss: 0.04280

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11486
Policy Update Magnitude: 0.39673
Value Function Update Magnitude: 0.83911

Collected Steps per Second: 22,894.81830
Overall Steps per Second: 10,590.26048

Timestep Collection Time: 2.18425
Timestep Consumption Time: 2.53782
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.72207

Cumulative Model Updates: 41,972
Cumulative Timesteps: 350,111,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 350111364...
Checkpoint 350111364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,725.21616
Policy Entropy: 3.72509
Value Function Loss: 0.04237

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.48004
Value Function Update Magnitude: 0.80054

Collected Steps per Second: 22,410.18436
Overall Steps per Second: 10,505.87152

Timestep Collection Time: 2.23122
Timestep Consumption Time: 2.52822
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.75943

Cumulative Model Updates: 41,978
Cumulative Timesteps: 350,161,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,066.15144
Policy Entropy: 3.73454
Value Function Loss: 0.04321

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.49016
Value Function Update Magnitude: 0.72715

Collected Steps per Second: 22,922.51634
Overall Steps per Second: 10,873.38481

Timestep Collection Time: 2.18196
Timestep Consumption Time: 2.41790
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.59986

Cumulative Model Updates: 41,984
Cumulative Timesteps: 350,211,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 350211382...
Checkpoint 350211382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,742.19030
Policy Entropy: 3.73483
Value Function Loss: 0.04379

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07394
Policy Update Magnitude: 0.47915
Value Function Update Magnitude: 0.63869

Collected Steps per Second: 22,397.07662
Overall Steps per Second: 10,698.19489

Timestep Collection Time: 2.23270
Timestep Consumption Time: 2.44154
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.67425

Cumulative Model Updates: 41,990
Cumulative Timesteps: 350,261,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.87422
Policy Entropy: 3.73053
Value Function Loss: 0.04268

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.45254
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 22,859.49925
Overall Steps per Second: 10,810.68272

Timestep Collection Time: 2.18736
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.62524

Cumulative Model Updates: 41,996
Cumulative Timesteps: 350,311,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 350311390...
Checkpoint 350311390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,664.43674
Policy Entropy: 3.71970
Value Function Loss: 0.04021

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.43648
Value Function Update Magnitude: 0.62734

Collected Steps per Second: 22,430.45109
Overall Steps per Second: 10,799.72861

Timestep Collection Time: 2.22974
Timestep Consumption Time: 2.40131
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.63104

Cumulative Model Updates: 42,002
Cumulative Timesteps: 350,361,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,010.48011
Policy Entropy: 3.72752
Value Function Loss: 0.03808

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.48689
Value Function Update Magnitude: 0.59592

Collected Steps per Second: 23,072.17102
Overall Steps per Second: 10,857.84792

Timestep Collection Time: 2.16781
Timestep Consumption Time: 2.43863
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.60644

Cumulative Model Updates: 42,008
Cumulative Timesteps: 350,411,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 350411420...
Checkpoint 350411420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,007.68364
Policy Entropy: 3.73583
Value Function Loss: 0.03961

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.45480
Value Function Update Magnitude: 0.65505

Collected Steps per Second: 22,470.59456
Overall Steps per Second: 10,605.83528

Timestep Collection Time: 2.22575
Timestep Consumption Time: 2.48995
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.71571

Cumulative Model Updates: 42,014
Cumulative Timesteps: 350,461,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,833.75403
Policy Entropy: 3.74632
Value Function Loss: 0.04022

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.42186
Value Function Update Magnitude: 0.70303

Collected Steps per Second: 22,826.06657
Overall Steps per Second: 10,834.56452

Timestep Collection Time: 2.19118
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.61634

Cumulative Model Updates: 42,020
Cumulative Timesteps: 350,511,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 350511450...
Checkpoint 350511450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,229.03851
Policy Entropy: 3.73808
Value Function Loss: 0.04003

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.42043
Value Function Update Magnitude: 0.68132

Collected Steps per Second: 22,261.60677
Overall Steps per Second: 10,678.25352

Timestep Collection Time: 2.24719
Timestep Consumption Time: 2.43766
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.68485

Cumulative Model Updates: 42,026
Cumulative Timesteps: 350,561,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,974.07794
Policy Entropy: 3.73869
Value Function Loss: 0.04027

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.43380
Value Function Update Magnitude: 0.67082

Collected Steps per Second: 22,913.50925
Overall Steps per Second: 10,691.60856

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.49465
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.67694

Cumulative Model Updates: 42,032
Cumulative Timesteps: 350,611,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 350611480...
Checkpoint 350611480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,013.03059
Policy Entropy: 3.73893
Value Function Loss: 0.04228

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08621
Policy Update Magnitude: 0.42870
Value Function Update Magnitude: 0.67700

Collected Steps per Second: 22,287.18915
Overall Steps per Second: 10,532.70434

Timestep Collection Time: 2.24470
Timestep Consumption Time: 2.50508
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.74978

Cumulative Model Updates: 42,038
Cumulative Timesteps: 350,661,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,992.52990
Policy Entropy: 3.73856
Value Function Loss: 0.04341

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06554
Policy Update Magnitude: 0.48105
Value Function Update Magnitude: 0.62078

Collected Steps per Second: 22,918.49135
Overall Steps per Second: 10,857.44723

Timestep Collection Time: 2.18234
Timestep Consumption Time: 2.42427
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.60661

Cumulative Model Updates: 42,044
Cumulative Timesteps: 350,711,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 350711524...
Checkpoint 350711524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,397.51406
Policy Entropy: 3.73706
Value Function Loss: 0.04234

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06803
Policy Update Magnitude: 0.53463
Value Function Update Magnitude: 0.54664

Collected Steps per Second: 22,423.25293
Overall Steps per Second: 10,620.37860

Timestep Collection Time: 2.23143
Timestep Consumption Time: 2.47989
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.71132

Cumulative Model Updates: 42,050
Cumulative Timesteps: 350,761,560

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,894.22488
Policy Entropy: 3.74443
Value Function Loss: 0.04098

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.50944
Value Function Update Magnitude: 0.55319

Collected Steps per Second: 22,786.75705
Overall Steps per Second: 10,789.51971

Timestep Collection Time: 2.19470
Timestep Consumption Time: 2.44036
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.63505

Cumulative Model Updates: 42,056
Cumulative Timesteps: 350,811,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 350811570...
Checkpoint 350811570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,630.72793
Policy Entropy: 3.74588
Value Function Loss: 0.04073

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07440
Policy Update Magnitude: 0.46004
Value Function Update Magnitude: 0.60430

Collected Steps per Second: 22,148.06961
Overall Steps per Second: 10,635.75222

Timestep Collection Time: 2.25826
Timestep Consumption Time: 2.44437
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.70263

Cumulative Model Updates: 42,062
Cumulative Timesteps: 350,861,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,703.48595
Policy Entropy: 3.73620
Value Function Loss: 0.04169

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.46651
Value Function Update Magnitude: 0.64208

Collected Steps per Second: 22,945.14688
Overall Steps per Second: 10,672.27181

Timestep Collection Time: 2.17946
Timestep Consumption Time: 2.50633
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.68579

Cumulative Model Updates: 42,068
Cumulative Timesteps: 350,911,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 350911594...
Checkpoint 350911594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,955.21105
Policy Entropy: 3.73697
Value Function Loss: 0.04206

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06755
Policy Update Magnitude: 0.49265
Value Function Update Magnitude: 0.66975

Collected Steps per Second: 22,449.77226
Overall Steps per Second: 10,525.72031

Timestep Collection Time: 2.22782
Timestep Consumption Time: 2.52378
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.75160

Cumulative Model Updates: 42,074
Cumulative Timesteps: 350,961,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,520.32086
Policy Entropy: 3.72856
Value Function Loss: 0.04234

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.48235
Value Function Update Magnitude: 0.69794

Collected Steps per Second: 22,869.09617
Overall Steps per Second: 10,802.53364

Timestep Collection Time: 2.18679
Timestep Consumption Time: 2.44268
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.62947

Cumulative Model Updates: 42,080
Cumulative Timesteps: 351,011,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 351011618...
Checkpoint 351011618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,500.65904
Policy Entropy: 3.74250
Value Function Loss: 0.04007

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.47085
Value Function Update Magnitude: 0.70664

Collected Steps per Second: 22,153.57170
Overall Steps per Second: 10,708.60884

Timestep Collection Time: 2.25742
Timestep Consumption Time: 2.41265
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.67007

Cumulative Model Updates: 42,086
Cumulative Timesteps: 351,061,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,714.89029
Policy Entropy: 3.75005
Value Function Loss: 0.03938

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.50258
Value Function Update Magnitude: 0.69747

Collected Steps per Second: 22,890.75045
Overall Steps per Second: 10,703.54876

Timestep Collection Time: 2.18542
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.67378

Cumulative Model Updates: 42,092
Cumulative Timesteps: 351,111,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 351111654...
Checkpoint 351111654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,314.23118
Policy Entropy: 3.75816
Value Function Loss: 0.03930

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06450
Policy Update Magnitude: 0.52735
Value Function Update Magnitude: 0.72047

Collected Steps per Second: 22,691.20937
Overall Steps per Second: 10,780.43230

Timestep Collection Time: 2.20420
Timestep Consumption Time: 2.43532
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.63952

Cumulative Model Updates: 42,098
Cumulative Timesteps: 351,161,670

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,376.74368
Policy Entropy: 3.74247
Value Function Loss: 0.04001

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06110
Policy Update Magnitude: 0.56781
Value Function Update Magnitude: 0.74444

Collected Steps per Second: 22,844.44793
Overall Steps per Second: 10,635.60721

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.51388
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.70382

Cumulative Model Updates: 42,104
Cumulative Timesteps: 351,211,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 351211698...
Checkpoint 351211698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,626.55618
Policy Entropy: 3.73549
Value Function Loss: 0.04041

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06648
Policy Update Magnitude: 0.56288
Value Function Update Magnitude: 0.74265

Collected Steps per Second: 22,622.70593
Overall Steps per Second: 10,591.43331

Timestep Collection Time: 2.21079
Timestep Consumption Time: 2.51133
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.72212

Cumulative Model Updates: 42,110
Cumulative Timesteps: 351,261,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,831.78398
Policy Entropy: 3.73871
Value Function Loss: 0.04159

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.51114
Value Function Update Magnitude: 0.75141

Collected Steps per Second: 23,119.39570
Overall Steps per Second: 10,851.54295

Timestep Collection Time: 2.16286
Timestep Consumption Time: 2.44515
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.60801

Cumulative Model Updates: 42,116
Cumulative Timesteps: 351,311,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 351311716...
Checkpoint 351311716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,966.05253
Policy Entropy: 3.75087
Value Function Loss: 0.04129

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.45837
Value Function Update Magnitude: 0.75862

Collected Steps per Second: 22,656.15189
Overall Steps per Second: 10,670.40773

Timestep Collection Time: 2.20805
Timestep Consumption Time: 2.48024
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.68829

Cumulative Model Updates: 42,122
Cumulative Timesteps: 351,361,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,135.56432
Policy Entropy: 3.76956
Value Function Loss: 0.04104

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.47713
Value Function Update Magnitude: 0.77892

Collected Steps per Second: 22,827.27146
Overall Steps per Second: 10,784.67166

Timestep Collection Time: 2.19080
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.63714

Cumulative Model Updates: 42,128
Cumulative Timesteps: 351,411,752

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 351411752...
Checkpoint 351411752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,026.95940
Policy Entropy: 3.77429
Value Function Loss: 0.04038

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.48527
Value Function Update Magnitude: 0.78424

Collected Steps per Second: 22,392.65726
Overall Steps per Second: 10,702.13921

Timestep Collection Time: 2.23350
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.67327

Cumulative Model Updates: 42,134
Cumulative Timesteps: 351,461,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,313.81319
Policy Entropy: 3.76250
Value Function Loss: 0.04075

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.47790
Value Function Update Magnitude: 0.77817

Collected Steps per Second: 22,608.78136
Overall Steps per Second: 10,555.47769

Timestep Collection Time: 2.21171
Timestep Consumption Time: 2.52555
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.73726

Cumulative Model Updates: 42,140
Cumulative Timesteps: 351,511,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 351511770...
Checkpoint 351511770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,359.20760
Policy Entropy: 3.75996
Value Function Loss: 0.04044

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.48215
Value Function Update Magnitude: 0.75001

Collected Steps per Second: 22,179.91984
Overall Steps per Second: 10,568.53659

Timestep Collection Time: 2.25456
Timestep Consumption Time: 2.47703
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.73159

Cumulative Model Updates: 42,146
Cumulative Timesteps: 351,561,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.83734
Policy Entropy: 3.75335
Value Function Loss: 0.04211

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.44993
Value Function Update Magnitude: 0.71453

Collected Steps per Second: 22,858.07979
Overall Steps per Second: 10,632.53440

Timestep Collection Time: 2.18829
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.70443

Cumulative Model Updates: 42,152
Cumulative Timesteps: 351,611,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 351611796...
Checkpoint 351611796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,824.75006
Policy Entropy: 3.74054
Value Function Loss: 0.04287

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07306
Policy Update Magnitude: 0.49344
Value Function Update Magnitude: 0.64561

Collected Steps per Second: 22,429.39752
Overall Steps per Second: 10,562.00311

Timestep Collection Time: 2.22966
Timestep Consumption Time: 2.50523
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.73490

Cumulative Model Updates: 42,158
Cumulative Timesteps: 351,661,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,180.11421
Policy Entropy: 3.72039
Value Function Loss: 0.04522

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07582
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.55274

Collected Steps per Second: 23,105.33142
Overall Steps per Second: 10,837.40827

Timestep Collection Time: 2.16513
Timestep Consumption Time: 2.45092
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.61605

Cumulative Model Updates: 42,164
Cumulative Timesteps: 351,711,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 351711832...
Checkpoint 351711832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,770.43489
Policy Entropy: 3.72159
Value Function Loss: 0.04463

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06610
Policy Update Magnitude: 0.51710
Value Function Update Magnitude: 0.59423

Collected Steps per Second: 22,552.65006
Overall Steps per Second: 10,610.23176

Timestep Collection Time: 2.21730
Timestep Consumption Time: 2.49570
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.71300

Cumulative Model Updates: 42,170
Cumulative Timesteps: 351,761,838

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,403.45735
Policy Entropy: 3.71440
Value Function Loss: 0.04568

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06841
Policy Update Magnitude: 0.55416
Value Function Update Magnitude: 0.59700

Collected Steps per Second: 22,868.14950
Overall Steps per Second: 10,802.29222

Timestep Collection Time: 2.18715
Timestep Consumption Time: 2.44298
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.63013

Cumulative Model Updates: 42,176
Cumulative Timesteps: 351,811,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 351811854...
Checkpoint 351811854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,239.58871
Policy Entropy: 3.72625
Value Function Loss: 0.04409

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10705
Policy Update Magnitude: 0.49444
Value Function Update Magnitude: 0.57933

Collected Steps per Second: 22,163.04161
Overall Steps per Second: 10,648.03596

Timestep Collection Time: 2.25682
Timestep Consumption Time: 2.44057
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.69739

Cumulative Model Updates: 42,182
Cumulative Timesteps: 351,861,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,339.02051
Policy Entropy: 3.72712
Value Function Loss: 0.04482

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.45537
Value Function Update Magnitude: 0.67468

Collected Steps per Second: 22,666.14933
Overall Steps per Second: 10,592.64291

Timestep Collection Time: 2.20593
Timestep Consumption Time: 2.51432
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.72026

Cumulative Model Updates: 42,188
Cumulative Timesteps: 351,911,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 351911872...
Checkpoint 351911872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.67575
Policy Entropy: 3.73312
Value Function Loss: 0.04521

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.50548
Value Function Update Magnitude: 0.67416

Collected Steps per Second: 22,522.28020
Overall Steps per Second: 10,609.17645

Timestep Collection Time: 2.22136
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.71573

Cumulative Model Updates: 42,194
Cumulative Timesteps: 351,961,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,287.07235
Policy Entropy: 3.73349
Value Function Loss: 0.04526

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07145
Policy Update Magnitude: 0.53548
Value Function Update Magnitude: 0.68506

Collected Steps per Second: 22,984.19084
Overall Steps per Second: 10,862.44636

Timestep Collection Time: 2.17637
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.60504

Cumulative Model Updates: 42,200
Cumulative Timesteps: 352,011,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 352011924...
Checkpoint 352011924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,526.26246
Policy Entropy: 3.73064
Value Function Loss: 0.04576

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06901
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.59644

Collected Steps per Second: 22,244.87204
Overall Steps per Second: 10,698.36855

Timestep Collection Time: 2.24834
Timestep Consumption Time: 2.42658
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.67492

Cumulative Model Updates: 42,206
Cumulative Timesteps: 352,061,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,696.10290
Policy Entropy: 3.72568
Value Function Loss: 0.04554

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.54686
Value Function Update Magnitude: 0.58433

Collected Steps per Second: 23,186.51599
Overall Steps per Second: 10,889.74957

Timestep Collection Time: 2.15772
Timestep Consumption Time: 2.43651
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.59423

Cumulative Model Updates: 42,212
Cumulative Timesteps: 352,111,968

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 352111968...
Checkpoint 352111968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,998.10006
Policy Entropy: 3.72685
Value Function Loss: 0.04585

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.49743
Value Function Update Magnitude: 0.57957

Collected Steps per Second: 22,471.00027
Overall Steps per Second: 10,632.65985

Timestep Collection Time: 2.22536
Timestep Consumption Time: 2.47770
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.70306

Cumulative Model Updates: 42,218
Cumulative Timesteps: 352,161,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,564.63182
Policy Entropy: 3.72650
Value Function Loss: 0.04658

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.45298
Value Function Update Magnitude: 0.56726

Collected Steps per Second: 22,570.02456
Overall Steps per Second: 10,893.63752

Timestep Collection Time: 2.21550
Timestep Consumption Time: 2.37470
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.59020

Cumulative Model Updates: 42,224
Cumulative Timesteps: 352,211,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 352211978...
Checkpoint 352211978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,980.00520
Policy Entropy: 3.73753
Value Function Loss: 0.04524

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.41998
Value Function Update Magnitude: 0.61349

Collected Steps per Second: 21,765.03718
Overall Steps per Second: 10,637.26098

Timestep Collection Time: 2.29754
Timestep Consumption Time: 2.40348
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.70102

Cumulative Model Updates: 42,230
Cumulative Timesteps: 352,261,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,610.97838
Policy Entropy: 3.74532
Value Function Loss: 0.04548

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.42244
Value Function Update Magnitude: 0.63249

Collected Steps per Second: 21,827.58157
Overall Steps per Second: 10,646.19541

Timestep Collection Time: 2.29105
Timestep Consumption Time: 2.40622
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.69726

Cumulative Model Updates: 42,236
Cumulative Timesteps: 352,311,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 352311992...
Checkpoint 352311992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,849.30880
Policy Entropy: 3.75524
Value Function Loss: 0.04357

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.48442
Value Function Update Magnitude: 0.69279

Collected Steps per Second: 22,108.16864
Overall Steps per Second: 10,829.57305

Timestep Collection Time: 2.26287
Timestep Consumption Time: 2.35670
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.61957

Cumulative Model Updates: 42,242
Cumulative Timesteps: 352,362,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,754.89375
Policy Entropy: 3.74710
Value Function Loss: 0.04263

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05780
Policy Update Magnitude: 0.55825
Value Function Update Magnitude: 0.72306

Collected Steps per Second: 21,860.04128
Overall Steps per Second: 10,579.52936

Timestep Collection Time: 2.28819
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.72800

Cumulative Model Updates: 42,248
Cumulative Timesteps: 352,412,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 352412040...
Checkpoint 352412040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.60723
Policy Entropy: 3.74289
Value Function Loss: 0.04356

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06336
Policy Update Magnitude: 0.57274
Value Function Update Magnitude: 0.74487

Collected Steps per Second: 21,704.11032
Overall Steps per Second: 10,582.47524

Timestep Collection Time: 2.30408
Timestep Consumption Time: 2.42147
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.72555

Cumulative Model Updates: 42,254
Cumulative Timesteps: 352,462,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.13910
Policy Entropy: 3.73649
Value Function Loss: 0.04417

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05572
Policy Update Magnitude: 0.58425
Value Function Update Magnitude: 0.74034

Collected Steps per Second: 22,218.64946
Overall Steps per Second: 10,814.59510

Timestep Collection Time: 2.25036
Timestep Consumption Time: 2.37302
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.62338

Cumulative Model Updates: 42,260
Cumulative Timesteps: 352,512,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 352512048...
Checkpoint 352512048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,659.96176
Policy Entropy: 3.73483
Value Function Loss: 0.04706

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06045
Policy Update Magnitude: 0.58635
Value Function Update Magnitude: 0.64219

Collected Steps per Second: 21,289.14165
Overall Steps per Second: 10,316.50811

Timestep Collection Time: 2.34899
Timestep Consumption Time: 2.49839
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.84738

Cumulative Model Updates: 42,266
Cumulative Timesteps: 352,562,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,273.28034
Policy Entropy: 3.73913
Value Function Loss: 0.04787

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05938
Policy Update Magnitude: 0.57226
Value Function Update Magnitude: 0.55849

Collected Steps per Second: 22,840.89645
Overall Steps per Second: 10,843.02303

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.42230
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.61144

Cumulative Model Updates: 42,272
Cumulative Timesteps: 352,612,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 352612058...
Checkpoint 352612058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,009.90736
Policy Entropy: 3.74675
Value Function Loss: 0.04827

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.51552
Value Function Update Magnitude: 0.56294

Collected Steps per Second: 22,179.60379
Overall Steps per Second: 10,743.74942

Timestep Collection Time: 2.25468
Timestep Consumption Time: 2.39993
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.65461

Cumulative Model Updates: 42,278
Cumulative Timesteps: 352,662,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,832.05945
Policy Entropy: 3.74878
Value Function Loss: 0.04570

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07031
Policy Update Magnitude: 0.45762
Value Function Update Magnitude: 0.57656

Collected Steps per Second: 23,122.84879
Overall Steps per Second: 10,870.67767

Timestep Collection Time: 2.16262
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.60008

Cumulative Model Updates: 42,284
Cumulative Timesteps: 352,712,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 352712072...
Checkpoint 352712072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.18265
Policy Entropy: 3.76324
Value Function Loss: 0.04448

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.41916
Value Function Update Magnitude: 0.58646

Collected Steps per Second: 22,777.19457
Overall Steps per Second: 10,684.71569

Timestep Collection Time: 2.19571
Timestep Consumption Time: 2.48500
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.68070

Cumulative Model Updates: 42,290
Cumulative Timesteps: 352,762,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,822.55824
Policy Entropy: 3.77437
Value Function Loss: 0.04259

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.44250
Value Function Update Magnitude: 0.65671

Collected Steps per Second: 22,876.87049
Overall Steps per Second: 10,908.06609

Timestep Collection Time: 2.18692
Timestep Consumption Time: 2.39959
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.58651

Cumulative Model Updates: 42,296
Cumulative Timesteps: 352,812,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 352812114...
Checkpoint 352812114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,635.14156
Policy Entropy: 3.77732
Value Function Loss: 0.04238

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05359
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.71648

Collected Steps per Second: 22,752.39692
Overall Steps per Second: 10,609.84622

Timestep Collection Time: 2.19871
Timestep Consumption Time: 2.51634
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.71505

Cumulative Model Updates: 42,302
Cumulative Timesteps: 352,862,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,375.27560
Policy Entropy: 3.76470
Value Function Loss: 0.04281

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06145
Policy Update Magnitude: 0.57301
Value Function Update Magnitude: 0.70652

Collected Steps per Second: 22,888.48656
Overall Steps per Second: 10,871.34036

Timestep Collection Time: 2.18590
Timestep Consumption Time: 2.41629
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.60219

Cumulative Model Updates: 42,308
Cumulative Timesteps: 352,912,172

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 352912172...
Checkpoint 352912172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,320.57206
Policy Entropy: 3.76019
Value Function Loss: 0.04415

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06966
Policy Update Magnitude: 0.56041
Value Function Update Magnitude: 0.60753

Collected Steps per Second: 22,770.31068
Overall Steps per Second: 10,675.62098

Timestep Collection Time: 2.19584
Timestep Consumption Time: 2.48773
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.68357

Cumulative Model Updates: 42,314
Cumulative Timesteps: 352,962,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,698.97182
Policy Entropy: 3.75491
Value Function Loss: 0.04388

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.48422
Value Function Update Magnitude: 0.57614

Collected Steps per Second: 23,077.20767
Overall Steps per Second: 10,847.56200

Timestep Collection Time: 2.16777
Timestep Consumption Time: 2.44396
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.61173

Cumulative Model Updates: 42,320
Cumulative Timesteps: 353,012,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 353012198...
Checkpoint 353012198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.31152
Policy Entropy: 3.76252
Value Function Loss: 0.04730

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.45795
Value Function Update Magnitude: 0.48499

Collected Steps per Second: 22,215.01625
Overall Steps per Second: 10,650.27281

Timestep Collection Time: 2.25091
Timestep Consumption Time: 2.44418
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.69509

Cumulative Model Updates: 42,326
Cumulative Timesteps: 353,062,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,751.89863
Policy Entropy: 3.76025
Value Function Loss: 0.04490

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.46495
Value Function Update Magnitude: 0.45078

Collected Steps per Second: 22,958.03600
Overall Steps per Second: 10,862.90986

Timestep Collection Time: 2.17876
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60466

Cumulative Model Updates: 42,332
Cumulative Timesteps: 353,112,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 353112222...
Checkpoint 353112222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.99607
Policy Entropy: 3.75575
Value Function Loss: 0.04545

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.49639
Value Function Update Magnitude: 0.49837

Collected Steps per Second: 22,287.45992
Overall Steps per Second: 10,696.36433

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.67542

Cumulative Model Updates: 42,338
Cumulative Timesteps: 353,162,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.66371
Policy Entropy: 3.75761
Value Function Loss: 0.04367

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.47618
Value Function Update Magnitude: 0.52571

Collected Steps per Second: 22,887.05020
Overall Steps per Second: 10,820.85286

Timestep Collection Time: 2.18473
Timestep Consumption Time: 2.43616
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.62089

Cumulative Model Updates: 42,344
Cumulative Timesteps: 353,212,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 353212234...
Checkpoint 353212234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,236.63859
Policy Entropy: 3.76067
Value Function Loss: 0.04336

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.42588
Value Function Update Magnitude: 0.49126

Collected Steps per Second: 22,266.46958
Overall Steps per Second: 10,665.44220

Timestep Collection Time: 2.24571
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.68841

Cumulative Model Updates: 42,350
Cumulative Timesteps: 353,262,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,583.33164
Policy Entropy: 3.77642
Value Function Loss: 0.04306

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.45534
Value Function Update Magnitude: 0.49336

Collected Steps per Second: 22,708.84420
Overall Steps per Second: 10,589.44495

Timestep Collection Time: 2.20311
Timestep Consumption Time: 2.52141
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.72452

Cumulative Model Updates: 42,356
Cumulative Timesteps: 353,312,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 353312268...
Checkpoint 353312268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,898.88442
Policy Entropy: 3.76224
Value Function Loss: 0.04404

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.43472
Value Function Update Magnitude: 0.48056

Collected Steps per Second: 22,401.81522
Overall Steps per Second: 10,601.05151

Timestep Collection Time: 2.23232
Timestep Consumption Time: 2.48495
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.71727

Cumulative Model Updates: 42,362
Cumulative Timesteps: 353,362,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,563.86753
Policy Entropy: 3.76155
Value Function Loss: 0.04294

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07495
Policy Update Magnitude: 0.46651
Value Function Update Magnitude: 0.50764

Collected Steps per Second: 22,940.07108
Overall Steps per Second: 10,816.11457

Timestep Collection Time: 2.17959
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.62273

Cumulative Model Updates: 42,368
Cumulative Timesteps: 353,412,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 353412276...
Checkpoint 353412276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,075.43398
Policy Entropy: 3.75586
Value Function Loss: 0.04100

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08459
Policy Update Magnitude: 0.46193
Value Function Update Magnitude: 0.61286

Collected Steps per Second: 22,251.48305
Overall Steps per Second: 10,666.60387

Timestep Collection Time: 2.24722
Timestep Consumption Time: 2.44068
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.68790

Cumulative Model Updates: 42,374
Cumulative Timesteps: 353,462,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,671.97378
Policy Entropy: 3.76383
Value Function Loss: 0.04112

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06333
Policy Update Magnitude: 0.48203
Value Function Update Magnitude: 0.65344

Collected Steps per Second: 22,898.00357
Overall Steps per Second: 10,702.74717

Timestep Collection Time: 2.18403
Timestep Consumption Time: 2.48860
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.67263

Cumulative Model Updates: 42,380
Cumulative Timesteps: 353,512,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 353512290...
Checkpoint 353512290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,657.08075
Policy Entropy: 3.75675
Value Function Loss: 0.04209

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06843
Policy Update Magnitude: 0.52429
Value Function Update Magnitude: 0.67770

Collected Steps per Second: 22,775.47924
Overall Steps per Second: 10,826.35613

Timestep Collection Time: 2.19543
Timestep Consumption Time: 2.42311
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.61854

Cumulative Model Updates: 42,386
Cumulative Timesteps: 353,562,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,557.75140
Policy Entropy: 3.74349
Value Function Loss: 0.04319

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.48597
Value Function Update Magnitude: 0.69873

Collected Steps per Second: 23,022.04291
Overall Steps per Second: 10,699.85489

Timestep Collection Time: 2.17244
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.67427

Cumulative Model Updates: 42,392
Cumulative Timesteps: 353,612,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 353612306...
Checkpoint 353612306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,157.38927
Policy Entropy: 3.74078
Value Function Loss: 0.04255

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.44748
Value Function Update Magnitude: 0.68540

Collected Steps per Second: 22,443.07074
Overall Steps per Second: 10,575.13970

Timestep Collection Time: 2.22893
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.73034

Cumulative Model Updates: 42,398
Cumulative Timesteps: 353,662,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,920.85143
Policy Entropy: 3.74440
Value Function Loss: 0.04035

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.44222
Value Function Update Magnitude: 0.69657

Collected Steps per Second: 23,019.93987
Overall Steps per Second: 10,811.10955

Timestep Collection Time: 2.17203
Timestep Consumption Time: 2.45284
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.62487

Cumulative Model Updates: 42,404
Cumulative Timesteps: 353,712,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 353712330...
Checkpoint 353712330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,880.52861
Policy Entropy: 3.75114
Value Function Loss: 0.04150

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.41843
Value Function Update Magnitude: 0.62596

Collected Steps per Second: 22,481.08460
Overall Steps per Second: 10,638.34789

Timestep Collection Time: 2.22454
Timestep Consumption Time: 2.47638
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.70092

Cumulative Model Updates: 42,410
Cumulative Timesteps: 353,762,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,434.08571
Policy Entropy: 3.75399
Value Function Loss: 0.04305

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.40515
Value Function Update Magnitude: 0.56101

Collected Steps per Second: 22,972.26040
Overall Steps per Second: 10,909.16668

Timestep Collection Time: 2.17654
Timestep Consumption Time: 2.40676
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58330

Cumulative Model Updates: 42,416
Cumulative Timesteps: 353,812,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 353812340...
Checkpoint 353812340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,704.83386
Policy Entropy: 3.74512
Value Function Loss: 0.04454

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.42841
Value Function Update Magnitude: 0.56540

Collected Steps per Second: 22,154.90860
Overall Steps per Second: 10,652.92033

Timestep Collection Time: 2.25756
Timestep Consumption Time: 2.43749
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.69505

Cumulative Model Updates: 42,422
Cumulative Timesteps: 353,862,356

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,993.55740
Policy Entropy: 3.75402
Value Function Loss: 0.04202

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.43799
Value Function Update Magnitude: 0.62133

Collected Steps per Second: 23,033.41222
Overall Steps per Second: 10,870.06073

Timestep Collection Time: 2.17085
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.59997

Cumulative Model Updates: 42,428
Cumulative Timesteps: 353,912,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 353912358...
Checkpoint 353912358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,085.16727
Policy Entropy: 3.74596
Value Function Loss: 0.04099

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.42477
Value Function Update Magnitude: 0.61654

Collected Steps per Second: 22,272.82366
Overall Steps per Second: 10,514.98274

Timestep Collection Time: 2.24579
Timestep Consumption Time: 2.51124
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.75702

Cumulative Model Updates: 42,434
Cumulative Timesteps: 353,962,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,950.71458
Policy Entropy: 3.75566
Value Function Loss: 0.04207

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.44414
Value Function Update Magnitude: 0.56733

Collected Steps per Second: 23,077.44081
Overall Steps per Second: 10,884.03938

Timestep Collection Time: 2.16774
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.59627

Cumulative Model Updates: 42,440
Cumulative Timesteps: 354,012,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 354012404...
Checkpoint 354012404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.38726
Policy Entropy: 3.75005
Value Function Loss: 0.04439

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.48132
Value Function Update Magnitude: 0.54288

Collected Steps per Second: 22,594.71090
Overall Steps per Second: 10,647.76705

Timestep Collection Time: 2.21362
Timestep Consumption Time: 2.48371
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.69732

Cumulative Model Updates: 42,446
Cumulative Timesteps: 354,062,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.35233
Policy Entropy: 3.75582
Value Function Loss: 0.04475

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.46997
Value Function Update Magnitude: 0.56566

Collected Steps per Second: 23,148.25101
Overall Steps per Second: 10,867.48443

Timestep Collection Time: 2.16034
Timestep Consumption Time: 2.44128
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.60162

Cumulative Model Updates: 42,452
Cumulative Timesteps: 354,112,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 354112428...
Checkpoint 354112428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,548.98954
Policy Entropy: 3.76003
Value Function Loss: 0.04812

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.45395
Value Function Update Magnitude: 0.55733

Collected Steps per Second: 22,562.29141
Overall Steps per Second: 10,655.07874

Timestep Collection Time: 2.21635
Timestep Consumption Time: 2.47681
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.69316

Cumulative Model Updates: 42,458
Cumulative Timesteps: 354,162,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,183.47399
Policy Entropy: 3.75977
Value Function Loss: 0.04950

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05887
Policy Update Magnitude: 0.52487
Value Function Update Magnitude: 0.51813

Collected Steps per Second: 23,058.22860
Overall Steps per Second: 10,929.60554

Timestep Collection Time: 2.16938
Timestep Consumption Time: 2.40737
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.57674

Cumulative Model Updates: 42,464
Cumulative Timesteps: 354,212,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 354212456...
Checkpoint 354212456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,483.15654
Policy Entropy: 3.75946
Value Function Loss: 0.04814

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06204
Policy Update Magnitude: 0.58400
Value Function Update Magnitude: 0.58153

Collected Steps per Second: 22,481.35646
Overall Steps per Second: 10,621.41343

Timestep Collection Time: 2.22451
Timestep Consumption Time: 2.48390
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.70841

Cumulative Model Updates: 42,470
Cumulative Timesteps: 354,262,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,259.01295
Policy Entropy: 3.74363
Value Function Loss: 0.04543

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06168
Policy Update Magnitude: 0.58603
Value Function Update Magnitude: 0.66654

Collected Steps per Second: 22,900.82348
Overall Steps per Second: 10,877.39104

Timestep Collection Time: 2.18385
Timestep Consumption Time: 2.41394
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.59779

Cumulative Model Updates: 42,476
Cumulative Timesteps: 354,312,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 354312478...
Checkpoint 354312478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.06314
Policy Entropy: 3.74846
Value Function Loss: 0.04261

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.56829
Value Function Update Magnitude: 0.68856

Collected Steps per Second: 22,497.03502
Overall Steps per Second: 10,685.83672

Timestep Collection Time: 2.22269
Timestep Consumption Time: 2.45677
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.67947

Cumulative Model Updates: 42,482
Cumulative Timesteps: 354,362,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.28538
Policy Entropy: 3.75578
Value Function Loss: 0.04296

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.49850
Value Function Update Magnitude: 0.68752

Collected Steps per Second: 22,973.48822
Overall Steps per Second: 10,831.98323

Timestep Collection Time: 2.17738
Timestep Consumption Time: 2.44061
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.61799

Cumulative Model Updates: 42,488
Cumulative Timesteps: 354,412,504

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 354412504...
Checkpoint 354412504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,852.24509
Policy Entropy: 3.76373
Value Function Loss: 0.04352

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.53285
Value Function Update Magnitude: 0.68918

Collected Steps per Second: 22,565.13023
Overall Steps per Second: 10,672.95119

Timestep Collection Time: 2.21643
Timestep Consumption Time: 2.46962
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.68605

Cumulative Model Updates: 42,494
Cumulative Timesteps: 354,462,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,175.90840
Policy Entropy: 3.74805
Value Function Loss: 0.04541

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.70989

Collected Steps per Second: 22,609.88116
Overall Steps per Second: 10,573.00899

Timestep Collection Time: 2.21266
Timestep Consumption Time: 2.51901
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.73167

Cumulative Model Updates: 42,500
Cumulative Timesteps: 354,512,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 354512546...
Checkpoint 354512546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,012.82914
Policy Entropy: 3.74164
Value Function Loss: 0.04577

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.48038
Value Function Update Magnitude: 0.67446

Collected Steps per Second: 22,531.46944
Overall Steps per Second: 10,588.39986

Timestep Collection Time: 2.21930
Timestep Consumption Time: 2.50323
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.72253

Cumulative Model Updates: 42,506
Cumulative Timesteps: 354,562,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,080.84160
Policy Entropy: 3.71779
Value Function Loss: 0.04705

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.44846
Value Function Update Magnitude: 0.58759

Collected Steps per Second: 23,054.56588
Overall Steps per Second: 10,829.52667

Timestep Collection Time: 2.16946
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.61848

Cumulative Model Updates: 42,512
Cumulative Timesteps: 354,612,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 354612566...
Checkpoint 354612566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,025.79363
Policy Entropy: 3.73104
Value Function Loss: 0.04657

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.46401
Value Function Update Magnitude: 0.55662

Collected Steps per Second: 21,958.29355
Overall Steps per Second: 10,670.22674

Timestep Collection Time: 2.27841
Timestep Consumption Time: 2.41034
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.68875

Cumulative Model Updates: 42,518
Cumulative Timesteps: 354,662,596

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,140.68558
Policy Entropy: 3.73450
Value Function Loss: 0.04629

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.45578
Value Function Update Magnitude: 0.56610

Collected Steps per Second: 22,763.93386
Overall Steps per Second: 10,849.35129

Timestep Collection Time: 2.19734
Timestep Consumption Time: 2.41308
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.61041

Cumulative Model Updates: 42,524
Cumulative Timesteps: 354,712,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 354712616...
Checkpoint 354712616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.38244
Policy Entropy: 3.73459
Value Function Loss: 0.04582

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.46076
Value Function Update Magnitude: 0.58693

Collected Steps per Second: 22,352.40371
Overall Steps per Second: 10,716.94186

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.66775

Cumulative Model Updates: 42,530
Cumulative Timesteps: 354,762,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,888.87687
Policy Entropy: 3.73377
Value Function Loss: 0.04482

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.52666
Value Function Update Magnitude: 0.60080

Collected Steps per Second: 22,861.09905
Overall Steps per Second: 10,806.77272

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.43990
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.62728

Cumulative Model Updates: 42,536
Cumulative Timesteps: 354,812,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 354812646...
Checkpoint 354812646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,579.20352
Policy Entropy: 3.72944
Value Function Loss: 0.04571

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06370
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.59271

Collected Steps per Second: 22,414.20884
Overall Steps per Second: 10,691.57105

Timestep Collection Time: 2.23117
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.67752

Cumulative Model Updates: 42,542
Cumulative Timesteps: 354,862,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,924.30254
Policy Entropy: 3.72630
Value Function Loss: 0.04420

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06306
Policy Update Magnitude: 0.56776
Value Function Update Magnitude: 0.63751

Collected Steps per Second: 23,038.63449
Overall Steps per Second: 10,703.15074

Timestep Collection Time: 2.17096
Timestep Consumption Time: 2.50205
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.67302

Cumulative Model Updates: 42,548
Cumulative Timesteps: 354,912,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 354912672...
Checkpoint 354912672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,405.33063
Policy Entropy: 3.72674
Value Function Loss: 0.04452

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06140
Policy Update Magnitude: 0.56562
Value Function Update Magnitude: 0.68553

Collected Steps per Second: 22,423.20623
Overall Steps per Second: 10,565.71883

Timestep Collection Time: 2.23072
Timestep Consumption Time: 2.50345
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.73418

Cumulative Model Updates: 42,554
Cumulative Timesteps: 354,962,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,728.93965
Policy Entropy: 3.72929
Value Function Loss: 0.04388

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05818
Policy Update Magnitude: 0.58014
Value Function Update Magnitude: 0.66404

Collected Steps per Second: 22,863.87658
Overall Steps per Second: 10,759.58116

Timestep Collection Time: 2.18703
Timestep Consumption Time: 2.46036
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.64739

Cumulative Model Updates: 42,560
Cumulative Timesteps: 355,012,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 355012696...
Checkpoint 355012696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,326.05265
Policy Entropy: 3.73481
Value Function Loss: 0.04550

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05779
Policy Update Magnitude: 0.59318
Value Function Update Magnitude: 0.65461

Collected Steps per Second: 22,511.33700
Overall Steps per Second: 10,676.33840

Timestep Collection Time: 2.22235
Timestep Consumption Time: 2.46353
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.68588

Cumulative Model Updates: 42,566
Cumulative Timesteps: 355,062,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,342.91167
Policy Entropy: 3.74034
Value Function Loss: 0.04560

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07206
Policy Update Magnitude: 0.55369
Value Function Update Magnitude: 0.66957

Collected Steps per Second: 22,996.13880
Overall Steps per Second: 10,856.45874

Timestep Collection Time: 2.17445
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.60592

Cumulative Model Updates: 42,572
Cumulative Timesteps: 355,112,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 355112728...
Checkpoint 355112728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,967.73893
Policy Entropy: 3.75175
Value Function Loss: 0.04447

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.47973
Value Function Update Magnitude: 0.71053

Collected Steps per Second: 19,991.91464
Overall Steps per Second: 9,982.02413

Timestep Collection Time: 2.50131
Timestep Consumption Time: 2.50829
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 5.00961

Cumulative Model Updates: 42,578
Cumulative Timesteps: 355,162,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,738.66601
Policy Entropy: 3.75403
Value Function Loss: 0.04350

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06521
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.68636

Collected Steps per Second: 22,633.25991
Overall Steps per Second: 10,772.83422

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.43285
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.64260

Cumulative Model Updates: 42,584
Cumulative Timesteps: 355,212,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 355212748...
Checkpoint 355212748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.77186
Policy Entropy: 3.74687
Value Function Loss: 0.04519

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06970
Policy Update Magnitude: 0.56131
Value Function Update Magnitude: 0.69506

Collected Steps per Second: 22,526.59415
Overall Steps per Second: 10,598.02811

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.72069

Cumulative Model Updates: 42,590
Cumulative Timesteps: 355,262,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,251.66497
Policy Entropy: 3.74129
Value Function Loss: 0.04644

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06844
Policy Update Magnitude: 0.57060
Value Function Update Magnitude: 0.72698

Collected Steps per Second: 22,839.96122
Overall Steps per Second: 10,818.90778

Timestep Collection Time: 2.18985
Timestep Consumption Time: 2.43317
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.62302

Cumulative Model Updates: 42,596
Cumulative Timesteps: 355,312,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 355312794...
Checkpoint 355312794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,685.92880
Policy Entropy: 3.74389
Value Function Loss: 0.04679

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06133
Policy Update Magnitude: 0.58295
Value Function Update Magnitude: 0.73292

Collected Steps per Second: 22,242.09553
Overall Steps per Second: 10,682.46011

Timestep Collection Time: 2.24925
Timestep Consumption Time: 2.43394
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.68319

Cumulative Model Updates: 42,602
Cumulative Timesteps: 355,362,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,713.75439
Policy Entropy: 3.73663
Value Function Loss: 0.04638

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.52996
Value Function Update Magnitude: 0.73675

Collected Steps per Second: 22,772.45848
Overall Steps per Second: 10,645.15633

Timestep Collection Time: 2.19599
Timestep Consumption Time: 2.50174
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.69772

Cumulative Model Updates: 42,608
Cumulative Timesteps: 355,412,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 355412830...
Checkpoint 355412830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,134.08895
Policy Entropy: 3.73332
Value Function Loss: 0.04524

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.48331
Value Function Update Magnitude: 0.74185

Collected Steps per Second: 22,526.14309
Overall Steps per Second: 10,601.71742

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.49717
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.71735

Cumulative Model Updates: 42,614
Cumulative Timesteps: 355,462,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,654.41371
Policy Entropy: 3.72743
Value Function Loss: 0.04461

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.47176
Value Function Update Magnitude: 0.71969

Collected Steps per Second: 23,102.87868
Overall Steps per Second: 10,793.80813

Timestep Collection Time: 2.16441
Timestep Consumption Time: 2.46825
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.63266

Cumulative Model Updates: 42,620
Cumulative Timesteps: 355,512,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 355512846...
Checkpoint 355512846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,809.09959
Policy Entropy: 3.74008
Value Function Loss: 0.04317

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05839
Policy Update Magnitude: 0.53697
Value Function Update Magnitude: 0.75137

Collected Steps per Second: 22,552.27085
Overall Steps per Second: 10,660.32806

Timestep Collection Time: 2.21725
Timestep Consumption Time: 2.47341
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.69066

Cumulative Model Updates: 42,626
Cumulative Timesteps: 355,562,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,110.22646
Policy Entropy: 3.73107
Value Function Loss: 0.04260

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05291
Policy Update Magnitude: 0.58455
Value Function Update Magnitude: 0.77776

Collected Steps per Second: 22,955.12853
Overall Steps per Second: 10,828.44536

Timestep Collection Time: 2.17851
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61821

Cumulative Model Updates: 42,632
Cumulative Timesteps: 355,612,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 355612858...
Checkpoint 355612858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,898.13869
Policy Entropy: 3.72426
Value Function Loss: 0.04478

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.57426
Value Function Update Magnitude: 0.75208

Collected Steps per Second: 22,253.40541
Overall Steps per Second: 10,678.17631

Timestep Collection Time: 2.24694
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.68263

Cumulative Model Updates: 42,638
Cumulative Timesteps: 355,662,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,264.99569
Policy Entropy: 3.73217
Value Function Loss: 0.04633

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.14622
Policy Update Magnitude: 0.46160
Value Function Update Magnitude: 0.76950

Collected Steps per Second: 23,120.77708
Overall Steps per Second: 10,873.25893

Timestep Collection Time: 2.16360
Timestep Consumption Time: 2.43705
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.60064

Cumulative Model Updates: 42,644
Cumulative Timesteps: 355,712,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 355712884...
Checkpoint 355712884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,723.74831
Policy Entropy: 3.74314
Value Function Loss: 0.04610

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.44496
Value Function Update Magnitude: 0.79157

Collected Steps per Second: 22,060.52463
Overall Steps per Second: 10,652.30173

Timestep Collection Time: 2.26713
Timestep Consumption Time: 2.42801
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.69514

Cumulative Model Updates: 42,650
Cumulative Timesteps: 355,762,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,771.04556
Policy Entropy: 3.75072
Value Function Loss: 0.04445

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.45011
Value Function Update Magnitude: 0.77780

Collected Steps per Second: 23,023.41260
Overall Steps per Second: 10,765.59398

Timestep Collection Time: 2.17274
Timestep Consumption Time: 2.47391
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.64665

Cumulative Model Updates: 42,656
Cumulative Timesteps: 355,812,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 355812922...
Checkpoint 355812922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,825.66861
Policy Entropy: 3.74766
Value Function Loss: 0.04337

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.42921
Value Function Update Magnitude: 0.75154

Collected Steps per Second: 22,522.83078
Overall Steps per Second: 10,765.63238

Timestep Collection Time: 2.22112
Timestep Consumption Time: 2.42570
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.64682

Cumulative Model Updates: 42,662
Cumulative Timesteps: 355,862,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,164.13081
Policy Entropy: 3.75819
Value Function Loss: 0.04306

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.39992
Value Function Update Magnitude: 0.74344

Collected Steps per Second: 22,343.02006
Overall Steps per Second: 10,766.15647

Timestep Collection Time: 2.23954
Timestep Consumption Time: 2.40818
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.64771

Cumulative Model Updates: 42,668
Cumulative Timesteps: 355,912,986

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 355912986...
Checkpoint 355912986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,279.90895
Policy Entropy: 3.74619
Value Function Loss: 0.04274

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.37474
Value Function Update Magnitude: 0.76401

Collected Steps per Second: 22,088.44484
Overall Steps per Second: 10,862.68831

Timestep Collection Time: 2.26444
Timestep Consumption Time: 2.34013
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.60457

Cumulative Model Updates: 42,674
Cumulative Timesteps: 355,963,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,534.16381
Policy Entropy: 3.75389
Value Function Loss: 0.04406

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.39782
Value Function Update Magnitude: 0.75549

Collected Steps per Second: 22,495.15763
Overall Steps per Second: 10,887.35326

Timestep Collection Time: 2.22288
Timestep Consumption Time: 2.36997
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.59285

Cumulative Model Updates: 42,680
Cumulative Timesteps: 356,013,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 356013008...
Checkpoint 356013008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,139.32779
Policy Entropy: 3.76284
Value Function Loss: 0.04600

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.40018
Value Function Update Magnitude: 0.72619

Collected Steps per Second: 21,821.35044
Overall Steps per Second: 10,698.13436

Timestep Collection Time: 2.29133
Timestep Consumption Time: 2.38238
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.67371

Cumulative Model Updates: 42,686
Cumulative Timesteps: 356,063,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.43517
Policy Entropy: 3.76839
Value Function Loss: 0.04769

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06369
Policy Update Magnitude: 0.49083
Value Function Update Magnitude: 0.65699

Collected Steps per Second: 22,163.61379
Overall Steps per Second: 10,834.00573

Timestep Collection Time: 2.25667
Timestep Consumption Time: 2.35990
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.61658

Cumulative Model Updates: 42,692
Cumulative Timesteps: 356,113,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 356113024...
Checkpoint 356113024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,715.28996
Policy Entropy: 3.76566
Value Function Loss: 0.04839

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06274
Policy Update Magnitude: 0.56539
Value Function Update Magnitude: 0.64677

Collected Steps per Second: 22,086.22759
Overall Steps per Second: 10,726.90498

Timestep Collection Time: 2.26512
Timestep Consumption Time: 2.39867
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.66379

Cumulative Model Updates: 42,698
Cumulative Timesteps: 356,163,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,320.58755
Policy Entropy: 3.75213
Value Function Loss: 0.04888

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.55512
Value Function Update Magnitude: 0.65651

Collected Steps per Second: 22,209.49193
Overall Steps per Second: 10,818.59646

Timestep Collection Time: 2.25237
Timestep Consumption Time: 2.37152
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.62389

Cumulative Model Updates: 42,704
Cumulative Timesteps: 356,213,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 356213076...
Checkpoint 356213076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,924.20750
Policy Entropy: 3.74197
Value Function Loss: 0.04697

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.47805
Value Function Update Magnitude: 0.72266

Collected Steps per Second: 21,881.07906
Overall Steps per Second: 10,637.30749

Timestep Collection Time: 2.28618
Timestep Consumption Time: 2.41652
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.70269

Cumulative Model Updates: 42,710
Cumulative Timesteps: 356,263,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,203.29399
Policy Entropy: 3.72756
Value Function Loss: 0.04513

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.42600
Value Function Update Magnitude: 0.72841

Collected Steps per Second: 22,599.66325
Overall Steps per Second: 10,677.48868

Timestep Collection Time: 2.21375
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68556

Cumulative Model Updates: 42,716
Cumulative Timesteps: 356,313,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 356313130...
Checkpoint 356313130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,507.06203
Policy Entropy: 3.72501
Value Function Loss: 0.04337

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.43820
Value Function Update Magnitude: 0.70462

Collected Steps per Second: 22,528.23990
Overall Steps per Second: 10,674.53475

Timestep Collection Time: 2.22059
Timestep Consumption Time: 2.46589
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.68648

Cumulative Model Updates: 42,722
Cumulative Timesteps: 356,363,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,548.78773
Policy Entropy: 3.73580
Value Function Loss: 0.04477

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.43368
Value Function Update Magnitude: 0.61014

Collected Steps per Second: 23,079.57616
Overall Steps per Second: 10,707.46215

Timestep Collection Time: 2.16642
Timestep Consumption Time: 2.50322
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.66964

Cumulative Model Updates: 42,728
Cumulative Timesteps: 356,413,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 356413156...
Checkpoint 356413156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,364.76265
Policy Entropy: 3.73948
Value Function Loss: 0.04437

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.42841
Value Function Update Magnitude: 0.58478

Collected Steps per Second: 22,322.18581
Overall Steps per Second: 10,684.11380

Timestep Collection Time: 2.24028
Timestep Consumption Time: 2.44031
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.68059

Cumulative Model Updates: 42,734
Cumulative Timesteps: 356,463,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,749.15828
Policy Entropy: 3.74138
Value Function Loss: 0.04603

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.44406
Value Function Update Magnitude: 0.56226

Collected Steps per Second: 23,155.21652
Overall Steps per Second: 10,878.39648

Timestep Collection Time: 2.16012
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.59792

Cumulative Model Updates: 42,740
Cumulative Timesteps: 356,513,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 356513182...
Checkpoint 356513182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,587.39604
Policy Entropy: 3.73584
Value Function Loss: 0.04455

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06298
Policy Update Magnitude: 0.51602
Value Function Update Magnitude: 0.60129

Collected Steps per Second: 22,694.02289
Overall Steps per Second: 10,651.24752

Timestep Collection Time: 2.20322
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.69429

Cumulative Model Updates: 42,746
Cumulative Timesteps: 356,563,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,970.72005
Policy Entropy: 3.72639
Value Function Loss: 0.04545

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.51168
Value Function Update Magnitude: 0.69777

Collected Steps per Second: 22,960.75449
Overall Steps per Second: 10,807.80379

Timestep Collection Time: 2.17780
Timestep Consumption Time: 2.44885
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.62666

Cumulative Model Updates: 42,752
Cumulative Timesteps: 356,613,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 356613186...
Checkpoint 356613186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,498.10924
Policy Entropy: 3.72751
Value Function Loss: 0.04349

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.15361
Policy Update Magnitude: 0.42466
Value Function Update Magnitude: 0.71995

Collected Steps per Second: 22,435.07161
Overall Steps per Second: 10,740.36872

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.42697
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.65589

Cumulative Model Updates: 42,758
Cumulative Timesteps: 356,663,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,869.60262
Policy Entropy: 3.74525
Value Function Loss: 0.04275

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.37186
Value Function Update Magnitude: 0.74745

Collected Steps per Second: 22,872.40306
Overall Steps per Second: 10,906.35333

Timestep Collection Time: 2.18683
Timestep Consumption Time: 2.39931
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.58613

Cumulative Model Updates: 42,764
Cumulative Timesteps: 356,713,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 356713210...
Checkpoint 356713210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,139.30041
Policy Entropy: 3.76856
Value Function Loss: 0.03999

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.42435
Value Function Update Magnitude: 0.72603

Collected Steps per Second: 22,381.27613
Overall Steps per Second: 10,635.71334

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.46772
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.70227

Cumulative Model Updates: 42,770
Cumulative Timesteps: 356,763,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,398.02633
Policy Entropy: 3.75496
Value Function Loss: 0.03885

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.48545
Value Function Update Magnitude: 0.67101

Collected Steps per Second: 23,129.43609
Overall Steps per Second: 10,865.87764

Timestep Collection Time: 2.16339
Timestep Consumption Time: 2.44167
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60506

Cumulative Model Updates: 42,776
Cumulative Timesteps: 356,813,260

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 356813260...
Checkpoint 356813260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,402.34819
Policy Entropy: 3.75125
Value Function Loss: 0.03893

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07187
Policy Update Magnitude: 0.54096
Value Function Update Magnitude: 0.71511

Collected Steps per Second: 22,291.36281
Overall Steps per Second: 10,718.29296

Timestep Collection Time: 2.24419
Timestep Consumption Time: 2.42316
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.66735

Cumulative Model Updates: 42,782
Cumulative Timesteps: 356,863,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.01810
Policy Entropy: 3.75399
Value Function Loss: 0.04099

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07092
Policy Update Magnitude: 0.56091
Value Function Update Magnitude: 0.74063

Collected Steps per Second: 22,826.84298
Overall Steps per Second: 10,817.66634

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62503

Cumulative Model Updates: 42,788
Cumulative Timesteps: 356,913,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 356913318...
Checkpoint 356913318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,752.88416
Policy Entropy: 3.75436
Value Function Loss: 0.04107

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04987
Policy Update Magnitude: 0.58066
Value Function Update Magnitude: 0.75181

Collected Steps per Second: 22,294.45304
Overall Steps per Second: 10,723.71551

Timestep Collection Time: 2.24352
Timestep Consumption Time: 2.42072
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.66424

Cumulative Model Updates: 42,794
Cumulative Timesteps: 356,963,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,885.14424
Policy Entropy: 3.76055
Value Function Loss: 0.03979

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05770
Policy Update Magnitude: 0.60043
Value Function Update Magnitude: 0.75709

Collected Steps per Second: 22,942.55840
Overall Steps per Second: 10,807.79795

Timestep Collection Time: 2.17936
Timestep Consumption Time: 2.44693
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.62629

Cumulative Model Updates: 42,800
Cumulative Timesteps: 357,013,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 357013336...
Checkpoint 357013336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.05139
Policy Entropy: 3.76218
Value Function Loss: 0.03938

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.56916
Value Function Update Magnitude: 0.74845

Collected Steps per Second: 22,459.08121
Overall Steps per Second: 10,729.06445

Timestep Collection Time: 2.22654
Timestep Consumption Time: 2.43426
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.66080

Cumulative Model Updates: 42,806
Cumulative Timesteps: 357,063,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,442.16829
Policy Entropy: 3.77153
Value Function Loss: 0.03897

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.48666
Value Function Update Magnitude: 0.75417

Collected Steps per Second: 22,887.04271
Overall Steps per Second: 10,834.20897

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.61797

Cumulative Model Updates: 42,812
Cumulative Timesteps: 357,113,374

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 357113374...
Checkpoint 357113374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,232.10427
Policy Entropy: 3.75837
Value Function Loss: 0.04024

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.43571
Value Function Update Magnitude: 0.74327

Collected Steps per Second: 22,414.49286
Overall Steps per Second: 10,677.89198

Timestep Collection Time: 2.23106
Timestep Consumption Time: 2.45226
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.68332

Cumulative Model Updates: 42,818
Cumulative Timesteps: 357,163,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,190.03634
Policy Entropy: 3.75585
Value Function Loss: 0.04102

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.42903
Value Function Update Magnitude: 0.74737

Collected Steps per Second: 22,973.02599
Overall Steps per Second: 10,810.55607

Timestep Collection Time: 2.17681
Timestep Consumption Time: 2.44904
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.62585

Cumulative Model Updates: 42,824
Cumulative Timesteps: 357,213,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 357213390...
Checkpoint 357213390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,264.53108
Policy Entropy: 3.75785
Value Function Loss: 0.04158

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.42360
Value Function Update Magnitude: 0.74356

Collected Steps per Second: 22,413.91097
Overall Steps per Second: 10,700.28439

Timestep Collection Time: 2.23076
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.67277

Cumulative Model Updates: 42,830
Cumulative Timesteps: 357,263,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,592.70591
Policy Entropy: 3.75849
Value Function Loss: 0.04183

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.41023
Value Function Update Magnitude: 0.75603

Collected Steps per Second: 22,841.84466
Overall Steps per Second: 10,819.76112

Timestep Collection Time: 2.18932
Timestep Consumption Time: 2.43260
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.62191

Cumulative Model Updates: 42,836
Cumulative Timesteps: 357,313,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 357313398...
Checkpoint 357313398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,193.87523
Policy Entropy: 3.75985
Value Function Loss: 0.04239

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.44817
Value Function Update Magnitude: 0.77123

Collected Steps per Second: 22,598.40471
Overall Steps per Second: 10,761.14408

Timestep Collection Time: 2.21449
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.65043

Cumulative Model Updates: 42,842
Cumulative Timesteps: 357,363,442

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,938.10298
Policy Entropy: 3.77215
Value Function Loss: 0.04165

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.45366
Value Function Update Magnitude: 0.78603

Collected Steps per Second: 22,882.87532
Overall Steps per Second: 10,807.59978

Timestep Collection Time: 2.18548
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.62730

Cumulative Model Updates: 42,848
Cumulative Timesteps: 357,413,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 357413452...
Checkpoint 357413452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,199.92500
Policy Entropy: 3.77572
Value Function Loss: 0.04127

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.44275
Value Function Update Magnitude: 0.78838

Collected Steps per Second: 22,253.11103
Overall Steps per Second: 10,670.26399

Timestep Collection Time: 2.24742
Timestep Consumption Time: 2.43963
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.68704

Cumulative Model Updates: 42,854
Cumulative Timesteps: 357,463,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,567.82125
Policy Entropy: 3.78868
Value Function Loss: 0.03946

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.45976
Value Function Update Magnitude: 0.79247

Collected Steps per Second: 22,921.00568
Overall Steps per Second: 10,737.47802

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.47667
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.65938

Cumulative Model Updates: 42,860
Cumulative Timesteps: 357,513,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 357513494...
Checkpoint 357513494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,288.78552
Policy Entropy: 3.77715
Value Function Loss: 0.04097

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.48522
Value Function Update Magnitude: 0.77802

Collected Steps per Second: 22,556.85576
Overall Steps per Second: 10,644.42133

Timestep Collection Time: 2.21786
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.69993

Cumulative Model Updates: 42,866
Cumulative Timesteps: 357,563,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,642.78121
Policy Entropy: 3.78033
Value Function Loss: 0.04101

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.51001
Value Function Update Magnitude: 0.78123

Collected Steps per Second: 23,281.39593
Overall Steps per Second: 10,709.73903

Timestep Collection Time: 2.14850
Timestep Consumption Time: 2.52202
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.67052

Cumulative Model Updates: 42,872
Cumulative Timesteps: 357,613,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 357613542...
Checkpoint 357613542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,629.23250
Policy Entropy: 3.77016
Value Function Loss: 0.04172

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.50642
Value Function Update Magnitude: 0.76895

Collected Steps per Second: 22,126.25184
Overall Steps per Second: 10,599.10930

Timestep Collection Time: 2.26021
Timestep Consumption Time: 2.45811
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.71832

Cumulative Model Updates: 42,878
Cumulative Timesteps: 357,663,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,011.71993
Policy Entropy: 3.77831
Value Function Loss: 0.04064

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.76929

Collected Steps per Second: 22,881.77099
Overall Steps per Second: 10,810.84095

Timestep Collection Time: 2.18593
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.62665

Cumulative Model Updates: 42,884
Cumulative Timesteps: 357,713,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 357713570...
Checkpoint 357713570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,302.87108
Policy Entropy: 3.77721
Value Function Loss: 0.03950

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.51360
Value Function Update Magnitude: 0.75486

Collected Steps per Second: 22,510.37980
Overall Steps per Second: 10,778.20269

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.41915
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.64159

Cumulative Model Updates: 42,890
Cumulative Timesteps: 357,763,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,211.72163
Policy Entropy: 3.78121
Value Function Loss: 0.04012

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.45105
Value Function Update Magnitude: 0.72747

Collected Steps per Second: 23,070.67417
Overall Steps per Second: 10,865.13053

Timestep Collection Time: 2.16838
Timestep Consumption Time: 2.43589
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60427

Cumulative Model Updates: 42,896
Cumulative Timesteps: 357,813,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 357813624...
Checkpoint 357813624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.00518
Policy Entropy: 3.77988
Value Function Loss: 0.04110

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07411
Policy Update Magnitude: 0.48991
Value Function Update Magnitude: 0.71940

Collected Steps per Second: 22,337.98296
Overall Steps per Second: 10,680.51818

Timestep Collection Time: 2.23897
Timestep Consumption Time: 2.44376
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.68273

Cumulative Model Updates: 42,902
Cumulative Timesteps: 357,863,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,596.79923
Policy Entropy: 3.78136
Value Function Loss: 0.04098

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.72243

Collected Steps per Second: 23,038.23695
Overall Steps per Second: 10,952.55971

Timestep Collection Time: 2.17057
Timestep Consumption Time: 2.39513
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.56569

Cumulative Model Updates: 42,908
Cumulative Timesteps: 357,913,644

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 357913644...
Checkpoint 357913644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,154.36089
Policy Entropy: 3.79421
Value Function Loss: 0.04022

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06881
Policy Update Magnitude: 0.55060
Value Function Update Magnitude: 0.69735

Collected Steps per Second: 22,738.35058
Overall Steps per Second: 10,617.85825

Timestep Collection Time: 2.20034
Timestep Consumption Time: 2.51173
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.71206

Cumulative Model Updates: 42,914
Cumulative Timesteps: 357,963,676

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.88039
Policy Entropy: 3.80882
Value Function Loss: 0.04096

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06519
Policy Update Magnitude: 0.56250
Value Function Update Magnitude: 0.65139

Collected Steps per Second: 23,059.33481
Overall Steps per Second: 10,848.97786

Timestep Collection Time: 2.16867
Timestep Consumption Time: 2.44080
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.60947

Cumulative Model Updates: 42,920
Cumulative Timesteps: 358,013,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 358013684...
Checkpoint 358013684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,031.97141
Policy Entropy: 3.81133
Value Function Loss: 0.04023

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.56811
Value Function Update Magnitude: 0.68835

Collected Steps per Second: 22,585.06815
Overall Steps per Second: 10,666.03448

Timestep Collection Time: 2.21438
Timestep Consumption Time: 2.47452
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.68890

Cumulative Model Updates: 42,926
Cumulative Timesteps: 358,063,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,613.18359
Policy Entropy: 3.79934
Value Function Loss: 0.03971

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.49638
Value Function Update Magnitude: 0.69577

Collected Steps per Second: 23,029.32478
Overall Steps per Second: 10,845.95146

Timestep Collection Time: 2.17123
Timestep Consumption Time: 2.43897
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61020

Cumulative Model Updates: 42,932
Cumulative Timesteps: 358,113,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 358113698...
Checkpoint 358113698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,839.79554
Policy Entropy: 3.80129
Value Function Loss: 0.03886

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.49675
Value Function Update Magnitude: 0.68920

Collected Steps per Second: 22,442.60575
Overall Steps per Second: 10,735.00921

Timestep Collection Time: 2.22853
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.65896

Cumulative Model Updates: 42,938
Cumulative Timesteps: 358,163,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,634.15879
Policy Entropy: 3.79004
Value Function Loss: 0.03890

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.71369

Collected Steps per Second: 23,052.55582
Overall Steps per Second: 10,893.37411

Timestep Collection Time: 2.16896
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.58995

Cumulative Model Updates: 42,944
Cumulative Timesteps: 358,213,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 358213712...
Checkpoint 358213712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,873.95288
Policy Entropy: 3.78850
Value Function Loss: 0.04142

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05303
Policy Update Magnitude: 0.57206
Value Function Update Magnitude: 0.68871

Collected Steps per Second: 22,367.09910
Overall Steps per Second: 10,629.24876

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.46956
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.70588

Cumulative Model Updates: 42,950
Cumulative Timesteps: 358,263,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,260.00613
Policy Entropy: 3.76944
Value Function Loss: 0.04383

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.05961
Policy Update Magnitude: 0.58636
Value Function Update Magnitude: 0.61462

Collected Steps per Second: 22,487.37406
Overall Steps per Second: 10,584.63192

Timestep Collection Time: 2.22409
Timestep Consumption Time: 2.50106
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.72515

Cumulative Model Updates: 42,956
Cumulative Timesteps: 358,313,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 358313746...
Checkpoint 358313746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,171.75219
Policy Entropy: 3.77348
Value Function Loss: 0.04459

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.54476
Value Function Update Magnitude: 0.59956

Collected Steps per Second: 22,774.52460
Overall Steps per Second: 10,691.95516

Timestep Collection Time: 2.19640
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.67847

Cumulative Model Updates: 42,962
Cumulative Timesteps: 358,363,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,745.30009
Policy Entropy: 3.76853
Value Function Loss: 0.04792

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.47369
Value Function Update Magnitude: 0.62117

Collected Steps per Second: 23,193.68059
Overall Steps per Second: 10,709.78975

Timestep Collection Time: 2.15628
Timestep Consumption Time: 2.51347
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.66975

Cumulative Model Updates: 42,968
Cumulative Timesteps: 358,413,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 358413780...
Checkpoint 358413780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,898.42983
Policy Entropy: 3.75899
Value Function Loss: 0.04824

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.54598
Value Function Update Magnitude: 0.63406

Collected Steps per Second: 22,437.40381
Overall Steps per Second: 10,596.88806

Timestep Collection Time: 2.22985
Timestep Consumption Time: 2.49154
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.72139

Cumulative Model Updates: 42,974
Cumulative Timesteps: 358,463,812

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,781.55941
Policy Entropy: 3.75687
Value Function Loss: 0.04607

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.63719

Collected Steps per Second: 22,991.55202
Overall Steps per Second: 10,866.57266

Timestep Collection Time: 2.17489
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.60163

Cumulative Model Updates: 42,980
Cumulative Timesteps: 358,513,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 358513816...
Checkpoint 358513816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,386.42972
Policy Entropy: 3.75672
Value Function Loss: 0.04224

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.47914
Value Function Update Magnitude: 0.61818

Collected Steps per Second: 22,560.62559
Overall Steps per Second: 10,756.14763

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.64925

Cumulative Model Updates: 42,986
Cumulative Timesteps: 358,563,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,799.96945
Policy Entropy: 3.75497
Value Function Loss: 0.04259

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.42576
Value Function Update Magnitude: 0.58150

Collected Steps per Second: 23,252.14056
Overall Steps per Second: 10,880.82292

Timestep Collection Time: 2.15060
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.59579

Cumulative Model Updates: 42,992
Cumulative Timesteps: 358,613,830

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 358613830...
Checkpoint 358613830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,144.85128
Policy Entropy: 3.75141
Value Function Loss: 0.04324

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.41659
Value Function Update Magnitude: 0.55874

Collected Steps per Second: 22,290.17905
Overall Steps per Second: 10,631.20042

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.46019
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.70351

Cumulative Model Updates: 42,998
Cumulative Timesteps: 358,663,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,987.57890
Policy Entropy: 3.75072
Value Function Loss: 0.04298

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.42929
Value Function Update Magnitude: 0.56161

Collected Steps per Second: 23,144.26707
Overall Steps per Second: 10,865.19378

Timestep Collection Time: 2.16149
Timestep Consumption Time: 2.44276
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.60424

Cumulative Model Updates: 43,004
Cumulative Timesteps: 358,713,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 358713860...
Checkpoint 358713860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,059.01858
Policy Entropy: 3.74408
Value Function Loss: 0.04509

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.44236
Value Function Update Magnitude: 0.55385

Collected Steps per Second: 22,321.18045
Overall Steps per Second: 10,705.57719

Timestep Collection Time: 2.24002
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.67046

Cumulative Model Updates: 43,010
Cumulative Timesteps: 358,763,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,036.10340
Policy Entropy: 3.75003
Value Function Loss: 0.04697

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.46475
Value Function Update Magnitude: 0.52817

Collected Steps per Second: 23,210.04876
Overall Steps per Second: 10,888.77545

Timestep Collection Time: 2.15519
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.59390

Cumulative Model Updates: 43,016
Cumulative Timesteps: 358,813,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 358813882...
Checkpoint 358813882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,487.40733
Policy Entropy: 3.73847
Value Function Loss: 0.04780

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.46013
Value Function Update Magnitude: 0.55882

Collected Steps per Second: 22,414.48137
Overall Steps per Second: 10,653.20561

Timestep Collection Time: 2.23124
Timestep Consumption Time: 2.46331
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.69455

Cumulative Model Updates: 43,022
Cumulative Timesteps: 358,863,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,319.75790
Policy Entropy: 3.73485
Value Function Loss: 0.04642

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.45642
Value Function Update Magnitude: 0.59976

Collected Steps per Second: 22,738.65094
Overall Steps per Second: 10,799.30464

Timestep Collection Time: 2.19978
Timestep Consumption Time: 2.43200
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.63178

Cumulative Model Updates: 43,028
Cumulative Timesteps: 358,913,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 358913914...
Checkpoint 358913914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.11959
Policy Entropy: 3.73437
Value Function Loss: 0.04463

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.47969
Value Function Update Magnitude: 0.60765

Collected Steps per Second: 22,400.47366
Overall Steps per Second: 10,789.77174

Timestep Collection Time: 2.23352
Timestep Consumption Time: 2.40346
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.63698

Cumulative Model Updates: 43,034
Cumulative Timesteps: 358,963,946

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,941.44020
Policy Entropy: 3.74399
Value Function Loss: 0.04569

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.50010
Value Function Update Magnitude: 0.60075

Collected Steps per Second: 23,226.56082
Overall Steps per Second: 10,896.09973

Timestep Collection Time: 2.15314
Timestep Consumption Time: 2.43658
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.58972

Cumulative Model Updates: 43,040
Cumulative Timesteps: 359,013,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 359013956...
Checkpoint 359013956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,002.08284
Policy Entropy: 3.76023
Value Function Loss: 0.04496

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.46209
Value Function Update Magnitude: 0.57827

Collected Steps per Second: 22,369.18514
Overall Steps per Second: 10,591.68777

Timestep Collection Time: 2.23763
Timestep Consumption Time: 2.48815
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.72578

Cumulative Model Updates: 43,046
Cumulative Timesteps: 359,064,010

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,332.03076
Policy Entropy: 3.75695
Value Function Loss: 0.04519

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07204
Policy Update Magnitude: 0.45978
Value Function Update Magnitude: 0.60433

Collected Steps per Second: 22,991.26582
Overall Steps per Second: 10,857.93301

Timestep Collection Time: 2.17552
Timestep Consumption Time: 2.43106
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60659

Cumulative Model Updates: 43,052
Cumulative Timesteps: 359,114,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 359114028...
Checkpoint 359114028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,055.14824
Policy Entropy: 3.77432
Value Function Loss: 0.04331

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05649
Policy Update Magnitude: 0.55983
Value Function Update Magnitude: 0.59462

Collected Steps per Second: 22,584.71708
Overall Steps per Second: 10,714.83695

Timestep Collection Time: 2.21406
Timestep Consumption Time: 2.45274
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.66680

Cumulative Model Updates: 43,058
Cumulative Timesteps: 359,164,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,320.51918
Policy Entropy: 3.77392
Value Function Loss: 0.04377

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06345
Policy Update Magnitude: 0.59220
Value Function Update Magnitude: 0.61086

Collected Steps per Second: 23,011.63999
Overall Steps per Second: 10,851.59741

Timestep Collection Time: 2.17342
Timestep Consumption Time: 2.43548
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.60891

Cumulative Model Updates: 43,064
Cumulative Timesteps: 359,214,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 359214046...
Checkpoint 359214046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,873.54461
Policy Entropy: 3.76762
Value Function Loss: 0.04468

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06158
Policy Update Magnitude: 0.59069
Value Function Update Magnitude: 0.60368

Collected Steps per Second: 22,419.12176
Overall Steps per Second: 10,683.90970

Timestep Collection Time: 2.23104
Timestep Consumption Time: 2.45058
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.68162

Cumulative Model Updates: 43,070
Cumulative Timesteps: 359,264,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,361.18718
Policy Entropy: 3.76631
Value Function Loss: 0.04574

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05703
Policy Update Magnitude: 0.60135
Value Function Update Magnitude: 0.60733

Collected Steps per Second: 23,042.94926
Overall Steps per Second: 10,835.71503

Timestep Collection Time: 2.17038
Timestep Consumption Time: 2.44510
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.61548

Cumulative Model Updates: 43,076
Cumulative Timesteps: 359,314,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 359314076...
Checkpoint 359314076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.99607
Policy Entropy: 3.77058
Value Function Loss: 0.04582

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06247
Policy Update Magnitude: 0.61352
Value Function Update Magnitude: 0.61375

Collected Steps per Second: 22,632.03767
Overall Steps per Second: 10,696.45099

Timestep Collection Time: 2.21058
Timestep Consumption Time: 2.46667
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.67725

Cumulative Model Updates: 43,082
Cumulative Timesteps: 359,364,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.88938
Policy Entropy: 3.77753
Value Function Loss: 0.04484

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.59173
Value Function Update Magnitude: 0.59991

Collected Steps per Second: 23,063.96885
Overall Steps per Second: 10,855.27202

Timestep Collection Time: 2.16840
Timestep Consumption Time: 2.43876
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.60716

Cumulative Model Updates: 43,088
Cumulative Timesteps: 359,414,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 359414118...
Checkpoint 359414118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,826.35122
Policy Entropy: 3.77085
Value Function Loss: 0.04528

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.49595
Value Function Update Magnitude: 0.58261

Collected Steps per Second: 22,515.62888
Overall Steps per Second: 10,682.29776

Timestep Collection Time: 2.22166
Timestep Consumption Time: 2.46104
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.68270

Cumulative Model Updates: 43,094
Cumulative Timesteps: 359,464,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,531.33071
Policy Entropy: 3.77091
Value Function Loss: 0.04420

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.45246
Value Function Update Magnitude: 0.58139

Collected Steps per Second: 22,931.72728
Overall Steps per Second: 10,817.90323

Timestep Collection Time: 2.18065
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.62252

Cumulative Model Updates: 43,100
Cumulative Timesteps: 359,514,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 359514146...
Checkpoint 359514146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,588.40575
Policy Entropy: 3.76629
Value Function Loss: 0.04257

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.46045
Value Function Update Magnitude: 0.61718

Collected Steps per Second: 22,330.57414
Overall Steps per Second: 10,767.22323

Timestep Collection Time: 2.23908
Timestep Consumption Time: 2.40464
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.64372

Cumulative Model Updates: 43,106
Cumulative Timesteps: 359,564,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,739.63007
Policy Entropy: 3.77162
Value Function Loss: 0.04242

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.46190
Value Function Update Magnitude: 0.64757

Collected Steps per Second: 22,933.45065
Overall Steps per Second: 10,894.71959

Timestep Collection Time: 2.18214
Timestep Consumption Time: 2.41128
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.59342

Cumulative Model Updates: 43,112
Cumulative Timesteps: 359,614,190

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 359614190...
Checkpoint 359614190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,396.41580
Policy Entropy: 3.76961
Value Function Loss: 0.04226

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.44402
Value Function Update Magnitude: 0.65787

Collected Steps per Second: 22,413.83088
Overall Steps per Second: 10,616.07664

Timestep Collection Time: 2.23201
Timestep Consumption Time: 2.48046
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.71248

Cumulative Model Updates: 43,118
Cumulative Timesteps: 359,664,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.85893
Policy Entropy: 3.77044
Value Function Loss: 0.04046

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.45214
Value Function Update Magnitude: 0.71296

Collected Steps per Second: 22,948.60790
Overall Steps per Second: 10,869.37218

Timestep Collection Time: 2.17896
Timestep Consumption Time: 2.42149
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.60045

Cumulative Model Updates: 43,124
Cumulative Timesteps: 359,714,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 359714222...
Checkpoint 359714222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,674.69216
Policy Entropy: 3.77194
Value Function Loss: 0.03933

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.51182
Value Function Update Magnitude: 0.73089

Collected Steps per Second: 22,668.61162
Overall Steps per Second: 10,698.72027

Timestep Collection Time: 2.20605
Timestep Consumption Time: 2.46816
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.67420

Cumulative Model Updates: 43,130
Cumulative Timesteps: 359,764,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,716.93394
Policy Entropy: 3.77362
Value Function Loss: 0.04074

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07261
Policy Update Magnitude: 0.57269
Value Function Update Magnitude: 0.73696

Collected Steps per Second: 22,911.23320
Overall Steps per Second: 10,820.09326

Timestep Collection Time: 2.18242
Timestep Consumption Time: 2.43879
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.62122

Cumulative Model Updates: 43,136
Cumulative Timesteps: 359,814,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 359814232...
Checkpoint 359814232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,578.05869
Policy Entropy: 3.78378
Value Function Loss: 0.04221

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06185
Policy Update Magnitude: 0.59302
Value Function Update Magnitude: 0.74481

Collected Steps per Second: 22,438.09668
Overall Steps per Second: 10,733.85471

Timestep Collection Time: 2.22862
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.65872

Cumulative Model Updates: 43,142
Cumulative Timesteps: 359,864,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,054.25977
Policy Entropy: 3.77341
Value Function Loss: 0.04229

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06343
Policy Update Magnitude: 0.57777
Value Function Update Magnitude: 0.74858

Collected Steps per Second: 22,855.44028
Overall Steps per Second: 10,822.76984

Timestep Collection Time: 2.18828
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62118

Cumulative Model Updates: 43,148
Cumulative Timesteps: 359,914,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 359914252...
Checkpoint 359914252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,826.88966
Policy Entropy: 3.77111
Value Function Loss: 0.04142

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05631
Policy Update Magnitude: 0.59668
Value Function Update Magnitude: 0.77387

Collected Steps per Second: 22,490.28498
Overall Steps per Second: 10,779.29305

Timestep Collection Time: 2.22532
Timestep Consumption Time: 2.41766
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.64298

Cumulative Model Updates: 43,154
Cumulative Timesteps: 359,964,300

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,464.27531
Policy Entropy: 3.75346
Value Function Loss: 0.04153

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06085
Policy Update Magnitude: 0.58893
Value Function Update Magnitude: 0.79798

Collected Steps per Second: 23,040.49731
Overall Steps per Second: 10,884.49109

Timestep Collection Time: 2.17131
Timestep Consumption Time: 2.42496
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.59626

Cumulative Model Updates: 43,160
Cumulative Timesteps: 360,014,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 360014328...
Checkpoint 360014328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,811.60929
Policy Entropy: 3.77096
Value Function Loss: 0.04117

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06756
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.76206

Collected Steps per Second: 22,369.08889
Overall Steps per Second: 10,575.90055

Timestep Collection Time: 2.23639
Timestep Consumption Time: 2.49380
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.73019

Cumulative Model Updates: 43,166
Cumulative Timesteps: 360,064,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,449.81713
Policy Entropy: 3.76921
Value Function Loss: 0.04473

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.49495
Value Function Update Magnitude: 0.63108

Collected Steps per Second: 23,001.23529
Overall Steps per Second: 10,847.48916

Timestep Collection Time: 2.17414
Timestep Consumption Time: 2.43596
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61010

Cumulative Model Updates: 43,172
Cumulative Timesteps: 360,114,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 360114362...
Checkpoint 360114362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,009.89582
Policy Entropy: 3.76165
Value Function Loss: 0.04485

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.44294
Value Function Update Magnitude: 0.58963

Collected Steps per Second: 22,270.69178
Overall Steps per Second: 10,691.85833

Timestep Collection Time: 2.24645
Timestep Consumption Time: 2.43281
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.67926

Cumulative Model Updates: 43,178
Cumulative Timesteps: 360,164,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,496.27489
Policy Entropy: 3.75525
Value Function Loss: 0.04620

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.43178
Value Function Update Magnitude: 0.59278

Collected Steps per Second: 23,045.74034
Overall Steps per Second: 10,873.19091

Timestep Collection Time: 2.17090
Timestep Consumption Time: 2.43033
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.60123

Cumulative Model Updates: 43,184
Cumulative Timesteps: 360,214,422

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 360214422...
Checkpoint 360214422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,513.73428
Policy Entropy: 3.75540
Value Function Loss: 0.04592

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.43608
Value Function Update Magnitude: 0.61762

Collected Steps per Second: 22,359.78207
Overall Steps per Second: 10,707.13078

Timestep Collection Time: 2.23741
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.67240

Cumulative Model Updates: 43,190
Cumulative Timesteps: 360,264,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,240.07217
Policy Entropy: 3.75900
Value Function Loss: 0.04581

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.45583
Value Function Update Magnitude: 0.62061

Collected Steps per Second: 23,100.33438
Overall Steps per Second: 10,893.56906

Timestep Collection Time: 2.16542
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.59188

Cumulative Model Updates: 43,196
Cumulative Timesteps: 360,314,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 360314472...
Checkpoint 360314472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,299.86252
Policy Entropy: 3.76920
Value Function Loss: 0.04574

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.59591

Collected Steps per Second: 22,542.83260
Overall Steps per Second: 10,688.18017

Timestep Collection Time: 2.21898
Timestep Consumption Time: 2.46115
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.68012

Cumulative Model Updates: 43,202
Cumulative Timesteps: 360,364,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,261.32001
Policy Entropy: 3.76269
Value Function Loss: 0.04560

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.60921

Collected Steps per Second: 22,789.21011
Overall Steps per Second: 10,820.08606

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62177

Cumulative Model Updates: 43,208
Cumulative Timesteps: 360,414,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 360414502...
Checkpoint 360414502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,195.32135
Policy Entropy: 3.76307
Value Function Loss: 0.04320

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.50548
Value Function Update Magnitude: 0.60593

Collected Steps per Second: 22,648.18901
Overall Steps per Second: 10,680.08400

Timestep Collection Time: 2.20848
Timestep Consumption Time: 2.47482
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.68330

Cumulative Model Updates: 43,214
Cumulative Timesteps: 360,464,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,788.97671
Policy Entropy: 3.75274
Value Function Loss: 0.04181

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.67760

Collected Steps per Second: 22,959.69056
Overall Steps per Second: 10,869.16843

Timestep Collection Time: 2.17869
Timestep Consumption Time: 2.42350
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.60219

Cumulative Model Updates: 43,220
Cumulative Timesteps: 360,514,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 360514542...
Checkpoint 360514542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,861.59190
Policy Entropy: 3.74736
Value Function Loss: 0.04344

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.54065
Value Function Update Magnitude: 0.70744

Collected Steps per Second: 22,547.16812
Overall Steps per Second: 10,712.87788

Timestep Collection Time: 2.21793
Timestep Consumption Time: 2.45010
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.66803

Cumulative Model Updates: 43,226
Cumulative Timesteps: 360,564,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,536.56526
Policy Entropy: 3.75230
Value Function Loss: 0.04338

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.47408
Value Function Update Magnitude: 0.69985

Collected Steps per Second: 23,079.87624
Overall Steps per Second: 10,871.53273

Timestep Collection Time: 2.16743
Timestep Consumption Time: 2.43395
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.60138

Cumulative Model Updates: 43,232
Cumulative Timesteps: 360,614,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 360614574...
Checkpoint 360614574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,853.76241
Policy Entropy: 3.75605
Value Function Loss: 0.04254

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.45006
Value Function Update Magnitude: 0.75778

Collected Steps per Second: 22,388.31489
Overall Steps per Second: 10,671.79732

Timestep Collection Time: 2.23420
Timestep Consumption Time: 2.45292
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.68712

Cumulative Model Updates: 43,238
Cumulative Timesteps: 360,664,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,612.77771
Policy Entropy: 3.76048
Value Function Loss: 0.04008

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.48121
Value Function Update Magnitude: 0.77614

Collected Steps per Second: 22,319.36486
Overall Steps per Second: 10,884.25379

Timestep Collection Time: 2.24110
Timestep Consumption Time: 2.35453
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59563

Cumulative Model Updates: 43,244
Cumulative Timesteps: 360,714,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 360714614...
Checkpoint 360714614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,864.91835
Policy Entropy: 3.75443
Value Function Loss: 0.04292

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.50294
Value Function Update Magnitude: 0.78809

Collected Steps per Second: 21,896.17172
Overall Steps per Second: 10,697.02887

Timestep Collection Time: 2.28579
Timestep Consumption Time: 2.39308
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.67887

Cumulative Model Updates: 43,250
Cumulative Timesteps: 360,764,664

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,100.61134
Policy Entropy: 3.75322
Value Function Loss: 0.04627

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05969
Policy Update Magnitude: 0.56862
Value Function Update Magnitude: 0.72509

Collected Steps per Second: 21,908.71907
Overall Steps per Second: 10,777.55289

Timestep Collection Time: 2.28302
Timestep Consumption Time: 2.35792
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.64094

Cumulative Model Updates: 43,256
Cumulative Timesteps: 360,814,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 360814682...
Checkpoint 360814682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,433.89111
Policy Entropy: 3.74159
Value Function Loss: 0.04916

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.57955
Value Function Update Magnitude: 0.61091

Collected Steps per Second: 21,500.38845
Overall Steps per Second: 10,659.56944

Timestep Collection Time: 2.32563
Timestep Consumption Time: 2.36518
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.69081

Cumulative Model Updates: 43,262
Cumulative Timesteps: 360,864,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,093.93514
Policy Entropy: 3.75186
Value Function Loss: 0.04808

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.52942
Value Function Update Magnitude: 0.64324

Collected Steps per Second: 21,997.21931
Overall Steps per Second: 10,658.30545

Timestep Collection Time: 2.27447
Timestep Consumption Time: 2.41971
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.69418

Cumulative Model Updates: 43,268
Cumulative Timesteps: 360,914,716

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 360914716...
Checkpoint 360914716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,717.42252
Policy Entropy: 3.73152
Value Function Loss: 0.04746

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.50386
Value Function Update Magnitude: 0.67626

Collected Steps per Second: 21,989.76892
Overall Steps per Second: 10,690.16485

Timestep Collection Time: 2.27415
Timestep Consumption Time: 2.40380
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.67794

Cumulative Model Updates: 43,274
Cumulative Timesteps: 360,964,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,369.86306
Policy Entropy: 3.74061
Value Function Loss: 0.04526

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.51693
Value Function Update Magnitude: 0.69735

Collected Steps per Second: 22,440.37509
Overall Steps per Second: 10,778.98815

Timestep Collection Time: 2.22866
Timestep Consumption Time: 2.41111
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.63977

Cumulative Model Updates: 43,280
Cumulative Timesteps: 361,014,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 361014736...
Checkpoint 361014736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,574.19156
Policy Entropy: 3.74396
Value Function Loss: 0.04581

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.44252
Value Function Update Magnitude: 0.69984

Collected Steps per Second: 22,427.49015
Overall Steps per Second: 10,574.37447

Timestep Collection Time: 2.22994
Timestep Consumption Time: 2.49960
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.72955

Cumulative Model Updates: 43,286
Cumulative Timesteps: 361,064,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,053.70462
Policy Entropy: 3.73386
Value Function Loss: 0.04916

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11024
Policy Update Magnitude: 0.40057
Value Function Update Magnitude: 0.59325

Collected Steps per Second: 22,630.74158
Overall Steps per Second: 10,829.42448

Timestep Collection Time: 2.21000
Timestep Consumption Time: 2.40834
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61834

Cumulative Model Updates: 43,292
Cumulative Timesteps: 361,114,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 361114762...
Checkpoint 361114762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,341.04725
Policy Entropy: 3.73582
Value Function Loss: 0.04836

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.40819
Value Function Update Magnitude: 0.55927

Collected Steps per Second: 22,588.45916
Overall Steps per Second: 10,733.93667

Timestep Collection Time: 2.21476
Timestep Consumption Time: 2.44597
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.66073

Cumulative Model Updates: 43,298
Cumulative Timesteps: 361,164,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,768.28850
Policy Entropy: 3.73316
Value Function Loss: 0.04919

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.41685
Value Function Update Magnitude: 0.57132

Collected Steps per Second: 22,576.25707
Overall Steps per Second: 10,568.05359

Timestep Collection Time: 2.21472
Timestep Consumption Time: 2.51652
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.73124

Cumulative Model Updates: 43,304
Cumulative Timesteps: 361,214,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 361214790...
Checkpoint 361214790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,198.26932
Policy Entropy: 3.74522
Value Function Loss: 0.04569

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.45677
Value Function Update Magnitude: 0.59564

Collected Steps per Second: 22,643.69662
Overall Steps per Second: 10,627.57168

Timestep Collection Time: 2.20909
Timestep Consumption Time: 2.49772
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.70681

Cumulative Model Updates: 43,310
Cumulative Timesteps: 361,264,812

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,356.47566
Policy Entropy: 3.73082
Value Function Loss: 0.04522

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.52643
Value Function Update Magnitude: 0.62969

Collected Steps per Second: 23,144.58645
Overall Steps per Second: 10,821.33172

Timestep Collection Time: 2.16033
Timestep Consumption Time: 2.46017
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.62050

Cumulative Model Updates: 43,316
Cumulative Timesteps: 361,314,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 361314812...
Checkpoint 361314812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,596.86083
Policy Entropy: 3.72899
Value Function Loss: 0.04464

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.50073
Value Function Update Magnitude: 0.72535

Collected Steps per Second: 22,467.41843
Overall Steps per Second: 10,644.02999

Timestep Collection Time: 2.22633
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.69935

Cumulative Model Updates: 43,322
Cumulative Timesteps: 361,364,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,227.92847
Policy Entropy: 3.72485
Value Function Loss: 0.04461

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07132
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.75457

Collected Steps per Second: 22,942.36917
Overall Steps per Second: 10,816.25664

Timestep Collection Time: 2.17964
Timestep Consumption Time: 2.44359
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.62323

Cumulative Model Updates: 43,328
Cumulative Timesteps: 361,414,838

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 361414838...
Checkpoint 361414838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,504.93617
Policy Entropy: 3.73262
Value Function Loss: 0.04424

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.54994
Value Function Update Magnitude: 0.73395

Collected Steps per Second: 22,328.24112
Overall Steps per Second: 10,689.24384

Timestep Collection Time: 2.24048
Timestep Consumption Time: 2.43955
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.68003

Cumulative Model Updates: 43,334
Cumulative Timesteps: 361,464,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,604.86201
Policy Entropy: 3.72685
Value Function Loss: 0.04641

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.18330
Policy Update Magnitude: 0.42999
Value Function Update Magnitude: 0.65277

Collected Steps per Second: 22,886.54449
Overall Steps per Second: 10,702.05905

Timestep Collection Time: 2.18530
Timestep Consumption Time: 2.48800
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.67331

Cumulative Model Updates: 43,340
Cumulative Timesteps: 361,514,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 361514878...
Checkpoint 361514878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,734.50197
Policy Entropy: 3.73583
Value Function Loss: 0.04844

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.37367
Value Function Update Magnitude: 0.60048

Collected Steps per Second: 22,763.72220
Overall Steps per Second: 10,813.37552

Timestep Collection Time: 2.19657
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.62409

Cumulative Model Updates: 43,346
Cumulative Timesteps: 361,564,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,576.20591
Policy Entropy: 3.73436
Value Function Loss: 0.04970

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.18412
Policy Update Magnitude: 0.37275
Value Function Update Magnitude: 0.64690

Collected Steps per Second: 22,999.45396
Overall Steps per Second: 10,716.52877

Timestep Collection Time: 2.17492
Timestep Consumption Time: 2.49282
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.66774

Cumulative Model Updates: 43,352
Cumulative Timesteps: 361,614,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 361614902...
Checkpoint 361614902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,701.77579
Policy Entropy: 3.74239
Value Function Loss: 0.05139

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.38792
Value Function Update Magnitude: 0.67514

Collected Steps per Second: 22,441.61063
Overall Steps per Second: 10,554.44445

Timestep Collection Time: 2.22898
Timestep Consumption Time: 2.51044
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.73943

Cumulative Model Updates: 43,358
Cumulative Timesteps: 361,664,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,095.70734
Policy Entropy: 3.73258
Value Function Loss: 0.04860

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.46351
Value Function Update Magnitude: 0.69910

Collected Steps per Second: 22,833.87708
Overall Steps per Second: 10,824.94974

Timestep Collection Time: 2.19034
Timestep Consumption Time: 2.42991
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.62025

Cumulative Model Updates: 43,364
Cumulative Timesteps: 361,714,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 361714938...
Checkpoint 361714938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,959.83648
Policy Entropy: 3.72755
Value Function Loss: 0.04683

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.69020

Collected Steps per Second: 22,317.80990
Overall Steps per Second: 10,626.13344

Timestep Collection Time: 2.24036
Timestep Consumption Time: 2.46502
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.70538

Cumulative Model Updates: 43,370
Cumulative Timesteps: 361,764,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,424.03248
Policy Entropy: 3.72569
Value Function Loss: 0.04644

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07168
Policy Update Magnitude: 0.58958
Value Function Update Magnitude: 0.61682

Collected Steps per Second: 23,211.39021
Overall Steps per Second: 10,903.23091

Timestep Collection Time: 2.15420
Timestep Consumption Time: 2.43178
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.58598

Cumulative Model Updates: 43,376
Cumulative Timesteps: 361,814,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 361814940...
Checkpoint 361814940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.53440
Policy Entropy: 3.73251
Value Function Loss: 0.04695

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.65434

Collected Steps per Second: 22,643.57132
Overall Steps per Second: 10,614.23645

Timestep Collection Time: 2.20937
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.71329

Cumulative Model Updates: 43,382
Cumulative Timesteps: 361,864,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,921.62232
Policy Entropy: 3.73193
Value Function Loss: 0.04747

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.47141
Value Function Update Magnitude: 0.71445

Collected Steps per Second: 22,823.14237
Overall Steps per Second: 10,707.35278

Timestep Collection Time: 2.19076
Timestep Consumption Time: 2.47893
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.66969

Cumulative Model Updates: 43,388
Cumulative Timesteps: 361,914,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 361914968...
Checkpoint 361914968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,352.22617
Policy Entropy: 3.73680
Value Function Loss: 0.04823

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.44351
Value Function Update Magnitude: 0.69321

Collected Steps per Second: 22,259.99442
Overall Steps per Second: 10,577.21606

Timestep Collection Time: 2.24798
Timestep Consumption Time: 2.48294
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.73092

Cumulative Model Updates: 43,394
Cumulative Timesteps: 361,965,008

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,267.90558
Policy Entropy: 3.73085
Value Function Loss: 0.04583

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.46416
Value Function Update Magnitude: 0.75428

Collected Steps per Second: 23,000.44312
Overall Steps per Second: 10,731.37510

Timestep Collection Time: 2.17457
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.66073

Cumulative Model Updates: 43,400
Cumulative Timesteps: 362,015,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 362015024...
Checkpoint 362015024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,040.55296
Policy Entropy: 3.73377
Value Function Loss: 0.04452

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.47372
Value Function Update Magnitude: 0.80857

Collected Steps per Second: 22,400.33898
Overall Steps per Second: 10,602.11985

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.71698

Cumulative Model Updates: 43,406
Cumulative Timesteps: 362,065,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,718.70739
Policy Entropy: 3.73328
Value Function Loss: 0.04181

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.47824
Value Function Update Magnitude: 0.79990

Collected Steps per Second: 22,706.41649
Overall Steps per Second: 10,669.55786

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.48441
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.68660

Cumulative Model Updates: 43,412
Cumulative Timesteps: 362,115,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 362115038...
Checkpoint 362115038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,856.44294
Policy Entropy: 3.75255
Value Function Loss: 0.04313

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.50019
Value Function Update Magnitude: 0.72595

Collected Steps per Second: 22,542.30456
Overall Steps per Second: 10,649.37765

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.47825
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.69736

Cumulative Model Updates: 43,418
Cumulative Timesteps: 362,165,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,557.41754
Policy Entropy: 3.76601
Value Function Loss: 0.04624

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.49340
Value Function Update Magnitude: 0.64418

Collected Steps per Second: 22,902.86590
Overall Steps per Second: 10,737.21721

Timestep Collection Time: 2.18383
Timestep Consumption Time: 2.47436
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.65819

Cumulative Model Updates: 43,424
Cumulative Timesteps: 362,215,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 362215078...
Checkpoint 362215078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,249.30187
Policy Entropy: 3.78382
Value Function Loss: 0.04726

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.46257
Value Function Update Magnitude: 0.60576

Collected Steps per Second: 22,431.57884
Overall Steps per Second: 10,612.10824

Timestep Collection Time: 2.23007
Timestep Consumption Time: 2.48379
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.71386

Cumulative Model Updates: 43,430
Cumulative Timesteps: 362,265,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,913.66201
Policy Entropy: 3.76828
Value Function Loss: 0.04881

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.51717
Value Function Update Magnitude: 0.58039

Collected Steps per Second: 22,904.72081
Overall Steps per Second: 10,857.65866

Timestep Collection Time: 2.18392
Timestep Consumption Time: 2.42315
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.60707

Cumulative Model Updates: 43,436
Cumulative Timesteps: 362,315,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 362315124...
Checkpoint 362315124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,348.87573
Policy Entropy: 3.76243
Value Function Loss: 0.04617

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.51275
Value Function Update Magnitude: 0.58346

Collected Steps per Second: 22,466.30907
Overall Steps per Second: 10,685.25364

Timestep Collection Time: 2.22591
Timestep Consumption Time: 2.45418
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.68009

Cumulative Model Updates: 43,442
Cumulative Timesteps: 362,365,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,159.84836
Policy Entropy: 3.75647
Value Function Loss: 0.04597

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.47492
Value Function Update Magnitude: 0.57767

Collected Steps per Second: 22,942.09853
Overall Steps per Second: 10,865.78351

Timestep Collection Time: 2.18079
Timestep Consumption Time: 2.42375
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60455

Cumulative Model Updates: 43,448
Cumulative Timesteps: 362,415,164

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 362415164...
Checkpoint 362415164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,022.87745
Policy Entropy: 3.76015
Value Function Loss: 0.04340

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.51218
Value Function Update Magnitude: 0.57783

Collected Steps per Second: 22,324.24701
Overall Steps per Second: 10,696.70164

Timestep Collection Time: 2.23972
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.67434

Cumulative Model Updates: 43,454
Cumulative Timesteps: 362,465,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,701.66040
Policy Entropy: 3.77524
Value Function Loss: 0.04316

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.60618

Collected Steps per Second: 22,977.93231
Overall Steps per Second: 10,856.58094

Timestep Collection Time: 2.17678
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.60716

Cumulative Model Updates: 43,460
Cumulative Timesteps: 362,515,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 362515182...
Checkpoint 362515182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,918.56173
Policy Entropy: 3.77447
Value Function Loss: 0.04130

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.60855

Collected Steps per Second: 22,535.81861
Overall Steps per Second: 10,693.07136

Timestep Collection Time: 2.21887
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.67630

Cumulative Model Updates: 43,466
Cumulative Timesteps: 362,565,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,196.84046
Policy Entropy: 3.77780
Value Function Loss: 0.04564

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.54087
Value Function Update Magnitude: 0.61230

Collected Steps per Second: 23,066.68911
Overall Steps per Second: 10,863.76157

Timestep Collection Time: 2.16850
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.60430

Cumulative Model Updates: 43,472
Cumulative Timesteps: 362,615,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 362615206...
Checkpoint 362615206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,271.65928
Policy Entropy: 3.79149
Value Function Loss: 0.04568

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.48348
Value Function Update Magnitude: 0.62245

Collected Steps per Second: 22,641.37214
Overall Steps per Second: 10,663.68605

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.48215
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.69200

Cumulative Model Updates: 43,478
Cumulative Timesteps: 362,665,240

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,114.06796
Policy Entropy: 3.79793
Value Function Loss: 0.04472

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.47732
Value Function Update Magnitude: 0.65860

Collected Steps per Second: 22,842.28465
Overall Steps per Second: 10,820.08612

Timestep Collection Time: 2.18954
Timestep Consumption Time: 2.43279
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.62233

Cumulative Model Updates: 43,484
Cumulative Timesteps: 362,715,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 362715254...
Checkpoint 362715254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,865.01591
Policy Entropy: 3.80065
Value Function Loss: 0.04232

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.50119
Value Function Update Magnitude: 0.70637

Collected Steps per Second: 22,395.92301
Overall Steps per Second: 10,723.03150

Timestep Collection Time: 2.23255
Timestep Consumption Time: 2.43031
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.66286

Cumulative Model Updates: 43,490
Cumulative Timesteps: 362,765,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,034.65383
Policy Entropy: 3.79766
Value Function Loss: 0.03987

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.52921
Value Function Update Magnitude: 0.72552

Collected Steps per Second: 22,781.24319
Overall Steps per Second: 10,821.73061

Timestep Collection Time: 2.19619
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.62329

Cumulative Model Updates: 43,496
Cumulative Timesteps: 362,815,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 362815286...
Checkpoint 362815286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,780.52046
Policy Entropy: 3.79728
Value Function Loss: 0.04006

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.55932
Value Function Update Magnitude: 0.73963

Collected Steps per Second: 22,613.77377
Overall Steps per Second: 10,733.35011

Timestep Collection Time: 2.21201
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.66043

Cumulative Model Updates: 43,502
Cumulative Timesteps: 362,865,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,164.26188
Policy Entropy: 3.79091
Value Function Loss: 0.04054

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.53268
Value Function Update Magnitude: 0.70233

Collected Steps per Second: 23,232.44189
Overall Steps per Second: 10,932.33916

Timestep Collection Time: 2.15294
Timestep Consumption Time: 2.42230
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.57523

Cumulative Model Updates: 43,508
Cumulative Timesteps: 362,915,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 362915326...
Checkpoint 362915326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,108.56629
Policy Entropy: 3.78612
Value Function Loss: 0.04294

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.45189
Value Function Update Magnitude: 0.61696

Collected Steps per Second: 22,109.23126
Overall Steps per Second: 10,670.47532

Timestep Collection Time: 2.26376
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.69051

Cumulative Model Updates: 43,514
Cumulative Timesteps: 362,965,376

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.91767
Policy Entropy: 3.78241
Value Function Loss: 0.04215

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.46512
Value Function Update Magnitude: 0.65165

Collected Steps per Second: 22,269.25815
Overall Steps per Second: 10,885.14962

Timestep Collection Time: 2.24642
Timestep Consumption Time: 2.34939
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.59580

Cumulative Model Updates: 43,520
Cumulative Timesteps: 363,015,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 363015402...
Checkpoint 363015402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,173.00701
Policy Entropy: 3.77981
Value Function Loss: 0.04294

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.45926
Value Function Update Magnitude: 0.63696

Collected Steps per Second: 21,880.72942
Overall Steps per Second: 10,607.32324

Timestep Collection Time: 2.28557
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.71467

Cumulative Model Updates: 43,526
Cumulative Timesteps: 363,065,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,942.22050
Policy Entropy: 3.78042
Value Function Loss: 0.04233

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.49018
Value Function Update Magnitude: 0.62902

Collected Steps per Second: 22,239.97838
Overall Steps per Second: 10,851.92724

Timestep Collection Time: 2.25036
Timestep Consumption Time: 2.36154
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61190

Cumulative Model Updates: 43,532
Cumulative Timesteps: 363,115,460

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 363115460...
Checkpoint 363115460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,143.65647
Policy Entropy: 3.77648
Value Function Loss: 0.04333

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.64522

Collected Steps per Second: 21,982.99860
Overall Steps per Second: 10,717.03693

Timestep Collection Time: 2.27658
Timestep Consumption Time: 2.39318
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.66976

Cumulative Model Updates: 43,538
Cumulative Timesteps: 363,165,506

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,887.18960
Policy Entropy: 3.77976
Value Function Loss: 0.04193

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.53045
Value Function Update Magnitude: 0.66878

Collected Steps per Second: 22,215.08933
Overall Steps per Second: 10,855.84160

Timestep Collection Time: 2.25216
Timestep Consumption Time: 2.35660
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.60876

Cumulative Model Updates: 43,544
Cumulative Timesteps: 363,215,538

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 363215538...
Checkpoint 363215538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,335.45471
Policy Entropy: 3.78603
Value Function Loss: 0.04257

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.51115
Value Function Update Magnitude: 0.67329

Collected Steps per Second: 21,864.10064
Overall Steps per Second: 10,658.45129

Timestep Collection Time: 2.28695
Timestep Consumption Time: 2.40436
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.69130

Cumulative Model Updates: 43,550
Cumulative Timesteps: 363,265,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,441.37891
Policy Entropy: 3.78965
Value Function Loss: 0.04134

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.49545
Value Function Update Magnitude: 0.71314

Collected Steps per Second: 23,094.63916
Overall Steps per Second: 10,914.13318

Timestep Collection Time: 2.16544
Timestep Consumption Time: 2.41669
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.58213

Cumulative Model Updates: 43,556
Cumulative Timesteps: 363,315,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 363315550...
Checkpoint 363315550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,958.50888
Policy Entropy: 3.78950
Value Function Loss: 0.04177

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.46230
Value Function Update Magnitude: 0.75340

Collected Steps per Second: 22,529.50499
Overall Steps per Second: 10,656.85358

Timestep Collection Time: 2.21984
Timestep Consumption Time: 2.47310
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.69294

Cumulative Model Updates: 43,562
Cumulative Timesteps: 363,365,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,869.20315
Policy Entropy: 3.78901
Value Function Loss: 0.04128

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.45594
Value Function Update Magnitude: 0.73902

Collected Steps per Second: 22,740.87792
Overall Steps per Second: 10,846.36199

Timestep Collection Time: 2.19886
Timestep Consumption Time: 2.41135
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61021

Cumulative Model Updates: 43,568
Cumulative Timesteps: 363,415,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 363415566...
Checkpoint 363415566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,595.08435
Policy Entropy: 3.78956
Value Function Loss: 0.04113

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.49688
Value Function Update Magnitude: 0.70127

Collected Steps per Second: 22,483.86802
Overall Steps per Second: 10,706.37035

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.44640
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.67030

Cumulative Model Updates: 43,574
Cumulative Timesteps: 363,465,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,981.61739
Policy Entropy: 3.78960
Value Function Loss: 0.04140

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07022
Policy Update Magnitude: 0.52595
Value Function Update Magnitude: 0.74827

Collected Steps per Second: 22,839.35288
Overall Steps per Second: 10,818.80821

Timestep Collection Time: 2.19025
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.62380

Cumulative Model Updates: 43,580
Cumulative Timesteps: 363,515,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 363515592...
Checkpoint 363515592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,112.52810
Policy Entropy: 3.77994
Value Function Loss: 0.04162

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06458
Policy Update Magnitude: 0.59476
Value Function Update Magnitude: 0.76745

Collected Steps per Second: 22,556.64707
Overall Steps per Second: 10,750.04898

Timestep Collection Time: 2.21664
Timestep Consumption Time: 2.43450
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.65114

Cumulative Model Updates: 43,586
Cumulative Timesteps: 363,565,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,789.94649
Policy Entropy: 3.76804
Value Function Loss: 0.04349

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.60803
Value Function Update Magnitude: 0.76965

Collected Steps per Second: 22,997.95009
Overall Steps per Second: 10,829.55467

Timestep Collection Time: 2.17463
Timestep Consumption Time: 2.44347
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.61810

Cumulative Model Updates: 43,592
Cumulative Timesteps: 363,615,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 363615604...
Checkpoint 363615604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,125.86326
Policy Entropy: 3.76738
Value Function Loss: 0.04394

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.58737
Value Function Update Magnitude: 0.78949

Collected Steps per Second: 22,566.70532
Overall Steps per Second: 10,692.37934

Timestep Collection Time: 2.21627
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.67754

Cumulative Model Updates: 43,598
Cumulative Timesteps: 363,665,618

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,486.38394
Policy Entropy: 3.75611
Value Function Loss: 0.04201

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.54500
Value Function Update Magnitude: 0.78796

Collected Steps per Second: 22,717.27310
Overall Steps per Second: 10,798.38439

Timestep Collection Time: 2.20167
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.63180

Cumulative Model Updates: 43,604
Cumulative Timesteps: 363,715,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 363715634...
Checkpoint 363715634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,978.30625
Policy Entropy: 3.75877
Value Function Loss: 0.04076

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.51037
Value Function Update Magnitude: 0.78937

Collected Steps per Second: 22,452.70793
Overall Steps per Second: 10,795.11950

Timestep Collection Time: 2.22833
Timestep Consumption Time: 2.40636
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.63469

Cumulative Model Updates: 43,610
Cumulative Timesteps: 363,765,666

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,444.73004
Policy Entropy: 3.74820
Value Function Loss: 0.04077

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.52341
Value Function Update Magnitude: 0.77263

Collected Steps per Second: 22,917.79648
Overall Steps per Second: 10,918.78972

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.39822
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.58054

Cumulative Model Updates: 43,616
Cumulative Timesteps: 363,815,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 363815680...
Checkpoint 363815680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,923.43553
Policy Entropy: 3.74932
Value Function Loss: 0.04231

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.50724
Value Function Update Magnitude: 0.77106

Collected Steps per Second: 22,708.17866
Overall Steps per Second: 10,636.46348

Timestep Collection Time: 2.20273
Timestep Consumption Time: 2.49996
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.70269

Cumulative Model Updates: 43,622
Cumulative Timesteps: 363,865,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,959.90781
Policy Entropy: 3.75280
Value Function Loss: 0.04362

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.50391
Value Function Update Magnitude: 0.80428

Collected Steps per Second: 22,865.87769
Overall Steps per Second: 10,841.10346

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.61577

Cumulative Model Updates: 43,628
Cumulative Timesteps: 363,915,740

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 363915740...
Checkpoint 363915740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,978.70590
Policy Entropy: 3.76351
Value Function Loss: 0.04261

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07114
Policy Update Magnitude: 0.50322
Value Function Update Magnitude: 0.80796

Collected Steps per Second: 22,348.74868
Overall Steps per Second: 10,630.49666

Timestep Collection Time: 2.23843
Timestep Consumption Time: 2.46747
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.70589

Cumulative Model Updates: 43,634
Cumulative Timesteps: 363,965,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,319.01272
Policy Entropy: 3.77142
Value Function Loss: 0.04203

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.49286
Value Function Update Magnitude: 0.78223

Collected Steps per Second: 22,729.79160
Overall Steps per Second: 10,654.59805

Timestep Collection Time: 2.19976
Timestep Consumption Time: 2.49305
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.69281

Cumulative Model Updates: 43,640
Cumulative Timesteps: 364,015,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 364015766...
Checkpoint 364015766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,411.38876
Policy Entropy: 3.76571
Value Function Loss: 0.04058

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.46687
Value Function Update Magnitude: 0.77276

Collected Steps per Second: 22,707.71266
Overall Steps per Second: 10,663.27593

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.48769
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.69012

Cumulative Model Updates: 43,646
Cumulative Timesteps: 364,065,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,275.71737
Policy Entropy: 3.76105
Value Function Loss: 0.04065

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.48102
Value Function Update Magnitude: 0.75661

Collected Steps per Second: 22,918.29672
Overall Steps per Second: 10,718.43677

Timestep Collection Time: 2.18245
Timestep Consumption Time: 2.48409
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.66654

Cumulative Model Updates: 43,652
Cumulative Timesteps: 364,115,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 364115796...
Checkpoint 364115796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,410.91394
Policy Entropy: 3.77118
Value Function Loss: 0.04024

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.46118
Value Function Update Magnitude: 0.74563

Collected Steps per Second: 22,896.06427
Overall Steps per Second: 10,650.25796

Timestep Collection Time: 2.18509
Timestep Consumption Time: 2.51245
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.69754

Cumulative Model Updates: 43,658
Cumulative Timesteps: 364,165,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,543.49263
Policy Entropy: 3.78086
Value Function Loss: 0.03989

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.45115
Value Function Update Magnitude: 0.72639

Collected Steps per Second: 22,829.55879
Overall Steps per Second: 10,819.96021

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62201

Cumulative Model Updates: 43,664
Cumulative Timesteps: 364,215,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 364215836...
Checkpoint 364215836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,059.66589
Policy Entropy: 3.78891
Value Function Loss: 0.03903

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.48239
Value Function Update Magnitude: 0.71970

Collected Steps per Second: 22,282.00534
Overall Steps per Second: 10,662.16570

Timestep Collection Time: 2.24396
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.68948

Cumulative Model Updates: 43,670
Cumulative Timesteps: 364,265,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,182.77750
Policy Entropy: 3.77363
Value Function Loss: 0.04008

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06128
Policy Update Magnitude: 0.52485
Value Function Update Magnitude: 0.69207

Collected Steps per Second: 22,418.45844
Overall Steps per Second: 10,561.21756

Timestep Collection Time: 2.23102
Timestep Consumption Time: 2.50480
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.73582

Cumulative Model Updates: 43,676
Cumulative Timesteps: 364,315,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 364315852...
Checkpoint 364315852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,698.16959
Policy Entropy: 3.77969
Value Function Loss: 0.04022

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06091
Policy Update Magnitude: 0.58479
Value Function Update Magnitude: 0.66442

Collected Steps per Second: 22,630.05711
Overall Steps per Second: 10,594.71204

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.51079
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.72103

Cumulative Model Updates: 43,682
Cumulative Timesteps: 364,365,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,251.26612
Policy Entropy: 3.77939
Value Function Loss: 0.04099

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05734
Policy Update Magnitude: 0.61658
Value Function Update Magnitude: 0.61006

Collected Steps per Second: 22,561.70286
Overall Steps per Second: 10,610.03568

Timestep Collection Time: 2.21677
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.71384

Cumulative Model Updates: 43,688
Cumulative Timesteps: 364,415,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 364415884...
Checkpoint 364415884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,209.54550
Policy Entropy: 3.76721
Value Function Loss: 0.04257

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05732
Policy Update Magnitude: 0.62457
Value Function Update Magnitude: 0.59143

Collected Steps per Second: 22,623.40903
Overall Steps per Second: 10,668.69999

Timestep Collection Time: 2.21090
Timestep Consumption Time: 2.47740
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.68829

Cumulative Model Updates: 43,694
Cumulative Timesteps: 364,465,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,060.52083
Policy Entropy: 3.75696
Value Function Loss: 0.04258

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.60436
Value Function Update Magnitude: 0.63700

Collected Steps per Second: 23,011.02364
Overall Steps per Second: 10,659.33276

Timestep Collection Time: 2.17339
Timestep Consumption Time: 2.51846
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.69185

Cumulative Model Updates: 43,700
Cumulative Timesteps: 364,515,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 364515914...
Checkpoint 364515914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,031.57865
Policy Entropy: 3.75942
Value Function Loss: 0.04347

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.49905
Value Function Update Magnitude: 0.72661

Collected Steps per Second: 22,430.35150
Overall Steps per Second: 10,668.25889

Timestep Collection Time: 2.22975
Timestep Consumption Time: 2.45837
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.68811

Cumulative Model Updates: 43,706
Cumulative Timesteps: 364,565,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,752.08183
Policy Entropy: 3.75746
Value Function Loss: 0.04455

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.46920
Value Function Update Magnitude: 0.74808

Collected Steps per Second: 23,002.08631
Overall Steps per Second: 10,860.34910

Timestep Collection Time: 2.17485
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.60630

Cumulative Model Updates: 43,712
Cumulative Timesteps: 364,615,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 364615954...
Checkpoint 364615954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.72973
Policy Entropy: 3.76360
Value Function Loss: 0.04563

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.49162
Value Function Update Magnitude: 0.71655

Collected Steps per Second: 22,603.99934
Overall Steps per Second: 10,691.86845

Timestep Collection Time: 2.21306
Timestep Consumption Time: 2.46564
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.67870

Cumulative Model Updates: 43,718
Cumulative Timesteps: 364,665,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,611.90097
Policy Entropy: 3.75864
Value Function Loss: 0.04583

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.49789
Value Function Update Magnitude: 0.76080

Collected Steps per Second: 22,813.55151
Overall Steps per Second: 10,789.19184

Timestep Collection Time: 2.19168
Timestep Consumption Time: 2.44259
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.63427

Cumulative Model Updates: 43,724
Cumulative Timesteps: 364,715,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 364715978...
Checkpoint 364715978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,903.04643
Policy Entropy: 3.74779
Value Function Loss: 0.04600

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.49616
Value Function Update Magnitude: 0.73922

Collected Steps per Second: 22,710.50045
Overall Steps per Second: 10,794.50570

Timestep Collection Time: 2.20277
Timestep Consumption Time: 2.43163
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.63439

Cumulative Model Updates: 43,730
Cumulative Timesteps: 364,766,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,625.36660
Policy Entropy: 3.73744
Value Function Loss: 0.04644

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.47571
Value Function Update Magnitude: 0.64033

Collected Steps per Second: 22,929.07701
Overall Steps per Second: 10,828.98287

Timestep Collection Time: 2.18072
Timestep Consumption Time: 2.43670
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61742

Cumulative Model Updates: 43,736
Cumulative Timesteps: 364,816,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 364816006...
Checkpoint 364816006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,772.92707
Policy Entropy: 3.73966
Value Function Loss: 0.04669

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.49480
Value Function Update Magnitude: 0.62370

Collected Steps per Second: 22,454.05866
Overall Steps per Second: 10,683.55030

Timestep Collection Time: 2.22775
Timestep Consumption Time: 2.45440
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.68215

Cumulative Model Updates: 43,742
Cumulative Timesteps: 364,866,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,367.74276
Policy Entropy: 3.75032
Value Function Loss: 0.04744

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07238
Policy Update Magnitude: 0.59255
Value Function Update Magnitude: 0.61072

Collected Steps per Second: 23,000.36470
Overall Steps per Second: 10,875.86022

Timestep Collection Time: 2.17518
Timestep Consumption Time: 2.42491
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.60010

Cumulative Model Updates: 43,748
Cumulative Timesteps: 364,916,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 364916058...
Checkpoint 364916058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,526.24492
Policy Entropy: 3.75607
Value Function Loss: 0.04771

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06048
Policy Update Magnitude: 0.64431
Value Function Update Magnitude: 0.60985

Collected Steps per Second: 22,494.71044
Overall Steps per Second: 10,651.27682

Timestep Collection Time: 2.22301
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.69484

Cumulative Model Updates: 43,754
Cumulative Timesteps: 364,966,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,718.95809
Policy Entropy: 3.74807
Value Function Loss: 0.04924

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.62416
Value Function Update Magnitude: 0.62181

Collected Steps per Second: 23,134.46680
Overall Steps per Second: 10,958.59175

Timestep Collection Time: 2.16214
Timestep Consumption Time: 2.40231
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.56446

Cumulative Model Updates: 43,760
Cumulative Timesteps: 365,016,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 365016084...
Checkpoint 365016084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,404.83847
Policy Entropy: 3.73454
Value Function Loss: 0.05036

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.51940
Value Function Update Magnitude: 0.62123

Collected Steps per Second: 22,434.23821
Overall Steps per Second: 10,599.15064

Timestep Collection Time: 2.22918
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.71830

Cumulative Model Updates: 43,766
Cumulative Timesteps: 365,066,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,017.16178
Policy Entropy: 3.72234
Value Function Loss: 0.05199

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.51715
Value Function Update Magnitude: 0.58444

Collected Steps per Second: 22,978.07332
Overall Steps per Second: 10,832.38637

Timestep Collection Time: 2.17712
Timestep Consumption Time: 2.44107
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61819

Cumulative Model Updates: 43,772
Cumulative Timesteps: 365,116,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 365116120...
Checkpoint 365116120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,411.72279
Policy Entropy: 3.73336
Value Function Loss: 0.04980

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.44765
Value Function Update Magnitude: 0.60639

Collected Steps per Second: 22,322.29950
Overall Steps per Second: 10,726.78920

Timestep Collection Time: 2.24000
Timestep Consumption Time: 2.42141
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.66141

Cumulative Model Updates: 43,778
Cumulative Timesteps: 365,166,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,417.86595
Policy Entropy: 3.72922
Value Function Loss: 0.04875

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.43738
Value Function Update Magnitude: 0.64562

Collected Steps per Second: 22,835.69170
Overall Steps per Second: 10,820.35693

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.43175
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.62166

Cumulative Model Updates: 43,784
Cumulative Timesteps: 365,216,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 365216130...
Checkpoint 365216130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,814.99888
Policy Entropy: 3.73338
Value Function Loss: 0.04645

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.48062
Value Function Update Magnitude: 0.63174

Collected Steps per Second: 22,473.35649
Overall Steps per Second: 10,757.94869

Timestep Collection Time: 2.22486
Timestep Consumption Time: 2.42287
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.64773

Cumulative Model Updates: 43,790
Cumulative Timesteps: 365,266,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,155.13934
Policy Entropy: 3.73648
Value Function Loss: 0.04870

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.47852
Value Function Update Magnitude: 0.63189

Collected Steps per Second: 22,722.33923
Overall Steps per Second: 10,756.83221

Timestep Collection Time: 2.20109
Timestep Consumption Time: 2.44842
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.64951

Cumulative Model Updates: 43,796
Cumulative Timesteps: 365,316,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 365316144...
Checkpoint 365316144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,835.79017
Policy Entropy: 3.73828
Value Function Loss: 0.04955

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.51173
Value Function Update Magnitude: 0.65212

Collected Steps per Second: 22,588.27762
Overall Steps per Second: 10,768.98816

Timestep Collection Time: 2.21478
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.64556

Cumulative Model Updates: 43,802
Cumulative Timesteps: 365,366,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,276.83945
Policy Entropy: 3.75174
Value Function Loss: 0.04890

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.50540
Value Function Update Magnitude: 0.62001

Collected Steps per Second: 22,904.28012
Overall Steps per Second: 10,893.16719

Timestep Collection Time: 2.18387
Timestep Consumption Time: 2.40800
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.59187

Cumulative Model Updates: 43,808
Cumulative Timesteps: 365,416,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 365416192...
Checkpoint 365416192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,145.49820
Policy Entropy: 3.74913
Value Function Loss: 0.04675

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.51123
Value Function Update Magnitude: 0.68128

Collected Steps per Second: 22,571.80983
Overall Steps per Second: 10,641.36286

Timestep Collection Time: 2.21577
Timestep Consumption Time: 2.48419
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.69996

Cumulative Model Updates: 43,814
Cumulative Timesteps: 365,466,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,300.02363
Policy Entropy: 3.73709
Value Function Loss: 0.04560

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.53319
Value Function Update Magnitude: 0.69735

Collected Steps per Second: 22,915.82388
Overall Steps per Second: 10,810.90898

Timestep Collection Time: 2.18199
Timestep Consumption Time: 2.44316
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.62514

Cumulative Model Updates: 43,820
Cumulative Timesteps: 365,516,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 365516208...
Checkpoint 365516208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.37803
Policy Entropy: 3.74527
Value Function Loss: 0.04800

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.54142
Value Function Update Magnitude: 0.62414

Collected Steps per Second: 22,667.91138
Overall Steps per Second: 10,717.09786

Timestep Collection Time: 2.20656
Timestep Consumption Time: 2.46057
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.66712

Cumulative Model Updates: 43,826
Cumulative Timesteps: 365,566,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.42637
Policy Entropy: 3.74023
Value Function Loss: 0.04643

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06156
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.68821

Collected Steps per Second: 22,751.54447
Overall Steps per Second: 10,820.68208

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.62374

Cumulative Model Updates: 43,832
Cumulative Timesteps: 365,616,258

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 365616258...
Checkpoint 365616258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,458.57806
Policy Entropy: 3.73570
Value Function Loss: 0.04510

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07270
Policy Update Magnitude: 0.60274
Value Function Update Magnitude: 0.65970

Collected Steps per Second: 22,624.06505
Overall Steps per Second: 10,789.20245

Timestep Collection Time: 2.21136
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.63704

Cumulative Model Updates: 43,838
Cumulative Timesteps: 365,666,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,062.73153
Policy Entropy: 3.72723
Value Function Loss: 0.04399

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.57268
Value Function Update Magnitude: 0.67087

Collected Steps per Second: 22,407.10805
Overall Steps per Second: 10,574.46911

Timestep Collection Time: 2.23179
Timestep Consumption Time: 2.49733
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.72913

Cumulative Model Updates: 43,844
Cumulative Timesteps: 365,716,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 365716296...
Checkpoint 365716296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.43050
Policy Entropy: 3.73953
Value Function Loss: 0.04318

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.69565

Collected Steps per Second: 22,899.56069
Overall Steps per Second: 10,815.19418

Timestep Collection Time: 2.18345
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.62313

Cumulative Model Updates: 43,850
Cumulative Timesteps: 365,766,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,540.04898
Policy Entropy: 3.73977
Value Function Loss: 0.04423

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.50422
Value Function Update Magnitude: 0.61780

Collected Steps per Second: 22,639.04587
Overall Steps per Second: 10,605.48403

Timestep Collection Time: 2.20910
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.71567

Cumulative Model Updates: 43,856
Cumulative Timesteps: 365,816,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 365816308...
Checkpoint 365816308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,249.41720
Policy Entropy: 3.73760
Value Function Loss: 0.04414

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.48986
Value Function Update Magnitude: 0.56112

Collected Steps per Second: 22,370.60632
Overall Steps per Second: 10,599.07105

Timestep Collection Time: 2.23615
Timestep Consumption Time: 2.48351
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.71966

Cumulative Model Updates: 43,862
Cumulative Timesteps: 365,866,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,485.03037
Policy Entropy: 3.74425
Value Function Loss: 0.04673

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.47295
Value Function Update Magnitude: 0.57639

Collected Steps per Second: 22,805.82282
Overall Steps per Second: 10,806.71994

Timestep Collection Time: 2.19356
Timestep Consumption Time: 2.43559
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.62916

Cumulative Model Updates: 43,868
Cumulative Timesteps: 365,916,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 365916358...
Checkpoint 365916358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,394.27811
Policy Entropy: 3.74491
Value Function Loss: 0.04650

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.52356
Value Function Update Magnitude: 0.53499

Collected Steps per Second: 22,367.15912
Overall Steps per Second: 10,701.71367

Timestep Collection Time: 2.23685
Timestep Consumption Time: 2.43829
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.67514

Cumulative Model Updates: 43,874
Cumulative Timesteps: 365,966,390

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,784.59770
Policy Entropy: 3.74158
Value Function Loss: 0.04599

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.49764
Value Function Update Magnitude: 0.62575

Collected Steps per Second: 22,800.16875
Overall Steps per Second: 10,578.13681

Timestep Collection Time: 2.19332
Timestep Consumption Time: 2.53417
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.72749

Cumulative Model Updates: 43,880
Cumulative Timesteps: 366,016,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 366016398...
Checkpoint 366016398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,716.59080
Policy Entropy: 3.74485
Value Function Loss: 0.04571

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.47237
Value Function Update Magnitude: 0.64495

Collected Steps per Second: 22,662.16462
Overall Steps per Second: 10,620.58778

Timestep Collection Time: 2.20720
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.70972

Cumulative Model Updates: 43,886
Cumulative Timesteps: 366,066,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,781.00164
Policy Entropy: 3.75793
Value Function Loss: 0.04547

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.53893
Value Function Update Magnitude: 0.63384

Collected Steps per Second: 23,060.25815
Overall Steps per Second: 10,871.79570

Timestep Collection Time: 2.16927
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.60126

Cumulative Model Updates: 43,892
Cumulative Timesteps: 366,116,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 366116442...
Checkpoint 366116442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,351.87783
Policy Entropy: 3.76136
Value Function Loss: 0.04708

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.60102
Value Function Update Magnitude: 0.63548

Collected Steps per Second: 22,891.54240
Overall Steps per Second: 10,662.85595

Timestep Collection Time: 2.18561
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.69218

Cumulative Model Updates: 43,898
Cumulative Timesteps: 366,166,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,911.61309
Policy Entropy: 3.77553
Value Function Loss: 0.04553

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.50618
Value Function Update Magnitude: 0.67809

Collected Steps per Second: 22,674.18222
Overall Steps per Second: 10,761.44903

Timestep Collection Time: 2.20524
Timestep Consumption Time: 2.44116
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.64640

Cumulative Model Updates: 43,904
Cumulative Timesteps: 366,216,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 366216476...
Checkpoint 366216476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.11564
Policy Entropy: 3.77085
Value Function Loss: 0.04611

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.47011
Value Function Update Magnitude: 0.62868

Collected Steps per Second: 22,387.59383
Overall Steps per Second: 10,702.45458

Timestep Collection Time: 2.23463
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.67444

Cumulative Model Updates: 43,910
Cumulative Timesteps: 366,266,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,924.35825
Policy Entropy: 3.76023
Value Function Loss: 0.04416

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.44914
Value Function Update Magnitude: 0.56201

Collected Steps per Second: 22,816.97520
Overall Steps per Second: 10,687.35011

Timestep Collection Time: 2.19161
Timestep Consumption Time: 2.48738
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.67899

Cumulative Model Updates: 43,916
Cumulative Timesteps: 366,316,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 366316510...
Checkpoint 366316510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,935.44672
Policy Entropy: 3.75138
Value Function Loss: 0.04449

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.42371
Value Function Update Magnitude: 0.57183

Collected Steps per Second: 22,664.75112
Overall Steps per Second: 10,793.88309

Timestep Collection Time: 2.20651
Timestep Consumption Time: 2.42667
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.63318

Cumulative Model Updates: 43,922
Cumulative Timesteps: 366,366,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,263.08336
Policy Entropy: 3.75274
Value Function Loss: 0.04418

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.43286
Value Function Update Magnitude: 0.65183

Collected Steps per Second: 22,721.84215
Overall Steps per Second: 10,634.02742

Timestep Collection Time: 2.20176
Timestep Consumption Time: 2.50276
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.70452

Cumulative Model Updates: 43,928
Cumulative Timesteps: 366,416,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 366416548...
Checkpoint 366416548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.57801
Policy Entropy: 3.75006
Value Function Loss: 0.04342

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.47788
Value Function Update Magnitude: 0.74758

Collected Steps per Second: 22,509.68192
Overall Steps per Second: 10,562.69452

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.73516

Cumulative Model Updates: 43,934
Cumulative Timesteps: 366,466,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,358.90387
Policy Entropy: 3.76359
Value Function Loss: 0.04209

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.49902
Value Function Update Magnitude: 0.79700

Collected Steps per Second: 22,602.19966
Overall Steps per Second: 10,656.34215

Timestep Collection Time: 2.21332
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.69448

Cumulative Model Updates: 43,940
Cumulative Timesteps: 366,516,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 366516590...
Checkpoint 366516590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,058.99956
Policy Entropy: 3.75701
Value Function Loss: 0.04165

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.81173

Collected Steps per Second: 22,479.20521
Overall Steps per Second: 10,751.25635

Timestep Collection Time: 2.22437
Timestep Consumption Time: 2.42644
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.65081

Cumulative Model Updates: 43,946
Cumulative Timesteps: 366,566,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,902.31816
Policy Entropy: 3.76361
Value Function Loss: 0.04065

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.57859
Value Function Update Magnitude: 0.81528

Collected Steps per Second: 23,034.73197
Overall Steps per Second: 10,736.98605

Timestep Collection Time: 2.17098
Timestep Consumption Time: 2.48656
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.65755

Cumulative Model Updates: 43,952
Cumulative Timesteps: 366,616,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 366616600...
Checkpoint 366616600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,266.41646
Policy Entropy: 3.75519
Value Function Loss: 0.04095

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.55865
Value Function Update Magnitude: 0.82110

Collected Steps per Second: 22,232.40715
Overall Steps per Second: 10,531.40210

Timestep Collection Time: 2.25104
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.75207

Cumulative Model Updates: 43,958
Cumulative Timesteps: 366,666,646

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,424.00046
Policy Entropy: 3.76285
Value Function Loss: 0.04056

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.81046

Collected Steps per Second: 22,813.77354
Overall Steps per Second: 10,788.14593

Timestep Collection Time: 2.19236
Timestep Consumption Time: 2.44384
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.63620

Cumulative Model Updates: 43,964
Cumulative Timesteps: 366,716,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 366716662...
Checkpoint 366716662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,267.82058
Policy Entropy: 3.76497
Value Function Loss: 0.04017

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06913
Policy Update Magnitude: 0.57887
Value Function Update Magnitude: 0.80794

Collected Steps per Second: 22,383.47990
Overall Steps per Second: 10,721.27727

Timestep Collection Time: 2.23451
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.66512

Cumulative Model Updates: 43,970
Cumulative Timesteps: 366,766,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,844.35069
Policy Entropy: 3.76111
Value Function Loss: 0.04202

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.53472
Value Function Update Magnitude: 0.75336

Collected Steps per Second: 22,887.34772
Overall Steps per Second: 10,822.38410

Timestep Collection Time: 2.18470
Timestep Consumption Time: 2.43554
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.62024

Cumulative Model Updates: 43,976
Cumulative Timesteps: 366,816,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 366816680...
Checkpoint 366816680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,664.83078
Policy Entropy: 3.76908
Value Function Loss: 0.04325

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.49055
Value Function Update Magnitude: 0.65271

Collected Steps per Second: 22,167.30452
Overall Steps per Second: 10,661.89936

Timestep Collection Time: 2.25639
Timestep Consumption Time: 2.43490
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.69128

Cumulative Model Updates: 43,982
Cumulative Timesteps: 366,866,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,873.56156
Policy Entropy: 3.75864
Value Function Loss: 0.04397

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.55175
Value Function Update Magnitude: 0.67278

Collected Steps per Second: 22,722.81535
Overall Steps per Second: 10,639.14016

Timestep Collection Time: 2.20166
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.70226

Cumulative Model Updates: 43,988
Cumulative Timesteps: 366,916,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 366916726...
Checkpoint 366916726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,299.03084
Policy Entropy: 3.75008
Value Function Loss: 0.04277

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06997
Policy Update Magnitude: 0.58394
Value Function Update Magnitude: 0.75639

Collected Steps per Second: 22,694.14281
Overall Steps per Second: 10,667.95316

Timestep Collection Time: 2.20365
Timestep Consumption Time: 2.48422
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.68787

Cumulative Model Updates: 43,994
Cumulative Timesteps: 366,966,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,733.64479
Policy Entropy: 3.73531
Value Function Loss: 0.04373

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.76991

Collected Steps per Second: 23,039.68253
Overall Steps per Second: 10,742.78873

Timestep Collection Time: 2.17156
Timestep Consumption Time: 2.48571
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.65726

Cumulative Model Updates: 44,000
Cumulative Timesteps: 367,016,768

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 367016768...
Checkpoint 367016768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,443.15861
Policy Entropy: 3.73826
Value Function Loss: 0.04297

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.75104

Collected Steps per Second: 22,559.75263
Overall Steps per Second: 10,638.64244

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.48470
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.70210

Cumulative Model Updates: 44,006
Cumulative Timesteps: 367,066,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,305.92975
Policy Entropy: 3.73366
Value Function Loss: 0.04461

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.51366
Value Function Update Magnitude: 0.67141

Collected Steps per Second: 22,462.21451
Overall Steps per Second: 10,603.39768

Timestep Collection Time: 2.22712
Timestep Consumption Time: 2.49080
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.71792

Cumulative Model Updates: 44,012
Cumulative Timesteps: 367,116,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 367116818...
Checkpoint 367116818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,989.54207
Policy Entropy: 3.73502
Value Function Loss: 0.04441

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09307
Policy Update Magnitude: 0.47035
Value Function Update Magnitude: 0.62525

Collected Steps per Second: 22,823.99505
Overall Steps per Second: 10,819.10239

Timestep Collection Time: 2.19147
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62312

Cumulative Model Updates: 44,018
Cumulative Timesteps: 367,166,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,380.35143
Policy Entropy: 3.74250
Value Function Loss: 0.04545

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.44923
Value Function Update Magnitude: 0.63312

Collected Steps per Second: 22,706.00388
Overall Steps per Second: 10,608.19543

Timestep Collection Time: 2.20232
Timestep Consumption Time: 2.51158
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.71390

Cumulative Model Updates: 44,024
Cumulative Timesteps: 367,216,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 367216842...
Checkpoint 367216842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,703.96791
Policy Entropy: 3.74515
Value Function Loss: 0.04461

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.45112
Value Function Update Magnitude: 0.64772

Collected Steps per Second: 22,469.69344
Overall Steps per Second: 10,574.40462

Timestep Collection Time: 2.22522
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.72840

Cumulative Model Updates: 44,030
Cumulative Timesteps: 367,266,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,412.05087
Policy Entropy: 3.74976
Value Function Loss: 0.04339

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07637
Policy Update Magnitude: 0.49386
Value Function Update Magnitude: 0.66624

Collected Steps per Second: 22,422.08862
Overall Steps per Second: 10,560.45569

Timestep Collection Time: 2.23039
Timestep Consumption Time: 2.50520
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.73559

Cumulative Model Updates: 44,036
Cumulative Timesteps: 367,316,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 367316852...
Checkpoint 367316852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,616.95123
Policy Entropy: 3.74999
Value Function Loss: 0.04349

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.55819
Value Function Update Magnitude: 0.66270

Collected Steps per Second: 22,669.89116
Overall Steps per Second: 10,637.42252

Timestep Collection Time: 2.20636
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.70208

Cumulative Model Updates: 44,042
Cumulative Timesteps: 367,366,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,359.22537
Policy Entropy: 3.75140
Value Function Loss: 0.04519

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.57061
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 22,685.10683
Overall Steps per Second: 10,779.17916

Timestep Collection Time: 2.20444
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.63931

Cumulative Model Updates: 44,048
Cumulative Timesteps: 367,416,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 367416878...
Checkpoint 367416878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,741.53985
Policy Entropy: 3.74449
Value Function Loss: 0.04844

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.14988
Policy Update Magnitude: 0.51205
Value Function Update Magnitude: 0.59451

Collected Steps per Second: 22,145.72780
Overall Steps per Second: 10,656.55283

Timestep Collection Time: 2.25849
Timestep Consumption Time: 2.43496
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.69345

Cumulative Model Updates: 44,054
Cumulative Timesteps: 367,466,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,624.45358
Policy Entropy: 3.73398
Value Function Loss: 0.05146

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.44111
Value Function Update Magnitude: 0.58744

Collected Steps per Second: 22,357.19909
Overall Steps per Second: 10,526.99284

Timestep Collection Time: 2.23642
Timestep Consumption Time: 2.51328
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.74969

Cumulative Model Updates: 44,060
Cumulative Timesteps: 367,516,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 367516894...
Checkpoint 367516894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,818.01671
Policy Entropy: 3.74107
Value Function Loss: 0.04713

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.45561
Value Function Update Magnitude: 0.60012

Collected Steps per Second: 22,338.59712
Overall Steps per Second: 10,564.14552

Timestep Collection Time: 2.23935
Timestep Consumption Time: 2.49591
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.73526

Cumulative Model Updates: 44,066
Cumulative Timesteps: 367,566,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,450.77084
Policy Entropy: 3.75537
Value Function Loss: 0.04415

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.44218
Value Function Update Magnitude: 0.59268

Collected Steps per Second: 22,780.23333
Overall Steps per Second: 10,704.58534

Timestep Collection Time: 2.19550
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.67220

Cumulative Model Updates: 44,072
Cumulative Timesteps: 367,616,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 367616932...
Checkpoint 367616932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,853.01088
Policy Entropy: 3.77631
Value Function Loss: 0.04077

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.43504
Value Function Update Magnitude: 0.61374

Collected Steps per Second: 22,118.42013
Overall Steps per Second: 10,543.67202

Timestep Collection Time: 2.26264
Timestep Consumption Time: 2.48390
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.74654

Cumulative Model Updates: 44,078
Cumulative Timesteps: 367,666,978

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415.30098
Policy Entropy: 3.77918
Value Function Loss: 0.04059

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.43736
Value Function Update Magnitude: 0.71568

Collected Steps per Second: 22,881.66167
Overall Steps per Second: 10,796.29918

Timestep Collection Time: 2.18533
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.63159

Cumulative Model Updates: 44,084
Cumulative Timesteps: 367,716,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 367716982...
Checkpoint 367716982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.09031
Policy Entropy: 3.78985
Value Function Loss: 0.03972

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.51612
Value Function Update Magnitude: 0.72194

Collected Steps per Second: 22,259.30524
Overall Steps per Second: 10,591.82814

Timestep Collection Time: 2.24697
Timestep Consumption Time: 2.47516
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.72213

Cumulative Model Updates: 44,090
Cumulative Timesteps: 367,766,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,127.56803
Policy Entropy: 3.79044
Value Function Loss: 0.03980

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.76323

Collected Steps per Second: 22,795.26570
Overall Steps per Second: 10,685.83716

Timestep Collection Time: 2.19388
Timestep Consumption Time: 2.48615
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.68003

Cumulative Model Updates: 44,096
Cumulative Timesteps: 367,817,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 367817008...
Checkpoint 367817008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,339.05096
Policy Entropy: 3.80088
Value Function Loss: 0.03850

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.50926
Value Function Update Magnitude: 0.79193

Collected Steps per Second: 22,722.22092
Overall Steps per Second: 10,817.80139

Timestep Collection Time: 2.20128
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62368

Cumulative Model Updates: 44,102
Cumulative Timesteps: 367,867,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.00109
Policy Entropy: 3.79849
Value Function Loss: 0.03666

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06912
Policy Update Magnitude: 0.51386
Value Function Update Magnitude: 0.79918

Collected Steps per Second: 22,967.28633
Overall Steps per Second: 10,869.45302

Timestep Collection Time: 2.17779
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60170

Cumulative Model Updates: 44,108
Cumulative Timesteps: 367,917,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 367917044...
Checkpoint 367917044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,336.04068
Policy Entropy: 3.80035
Value Function Loss: 0.03645

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.80616

Collected Steps per Second: 22,478.02873
Overall Steps per Second: 10,761.49915

Timestep Collection Time: 2.22493
Timestep Consumption Time: 2.42238
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.64731

Cumulative Model Updates: 44,114
Cumulative Timesteps: 367,967,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,913.36724
Policy Entropy: 3.79437
Value Function Loss: 0.03694

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06451
Policy Update Magnitude: 0.58761
Value Function Update Magnitude: 0.82405

Collected Steps per Second: 23,305.40416
Overall Steps per Second: 10,951.80013

Timestep Collection Time: 2.14774
Timestep Consumption Time: 2.42265
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.57039

Cumulative Model Updates: 44,120
Cumulative Timesteps: 368,017,110

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 368017110...
Checkpoint 368017110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,936.39056
Policy Entropy: 3.77652
Value Function Loss: 0.04022

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06337
Policy Update Magnitude: 0.59936
Value Function Update Magnitude: 0.81306

Collected Steps per Second: 22,526.29945
Overall Steps per Second: 10,573.17386

Timestep Collection Time: 2.22069
Timestep Consumption Time: 2.51053
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.73122

Cumulative Model Updates: 44,126
Cumulative Timesteps: 368,067,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.83900
Policy Entropy: 3.76411
Value Function Loss: 0.04139

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05024
Policy Update Magnitude: 0.60795
Value Function Update Magnitude: 0.81919

Collected Steps per Second: 22,826.80416
Overall Steps per Second: 10,820.57522

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62120

Cumulative Model Updates: 44,132
Cumulative Timesteps: 368,117,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 368117138...
Checkpoint 368117138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,721.13747
Policy Entropy: 3.74398
Value Function Loss: 0.04164

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.55998
Value Function Update Magnitude: 0.81822

Collected Steps per Second: 22,532.39240
Overall Steps per Second: 10,718.06515

Timestep Collection Time: 2.21965
Timestep Consumption Time: 2.44668
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.66633

Cumulative Model Updates: 44,138
Cumulative Timesteps: 368,167,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,350.23660
Policy Entropy: 3.75009
Value Function Loss: 0.04143

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.45878
Value Function Update Magnitude: 0.81883

Collected Steps per Second: 22,953.19729
Overall Steps per Second: 10,862.27782

Timestep Collection Time: 2.17948
Timestep Consumption Time: 2.42600
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.60548

Cumulative Model Updates: 44,144
Cumulative Timesteps: 368,217,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 368217178...
Checkpoint 368217178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,250.34419
Policy Entropy: 3.73870
Value Function Loss: 0.04372

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.49869
Value Function Update Magnitude: 0.78914

Collected Steps per Second: 21,508.57725
Overall Steps per Second: 10,702.89328

Timestep Collection Time: 2.32596
Timestep Consumption Time: 2.34829
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.67425

Cumulative Model Updates: 44,150
Cumulative Timesteps: 368,267,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,190.85985
Policy Entropy: 3.75061
Value Function Loss: 0.04526

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.48554
Value Function Update Magnitude: 0.74984

Collected Steps per Second: 22,018.04968
Overall Steps per Second: 10,805.00111

Timestep Collection Time: 2.27095
Timestep Consumption Time: 2.35672
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62767

Cumulative Model Updates: 44,156
Cumulative Timesteps: 368,317,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 368317208...
Checkpoint 368317208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,570.93817
Policy Entropy: 3.75200
Value Function Loss: 0.04307

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.45956
Value Function Update Magnitude: 0.79000

Collected Steps per Second: 21,634.35738
Overall Steps per Second: 10,730.42825

Timestep Collection Time: 2.31160
Timestep Consumption Time: 2.34898
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.66058

Cumulative Model Updates: 44,162
Cumulative Timesteps: 368,367,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,755.74524
Policy Entropy: 3.75325
Value Function Loss: 0.04015

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.46129
Value Function Update Magnitude: 0.79037

Collected Steps per Second: 22,283.55765
Overall Steps per Second: 10,862.41319

Timestep Collection Time: 2.24452
Timestep Consumption Time: 2.35998
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60450

Cumulative Model Updates: 44,168
Cumulative Timesteps: 368,417,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 368417234...
Checkpoint 368417234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.77248
Policy Entropy: 3.75235
Value Function Loss: 0.04088

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.49537
Value Function Update Magnitude: 0.76596

Collected Steps per Second: 21,658.06596
Overall Steps per Second: 10,689.20994

Timestep Collection Time: 2.30898
Timestep Consumption Time: 2.36938
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.67836

Cumulative Model Updates: 44,174
Cumulative Timesteps: 368,467,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,880.28292
Policy Entropy: 3.74753
Value Function Loss: 0.04087

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.51680
Value Function Update Magnitude: 0.78141

Collected Steps per Second: 22,222.14124
Overall Steps per Second: 10,833.07321

Timestep Collection Time: 2.25028
Timestep Consumption Time: 2.36577
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.61605

Cumulative Model Updates: 44,180
Cumulative Timesteps: 368,517,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 368517248...
Checkpoint 368517248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,662.98543
Policy Entropy: 3.75675
Value Function Loss: 0.04065

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.52359
Value Function Update Magnitude: 0.78065

Collected Steps per Second: 21,986.54315
Overall Steps per Second: 10,650.17478

Timestep Collection Time: 2.27539
Timestep Consumption Time: 2.42200
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69739

Cumulative Model Updates: 44,186
Cumulative Timesteps: 368,567,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,288.66837
Policy Entropy: 3.75217
Value Function Loss: 0.03995

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.53546
Value Function Update Magnitude: 0.78030

Collected Steps per Second: 22,380.10457
Overall Steps per Second: 10,645.32998

Timestep Collection Time: 2.23511
Timestep Consumption Time: 2.46385
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.69896

Cumulative Model Updates: 44,192
Cumulative Timesteps: 368,617,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 368617298...
Checkpoint 368617298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,141.42991
Policy Entropy: 3.75671
Value Function Loss: 0.04161

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.55555
Value Function Update Magnitude: 0.80271

Collected Steps per Second: 22,599.13252
Overall Steps per Second: 10,850.88087

Timestep Collection Time: 2.21283
Timestep Consumption Time: 2.39583
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.60866

Cumulative Model Updates: 44,198
Cumulative Timesteps: 368,667,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,649.41506
Policy Entropy: 3.75060
Value Function Loss: 0.04284

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.58028
Value Function Update Magnitude: 0.80986

Collected Steps per Second: 22,895.38135
Overall Steps per Second: 10,775.91431

Timestep Collection Time: 2.18455
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.64146

Cumulative Model Updates: 44,204
Cumulative Timesteps: 368,717,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 368717322...
Checkpoint 368717322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,008.98228
Policy Entropy: 3.75395
Value Function Loss: 0.04259

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.78546

Collected Steps per Second: 22,486.87456
Overall Steps per Second: 10,791.25442

Timestep Collection Time: 2.22370
Timestep Consumption Time: 2.41006
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.63375

Cumulative Model Updates: 44,210
Cumulative Timesteps: 368,767,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,007.95502
Policy Entropy: 3.74781
Value Function Loss: 0.04318

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.76281

Collected Steps per Second: 22,957.46471
Overall Steps per Second: 10,910.75319

Timestep Collection Time: 2.17872
Timestep Consumption Time: 2.40556
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.58428

Cumulative Model Updates: 44,216
Cumulative Timesteps: 368,817,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 368817344...
Checkpoint 368817344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,189.76174
Policy Entropy: 3.75983
Value Function Loss: 0.04273

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.49027
Value Function Update Magnitude: 0.76377

Collected Steps per Second: 22,521.03121
Overall Steps per Second: 10,782.18233

Timestep Collection Time: 2.22157
Timestep Consumption Time: 2.41868
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.64025

Cumulative Model Updates: 44,222
Cumulative Timesteps: 368,867,376

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,179.66417
Policy Entropy: 3.74682
Value Function Loss: 0.04250

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.52651
Value Function Update Magnitude: 0.80047

Collected Steps per Second: 22,596.93651
Overall Steps per Second: 10,753.68840

Timestep Collection Time: 2.21366
Timestep Consumption Time: 2.43795
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.65161

Cumulative Model Updates: 44,228
Cumulative Timesteps: 368,917,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 368917398...
Checkpoint 368917398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,031.66640
Policy Entropy: 3.74584
Value Function Loss: 0.04198

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.82878

Collected Steps per Second: 22,473.48275
Overall Steps per Second: 10,713.55414

Timestep Collection Time: 2.22627
Timestep Consumption Time: 2.44370
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.66997

Cumulative Model Updates: 44,234
Cumulative Timesteps: 368,967,430

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,703.14665
Policy Entropy: 3.74456
Value Function Loss: 0.04178

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.50762
Value Function Update Magnitude: 0.84278

Collected Steps per Second: 23,072.75334
Overall Steps per Second: 10,854.92976

Timestep Collection Time: 2.16819
Timestep Consumption Time: 2.44041
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60860

Cumulative Model Updates: 44,240
Cumulative Timesteps: 369,017,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 369017456...
Checkpoint 369017456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,085.94755
Policy Entropy: 3.75034
Value Function Loss: 0.04224

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.47129
Value Function Update Magnitude: 0.76546

Collected Steps per Second: 22,637.02255
Overall Steps per Second: 10,713.30962

Timestep Collection Time: 2.20904
Timestep Consumption Time: 2.45862
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.66765

Cumulative Model Updates: 44,246
Cumulative Timesteps: 369,067,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,693.64943
Policy Entropy: 3.73712
Value Function Loss: 0.04478

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.45064
Value Function Update Magnitude: 0.65703

Collected Steps per Second: 22,775.87721
Overall Steps per Second: 10,806.31716

Timestep Collection Time: 2.19583
Timestep Consumption Time: 2.43220
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62803

Cumulative Model Updates: 44,252
Cumulative Timesteps: 369,117,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 369117474...
Checkpoint 369117474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,278.42366
Policy Entropy: 3.74524
Value Function Loss: 0.04407

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.47628
Value Function Update Magnitude: 0.65869

Collected Steps per Second: 22,304.81415
Overall Steps per Second: 10,682.19687

Timestep Collection Time: 2.24257
Timestep Consumption Time: 2.43999
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.68256

Cumulative Model Updates: 44,258
Cumulative Timesteps: 369,167,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,686.13912
Policy Entropy: 3.75138
Value Function Loss: 0.04282

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.52598
Value Function Update Magnitude: 0.74600

Collected Steps per Second: 22,678.79268
Overall Steps per Second: 10,617.63325

Timestep Collection Time: 2.20470
Timestep Consumption Time: 2.50444
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.70915

Cumulative Model Updates: 44,264
Cumulative Timesteps: 369,217,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 369217494...
Checkpoint 369217494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,975.31217
Policy Entropy: 3.75681
Value Function Loss: 0.04138

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.53725
Value Function Update Magnitude: 0.79436

Collected Steps per Second: 22,638.33617
Overall Steps per Second: 10,624.04124

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.49836
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.70762

Cumulative Model Updates: 44,270
Cumulative Timesteps: 369,267,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,854.41425
Policy Entropy: 3.75459
Value Function Loss: 0.04225

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.52446
Value Function Update Magnitude: 0.79675

Collected Steps per Second: 22,921.91527
Overall Steps per Second: 10,828.98848

Timestep Collection Time: 2.18149
Timestep Consumption Time: 2.43611
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.61761

Cumulative Model Updates: 44,276
Cumulative Timesteps: 369,317,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 369317512...
Checkpoint 369317512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,545.38860
Policy Entropy: 3.76551
Value Function Loss: 0.04233

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.55052
Value Function Update Magnitude: 0.72538

Collected Steps per Second: 22,706.07005
Overall Steps per Second: 10,590.22233

Timestep Collection Time: 2.20223
Timestep Consumption Time: 2.51948
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.72171

Cumulative Model Updates: 44,282
Cumulative Timesteps: 369,367,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,673.38915
Policy Entropy: 3.76684
Value Function Loss: 0.04139

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10006
Policy Update Magnitude: 0.55231
Value Function Update Magnitude: 0.68394

Collected Steps per Second: 23,154.50029
Overall Steps per Second: 10,890.32736

Timestep Collection Time: 2.16062
Timestep Consumption Time: 2.43318
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.59380

Cumulative Model Updates: 44,288
Cumulative Timesteps: 369,417,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 369417544...
Checkpoint 369417544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,071.59346
Policy Entropy: 3.79518
Value Function Loss: 0.03937

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.50659
Value Function Update Magnitude: 0.72286

Collected Steps per Second: 22,360.07782
Overall Steps per Second: 10,740.83197

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.41949
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.65606

Cumulative Model Updates: 44,294
Cumulative Timesteps: 369,467,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,766.45987
Policy Entropy: 3.78553
Value Function Loss: 0.04010

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.49121
Value Function Update Magnitude: 0.75889

Collected Steps per Second: 22,607.95507
Overall Steps per Second: 10,764.62853

Timestep Collection Time: 2.21188
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.64540

Cumulative Model Updates: 44,300
Cumulative Timesteps: 369,517,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 369517560...
Checkpoint 369517560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,205.30789
Policy Entropy: 3.78577
Value Function Loss: 0.04109

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.50291
Value Function Update Magnitude: 0.80775

Collected Steps per Second: 22,471.29240
Overall Steps per Second: 10,748.50177

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.65460

Cumulative Model Updates: 44,306
Cumulative Timesteps: 369,567,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,184.14579
Policy Entropy: 3.76819
Value Function Loss: 0.04227

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.50975
Value Function Update Magnitude: 0.83357

Collected Steps per Second: 22,602.42069
Overall Steps per Second: 10,634.63662

Timestep Collection Time: 2.21366
Timestep Consumption Time: 2.49116
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.70482

Cumulative Model Updates: 44,312
Cumulative Timesteps: 369,617,624

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 369617624...
Checkpoint 369617624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,025.71791
Policy Entropy: 3.77434
Value Function Loss: 0.04139

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 0.53536
Value Function Update Magnitude: 0.84786

Collected Steps per Second: 22,485.30255
Overall Steps per Second: 10,659.11337

Timestep Collection Time: 2.22430
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.69214

Cumulative Model Updates: 44,318
Cumulative Timesteps: 369,667,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,697.58614
Policy Entropy: 3.75837
Value Function Loss: 0.04083

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.59908
Value Function Update Magnitude: 0.85281

Collected Steps per Second: 22,911.82361
Overall Steps per Second: 10,678.37074

Timestep Collection Time: 2.18298
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.68386

Cumulative Model Updates: 44,324
Cumulative Timesteps: 369,717,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 369717654...
Checkpoint 369717654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.07253
Policy Entropy: 3.76528
Value Function Loss: 0.04074

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06342
Policy Update Magnitude: 0.62882
Value Function Update Magnitude: 0.85872

Collected Steps per Second: 22,490.11269
Overall Steps per Second: 10,633.78584

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.47959
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.70350

Cumulative Model Updates: 44,330
Cumulative Timesteps: 369,767,670

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,569.90538
Policy Entropy: 3.76233
Value Function Loss: 0.04066

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06597
Policy Update Magnitude: 0.60530
Value Function Update Magnitude: 0.84338

Collected Steps per Second: 22,643.26024
Overall Steps per Second: 10,652.80796

Timestep Collection Time: 2.20922
Timestep Consumption Time: 2.48663
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.69585

Cumulative Model Updates: 44,336
Cumulative Timesteps: 369,817,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 369817694...
Checkpoint 369817694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,811.73094
Policy Entropy: 3.75892
Value Function Loss: 0.04119

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.56304
Value Function Update Magnitude: 0.81316

Collected Steps per Second: 22,542.29125
Overall Steps per Second: 10,687.52424

Timestep Collection Time: 2.21867
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.67966

Cumulative Model Updates: 44,342
Cumulative Timesteps: 369,867,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,942.13699
Policy Entropy: 3.75484
Value Function Loss: 0.04153

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.49766
Value Function Update Magnitude: 0.81346

Collected Steps per Second: 23,179.29931
Overall Steps per Second: 10,742.42216

Timestep Collection Time: 2.15779
Timestep Consumption Time: 2.49815
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.65593

Cumulative Model Updates: 44,348
Cumulative Timesteps: 369,917,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 369917724...
Checkpoint 369917724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.99498
Policy Entropy: 3.74977
Value Function Loss: 0.04133

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.49054
Value Function Update Magnitude: 0.77767

Collected Steps per Second: 22,595.73243
Overall Steps per Second: 10,625.23288

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.70691

Cumulative Model Updates: 44,354
Cumulative Timesteps: 369,967,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,414.61892
Policy Entropy: 3.74749
Value Function Loss: 0.04438

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07493
Policy Update Magnitude: 0.52558
Value Function Update Magnitude: 0.67796

Collected Steps per Second: 23,105.83325
Overall Steps per Second: 10,856.73229

Timestep Collection Time: 2.16586
Timestep Consumption Time: 2.44363
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.60949

Cumulative Model Updates: 44,360
Cumulative Timesteps: 370,017,780

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 370017780...
Checkpoint 370017780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,934.24886
Policy Entropy: 3.73569
Value Function Loss: 0.04480

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05552
Policy Update Magnitude: 0.60219
Value Function Update Magnitude: 0.65835

Collected Steps per Second: 21,739.41956
Overall Steps per Second: 10,646.75515

Timestep Collection Time: 2.30080
Timestep Consumption Time: 2.39716
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.69796

Cumulative Model Updates: 44,366
Cumulative Timesteps: 370,067,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,043.27574
Policy Entropy: 3.73420
Value Function Loss: 0.04743

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.63840
Value Function Update Magnitude: 0.69116

Collected Steps per Second: 22,430.84104
Overall Steps per Second: 10,920.35211

Timestep Collection Time: 2.22979
Timestep Consumption Time: 2.35028
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.58007

Cumulative Model Updates: 44,372
Cumulative Timesteps: 370,117,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 370117814...
Checkpoint 370117814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,738.57850
Policy Entropy: 3.73515
Value Function Loss: 0.04676

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.63570
Value Function Update Magnitude: 0.73189

Collected Steps per Second: 22,037.90947
Overall Steps per Second: 10,612.84365

Timestep Collection Time: 2.26909
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.71184

Cumulative Model Updates: 44,378
Cumulative Timesteps: 370,167,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,270.26507
Policy Entropy: 3.73637
Value Function Loss: 0.04713

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06902
Policy Update Magnitude: 0.62178
Value Function Update Magnitude: 0.68198

Collected Steps per Second: 22,132.61038
Overall Steps per Second: 10,836.99428

Timestep Collection Time: 2.25920
Timestep Consumption Time: 2.35481
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.61401

Cumulative Model Updates: 44,384
Cumulative Timesteps: 370,217,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 370217822...
Checkpoint 370217822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,357.34945
Policy Entropy: 3.72563
Value Function Loss: 0.04853

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.70655

Collected Steps per Second: 21,680.58562
Overall Steps per Second: 10,769.05619

Timestep Collection Time: 2.30723
Timestep Consumption Time: 2.33775
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.64498

Cumulative Model Updates: 44,390
Cumulative Timesteps: 370,267,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,557.09314
Policy Entropy: 3.70627
Value Function Loss: 0.04946

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.45763
Value Function Update Magnitude: 0.68825

Collected Steps per Second: 22,327.78548
Overall Steps per Second: 10,903.62376

Timestep Collection Time: 2.23990
Timestep Consumption Time: 2.34683
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58673

Cumulative Model Updates: 44,396
Cumulative Timesteps: 370,317,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 370317856...
Checkpoint 370317856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,570.84124
Policy Entropy: 3.70251
Value Function Loss: 0.05029

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.40626
Value Function Update Magnitude: 0.63814

Collected Steps per Second: 22,012.49306
Overall Steps per Second: 10,590.96168

Timestep Collection Time: 2.27144
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.72101

Cumulative Model Updates: 44,402
Cumulative Timesteps: 370,367,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,399.26594
Policy Entropy: 3.70221
Value Function Loss: 0.04997

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.40079
Value Function Update Magnitude: 0.64201

Collected Steps per Second: 23,170.54488
Overall Steps per Second: 10,975.13548

Timestep Collection Time: 2.15929
Timestep Consumption Time: 2.39937
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.55867

Cumulative Model Updates: 44,408
Cumulative Timesteps: 370,417,888

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 370417888...
Checkpoint 370417888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,221.48678
Policy Entropy: 3.71861
Value Function Loss: 0.04881

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.43011
Value Function Update Magnitude: 0.59535

Collected Steps per Second: 22,339.16431
Overall Steps per Second: 10,594.55267

Timestep Collection Time: 2.23948
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.72205

Cumulative Model Updates: 44,414
Cumulative Timesteps: 370,467,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,625.29849
Policy Entropy: 3.71116
Value Function Loss: 0.04968

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.47319
Value Function Update Magnitude: 0.66730

Collected Steps per Second: 22,581.33998
Overall Steps per Second: 10,809.88231

Timestep Collection Time: 2.21501
Timestep Consumption Time: 2.41205
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.62706

Cumulative Model Updates: 44,420
Cumulative Timesteps: 370,517,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 370517934...
Checkpoint 370517934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,857.40202
Policy Entropy: 3.71144
Value Function Loss: 0.04890

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.52670
Value Function Update Magnitude: 0.74739

Collected Steps per Second: 22,640.02870
Overall Steps per Second: 10,787.87069

Timestep Collection Time: 2.20901
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.63595

Cumulative Model Updates: 44,426
Cumulative Timesteps: 370,567,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,968.54254
Policy Entropy: 3.68927
Value Function Loss: 0.05105

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06638
Policy Update Magnitude: 0.59142
Value Function Update Magnitude: 0.77383

Collected Steps per Second: 22,530.00697
Overall Steps per Second: 10,780.63964

Timestep Collection Time: 2.21962
Timestep Consumption Time: 2.41907
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.63869

Cumulative Model Updates: 44,432
Cumulative Timesteps: 370,617,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 370617954...
Checkpoint 370617954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,544.19315
Policy Entropy: 3.68299
Value Function Loss: 0.04962

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07932
Policy Update Magnitude: 0.63449
Value Function Update Magnitude: 0.77201

Collected Steps per Second: 22,611.01818
Overall Steps per Second: 10,730.75866

Timestep Collection Time: 2.21131
Timestep Consumption Time: 2.44819
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.65950

Cumulative Model Updates: 44,438
Cumulative Timesteps: 370,667,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,723.86059
Policy Entropy: 3.69748
Value Function Loss: 0.05014

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10820
Policy Update Magnitude: 0.60911
Value Function Update Magnitude: 0.73938

Collected Steps per Second: 22,825.70865
Overall Steps per Second: 10,822.14039

Timestep Collection Time: 2.19139
Timestep Consumption Time: 2.43062
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.62201

Cumulative Model Updates: 44,444
Cumulative Timesteps: 370,717,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 370717974...
Checkpoint 370717974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,455.15100
Policy Entropy: 3.70837
Value Function Loss: 0.04865

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.50565
Value Function Update Magnitude: 0.63732

Collected Steps per Second: 22,491.17469
Overall Steps per Second: 10,757.18190

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.42496
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.64806

Cumulative Model Updates: 44,450
Cumulative Timesteps: 370,767,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,661.21527
Policy Entropy: 3.71402
Value Function Loss: 0.04926

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.49499
Value Function Update Magnitude: 0.64353

Collected Steps per Second: 22,860.47968
Overall Steps per Second: 10,824.84468

Timestep Collection Time: 2.18788
Timestep Consumption Time: 2.43260
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.62048

Cumulative Model Updates: 44,456
Cumulative Timesteps: 370,817,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 370817990...
Checkpoint 370817990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,054.23961
Policy Entropy: 3.70398
Value Function Loss: 0.04796

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.45449
Value Function Update Magnitude: 0.67057

Collected Steps per Second: 22,498.47600
Overall Steps per Second: 10,707.67316

Timestep Collection Time: 2.22326
Timestep Consumption Time: 2.44815
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.67142

Cumulative Model Updates: 44,462
Cumulative Timesteps: 370,868,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,642.17386
Policy Entropy: 3.71094
Value Function Loss: 0.04831

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.50124
Value Function Update Magnitude: 0.69153

Collected Steps per Second: 22,669.67696
Overall Steps per Second: 10,615.83203

Timestep Collection Time: 2.20621
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.71127

Cumulative Model Updates: 44,468
Cumulative Timesteps: 370,918,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 370918024...
Checkpoint 370918024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,901.35094
Policy Entropy: 3.70969
Value Function Loss: 0.04932

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.58656
Value Function Update Magnitude: 0.63290

Collected Steps per Second: 22,732.15322
Overall Steps per Second: 10,867.87847

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.40205
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.60237

Cumulative Model Updates: 44,474
Cumulative Timesteps: 370,968,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,266.47494
Policy Entropy: 3.70639
Value Function Loss: 0.05007

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.58311
Value Function Update Magnitude: 0.61850

Collected Steps per Second: 23,076.33036
Overall Steps per Second: 10,868.38113

Timestep Collection Time: 2.16733
Timestep Consumption Time: 2.43446
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60179

Cumulative Model Updates: 44,480
Cumulative Timesteps: 371,018,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 371018056...
Checkpoint 371018056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,305.90867
Policy Entropy: 3.70620
Value Function Loss: 0.05102

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.50041
Value Function Update Magnitude: 0.62266

Collected Steps per Second: 22,441.80793
Overall Steps per Second: 10,725.09873

Timestep Collection Time: 2.22941
Timestep Consumption Time: 2.43553
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.66495

Cumulative Model Updates: 44,486
Cumulative Timesteps: 371,068,088

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,423.34363
Policy Entropy: 3.71193
Value Function Loss: 0.05033

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.44600
Value Function Update Magnitude: 0.61555

Collected Steps per Second: 22,921.21887
Overall Steps per Second: 10,826.71489

Timestep Collection Time: 2.18191
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.61931

Cumulative Model Updates: 44,492
Cumulative Timesteps: 371,118,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 371118100...
Checkpoint 371118100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,817.21723
Policy Entropy: 3.73300
Value Function Loss: 0.04838

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.45859
Value Function Update Magnitude: 0.71393

Collected Steps per Second: 22,339.97773
Overall Steps per Second: 10,691.59753

Timestep Collection Time: 2.23814
Timestep Consumption Time: 2.43843
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.67657

Cumulative Model Updates: 44,498
Cumulative Timesteps: 371,168,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,658.94680
Policy Entropy: 3.75630
Value Function Loss: 0.04827

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.49112
Value Function Update Magnitude: 0.81193

Collected Steps per Second: 22,687.94859
Overall Steps per Second: 10,728.88718

Timestep Collection Time: 2.20469
Timestep Consumption Time: 2.45749
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.66218

Cumulative Model Updates: 44,504
Cumulative Timesteps: 371,218,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 371218120...
Checkpoint 371218120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,852.61138
Policy Entropy: 3.77583
Value Function Loss: 0.04522

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.49511
Value Function Update Magnitude: 0.83589

Collected Steps per Second: 22,661.23609
Overall Steps per Second: 10,780.48881

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.63875

Cumulative Model Updates: 44,510
Cumulative Timesteps: 371,268,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,656.27015
Policy Entropy: 3.75809
Value Function Loss: 0.04773

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.49856
Value Function Update Magnitude: 0.83919

Collected Steps per Second: 22,965.55135
Overall Steps per Second: 10,719.74303

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.48821
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.66634

Cumulative Model Updates: 44,516
Cumulative Timesteps: 371,318,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 371318150...
Checkpoint 371318150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,211.59021
Policy Entropy: 3.74955
Value Function Loss: 0.04624

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.80685

Collected Steps per Second: 22,757.40199
Overall Steps per Second: 10,854.45606

Timestep Collection Time: 2.19788
Timestep Consumption Time: 2.41018
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60806

Cumulative Model Updates: 44,522
Cumulative Timesteps: 371,368,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,916.84631
Policy Entropy: 3.74911
Value Function Loss: 0.04734

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.50346
Value Function Update Magnitude: 0.76830

Collected Steps per Second: 22,954.95217
Overall Steps per Second: 10,729.65792

Timestep Collection Time: 2.17905
Timestep Consumption Time: 2.48279
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.66184

Cumulative Model Updates: 44,528
Cumulative Timesteps: 371,418,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 371418188...
Checkpoint 371418188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,553.50198
Policy Entropy: 3.75401
Value Function Loss: 0.04654

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.51372
Value Function Update Magnitude: 0.78481

Collected Steps per Second: 22,675.95691
Overall Steps per Second: 10,779.46583

Timestep Collection Time: 2.20621
Timestep Consumption Time: 2.43483
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.64105

Cumulative Model Updates: 44,534
Cumulative Timesteps: 371,468,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,758.23130
Policy Entropy: 3.75027
Value Function Loss: 0.04655

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.46542
Value Function Update Magnitude: 0.75693

Collected Steps per Second: 23,024.19289
Overall Steps per Second: 10,737.39677

Timestep Collection Time: 2.17258
Timestep Consumption Time: 2.48609
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.65867

Cumulative Model Updates: 44,540
Cumulative Timesteps: 371,518,238

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 371518238...
Checkpoint 371518238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,057.24314
Policy Entropy: 3.74181
Value Function Loss: 0.04849

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08115
Policy Update Magnitude: 0.47313
Value Function Update Magnitude: 0.67653

Collected Steps per Second: 22,752.40926
Overall Steps per Second: 10,819.77934

Timestep Collection Time: 2.19845
Timestep Consumption Time: 2.42457
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.62301

Cumulative Model Updates: 44,546
Cumulative Timesteps: 371,568,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,933.95882
Policy Entropy: 3.73725
Value Function Loss: 0.04964

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.49669
Value Function Update Magnitude: 0.66754

Collected Steps per Second: 23,018.01496
Overall Steps per Second: 10,754.12137

Timestep Collection Time: 2.17325
Timestep Consumption Time: 2.47836
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.65161

Cumulative Model Updates: 44,552
Cumulative Timesteps: 371,618,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 371618282...
Checkpoint 371618282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,194.21444
Policy Entropy: 3.73723
Value Function Loss: 0.05172

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.16688
Policy Update Magnitude: 0.46656
Value Function Update Magnitude: 0.68617

Collected Steps per Second: 22,539.26191
Overall Steps per Second: 10,774.19340

Timestep Collection Time: 2.21950
Timestep Consumption Time: 2.42363
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.64313

Cumulative Model Updates: 44,558
Cumulative Timesteps: 371,668,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,389.71631
Policy Entropy: 3.73541
Value Function Loss: 0.05234

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.45855
Value Function Update Magnitude: 0.66199

Collected Steps per Second: 22,750.28624
Overall Steps per Second: 10,626.04600

Timestep Collection Time: 2.19821
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.70636

Cumulative Model Updates: 44,564
Cumulative Timesteps: 371,718,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 371718318...
Checkpoint 371718318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,279.77849
Policy Entropy: 3.73097
Value Function Loss: 0.05287

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.53318
Value Function Update Magnitude: 0.62396

Collected Steps per Second: 22,833.19151
Overall Steps per Second: 10,676.67612

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.49481
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.68592

Cumulative Model Updates: 44,570
Cumulative Timesteps: 371,768,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,376.09177
Policy Entropy: 3.75190
Value Function Loss: 0.04887

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.55679
Value Function Update Magnitude: 0.62366

Collected Steps per Second: 22,859.13807
Overall Steps per Second: 10,846.68506

Timestep Collection Time: 2.18810
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.61136

Cumulative Model Updates: 44,576
Cumulative Timesteps: 371,818,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 371818366...
Checkpoint 371818366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,587.29208
Policy Entropy: 3.76128
Value Function Loss: 0.04923

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.50780
Value Function Update Magnitude: 0.63752

Collected Steps per Second: 22,431.80823
Overall Steps per Second: 10,598.28050

Timestep Collection Time: 2.22960
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.71907

Cumulative Model Updates: 44,582
Cumulative Timesteps: 371,868,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,643.65717
Policy Entropy: 3.76971
Value Function Loss: 0.04567

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.51812
Value Function Update Magnitude: 0.63972

Collected Steps per Second: 22,850.17962
Overall Steps per Second: 10,802.20810

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.44159
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.63072

Cumulative Model Updates: 44,588
Cumulative Timesteps: 371,918,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 371918402...
Checkpoint 371918402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,414.82178
Policy Entropy: 3.77427
Value Function Loss: 0.04474

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.48324
Value Function Update Magnitude: 0.70791

Collected Steps per Second: 22,669.02177
Overall Steps per Second: 10,752.97751

Timestep Collection Time: 2.20706
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.65285

Cumulative Model Updates: 44,594
Cumulative Timesteps: 371,968,434

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,307.59564
Policy Entropy: 3.78090
Value Function Loss: 0.04330

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.45599
Value Function Update Magnitude: 0.77977

Collected Steps per Second: 22,988.08534
Overall Steps per Second: 10,840.08139

Timestep Collection Time: 2.17634
Timestep Consumption Time: 2.43893
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.61528

Cumulative Model Updates: 44,600
Cumulative Timesteps: 372,018,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 372018464...
Checkpoint 372018464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,471.93648
Policy Entropy: 3.77038
Value Function Loss: 0.04325

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.48539
Value Function Update Magnitude: 0.79248

Collected Steps per Second: 22,639.50289
Overall Steps per Second: 10,702.36445

Timestep Collection Time: 2.20862
Timestep Consumption Time: 2.46343
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.67205

Cumulative Model Updates: 44,606
Cumulative Timesteps: 372,068,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,402.33881
Policy Entropy: 3.75540
Value Function Loss: 0.04423

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.48237
Value Function Update Magnitude: 0.79005

Collected Steps per Second: 22,671.40355
Overall Steps per Second: 10,643.03137

Timestep Collection Time: 2.20666
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.70054

Cumulative Model Updates: 44,612
Cumulative Timesteps: 372,118,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 372118494...
Checkpoint 372118494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,955.74832
Policy Entropy: 3.75394
Value Function Loss: 0.04307

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.51079
Value Function Update Magnitude: 0.75466

Collected Steps per Second: 22,506.52709
Overall Steps per Second: 10,637.03672

Timestep Collection Time: 2.22220
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.70187

Cumulative Model Updates: 44,618
Cumulative Timesteps: 372,168,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,307.23478
Policy Entropy: 3.75133
Value Function Loss: 0.04295

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.50221
Value Function Update Magnitude: 0.75000

Collected Steps per Second: 22,948.55160
Overall Steps per Second: 10,726.90355

Timestep Collection Time: 2.17922
Timestep Consumption Time: 2.48289
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.66211

Cumulative Model Updates: 44,624
Cumulative Timesteps: 372,218,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 372218518...
Checkpoint 372218518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,045.43343
Policy Entropy: 3.76068
Value Function Loss: 0.04097

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.46524
Value Function Update Magnitude: 0.76898

Collected Steps per Second: 22,528.12988
Overall Steps per Second: 10,648.04699

Timestep Collection Time: 2.22078
Timestep Consumption Time: 2.47774
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.69851

Cumulative Model Updates: 44,630
Cumulative Timesteps: 372,268,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,179.39686
Policy Entropy: 3.75993
Value Function Loss: 0.04220

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.50666
Value Function Update Magnitude: 0.77739

Collected Steps per Second: 22,593.21065
Overall Steps per Second: 10,785.97176

Timestep Collection Time: 2.21500
Timestep Consumption Time: 2.42473
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.63973

Cumulative Model Updates: 44,636
Cumulative Timesteps: 372,318,592

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 372318592...
Checkpoint 372318592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,149.38795
Policy Entropy: 3.76131
Value Function Loss: 0.04061

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.50935
Value Function Update Magnitude: 0.77457

Collected Steps per Second: 22,588.38130
Overall Steps per Second: 10,775.98353

Timestep Collection Time: 2.21362
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.64013

Cumulative Model Updates: 44,642
Cumulative Timesteps: 372,368,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,233.46621
Policy Entropy: 3.76475
Value Function Loss: 0.04153

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05819
Policy Update Magnitude: 0.53584
Value Function Update Magnitude: 0.78090

Collected Steps per Second: 23,064.33170
Overall Steps per Second: 10,872.23620

Timestep Collection Time: 2.16846
Timestep Consumption Time: 2.43170
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.60016

Cumulative Model Updates: 44,648
Cumulative Timesteps: 372,418,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 372418608...
Checkpoint 372418608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,413.26210
Policy Entropy: 3.75969
Value Function Loss: 0.04128

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.56221
Value Function Update Magnitude: 0.78261

Collected Steps per Second: 22,532.13253
Overall Steps per Second: 10,647.26670

Timestep Collection Time: 2.21967
Timestep Consumption Time: 2.47768
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.69736

Cumulative Model Updates: 44,654
Cumulative Timesteps: 372,468,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,357.63345
Policy Entropy: 3.75353
Value Function Loss: 0.04288

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.52186
Value Function Update Magnitude: 0.81129

Collected Steps per Second: 22,810.81768
Overall Steps per Second: 10,804.96399

Timestep Collection Time: 2.19378
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.63139

Cumulative Model Updates: 44,660
Cumulative Timesteps: 372,518,664

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 372518664...
Checkpoint 372518664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,795.28532
Policy Entropy: 3.74610
Value Function Loss: 0.04438

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.48527
Value Function Update Magnitude: 0.79748

Collected Steps per Second: 22,763.70934
Overall Steps per Second: 10,734.52220

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.46159
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.65824

Cumulative Model Updates: 44,666
Cumulative Timesteps: 372,568,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,233.69226
Policy Entropy: 3.73704
Value Function Loss: 0.04561

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.48794
Value Function Update Magnitude: 0.78761

Collected Steps per Second: 22,837.16352
Overall Steps per Second: 10,675.83212

Timestep Collection Time: 2.19038
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.68554

Cumulative Model Updates: 44,672
Cumulative Timesteps: 372,618,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 372618690...
Checkpoint 372618690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,564.28102
Policy Entropy: 3.75436
Value Function Loss: 0.04634

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.46883
Value Function Update Magnitude: 0.79591

Collected Steps per Second: 22,899.56861
Overall Steps per Second: 10,851.93457

Timestep Collection Time: 2.18450
Timestep Consumption Time: 2.42519
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60968

Cumulative Model Updates: 44,678
Cumulative Timesteps: 372,668,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,373.95269
Policy Entropy: 3.74835
Value Function Loss: 0.04614

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.48502
Value Function Update Magnitude: 0.84528

Collected Steps per Second: 23,138.62663
Overall Steps per Second: 10,872.09119

Timestep Collection Time: 2.16201
Timestep Consumption Time: 2.43931
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60132

Cumulative Model Updates: 44,684
Cumulative Timesteps: 372,718,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 372718740...
Checkpoint 372718740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,966.90252
Policy Entropy: 3.76470
Value Function Loss: 0.04589

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.52804
Value Function Update Magnitude: 0.85330

Collected Steps per Second: 22,580.17948
Overall Steps per Second: 10,777.72820

Timestep Collection Time: 2.21460
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.63975

Cumulative Model Updates: 44,690
Cumulative Timesteps: 372,768,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,491.19314
Policy Entropy: 3.74486
Value Function Loss: 0.04838

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.52620
Value Function Update Magnitude: 0.71160

Collected Steps per Second: 22,865.77946
Overall Steps per Second: 10,833.55088

Timestep Collection Time: 2.18790
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61788

Cumulative Model Updates: 44,696
Cumulative Timesteps: 372,818,774

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 372818774...
Checkpoint 372818774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,416.72307
Policy Entropy: 3.74877
Value Function Loss: 0.04913

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.15693
Policy Update Magnitude: 0.45429
Value Function Update Magnitude: 0.68223

Collected Steps per Second: 22,556.51640
Overall Steps per Second: 10,658.68123

Timestep Collection Time: 2.21807
Timestep Consumption Time: 2.47594
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.69401

Cumulative Model Updates: 44,702
Cumulative Timesteps: 372,868,806

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,693.95183
Policy Entropy: 3.73757
Value Function Loss: 0.04886

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.44547
Value Function Update Magnitude: 0.67873

Collected Steps per Second: 22,828.49946
Overall Steps per Second: 10,798.71735

Timestep Collection Time: 2.19112
Timestep Consumption Time: 2.44091
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.63203

Cumulative Model Updates: 44,708
Cumulative Timesteps: 372,918,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 372918826...
Checkpoint 372918826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,364.37475
Policy Entropy: 3.74115
Value Function Loss: 0.04889

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06126
Policy Update Magnitude: 0.56053
Value Function Update Magnitude: 0.62610

Collected Steps per Second: 22,382.37042
Overall Steps per Second: 10,713.36197

Timestep Collection Time: 2.23515
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.66968

Cumulative Model Updates: 44,714
Cumulative Timesteps: 372,968,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,302.63577
Policy Entropy: 3.73638
Value Function Loss: 0.04654

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06118
Policy Update Magnitude: 0.63629
Value Function Update Magnitude: 0.59780

Collected Steps per Second: 22,979.34799
Overall Steps per Second: 10,918.38828

Timestep Collection Time: 2.17691
Timestep Consumption Time: 2.40472
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.58163

Cumulative Model Updates: 44,720
Cumulative Timesteps: 373,018,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 373018878...
Checkpoint 373018878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.19132
Policy Entropy: 3.74945
Value Function Loss: 0.04513

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.62445
Value Function Update Magnitude: 0.59004

Collected Steps per Second: 22,610.01833
Overall Steps per Second: 10,684.92475

Timestep Collection Time: 2.21159
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.67986

Cumulative Model Updates: 44,726
Cumulative Timesteps: 373,068,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,704.00445
Policy Entropy: 3.76397
Value Function Loss: 0.04267

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.53080
Value Function Update Magnitude: 0.57797

Collected Steps per Second: 22,686.46981
Overall Steps per Second: 10,660.95582

Timestep Collection Time: 2.20528
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.69283

Cumulative Model Updates: 44,732
Cumulative Timesteps: 373,118,912

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 373118912...
Checkpoint 373118912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,487.32354
Policy Entropy: 3.76912
Value Function Loss: 0.04385

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.51162
Value Function Update Magnitude: 0.61824

Collected Steps per Second: 22,493.33260
Overall Steps per Second: 10,617.73415

Timestep Collection Time: 2.22448
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.71249

Cumulative Model Updates: 44,738
Cumulative Timesteps: 373,168,948

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,096.42717
Policy Entropy: 3.76896
Value Function Loss: 0.04198

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.49685
Value Function Update Magnitude: 0.68719

Collected Steps per Second: 23,125.80856
Overall Steps per Second: 10,698.51073

Timestep Collection Time: 2.16295
Timestep Consumption Time: 2.51247
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.67542

Cumulative Model Updates: 44,744
Cumulative Timesteps: 373,218,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 373218968...
Checkpoint 373218968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,947.38542
Policy Entropy: 3.76807
Value Function Loss: 0.04208

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.49998
Value Function Update Magnitude: 0.65169

Collected Steps per Second: 22,569.32879
Overall Steps per Second: 10,680.03575

Timestep Collection Time: 2.21557
Timestep Consumption Time: 2.46643
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.68201

Cumulative Model Updates: 44,750
Cumulative Timesteps: 373,268,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,059.97363
Policy Entropy: 3.78345
Value Function Loss: 0.04211

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.51205
Value Function Update Magnitude: 0.60738

Collected Steps per Second: 22,740.39909
Overall Steps per Second: 10,662.18129

Timestep Collection Time: 2.19891
Timestep Consumption Time: 2.49094
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.68985

Cumulative Model Updates: 44,756
Cumulative Timesteps: 373,318,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 373318976...
Checkpoint 373318976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,711.47537
Policy Entropy: 3.78243
Value Function Loss: 0.04251

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.51072
Value Function Update Magnitude: 0.64116

Collected Steps per Second: 22,670.42465
Overall Steps per Second: 10,789.56096

Timestep Collection Time: 2.20640
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.63596

Cumulative Model Updates: 44,762
Cumulative Timesteps: 373,368,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,877.27054
Policy Entropy: 3.78334
Value Function Loss: 0.04164

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06415
Policy Update Magnitude: 0.55910
Value Function Update Magnitude: 0.68209

Collected Steps per Second: 22,761.74919
Overall Steps per Second: 10,657.29587

Timestep Collection Time: 2.19728
Timestep Consumption Time: 2.49565
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.69294

Cumulative Model Updates: 44,768
Cumulative Timesteps: 373,419,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 373419010...
Checkpoint 373419010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,244.73058
Policy Entropy: 3.77551
Value Function Loss: 0.04210

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06711
Policy Update Magnitude: 0.58513
Value Function Update Magnitude: 0.63186

Collected Steps per Second: 22,715.03851
Overall Steps per Second: 10,672.91413

Timestep Collection Time: 2.20154
Timestep Consumption Time: 2.48397
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.68551

Cumulative Model Updates: 44,774
Cumulative Timesteps: 373,469,018

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,615.80433
Policy Entropy: 3.78457
Value Function Loss: 0.04457

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.54772
Value Function Update Magnitude: 0.65510

Collected Steps per Second: 23,008.97276
Overall Steps per Second: 10,731.09046

Timestep Collection Time: 2.17350
Timestep Consumption Time: 2.48679
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.66029

Cumulative Model Updates: 44,780
Cumulative Timesteps: 373,519,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 373519028...
Checkpoint 373519028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,753.70011
Policy Entropy: 3.78957
Value Function Loss: 0.04554

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.50449
Value Function Update Magnitude: 0.73796

Collected Steps per Second: 22,780.11120
Overall Steps per Second: 10,641.93334

Timestep Collection Time: 2.19490
Timestep Consumption Time: 2.50350
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.69839

Cumulative Model Updates: 44,786
Cumulative Timesteps: 373,569,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,523.10674
Policy Entropy: 3.77921
Value Function Loss: 0.04553

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06830
Policy Update Magnitude: 0.59174
Value Function Update Magnitude: 0.76714

Collected Steps per Second: 22,942.52571
Overall Steps per Second: 10,834.47510

Timestep Collection Time: 2.18006
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.61637

Cumulative Model Updates: 44,792
Cumulative Timesteps: 373,619,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 373619044...
Checkpoint 373619044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,752.19556
Policy Entropy: 3.77604
Value Function Loss: 0.04433

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06587
Policy Update Magnitude: 0.62540
Value Function Update Magnitude: 0.76536

Collected Steps per Second: 22,651.11543
Overall Steps per Second: 10,700.45024

Timestep Collection Time: 2.20766
Timestep Consumption Time: 2.46560
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.67326

Cumulative Model Updates: 44,798
Cumulative Timesteps: 373,669,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,199.84423
Policy Entropy: 3.77063
Value Function Loss: 0.04458

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.63131
Value Function Update Magnitude: 0.76927

Collected Steps per Second: 22,945.15290
Overall Steps per Second: 10,828.53377

Timestep Collection Time: 2.17928
Timestep Consumption Time: 2.43852
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.61780

Cumulative Model Updates: 44,804
Cumulative Timesteps: 373,719,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 373719054...
Checkpoint 373719054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,234.97613
Policy Entropy: 3.77125
Value Function Loss: 0.04451

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06384
Policy Update Magnitude: 0.63418
Value Function Update Magnitude: 0.78379

Collected Steps per Second: 22,624.67896
Overall Steps per Second: 10,707.03275

Timestep Collection Time: 2.21095
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.67188

Cumulative Model Updates: 44,810
Cumulative Timesteps: 373,769,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,964.58829
Policy Entropy: 3.76156
Value Function Loss: 0.04439

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.62650
Value Function Update Magnitude: 0.79300

Collected Steps per Second: 22,305.94059
Overall Steps per Second: 10,514.16158

Timestep Collection Time: 2.24281
Timestep Consumption Time: 2.51534
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.75815

Cumulative Model Updates: 44,816
Cumulative Timesteps: 373,819,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 373819104...
Checkpoint 373819104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,301.23529
Policy Entropy: 3.77146
Value Function Loss: 0.04456

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.53109
Value Function Update Magnitude: 0.80198

Collected Steps per Second: 22,576.20077
Overall Steps per Second: 10,585.71608

Timestep Collection Time: 2.21570
Timestep Consumption Time: 2.50973
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.72542

Cumulative Model Updates: 44,822
Cumulative Timesteps: 373,869,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,978.48810
Policy Entropy: 3.75470
Value Function Loss: 0.04630

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.47529
Value Function Update Magnitude: 0.83738

Collected Steps per Second: 22,820.35854
Overall Steps per Second: 10,810.02115

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.43538
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.62737

Cumulative Model Updates: 44,828
Cumulative Timesteps: 373,919,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 373919148...
Checkpoint 373919148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,906.90875
Policy Entropy: 3.73316
Value Function Loss: 0.04618

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.47849
Value Function Update Magnitude: 0.82741

Collected Steps per Second: 22,650.45974
Overall Steps per Second: 10,782.83545

Timestep Collection Time: 2.20817
Timestep Consumption Time: 2.43032
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.63848

Cumulative Model Updates: 44,834
Cumulative Timesteps: 373,969,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,081.30527
Policy Entropy: 3.72401
Value Function Loss: 0.04872

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.46255
Value Function Update Magnitude: 0.68604

Collected Steps per Second: 22,921.74603
Overall Steps per Second: 10,825.77261

Timestep Collection Time: 2.18133
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.61861

Cumulative Model Updates: 44,840
Cumulative Timesteps: 374,019,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 374019164...
Checkpoint 374019164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,697.87633
Policy Entropy: 3.73936
Value Function Loss: 0.04692

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.44049
Value Function Update Magnitude: 0.62127

Collected Steps per Second: 22,539.79344
Overall Steps per Second: 10,687.95916

Timestep Collection Time: 2.21901
Timestep Consumption Time: 2.46065
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.67966

Cumulative Model Updates: 44,846
Cumulative Timesteps: 374,069,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,842.81263
Policy Entropy: 3.74254
Value Function Loss: 0.04982

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.45302
Value Function Update Magnitude: 0.62294

Collected Steps per Second: 22,936.89044
Overall Steps per Second: 10,820.59246

Timestep Collection Time: 2.18077
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.62267

Cumulative Model Updates: 44,852
Cumulative Timesteps: 374,119,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 374119200...
Checkpoint 374119200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,918.12965
Policy Entropy: 3.74680
Value Function Loss: 0.04921

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.50042
Value Function Update Magnitude: 0.56926

Collected Steps per Second: 22,808.28724
Overall Steps per Second: 10,702.88675

Timestep Collection Time: 2.19254
Timestep Consumption Time: 2.47985
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.67238

Cumulative Model Updates: 44,858
Cumulative Timesteps: 374,169,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,205.01025
Policy Entropy: 3.76172
Value Function Loss: 0.04814

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.55464
Value Function Update Magnitude: 0.54821

Collected Steps per Second: 23,169.93231
Overall Steps per Second: 10,967.83658

Timestep Collection Time: 2.15849
Timestep Consumption Time: 2.40139
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.55988

Cumulative Model Updates: 44,864
Cumulative Timesteps: 374,219,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 374219220...
Checkpoint 374219220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,040.66978
Policy Entropy: 3.76565
Value Function Loss: 0.04588

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.60321
Value Function Update Magnitude: 0.57689

Collected Steps per Second: 22,686.44409
Overall Steps per Second: 10,604.54427

Timestep Collection Time: 2.20422
Timestep Consumption Time: 2.51130
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.71553

Cumulative Model Updates: 44,870
Cumulative Timesteps: 374,269,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,274.79239
Policy Entropy: 3.77007
Value Function Loss: 0.04671

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06237
Policy Update Magnitude: 0.62988
Value Function Update Magnitude: 0.58324

Collected Steps per Second: 23,041.00215
Overall Steps per Second: 10,842.09982

Timestep Collection Time: 2.17004
Timestep Consumption Time: 2.44161
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.61165

Cumulative Model Updates: 44,876
Cumulative Timesteps: 374,319,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 374319226...
Checkpoint 374319226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,261.68249
Policy Entropy: 3.76027
Value Function Loss: 0.04751

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05823
Policy Update Magnitude: 0.65772
Value Function Update Magnitude: 0.59375

Collected Steps per Second: 22,799.31776
Overall Steps per Second: 10,687.81116

Timestep Collection Time: 2.19314
Timestep Consumption Time: 2.48528
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.67841

Cumulative Model Updates: 44,882
Cumulative Timesteps: 374,369,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,076.35212
Policy Entropy: 3.76709
Value Function Loss: 0.04717

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06895
Policy Update Magnitude: 0.63347
Value Function Update Magnitude: 0.65405

Collected Steps per Second: 22,900.64137
Overall Steps per Second: 10,819.00499

Timestep Collection Time: 2.18396
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62279

Cumulative Model Updates: 44,888
Cumulative Timesteps: 374,419,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 374419242...
Checkpoint 374419242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,220.33321
Policy Entropy: 3.75944
Value Function Loss: 0.04771

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.60927
Value Function Update Magnitude: 0.72059

Collected Steps per Second: 22,688.18089
Overall Steps per Second: 10,692.19885

Timestep Collection Time: 2.20599
Timestep Consumption Time: 2.47499
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.68098

Cumulative Model Updates: 44,894
Cumulative Timesteps: 374,469,292

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,195.14633
Policy Entropy: 3.74129
Value Function Loss: 0.04983

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.59571
Value Function Update Magnitude: 0.72500

Collected Steps per Second: 22,736.65179
Overall Steps per Second: 10,657.86475

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.49278
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.69231

Cumulative Model Updates: 44,900
Cumulative Timesteps: 374,519,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 374519302...
Checkpoint 374519302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,115.47886
Policy Entropy: 3.71950
Value Function Loss: 0.05201

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.52732
Value Function Update Magnitude: 0.73379

Collected Steps per Second: 22,426.07973
Overall Steps per Second: 10,595.08750

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.48992
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.71973

Cumulative Model Updates: 44,906
Cumulative Timesteps: 374,569,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,101.38842
Policy Entropy: 3.69721
Value Function Loss: 0.05269

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.49982
Value Function Update Magnitude: 0.78167

Collected Steps per Second: 23,208.58960
Overall Steps per Second: 10,787.15181

Timestep Collection Time: 2.15567
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.63792

Cumulative Model Updates: 44,912
Cumulative Timesteps: 374,619,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 374619338...
Checkpoint 374619338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,377.47105
Policy Entropy: 3.70416
Value Function Loss: 0.05408

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.48056
Value Function Update Magnitude: 0.73581

Collected Steps per Second: 22,587.00264
Overall Steps per Second: 10,614.18659

Timestep Collection Time: 2.21411
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.71162

Cumulative Model Updates: 44,918
Cumulative Timesteps: 374,669,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,275.99118
Policy Entropy: 3.70230
Value Function Loss: 0.05192

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.47628
Value Function Update Magnitude: 0.62573

Collected Steps per Second: 22,723.67467
Overall Steps per Second: 10,630.27283

Timestep Collection Time: 2.20132
Timestep Consumption Time: 2.50430
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.70562

Cumulative Model Updates: 44,924
Cumulative Timesteps: 374,719,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 374719370...
Checkpoint 374719370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,890.06965
Policy Entropy: 3.71605
Value Function Loss: 0.05139

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.48696
Value Function Update Magnitude: 0.62122

Collected Steps per Second: 22,566.84027
Overall Steps per Second: 10,607.21796

Timestep Collection Time: 2.21679
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.71622

Cumulative Model Updates: 44,930
Cumulative Timesteps: 374,769,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,690.78225
Policy Entropy: 3.70547
Value Function Loss: 0.04812

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07500
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.59171

Collected Steps per Second: 23,175.72395
Overall Steps per Second: 10,766.30255

Timestep Collection Time: 2.15769
Timestep Consumption Time: 2.48699
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.64468

Cumulative Model Updates: 44,936
Cumulative Timesteps: 374,819,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 374819402...
Checkpoint 374819402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,641.11936
Policy Entropy: 3.70611
Value Function Loss: 0.04975

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.52169
Value Function Update Magnitude: 0.59022

Collected Steps per Second: 22,589.03079
Overall Steps per Second: 10,622.54867

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.49450
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.70885

Cumulative Model Updates: 44,942
Cumulative Timesteps: 374,869,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,485.36752
Policy Entropy: 3.69716
Value Function Loss: 0.05076

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.48943
Value Function Update Magnitude: 0.59922

Collected Steps per Second: 22,721.95297
Overall Steps per Second: 10,663.26547

Timestep Collection Time: 2.20148
Timestep Consumption Time: 2.48958
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.69106

Cumulative Model Updates: 44,948
Cumulative Timesteps: 374,919,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 374919444...
Checkpoint 374919444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,055.34256
Policy Entropy: 3.69702
Value Function Loss: 0.05085

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.53255
Value Function Update Magnitude: 0.65447

Collected Steps per Second: 22,670.59213
Overall Steps per Second: 10,812.57460

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.42020
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.62702

Cumulative Model Updates: 44,954
Cumulative Timesteps: 374,969,474

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,063.03887
Policy Entropy: 3.68872
Value Function Loss: 0.05096

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.49546
Value Function Update Magnitude: 0.61577

Collected Steps per Second: 22,541.86375
Overall Steps per Second: 10,585.68852

Timestep Collection Time: 2.21880
Timestep Consumption Time: 2.50606
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.72487

Cumulative Model Updates: 44,960
Cumulative Timesteps: 375,019,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 375019490...
Checkpoint 375019490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,167.16413
Policy Entropy: 3.69713
Value Function Loss: 0.05263

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.48321
Value Function Update Magnitude: 0.52924

Collected Steps per Second: 22,511.55854
Overall Steps per Second: 10,588.18733

Timestep Collection Time: 2.22206
Timestep Consumption Time: 2.50226
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.72432

Cumulative Model Updates: 44,966
Cumulative Timesteps: 375,069,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.81061
Policy Entropy: 3.70117
Value Function Loss: 0.05423

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.51190
Value Function Update Magnitude: 0.46810

Collected Steps per Second: 23,054.45314
Overall Steps per Second: 10,860.04945

Timestep Collection Time: 2.16878
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.60403

Cumulative Model Updates: 44,972
Cumulative Timesteps: 375,119,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 375119512...
Checkpoint 375119512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,899.75656
Policy Entropy: 3.70489
Value Function Loss: 0.05227

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.44702

Collected Steps per Second: 22,540.49159
Overall Steps per Second: 10,683.54504

Timestep Collection Time: 2.21903
Timestep Consumption Time: 2.46275
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.68178

Cumulative Model Updates: 44,978
Cumulative Timesteps: 375,169,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,032.40263
Policy Entropy: 3.71257
Value Function Loss: 0.04847

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.52877
Value Function Update Magnitude: 0.48724

Collected Steps per Second: 23,022.77346
Overall Steps per Second: 10,885.81870

Timestep Collection Time: 2.17315
Timestep Consumption Time: 2.42292
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.59607

Cumulative Model Updates: 44,984
Cumulative Timesteps: 375,219,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 375219562...
Checkpoint 375219562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,670.15236
Policy Entropy: 3.72703
Value Function Loss: 0.04776

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.60366

Collected Steps per Second: 22,636.43509
Overall Steps per Second: 10,709.26599

Timestep Collection Time: 2.20971
Timestep Consumption Time: 2.46101
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.67072

Cumulative Model Updates: 44,990
Cumulative Timesteps: 375,269,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,011.20678
Policy Entropy: 3.72485
Value Function Loss: 0.04799

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07710
Policy Update Magnitude: 0.59536
Value Function Update Magnitude: 0.68958

Collected Steps per Second: 22,785.87352
Overall Steps per Second: 10,797.35032

Timestep Collection Time: 2.19478
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.63169

Cumulative Model Updates: 44,996
Cumulative Timesteps: 375,319,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 375319592...
Checkpoint 375319592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.22464
Policy Entropy: 3.72405
Value Function Loss: 0.04967

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.63462
Value Function Update Magnitude: 0.73098

Collected Steps per Second: 22,453.53968
Overall Steps per Second: 10,758.03400

Timestep Collection Time: 2.22744
Timestep Consumption Time: 2.42155
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.64899

Cumulative Model Updates: 45,002
Cumulative Timesteps: 375,369,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,965.62177
Policy Entropy: 3.71825
Value Function Loss: 0.05297

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06340
Policy Update Magnitude: 0.66185
Value Function Update Magnitude: 0.60521

Collected Steps per Second: 23,275.75122
Overall Steps per Second: 10,888.27184

Timestep Collection Time: 2.14953
Timestep Consumption Time: 2.44550
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.59504

Cumulative Model Updates: 45,008
Cumulative Timesteps: 375,419,638

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 375419638...
Checkpoint 375419638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,172.44204
Policy Entropy: 3.72037
Value Function Loss: 0.05205

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06067
Policy Update Magnitude: 0.65614
Value Function Update Magnitude: 0.54186

Collected Steps per Second: 22,714.03479
Overall Steps per Second: 10,636.68010

Timestep Collection Time: 2.20269
Timestep Consumption Time: 2.50103
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.70372

Cumulative Model Updates: 45,014
Cumulative Timesteps: 375,469,670

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,182.07478
Policy Entropy: 3.72026
Value Function Loss: 0.05050

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06240
Policy Update Magnitude: 0.63644
Value Function Update Magnitude: 0.51240

Collected Steps per Second: 22,147.58139
Overall Steps per Second: 10,825.68739

Timestep Collection Time: 2.25885
Timestep Consumption Time: 2.36238
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62123

Cumulative Model Updates: 45,020
Cumulative Timesteps: 375,519,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 375519698...
Checkpoint 375519698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,609.18789
Policy Entropy: 3.73148
Value Function Loss: 0.04944

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06154
Policy Update Magnitude: 0.63902
Value Function Update Magnitude: 0.51446

Collected Steps per Second: 21,776.55379
Overall Steps per Second: 10,767.69804

Timestep Collection Time: 2.29733
Timestep Consumption Time: 2.34879
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.64612

Cumulative Model Updates: 45,026
Cumulative Timesteps: 375,569,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,947.77533
Policy Entropy: 3.71875
Value Function Loss: 0.05360

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06714
Policy Update Magnitude: 0.64425
Value Function Update Magnitude: 0.55285

Collected Steps per Second: 22,228.74815
Overall Steps per Second: 10,847.17109

Timestep Collection Time: 2.25051
Timestep Consumption Time: 2.36138
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.61189

Cumulative Model Updates: 45,032
Cumulative Timesteps: 375,619,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 375619752...
Checkpoint 375619752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,544.35567
Policy Entropy: 3.72711
Value Function Loss: 0.05277

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.59206
Value Function Update Magnitude: 0.56129

Collected Steps per Second: 21,718.92400
Overall Steps per Second: 10,670.75889

Timestep Collection Time: 2.30297
Timestep Consumption Time: 2.38442
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.68739

Cumulative Model Updates: 45,038
Cumulative Timesteps: 375,669,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,512.35902
Policy Entropy: 3.71046
Value Function Loss: 0.05349

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.49629
Value Function Update Magnitude: 0.57258

Collected Steps per Second: 22,382.61515
Overall Steps per Second: 10,864.96191

Timestep Collection Time: 2.23406
Timestep Consumption Time: 2.36826
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.60232

Cumulative Model Updates: 45,044
Cumulative Timesteps: 375,719,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 375719774...
Checkpoint 375719774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,891.74122
Policy Entropy: 3.71957
Value Function Loss: 0.04969

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.49936
Value Function Update Magnitude: 0.68798

Collected Steps per Second: 21,966.29613
Overall Steps per Second: 10,642.90526

Timestep Collection Time: 2.27749
Timestep Consumption Time: 2.42311
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.70060

Cumulative Model Updates: 45,050
Cumulative Timesteps: 375,769,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,537.18450
Policy Entropy: 3.72213
Value Function Loss: 0.04759

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.50564
Value Function Update Magnitude: 0.82755

Collected Steps per Second: 22,218.03472
Overall Steps per Second: 10,848.82395

Timestep Collection Time: 2.25114
Timestep Consumption Time: 2.35913
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.61027

Cumulative Model Updates: 45,056
Cumulative Timesteps: 375,819,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 375819818...
Checkpoint 375819818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.15470
Policy Entropy: 3.72291
Value Function Loss: 0.04578

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.52136
Value Function Update Magnitude: 0.84603

Collected Steps per Second: 21,791.23252
Overall Steps per Second: 10,629.94484

Timestep Collection Time: 2.29533
Timestep Consumption Time: 2.41006
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.70539

Cumulative Model Updates: 45,062
Cumulative Timesteps: 375,869,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,436.46495
Policy Entropy: 3.71992
Value Function Loss: 0.04575

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10230
Policy Update Magnitude: 0.52152
Value Function Update Magnitude: 0.84770

Collected Steps per Second: 22,810.73886
Overall Steps per Second: 10,733.85358

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.46729
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.66021

Cumulative Model Updates: 45,068
Cumulative Timesteps: 375,919,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 375919858...
Checkpoint 375919858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,419.19944
Policy Entropy: 3.71438
Value Function Loss: 0.04762

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.49124
Value Function Update Magnitude: 0.85037

Collected Steps per Second: 22,602.08963
Overall Steps per Second: 10,814.70169

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.41221
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.62537

Cumulative Model Updates: 45,074
Cumulative Timesteps: 375,969,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,688.02958
Policy Entropy: 3.71173
Value Function Loss: 0.04988

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.46022
Value Function Update Magnitude: 0.77838

Collected Steps per Second: 22,725.28847
Overall Steps per Second: 10,712.30811

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.67014

Cumulative Model Updates: 45,080
Cumulative Timesteps: 376,019,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 376019908...
Checkpoint 376019908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,461.68799
Policy Entropy: 3.71772
Value Function Loss: 0.05156

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.48945
Value Function Update Magnitude: 0.68448

Collected Steps per Second: 22,596.31200
Overall Steps per Second: 10,849.02270

Timestep Collection Time: 2.21302
Timestep Consumption Time: 2.39625
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.60926

Cumulative Model Updates: 45,086
Cumulative Timesteps: 376,069,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,060.24848
Policy Entropy: 3.72215
Value Function Loss: 0.05098

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06065
Policy Update Magnitude: 0.56503
Value Function Update Magnitude: 0.64637

Collected Steps per Second: 22,885.75011
Overall Steps per Second: 10,881.85671

Timestep Collection Time: 2.18494
Timestep Consumption Time: 2.41023
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.59517

Cumulative Model Updates: 45,092
Cumulative Timesteps: 376,119,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 376119918...
Checkpoint 376119918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,832.80103
Policy Entropy: 3.71465
Value Function Loss: 0.04968

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05956
Policy Update Magnitude: 0.63987
Value Function Update Magnitude: 0.64915

Collected Steps per Second: 22,578.73147
Overall Steps per Second: 10,763.24879

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.43184
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.64711

Cumulative Model Updates: 45,098
Cumulative Timesteps: 376,169,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,263.43780
Policy Entropy: 3.71687
Value Function Loss: 0.04931

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05702
Policy Update Magnitude: 0.65669
Value Function Update Magnitude: 0.60485

Collected Steps per Second: 22,979.07354
Overall Steps per Second: 10,811.49611

Timestep Collection Time: 2.17694
Timestep Consumption Time: 2.44999
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.62693

Cumulative Model Updates: 45,104
Cumulative Timesteps: 376,219,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 376219960...
Checkpoint 376219960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,081.38047
Policy Entropy: 3.70901
Value Function Loss: 0.05061

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.65433
Value Function Update Magnitude: 0.60970

Collected Steps per Second: 22,509.19242
Overall Steps per Second: 10,685.48086

Timestep Collection Time: 2.22131
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.67925

Cumulative Model Updates: 45,110
Cumulative Timesteps: 376,269,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,158.90957
Policy Entropy: 3.71088
Value Function Loss: 0.05163

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.56049
Value Function Update Magnitude: 0.59252

Collected Steps per Second: 22,729.09520
Overall Steps per Second: 10,651.84782

Timestep Collection Time: 2.20106
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.69665

Cumulative Model Updates: 45,116
Cumulative Timesteps: 376,319,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 376319988...
Checkpoint 376319988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,298.31863
Policy Entropy: 3.71573
Value Function Loss: 0.05218

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.48297
Value Function Update Magnitude: 0.62845

Collected Steps per Second: 21,887.44001
Overall Steps per Second: 10,499.88291

Timestep Collection Time: 2.28469
Timestep Consumption Time: 2.47784
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.76253

Cumulative Model Updates: 45,122
Cumulative Timesteps: 376,369,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,360.44552
Policy Entropy: 3.72780
Value Function Loss: 0.04694

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.44802
Value Function Update Magnitude: 0.75066

Collected Steps per Second: 23,014.26719
Overall Steps per Second: 10,854.46185

Timestep Collection Time: 2.17343
Timestep Consumption Time: 2.43481
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.60824

Cumulative Model Updates: 45,128
Cumulative Timesteps: 376,420,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 376420014...
Checkpoint 376420014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,904.79758
Policy Entropy: 3.73665
Value Function Loss: 0.04637

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.46856
Value Function Update Magnitude: 0.75891

Collected Steps per Second: 22,741.81799
Overall Steps per Second: 10,682.30711

Timestep Collection Time: 2.19956
Timestep Consumption Time: 2.48314
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.68270

Cumulative Model Updates: 45,134
Cumulative Timesteps: 376,470,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.31569
Policy Entropy: 3.73897
Value Function Loss: 0.04328

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.50022
Value Function Update Magnitude: 0.74128

Collected Steps per Second: 22,890.03691
Overall Steps per Second: 10,823.39096

Timestep Collection Time: 2.18558
Timestep Consumption Time: 2.43663
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.62221

Cumulative Model Updates: 45,140
Cumulative Timesteps: 376,520,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 376520064...
Checkpoint 376520064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,406.13598
Policy Entropy: 3.73692
Value Function Loss: 0.04466

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.72697

Collected Steps per Second: 22,512.12768
Overall Steps per Second: 10,696.38707

Timestep Collection Time: 2.22174
Timestep Consumption Time: 2.45424
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.67597

Cumulative Model Updates: 45,146
Cumulative Timesteps: 376,570,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,587.82810
Policy Entropy: 3.73559
Value Function Loss: 0.04510

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.58272
Value Function Update Magnitude: 0.70091

Collected Steps per Second: 23,034.52424
Overall Steps per Second: 10,833.23271

Timestep Collection Time: 2.17074
Timestep Consumption Time: 2.44487
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61561

Cumulative Model Updates: 45,152
Cumulative Timesteps: 376,620,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 376620082...
Checkpoint 376620082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.72926
Policy Entropy: 3.73879
Value Function Loss: 0.04607

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.75076

Collected Steps per Second: 22,480.62374
Overall Steps per Second: 10,753.70055

Timestep Collection Time: 2.22485
Timestep Consumption Time: 2.42620
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.65105

Cumulative Model Updates: 45,158
Cumulative Timesteps: 376,670,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,437.67542
Policy Entropy: 3.73140
Value Function Loss: 0.04373

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.46624
Value Function Update Magnitude: 0.79680

Collected Steps per Second: 22,839.13441
Overall Steps per Second: 10,789.96723

Timestep Collection Time: 2.18958
Timestep Consumption Time: 2.44510
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.63468

Cumulative Model Updates: 45,164
Cumulative Timesteps: 376,720,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 376720106...
Checkpoint 376720106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,630.01423
Policy Entropy: 3.72493
Value Function Loss: 0.04459

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.47520
Value Function Update Magnitude: 0.81617

Collected Steps per Second: 22,486.67297
Overall Steps per Second: 10,739.22003

Timestep Collection Time: 2.22514
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.65918

Cumulative Model Updates: 45,170
Cumulative Timesteps: 376,770,142

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,909.96986
Policy Entropy: 3.72015
Value Function Loss: 0.04605

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06422
Policy Update Magnitude: 0.56503
Value Function Update Magnitude: 0.84023

Collected Steps per Second: 23,006.54253
Overall Steps per Second: 10,852.10281

Timestep Collection Time: 2.17512
Timestep Consumption Time: 2.43615
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61127

Cumulative Model Updates: 45,176
Cumulative Timesteps: 376,820,184

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 376820184...
Checkpoint 376820184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,469.55979
Policy Entropy: 3.72653
Value Function Loss: 0.04575

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07130
Policy Update Magnitude: 0.62508
Value Function Update Magnitude: 0.84279

Collected Steps per Second: 22,679.38991
Overall Steps per Second: 10,668.08049

Timestep Collection Time: 2.20491
Timestep Consumption Time: 2.48253
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.68744

Cumulative Model Updates: 45,182
Cumulative Timesteps: 376,870,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,204.28486
Policy Entropy: 3.73615
Value Function Loss: 0.04431

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.57009
Value Function Update Magnitude: 0.82896

Collected Steps per Second: 22,942.44074
Overall Steps per Second: 10,821.95105

Timestep Collection Time: 2.17963
Timestep Consumption Time: 2.44116
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.62079

Cumulative Model Updates: 45,188
Cumulative Timesteps: 376,920,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 376920196...
Checkpoint 376920196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,738.05208
Policy Entropy: 3.72635
Value Function Loss: 0.04518

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.53586
Value Function Update Magnitude: 0.79079

Collected Steps per Second: 22,435.32662
Overall Steps per Second: 10,743.95693

Timestep Collection Time: 2.22916
Timestep Consumption Time: 2.42573
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.65490

Cumulative Model Updates: 45,194
Cumulative Timesteps: 376,970,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,423.22966
Policy Entropy: 3.74863
Value Function Loss: 0.04644

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.44940
Value Function Update Magnitude: 0.67683

Collected Steps per Second: 22,944.41349
Overall Steps per Second: 10,838.67621

Timestep Collection Time: 2.17996
Timestep Consumption Time: 2.43481
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61477

Cumulative Model Updates: 45,200
Cumulative Timesteps: 377,020,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 377020226...
Checkpoint 377020226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,826.07033
Policy Entropy: 3.72507
Value Function Loss: 0.04732

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.41885
Value Function Update Magnitude: 0.66086

Collected Steps per Second: 22,583.53205
Overall Steps per Second: 10,702.41589

Timestep Collection Time: 2.21524
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.67446

Cumulative Model Updates: 45,206
Cumulative Timesteps: 377,070,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,796.83377
Policy Entropy: 3.73668
Value Function Loss: 0.04601

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.44478
Value Function Update Magnitude: 0.67391

Collected Steps per Second: 22,398.74128
Overall Steps per Second: 10,560.02531

Timestep Collection Time: 2.23414
Timestep Consumption Time: 2.50467
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.73881

Cumulative Model Updates: 45,212
Cumulative Timesteps: 377,120,296

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 377120296...
Checkpoint 377120296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,220.94537
Policy Entropy: 3.73955
Value Function Loss: 0.04602

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11301
Policy Update Magnitude: 0.42004
Value Function Update Magnitude: 0.69796

Collected Steps per Second: 22,657.02370
Overall Steps per Second: 10,662.41677

Timestep Collection Time: 2.20744
Timestep Consumption Time: 2.48324
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.69068

Cumulative Model Updates: 45,218
Cumulative Timesteps: 377,170,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,979.39271
Policy Entropy: 3.74824
Value Function Loss: 0.04558

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.45365
Value Function Update Magnitude: 0.66593

Collected Steps per Second: 23,036.59026
Overall Steps per Second: 10,781.93411

Timestep Collection Time: 2.17046
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.63739

Cumulative Model Updates: 45,224
Cumulative Timesteps: 377,220,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 377220310...
Checkpoint 377220310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,719.91132
Policy Entropy: 3.75826
Value Function Loss: 0.04717

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.49058
Value Function Update Magnitude: 0.71023

Collected Steps per Second: 22,559.60486
Overall Steps per Second: 10,623.22420

Timestep Collection Time: 2.21688
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.70780

Cumulative Model Updates: 45,230
Cumulative Timesteps: 377,270,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,442.72922
Policy Entropy: 3.75489
Value Function Loss: 0.04743

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.47669
Value Function Update Magnitude: 0.69454

Collected Steps per Second: 22,859.82183
Overall Steps per Second: 10,821.00258

Timestep Collection Time: 2.18847
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62323

Cumulative Model Updates: 45,236
Cumulative Timesteps: 377,320,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 377320350...
Checkpoint 377320350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,655.14889
Policy Entropy: 3.76212
Value Function Loss: 0.04824

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.44187
Value Function Update Magnitude: 0.74407

Collected Steps per Second: 22,476.22466
Overall Steps per Second: 10,761.97943

Timestep Collection Time: 2.22555
Timestep Consumption Time: 2.42248
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.64803

Cumulative Model Updates: 45,242
Cumulative Timesteps: 377,370,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,636.09629
Policy Entropy: 3.75984
Value Function Loss: 0.04707

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.42772
Value Function Update Magnitude: 0.73818

Collected Steps per Second: 22,942.13778
Overall Steps per Second: 10,834.77168

Timestep Collection Time: 2.18140
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61902

Cumulative Model Updates: 45,248
Cumulative Timesteps: 377,420,418

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 377420418...
Checkpoint 377420418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.43759
Policy Entropy: 3.75161
Value Function Loss: 0.04770

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.44174
Value Function Update Magnitude: 0.79811

Collected Steps per Second: 22,502.22310
Overall Steps per Second: 10,681.93505

Timestep Collection Time: 2.22325
Timestep Consumption Time: 2.46017
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.68342

Cumulative Model Updates: 45,254
Cumulative Timesteps: 377,470,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,345.10059
Policy Entropy: 3.75741
Value Function Loss: 0.04516

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.45868
Value Function Update Magnitude: 0.85711

Collected Steps per Second: 22,652.64770
Overall Steps per Second: 10,659.97845

Timestep Collection Time: 2.20725
Timestep Consumption Time: 2.48319
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.69044

Cumulative Model Updates: 45,260
Cumulative Timesteps: 377,520,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 377520446...
Checkpoint 377520446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,094.15313
Policy Entropy: 3.74925
Value Function Loss: 0.04606

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.49858
Value Function Update Magnitude: 0.87629

Collected Steps per Second: 22,777.39485
Overall Steps per Second: 10,822.36750

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.42558
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.62135

Cumulative Model Updates: 45,266
Cumulative Timesteps: 377,570,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,054.55103
Policy Entropy: 3.75211
Value Function Loss: 0.04534

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.47183
Value Function Update Magnitude: 0.87980

Collected Steps per Second: 23,000.70560
Overall Steps per Second: 10,865.39939

Timestep Collection Time: 2.17489
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60397

Cumulative Model Updates: 45,272
Cumulative Timesteps: 377,620,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 377620484...
Checkpoint 377620484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,710.87873
Policy Entropy: 3.75433
Value Function Loss: 0.04463

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.46028
Value Function Update Magnitude: 0.86013

Collected Steps per Second: 22,411.32060
Overall Steps per Second: 10,752.57488

Timestep Collection Time: 2.23137
Timestep Consumption Time: 2.41942
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.65079

Cumulative Model Updates: 45,278
Cumulative Timesteps: 377,670,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,289.62059
Policy Entropy: 3.76497
Value Function Loss: 0.04153

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06717
Policy Update Magnitude: 0.49460
Value Function Update Magnitude: 0.81904

Collected Steps per Second: 22,843.23578
Overall Steps per Second: 10,720.53669

Timestep Collection Time: 2.18988
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.66618

Cumulative Model Updates: 45,284
Cumulative Timesteps: 377,720,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 377720516...
Checkpoint 377720516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,531.08427
Policy Entropy: 3.76576
Value Function Loss: 0.04097

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06072
Policy Update Magnitude: 0.57838
Value Function Update Magnitude: 0.82437

Collected Steps per Second: 22,074.57498
Overall Steps per Second: 10,828.65135

Timestep Collection Time: 2.26632
Timestep Consumption Time: 2.35365
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61997

Cumulative Model Updates: 45,290
Cumulative Timesteps: 377,770,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,113.10390
Policy Entropy: 3.74392
Value Function Loss: 0.04836

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06156
Policy Update Magnitude: 0.62577
Value Function Update Magnitude: 0.71424

Collected Steps per Second: 22,075.85490
Overall Steps per Second: 10,710.12702

Timestep Collection Time: 2.26628
Timestep Consumption Time: 2.40500
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.67128

Cumulative Model Updates: 45,296
Cumulative Timesteps: 377,820,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 377820574...
Checkpoint 377820574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,965.19799
Policy Entropy: 3.73359
Value Function Loss: 0.05441

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.61033
Value Function Update Magnitude: 0.57639

Collected Steps per Second: 22,077.87215
Overall Steps per Second: 10,840.25453

Timestep Collection Time: 2.26553
Timestep Consumption Time: 2.34857
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61410

Cumulative Model Updates: 45,302
Cumulative Timesteps: 377,870,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,007.89514
Policy Entropy: 3.72706
Value Function Loss: 0.05510

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07078
Policy Update Magnitude: 0.59999
Value Function Update Magnitude: 0.57309

Collected Steps per Second: 22,224.30637
Overall Steps per Second: 10,858.94517

Timestep Collection Time: 2.24979
Timestep Consumption Time: 2.35471
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60450

Cumulative Model Updates: 45,308
Cumulative Timesteps: 377,920,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 377920592...
Checkpoint 377920592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,688.90498
Policy Entropy: 3.72478
Value Function Loss: 0.05369

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06446
Policy Update Magnitude: 0.58636
Value Function Update Magnitude: 0.68846

Collected Steps per Second: 21,675.71021
Overall Steps per Second: 10,692.19805

Timestep Collection Time: 2.30701
Timestep Consumption Time: 2.36986
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.67687

Cumulative Model Updates: 45,314
Cumulative Timesteps: 377,970,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,522.17113
Policy Entropy: 3.71153
Value Function Loss: 0.05167

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.55941
Value Function Update Magnitude: 0.74943

Collected Steps per Second: 22,178.31446
Overall Steps per Second: 10,546.70155

Timestep Collection Time: 2.25554
Timestep Consumption Time: 2.48756
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.74309

Cumulative Model Updates: 45,320
Cumulative Timesteps: 378,020,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 378020622...
Checkpoint 378020622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,162.65305
Policy Entropy: 3.71598
Value Function Loss: 0.04998

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.49370
Value Function Update Magnitude: 0.77309

Collected Steps per Second: 22,451.22600
Overall Steps per Second: 10,632.04429

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.47611
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.70352

Cumulative Model Updates: 45,326
Cumulative Timesteps: 378,070,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,659.48076
Policy Entropy: 3.72763
Value Function Loss: 0.04914

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.43722
Value Function Update Magnitude: 0.76548

Collected Steps per Second: 22,958.72950
Overall Steps per Second: 10,833.22232

Timestep Collection Time: 2.17878
Timestep Consumption Time: 2.43868
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.61746

Cumulative Model Updates: 45,332
Cumulative Timesteps: 378,120,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 378120652...
Checkpoint 378120652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,307.48336
Policy Entropy: 3.72114
Value Function Loss: 0.04973

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.41624
Value Function Update Magnitude: 0.72877

Collected Steps per Second: 22,662.41564
Overall Steps per Second: 10,678.51481

Timestep Collection Time: 2.20709
Timestep Consumption Time: 2.47689
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.68398

Cumulative Model Updates: 45,338
Cumulative Timesteps: 378,170,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,475.53949
Policy Entropy: 3.74220
Value Function Loss: 0.04754

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.43229
Value Function Update Magnitude: 0.80501

Collected Steps per Second: 23,085.50751
Overall Steps per Second: 10,892.60820

Timestep Collection Time: 2.16716
Timestep Consumption Time: 2.42586
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.59302

Cumulative Model Updates: 45,344
Cumulative Timesteps: 378,220,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 378220700...
Checkpoint 378220700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,817.10450
Policy Entropy: 3.75227
Value Function Loss: 0.04589

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.41867
Value Function Update Magnitude: 0.76463

Collected Steps per Second: 22,831.21912
Overall Steps per Second: 10,682.10336

Timestep Collection Time: 2.18998
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.68073

Cumulative Model Updates: 45,350
Cumulative Timesteps: 378,270,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,309.08543
Policy Entropy: 3.76542
Value Function Loss: 0.04167

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07048
Policy Update Magnitude: 0.48717
Value Function Update Magnitude: 0.74242

Collected Steps per Second: 23,086.81778
Overall Steps per Second: 10,927.54104

Timestep Collection Time: 2.16790
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.58017

Cumulative Model Updates: 45,356
Cumulative Timesteps: 378,320,750

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 378320750...
Checkpoint 378320750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,292.97236
Policy Entropy: 3.75948
Value Function Loss: 0.04019

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.55927
Value Function Update Magnitude: 0.80410

Collected Steps per Second: 22,489.07155
Overall Steps per Second: 10,647.96849

Timestep Collection Time: 2.22330
Timestep Consumption Time: 2.47243
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.69573

Cumulative Model Updates: 45,362
Cumulative Timesteps: 378,370,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,594.49369
Policy Entropy: 3.74760
Value Function Loss: 0.03957

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06553
Policy Update Magnitude: 0.56436
Value Function Update Magnitude: 0.81486

Collected Steps per Second: 22,874.27916
Overall Steps per Second: 10,821.71636

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.43467
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.62071

Cumulative Model Updates: 45,368
Cumulative Timesteps: 378,420,754

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 378420754...
Checkpoint 378420754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,312.95502
Policy Entropy: 3.74424
Value Function Loss: 0.04069

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.51681
Value Function Update Magnitude: 0.78407

Collected Steps per Second: 22,692.08547
Overall Steps per Second: 10,725.10488

Timestep Collection Time: 2.20412
Timestep Consumption Time: 2.45933
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.66345

Cumulative Model Updates: 45,374
Cumulative Timesteps: 378,470,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,570.04627
Policy Entropy: 3.76468
Value Function Loss: 0.04187

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.48508
Value Function Update Magnitude: 0.67474

Collected Steps per Second: 22,813.31039
Overall Steps per Second: 10,810.47589

Timestep Collection Time: 2.19188
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.62551

Cumulative Model Updates: 45,380
Cumulative Timesteps: 378,520,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 378520774...
Checkpoint 378520774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,433.12057
Policy Entropy: 3.76836
Value Function Loss: 0.04294

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.51860
Value Function Update Magnitude: 0.64577

Collected Steps per Second: 22,455.59806
Overall Steps per Second: 10,767.21418

Timestep Collection Time: 2.22679
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.64410

Cumulative Model Updates: 45,386
Cumulative Timesteps: 378,570,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,384.76746
Policy Entropy: 3.77273
Value Function Loss: 0.04400

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.44253
Value Function Update Magnitude: 0.63924

Collected Steps per Second: 22,840.90753
Overall Steps per Second: 10,822.46093

Timestep Collection Time: 2.18923
Timestep Consumption Time: 2.43116
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62039

Cumulative Model Updates: 45,392
Cumulative Timesteps: 378,620,782

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 378620782...
Checkpoint 378620782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,594.20610
Policy Entropy: 3.77244
Value Function Loss: 0.04740

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.39706
Value Function Update Magnitude: 0.58234

Collected Steps per Second: 22,641.06251
Overall Steps per Second: 10,675.39928

Timestep Collection Time: 2.20882
Timestep Consumption Time: 2.47578
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.68460

Cumulative Model Updates: 45,398
Cumulative Timesteps: 378,670,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,662.53402
Policy Entropy: 3.78338
Value Function Loss: 0.04344

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.42330
Value Function Update Magnitude: 0.49614

Collected Steps per Second: 22,573.19128
Overall Steps per Second: 10,622.05441

Timestep Collection Time: 2.21599
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.70926

Cumulative Model Updates: 45,404
Cumulative Timesteps: 378,720,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 378720814...
Checkpoint 378720814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,073.49402
Policy Entropy: 3.79588
Value Function Loss: 0.03855

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.42735
Value Function Update Magnitude: 0.53647

Collected Steps per Second: 22,486.25141
Overall Steps per Second: 10,635.80473

Timestep Collection Time: 2.22474
Timestep Consumption Time: 2.47881
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.70355

Cumulative Model Updates: 45,410
Cumulative Timesteps: 378,770,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,578.52155
Policy Entropy: 3.79476
Value Function Loss: 0.03653

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.43059
Value Function Update Magnitude: 0.59602

Collected Steps per Second: 22,583.77593
Overall Steps per Second: 10,742.86658

Timestep Collection Time: 2.21495
Timestep Consumption Time: 2.44135
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.65630

Cumulative Model Updates: 45,416
Cumulative Timesteps: 378,820,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 378820862...
Checkpoint 378820862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,693.89941
Policy Entropy: 3.80243
Value Function Loss: 0.03515

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.44650
Value Function Update Magnitude: 0.63721

Collected Steps per Second: 22,438.13095
Overall Steps per Second: 10,666.39962

Timestep Collection Time: 2.22915
Timestep Consumption Time: 2.46015
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.68930

Cumulative Model Updates: 45,422
Cumulative Timesteps: 378,870,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,729.19385
Policy Entropy: 3.80697
Value Function Loss: 0.03466

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.48819
Value Function Update Magnitude: 0.69118

Collected Steps per Second: 22,918.79498
Overall Steps per Second: 10,845.79502

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.42866
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61045

Cumulative Model Updates: 45,428
Cumulative Timesteps: 378,920,884

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 378920884...
Checkpoint 378920884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,697.55643
Policy Entropy: 3.80850
Value Function Loss: 0.03505

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.53814
Value Function Update Magnitude: 0.72215

Collected Steps per Second: 22,480.54623
Overall Steps per Second: 10,670.30577

Timestep Collection Time: 2.22530
Timestep Consumption Time: 2.46304
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.68834

Cumulative Model Updates: 45,434
Cumulative Timesteps: 378,970,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,561.07468
Policy Entropy: 3.80242
Value Function Loss: 0.03614

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.55709
Value Function Update Magnitude: 0.76472

Collected Steps per Second: 22,666.49187
Overall Steps per Second: 10,650.26194

Timestep Collection Time: 2.20599
Timestep Consumption Time: 2.48892
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69491

Cumulative Model Updates: 45,440
Cumulative Timesteps: 379,020,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 379020912...
Checkpoint 379020912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,004.66683
Policy Entropy: 3.79531
Value Function Loss: 0.03641

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.54002
Value Function Update Magnitude: 0.77307

Collected Steps per Second: 22,175.68264
Overall Steps per Second: 10,491.72524

Timestep Collection Time: 2.25490
Timestep Consumption Time: 2.51114
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.76604

Cumulative Model Updates: 45,446
Cumulative Timesteps: 379,070,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,712.54817
Policy Entropy: 3.78820
Value Function Loss: 0.03767

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.49793
Value Function Update Magnitude: 0.75994

Collected Steps per Second: 22,233.09758
Overall Steps per Second: 10,508.19036

Timestep Collection Time: 2.24953
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.75953

Cumulative Model Updates: 45,452
Cumulative Timesteps: 379,120,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 379120930...
Checkpoint 379120930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,641.13766
Policy Entropy: 3.79124
Value Function Loss: 0.03875

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06792
Policy Update Magnitude: 0.47414
Value Function Update Magnitude: 0.78349

Collected Steps per Second: 22,172.77797
Overall Steps per Second: 10,515.28933

Timestep Collection Time: 2.25574
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.75650

Cumulative Model Updates: 45,458
Cumulative Timesteps: 379,170,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,280.53365
Policy Entropy: 3.77664
Value Function Loss: 0.03909

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05867
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.80735

Collected Steps per Second: 22,518.50432
Overall Steps per Second: 10,550.05116

Timestep Collection Time: 2.22075
Timestep Consumption Time: 2.51932
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.74007

Cumulative Model Updates: 45,464
Cumulative Timesteps: 379,220,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 379220954...
Checkpoint 379220954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.09205
Policy Entropy: 3.77448
Value Function Loss: 0.03890

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06048
Policy Update Magnitude: 0.59736
Value Function Update Magnitude: 0.80435

Collected Steps per Second: 22,217.61515
Overall Steps per Second: 10,549.49618

Timestep Collection Time: 2.25065
Timestep Consumption Time: 2.48930
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.73994

Cumulative Model Updates: 45,470
Cumulative Timesteps: 379,270,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252.58458
Policy Entropy: 3.76107
Value Function Loss: 0.04126

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06298
Policy Update Magnitude: 0.59207
Value Function Update Magnitude: 0.77064

Collected Steps per Second: 22,541.74741
Overall Steps per Second: 10,540.61157

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.52646
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.74546

Cumulative Model Updates: 45,476
Cumulative Timesteps: 379,320,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 379320978...
Checkpoint 379320978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,446.00421
Policy Entropy: 3.76650
Value Function Loss: 0.04394

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10282
Policy Update Magnitude: 0.52882
Value Function Update Magnitude: 0.67297

Collected Steps per Second: 21,677.34372
Overall Steps per Second: 10,469.44879

Timestep Collection Time: 2.30794
Timestep Consumption Time: 2.47073
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.77867

Cumulative Model Updates: 45,482
Cumulative Timesteps: 379,371,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,942.06094
Policy Entropy: 3.74285
Value Function Loss: 0.04481

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11806
Policy Update Magnitude: 0.45151
Value Function Update Magnitude: 0.61637

Collected Steps per Second: 22,156.57083
Overall Steps per Second: 10,582.47851

Timestep Collection Time: 2.25748
Timestep Consumption Time: 2.46901
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.72649

Cumulative Model Updates: 45,488
Cumulative Timesteps: 379,421,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 379421026...
Checkpoint 379421026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,970.50390
Policy Entropy: 3.74961
Value Function Loss: 0.04259

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.41728
Value Function Update Magnitude: 0.60532

Collected Steps per Second: 21,711.08667
Overall Steps per Second: 10,363.88052

Timestep Collection Time: 2.30316
Timestep Consumption Time: 2.52168
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.82483

Cumulative Model Updates: 45,494
Cumulative Timesteps: 379,471,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,321.69785
Policy Entropy: 3.75420
Value Function Loss: 0.04252

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.45290
Value Function Update Magnitude: 0.58383

Collected Steps per Second: 21,916.72861
Overall Steps per Second: 10,453.09043

Timestep Collection Time: 2.28191
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.78442

Cumulative Model Updates: 45,500
Cumulative Timesteps: 379,521,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 379521042...
Checkpoint 379521042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,221.81987
Policy Entropy: 3.76969
Value Function Loss: 0.04260

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.45900
Value Function Update Magnitude: 0.68552

Collected Steps per Second: 21,952.87227
Overall Steps per Second: 10,427.05988

Timestep Collection Time: 2.27779
Timestep Consumption Time: 2.51781
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.79560

Cumulative Model Updates: 45,506
Cumulative Timesteps: 379,571,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,264.85337
Policy Entropy: 3.77437
Value Function Loss: 0.04351

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.46005
Value Function Update Magnitude: 0.73153

Collected Steps per Second: 21,959.18920
Overall Steps per Second: 10,547.84249

Timestep Collection Time: 2.27695
Timestep Consumption Time: 2.46335
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74031

Cumulative Model Updates: 45,512
Cumulative Timesteps: 379,621,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 379621046...
Checkpoint 379621046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,401.16614
Policy Entropy: 3.77607
Value Function Loss: 0.04336

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.45426
Value Function Update Magnitude: 0.75849

Collected Steps per Second: 21,526.51037
Overall Steps per Second: 10,310.12800

Timestep Collection Time: 2.32281
Timestep Consumption Time: 2.52698
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.84979

Cumulative Model Updates: 45,518
Cumulative Timesteps: 379,671,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,766.29984
Policy Entropy: 3.75795
Value Function Loss: 0.04396

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.41187
Value Function Update Magnitude: 0.84998

Collected Steps per Second: 22,183.32977
Overall Steps per Second: 10,421.27475

Timestep Collection Time: 2.25494
Timestep Consumption Time: 2.54505
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.79999

Cumulative Model Updates: 45,524
Cumulative Timesteps: 379,721,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 379721070...
Checkpoint 379721070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,162.59315
Policy Entropy: 3.75159
Value Function Loss: 0.04578

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.11889
Policy Update Magnitude: 0.35916
Value Function Update Magnitude: 0.80481

Collected Steps per Second: 21,755.73137
Overall Steps per Second: 10,466.34870

Timestep Collection Time: 2.29898
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.77874

Cumulative Model Updates: 45,530
Cumulative Timesteps: 379,771,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,070.22176
Policy Entropy: 3.75811
Value Function Loss: 0.04723

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08275
Policy Update Magnitude: 0.42294
Value Function Update Magnitude: 0.76745

Collected Steps per Second: 22,299.21745
Overall Steps per Second: 10,497.34145

Timestep Collection Time: 2.24349
Timestep Consumption Time: 2.52229
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.76578

Cumulative Model Updates: 45,536
Cumulative Timesteps: 379,821,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 379821114...
Checkpoint 379821114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,868.14522
Policy Entropy: 3.75318
Value Function Loss: 0.04846

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.45015
Value Function Update Magnitude: 0.76998

Collected Steps per Second: 21,687.86083
Overall Steps per Second: 10,341.59590

Timestep Collection Time: 2.30571
Timestep Consumption Time: 2.52971
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.83542

Cumulative Model Updates: 45,542
Cumulative Timesteps: 379,871,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,448.65441
Policy Entropy: 3.75046
Value Function Loss: 0.04844

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.46694
Value Function Update Magnitude: 0.73374

Collected Steps per Second: 22,450.16280
Overall Steps per Second: 10,540.77933

Timestep Collection Time: 2.22742
Timestep Consumption Time: 2.51663
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.74405

Cumulative Model Updates: 45,548
Cumulative Timesteps: 379,921,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 379921126...
Checkpoint 379921126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,677.37242
Policy Entropy: 3.74860
Value Function Loss: 0.05044

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.46863
Value Function Update Magnitude: 0.73561

Collected Steps per Second: 22,122.11797
Overall Steps per Second: 10,414.28892

Timestep Collection Time: 2.26118
Timestep Consumption Time: 2.54203
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.80321

Cumulative Model Updates: 45,554
Cumulative Timesteps: 379,971,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,240.93403
Policy Entropy: 3.76106
Value Function Loss: 0.04800

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.47331
Value Function Update Magnitude: 0.77931

Collected Steps per Second: 22,469.56649
Overall Steps per Second: 10,502.48067

Timestep Collection Time: 2.22550
Timestep Consumption Time: 2.53585
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.76135

Cumulative Model Updates: 45,560
Cumulative Timesteps: 380,021,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 380021154...
Checkpoint 380021154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,665.05503
Policy Entropy: 3.75390
Value Function Loss: 0.04741

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.51767
Value Function Update Magnitude: 0.78167

Collected Steps per Second: 21,647.92046
Overall Steps per Second: 10,360.67891

Timestep Collection Time: 2.31024
Timestep Consumption Time: 2.51685
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.82710

Cumulative Model Updates: 45,566
Cumulative Timesteps: 380,071,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,619.39089
Policy Entropy: 3.74492
Value Function Loss: 0.04656

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.54632
Value Function Update Magnitude: 0.82688

Collected Steps per Second: 21,521.91628
Overall Steps per Second: 10,203.50690

Timestep Collection Time: 2.32321
Timestep Consumption Time: 2.57706
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.90028

Cumulative Model Updates: 45,572
Cumulative Timesteps: 380,121,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 380121166...
Checkpoint 380121166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,760.88679
Policy Entropy: 3.74983
Value Function Loss: 0.04591

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.56519
Value Function Update Magnitude: 0.87232

Collected Steps per Second: 19,653.39894
Overall Steps per Second: 9,757.23918

Timestep Collection Time: 2.54521
Timestep Consumption Time: 2.58145
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 5.12666

Cumulative Model Updates: 45,578
Cumulative Timesteps: 380,171,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,556.21472
Policy Entropy: 3.74608
Value Function Loss: 0.04810

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.53872
Value Function Update Magnitude: 0.86248

Collected Steps per Second: 20,205.41091
Overall Steps per Second: 9,929.52699

Timestep Collection Time: 2.47617
Timestep Consumption Time: 2.56254
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 5.03871

Cumulative Model Updates: 45,584
Cumulative Timesteps: 380,221,220

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 380221220...
Checkpoint 380221220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,904.10570
Policy Entropy: 3.73973
Value Function Loss: 0.04656

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.59019
Value Function Update Magnitude: 0.83549

Collected Steps per Second: 21,693.47656
Overall Steps per Second: 10,457.25210

Timestep Collection Time: 2.30549
Timestep Consumption Time: 2.47722
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.78271

Cumulative Model Updates: 45,590
Cumulative Timesteps: 380,271,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,886.34621
Policy Entropy: 3.72510
Value Function Loss: 0.04880

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.61367
Value Function Update Magnitude: 0.86394

Collected Steps per Second: 10,775.04883
Overall Steps per Second: 6,619.94812

Timestep Collection Time: 4.64165
Timestep Consumption Time: 2.91339
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 7.55504

Cumulative Model Updates: 45,596
Cumulative Timesteps: 380,321,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 380321248...
Checkpoint 380321248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,972.02530
Policy Entropy: 3.73973
Value Function Loss: 0.04607

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.61479
Value Function Update Magnitude: 0.87126

Collected Steps per Second: 11,996.45172
Overall Steps per Second: 7,414.33204

Timestep Collection Time: 4.16923
Timestep Consumption Time: 2.57662
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 6.74585

Cumulative Model Updates: 45,602
Cumulative Timesteps: 380,371,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,200.81029
Policy Entropy: 3.74598
Value Function Loss: 0.04561

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.88911

Collected Steps per Second: 22,814.41818
Overall Steps per Second: 10,653.79710

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.50307
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.69598

Cumulative Model Updates: 45,608
Cumulative Timesteps: 380,421,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 380421294...
Checkpoint 380421294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,243.02274
Policy Entropy: 3.76718
Value Function Loss: 0.04443

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.50391
Value Function Update Magnitude: 0.89780

Collected Steps per Second: 21,253.78727
Overall Steps per Second: 10,189.24920

Timestep Collection Time: 2.35252
Timestep Consumption Time: 2.55461
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.90713

Cumulative Model Updates: 45,614
Cumulative Timesteps: 380,471,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,214.76420
Policy Entropy: 3.76196
Value Function Loss: 0.04653

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.49811
Value Function Update Magnitude: 0.86727

Collected Steps per Second: 21,439.77679
Overall Steps per Second: 10,421.38624

Timestep Collection Time: 2.33351
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.80070

Cumulative Model Updates: 45,620
Cumulative Timesteps: 380,521,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 380521324...
Checkpoint 380521324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,308.80905
Policy Entropy: 3.75102
Value Function Loss: 0.04893

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.47291
Value Function Update Magnitude: 0.84738

Collected Steps per Second: 22,283.08293
Overall Steps per Second: 10,626.46686

Timestep Collection Time: 2.24421
Timestep Consumption Time: 2.46177
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.70599

Cumulative Model Updates: 45,626
Cumulative Timesteps: 380,571,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,287.13006
Policy Entropy: 3.74265
Value Function Loss: 0.05124

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.43774
Value Function Update Magnitude: 0.76777

Collected Steps per Second: 22,936.82220
Overall Steps per Second: 10,856.77928

Timestep Collection Time: 2.18051
Timestep Consumption Time: 2.42620
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60671

Cumulative Model Updates: 45,632
Cumulative Timesteps: 380,621,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 380621346...
Checkpoint 380621346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,499.54360
Policy Entropy: 3.73751
Value Function Loss: 0.05060

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.44450
Value Function Update Magnitude: 0.72317

Collected Steps per Second: 22,174.21695
Overall Steps per Second: 10,712.56091

Timestep Collection Time: 2.25586
Timestep Consumption Time: 2.41361
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.66947

Cumulative Model Updates: 45,638
Cumulative Timesteps: 380,671,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,912.49691
Policy Entropy: 3.75082
Value Function Loss: 0.04990

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.52108
Value Function Update Magnitude: 0.64585

Collected Steps per Second: 22,909.41614
Overall Steps per Second: 10,841.12611

Timestep Collection Time: 2.18303
Timestep Consumption Time: 2.43014
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61317

Cumulative Model Updates: 45,644
Cumulative Timesteps: 380,721,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 380721380...
Checkpoint 380721380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,005.64025
Policy Entropy: 3.75360
Value Function Loss: 0.04900

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.52552
Value Function Update Magnitude: 0.66330

Collected Steps per Second: 21,949.37924
Overall Steps per Second: 10,674.74546

Timestep Collection Time: 2.27870
Timestep Consumption Time: 2.40675
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.68545

Cumulative Model Updates: 45,650
Cumulative Timesteps: 380,771,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,410.49236
Policy Entropy: 3.76405
Value Function Loss: 0.04749

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.49660
Value Function Update Magnitude: 0.77549

Collected Steps per Second: 22,145.22064
Overall Steps per Second: 10,851.53558

Timestep Collection Time: 2.25909
Timestep Consumption Time: 2.35114
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61022

Cumulative Model Updates: 45,656
Cumulative Timesteps: 380,821,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 380821424...
Checkpoint 380821424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,232.91190
Policy Entropy: 3.77364
Value Function Loss: 0.04570

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.46199
Value Function Update Magnitude: 0.81369

Collected Steps per Second: 21,523.31225
Overall Steps per Second: 10,676.60600

Timestep Collection Time: 2.32381
Timestep Consumption Time: 2.36083
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.68463

Cumulative Model Updates: 45,662
Cumulative Timesteps: 380,871,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,783.30741
Policy Entropy: 3.77487
Value Function Loss: 0.04621

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.47687
Value Function Update Magnitude: 0.86567

Collected Steps per Second: 22,206.33786
Overall Steps per Second: 10,842.56236

Timestep Collection Time: 2.25197
Timestep Consumption Time: 2.36022
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.61219

Cumulative Model Updates: 45,668
Cumulative Timesteps: 380,921,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 380921448...
Checkpoint 380921448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,014.75910
Policy Entropy: 3.78262
Value Function Loss: 0.04483

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.46543
Value Function Update Magnitude: 0.87599

Collected Steps per Second: 21,668.90584
Overall Steps per Second: 10,734.80748

Timestep Collection Time: 2.30948
Timestep Consumption Time: 2.35236
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.66184

Cumulative Model Updates: 45,674
Cumulative Timesteps: 380,971,492

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,397.89514
Policy Entropy: 3.76520
Value Function Loss: 0.04536

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.48935
Value Function Update Magnitude: 0.85545

Collected Steps per Second: 22,071.67308
Overall Steps per Second: 10,797.15426

Timestep Collection Time: 2.26553
Timestep Consumption Time: 2.36569
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.63122

Cumulative Model Updates: 45,680
Cumulative Timesteps: 381,021,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 381021496...
Checkpoint 381021496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,260.02850
Policy Entropy: 3.76503
Value Function Loss: 0.04590

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.58596
Value Function Update Magnitude: 0.79762

Collected Steps per Second: 21,586.06428
Overall Steps per Second: 10,452.74008

Timestep Collection Time: 2.31696
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.78477

Cumulative Model Updates: 45,686
Cumulative Timesteps: 381,071,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,023.82033
Policy Entropy: 3.76896
Value Function Loss: 0.04698

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.62468
Value Function Update Magnitude: 0.68787

Collected Steps per Second: 22,829.70036
Overall Steps per Second: 10,735.11469

Timestep Collection Time: 2.19030
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.65798

Cumulative Model Updates: 45,692
Cumulative Timesteps: 381,121,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 381121514...
Checkpoint 381121514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.01988
Policy Entropy: 3.79261
Value Function Loss: 0.04534

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.56546
Value Function Update Magnitude: 0.70549

Collected Steps per Second: 22,610.33593
Overall Steps per Second: 10,647.22299

Timestep Collection Time: 2.21182
Timestep Consumption Time: 2.48518
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.69700

Cumulative Model Updates: 45,698
Cumulative Timesteps: 381,171,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,185.59004
Policy Entropy: 3.78976
Value Function Loss: 0.04208

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.50668
Value Function Update Magnitude: 0.75552

Collected Steps per Second: 22,897.21616
Overall Steps per Second: 10,938.34697

Timestep Collection Time: 2.18428
Timestep Consumption Time: 2.38807
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.57235

Cumulative Model Updates: 45,704
Cumulative Timesteps: 381,221,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 381221538...
Checkpoint 381221538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,747.76340
Policy Entropy: 3.78508
Value Function Loss: 0.04123

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.51778
Value Function Update Magnitude: 0.83487

Collected Steps per Second: 22,642.20468
Overall Steps per Second: 10,592.88539

Timestep Collection Time: 2.20906
Timestep Consumption Time: 2.51279
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.72185

Cumulative Model Updates: 45,710
Cumulative Timesteps: 381,271,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,382.93704
Policy Entropy: 3.77699
Value Function Loss: 0.04023

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.48360
Value Function Update Magnitude: 0.85423

Collected Steps per Second: 23,044.54286
Overall Steps per Second: 10,917.58297

Timestep Collection Time: 2.17032
Timestep Consumption Time: 2.41073
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.58105

Cumulative Model Updates: 45,716
Cumulative Timesteps: 381,321,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 381321570...
Checkpoint 381321570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,504.31107
Policy Entropy: 3.78038
Value Function Loss: 0.04228

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.45601
Value Function Update Magnitude: 0.79357

Collected Steps per Second: 22,691.10541
Overall Steps per Second: 10,643.88912

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.49532
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.69997

Cumulative Model Updates: 45,722
Cumulative Timesteps: 381,371,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,219.75183
Policy Entropy: 3.77946
Value Function Loss: 0.04081

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.52320
Value Function Update Magnitude: 0.66073

Collected Steps per Second: 22,799.29244
Overall Steps per Second: 10,824.40411

Timestep Collection Time: 2.19419
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.62159

Cumulative Model Updates: 45,728
Cumulative Timesteps: 381,421,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 381421622...
Checkpoint 381421622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,079.47436
Policy Entropy: 3.76975
Value Function Loss: 0.03844

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.58107
Value Function Update Magnitude: 0.66918

Collected Steps per Second: 22,264.96258
Overall Steps per Second: 10,685.93720

Timestep Collection Time: 2.24586
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.67942

Cumulative Model Updates: 45,734
Cumulative Timesteps: 381,471,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,836.59748
Policy Entropy: 3.75632
Value Function Loss: 0.03679

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07078
Policy Update Magnitude: 0.59502
Value Function Update Magnitude: 0.74024

Collected Steps per Second: 22,606.47353
Overall Steps per Second: 10,609.34136

Timestep Collection Time: 2.21308
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.71566

Cumulative Model Updates: 45,740
Cumulative Timesteps: 381,521,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 381521656...
Checkpoint 381521656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,459.08304
Policy Entropy: 3.74762
Value Function Loss: 0.03804

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06383
Policy Update Magnitude: 0.60162
Value Function Update Magnitude: 0.75966

Collected Steps per Second: 22,394.42467
Overall Steps per Second: 10,556.89143

Timestep Collection Time: 2.23413
Timestep Consumption Time: 2.50515
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.73927

Cumulative Model Updates: 45,746
Cumulative Timesteps: 381,571,688

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.88622
Policy Entropy: 3.75710
Value Function Loss: 0.03950

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06013
Policy Update Magnitude: 0.60593
Value Function Update Magnitude: 0.73486

Collected Steps per Second: 22,837.45152
Overall Steps per Second: 10,803.77591

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.43921
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62912

Cumulative Model Updates: 45,752
Cumulative Timesteps: 381,621,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 381621700...
Checkpoint 381621700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,354.21308
Policy Entropy: 3.75976
Value Function Loss: 0.04077

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05767
Policy Update Magnitude: 0.59403
Value Function Update Magnitude: 0.74071

Collected Steps per Second: 22,537.73185
Overall Steps per Second: 10,770.35119

Timestep Collection Time: 2.21948
Timestep Consumption Time: 2.42494
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.64442

Cumulative Model Updates: 45,758
Cumulative Timesteps: 381,671,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,670.33480
Policy Entropy: 3.75997
Value Function Loss: 0.04228

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06811
Policy Update Magnitude: 0.59121
Value Function Update Magnitude: 0.73918

Collected Steps per Second: 23,112.11988
Overall Steps per Second: 10,888.84477

Timestep Collection Time: 2.16484
Timestep Consumption Time: 2.43014
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.59498

Cumulative Model Updates: 45,764
Cumulative Timesteps: 381,721,756

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 381721756...
Checkpoint 381721756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,519.15520
Policy Entropy: 3.74524
Value Function Loss: 0.04392

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05884
Policy Update Magnitude: 0.59404
Value Function Update Magnitude: 0.76598

Collected Steps per Second: 22,358.16822
Overall Steps per Second: 10,606.89468

Timestep Collection Time: 2.23757
Timestep Consumption Time: 2.47898
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.71655

Cumulative Model Updates: 45,770
Cumulative Timesteps: 381,771,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,829.81018
Policy Entropy: 3.73990
Value Function Loss: 0.04323

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05368
Policy Update Magnitude: 0.62639
Value Function Update Magnitude: 0.79097

Collected Steps per Second: 23,005.47102
Overall Steps per Second: 10,670.18550

Timestep Collection Time: 2.17374
Timestep Consumption Time: 2.51296
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.68670

Cumulative Model Updates: 45,776
Cumulative Timesteps: 381,821,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 381821792...
Checkpoint 381821792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,951.93812
Policy Entropy: 3.73692
Value Function Loss: 0.04361

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06226
Policy Update Magnitude: 0.62422
Value Function Update Magnitude: 0.76217

Collected Steps per Second: 22,603.73879
Overall Steps per Second: 10,787.26520

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.63547

Cumulative Model Updates: 45,782
Cumulative Timesteps: 381,871,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,944.07819
Policy Entropy: 3.73897
Value Function Loss: 0.04276

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.60092
Value Function Update Magnitude: 0.75431

Collected Steps per Second: 22,979.42541
Overall Steps per Second: 10,711.78467

Timestep Collection Time: 2.17699
Timestep Consumption Time: 2.49319
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.67018

Cumulative Model Updates: 45,788
Cumulative Timesteps: 381,921,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 381921822...
Checkpoint 381921822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,369.43399
Policy Entropy: 3.73596
Value Function Loss: 0.04337

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.52525
Value Function Update Magnitude: 0.69595

Collected Steps per Second: 22,678.92693
Overall Steps per Second: 10,851.88608

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.40319
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.60823

Cumulative Model Updates: 45,794
Cumulative Timesteps: 381,971,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.58480
Policy Entropy: 3.73395
Value Function Loss: 0.04576

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.57531
Value Function Update Magnitude: 0.60738

Collected Steps per Second: 22,905.66011
Overall Steps per Second: 10,723.63848

Timestep Collection Time: 2.18357
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.66409

Cumulative Model Updates: 45,800
Cumulative Timesteps: 382,021,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 382021846...
Checkpoint 382021846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,107.92383
Policy Entropy: 3.73492
Value Function Loss: 0.04657

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.57348
Value Function Update Magnitude: 0.63447

Collected Steps per Second: 22,559.38302
Overall Steps per Second: 10,652.48516

Timestep Collection Time: 2.21690
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.69487

Cumulative Model Updates: 45,806
Cumulative Timesteps: 382,071,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,465.26577
Policy Entropy: 3.73732
Value Function Loss: 0.04667

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.50771
Value Function Update Magnitude: 0.77570

Collected Steps per Second: 23,091.71836
Overall Steps per Second: 10,692.03713

Timestep Collection Time: 2.16571
Timestep Consumption Time: 2.51160
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.67731

Cumulative Model Updates: 45,812
Cumulative Timesteps: 382,121,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 382121868...
Checkpoint 382121868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,332.43362
Policy Entropy: 3.75226
Value Function Loss: 0.04286

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.56255
Value Function Update Magnitude: 0.79762

Collected Steps per Second: 22,430.64014
Overall Steps per Second: 10,650.27232

Timestep Collection Time: 2.23097
Timestep Consumption Time: 2.46769
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.69866

Cumulative Model Updates: 45,818
Cumulative Timesteps: 382,171,910

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,143.22568
Policy Entropy: 3.75045
Value Function Loss: 0.04291

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07234
Policy Update Magnitude: 0.59748
Value Function Update Magnitude: 0.76070

Collected Steps per Second: 22,917.88537
Overall Steps per Second: 10,834.19018

Timestep Collection Time: 2.18214
Timestep Consumption Time: 2.43380
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61594

Cumulative Model Updates: 45,824
Cumulative Timesteps: 382,221,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 382221920...
Checkpoint 382221920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,492.87478
Policy Entropy: 3.75038
Value Function Loss: 0.04398

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05609
Policy Update Magnitude: 0.60660
Value Function Update Magnitude: 0.60562

Collected Steps per Second: 22,496.65574
Overall Steps per Second: 10,802.11595

Timestep Collection Time: 2.22389
Timestep Consumption Time: 2.40761
PPO Batch Consumption Time: 0.27550
Total Iteration Time: 4.63150

Cumulative Model Updates: 45,830
Cumulative Timesteps: 382,271,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,279.36375
Policy Entropy: 3.73571
Value Function Loss: 0.04704

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05556
Policy Update Magnitude: 0.63164
Value Function Update Magnitude: 0.51981

Collected Steps per Second: 23,097.99143
Overall Steps per Second: 10,810.36239

Timestep Collection Time: 2.16530
Timestep Consumption Time: 2.46119
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.62649

Cumulative Model Updates: 45,836
Cumulative Timesteps: 382,321,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 382321964...
Checkpoint 382321964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,613.96516
Policy Entropy: 3.73090
Value Function Loss: 0.04732

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.58627
Value Function Update Magnitude: 0.52574

Collected Steps per Second: 22,446.82912
Overall Steps per Second: 10,638.03567

Timestep Collection Time: 2.22856
Timestep Consumption Time: 2.47382
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.70237

Cumulative Model Updates: 45,842
Cumulative Timesteps: 382,371,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,926.20756
Policy Entropy: 3.73970
Value Function Loss: 0.04692

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.49832
Value Function Update Magnitude: 0.61442

Collected Steps per Second: 23,104.76026
Overall Steps per Second: 10,854.08231

Timestep Collection Time: 2.16432
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60711

Cumulative Model Updates: 45,848
Cumulative Timesteps: 382,421,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 382421994...
Checkpoint 382421994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,559.79447
Policy Entropy: 3.74044
Value Function Loss: 0.04633

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.60083

Collected Steps per Second: 22,313.48126
Overall Steps per Second: 10,731.09460

Timestep Collection Time: 2.24160
Timestep Consumption Time: 2.41943
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.66103

Cumulative Model Updates: 45,854
Cumulative Timesteps: 382,472,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,487.06576
Policy Entropy: 3.74465
Value Function Loss: 0.04631

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.60247
Value Function Update Magnitude: 0.67924

Collected Steps per Second: 23,047.83629
Overall Steps per Second: 10,888.49416

Timestep Collection Time: 2.17027
Timestep Consumption Time: 2.42357
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.59384

Cumulative Model Updates: 45,860
Cumulative Timesteps: 382,522,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 382522032...
Checkpoint 382522032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,504.36086
Policy Entropy: 3.75170
Value Function Loss: 0.04514

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.58074
Value Function Update Magnitude: 0.77937

Collected Steps per Second: 22,491.16871
Overall Steps per Second: 10,636.72423

Timestep Collection Time: 2.22425
Timestep Consumption Time: 2.47889
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.70314

Cumulative Model Updates: 45,866
Cumulative Timesteps: 382,572,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,913.81005
Policy Entropy: 3.73358
Value Function Loss: 0.04429

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.80200

Collected Steps per Second: 23,047.29326
Overall Steps per Second: 10,851.27650

Timestep Collection Time: 2.17006
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.60904

Cumulative Model Updates: 45,872
Cumulative Timesteps: 382,622,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 382622072...
Checkpoint 382622072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,251.59771
Policy Entropy: 3.73667
Value Function Loss: 0.04204

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.46514
Value Function Update Magnitude: 0.79783

Collected Steps per Second: 22,352.50659
Overall Steps per Second: 10,745.99905

Timestep Collection Time: 2.23796
Timestep Consumption Time: 2.41717
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.65513

Cumulative Model Updates: 45,878
Cumulative Timesteps: 382,672,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,688.85647
Policy Entropy: 3.73278
Value Function Loss: 0.04285

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.41330
Value Function Update Magnitude: 0.78447

Collected Steps per Second: 23,140.78929
Overall Steps per Second: 10,901.39882

Timestep Collection Time: 2.16198
Timestep Consumption Time: 2.42734
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.58932

Cumulative Model Updates: 45,884
Cumulative Timesteps: 382,722,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 382722126...
Checkpoint 382722126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,404.30015
Policy Entropy: 3.74477
Value Function Loss: 0.04389

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.42122
Value Function Update Magnitude: 0.74419

Collected Steps per Second: 22,434.01535
Overall Steps per Second: 10,612.21388

Timestep Collection Time: 2.23072
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.71570

Cumulative Model Updates: 45,890
Cumulative Timesteps: 382,772,170

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,532.05540
Policy Entropy: 3.74092
Value Function Loss: 0.04680

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.41427
Value Function Update Magnitude: 0.63977

Collected Steps per Second: 22,961.51903
Overall Steps per Second: 10,842.99753

Timestep Collection Time: 2.17825
Timestep Consumption Time: 2.43449
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61275

Cumulative Model Updates: 45,896
Cumulative Timesteps: 382,822,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 382822186...
Checkpoint 382822186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,963.99224
Policy Entropy: 3.73767
Value Function Loss: 0.04820

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.40557
Value Function Update Magnitude: 0.65304

Collected Steps per Second: 21,775.94219
Overall Steps per Second: 10,759.57622

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.35176
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.64870

Cumulative Model Updates: 45,902
Cumulative Timesteps: 382,872,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,657.57047
Policy Entropy: 3.72599
Value Function Loss: 0.04806

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.41286
Value Function Update Magnitude: 0.69732

Collected Steps per Second: 22,298.77749
Overall Steps per Second: 10,888.25169

Timestep Collection Time: 2.24317
Timestep Consumption Time: 2.35077
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.59394

Cumulative Model Updates: 45,908
Cumulative Timesteps: 382,922,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 382922224...
Checkpoint 382922224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,866.77098
Policy Entropy: 3.72432
Value Function Loss: 0.04859

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.42550
Value Function Update Magnitude: 0.81533

Collected Steps per Second: 21,744.36463
Overall Steps per Second: 10,618.90753

Timestep Collection Time: 2.30009
Timestep Consumption Time: 2.40981
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.70990

Cumulative Model Updates: 45,914
Cumulative Timesteps: 382,972,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.70311
Policy Entropy: 3.72371
Value Function Loss: 0.04857

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.48148
Value Function Update Magnitude: 0.85893

Collected Steps per Second: 22,121.77457
Overall Steps per Second: 10,847.33631

Timestep Collection Time: 2.26121
Timestep Consumption Time: 2.35024
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.61145

Cumulative Model Updates: 45,920
Cumulative Timesteps: 383,022,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 383022260...
Checkpoint 383022260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.69205
Policy Entropy: 3.71153
Value Function Loss: 0.04804

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.53709
Value Function Update Magnitude: 0.86837

Collected Steps per Second: 21,892.17491
Overall Steps per Second: 10,717.28639

Timestep Collection Time: 2.28538
Timestep Consumption Time: 2.38296
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.66835

Cumulative Model Updates: 45,926
Cumulative Timesteps: 383,072,292

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.18946
Policy Entropy: 3.71319
Value Function Loss: 0.04799

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.47897
Value Function Update Magnitude: 0.84479

Collected Steps per Second: 22,222.14125
Overall Steps per Second: 10,862.81014

Timestep Collection Time: 2.25046
Timestep Consumption Time: 2.35332
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.60378

Cumulative Model Updates: 45,932
Cumulative Timesteps: 383,122,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 383122302...
Checkpoint 383122302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,478.76194
Policy Entropy: 3.72900
Value Function Loss: 0.04809

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.44216
Value Function Update Magnitude: 0.85212

Collected Steps per Second: 22,040.47932
Overall Steps per Second: 10,704.48865

Timestep Collection Time: 2.26919
Timestep Consumption Time: 2.40306
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.67225

Cumulative Model Updates: 45,938
Cumulative Timesteps: 383,172,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,728.79596
Policy Entropy: 3.74309
Value Function Loss: 0.04749

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.44950
Value Function Update Magnitude: 0.84781

Collected Steps per Second: 23,097.88527
Overall Steps per Second: 10,860.48883

Timestep Collection Time: 2.16496
Timestep Consumption Time: 2.43944
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.60440

Cumulative Model Updates: 45,944
Cumulative Timesteps: 383,222,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 383222322...
Checkpoint 383222322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,282.99387
Policy Entropy: 3.73846
Value Function Loss: 0.04731

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.45652
Value Function Update Magnitude: 0.82440

Collected Steps per Second: 22,076.82690
Overall Steps per Second: 10,648.82108

Timestep Collection Time: 2.26518
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.69611

Cumulative Model Updates: 45,950
Cumulative Timesteps: 383,272,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,047.78784
Policy Entropy: 3.74377
Value Function Loss: 0.04641

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.46827
Value Function Update Magnitude: 0.75682

Collected Steps per Second: 22,818.88051
Overall Steps per Second: 10,862.86040

Timestep Collection Time: 2.19161
Timestep Consumption Time: 2.41215
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60376

Cumulative Model Updates: 45,956
Cumulative Timesteps: 383,322,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 383322340...
Checkpoint 383322340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,976.04166
Policy Entropy: 3.75602
Value Function Loss: 0.04595

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.48877
Value Function Update Magnitude: 0.72335

Collected Steps per Second: 22,427.86857
Overall Steps per Second: 10,655.18523

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.46367
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.69349

Cumulative Model Updates: 45,962
Cumulative Timesteps: 383,372,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,342.89429
Policy Entropy: 3.75116
Value Function Loss: 0.04566

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.48971
Value Function Update Magnitude: 0.69307

Collected Steps per Second: 23,087.16028
Overall Steps per Second: 10,966.66700

Timestep Collection Time: 2.16683
Timestep Consumption Time: 2.39481
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.56164

Cumulative Model Updates: 45,968
Cumulative Timesteps: 383,422,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 383422376...
Checkpoint 383422376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,856.34518
Policy Entropy: 3.74343
Value Function Loss: 0.04537

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.51350
Value Function Update Magnitude: 0.72579

Collected Steps per Second: 22,349.59614
Overall Steps per Second: 10,617.06359

Timestep Collection Time: 2.23780
Timestep Consumption Time: 2.47292
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.71072

Cumulative Model Updates: 45,974
Cumulative Timesteps: 383,472,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,846.35914
Policy Entropy: 3.73763
Value Function Loss: 0.04517

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.47962
Value Function Update Magnitude: 0.75763

Collected Steps per Second: 22,772.74828
Overall Steps per Second: 10,854.60718

Timestep Collection Time: 2.19649
Timestep Consumption Time: 2.41170
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60818

Cumulative Model Updates: 45,980
Cumulative Timesteps: 383,522,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 383522410...
Checkpoint 383522410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,141.43432
Policy Entropy: 3.74079
Value Function Loss: 0.04239

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.47993
Value Function Update Magnitude: 0.76233

Collected Steps per Second: 22,411.09428
Overall Steps per Second: 10,682.03157

Timestep Collection Time: 2.23175
Timestep Consumption Time: 2.45050
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.68226

Cumulative Model Updates: 45,986
Cumulative Timesteps: 383,572,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.37620
Policy Entropy: 3.74761
Value Function Loss: 0.04443

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.49010
Value Function Update Magnitude: 0.71238

Collected Steps per Second: 22,610.87437
Overall Steps per Second: 10,649.19311

Timestep Collection Time: 2.21239
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.69745

Cumulative Model Updates: 45,992
Cumulative Timesteps: 383,622,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 383622450...
Checkpoint 383622450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,806.18979
Policy Entropy: 3.74859
Value Function Loss: 0.04654

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.52879
Value Function Update Magnitude: 0.66593

Collected Steps per Second: 22,507.47287
Overall Steps per Second: 10,631.91404

Timestep Collection Time: 2.22237
Timestep Consumption Time: 2.48233
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.70470

Cumulative Model Updates: 45,998
Cumulative Timesteps: 383,672,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,878.95609
Policy Entropy: 3.73470
Value Function Loss: 0.04837

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.60080
Value Function Update Magnitude: 0.62759

Collected Steps per Second: 23,237.61373
Overall Steps per Second: 10,702.41746

Timestep Collection Time: 2.15229
Timestep Consumption Time: 2.52086
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.67315

Cumulative Model Updates: 46,004
Cumulative Timesteps: 383,722,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 383722484...
Checkpoint 383722484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,561.68985
Policy Entropy: 3.71680
Value Function Loss: 0.04920

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.55933
Value Function Update Magnitude: 0.61084

Collected Steps per Second: 22,577.09370
Overall Steps per Second: 10,642.55772

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.48368
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.69849

Cumulative Model Updates: 46,010
Cumulative Timesteps: 383,772,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,127.64438
Policy Entropy: 3.71816
Value Function Loss: 0.04989

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.51906
Value Function Update Magnitude: 0.57615

Collected Steps per Second: 22,979.81743
Overall Steps per Second: 10,849.15440

Timestep Collection Time: 2.17600
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.60902

Cumulative Model Updates: 46,016
Cumulative Timesteps: 383,822,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 383822492...
Checkpoint 383822492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.67587
Policy Entropy: 3.72972
Value Function Loss: 0.04993

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.50196
Value Function Update Magnitude: 0.63545

Collected Steps per Second: 22,111.50550
Overall Steps per Second: 10,637.37295

Timestep Collection Time: 2.26145
Timestep Consumption Time: 2.43934
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.70078

Cumulative Model Updates: 46,022
Cumulative Timesteps: 383,872,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,251.25144
Policy Entropy: 3.75058
Value Function Loss: 0.04902

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.46532
Value Function Update Magnitude: 0.71539

Collected Steps per Second: 22,839.84408
Overall Steps per Second: 10,642.72766

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.50919
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.69861

Cumulative Model Updates: 46,028
Cumulative Timesteps: 383,922,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 383922502...
Checkpoint 383922502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,315.52061
Policy Entropy: 3.75953
Value Function Loss: 0.04688

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.43341
Value Function Update Magnitude: 0.76660

Collected Steps per Second: 22,528.61901
Overall Steps per Second: 10,691.55428

Timestep Collection Time: 2.21993
Timestep Consumption Time: 2.45778
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.67771

Cumulative Model Updates: 46,034
Cumulative Timesteps: 383,972,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,008.65722
Policy Entropy: 3.74653
Value Function Loss: 0.04540

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.43920
Value Function Update Magnitude: 0.77911

Collected Steps per Second: 23,015.57829
Overall Steps per Second: 10,734.80572

Timestep Collection Time: 2.17288
Timestep Consumption Time: 2.48580
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.65868

Cumulative Model Updates: 46,040
Cumulative Timesteps: 384,022,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 384022524...
Checkpoint 384022524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,468.29883
Policy Entropy: 3.74586
Value Function Loss: 0.04292

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.46217
Value Function Update Magnitude: 0.79453

Collected Steps per Second: 22,491.09319
Overall Steps per Second: 10,631.63977

Timestep Collection Time: 2.22364
Timestep Consumption Time: 2.48044
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.70407

Cumulative Model Updates: 46,046
Cumulative Timesteps: 384,072,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,277.56669
Policy Entropy: 3.74071
Value Function Loss: 0.04556

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.44860
Value Function Update Magnitude: 0.79104

Collected Steps per Second: 22,930.00155
Overall Steps per Second: 10,833.51202

Timestep Collection Time: 2.18273
Timestep Consumption Time: 2.43719
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.61992

Cumulative Model Updates: 46,052
Cumulative Timesteps: 384,122,586

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 384122586...
Checkpoint 384122586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,716.43949
Policy Entropy: 3.75199
Value Function Loss: 0.04588

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.47458
Value Function Update Magnitude: 0.78898

Collected Steps per Second: 22,465.43308
Overall Steps per Second: 10,732.20503

Timestep Collection Time: 2.22671
Timestep Consumption Time: 2.43440
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.66111

Cumulative Model Updates: 46,058
Cumulative Timesteps: 384,172,610

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,232.37243
Policy Entropy: 3.75358
Value Function Loss: 0.04799

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.48884
Value Function Update Magnitude: 0.79749

Collected Steps per Second: 22,754.24110
Overall Steps per Second: 10,813.20133

Timestep Collection Time: 2.19854
Timestep Consumption Time: 2.42785
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62638

Cumulative Model Updates: 46,064
Cumulative Timesteps: 384,222,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 384222636...
Checkpoint 384222636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,655.96042
Policy Entropy: 3.75639
Value Function Loss: 0.04719

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.50039
Value Function Update Magnitude: 0.82648

Collected Steps per Second: 22,443.76524
Overall Steps per Second: 10,749.20996

Timestep Collection Time: 2.22788
Timestep Consumption Time: 2.42381
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.65169

Cumulative Model Updates: 46,070
Cumulative Timesteps: 384,272,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,823.69896
Policy Entropy: 3.76216
Value Function Loss: 0.04410

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.50462
Value Function Update Magnitude: 0.83802

Collected Steps per Second: 23,027.24489
Overall Steps per Second: 10,852.36114

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.43839
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.61190

Cumulative Model Updates: 46,076
Cumulative Timesteps: 384,322,688

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 384322688...
Checkpoint 384322688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,732.31406
Policy Entropy: 3.76968
Value Function Loss: 0.04299

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.50604
Value Function Update Magnitude: 0.83338

Collected Steps per Second: 22,432.73398
Overall Steps per Second: 10,652.20170

Timestep Collection Time: 2.22969
Timestep Consumption Time: 2.46587
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.69556

Cumulative Model Updates: 46,082
Cumulative Timesteps: 384,372,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.67189
Policy Entropy: 3.76711
Value Function Loss: 0.04434

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08256
Policy Update Magnitude: 0.56940
Value Function Update Magnitude: 0.82451

Collected Steps per Second: 23,182.11174
Overall Steps per Second: 10,880.55190

Timestep Collection Time: 2.15727
Timestep Consumption Time: 2.43901
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.59627

Cumulative Model Updates: 46,088
Cumulative Timesteps: 384,422,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 384422716...
Checkpoint 384422716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,632.58473
Policy Entropy: 3.77234
Value Function Loss: 0.04590

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.84789

Collected Steps per Second: 22,554.96109
Overall Steps per Second: 10,682.83373

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.46429
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.68172

Cumulative Model Updates: 46,094
Cumulative Timesteps: 384,472,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,509.94973
Policy Entropy: 3.76450
Value Function Loss: 0.04756

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.51006
Value Function Update Magnitude: 0.83022

Collected Steps per Second: 23,254.18815
Overall Steps per Second: 10,904.35314

Timestep Collection Time: 2.15135
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58789

Cumulative Model Updates: 46,100
Cumulative Timesteps: 384,522,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 384522758...
Checkpoint 384522758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,685.65192
Policy Entropy: 3.76650
Value Function Loss: 0.04929

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07154
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.78953

Collected Steps per Second: 22,001.99992
Overall Steps per Second: 10,619.04120

Timestep Collection Time: 2.27379
Timestep Consumption Time: 2.43737
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.71116

Cumulative Model Updates: 46,106
Cumulative Timesteps: 384,572,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,986.32269
Policy Entropy: 3.78087
Value Function Loss: 0.04788

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.59941
Value Function Update Magnitude: 0.81493

Collected Steps per Second: 22,214.02639
Overall Steps per Second: 10,852.67160

Timestep Collection Time: 2.25155
Timestep Consumption Time: 2.35708
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60863

Cumulative Model Updates: 46,112
Cumulative Timesteps: 384,622,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 384622802...
Checkpoint 384622802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,966.64479
Policy Entropy: 3.78680
Value Function Loss: 0.04622

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10077
Policy Update Magnitude: 0.55730
Value Function Update Magnitude: 0.81799

Collected Steps per Second: 21,639.90403
Overall Steps per Second: 10,716.30908

Timestep Collection Time: 2.31101
Timestep Consumption Time: 2.35571
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.66672

Cumulative Model Updates: 46,118
Cumulative Timesteps: 384,672,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,320.65421
Policy Entropy: 3.78848
Value Function Loss: 0.04466

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.50474
Value Function Update Magnitude: 0.81704

Collected Steps per Second: 22,141.54316
Overall Steps per Second: 10,823.97007

Timestep Collection Time: 2.25910
Timestep Consumption Time: 2.36212
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62122

Cumulative Model Updates: 46,124
Cumulative Timesteps: 384,722,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 384722832...
Checkpoint 384722832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,333.70497
Policy Entropy: 3.76157
Value Function Loss: 0.04431

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.49574
Value Function Update Magnitude: 0.77885

Collected Steps per Second: 21,817.43195
Overall Steps per Second: 10,632.25169

Timestep Collection Time: 2.29275
Timestep Consumption Time: 2.41199
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.70474

Cumulative Model Updates: 46,130
Cumulative Timesteps: 384,772,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,969.82018
Policy Entropy: 3.75533
Value Function Loss: 0.04499

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07223
Policy Update Magnitude: 0.51352
Value Function Update Magnitude: 0.78853

Collected Steps per Second: 22,662.94958
Overall Steps per Second: 10,685.45578

Timestep Collection Time: 2.20739
Timestep Consumption Time: 2.47430
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.68169

Cumulative Model Updates: 46,136
Cumulative Timesteps: 384,822,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 384822880...
Checkpoint 384822880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,340.27983
Policy Entropy: 3.75427
Value Function Loss: 0.04698

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.81956

Collected Steps per Second: 22,590.53559
Overall Steps per Second: 10,719.35478

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.45183
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.66577

Cumulative Model Updates: 46,142
Cumulative Timesteps: 384,872,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,786.25447
Policy Entropy: 3.75280
Value Function Loss: 0.04710

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.58486
Value Function Update Magnitude: 0.81892

Collected Steps per Second: 22,944.70925
Overall Steps per Second: 10,716.93230

Timestep Collection Time: 2.17994
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.66719

Cumulative Model Updates: 46,148
Cumulative Timesteps: 384,922,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 384922912...
Checkpoint 384922912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,841.26553
Policy Entropy: 3.75552
Value Function Loss: 0.04791

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.59836
Value Function Update Magnitude: 0.70754

Collected Steps per Second: 22,628.01758
Overall Steps per Second: 10,640.18549

Timestep Collection Time: 2.20992
Timestep Consumption Time: 2.48981
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.69973

Cumulative Model Updates: 46,154
Cumulative Timesteps: 384,972,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,282.47313
Policy Entropy: 3.75438
Value Function Loss: 0.04989

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09537
Policy Update Magnitude: 0.51163
Value Function Update Magnitude: 0.65759

Collected Steps per Second: 22,931.03323
Overall Steps per Second: 10,820.49891

Timestep Collection Time: 2.18167
Timestep Consumption Time: 2.44177
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.62345

Cumulative Model Updates: 46,160
Cumulative Timesteps: 385,022,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 385022946...
Checkpoint 385022946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,204.48492
Policy Entropy: 3.74408
Value Function Loss: 0.05057

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.47656
Value Function Update Magnitude: 0.70630

Collected Steps per Second: 22,434.00524
Overall Steps per Second: 10,736.54580

Timestep Collection Time: 2.22947
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.65848

Cumulative Model Updates: 46,166
Cumulative Timesteps: 385,072,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,400.66132
Policy Entropy: 3.74056
Value Function Loss: 0.04891

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10246
Policy Update Magnitude: 0.45377
Value Function Update Magnitude: 0.77937

Collected Steps per Second: 23,169.61350
Overall Steps per Second: 10,898.91261

Timestep Collection Time: 2.15938
Timestep Consumption Time: 2.43117
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.59055

Cumulative Model Updates: 46,172
Cumulative Timesteps: 385,122,994

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 385122994...
Checkpoint 385122994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,618.96145
Policy Entropy: 3.73913
Value Function Loss: 0.04503

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.48903
Value Function Update Magnitude: 0.82481

Collected Steps per Second: 22,639.20413
Overall Steps per Second: 10,604.38709

Timestep Collection Time: 2.20918
Timestep Consumption Time: 2.50717
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.71635

Cumulative Model Updates: 46,178
Cumulative Timesteps: 385,173,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,583.57544
Policy Entropy: 3.74773
Value Function Loss: 0.04462

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.48465
Value Function Update Magnitude: 0.82735

Collected Steps per Second: 23,023.41260
Overall Steps per Second: 10,843.34163

Timestep Collection Time: 2.17274
Timestep Consumption Time: 2.44059
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61334

Cumulative Model Updates: 46,184
Cumulative Timesteps: 385,223,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 385223032...
Checkpoint 385223032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,576.91031
Policy Entropy: 3.74403
Value Function Loss: 0.04547

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.46217
Value Function Update Magnitude: 0.83490

Collected Steps per Second: 22,551.75522
Overall Steps per Second: 10,758.06837

Timestep Collection Time: 2.21845
Timestep Consumption Time: 2.43201
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.65046

Cumulative Model Updates: 46,190
Cumulative Timesteps: 385,273,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,396.25884
Policy Entropy: 3.73878
Value Function Loss: 0.04595

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.46092
Value Function Update Magnitude: 0.81542

Collected Steps per Second: 23,076.60537
Overall Steps per Second: 10,844.71471

Timestep Collection Time: 2.16696
Timestep Consumption Time: 2.44414
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61109

Cumulative Model Updates: 46,196
Cumulative Timesteps: 385,323,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 385323068...
Checkpoint 385323068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,506.25397
Policy Entropy: 3.73608
Value Function Loss: 0.04508

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.46854
Value Function Update Magnitude: 0.79897

Collected Steps per Second: 22,396.89102
Overall Steps per Second: 10,665.37975

Timestep Collection Time: 2.23281
Timestep Consumption Time: 2.45601
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.68882

Cumulative Model Updates: 46,202
Cumulative Timesteps: 385,373,076

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.01575
Policy Entropy: 3.72986
Value Function Loss: 0.04366

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.49786
Value Function Update Magnitude: 0.79537

Collected Steps per Second: 23,031.75263
Overall Steps per Second: 10,949.94805

Timestep Collection Time: 2.17213
Timestep Consumption Time: 2.39666
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.56879

Cumulative Model Updates: 46,208
Cumulative Timesteps: 385,423,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 385423104...
Checkpoint 385423104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,620.58527
Policy Entropy: 3.74253
Value Function Loss: 0.04260

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.48195
Value Function Update Magnitude: 0.77421

Collected Steps per Second: 21,803.38843
Overall Steps per Second: 10,659.92384

Timestep Collection Time: 2.29405
Timestep Consumption Time: 2.39811
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.69215

Cumulative Model Updates: 46,214
Cumulative Timesteps: 385,473,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.66486
Policy Entropy: 3.74736
Value Function Loss: 0.04274

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.47726
Value Function Update Magnitude: 0.74305

Collected Steps per Second: 22,869.25069
Overall Steps per Second: 10,821.74477

Timestep Collection Time: 2.18739
Timestep Consumption Time: 2.43515
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62254

Cumulative Model Updates: 46,220
Cumulative Timesteps: 385,523,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 385523146...
Checkpoint 385523146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,978.88819
Policy Entropy: 3.74263
Value Function Loss: 0.04522

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.52137
Value Function Update Magnitude: 0.58245

Collected Steps per Second: 22,643.78304
Overall Steps per Second: 10,670.92479

Timestep Collection Time: 2.20811
Timestep Consumption Time: 2.47752
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.68563

Cumulative Model Updates: 46,226
Cumulative Timesteps: 385,573,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388.14185
Policy Entropy: 3.73379
Value Function Loss: 0.04896

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11464
Policy Update Magnitude: 0.53071
Value Function Update Magnitude: 0.56789

Collected Steps per Second: 22,581.55953
Overall Steps per Second: 10,638.93004

Timestep Collection Time: 2.21517
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.70179

Cumulative Model Updates: 46,232
Cumulative Timesteps: 385,623,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 385623168...
Checkpoint 385623168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.70014
Policy Entropy: 3.72449
Value Function Loss: 0.05097

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.51889
Value Function Update Magnitude: 0.61410

Collected Steps per Second: 22,688.79186
Overall Steps per Second: 10,803.27307

Timestep Collection Time: 2.20558
Timestep Consumption Time: 2.42653
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.63211

Cumulative Model Updates: 46,238
Cumulative Timesteps: 385,673,210

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,240.23684
Policy Entropy: 3.73264
Value Function Loss: 0.05015

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.56059
Value Function Update Magnitude: 0.64937

Collected Steps per Second: 22,824.44916
Overall Steps per Second: 10,638.12707

Timestep Collection Time: 2.19177
Timestep Consumption Time: 2.51075
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.70252

Cumulative Model Updates: 46,244
Cumulative Timesteps: 385,723,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 385723236...
Checkpoint 385723236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,723.86159
Policy Entropy: 3.72535
Value Function Loss: 0.04968

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.55313
Value Function Update Magnitude: 0.61241

Collected Steps per Second: 22,441.18196
Overall Steps per Second: 10,543.26011

Timestep Collection Time: 2.22912
Timestep Consumption Time: 2.51553
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.74464

Cumulative Model Updates: 46,250
Cumulative Timesteps: 385,773,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,449.27618
Policy Entropy: 3.74246
Value Function Loss: 0.04866

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.15253
Policy Update Magnitude: 0.50247
Value Function Update Magnitude: 0.60086

Collected Steps per Second: 23,059.22671
Overall Steps per Second: 10,856.29275

Timestep Collection Time: 2.16876
Timestep Consumption Time: 2.43778
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.60654

Cumulative Model Updates: 46,256
Cumulative Timesteps: 385,823,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 385823270...
Checkpoint 385823270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,909.16109
Policy Entropy: 3.75157
Value Function Loss: 0.04950

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.40047
Value Function Update Magnitude: 0.57956

Collected Steps per Second: 22,501.39807
Overall Steps per Second: 10,726.44620

Timestep Collection Time: 2.22288
Timestep Consumption Time: 2.44017
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.66305

Cumulative Model Updates: 46,262
Cumulative Timesteps: 385,873,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,019.43842
Policy Entropy: 3.75356
Value Function Loss: 0.04586

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.41921
Value Function Update Magnitude: 0.61372

Collected Steps per Second: 23,219.31331
Overall Steps per Second: 10,876.09072

Timestep Collection Time: 2.15390
Timestep Consumption Time: 2.44445
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.59834

Cumulative Model Updates: 46,268
Cumulative Timesteps: 385,923,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 385923300...
Checkpoint 385923300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,799.32825
Policy Entropy: 3.74633
Value Function Loss: 0.04556

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.50749
Value Function Update Magnitude: 0.62356

Collected Steps per Second: 22,477.13188
Overall Steps per Second: 10,641.34130

Timestep Collection Time: 2.22448
Timestep Consumption Time: 2.47417
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.69866

Cumulative Model Updates: 46,274
Cumulative Timesteps: 385,973,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.16833
Policy Entropy: 3.74695
Value Function Loss: 0.04303

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.52750
Value Function Update Magnitude: 0.67095

Collected Steps per Second: 22,747.56999
Overall Steps per Second: 10,807.75462

Timestep Collection Time: 2.19812
Timestep Consumption Time: 2.42837
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62649

Cumulative Model Updates: 46,280
Cumulative Timesteps: 386,023,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 386023302...
Checkpoint 386023302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.81129
Policy Entropy: 3.75715
Value Function Loss: 0.04299

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.52655
Value Function Update Magnitude: 0.72333

Collected Steps per Second: 22,476.94455
Overall Steps per Second: 10,763.95586

Timestep Collection Time: 2.22468
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.64550

Cumulative Model Updates: 46,286
Cumulative Timesteps: 386,073,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,120.95033
Policy Entropy: 3.75782
Value Function Loss: 0.04383

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.48027
Value Function Update Magnitude: 0.69499

Collected Steps per Second: 22,951.42913
Overall Steps per Second: 10,838.71087

Timestep Collection Time: 2.17877
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.61365

Cumulative Model Updates: 46,292
Cumulative Timesteps: 386,123,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 386123312...
Checkpoint 386123312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,621.42651
Policy Entropy: 3.74714
Value Function Loss: 0.04263

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.50015
Value Function Update Magnitude: 0.72111

Collected Steps per Second: 22,736.69622
Overall Steps per Second: 10,670.34220

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.48839
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.68888

Cumulative Model Updates: 46,298
Cumulative Timesteps: 386,173,344

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,727.27039
Policy Entropy: 3.72832
Value Function Loss: 0.04182

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07731
Policy Update Magnitude: 0.51121
Value Function Update Magnitude: 0.69700

Collected Steps per Second: 22,764.82334
Overall Steps per Second: 10,695.17665

Timestep Collection Time: 2.19734
Timestep Consumption Time: 2.47972
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.67706

Cumulative Model Updates: 46,304
Cumulative Timesteps: 386,223,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 386223366...
Checkpoint 386223366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,456.20669
Policy Entropy: 3.72388
Value Function Loss: 0.04196

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07267
Policy Update Magnitude: 0.57719
Value Function Update Magnitude: 0.63639

Collected Steps per Second: 22,760.93604
Overall Steps per Second: 10,812.15465

Timestep Collection Time: 2.19736
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.62572

Cumulative Model Updates: 46,310
Cumulative Timesteps: 386,273,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,073.28834
Policy Entropy: 3.72788
Value Function Loss: 0.04498

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.58669
Value Function Update Magnitude: 0.66797

Collected Steps per Second: 22,790.20506
Overall Steps per Second: 10,658.44864

Timestep Collection Time: 2.19428
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.69186

Cumulative Model Updates: 46,316
Cumulative Timesteps: 386,323,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 386323388...
Checkpoint 386323388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,768.09943
Policy Entropy: 3.73456
Value Function Loss: 0.04579

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.50456
Value Function Update Magnitude: 0.72712

Collected Steps per Second: 22,762.74385
Overall Steps per Second: 10,690.71956

Timestep Collection Time: 2.19763
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.67920

Cumulative Model Updates: 46,322
Cumulative Timesteps: 386,373,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,474.14194
Policy Entropy: 3.74713
Value Function Loss: 0.04494

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.47659
Value Function Update Magnitude: 0.77818

Collected Steps per Second: 23,041.81426
Overall Steps per Second: 10,743.19358

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.48543
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.65653

Cumulative Model Updates: 46,328
Cumulative Timesteps: 386,423,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 386423438...
Checkpoint 386423438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,743.41997
Policy Entropy: 3.75729
Value Function Loss: 0.04277

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.46505
Value Function Update Magnitude: 0.78974

Collected Steps per Second: 22,693.61841
Overall Steps per Second: 10,636.46078

Timestep Collection Time: 2.20335
Timestep Consumption Time: 2.49765
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.70100

Cumulative Model Updates: 46,334
Cumulative Timesteps: 386,473,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,347.72024
Policy Entropy: 3.75163
Value Function Loss: 0.04297

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06879
Policy Update Magnitude: 0.54842
Value Function Update Magnitude: 0.78917

Collected Steps per Second: 22,607.69978
Overall Steps per Second: 10,779.14222

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.42802
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.64063

Cumulative Model Updates: 46,340
Cumulative Timesteps: 386,523,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 386523462...
Checkpoint 386523462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,219.46235
Policy Entropy: 3.74230
Value Function Loss: 0.04577

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06269
Policy Update Magnitude: 0.61410
Value Function Update Magnitude: 0.73613

Collected Steps per Second: 22,465.92323
Overall Steps per Second: 10,706.54965

Timestep Collection Time: 2.22622
Timestep Consumption Time: 2.44513
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.67135

Cumulative Model Updates: 46,346
Cumulative Timesteps: 386,573,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,251.45953
Policy Entropy: 3.73445
Value Function Loss: 0.04679

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06706
Policy Update Magnitude: 0.62047
Value Function Update Magnitude: 0.62479

Collected Steps per Second: 23,042.08292
Overall Steps per Second: 10,860.36481

Timestep Collection Time: 2.17055
Timestep Consumption Time: 2.43464
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60519

Cumulative Model Updates: 46,352
Cumulative Timesteps: 386,623,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 386623490...
Checkpoint 386623490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,862.84007
Policy Entropy: 3.75017
Value Function Loss: 0.04732

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06443
Policy Update Magnitude: 0.61698
Value Function Update Magnitude: 0.58977

Collected Steps per Second: 22,566.93160
Overall Steps per Second: 10,776.28058

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.63982

Cumulative Model Updates: 46,358
Cumulative Timesteps: 386,673,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,432.49367
Policy Entropy: 3.75933
Value Function Loss: 0.04660

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.57876
Value Function Update Magnitude: 0.58678

Collected Steps per Second: 23,021.66034
Overall Steps per Second: 10,864.26720

Timestep Collection Time: 2.17282
Timestep Consumption Time: 2.43144
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.60427

Cumulative Model Updates: 46,364
Cumulative Timesteps: 386,723,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 386723512...
Checkpoint 386723512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,939.82791
Policy Entropy: 3.74786
Value Function Loss: 0.04665

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.51439
Value Function Update Magnitude: 0.60704

Collected Steps per Second: 22,705.48363
Overall Steps per Second: 10,588.39253

Timestep Collection Time: 2.20273
Timestep Consumption Time: 2.52075
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.72347

Cumulative Model Updates: 46,370
Cumulative Timesteps: 386,773,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,397.83850
Policy Entropy: 3.74369
Value Function Loss: 0.05023

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.48395
Value Function Update Magnitude: 0.60035

Collected Steps per Second: 23,037.24990
Overall Steps per Second: 10,883.53895

Timestep Collection Time: 2.17066
Timestep Consumption Time: 2.42399
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.59465

Cumulative Model Updates: 46,376
Cumulative Timesteps: 386,823,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 386823532...
Checkpoint 386823532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,906.21546
Policy Entropy: 3.72293
Value Function Loss: 0.05228

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.49327
Value Function Update Magnitude: 0.60792

Collected Steps per Second: 22,504.09801
Overall Steps per Second: 10,676.72054

Timestep Collection Time: 2.22200
Timestep Consumption Time: 2.46147
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.68346

Cumulative Model Updates: 46,382
Cumulative Timesteps: 386,873,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,580.66084
Policy Entropy: 3.72392
Value Function Loss: 0.05399

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.51315
Value Function Update Magnitude: 0.59945

Collected Steps per Second: 23,166.10184
Overall Steps per Second: 10,863.43528

Timestep Collection Time: 2.15936
Timestep Consumption Time: 2.44544
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.60480

Cumulative Model Updates: 46,388
Cumulative Timesteps: 386,923,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 386923560...
Checkpoint 386923560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,910.11491
Policy Entropy: 3.72386
Value Function Loss: 0.05224

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.51486
Value Function Update Magnitude: 0.60559

Collected Steps per Second: 22,528.56063
Overall Steps per Second: 10,698.54220

Timestep Collection Time: 2.21976
Timestep Consumption Time: 2.45452
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.67428

Cumulative Model Updates: 46,394
Cumulative Timesteps: 386,973,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,331.42225
Policy Entropy: 3.72929
Value Function Loss: 0.05027

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.50224
Value Function Update Magnitude: 0.62471

Collected Steps per Second: 23,277.63147
Overall Steps per Second: 10,902.87796

Timestep Collection Time: 2.14816
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.58631

Cumulative Model Updates: 46,400
Cumulative Timesteps: 387,023,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 387023572...
Checkpoint 387023572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,104.68280
Policy Entropy: 3.73085
Value Function Loss: 0.04841

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.52485
Value Function Update Magnitude: 0.67121

Collected Steps per Second: 22,343.75390
Overall Steps per Second: 10,651.49788

Timestep Collection Time: 2.23821
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.69511

Cumulative Model Updates: 46,406
Cumulative Timesteps: 387,073,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.93096
Policy Entropy: 3.74062
Value Function Loss: 0.05017

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.63100
Value Function Update Magnitude: 0.64387

Collected Steps per Second: 23,051.09549
Overall Steps per Second: 10,966.46788

Timestep Collection Time: 2.17031
Timestep Consumption Time: 2.39160
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.56191

Cumulative Model Updates: 46,412
Cumulative Timesteps: 387,123,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 387123610...
Checkpoint 387123610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.14918
Policy Entropy: 3.75089
Value Function Loss: 0.05054

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08185
Policy Update Magnitude: 0.64914
Value Function Update Magnitude: 0.66122

Collected Steps per Second: 22,670.14638
Overall Steps per Second: 10,611.97797

Timestep Collection Time: 2.20731
Timestep Consumption Time: 2.50812
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.71543

Cumulative Model Updates: 46,418
Cumulative Timesteps: 387,173,650

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,453.67562
Policy Entropy: 3.74782
Value Function Loss: 0.05031

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.60613
Value Function Update Magnitude: 0.64621

Collected Steps per Second: 23,201.84861
Overall Steps per Second: 10,910.22036

Timestep Collection Time: 2.15526
Timestep Consumption Time: 2.42815
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.58341

Cumulative Model Updates: 46,424
Cumulative Timesteps: 387,223,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 387223656...
Checkpoint 387223656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,740.68427
Policy Entropy: 3.74847
Value Function Loss: 0.04890

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.60283
Value Function Update Magnitude: 0.61269

Collected Steps per Second: 22,402.78768
Overall Steps per Second: 10,607.02097

Timestep Collection Time: 2.23222
Timestep Consumption Time: 2.48239
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.71461

Cumulative Model Updates: 46,430
Cumulative Timesteps: 387,273,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,893.69737
Policy Entropy: 3.73257
Value Function Loss: 0.04697

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06753
Policy Update Magnitude: 0.61121
Value Function Update Magnitude: 0.61066

Collected Steps per Second: 23,079.54295
Overall Steps per Second: 10,863.92364

Timestep Collection Time: 2.16746
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.60460

Cumulative Model Updates: 46,436
Cumulative Timesteps: 387,323,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 387323688...
Checkpoint 387323688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,236.53508
Policy Entropy: 3.72655
Value Function Loss: 0.04701

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06430
Policy Update Magnitude: 0.62044
Value Function Update Magnitude: 0.64337

Collected Steps per Second: 22,344.42891
Overall Steps per Second: 10,716.08811

Timestep Collection Time: 2.23832
Timestep Consumption Time: 2.42887
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.66719

Cumulative Model Updates: 46,442
Cumulative Timesteps: 387,373,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,926.69600
Policy Entropy: 3.71908
Value Function Loss: 0.04562

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06488
Policy Update Magnitude: 0.62706
Value Function Update Magnitude: 0.68991

Collected Steps per Second: 23,192.12580
Overall Steps per Second: 10,904.27457

Timestep Collection Time: 2.15677
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.58719

Cumulative Model Updates: 46,448
Cumulative Timesteps: 387,423,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 387423722...
Checkpoint 387423722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,358.88564
Policy Entropy: 3.72411
Value Function Loss: 0.04594

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07079
Policy Update Magnitude: 0.61914
Value Function Update Magnitude: 0.73299

Collected Steps per Second: 22,341.25567
Overall Steps per Second: 10,627.67614

Timestep Collection Time: 2.23855
Timestep Consumption Time: 2.46728
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.70583

Cumulative Model Updates: 46,454
Cumulative Timesteps: 387,473,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,721.60332
Policy Entropy: 3.73019
Value Function Loss: 0.04745

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.63122
Value Function Update Magnitude: 0.68571

Collected Steps per Second: 23,216.92921
Overall Steps per Second: 10,909.45826

Timestep Collection Time: 2.15455
Timestep Consumption Time: 2.43065
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.58520

Cumulative Model Updates: 46,460
Cumulative Timesteps: 387,523,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 387523756...
Checkpoint 387523756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,692.07617
Policy Entropy: 3.72446
Value Function Loss: 0.04877

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.56803
Value Function Update Magnitude: 0.66798

Collected Steps per Second: 22,644.87670
Overall Steps per Second: 10,674.30894

Timestep Collection Time: 2.20951
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.68733

Cumulative Model Updates: 46,466
Cumulative Timesteps: 387,573,790

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,456.51830
Policy Entropy: 3.72592
Value Function Loss: 0.05045

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10314
Policy Update Magnitude: 0.47141
Value Function Update Magnitude: 0.66269

Collected Steps per Second: 23,016.96775
Overall Steps per Second: 10,852.98876

Timestep Collection Time: 2.17309
Timestep Consumption Time: 2.43559
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.60868

Cumulative Model Updates: 46,472
Cumulative Timesteps: 387,623,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 387623808...
Checkpoint 387623808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,994.27385
Policy Entropy: 3.71322
Value Function Loss: 0.05185

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07315
Policy Update Magnitude: 0.54750
Value Function Update Magnitude: 0.59611

Collected Steps per Second: 22,750.63568
Overall Steps per Second: 10,656.68783

Timestep Collection Time: 2.19967
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.69602

Cumulative Model Updates: 46,478
Cumulative Timesteps: 387,673,852

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,920.62464
Policy Entropy: 3.72152
Value Function Loss: 0.05341

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.52310

Collected Steps per Second: 22,945.53408
Overall Steps per Second: 10,844.53590

Timestep Collection Time: 2.17994
Timestep Consumption Time: 2.43252
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61246

Cumulative Model Updates: 46,484
Cumulative Timesteps: 387,723,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 387723872...
Checkpoint 387723872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,074.33050
Policy Entropy: 3.72038
Value Function Loss: 0.05415

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.51226
Value Function Update Magnitude: 0.51660

Collected Steps per Second: 22,674.32976
Overall Steps per Second: 10,692.79934

Timestep Collection Time: 2.20602
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.67791

Cumulative Model Updates: 46,490
Cumulative Timesteps: 387,773,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,835.79295
Policy Entropy: 3.69658
Value Function Loss: 0.05344

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.45959
Value Function Update Magnitude: 0.53123

Collected Steps per Second: 22,771.20235
Overall Steps per Second: 10,700.66744

Timestep Collection Time: 2.19716
Timestep Consumption Time: 2.47844
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.67560

Cumulative Model Updates: 46,496
Cumulative Timesteps: 387,823,924

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 387823924...
Checkpoint 387823924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,661.59982
Policy Entropy: 3.70337
Value Function Loss: 0.05216

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.47626
Value Function Update Magnitude: 0.56635

Collected Steps per Second: 22,738.12758
Overall Steps per Second: 10,805.32046

Timestep Collection Time: 2.19948
Timestep Consumption Time: 2.42898
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.62846

Cumulative Model Updates: 46,502
Cumulative Timesteps: 387,873,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,826.39206
Policy Entropy: 3.70783
Value Function Loss: 0.05093

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.44601
Value Function Update Magnitude: 0.55419

Collected Steps per Second: 23,002.48580
Overall Steps per Second: 10,709.33590

Timestep Collection Time: 2.17568
Timestep Consumption Time: 2.49744
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.67312

Cumulative Model Updates: 46,508
Cumulative Timesteps: 387,923,982

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 387923982...
Checkpoint 387923982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,647.49513
Policy Entropy: 3.70998
Value Function Loss: 0.05087

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.42906
Value Function Update Magnitude: 0.67731

Collected Steps per Second: 22,556.93608
Overall Steps per Second: 10,649.72730

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.47834
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.69496

Cumulative Model Updates: 46,514
Cumulative Timesteps: 387,973,982

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,215.63455
Policy Entropy: 3.70701
Value Function Loss: 0.05011

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.41369
Value Function Update Magnitude: 0.72846

Collected Steps per Second: 23,462.25407
Overall Steps per Second: 10,810.24741

Timestep Collection Time: 2.13159
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.62635

Cumulative Model Updates: 46,520
Cumulative Timesteps: 388,023,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 388023994...
Checkpoint 388023994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,506.48093
Policy Entropy: 3.70468
Value Function Loss: 0.04750

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.46120
Value Function Update Magnitude: 0.77004

Collected Steps per Second: 22,428.33922
Overall Steps per Second: 10,587.06255

Timestep Collection Time: 2.23012
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.72445

Cumulative Model Updates: 46,526
Cumulative Timesteps: 388,074,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,842.68986
Policy Entropy: 3.71091
Value Function Loss: 0.04580

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.46206
Value Function Update Magnitude: 0.80597

Collected Steps per Second: 22,891.74238
Overall Steps per Second: 10,831.50957

Timestep Collection Time: 2.18507
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61801

Cumulative Model Updates: 46,532
Cumulative Timesteps: 388,124,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 388124032...
Checkpoint 388124032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,707.30120
Policy Entropy: 3.71009
Value Function Loss: 0.04890

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.43895
Value Function Update Magnitude: 0.80453

Collected Steps per Second: 22,513.48880
Overall Steps per Second: 10,640.40351

Timestep Collection Time: 2.22116
Timestep Consumption Time: 2.47848
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.69963

Cumulative Model Updates: 46,538
Cumulative Timesteps: 388,174,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,706.09473
Policy Entropy: 3.72520
Value Function Loss: 0.05098

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.44489
Value Function Update Magnitude: 0.82890

Collected Steps per Second: 22,827.88190
Overall Steps per Second: 10,838.42394

Timestep Collection Time: 2.19136
Timestep Consumption Time: 2.42408
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.61543

Cumulative Model Updates: 46,544
Cumulative Timesteps: 388,224,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 388224062...
Checkpoint 388224062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,975.44396
Policy Entropy: 3.71831
Value Function Loss: 0.05273

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.45356
Value Function Update Magnitude: 0.85459

Collected Steps per Second: 22,386.22499
Overall Steps per Second: 10,773.53374

Timestep Collection Time: 2.23468
Timestep Consumption Time: 2.40874
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.64342

Cumulative Model Updates: 46,550
Cumulative Timesteps: 388,274,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,822.40456
Policy Entropy: 3.73357
Value Function Loss: 0.04920

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.47072
Value Function Update Magnitude: 0.87203

Collected Steps per Second: 22,518.67194
Overall Steps per Second: 10,870.69337

Timestep Collection Time: 2.22091
Timestep Consumption Time: 2.37971
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.60063

Cumulative Model Updates: 46,556
Cumulative Timesteps: 388,324,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 388324100...
Checkpoint 388324100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,197.03564
Policy Entropy: 3.72448
Value Function Loss: 0.04798

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.44166
Value Function Update Magnitude: 0.87561

Collected Steps per Second: 21,745.41051
Overall Steps per Second: 10,603.23125

Timestep Collection Time: 2.29989
Timestep Consumption Time: 2.41679
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.71668

Cumulative Model Updates: 46,562
Cumulative Timesteps: 388,374,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,773.17914
Policy Entropy: 3.72868
Value Function Loss: 0.04567

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.41746
Value Function Update Magnitude: 0.85905

Collected Steps per Second: 22,581.49544
Overall Steps per Second: 10,907.06239

Timestep Collection Time: 2.21597
Timestep Consumption Time: 2.37188
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.58785

Cumulative Model Updates: 46,568
Cumulative Timesteps: 388,424,152

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 388424152...
Checkpoint 388424152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,719.90757
Policy Entropy: 3.71681
Value Function Loss: 0.04693

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.41456
Value Function Update Magnitude: 0.85314

Collected Steps per Second: 21,734.61014
Overall Steps per Second: 10,668.65000

Timestep Collection Time: 2.30121
Timestep Consumption Time: 2.38691
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.68813

Cumulative Model Updates: 46,574
Cumulative Timesteps: 388,474,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,511.73861
Policy Entropy: 3.71302
Value Function Loss: 0.04860

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.45337
Value Function Update Magnitude: 0.80754

Collected Steps per Second: 22,240.40557
Overall Steps per Second: 10,598.28317

Timestep Collection Time: 2.24870
Timestep Consumption Time: 2.47018
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.71888

Cumulative Model Updates: 46,580
Cumulative Timesteps: 388,524,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 388524180...
Checkpoint 388524180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,032.51721
Policy Entropy: 3.72035
Value Function Loss: 0.05108

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.44945
Value Function Update Magnitude: 0.71059

Collected Steps per Second: 22,494.35819
Overall Steps per Second: 10,677.73532

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.46006
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.68302

Cumulative Model Updates: 46,586
Cumulative Timesteps: 388,574,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,196.25053
Policy Entropy: 3.72759
Value Function Loss: 0.05168

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.44255
Value Function Update Magnitude: 0.69738

Collected Steps per Second: 23,203.29044
Overall Steps per Second: 10,762.58765

Timestep Collection Time: 2.15633
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.64888

Cumulative Model Updates: 46,592
Cumulative Timesteps: 388,624,218

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 388624218...
Checkpoint 388624218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,033.24129
Policy Entropy: 3.73856
Value Function Loss: 0.05360

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.45356
Value Function Update Magnitude: 0.75889

Collected Steps per Second: 22,349.01447
Overall Steps per Second: 10,590.40188

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.72333

Cumulative Model Updates: 46,598
Cumulative Timesteps: 388,674,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,284.01749
Policy Entropy: 3.73210
Value Function Loss: 0.05173

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.48945
Value Function Update Magnitude: 0.78817

Collected Steps per Second: 22,906.29897
Overall Steps per Second: 10,885.16245

Timestep Collection Time: 2.18350
Timestep Consumption Time: 2.41137
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.59488

Cumulative Model Updates: 46,604
Cumulative Timesteps: 388,724,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 388724256...
Checkpoint 388724256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,643.74518
Policy Entropy: 3.73453
Value Function Loss: 0.04929

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.50298
Value Function Update Magnitude: 0.85742

Collected Steps per Second: 22,536.62393
Overall Steps per Second: 10,665.49462

Timestep Collection Time: 2.21897
Timestep Consumption Time: 2.46980
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.68877

Cumulative Model Updates: 46,610
Cumulative Timesteps: 388,774,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,863.37733
Policy Entropy: 3.72899
Value Function Loss: 0.04732

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.52670
Value Function Update Magnitude: 0.85340

Collected Steps per Second: 23,164.40733
Overall Steps per Second: 10,896.99480

Timestep Collection Time: 2.15961
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.59081

Cumulative Model Updates: 46,616
Cumulative Timesteps: 388,824,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 388824290...
Checkpoint 388824290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,147.14089
Policy Entropy: 3.71547
Value Function Loss: 0.04924

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.51005
Value Function Update Magnitude: 0.78059

Collected Steps per Second: 22,570.86798
Overall Steps per Second: 10,671.23934

Timestep Collection Time: 2.21622
Timestep Consumption Time: 2.47133
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.68755

Cumulative Model Updates: 46,622
Cumulative Timesteps: 388,874,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,920.77128
Policy Entropy: 3.71645
Value Function Loss: 0.04948

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.51448
Value Function Update Magnitude: 0.77500

Collected Steps per Second: 23,113.30348
Overall Steps per Second: 10,944.92722

Timestep Collection Time: 2.16404
Timestep Consumption Time: 2.40594
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.56997

Cumulative Model Updates: 46,628
Cumulative Timesteps: 388,924,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 388924330...
Checkpoint 388924330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,416.26960
Policy Entropy: 3.71662
Value Function Loss: 0.04853

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.50261
Value Function Update Magnitude: 0.80541

Collected Steps per Second: 22,460.76889
Overall Steps per Second: 10,581.40421

Timestep Collection Time: 2.22637
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.72584

Cumulative Model Updates: 46,634
Cumulative Timesteps: 388,974,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,974.40443
Policy Entropy: 3.71737
Value Function Loss: 0.05045

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.52862
Value Function Update Magnitude: 0.67496

Collected Steps per Second: 22,732.47411
Overall Steps per Second: 10,690.51055

Timestep Collection Time: 2.20046
Timestep Consumption Time: 2.47864
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.67910

Cumulative Model Updates: 46,640
Cumulative Timesteps: 389,024,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 389024358...
Checkpoint 389024358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,262.38408
Policy Entropy: 3.71421
Value Function Loss: 0.05141

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.60305
Value Function Update Magnitude: 0.64288

Collected Steps per Second: 22,719.27999
Overall Steps per Second: 10,791.52101

Timestep Collection Time: 2.20086
Timestep Consumption Time: 2.43259
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.63345

Cumulative Model Updates: 46,646
Cumulative Timesteps: 389,074,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,748.98686
Policy Entropy: 3.70383
Value Function Loss: 0.05440

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07281
Policy Update Magnitude: 0.61394
Value Function Update Magnitude: 0.61219

Collected Steps per Second: 22,770.14489
Overall Steps per Second: 10,671.00378

Timestep Collection Time: 2.19691
Timestep Consumption Time: 2.49093
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.68784

Cumulative Model Updates: 46,652
Cumulative Timesteps: 389,124,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 389124384...
Checkpoint 389124384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,754.09043
Policy Entropy: 3.68850
Value Function Loss: 0.05359

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.60088
Value Function Update Magnitude: 0.62033

Collected Steps per Second: 22,705.16821
Overall Steps per Second: 10,665.42936

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.68804

Cumulative Model Updates: 46,658
Cumulative Timesteps: 389,174,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,150.85393
Policy Entropy: 3.70217
Value Function Loss: 0.05333

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.61051
Value Function Update Magnitude: 0.59626

Collected Steps per Second: 23,085.82425
Overall Steps per Second: 10,740.91368

Timestep Collection Time: 2.16670
Timestep Consumption Time: 2.49026
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.65696

Cumulative Model Updates: 46,664
Cumulative Timesteps: 389,224,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 389224404...
Checkpoint 389224404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,056.34935
Policy Entropy: 3.71964
Value Function Loss: 0.05071

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.63096

Collected Steps per Second: 22,242.42203
Overall Steps per Second: 10,619.30433

Timestep Collection Time: 2.24832
Timestep Consumption Time: 2.46084
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.70916

Cumulative Model Updates: 46,670
Cumulative Timesteps: 389,274,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,574.33699
Policy Entropy: 3.72076
Value Function Loss: 0.05309

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.58215
Value Function Update Magnitude: 0.64437

Collected Steps per Second: 23,233.10823
Overall Steps per Second: 10,856.32462

Timestep Collection Time: 2.15262
Timestep Consumption Time: 2.45410
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.60672

Cumulative Model Updates: 46,676
Cumulative Timesteps: 389,324,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 389324424...
Checkpoint 389324424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,459.91017
Policy Entropy: 3.71354
Value Function Loss: 0.05285

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.61000
Value Function Update Magnitude: 0.67660

Collected Steps per Second: 22,622.30429
Overall Steps per Second: 10,664.68511

Timestep Collection Time: 2.21030
Timestep Consumption Time: 2.47826
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.68856

Cumulative Model Updates: 46,682
Cumulative Timesteps: 389,374,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.07557
Policy Entropy: 3.69841
Value Function Loss: 0.05359

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.64371

Collected Steps per Second: 22,660.25691
Overall Steps per Second: 10,633.79239

Timestep Collection Time: 2.20765
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.70444

Cumulative Model Updates: 46,688
Cumulative Timesteps: 389,424,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 389424452...
Checkpoint 389424452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,069.97854
Policy Entropy: 3.70142
Value Function Loss: 0.05183

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.53345
Value Function Update Magnitude: 0.67064

Collected Steps per Second: 22,606.88117
Overall Steps per Second: 10,617.09228

Timestep Collection Time: 2.21331
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.71278

Cumulative Model Updates: 46,694
Cumulative Timesteps: 389,474,488

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,334.31067
Policy Entropy: 3.69838
Value Function Loss: 0.05110

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.57465
Value Function Update Magnitude: 0.68235

Collected Steps per Second: 22,900.99926
Overall Steps per Second: 10,734.51260

Timestep Collection Time: 2.18427
Timestep Consumption Time: 2.47565
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.65992

Cumulative Model Updates: 46,700
Cumulative Timesteps: 389,524,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 389524510...
Checkpoint 389524510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,670.43184
Policy Entropy: 3.71371
Value Function Loss: 0.05143

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.52572
Value Function Update Magnitude: 0.63081

Collected Steps per Second: 22,575.48636
Overall Steps per Second: 10,681.41589

Timestep Collection Time: 2.21488
Timestep Consumption Time: 2.46633
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.68121

Cumulative Model Updates: 46,706
Cumulative Timesteps: 389,574,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914.44519
Policy Entropy: 3.71970
Value Function Loss: 0.05073

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.50286
Value Function Update Magnitude: 0.68257

Collected Steps per Second: 22,625.48931
Overall Steps per Second: 10,647.87809

Timestep Collection Time: 2.21113
Timestep Consumption Time: 2.48727
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69840

Cumulative Model Updates: 46,712
Cumulative Timesteps: 389,624,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 389624540...
Checkpoint 389624540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,094.45370
Policy Entropy: 3.72992
Value Function Loss: 0.05016

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11049
Policy Update Magnitude: 0.52517
Value Function Update Magnitude: 0.73169

Collected Steps per Second: 22,302.76593
Overall Steps per Second: 10,589.44892

Timestep Collection Time: 2.24331
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.72470

Cumulative Model Updates: 46,718
Cumulative Timesteps: 389,674,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,379.96490
Policy Entropy: 3.73771
Value Function Loss: 0.04903

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.49543
Value Function Update Magnitude: 0.67248

Collected Steps per Second: 23,057.07779
Overall Steps per Second: 10,766.72730

Timestep Collection Time: 2.16975
Timestep Consumption Time: 2.47679
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.64654

Cumulative Model Updates: 46,724
Cumulative Timesteps: 389,724,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 389724600...
Checkpoint 389724600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,766.88312
Policy Entropy: 3.73489
Value Function Loss: 0.05054

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.47505
Value Function Update Magnitude: 0.59963

Collected Steps per Second: 22,591.64580
Overall Steps per Second: 10,587.48679

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.51075
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.72520

Cumulative Model Updates: 46,730
Cumulative Timesteps: 389,774,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,135.79154
Policy Entropy: 3.73762
Value Function Loss: 0.05181

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.54001
Value Function Update Magnitude: 0.59347

Collected Steps per Second: 22,977.01724
Overall Steps per Second: 10,849.96876

Timestep Collection Time: 2.17609
Timestep Consumption Time: 2.43222
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.60831

Cumulative Model Updates: 46,736
Cumulative Timesteps: 389,824,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 389824628...
Checkpoint 389824628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,282.40249
Policy Entropy: 3.73925
Value Function Loss: 0.05272

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.60462
Value Function Update Magnitude: 0.60808

Collected Steps per Second: 22,397.43125
Overall Steps per Second: 10,766.73717

Timestep Collection Time: 2.23374
Timestep Consumption Time: 2.41298
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.64672

Cumulative Model Updates: 46,742
Cumulative Timesteps: 389,874,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,753.17721
Policy Entropy: 3.75871
Value Function Loss: 0.05258

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.64034

Collected Steps per Second: 23,010.67179
Overall Steps per Second: 10,833.01130

Timestep Collection Time: 2.17325
Timestep Consumption Time: 2.44301
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.61626

Cumulative Model Updates: 46,748
Cumulative Timesteps: 389,924,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 389924666...
Checkpoint 389924666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,307.75610
Policy Entropy: 3.75450
Value Function Loss: 0.05047

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.50155
Value Function Update Magnitude: 0.67165

Collected Steps per Second: 22,404.58468
Overall Steps per Second: 10,665.35264

Timestep Collection Time: 2.23276
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.69033

Cumulative Model Updates: 46,754
Cumulative Timesteps: 389,974,690

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,917.80279
Policy Entropy: 3.74975
Value Function Loss: 0.05007

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.49492
Value Function Update Magnitude: 0.66465

Collected Steps per Second: 23,138.67950
Overall Steps per Second: 10,892.04094

Timestep Collection Time: 2.16088
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.59051

Cumulative Model Updates: 46,760
Cumulative Timesteps: 390,024,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 390024690...
Checkpoint 390024690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,375.18808
Policy Entropy: 3.73990
Value Function Loss: 0.05022

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.46538
Value Function Update Magnitude: 0.63840

Collected Steps per Second: 21,797.40774
Overall Steps per Second: 10,676.39905

Timestep Collection Time: 2.29394
Timestep Consumption Time: 2.38947
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.68341

Cumulative Model Updates: 46,766
Cumulative Timesteps: 390,074,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,046.34471
Policy Entropy: 3.73830
Value Function Loss: 0.05090

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.49871
Value Function Update Magnitude: 0.62219

Collected Steps per Second: 22,374.02302
Overall Steps per Second: 10,864.59768

Timestep Collection Time: 2.23599
Timestep Consumption Time: 2.36869
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.60468

Cumulative Model Updates: 46,772
Cumulative Timesteps: 390,124,720

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 390124720...
Checkpoint 390124720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,746.97408
Policy Entropy: 3.76115
Value Function Loss: 0.04708

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11534
Policy Update Magnitude: 0.52116
Value Function Update Magnitude: 0.71748

Collected Steps per Second: 22,002.42185
Overall Steps per Second: 10,698.37115

Timestep Collection Time: 2.27339
Timestep Consumption Time: 2.40209
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.67548

Cumulative Model Updates: 46,778
Cumulative Timesteps: 390,174,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,111.90184
Policy Entropy: 3.76392
Value Function Loss: 0.04780

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.48723
Value Function Update Magnitude: 0.77317

Collected Steps per Second: 22,293.06972
Overall Steps per Second: 10,854.44557

Timestep Collection Time: 2.24357
Timestep Consumption Time: 2.36431
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60788

Cumulative Model Updates: 46,784
Cumulative Timesteps: 390,224,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 390224756...
Checkpoint 390224756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.21771
Policy Entropy: 3.76158
Value Function Loss: 0.04600

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.52167
Value Function Update Magnitude: 0.77363

Collected Steps per Second: 21,614.96868
Overall Steps per Second: 10,738.24627

Timestep Collection Time: 2.31395
Timestep Consumption Time: 2.34379
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.65774

Cumulative Model Updates: 46,790
Cumulative Timesteps: 390,274,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,220.35594
Policy Entropy: 3.74678
Value Function Loss: 0.04742

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.53841
Value Function Update Magnitude: 0.74600

Collected Steps per Second: 22,454.40710
Overall Steps per Second: 10,825.82868

Timestep Collection Time: 2.22780
Timestep Consumption Time: 2.39300
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.62080

Cumulative Model Updates: 46,796
Cumulative Timesteps: 390,324,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 390324796...
Checkpoint 390324796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,974.24323
Policy Entropy: 3.74084
Value Function Loss: 0.04733

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.51449
Value Function Update Magnitude: 0.64689

Collected Steps per Second: 21,749.31668
Overall Steps per Second: 10,685.96135

Timestep Collection Time: 2.29892
Timestep Consumption Time: 2.38011
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.67904

Cumulative Model Updates: 46,802
Cumulative Timesteps: 390,374,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,443.71021
Policy Entropy: 3.74146
Value Function Loss: 0.04764

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.53035
Value Function Update Magnitude: 0.70791

Collected Steps per Second: 22,659.57366
Overall Steps per Second: 10,828.54947

Timestep Collection Time: 2.20693
Timestep Consumption Time: 2.41124
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61816

Cumulative Model Updates: 46,808
Cumulative Timesteps: 390,424,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 390424804...
Checkpoint 390424804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,998.97124
Policy Entropy: 3.74366
Value Function Loss: 0.04867

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.57769
Value Function Update Magnitude: 0.71010

Collected Steps per Second: 22,270.18068
Overall Steps per Second: 10,688.34027

Timestep Collection Time: 2.24569
Timestep Consumption Time: 2.43342
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.67912

Cumulative Model Updates: 46,814
Cumulative Timesteps: 390,474,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,018.29089
Policy Entropy: 3.73362
Value Function Loss: 0.04960

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.70219

Collected Steps per Second: 23,194.33657
Overall Steps per Second: 10,946.01967

Timestep Collection Time: 2.15647
Timestep Consumption Time: 2.41304
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.56951

Cumulative Model Updates: 46,820
Cumulative Timesteps: 390,524,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 390524834...
Checkpoint 390524834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,928.76876
Policy Entropy: 3.73293
Value Function Loss: 0.04976

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.52258
Value Function Update Magnitude: 0.74165

Collected Steps per Second: 22,511.20306
Overall Steps per Second: 10,633.91194

Timestep Collection Time: 2.22192
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.70363

Cumulative Model Updates: 46,826
Cumulative Timesteps: 390,574,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,684.56218
Policy Entropy: 3.73200
Value Function Loss: 0.05125

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.50324
Value Function Update Magnitude: 0.78371

Collected Steps per Second: 23,029.65503
Overall Steps per Second: 10,936.89818

Timestep Collection Time: 2.17302
Timestep Consumption Time: 2.40268
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.57570

Cumulative Model Updates: 46,832
Cumulative Timesteps: 390,624,896

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 390624896...
Checkpoint 390624896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,510.75665
Policy Entropy: 3.73924
Value Function Loss: 0.05140

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.48090
Value Function Update Magnitude: 0.80586

Collected Steps per Second: 22,147.91290
Overall Steps per Second: 10,587.41222

Timestep Collection Time: 2.25926
Timestep Consumption Time: 2.46691
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.72618

Cumulative Model Updates: 46,838
Cumulative Timesteps: 390,674,934

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,114.35570
Policy Entropy: 3.73535
Value Function Loss: 0.04987

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06831
Policy Update Magnitude: 0.52309
Value Function Update Magnitude: 0.79917

Collected Steps per Second: 23,034.50078
Overall Steps per Second: 10,831.05388

Timestep Collection Time: 2.17170
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.61857

Cumulative Model Updates: 46,844
Cumulative Timesteps: 390,724,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 390724958...
Checkpoint 390724958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,729.16274
Policy Entropy: 3.73968
Value Function Loss: 0.04886

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.53979
Value Function Update Magnitude: 0.77876

Collected Steps per Second: 22,516.29422
Overall Steps per Second: 10,716.67789

Timestep Collection Time: 2.22177
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.66805

Cumulative Model Updates: 46,850
Cumulative Timesteps: 390,774,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,935.70265
Policy Entropy: 3.73628
Value Function Loss: 0.04660

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.48222
Value Function Update Magnitude: 0.79237

Collected Steps per Second: 23,042.65272
Overall Steps per Second: 10,856.62189

Timestep Collection Time: 2.17102
Timestep Consumption Time: 2.43686
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.60788

Cumulative Model Updates: 46,856
Cumulative Timesteps: 390,825,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 390825010...
Checkpoint 390825010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,583.12092
Policy Entropy: 3.74557
Value Function Loss: 0.04593

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12250
Policy Update Magnitude: 0.40750
Value Function Update Magnitude: 0.80247

Collected Steps per Second: 22,255.40451
Overall Steps per Second: 10,711.21334

Timestep Collection Time: 2.24691
Timestep Consumption Time: 2.42165
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.66857

Cumulative Model Updates: 46,862
Cumulative Timesteps: 390,875,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,311.80106
Policy Entropy: 3.74717
Value Function Loss: 0.04641

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.43448
Value Function Update Magnitude: 0.79299

Collected Steps per Second: 22,865.65854
Overall Steps per Second: 10,807.04422

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.44090
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.62846

Cumulative Model Updates: 46,868
Cumulative Timesteps: 390,925,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 390925036...
Checkpoint 390925036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,012.78156
Policy Entropy: 3.75043
Value Function Loss: 0.04571

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.42087
Value Function Update Magnitude: 0.73111

Collected Steps per Second: 22,373.92414
Overall Steps per Second: 10,709.10958

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.67303

Cumulative Model Updates: 46,874
Cumulative Timesteps: 390,975,080

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,256.48705
Policy Entropy: 3.74806
Value Function Loss: 0.04518

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.41216
Value Function Update Magnitude: 0.63867

Collected Steps per Second: 22,708.98915
Overall Steps per Second: 10,661.36489

Timestep Collection Time: 2.20230
Timestep Consumption Time: 2.48866
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.69096

Cumulative Model Updates: 46,880
Cumulative Timesteps: 391,025,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 391025092...
Checkpoint 391025092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,150.01494
Policy Entropy: 3.75563
Value Function Loss: 0.04333

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.42087
Value Function Update Magnitude: 0.60377

Collected Steps per Second: 22,470.65130
Overall Steps per Second: 10,812.32527

Timestep Collection Time: 2.22610
Timestep Consumption Time: 2.40028
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.62639

Cumulative Model Updates: 46,886
Cumulative Timesteps: 391,075,114

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,667.33239
Policy Entropy: 3.76158
Value Function Loss: 0.03897

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.45183
Value Function Update Magnitude: 0.69167

Collected Steps per Second: 23,003.81412
Overall Steps per Second: 10,728.99141

Timestep Collection Time: 2.17355
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.66027

Cumulative Model Updates: 46,892
Cumulative Timesteps: 391,125,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 391125114...
Checkpoint 391125114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,413.98444
Policy Entropy: 3.75265
Value Function Loss: 0.03677

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.48496
Value Function Update Magnitude: 0.73958

Collected Steps per Second: 22,759.66231
Overall Steps per Second: 10,678.55736

Timestep Collection Time: 2.19704
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.68265

Cumulative Model Updates: 46,898
Cumulative Timesteps: 391,175,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.15995
Policy Entropy: 3.74995
Value Function Loss: 0.03832

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.54465
Value Function Update Magnitude: 0.72100

Collected Steps per Second: 22,909.67527
Overall Steps per Second: 10,694.53867

Timestep Collection Time: 2.18414
Timestep Consumption Time: 2.49469
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.67884

Cumulative Model Updates: 46,904
Cumulative Timesteps: 391,225,156

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 391225156...
Checkpoint 391225156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,194.98090
Policy Entropy: 3.73435
Value Function Loss: 0.04005

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06447
Policy Update Magnitude: 0.58360
Value Function Update Magnitude: 0.72072

Collected Steps per Second: 22,684.80253
Overall Steps per Second: 10,612.70684

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.50782
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71246

Cumulative Model Updates: 46,910
Cumulative Timesteps: 391,275,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,938.92672
Policy Entropy: 3.74356
Value Function Loss: 0.04040

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06319
Policy Update Magnitude: 0.60029
Value Function Update Magnitude: 0.71579

Collected Steps per Second: 23,115.99937
Overall Steps per Second: 10,845.16339

Timestep Collection Time: 2.16370
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61183

Cumulative Model Updates: 46,916
Cumulative Timesteps: 391,325,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 391325184...
Checkpoint 391325184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,656.97640
Policy Entropy: 3.74199
Value Function Loss: 0.04035

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.57046
Value Function Update Magnitude: 0.71567

Collected Steps per Second: 22,537.70727
Overall Steps per Second: 10,763.25150

Timestep Collection Time: 2.21966
Timestep Consumption Time: 2.42819
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.64785

Cumulative Model Updates: 46,922
Cumulative Timesteps: 391,375,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,534.84426
Policy Entropy: 3.74693
Value Function Loss: 0.03915

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.58203
Value Function Update Magnitude: 0.72973

Collected Steps per Second: 23,121.78696
Overall Steps per Second: 10,900.62865

Timestep Collection Time: 2.16359
Timestep Consumption Time: 2.42569
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.58928

Cumulative Model Updates: 46,928
Cumulative Timesteps: 391,425,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 391425236...
Checkpoint 391425236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,375.39600
Policy Entropy: 3.73877
Value Function Loss: 0.03950

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.59270
Value Function Update Magnitude: 0.71470

Collected Steps per Second: 22,373.15358
Overall Steps per Second: 10,611.09749

Timestep Collection Time: 2.23598
Timestep Consumption Time: 2.47851
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.71450

Cumulative Model Updates: 46,934
Cumulative Timesteps: 391,475,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,341.21782
Policy Entropy: 3.75819
Value Function Loss: 0.04014

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06484
Policy Update Magnitude: 0.59985
Value Function Update Magnitude: 0.67587

Collected Steps per Second: 23,024.65584
Overall Steps per Second: 10,852.61184

Timestep Collection Time: 2.17211
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.60829

Cumulative Model Updates: 46,940
Cumulative Timesteps: 391,525,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 391525274...
Checkpoint 391525274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.79257
Policy Entropy: 3.75167
Value Function Loss: 0.04223

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.60683
Value Function Update Magnitude: 0.70100

Collected Steps per Second: 22,728.69552
Overall Steps per Second: 10,691.50235

Timestep Collection Time: 2.20118
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.67942

Cumulative Model Updates: 46,946
Cumulative Timesteps: 391,575,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,452.67229
Policy Entropy: 3.75719
Value Function Loss: 0.04654

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.57117
Value Function Update Magnitude: 0.75121

Collected Steps per Second: 23,322.43424
Overall Steps per Second: 10,927.86328

Timestep Collection Time: 2.14489
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.57766

Cumulative Model Updates: 46,952
Cumulative Timesteps: 391,625,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 391625328...
Checkpoint 391625328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,917.75132
Policy Entropy: 3.73264
Value Function Loss: 0.04753

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.50558
Value Function Update Magnitude: 0.75055

Collected Steps per Second: 22,396.68637
Overall Steps per Second: 10,646.04588

Timestep Collection Time: 2.23301
Timestep Consumption Time: 2.46470
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.69771

Cumulative Model Updates: 46,958
Cumulative Timesteps: 391,675,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,085.91915
Policy Entropy: 3.74180
Value Function Loss: 0.04839

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.42106
Value Function Update Magnitude: 0.72128

Collected Steps per Second: 22,959.71422
Overall Steps per Second: 10,829.54675

Timestep Collection Time: 2.17816
Timestep Consumption Time: 2.43976
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.61792

Cumulative Model Updates: 46,964
Cumulative Timesteps: 391,725,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 391725350...
Checkpoint 391725350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,274.73793
Policy Entropy: 3.73523
Value Function Loss: 0.04643

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.39796
Value Function Update Magnitude: 0.76895

Collected Steps per Second: 22,528.68420
Overall Steps per Second: 10,679.64163

Timestep Collection Time: 2.21984
Timestep Consumption Time: 2.46290
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.68274

Cumulative Model Updates: 46,970
Cumulative Timesteps: 391,775,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,333.63848
Policy Entropy: 3.72481
Value Function Loss: 0.04513

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.40833
Value Function Update Magnitude: 0.80502

Collected Steps per Second: 23,067.28165
Overall Steps per Second: 10,869.52247

Timestep Collection Time: 2.16853
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60204

Cumulative Model Updates: 46,976
Cumulative Timesteps: 391,825,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 391825382...
Checkpoint 391825382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,263.38827
Policy Entropy: 3.72768
Value Function Loss: 0.04452

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.42903
Value Function Update Magnitude: 0.80329

Collected Steps per Second: 22,362.46803
Overall Steps per Second: 10,728.06945

Timestep Collection Time: 2.23723
Timestep Consumption Time: 2.42624
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.66347

Cumulative Model Updates: 46,982
Cumulative Timesteps: 391,875,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,587.30004
Policy Entropy: 3.72915
Value Function Loss: 0.04439

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.42138
Value Function Update Magnitude: 0.78733

Collected Steps per Second: 23,227.91485
Overall Steps per Second: 10,908.32657

Timestep Collection Time: 2.15336
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.58530

Cumulative Model Updates: 46,988
Cumulative Timesteps: 391,925,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 391925430...
Checkpoint 391925430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,006.60421
Policy Entropy: 3.74089
Value Function Loss: 0.04573

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.43043
Value Function Update Magnitude: 0.78116

Collected Steps per Second: 22,389.42441
Overall Steps per Second: 10,599.98694

Timestep Collection Time: 2.23382
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.71831

Cumulative Model Updates: 46,994
Cumulative Timesteps: 391,975,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,009.26452
Policy Entropy: 3.73997
Value Function Loss: 0.04791

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.44793
Value Function Update Magnitude: 0.72659

Collected Steps per Second: 23,091.04999
Overall Steps per Second: 10,894.52830

Timestep Collection Time: 2.16586
Timestep Consumption Time: 2.42470
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.59056

Cumulative Model Updates: 47,000
Cumulative Timesteps: 392,025,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 392025456...
Checkpoint 392025456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,834.82432
Policy Entropy: 3.73923
Value Function Loss: 0.04980

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.47560
Value Function Update Magnitude: 0.77343

Collected Steps per Second: 22,505.89885
Overall Steps per Second: 10,693.48936

Timestep Collection Time: 2.22208
Timestep Consumption Time: 2.45459
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.67668

Cumulative Model Updates: 47,006
Cumulative Timesteps: 392,075,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,862.59881
Policy Entropy: 3.72624
Value Function Loss: 0.05071

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.53624
Value Function Update Magnitude: 0.81779

Collected Steps per Second: 23,305.88591
Overall Steps per Second: 10,921.38169

Timestep Collection Time: 2.14598
Timestep Consumption Time: 2.43348
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.57946

Cumulative Model Updates: 47,012
Cumulative Timesteps: 392,125,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 392125480...
Checkpoint 392125480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,235.07765
Policy Entropy: 3.72300
Value Function Loss: 0.04986

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.60377
Value Function Update Magnitude: 0.79130

Collected Steps per Second: 22,658.69443
Overall Steps per Second: 10,589.33002

Timestep Collection Time: 2.20763
Timestep Consumption Time: 2.51618
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.72381

Cumulative Model Updates: 47,018
Cumulative Timesteps: 392,175,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.33059
Policy Entropy: 3.72482
Value Function Loss: 0.04966

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.52667
Value Function Update Magnitude: 0.80288

Collected Steps per Second: 23,468.10312
Overall Steps per Second: 10,976.47916

Timestep Collection Time: 2.13132
Timestep Consumption Time: 2.42552
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.55683

Cumulative Model Updates: 47,024
Cumulative Timesteps: 392,225,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 392225520...
Checkpoint 392225520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,028.54316
Policy Entropy: 3.73463
Value Function Loss: 0.04875

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.49862
Value Function Update Magnitude: 0.84984

Collected Steps per Second: 22,649.57757
Overall Steps per Second: 10,635.93196

Timestep Collection Time: 2.20799
Timestep Consumption Time: 2.49400
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.70199

Cumulative Model Updates: 47,030
Cumulative Timesteps: 392,275,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,502.55353
Policy Entropy: 3.72853
Value Function Loss: 0.04957

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.52064
Value Function Update Magnitude: 0.82344

Collected Steps per Second: 22,426.81648
Overall Steps per Second: 10,877.51918

Timestep Collection Time: 2.23037
Timestep Consumption Time: 2.36811
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.59848

Cumulative Model Updates: 47,036
Cumulative Timesteps: 392,325,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 392325550...
Checkpoint 392325550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,103.82594
Policy Entropy: 3.72479
Value Function Loss: 0.04890

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.50353
Value Function Update Magnitude: 0.68144

Collected Steps per Second: 21,924.66293
Overall Steps per Second: 10,616.37535

Timestep Collection Time: 2.28108
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.71084

Cumulative Model Updates: 47,042
Cumulative Timesteps: 392,375,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,382.06056
Policy Entropy: 3.72877
Value Function Loss: 0.04702

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.47064
Value Function Update Magnitude: 0.67060

Collected Steps per Second: 22,331.44061
Overall Steps per Second: 10,882.97932

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.35656
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.59672

Cumulative Model Updates: 47,048
Cumulative Timesteps: 392,425,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 392425588...
Checkpoint 392425588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,554.89094
Policy Entropy: 3.72743
Value Function Loss: 0.04710

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.46224
Value Function Update Magnitude: 0.73647

Collected Steps per Second: 21,717.17902
Overall Steps per Second: 10,694.56588

Timestep Collection Time: 2.30242
Timestep Consumption Time: 2.37304
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.67546

Cumulative Model Updates: 47,054
Cumulative Timesteps: 392,475,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.19378
Policy Entropy: 3.74163
Value Function Loss: 0.04498

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.46369
Value Function Update Magnitude: 0.75126

Collected Steps per Second: 22,155.47078
Overall Steps per Second: 10,814.66787

Timestep Collection Time: 2.25786
Timestep Consumption Time: 2.36771
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.62557

Cumulative Model Updates: 47,060
Cumulative Timesteps: 392,525,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 392525614...
Checkpoint 392525614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,875.95096
Policy Entropy: 3.74291
Value Function Loss: 0.04731

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.47726
Value Function Update Magnitude: 0.74999

Collected Steps per Second: 21,954.82084
Overall Steps per Second: 10,730.15160

Timestep Collection Time: 2.27850
Timestep Consumption Time: 2.38351
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.66200

Cumulative Model Updates: 47,066
Cumulative Timesteps: 392,575,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,346.78307
Policy Entropy: 3.73563
Value Function Loss: 0.04804

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.48647
Value Function Update Magnitude: 0.73530

Collected Steps per Second: 22,193.76504
Overall Steps per Second: 10,856.35804

Timestep Collection Time: 2.25298
Timestep Consumption Time: 2.35281
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60578

Cumulative Model Updates: 47,072
Cumulative Timesteps: 392,625,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 392625640...
Checkpoint 392625640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,973.98973
Policy Entropy: 3.72494
Value Function Loss: 0.05117

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.57418
Value Function Update Magnitude: 0.69989

Collected Steps per Second: 21,970.33171
Overall Steps per Second: 10,703.05626

Timestep Collection Time: 2.27689
Timestep Consumption Time: 2.39692
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.67381

Cumulative Model Updates: 47,078
Cumulative Timesteps: 392,675,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,288.68954
Policy Entropy: 3.72252
Value Function Loss: 0.05231

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.60845
Value Function Update Magnitude: 0.75052

Collected Steps per Second: 23,124.31657
Overall Steps per Second: 10,884.61766

Timestep Collection Time: 2.16352
Timestep Consumption Time: 2.43287
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.59639

Cumulative Model Updates: 47,084
Cumulative Timesteps: 392,725,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 392725694...
Checkpoint 392725694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,650.97157
Policy Entropy: 3.72483
Value Function Loss: 0.05242

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10435
Policy Update Magnitude: 0.54595
Value Function Update Magnitude: 0.73631

Collected Steps per Second: 22,298.91648
Overall Steps per Second: 10,641.74686

Timestep Collection Time: 2.24334
Timestep Consumption Time: 2.45739
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.70073

Cumulative Model Updates: 47,090
Cumulative Timesteps: 392,775,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,967.38168
Policy Entropy: 3.73171
Value Function Loss: 0.05218

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.48120
Value Function Update Magnitude: 0.70035

Collected Steps per Second: 22,520.45248
Overall Steps per Second: 10,660.61038

Timestep Collection Time: 2.22065
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.69110

Cumulative Model Updates: 47,096
Cumulative Timesteps: 392,825,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 392825728...
Checkpoint 392825728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,687.32387
Policy Entropy: 3.73406
Value Function Loss: 0.05072

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06743
Policy Update Magnitude: 0.52219
Value Function Update Magnitude: 0.76411

Collected Steps per Second: 22,474.38292
Overall Steps per Second: 10,636.98072

Timestep Collection Time: 2.22556
Timestep Consumption Time: 2.47672
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.70227

Cumulative Model Updates: 47,102
Cumulative Timesteps: 392,875,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,007.83118
Policy Entropy: 3.73787
Value Function Loss: 0.04842

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06520
Policy Update Magnitude: 0.59750
Value Function Update Magnitude: 0.79537

Collected Steps per Second: 22,898.53084
Overall Steps per Second: 10,686.62644

Timestep Collection Time: 2.18355
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.67875

Cumulative Model Updates: 47,108
Cumulative Timesteps: 392,925,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 392925746...
Checkpoint 392925746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,992.94206
Policy Entropy: 3.73188
Value Function Loss: 0.04626

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.53456
Value Function Update Magnitude: 0.83316

Collected Steps per Second: 22,717.79336
Overall Steps per Second: 10,633.48405

Timestep Collection Time: 2.20215
Timestep Consumption Time: 2.50261
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.70476

Cumulative Model Updates: 47,114
Cumulative Timesteps: 392,975,774

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,709.35961
Policy Entropy: 3.73012
Value Function Loss: 0.04692

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.46469
Value Function Update Magnitude: 0.83555

Collected Steps per Second: 23,215.92894
Overall Steps per Second: 10,891.55872

Timestep Collection Time: 2.15387
Timestep Consumption Time: 2.43721
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.59108

Cumulative Model Updates: 47,120
Cumulative Timesteps: 393,025,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 393025778...
Checkpoint 393025778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,183.74381
Policy Entropy: 3.71477
Value Function Loss: 0.04677

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.44981
Value Function Update Magnitude: 0.83644

Collected Steps per Second: 22,572.83571
Overall Steps per Second: 10,674.14859

Timestep Collection Time: 2.21576
Timestep Consumption Time: 2.46995
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.68571

Cumulative Model Updates: 47,126
Cumulative Timesteps: 393,075,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,769.59999
Policy Entropy: 3.70744
Value Function Loss: 0.04689

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.43958
Value Function Update Magnitude: 0.80480

Collected Steps per Second: 23,040.65542
Overall Steps per Second: 10,872.49253

Timestep Collection Time: 2.17129
Timestep Consumption Time: 2.43004
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60134

Cumulative Model Updates: 47,132
Cumulative Timesteps: 393,125,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 393125822...
Checkpoint 393125822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,306.25310
Policy Entropy: 3.71057
Value Function Loss: 0.04647

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.44311
Value Function Update Magnitude: 0.75783

Collected Steps per Second: 22,383.43687
Overall Steps per Second: 10,655.55138

Timestep Collection Time: 2.23469
Timestep Consumption Time: 2.45958
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.69427

Cumulative Model Updates: 47,138
Cumulative Timesteps: 393,175,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,914.09060
Policy Entropy: 3.71090
Value Function Loss: 0.05054

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.49773
Value Function Update Magnitude: 0.71434

Collected Steps per Second: 22,885.37673
Overall Steps per Second: 10,829.58881

Timestep Collection Time: 2.18550
Timestep Consumption Time: 2.43296
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.61846

Cumulative Model Updates: 47,144
Cumulative Timesteps: 393,225,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 393225858...
Checkpoint 393225858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,282.18989
Policy Entropy: 3.71881
Value Function Loss: 0.05237

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.52554
Value Function Update Magnitude: 0.65875

Collected Steps per Second: 22,238.92863
Overall Steps per Second: 10,702.78063

Timestep Collection Time: 2.24957
Timestep Consumption Time: 2.42473
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.67430

Cumulative Model Updates: 47,150
Cumulative Timesteps: 393,275,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.50780
Policy Entropy: 3.71561
Value Function Loss: 0.05282

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.57870
Value Function Update Magnitude: 0.61992

Collected Steps per Second: 23,181.94425
Overall Steps per Second: 10,874.45867

Timestep Collection Time: 2.15823
Timestep Consumption Time: 2.44264
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.60087

Cumulative Model Updates: 47,156
Cumulative Timesteps: 393,325,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 393325918...
Checkpoint 393325918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,257.81461
Policy Entropy: 3.72025
Value Function Loss: 0.05189

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.59404
Value Function Update Magnitude: 0.60415

Collected Steps per Second: 22,371.73887
Overall Steps per Second: 10,728.50127

Timestep Collection Time: 2.23586
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.66235

Cumulative Model Updates: 47,162
Cumulative Timesteps: 393,375,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,031.07876
Policy Entropy: 3.72597
Value Function Loss: 0.05356

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.57601
Value Function Update Magnitude: 0.52511

Collected Steps per Second: 22,867.32161
Overall Steps per Second: 10,818.76247

Timestep Collection Time: 2.18696
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62252

Cumulative Model Updates: 47,168
Cumulative Timesteps: 393,425,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 393425948...
Checkpoint 393425948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,014.32156
Policy Entropy: 3.73010
Value Function Loss: 0.05022

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.54133
Value Function Update Magnitude: 0.54372

Collected Steps per Second: 22,177.23706
Overall Steps per Second: 10,676.10758

Timestep Collection Time: 2.25501
Timestep Consumption Time: 2.42928
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.68429

Cumulative Model Updates: 47,174
Cumulative Timesteps: 393,475,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,674.00806
Policy Entropy: 3.73328
Value Function Loss: 0.04904

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07168
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.69660

Collected Steps per Second: 22,899.60924
Overall Steps per Second: 10,715.37624

Timestep Collection Time: 2.18467
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.66880

Cumulative Model Updates: 47,180
Cumulative Timesteps: 393,525,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 393525986...
Checkpoint 393525986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,219.95274
Policy Entropy: 3.73749
Value Function Loss: 0.04990

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08462
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.75943

Collected Steps per Second: 22,623.29670
Overall Steps per Second: 10,772.71142

Timestep Collection Time: 2.21135
Timestep Consumption Time: 2.43261
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.64396

Cumulative Model Updates: 47,186
Cumulative Timesteps: 393,576,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,236.65533
Policy Entropy: 3.73642
Value Function Loss: 0.04976

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10429
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.75519

Collected Steps per Second: 23,046.72315
Overall Steps per Second: 10,742.24666

Timestep Collection Time: 2.16959
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.65471

Cumulative Model Updates: 47,192
Cumulative Timesteps: 393,626,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 393626016...
Checkpoint 393626016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,153.47163
Policy Entropy: 3.74810
Value Function Loss: 0.04906

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.48009
Value Function Update Magnitude: 0.70883

Collected Steps per Second: 22,519.70429
Overall Steps per Second: 10,644.43799

Timestep Collection Time: 2.22090
Timestep Consumption Time: 2.47770
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.69860

Cumulative Model Updates: 47,198
Cumulative Timesteps: 393,676,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,631.35141
Policy Entropy: 3.75822
Value Function Loss: 0.04817

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.47126
Value Function Update Magnitude: 0.70962

Collected Steps per Second: 22,686.41863
Overall Steps per Second: 10,707.75582

Timestep Collection Time: 2.20502
Timestep Consumption Time: 2.46673
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.67175

Cumulative Model Updates: 47,204
Cumulative Timesteps: 393,726,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 393726054...
Checkpoint 393726054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,029.37552
Policy Entropy: 3.75719
Value Function Loss: 0.04663

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.50413
Value Function Update Magnitude: 0.81286

Collected Steps per Second: 22,667.11010
Overall Steps per Second: 10,636.29599

Timestep Collection Time: 2.20584
Timestep Consumption Time: 2.49505
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.70088

Cumulative Model Updates: 47,210
Cumulative Timesteps: 393,776,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,723.28701
Policy Entropy: 3.75135
Value Function Loss: 0.04684

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.52624
Value Function Update Magnitude: 0.84913

Collected Steps per Second: 23,081.79632
Overall Steps per Second: 10,867.25774

Timestep Collection Time: 2.16725
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.60319

Cumulative Model Updates: 47,216
Cumulative Timesteps: 393,826,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 393826078...
Checkpoint 393826078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,120.25243
Policy Entropy: 3.75558
Value Function Loss: 0.04461

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.52085
Value Function Update Magnitude: 0.82113

Collected Steps per Second: 22,314.39706
Overall Steps per Second: 10,738.52377

Timestep Collection Time: 2.24214
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.65911

Cumulative Model Updates: 47,222
Cumulative Timesteps: 393,876,110

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,974.69677
Policy Entropy: 3.74930
Value Function Loss: 0.04373

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.71704

Collected Steps per Second: 22,862.26907
Overall Steps per Second: 10,804.59010

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.44173
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.62970

Cumulative Model Updates: 47,228
Cumulative Timesteps: 393,926,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 393926132...
Checkpoint 393926132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.97021
Policy Entropy: 3.76302
Value Function Loss: 0.04182

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.49931
Value Function Update Magnitude: 0.69785

Collected Steps per Second: 22,608.71758
Overall Steps per Second: 10,668.20282

Timestep Collection Time: 2.21295
Timestep Consumption Time: 2.47687
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.68982

Cumulative Model Updates: 47,234
Cumulative Timesteps: 393,976,164

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,306.27842
Policy Entropy: 3.78252
Value Function Loss: 0.04318

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.51336
Value Function Update Magnitude: 0.64482

Collected Steps per Second: 22,588.13548
Overall Steps per Second: 10,662.98515

Timestep Collection Time: 2.21408
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.69024

Cumulative Model Updates: 47,240
Cumulative Timesteps: 394,026,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 394026176...
Checkpoint 394026176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,225.12307
Policy Entropy: 3.79695
Value Function Loss: 0.04459

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.51718
Value Function Update Magnitude: 0.63265

Collected Steps per Second: 22,849.00039
Overall Steps per Second: 10,843.10474

Timestep Collection Time: 2.18845
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.61159

Cumulative Model Updates: 47,246
Cumulative Timesteps: 394,076,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,154.11968
Policy Entropy: 3.80346
Value Function Loss: 0.04504

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.54490
Value Function Update Magnitude: 0.67051

Collected Steps per Second: 22,867.67981
Overall Steps per Second: 10,694.29125

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.49049
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.67838

Cumulative Model Updates: 47,252
Cumulative Timesteps: 394,126,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 394126212...
Checkpoint 394126212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.78183
Policy Entropy: 3.79115
Value Function Loss: 0.04504

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.54037
Value Function Update Magnitude: 0.66132

Collected Steps per Second: 22,769.83375
Overall Steps per Second: 10,814.75182

Timestep Collection Time: 2.19615
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.62387

Cumulative Model Updates: 47,258
Cumulative Timesteps: 394,176,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,996.15744
Policy Entropy: 3.78631
Value Function Loss: 0.04431

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.50860
Value Function Update Magnitude: 0.59157

Collected Steps per Second: 22,811.26459
Overall Steps per Second: 10,648.14588

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.50385
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.69584

Cumulative Model Updates: 47,264
Cumulative Timesteps: 394,226,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 394226220...
Checkpoint 394226220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.38157
Policy Entropy: 3.77709
Value Function Loss: 0.04472

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.55459

Collected Steps per Second: 22,537.28446
Overall Steps per Second: 10,570.30229

Timestep Collection Time: 2.21961
Timestep Consumption Time: 2.51289
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.73250

Cumulative Model Updates: 47,270
Cumulative Timesteps: 394,276,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,066.71380
Policy Entropy: 3.78386
Value Function Loss: 0.04350

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.52201
Value Function Update Magnitude: 0.61602

Collected Steps per Second: 22,871.58565
Overall Steps per Second: 10,823.79651

Timestep Collection Time: 2.18699
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.62130

Cumulative Model Updates: 47,276
Cumulative Timesteps: 394,326,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 394326264...
Checkpoint 394326264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,264.12023
Policy Entropy: 3.78335
Value Function Loss: 0.04148

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06829
Policy Update Magnitude: 0.58056
Value Function Update Magnitude: 0.70576

Collected Steps per Second: 22,494.29537
Overall Steps per Second: 10,682.45169

Timestep Collection Time: 2.22367
Timestep Consumption Time: 2.45877
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.68245

Cumulative Model Updates: 47,282
Cumulative Timesteps: 394,376,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,916.76367
Policy Entropy: 3.79252
Value Function Loss: 0.04100

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06457
Policy Update Magnitude: 0.62401
Value Function Update Magnitude: 0.75429

Collected Steps per Second: 23,137.30682
Overall Steps per Second: 10,874.67371

Timestep Collection Time: 2.16101
Timestep Consumption Time: 2.43683
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.59784

Cumulative Model Updates: 47,288
Cumulative Timesteps: 394,426,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 394426284...
Checkpoint 394426284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,021.69215
Policy Entropy: 3.79102
Value Function Loss: 0.04045

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07742
Policy Update Magnitude: 0.61061
Value Function Update Magnitude: 0.78650

Collected Steps per Second: 22,246.98755
Overall Steps per Second: 10,730.19512

Timestep Collection Time: 2.24848
Timestep Consumption Time: 2.41331
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.66180

Cumulative Model Updates: 47,294
Cumulative Timesteps: 394,476,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,579.55584
Policy Entropy: 3.78882
Value Function Loss: 0.04080

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.56194
Value Function Update Magnitude: 0.79231

Collected Steps per Second: 22,946.32397
Overall Steps per Second: 10,824.58216

Timestep Collection Time: 2.17935
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.61985

Cumulative Model Updates: 47,300
Cumulative Timesteps: 394,526,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 394526314...
Checkpoint 394526314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,438.89657
Policy Entropy: 3.78586
Value Function Loss: 0.04034

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06840
Policy Update Magnitude: 0.58676
Value Function Update Magnitude: 0.78395

Collected Steps per Second: 22,674.65773
Overall Steps per Second: 10,689.34273

Timestep Collection Time: 2.20616
Timestep Consumption Time: 2.47364
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.67980

Cumulative Model Updates: 47,306
Cumulative Timesteps: 394,576,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,822.93985
Policy Entropy: 3.78785
Value Function Loss: 0.04282

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06340
Policy Update Magnitude: 0.60141
Value Function Update Magnitude: 0.68643

Collected Steps per Second: 23,055.72925
Overall Steps per Second: 10,881.70798

Timestep Collection Time: 2.16892
Timestep Consumption Time: 2.42650
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.59542

Cumulative Model Updates: 47,312
Cumulative Timesteps: 394,626,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 394626344...
Checkpoint 394626344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,847.08360
Policy Entropy: 3.78523
Value Function Loss: 0.04605

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.58676
Value Function Update Magnitude: 0.59690

Collected Steps per Second: 22,387.50282
Overall Steps per Second: 10,674.94092

Timestep Collection Time: 2.23392
Timestep Consumption Time: 2.45107
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.68499

Cumulative Model Updates: 47,318
Cumulative Timesteps: 394,676,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.72568
Policy Entropy: 3.78193
Value Function Loss: 0.04780

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.52739
Value Function Update Magnitude: 0.70400

Collected Steps per Second: 23,435.01675
Overall Steps per Second: 10,868.99613

Timestep Collection Time: 2.13399
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.60116

Cumulative Model Updates: 47,324
Cumulative Timesteps: 394,726,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 394726366...
Checkpoint 394726366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,287.96301
Policy Entropy: 3.77744
Value Function Loss: 0.05165

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.50106
Value Function Update Magnitude: 0.69858

Collected Steps per Second: 22,701.98868
Overall Steps per Second: 10,638.79858

Timestep Collection Time: 2.20342
Timestep Consumption Time: 2.49843
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.70185

Cumulative Model Updates: 47,330
Cumulative Timesteps: 394,776,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,299.81008
Policy Entropy: 3.77738
Value Function Loss: 0.04932

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.46483
Value Function Update Magnitude: 0.70811

Collected Steps per Second: 23,122.03292
Overall Steps per Second: 10,896.11303

Timestep Collection Time: 2.16305
Timestep Consumption Time: 2.42703
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59008

Cumulative Model Updates: 47,336
Cumulative Timesteps: 394,826,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 394826402...
Checkpoint 394826402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,415.06911
Policy Entropy: 3.77239
Value Function Loss: 0.04631

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.47496
Value Function Update Magnitude: 0.78097

Collected Steps per Second: 21,685.99366
Overall Steps per Second: 10,670.13868

Timestep Collection Time: 2.30656
Timestep Consumption Time: 2.38129
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.68785

Cumulative Model Updates: 47,342
Cumulative Timesteps: 394,876,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,916.50915
Policy Entropy: 3.77445
Value Function Loss: 0.04270

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.54851
Value Function Update Magnitude: 0.79236

Collected Steps per Second: 22,360.54058
Overall Steps per Second: 10,858.09779

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.36944
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.60615

Cumulative Model Updates: 47,348
Cumulative Timesteps: 394,926,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 394926436...
Checkpoint 394926436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,497.24736
Policy Entropy: 3.77214
Value Function Loss: 0.04493

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06076
Policy Update Magnitude: 0.62658
Value Function Update Magnitude: 0.81282

Collected Steps per Second: 21,834.33462
Overall Steps per Second: 10,685.98788

Timestep Collection Time: 2.29135
Timestep Consumption Time: 2.39049
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.68183

Cumulative Model Updates: 47,354
Cumulative Timesteps: 394,976,466

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,539.66251
Policy Entropy: 3.77046
Value Function Loss: 0.04609

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.62871
Value Function Update Magnitude: 0.82208

Collected Steps per Second: 22,445.96180
Overall Steps per Second: 10,929.58149

Timestep Collection Time: 2.22828
Timestep Consumption Time: 2.34792
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.57620

Cumulative Model Updates: 47,360
Cumulative Timesteps: 395,026,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 395026482...
Checkpoint 395026482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,097.01065
Policy Entropy: 3.75927
Value Function Loss: 0.04752

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.63431
Value Function Update Magnitude: 0.83480

Collected Steps per Second: 21,816.70022
Overall Steps per Second: 10,661.46844

Timestep Collection Time: 2.29384
Timestep Consumption Time: 2.40007
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.69391

Cumulative Model Updates: 47,366
Cumulative Timesteps: 395,076,526

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,541.00112
Policy Entropy: 3.76400
Value Function Loss: 0.04619

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.54153
Value Function Update Magnitude: 0.83846

Collected Steps per Second: 23,042.20380
Overall Steps per Second: 10,937.56112

Timestep Collection Time: 2.17097
Timestep Consumption Time: 2.40262
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.57360

Cumulative Model Updates: 47,372
Cumulative Timesteps: 395,126,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 395126550...
Checkpoint 395126550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,618.46450
Policy Entropy: 3.75530
Value Function Loss: 0.04510

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.50601
Value Function Update Magnitude: 0.83602

Collected Steps per Second: 22,429.32058
Overall Steps per Second: 10,584.91102

Timestep Collection Time: 2.23038
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.72616

Cumulative Model Updates: 47,378
Cumulative Timesteps: 395,176,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,575.97246
Policy Entropy: 3.75109
Value Function Loss: 0.04668

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.53446
Value Function Update Magnitude: 0.82117

Collected Steps per Second: 23,015.28904
Overall Steps per Second: 10,901.56087

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.41519
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.58870

Cumulative Model Updates: 47,384
Cumulative Timesteps: 395,226,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 395226600...
Checkpoint 395226600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,659.63908
Policy Entropy: 3.75866
Value Function Loss: 0.04655

Mean KL Divergence: 0.02042
SB3 Clip Fraction: 0.16602
Policy Update Magnitude: 0.49321
Value Function Update Magnitude: 0.80913

Collected Steps per Second: 22,456.98121
Overall Steps per Second: 10,654.31522

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.46774
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.69537

Cumulative Model Updates: 47,390
Cumulative Timesteps: 395,276,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,812.61376
Policy Entropy: 3.75625
Value Function Loss: 0.04824

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.49689
Value Function Update Magnitude: 0.80220

Collected Steps per Second: 22,807.94268
Overall Steps per Second: 10,871.24608

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.40765
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.60039

Cumulative Model Updates: 47,396
Cumulative Timesteps: 395,326,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 395326638...
Checkpoint 395326638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,504.40883
Policy Entropy: 3.74962
Value Function Loss: 0.04725

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.57391
Value Function Update Magnitude: 0.82826

Collected Steps per Second: 22,431.43260
Overall Steps per Second: 10,643.03926

Timestep Collection Time: 2.23017
Timestep Consumption Time: 2.47017
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.70035

Cumulative Model Updates: 47,402
Cumulative Timesteps: 395,376,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,790.80342
Policy Entropy: 3.74525
Value Function Loss: 0.04693

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.60564
Value Function Update Magnitude: 0.83379

Collected Steps per Second: 23,287.55742
Overall Steps per Second: 10,921.66160

Timestep Collection Time: 2.14716
Timestep Consumption Time: 2.43109
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.57824

Cumulative Model Updates: 47,408
Cumulative Timesteps: 395,426,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 395426666...
Checkpoint 395426666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,194.29056
Policy Entropy: 3.74652
Value Function Loss: 0.04691

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.83012

Collected Steps per Second: 22,469.00592
Overall Steps per Second: 10,696.12267

Timestep Collection Time: 2.22538
Timestep Consumption Time: 2.44940
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.67478

Cumulative Model Updates: 47,414
Cumulative Timesteps: 395,476,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,899.52889
Policy Entropy: 3.76121
Value Function Loss: 0.04825

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.43133
Value Function Update Magnitude: 0.73594

Collected Steps per Second: 23,067.93907
Overall Steps per Second: 10,840.51332

Timestep Collection Time: 2.16890
Timestep Consumption Time: 2.44638
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.61528

Cumulative Model Updates: 47,420
Cumulative Timesteps: 395,526,700

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 395526700...
Checkpoint 395526700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,635.82734
Policy Entropy: 3.76554
Value Function Loss: 0.04682

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.45419
Value Function Update Magnitude: 0.74513

Collected Steps per Second: 22,442.92686
Overall Steps per Second: 10,662.17701

Timestep Collection Time: 2.22841
Timestep Consumption Time: 2.46219
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.69060

Cumulative Model Updates: 47,426
Cumulative Timesteps: 395,576,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,832.99604
Policy Entropy: 3.75970
Value Function Loss: 0.04657

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.49314
Value Function Update Magnitude: 0.77731

Collected Steps per Second: 22,799.60205
Overall Steps per Second: 10,712.96018

Timestep Collection Time: 2.19372
Timestep Consumption Time: 2.47502
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.66874

Cumulative Model Updates: 47,432
Cumulative Timesteps: 395,626,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 395626728...
Checkpoint 395626728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,105.44439
Policy Entropy: 3.75130
Value Function Loss: 0.05027

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.67406

Collected Steps per Second: 22,404.86096
Overall Steps per Second: 10,637.93616

Timestep Collection Time: 2.23291
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.70279

Cumulative Model Updates: 47,438
Cumulative Timesteps: 395,676,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,170.69868
Policy Entropy: 3.75269
Value Function Loss: 0.05022

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.72248

Collected Steps per Second: 22,803.23868
Overall Steps per Second: 10,650.42822

Timestep Collection Time: 2.19276
Timestep Consumption Time: 2.50208
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.69483

Cumulative Model Updates: 47,444
Cumulative Timesteps: 395,726,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 395726758...
Checkpoint 395726758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,043.62484
Policy Entropy: 3.76211
Value Function Loss: 0.05063

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.49999
Value Function Update Magnitude: 0.65502

Collected Steps per Second: 22,563.74864
Overall Steps per Second: 10,624.80314

Timestep Collection Time: 2.21630
Timestep Consumption Time: 2.49042
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.70672

Cumulative Model Updates: 47,450
Cumulative Timesteps: 395,776,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,768.67700
Policy Entropy: 3.76572
Value Function Loss: 0.04593

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.47396
Value Function Update Magnitude: 0.71541

Collected Steps per Second: 23,207.36882
Overall Steps per Second: 10,896.77067

Timestep Collection Time: 2.15492
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.58943

Cumulative Model Updates: 47,456
Cumulative Timesteps: 395,826,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 395826776...
Checkpoint 395826776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,239.92224
Policy Entropy: 3.77517
Value Function Loss: 0.04277

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.76677

Collected Steps per Second: 22,501.93623
Overall Steps per Second: 10,687.24575

Timestep Collection Time: 2.22301
Timestep Consumption Time: 2.45752
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.68053

Cumulative Model Updates: 47,462
Cumulative Timesteps: 395,876,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,468.37779
Policy Entropy: 3.76673
Value Function Loss: 0.04153

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.58105
Value Function Update Magnitude: 0.76780

Collected Steps per Second: 22,948.96758
Overall Steps per Second: 10,814.08577

Timestep Collection Time: 2.17883
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.62378

Cumulative Model Updates: 47,468
Cumulative Timesteps: 395,926,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 395926800...
Checkpoint 395926800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,570.87432
Policy Entropy: 3.76031
Value Function Loss: 0.04148

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.53498
Value Function Update Magnitude: 0.74617

Collected Steps per Second: 22,368.25586
Overall Steps per Second: 10,721.26089

Timestep Collection Time: 2.23656
Timestep Consumption Time: 2.42968
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.66624

Cumulative Model Updates: 47,474
Cumulative Timesteps: 395,976,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,891.58520
Policy Entropy: 3.75429
Value Function Loss: 0.04372

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.50806
Value Function Update Magnitude: 0.74416

Collected Steps per Second: 22,861.79696
Overall Steps per Second: 10,894.23363

Timestep Collection Time: 2.18793
Timestep Consumption Time: 2.40349
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.59142

Cumulative Model Updates: 47,480
Cumulative Timesteps: 396,026,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 396026848...
Checkpoint 396026848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,962.34585
Policy Entropy: 3.75971
Value Function Loss: 0.04484

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.50893
Value Function Update Magnitude: 0.74935

Collected Steps per Second: 22,653.37734
Overall Steps per Second: 10,667.96124

Timestep Collection Time: 2.20859
Timestep Consumption Time: 2.48134
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.68993

Cumulative Model Updates: 47,486
Cumulative Timesteps: 396,076,880

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,749.53186
Policy Entropy: 3.76042
Value Function Loss: 0.04355

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.50852
Value Function Update Magnitude: 0.74624

Collected Steps per Second: 23,111.92342
Overall Steps per Second: 10,839.65484

Timestep Collection Time: 2.16339
Timestep Consumption Time: 2.44931
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.61269

Cumulative Model Updates: 47,492
Cumulative Timesteps: 396,126,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 396126880...
Checkpoint 396126880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,359.46265
Policy Entropy: 3.77370
Value Function Loss: 0.04293

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.47368
Value Function Update Magnitude: 0.71955

Collected Steps per Second: 22,511.00098
Overall Steps per Second: 10,683.32573

Timestep Collection Time: 2.22185
Timestep Consumption Time: 2.45984
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.68169

Cumulative Model Updates: 47,498
Cumulative Timesteps: 396,176,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,698.28517
Policy Entropy: 3.76705
Value Function Loss: 0.04303

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07094
Policy Update Magnitude: 0.49378
Value Function Update Magnitude: 0.68374

Collected Steps per Second: 22,901.10209
Overall Steps per Second: 10,838.25904

Timestep Collection Time: 2.18374
Timestep Consumption Time: 2.43047
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61421

Cumulative Model Updates: 47,504
Cumulative Timesteps: 396,226,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 396226906...
Checkpoint 396226906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,639.01220
Policy Entropy: 3.76190
Value Function Loss: 0.04500

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.51417
Value Function Update Magnitude: 0.63296

Collected Steps per Second: 22,460.81973
Overall Steps per Second: 10,768.34624

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.41840
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.64565

Cumulative Model Updates: 47,510
Cumulative Timesteps: 396,276,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,925.47672
Policy Entropy: 3.76453
Value Function Loss: 0.04408

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.47510
Value Function Update Magnitude: 0.64389

Collected Steps per Second: 23,243.83682
Overall Steps per Second: 10,845.73535

Timestep Collection Time: 2.15197
Timestep Consumption Time: 2.45998
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.61195

Cumulative Model Updates: 47,516
Cumulative Timesteps: 396,326,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 396326952...
Checkpoint 396326952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,010.08758
Policy Entropy: 3.76709
Value Function Loss: 0.04382

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06928
Policy Update Magnitude: 0.53204
Value Function Update Magnitude: 0.61415

Collected Steps per Second: 22,632.92703
Overall Steps per Second: 10,623.17583

Timestep Collection Time: 2.20952
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.70744

Cumulative Model Updates: 47,522
Cumulative Timesteps: 396,376,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,186.83090
Policy Entropy: 3.77082
Value Function Loss: 0.04386

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.53668
Value Function Update Magnitude: 0.59316

Collected Steps per Second: 23,034.89538
Overall Steps per Second: 10,827.62676

Timestep Collection Time: 2.17062
Timestep Consumption Time: 2.44720
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.61782

Cumulative Model Updates: 47,528
Cumulative Timesteps: 396,426,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 396426960...
Checkpoint 396426960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.96884
Policy Entropy: 3.77074
Value Function Loss: 0.04325

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.52907
Value Function Update Magnitude: 0.63186

Collected Steps per Second: 22,206.44786
Overall Steps per Second: 10,653.73927

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.44237
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.69469

Cumulative Model Updates: 47,534
Cumulative Timesteps: 396,476,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,255.45751
Policy Entropy: 3.75417
Value Function Loss: 0.04290

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.51671
Value Function Update Magnitude: 0.72092

Collected Steps per Second: 22,999.70641
Overall Steps per Second: 10,723.13516

Timestep Collection Time: 2.17516
Timestep Consumption Time: 2.49027
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.66543

Cumulative Model Updates: 47,540
Cumulative Timesteps: 396,527,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 396527004...
Checkpoint 396527004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,201.35671
Policy Entropy: 3.75228
Value Function Loss: 0.04628

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.55534
Value Function Update Magnitude: 0.68898

Collected Steps per Second: 22,549.88719
Overall Steps per Second: 10,654.05877

Timestep Collection Time: 2.21837
Timestep Consumption Time: 2.47693
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.69530

Cumulative Model Updates: 47,546
Cumulative Timesteps: 396,577,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,119.12039
Policy Entropy: 3.75390
Value Function Loss: 0.04944

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06224
Policy Update Magnitude: 0.62781
Value Function Update Magnitude: 0.58430

Collected Steps per Second: 23,054.93407
Overall Steps per Second: 10,711.48879

Timestep Collection Time: 2.16986
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.67031

Cumulative Model Updates: 47,552
Cumulative Timesteps: 396,627,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 396627054...
Checkpoint 396627054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,818.94519
Policy Entropy: 3.75891
Value Function Loss: 0.04982

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06780
Policy Update Magnitude: 0.62428
Value Function Update Magnitude: 0.60811

Collected Steps per Second: 22,263.76792
Overall Steps per Second: 10,613.82008

Timestep Collection Time: 2.24679
Timestep Consumption Time: 2.46612
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.71291

Cumulative Model Updates: 47,558
Cumulative Timesteps: 396,677,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,164.29419
Policy Entropy: 3.76232
Value Function Loss: 0.04808

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.55994
Value Function Update Magnitude: 0.71659

Collected Steps per Second: 22,971.36867
Overall Steps per Second: 10,844.45315

Timestep Collection Time: 2.17784
Timestep Consumption Time: 2.43539
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.61323

Cumulative Model Updates: 47,564
Cumulative Timesteps: 396,727,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 396727104...
Checkpoint 396727104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,338.64992
Policy Entropy: 3.76016
Value Function Loss: 0.04736

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.50375
Value Function Update Magnitude: 0.79519

Collected Steps per Second: 22,603.90576
Overall Steps per Second: 10,752.60309

Timestep Collection Time: 2.21245
Timestep Consumption Time: 2.43852
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.65097

Cumulative Model Updates: 47,570
Cumulative Timesteps: 396,777,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,500.91730
Policy Entropy: 3.75537
Value Function Loss: 0.04598

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.49723
Value Function Update Magnitude: 0.85731

Collected Steps per Second: 22,971.42110
Overall Steps per Second: 10,859.09594

Timestep Collection Time: 2.17766
Timestep Consumption Time: 2.42898
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.60664

Cumulative Model Updates: 47,576
Cumulative Timesteps: 396,827,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 396827138...
Checkpoint 396827138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,974.27918
Policy Entropy: 3.75583
Value Function Loss: 0.04357

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.46658
Value Function Update Magnitude: 0.87575

Collected Steps per Second: 22,514.93448
Overall Steps per Second: 10,673.32222

Timestep Collection Time: 2.22137
Timestep Consumption Time: 2.46452
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.68589

Cumulative Model Updates: 47,582
Cumulative Timesteps: 396,877,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,152.61791
Policy Entropy: 3.75101
Value Function Loss: 0.04430

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.45567
Value Function Update Magnitude: 0.85175

Collected Steps per Second: 23,063.59251
Overall Steps per Second: 10,874.37085

Timestep Collection Time: 2.16905
Timestep Consumption Time: 2.43131
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.60036

Cumulative Model Updates: 47,588
Cumulative Timesteps: 396,927,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 396927178...
Checkpoint 396927178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,672.47463
Policy Entropy: 3.76093
Value Function Loss: 0.04524

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.50461
Value Function Update Magnitude: 0.79374

Collected Steps per Second: 22,638.11402
Overall Steps per Second: 10,649.22626

Timestep Collection Time: 2.20875
Timestep Consumption Time: 2.48661
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.69536

Cumulative Model Updates: 47,594
Cumulative Timesteps: 396,977,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,099.49403
Policy Entropy: 3.76335
Value Function Loss: 0.04582

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.49926
Value Function Update Magnitude: 0.73480

Collected Steps per Second: 23,384.28111
Overall Steps per Second: 10,968.08522

Timestep Collection Time: 2.13956
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.56160

Cumulative Model Updates: 47,600
Cumulative Timesteps: 397,027,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 397027212...
Checkpoint 397027212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.17057
Policy Entropy: 3.76968
Value Function Loss: 0.04467

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.54610
Value Function Update Magnitude: 0.66944

Collected Steps per Second: 22,438.42255
Overall Steps per Second: 10,586.05757

Timestep Collection Time: 2.22877
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.72414

Cumulative Model Updates: 47,606
Cumulative Timesteps: 397,077,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,411.92181
Policy Entropy: 3.74381
Value Function Loss: 0.04709

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.55038
Value Function Update Magnitude: 0.61448

Collected Steps per Second: 22,267.51734
Overall Steps per Second: 10,864.84510

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.35714
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60310

Cumulative Model Updates: 47,612
Cumulative Timesteps: 397,127,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 397127234...
Checkpoint 397127234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,689.87755
Policy Entropy: 3.73235
Value Function Loss: 0.04862

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.51744
Value Function Update Magnitude: 0.60409

Collected Steps per Second: 21,750.67864
Overall Steps per Second: 10,689.74327

Timestep Collection Time: 2.29887
Timestep Consumption Time: 2.37870
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.67757

Cumulative Model Updates: 47,618
Cumulative Timesteps: 397,177,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,407.60545
Policy Entropy: 3.73672
Value Function Loss: 0.04929

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.52923
Value Function Update Magnitude: 0.65776

Collected Steps per Second: 22,208.70544
Overall Steps per Second: 10,880.48506

Timestep Collection Time: 2.25218
Timestep Consumption Time: 2.34486
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.59704

Cumulative Model Updates: 47,624
Cumulative Timesteps: 397,227,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 397227254...
Checkpoint 397227254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,906.29425
Policy Entropy: 3.74571
Value Function Loss: 0.04666

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.57547
Value Function Update Magnitude: 0.74989

Collected Steps per Second: 21,581.28815
Overall Steps per Second: 10,730.14099

Timestep Collection Time: 2.31803
Timestep Consumption Time: 2.34417
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.66219

Cumulative Model Updates: 47,630
Cumulative Timesteps: 397,277,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,460.87112
Policy Entropy: 3.74157
Value Function Loss: 0.04641

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.51982
Value Function Update Magnitude: 0.82409

Collected Steps per Second: 22,398.85752
Overall Steps per Second: 10,757.31479

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.41584
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.64819

Cumulative Model Updates: 47,636
Cumulative Timesteps: 397,327,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 397327282...
Checkpoint 397327282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,582.86240
Policy Entropy: 3.72718
Value Function Loss: 0.04667

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.53278
Value Function Update Magnitude: 0.82248

Collected Steps per Second: 22,574.39237
Overall Steps per Second: 10,711.42423

Timestep Collection Time: 2.21578
Timestep Consumption Time: 2.45400
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.66978

Cumulative Model Updates: 47,642
Cumulative Timesteps: 397,377,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,530.91714
Policy Entropy: 3.72600
Value Function Loss: 0.04864

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.49525
Value Function Update Magnitude: 0.80884

Collected Steps per Second: 23,176.72949
Overall Steps per Second: 10,985.24405

Timestep Collection Time: 2.15742
Timestep Consumption Time: 2.39432
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.55174

Cumulative Model Updates: 47,648
Cumulative Timesteps: 397,427,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 397427304...
Checkpoint 397427304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,113.12219
Policy Entropy: 3.72081
Value Function Loss: 0.04993

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.49301
Value Function Update Magnitude: 0.79601

Collected Steps per Second: 22,483.27488
Overall Steps per Second: 10,643.19464

Timestep Collection Time: 2.22450
Timestep Consumption Time: 2.47466
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.69915

Cumulative Model Updates: 47,654
Cumulative Timesteps: 397,477,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,926.28271
Policy Entropy: 3.71528
Value Function Loss: 0.04975

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.47395
Value Function Update Magnitude: 0.78499

Collected Steps per Second: 22,958.98767
Overall Steps per Second: 10,896.14770

Timestep Collection Time: 2.17875
Timestep Consumption Time: 2.41204
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.59080

Cumulative Model Updates: 47,660
Cumulative Timesteps: 397,527,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 397527340...
Checkpoint 397527340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,068.59959
Policy Entropy: 3.71516
Value Function Loss: 0.04961

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.44806
Value Function Update Magnitude: 0.77838

Collected Steps per Second: 22,740.55404
Overall Steps per Second: 10,747.44312

Timestep Collection Time: 2.19995
Timestep Consumption Time: 2.45493
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.65487

Cumulative Model Updates: 47,666
Cumulative Timesteps: 397,577,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,503.83586
Policy Entropy: 3.72485
Value Function Loss: 0.04886

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.46935
Value Function Update Magnitude: 0.72286

Collected Steps per Second: 22,958.04613
Overall Steps per Second: 10,760.83407

Timestep Collection Time: 2.17911
Timestep Consumption Time: 2.46998
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.64908

Cumulative Model Updates: 47,672
Cumulative Timesteps: 397,627,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 397627396...
Checkpoint 397627396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,715.88675
Policy Entropy: 3.72879
Value Function Loss: 0.04818

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.49056
Value Function Update Magnitude: 0.68725

Collected Steps per Second: 22,467.04449
Overall Steps per Second: 10,625.57443

Timestep Collection Time: 2.22566
Timestep Consumption Time: 2.48034
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.70600

Cumulative Model Updates: 47,678
Cumulative Timesteps: 397,677,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,105.74268
Policy Entropy: 3.73470
Value Function Loss: 0.04714

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.50438
Value Function Update Magnitude: 0.70882

Collected Steps per Second: 23,179.36804
Overall Steps per Second: 10,877.24749

Timestep Collection Time: 2.15726
Timestep Consumption Time: 2.43986
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.59712

Cumulative Model Updates: 47,684
Cumulative Timesteps: 397,727,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 397727404...
Checkpoint 397727404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,268.60214
Policy Entropy: 3.73079
Value Function Loss: 0.04791

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.46796
Value Function Update Magnitude: 0.72733

Collected Steps per Second: 22,465.72797
Overall Steps per Second: 10,624.49264

Timestep Collection Time: 2.22606
Timestep Consumption Time: 2.48099
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.70705

Cumulative Model Updates: 47,690
Cumulative Timesteps: 397,777,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.59472
Policy Entropy: 3.73177
Value Function Loss: 0.04852

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.51143
Value Function Update Magnitude: 0.63260

Collected Steps per Second: 23,338.57553
Overall Steps per Second: 10,928.51658

Timestep Collection Time: 2.14280
Timestep Consumption Time: 2.43330
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.57610

Cumulative Model Updates: 47,696
Cumulative Timesteps: 397,827,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 397827424...
Checkpoint 397827424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,967.79256
Policy Entropy: 3.71721
Value Function Loss: 0.05012

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06950
Policy Update Magnitude: 0.60960
Value Function Update Magnitude: 0.55780

Collected Steps per Second: 22,458.76255
Overall Steps per Second: 10,669.64036

Timestep Collection Time: 2.22693
Timestep Consumption Time: 2.46058
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.68751

Cumulative Model Updates: 47,702
Cumulative Timesteps: 397,877,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,059.70210
Policy Entropy: 3.72260
Value Function Loss: 0.05199

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06568
Policy Update Magnitude: 0.63092
Value Function Update Magnitude: 0.54369

Collected Steps per Second: 23,106.81962
Overall Steps per Second: 10,843.52356

Timestep Collection Time: 2.16490
Timestep Consumption Time: 2.44836
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.61326

Cumulative Model Updates: 47,708
Cumulative Timesteps: 397,927,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 397927462...
Checkpoint 397927462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,462.98828
Policy Entropy: 3.71759
Value Function Loss: 0.05353

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06840
Policy Update Magnitude: 0.64750
Value Function Update Magnitude: 0.61164

Collected Steps per Second: 22,330.05586
Overall Steps per Second: 10,700.30642

Timestep Collection Time: 2.23931
Timestep Consumption Time: 2.43382
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.67314

Cumulative Model Updates: 47,714
Cumulative Timesteps: 397,977,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,194.32875
Policy Entropy: 3.72489
Value Function Loss: 0.05186

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07092
Policy Update Magnitude: 0.64429
Value Function Update Magnitude: 0.59214

Collected Steps per Second: 23,101.92253
Overall Steps per Second: 10,867.75586

Timestep Collection Time: 2.16475
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.60169

Cumulative Model Updates: 47,720
Cumulative Timesteps: 398,027,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 398027476...
Checkpoint 398027476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,817.09326
Policy Entropy: 3.71854
Value Function Loss: 0.05036

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07096
Policy Update Magnitude: 0.65701
Value Function Update Magnitude: 0.58237

Collected Steps per Second: 22,317.29057
Overall Steps per Second: 10,669.22034

Timestep Collection Time: 2.24131
Timestep Consumption Time: 2.44694
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.68825

Cumulative Model Updates: 47,726
Cumulative Timesteps: 398,077,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,663.38444
Policy Entropy: 3.71909
Value Function Loss: 0.05009

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.63287
Value Function Update Magnitude: 0.61381

Collected Steps per Second: 22,889.70780
Overall Steps per Second: 10,799.77504

Timestep Collection Time: 2.18570
Timestep Consumption Time: 2.44681
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.63250

Cumulative Model Updates: 47,732
Cumulative Timesteps: 398,127,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 398127526...
Checkpoint 398127526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,096.92012
Policy Entropy: 3.71405
Value Function Loss: 0.05057

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06116
Policy Update Magnitude: 0.64410
Value Function Update Magnitude: 0.64956

Collected Steps per Second: 22,691.69734
Overall Steps per Second: 10,706.95578

Timestep Collection Time: 2.20415
Timestep Consumption Time: 2.46720
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.67136

Cumulative Model Updates: 47,738
Cumulative Timesteps: 398,177,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,965.60878
Policy Entropy: 3.71972
Value Function Loss: 0.05105

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.62337
Value Function Update Magnitude: 0.67696

Collected Steps per Second: 23,133.73356
Overall Steps per Second: 10,893.44780

Timestep Collection Time: 2.16264
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59267

Cumulative Model Updates: 47,744
Cumulative Timesteps: 398,227,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 398227572...
Checkpoint 398227572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,364.27653
Policy Entropy: 3.70833
Value Function Loss: 0.05304

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.54321
Value Function Update Magnitude: 0.65075

Collected Steps per Second: 22,168.75038
Overall Steps per Second: 10,663.74122

Timestep Collection Time: 2.25552
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.68897

Cumulative Model Updates: 47,750
Cumulative Timesteps: 398,277,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.44895
Policy Entropy: 3.71465
Value Function Loss: 0.05307

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11528
Policy Update Magnitude: 0.52034
Value Function Update Magnitude: 0.68131

Collected Steps per Second: 22,705.57602
Overall Steps per Second: 10,658.57190

Timestep Collection Time: 2.20237
Timestep Consumption Time: 2.48926
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.69162

Cumulative Model Updates: 47,756
Cumulative Timesteps: 398,327,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 398327580...
Checkpoint 398327580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,608.01957
Policy Entropy: 3.70728
Value Function Loss: 0.05373

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.50585
Value Function Update Magnitude: 0.66354

Collected Steps per Second: 22,769.60952
Overall Steps per Second: 10,817.55143

Timestep Collection Time: 2.19635
Timestep Consumption Time: 2.42669
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62304

Cumulative Model Updates: 47,762
Cumulative Timesteps: 398,377,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,476.58195
Policy Entropy: 3.72312
Value Function Loss: 0.05373

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.50735
Value Function Update Magnitude: 0.73326

Collected Steps per Second: 23,004.36512
Overall Steps per Second: 10,750.18482

Timestep Collection Time: 2.17385
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.65183

Cumulative Model Updates: 47,768
Cumulative Timesteps: 398,427,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 398427598...
Checkpoint 398427598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,058.12614
Policy Entropy: 3.70719
Value Function Loss: 0.05430

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.46277
Value Function Update Magnitude: 0.69066

Collected Steps per Second: 22,458.88965
Overall Steps per Second: 10,627.79619

Timestep Collection Time: 2.22709
Timestep Consumption Time: 2.47925
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.70634

Cumulative Model Updates: 47,774
Cumulative Timesteps: 398,477,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,042.27468
Policy Entropy: 3.70836
Value Function Loss: 0.05381

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.48140
Value Function Update Magnitude: 0.72131

Collected Steps per Second: 23,032.08077
Overall Steps per Second: 10,701.47909

Timestep Collection Time: 2.17123
Timestep Consumption Time: 2.50177
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.67300

Cumulative Model Updates: 47,780
Cumulative Timesteps: 398,527,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 398527624...
Checkpoint 398527624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,184.48552
Policy Entropy: 3.70004
Value Function Loss: 0.05253

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.45628
Value Function Update Magnitude: 0.75353

Collected Steps per Second: 22,751.60167
Overall Steps per Second: 10,606.60027

Timestep Collection Time: 2.19800
Timestep Consumption Time: 2.51680
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.71480

Cumulative Model Updates: 47,786
Cumulative Timesteps: 398,577,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,582.32904
Policy Entropy: 3.69435
Value Function Loss: 0.05141

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.45594
Value Function Update Magnitude: 0.80888

Collected Steps per Second: 23,176.01458
Overall Steps per Second: 10,897.69940

Timestep Collection Time: 2.15861
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59069

Cumulative Model Updates: 47,792
Cumulative Timesteps: 398,627,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 398627660...
Checkpoint 398627660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,602.17646
Policy Entropy: 3.69595
Value Function Loss: 0.05098

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.46839
Value Function Update Magnitude: 0.80627

Collected Steps per Second: 22,282.01695
Overall Steps per Second: 10,723.71397

Timestep Collection Time: 2.24576
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.66629

Cumulative Model Updates: 47,798
Cumulative Timesteps: 398,677,700

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,168.70235
Policy Entropy: 3.68465
Value Function Loss: 0.05284

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.46924
Value Function Update Magnitude: 0.70812

Collected Steps per Second: 22,767.25673
Overall Steps per Second: 10,793.74695

Timestep Collection Time: 2.19701
Timestep Consumption Time: 2.43715
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.63416

Cumulative Model Updates: 47,804
Cumulative Timesteps: 398,727,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 398727720...
Checkpoint 398727720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,398.08408
Policy Entropy: 3.68301
Value Function Loss: 0.05325

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.49686
Value Function Update Magnitude: 0.64522

Collected Steps per Second: 22,506.85003
Overall Steps per Second: 10,752.88558

Timestep Collection Time: 2.22243
Timestep Consumption Time: 2.42934
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.65177

Cumulative Model Updates: 47,810
Cumulative Timesteps: 398,777,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,126.13562
Policy Entropy: 3.69171
Value Function Loss: 0.05469

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.51587
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 23,004.41569
Overall Steps per Second: 10,868.61888

Timestep Collection Time: 2.17445
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60242

Cumulative Model Updates: 47,816
Cumulative Timesteps: 398,827,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 398827762...
Checkpoint 398827762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,015.13751
Policy Entropy: 3.69857
Value Function Loss: 0.05278

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.51615
Value Function Update Magnitude: 0.61914

Collected Steps per Second: 22,398.15096
Overall Steps per Second: 10,677.49641

Timestep Collection Time: 2.23268
Timestep Consumption Time: 2.45081
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.68349

Cumulative Model Updates: 47,822
Cumulative Timesteps: 398,877,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,740.80837
Policy Entropy: 3.69941
Value Function Loss: 0.05219

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.60043

Collected Steps per Second: 22,885.54792
Overall Steps per Second: 10,810.53819

Timestep Collection Time: 2.18601
Timestep Consumption Time: 2.44170
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.62771

Cumulative Model Updates: 47,828
Cumulative Timesteps: 398,927,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 398927798...
Checkpoint 398927798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,796.84501
Policy Entropy: 3.69325
Value Function Loss: 0.05272

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.63672
Value Function Update Magnitude: 0.62507

Collected Steps per Second: 22,533.41759
Overall Steps per Second: 10,770.33479

Timestep Collection Time: 2.21937
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.64331

Cumulative Model Updates: 47,834
Cumulative Timesteps: 398,977,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,105.93442
Policy Entropy: 3.69145
Value Function Loss: 0.05316

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.53044
Value Function Update Magnitude: 0.67577

Collected Steps per Second: 23,200.48076
Overall Steps per Second: 10,838.79036

Timestep Collection Time: 2.15590
Timestep Consumption Time: 2.45882
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.61472

Cumulative Model Updates: 47,840
Cumulative Timesteps: 399,027,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 399027826...
Checkpoint 399027826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,078.25895
Policy Entropy: 3.68203
Value Function Loss: 0.05356

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.49895
Value Function Update Magnitude: 0.75721

Collected Steps per Second: 22,209.52698
Overall Steps per Second: 10,681.94265

Timestep Collection Time: 2.25264
Timestep Consumption Time: 2.43097
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.68361

Cumulative Model Updates: 47,846
Cumulative Timesteps: 399,077,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,460.89187
Policy Entropy: 3.68697
Value Function Loss: 0.05283

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.48209
Value Function Update Magnitude: 0.72209

Collected Steps per Second: 22,833.47736
Overall Steps per Second: 10,821.84608

Timestep Collection Time: 2.18985
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.62047

Cumulative Model Updates: 47,852
Cumulative Timesteps: 399,127,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 399127858...
Checkpoint 399127858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,507.85855
Policy Entropy: 3.68651
Value Function Loss: 0.05056

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.48072
Value Function Update Magnitude: 0.75187

Collected Steps per Second: 22,226.23885
Overall Steps per Second: 10,661.91880

Timestep Collection Time: 2.25175
Timestep Consumption Time: 2.44234
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.69409

Cumulative Model Updates: 47,858
Cumulative Timesteps: 399,177,906

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,576.30376
Policy Entropy: 3.69853
Value Function Loss: 0.04929

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.52767
Value Function Update Magnitude: 0.76128

Collected Steps per Second: 23,045.17710
Overall Steps per Second: 10,867.58779

Timestep Collection Time: 2.17069
Timestep Consumption Time: 2.43235
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.60305

Cumulative Model Updates: 47,864
Cumulative Timesteps: 399,227,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 399227930...
Checkpoint 399227930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,551.68584
Policy Entropy: 3.69948
Value Function Loss: 0.05217

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.64242

Collected Steps per Second: 22,408.58712
Overall Steps per Second: 10,741.72768

Timestep Collection Time: 2.23218
Timestep Consumption Time: 2.42443
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.65661

Cumulative Model Updates: 47,870
Cumulative Timesteps: 399,277,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,979.19827
Policy Entropy: 3.69445
Value Function Loss: 0.05507

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.58229
Value Function Update Magnitude: 0.64442

Collected Steps per Second: 22,921.15573
Overall Steps per Second: 10,802.79257

Timestep Collection Time: 2.18174
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.62917

Cumulative Model Updates: 47,876
Cumulative Timesteps: 399,327,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 399327958...
Checkpoint 399327958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,628.48885
Policy Entropy: 3.70185
Value Function Loss: 0.05318

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.64030
Value Function Update Magnitude: 0.65078

Collected Steps per Second: 22,505.60379
Overall Steps per Second: 10,727.30318

Timestep Collection Time: 2.22274
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.66324

Cumulative Model Updates: 47,882
Cumulative Timesteps: 399,377,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,269.06981
Policy Entropy: 3.70611
Value Function Loss: 0.05208

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.58781
Value Function Update Magnitude: 0.68202

Collected Steps per Second: 23,249.69578
Overall Steps per Second: 10,944.05755

Timestep Collection Time: 2.15143
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.57052

Cumulative Model Updates: 47,888
Cumulative Timesteps: 399,428,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 399428002...
Checkpoint 399428002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,174.66752
Policy Entropy: 3.70200
Value Function Loss: 0.05053

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.52752
Value Function Update Magnitude: 0.70661

Collected Steps per Second: 22,550.24907
Overall Steps per Second: 10,586.03269

Timestep Collection Time: 2.21833
Timestep Consumption Time: 2.50714
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.72547

Cumulative Model Updates: 47,894
Cumulative Timesteps: 399,478,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,668.92621
Policy Entropy: 3.71229
Value Function Loss: 0.05288

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.52317
Value Function Update Magnitude: 0.67388

Collected Steps per Second: 23,009.31425
Overall Steps per Second: 10,874.59411

Timestep Collection Time: 2.17329
Timestep Consumption Time: 2.42513
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.59842

Cumulative Model Updates: 47,900
Cumulative Timesteps: 399,528,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 399528032...
Checkpoint 399528032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,147.28141
Policy Entropy: 3.70418
Value Function Loss: 0.05420

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.53305
Value Function Update Magnitude: 0.62277

Collected Steps per Second: 22,461.85346
Overall Steps per Second: 10,641.80744

Timestep Collection Time: 2.22626
Timestep Consumption Time: 2.47275
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.69901

Cumulative Model Updates: 47,906
Cumulative Timesteps: 399,578,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,613.79868
Policy Entropy: 3.69574
Value Function Loss: 0.05546

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.62517

Collected Steps per Second: 22,821.07035
Overall Steps per Second: 10,852.07541

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.41694
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.60834

Cumulative Model Updates: 47,912
Cumulative Timesteps: 399,628,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 399628048...
Checkpoint 399628048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,105.97682
Policy Entropy: 3.69521
Value Function Loss: 0.05564

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.56060
Value Function Update Magnitude: 0.65806

Collected Steps per Second: 21,117.59190
Overall Steps per Second: 10,635.83991

Timestep Collection Time: 2.36883
Timestep Consumption Time: 2.33451
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.70334

Cumulative Model Updates: 47,918
Cumulative Timesteps: 399,678,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,783.56405
Policy Entropy: 3.70719
Value Function Loss: 0.05569

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.56876
Value Function Update Magnitude: 0.65716

Collected Steps per Second: 21,957.22849
Overall Steps per Second: 10,622.76259

Timestep Collection Time: 2.27797
Timestep Consumption Time: 2.43059
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.70857

Cumulative Model Updates: 47,924
Cumulative Timesteps: 399,728,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 399728090...
Checkpoint 399728090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,812.78155
Policy Entropy: 3.69621
Value Function Loss: 0.05447

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.59186
Value Function Update Magnitude: 0.70192

Collected Steps per Second: 21,687.79041
Overall Steps per Second: 10,548.39821

Timestep Collection Time: 2.30683
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.74290

Cumulative Model Updates: 47,930
Cumulative Timesteps: 399,778,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,000.11856
Policy Entropy: 3.70015
Value Function Loss: 0.05306

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.71077

Collected Steps per Second: 22,332.58940
Overall Steps per Second: 10,866.32032

Timestep Collection Time: 2.23978
Timestep Consumption Time: 2.36344
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.60321

Cumulative Model Updates: 47,936
Cumulative Timesteps: 399,828,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 399828140...
Checkpoint 399828140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,765.54197
Policy Entropy: 3.69334
Value Function Loss: 0.05544

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07752
Policy Update Magnitude: 0.53327
Value Function Update Magnitude: 0.63423

Collected Steps per Second: 21,888.60859
Overall Steps per Second: 10,623.05146

Timestep Collection Time: 2.28530
Timestep Consumption Time: 2.42352
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.70882

Cumulative Model Updates: 47,942
Cumulative Timesteps: 399,878,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,059.97621
Policy Entropy: 3.71510
Value Function Loss: 0.05686

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.56127
Value Function Update Magnitude: 0.56754

Collected Steps per Second: 22,877.21955
Overall Steps per Second: 10,872.88646

Timestep Collection Time: 2.18602
Timestep Consumption Time: 2.41350
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.59951

Cumulative Model Updates: 47,948
Cumulative Timesteps: 399,928,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 399928172...
Checkpoint 399928172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,112.25648
Policy Entropy: 3.72204
Value Function Loss: 0.05776

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.56452
Value Function Update Magnitude: 0.64039

Collected Steps per Second: 22,550.41506
Overall Steps per Second: 10,758.74907

Timestep Collection Time: 2.21805
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.64905

Cumulative Model Updates: 47,954
Cumulative Timesteps: 399,978,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,315.80770
Policy Entropy: 3.74433
Value Function Loss: 0.05547

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.59146
Value Function Update Magnitude: 0.72247

Collected Steps per Second: 23,082.56791
Overall Steps per Second: 10,930.06422

Timestep Collection Time: 2.16726
Timestep Consumption Time: 2.40965
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.57692

Cumulative Model Updates: 47,960
Cumulative Timesteps: 400,028,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 400028216...
Checkpoint 400028216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,109.57805
Policy Entropy: 3.75993
Value Function Loss: 0.05341

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.60829
Value Function Update Magnitude: 0.77208

Collected Steps per Second: 22,663.74091
Overall Steps per Second: 10,685.04121

Timestep Collection Time: 2.20670
Timestep Consumption Time: 2.47387
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.68056

Cumulative Model Updates: 47,966
Cumulative Timesteps: 400,078,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,466.87676
Policy Entropy: 3.78600
Value Function Loss: 0.05135

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10694
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.66878

Collected Steps per Second: 22,869.99873
Overall Steps per Second: 10,815.17798

Timestep Collection Time: 2.18688
Timestep Consumption Time: 2.43754
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.62443

Cumulative Model Updates: 47,972
Cumulative Timesteps: 400,128,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 400128242...
Checkpoint 400128242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,595.85098
Policy Entropy: 3.76324
Value Function Loss: 0.05170

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.60614
Value Function Update Magnitude: 0.68242

Collected Steps per Second: 22,809.48397
Overall Steps per Second: 10,639.05409

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.70004

Cumulative Model Updates: 47,978
Cumulative Timesteps: 400,178,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,459.81583
Policy Entropy: 3.75274
Value Function Loss: 0.05170

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.67206
Value Function Update Magnitude: 0.77782

Collected Steps per Second: 22,708.12329
Overall Steps per Second: 10,657.88632

Timestep Collection Time: 2.20230
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.69230

Cumulative Model Updates: 47,984
Cumulative Timesteps: 400,228,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 400228256...
Checkpoint 400228256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,540.98925
Policy Entropy: 3.73781
Value Function Loss: 0.05111

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07786
Policy Update Magnitude: 0.68240
Value Function Update Magnitude: 0.78789

Collected Steps per Second: 22,756.21218
Overall Steps per Second: 10,830.68616

Timestep Collection Time: 2.19738
Timestep Consumption Time: 2.41950
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.61688

Cumulative Model Updates: 47,990
Cumulative Timesteps: 400,278,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,389.12989
Policy Entropy: 3.75041
Value Function Loss: 0.05276

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.65015
Value Function Update Magnitude: 0.66279

Collected Steps per Second: 22,540.57967
Overall Steps per Second: 10,611.25708

Timestep Collection Time: 2.21893
Timestep Consumption Time: 2.49455
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.71348

Cumulative Model Updates: 47,996
Cumulative Timesteps: 400,328,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 400328276...
Checkpoint 400328276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,074.42892
Policy Entropy: 3.75867
Value Function Loss: 0.05601

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.52131
Value Function Update Magnitude: 0.55888

Collected Steps per Second: 22,633.64409
Overall Steps per Second: 10,632.46430

Timestep Collection Time: 2.20945
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.70333

Cumulative Model Updates: 48,002
Cumulative Timesteps: 400,378,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,176.42857
Policy Entropy: 3.75130
Value Function Loss: 0.05421

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.46168
Value Function Update Magnitude: 0.56199

Collected Steps per Second: 22,999.77346
Overall Steps per Second: 10,777.71915

Timestep Collection Time: 2.17446
Timestep Consumption Time: 2.46586
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.64031

Cumulative Model Updates: 48,008
Cumulative Timesteps: 400,428,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 400428296...
Checkpoint 400428296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,768.47981
Policy Entropy: 3.73577
Value Function Loss: 0.05493

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.48438
Value Function Update Magnitude: 0.55705

Collected Steps per Second: 22,355.99061
Overall Steps per Second: 10,741.58844

Timestep Collection Time: 2.23698
Timestep Consumption Time: 2.41875
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.65574

Cumulative Model Updates: 48,014
Cumulative Timesteps: 400,478,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,098.11780
Policy Entropy: 3.73662
Value Function Loss: 0.05258

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.50461
Value Function Update Magnitude: 0.58234

Collected Steps per Second: 22,847.00956
Overall Steps per Second: 10,812.35354

Timestep Collection Time: 2.18978
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.62711

Cumulative Model Updates: 48,020
Cumulative Timesteps: 400,528,336

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 400528336...
Checkpoint 400528336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,287.64735
Policy Entropy: 3.73785
Value Function Loss: 0.05706

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.51004
Value Function Update Magnitude: 0.57359

Collected Steps per Second: 22,487.12674
Overall Steps per Second: 10,650.77046

Timestep Collection Time: 2.22465
Timestep Consumption Time: 2.47229
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.69694

Cumulative Model Updates: 48,026
Cumulative Timesteps: 400,578,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,752.42056
Policy Entropy: 3.72639
Value Function Loss: 0.05877

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.50454
Value Function Update Magnitude: 0.56522

Collected Steps per Second: 22,866.08810
Overall Steps per Second: 10,827.44751

Timestep Collection Time: 2.18804
Timestep Consumption Time: 2.43281
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62085

Cumulative Model Updates: 48,032
Cumulative Timesteps: 400,628,394

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 400628394...
Checkpoint 400628394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,491.12066
Policy Entropy: 3.72261
Value Function Loss: 0.06062

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06358
Policy Update Magnitude: 0.59364
Value Function Update Magnitude: 0.63470

Collected Steps per Second: 22,584.59467
Overall Steps per Second: 10,801.00848

Timestep Collection Time: 2.21408
Timestep Consumption Time: 2.41549
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.62957

Cumulative Model Updates: 48,038
Cumulative Timesteps: 400,678,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,771.29429
Policy Entropy: 3.72471
Value Function Loss: 0.05942

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.61974
Value Function Update Magnitude: 0.75160

Collected Steps per Second: 22,935.27814
Overall Steps per Second: 10,860.24916

Timestep Collection Time: 2.18075
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.60542

Cumulative Model Updates: 48,044
Cumulative Timesteps: 400,728,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 400728414...
Checkpoint 400728414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,716.63566
Policy Entropy: 3.73524
Value Function Loss: 0.05652

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.83361

Collected Steps per Second: 22,707.18398
Overall Steps per Second: 10,680.66574

Timestep Collection Time: 2.20239
Timestep Consumption Time: 2.47991
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.68229

Cumulative Model Updates: 48,050
Cumulative Timesteps: 400,778,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,996.26474
Policy Entropy: 3.74093
Value Function Loss: 0.05481

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.51846
Value Function Update Magnitude: 0.81859

Collected Steps per Second: 23,275.39239
Overall Steps per Second: 10,969.07774

Timestep Collection Time: 2.14914
Timestep Consumption Time: 2.41114
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.56027

Cumulative Model Updates: 48,056
Cumulative Timesteps: 400,828,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 400828446...
Checkpoint 400828446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,979.94514
Policy Entropy: 3.74187
Value Function Loss: 0.05249

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.54154
Value Function Update Magnitude: 0.82952

Collected Steps per Second: 22,654.12180
Overall Steps per Second: 10,616.86710

Timestep Collection Time: 2.20808
Timestep Consumption Time: 2.50348
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.71156

Cumulative Model Updates: 48,062
Cumulative Timesteps: 400,878,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.52077
Policy Entropy: 3.74144
Value Function Loss: 0.05160

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.85277

Collected Steps per Second: 22,978.09404
Overall Steps per Second: 10,820.06505

Timestep Collection Time: 2.17659
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.62234

Cumulative Model Updates: 48,068
Cumulative Timesteps: 400,928,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 400928482...
Checkpoint 400928482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,412.02251
Policy Entropy: 3.72652
Value Function Loss: 0.05000

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.51796
Value Function Update Magnitude: 0.83583

Collected Steps per Second: 22,627.75483
Overall Steps per Second: 10,694.52925

Timestep Collection Time: 2.20968
Timestep Consumption Time: 2.46561
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.67529

Cumulative Model Updates: 48,074
Cumulative Timesteps: 400,978,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,747.15273
Policy Entropy: 3.72644
Value Function Loss: 0.04925

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.47331
Value Function Update Magnitude: 0.82310

Collected Steps per Second: 22,907.82958
Overall Steps per Second: 10,849.65978

Timestep Collection Time: 2.18327
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.60973

Cumulative Model Updates: 48,080
Cumulative Timesteps: 401,028,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 401028496...
Checkpoint 401028496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,211.53497
Policy Entropy: 3.71636
Value Function Loss: 0.04947

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.48540
Value Function Update Magnitude: 0.82327

Collected Steps per Second: 22,514.15508
Overall Steps per Second: 10,728.76948

Timestep Collection Time: 2.22145
Timestep Consumption Time: 2.44022
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.66167

Cumulative Model Updates: 48,086
Cumulative Timesteps: 401,078,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,553.26704
Policy Entropy: 3.71469
Value Function Loss: 0.05299

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.48978
Value Function Update Magnitude: 0.84407

Collected Steps per Second: 22,297.07592
Overall Steps per Second: 10,851.09368

Timestep Collection Time: 2.24272
Timestep Consumption Time: 2.36567
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60838

Cumulative Model Updates: 48,092
Cumulative Timesteps: 401,128,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 401128516...
Checkpoint 401128516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,177.90831
Policy Entropy: 3.70800
Value Function Loss: 0.05200

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.53959
Value Function Update Magnitude: 0.83562

Collected Steps per Second: 21,676.12464
Overall Steps per Second: 10,682.52426

Timestep Collection Time: 2.30807
Timestep Consumption Time: 2.37528
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.68335

Cumulative Model Updates: 48,098
Cumulative Timesteps: 401,178,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,725.80105
Policy Entropy: 3.70039
Value Function Loss: 0.05336

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.57542
Value Function Update Magnitude: 0.80015

Collected Steps per Second: 22,365.01469
Overall Steps per Second: 10,897.54551

Timestep Collection Time: 2.23680
Timestep Consumption Time: 2.35378
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.59058

Cumulative Model Updates: 48,104
Cumulative Timesteps: 401,228,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 401228572...
Checkpoint 401228572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,314.72154
Policy Entropy: 3.69404
Value Function Loss: 0.05168

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.55885
Value Function Update Magnitude: 0.81372

Collected Steps per Second: 21,957.67695
Overall Steps per Second: 10,670.41158

Timestep Collection Time: 2.27720
Timestep Consumption Time: 2.40884
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.68604

Cumulative Model Updates: 48,110
Cumulative Timesteps: 401,278,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,463.06154
Policy Entropy: 3.69422
Value Function Loss: 0.05284

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.48447
Value Function Update Magnitude: 0.75063

Collected Steps per Second: 22,172.28733
Overall Steps per Second: 10,587.01554

Timestep Collection Time: 2.25525
Timestep Consumption Time: 2.46790
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.72314

Cumulative Model Updates: 48,116
Cumulative Timesteps: 401,328,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 401328578...
Checkpoint 401328578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,104.23403
Policy Entropy: 3.67979
Value Function Loss: 0.05428

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.43485
Value Function Update Magnitude: 0.64348

Collected Steps per Second: 22,626.38327
Overall Steps per Second: 10,825.97618

Timestep Collection Time: 2.21034
Timestep Consumption Time: 2.40929
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.61963

Cumulative Model Updates: 48,122
Cumulative Timesteps: 401,378,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,478.78869
Policy Entropy: 3.67884
Value Function Loss: 0.05477

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.40445
Value Function Update Magnitude: 0.60266

Collected Steps per Second: 22,887.54903
Overall Steps per Second: 10,783.75582

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.45201
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.63660

Cumulative Model Updates: 48,128
Cumulative Timesteps: 401,428,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 401428590...
Checkpoint 401428590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,282.73101
Policy Entropy: 3.68383
Value Function Loss: 0.05201

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.40195
Value Function Update Magnitude: 0.63075

Collected Steps per Second: 22,784.28894
Overall Steps per Second: 10,913.35870

Timestep Collection Time: 2.19511
Timestep Consumption Time: 2.38771
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.58282

Cumulative Model Updates: 48,134
Cumulative Timesteps: 401,478,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,166.08869
Policy Entropy: 3.68968
Value Function Loss: 0.05320

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.42104
Value Function Update Magnitude: 0.60339

Collected Steps per Second: 22,848.65723
Overall Steps per Second: 10,885.93807

Timestep Collection Time: 2.18857
Timestep Consumption Time: 2.40506
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.59363

Cumulative Model Updates: 48,140
Cumulative Timesteps: 401,528,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 401528610...
Checkpoint 401528610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,550.23133
Policy Entropy: 3.70062
Value Function Loss: 0.05096

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.47447
Value Function Update Magnitude: 0.60269

Collected Steps per Second: 22,758.22080
Overall Steps per Second: 10,600.10839

Timestep Collection Time: 2.19701
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.71693

Cumulative Model Updates: 48,146
Cumulative Timesteps: 401,578,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,874.77234
Policy Entropy: 3.70070
Value Function Loss: 0.05286

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.48941
Value Function Update Magnitude: 0.61291

Collected Steps per Second: 22,928.00268
Overall Steps per Second: 10,845.84797

Timestep Collection Time: 2.18118
Timestep Consumption Time: 2.42981
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.61098

Cumulative Model Updates: 48,152
Cumulative Timesteps: 401,628,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 401628620...
Checkpoint 401628620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.62999
Policy Entropy: 3.70429
Value Function Loss: 0.05194

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.50030
Value Function Update Magnitude: 0.60920

Collected Steps per Second: 22,562.31744
Overall Steps per Second: 10,698.22957

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.45778
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.67404

Cumulative Model Updates: 48,158
Cumulative Timesteps: 401,678,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,258.41246
Policy Entropy: 3.70621
Value Function Loss: 0.05061

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.47504
Value Function Update Magnitude: 0.62888

Collected Steps per Second: 22,790.39520
Overall Steps per Second: 10,821.79841

Timestep Collection Time: 2.19505
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.62271

Cumulative Model Updates: 48,164
Cumulative Timesteps: 401,728,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 401728650...
Checkpoint 401728650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,182.29100
Policy Entropy: 3.70594
Value Function Loss: 0.05017

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.48148
Value Function Update Magnitude: 0.66163

Collected Steps per Second: 22,634.95264
Overall Steps per Second: 10,788.32936

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.63705

Cumulative Model Updates: 48,170
Cumulative Timesteps: 401,778,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.59500
Policy Entropy: 3.72032
Value Function Loss: 0.04977

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.49366
Value Function Update Magnitude: 0.62333

Collected Steps per Second: 22,963.71571
Overall Steps per Second: 10,843.26559

Timestep Collection Time: 2.17848
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.61355

Cumulative Model Updates: 48,176
Cumulative Timesteps: 401,828,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 401828702...
Checkpoint 401828702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.51880
Policy Entropy: 3.72300
Value Function Loss: 0.05193

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.48009
Value Function Update Magnitude: 0.60989

Collected Steps per Second: 22,867.75199
Overall Steps per Second: 10,667.28937

Timestep Collection Time: 2.18701
Timestep Consumption Time: 2.50134
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.68835

Cumulative Model Updates: 48,182
Cumulative Timesteps: 401,878,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,422.67004
Policy Entropy: 3.71365
Value Function Loss: 0.05403

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.50725
Value Function Update Magnitude: 0.61077

Collected Steps per Second: 22,855.58485
Overall Steps per Second: 10,820.39875

Timestep Collection Time: 2.18887
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.62349

Cumulative Model Updates: 48,188
Cumulative Timesteps: 401,928,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 401928742...
Checkpoint 401928742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,585.54895
Policy Entropy: 3.69809
Value Function Loss: 0.05577

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.58183

Collected Steps per Second: 22,522.53267
Overall Steps per Second: 10,772.18810

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.42216
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.64270

Cumulative Model Updates: 48,194
Cumulative Timesteps: 401,978,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,186.10400
Policy Entropy: 3.71769
Value Function Loss: 0.05399

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.59551

Collected Steps per Second: 22,949.72527
Overall Steps per Second: 10,852.20162

Timestep Collection Time: 2.17920
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60847

Cumulative Model Updates: 48,200
Cumulative Timesteps: 402,028,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 402028766...
Checkpoint 402028766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.98601
Policy Entropy: 3.72234
Value Function Loss: 0.05156

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.54439
Value Function Update Magnitude: 0.64550

Collected Steps per Second: 22,730.71492
Overall Steps per Second: 10,722.04744

Timestep Collection Time: 2.20063
Timestep Consumption Time: 2.46471
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.66534

Cumulative Model Updates: 48,206
Cumulative Timesteps: 402,078,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,340.62773
Policy Entropy: 3.74018
Value Function Loss: 0.04763

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.60625
Value Function Update Magnitude: 0.73196

Collected Steps per Second: 22,936.95598
Overall Steps per Second: 10,829.44130

Timestep Collection Time: 2.18015
Timestep Consumption Time: 2.43745
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.61760

Cumulative Model Updates: 48,212
Cumulative Timesteps: 402,128,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 402128794...
Checkpoint 402128794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.68495
Policy Entropy: 3.74130
Value Function Loss: 0.04655

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.63890
Value Function Update Magnitude: 0.77596

Collected Steps per Second: 22,597.04128
Overall Steps per Second: 10,657.47673

Timestep Collection Time: 2.21321
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.69267

Cumulative Model Updates: 48,218
Cumulative Timesteps: 402,178,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,064.47669
Policy Entropy: 3.75739
Value Function Loss: 0.04571

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.62752
Value Function Update Magnitude: 0.79468

Collected Steps per Second: 22,771.60610
Overall Steps per Second: 10,794.95236

Timestep Collection Time: 2.19668
Timestep Consumption Time: 2.43715
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.63383

Cumulative Model Updates: 48,224
Cumulative Timesteps: 402,228,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 402228828...
Checkpoint 402228828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,664.23962
Policy Entropy: 3.76181
Value Function Loss: 0.04767

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.56815
Value Function Update Magnitude: 0.79323

Collected Steps per Second: 22,764.08285
Overall Steps per Second: 10,733.90666

Timestep Collection Time: 2.19653
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.65832

Cumulative Model Updates: 48,230
Cumulative Timesteps: 402,278,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,690.18770
Policy Entropy: 3.76144
Value Function Loss: 0.04991

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.52647
Value Function Update Magnitude: 0.80698

Collected Steps per Second: 22,783.99046
Overall Steps per Second: 10,823.67589

Timestep Collection Time: 2.19540
Timestep Consumption Time: 2.42595
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62135

Cumulative Model Updates: 48,236
Cumulative Timesteps: 402,328,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 402328850...
Checkpoint 402328850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,955.21627
Policy Entropy: 3.74793
Value Function Loss: 0.05010

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.53234
Value Function Update Magnitude: 0.82711

Collected Steps per Second: 22,493.01816
Overall Steps per Second: 10,735.65005

Timestep Collection Time: 2.22345
Timestep Consumption Time: 2.43505
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.65850

Cumulative Model Updates: 48,242
Cumulative Timesteps: 402,378,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,712.71976
Policy Entropy: 3.76272
Value Function Loss: 0.04963

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06618
Policy Update Magnitude: 0.61606
Value Function Update Magnitude: 0.83355

Collected Steps per Second: 22,844.82959
Overall Steps per Second: 10,800.66046

Timestep Collection Time: 2.18877
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.62953

Cumulative Model Updates: 48,248
Cumulative Timesteps: 402,428,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 402428864...
Checkpoint 402428864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,797.51769
Policy Entropy: 3.76660
Value Function Loss: 0.04858

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06293
Policy Update Magnitude: 0.66455
Value Function Update Magnitude: 0.83957

Collected Steps per Second: 22,617.73094
Overall Steps per Second: 10,735.76007

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.44668
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.65733

Cumulative Model Updates: 48,254
Cumulative Timesteps: 402,478,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,354.10906
Policy Entropy: 3.75167
Value Function Loss: 0.05017

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06726
Policy Update Magnitude: 0.64927
Value Function Update Magnitude: 0.84193

Collected Steps per Second: 22,787.05240
Overall Steps per Second: 10,776.85342

Timestep Collection Time: 2.19511
Timestep Consumption Time: 2.44632
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.64143

Cumulative Model Updates: 48,260
Cumulative Timesteps: 402,528,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 402528884...
Checkpoint 402528884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,554.76764
Policy Entropy: 3.74571
Value Function Loss: 0.04889

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.53721
Value Function Update Magnitude: 0.85009

Collected Steps per Second: 22,643.30561
Overall Steps per Second: 10,779.46133

Timestep Collection Time: 2.20931
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.64086

Cumulative Model Updates: 48,266
Cumulative Timesteps: 402,578,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,959.45574
Policy Entropy: 3.73563
Value Function Loss: 0.04941

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.48578
Value Function Update Magnitude: 0.82876

Collected Steps per Second: 23,141.63094
Overall Steps per Second: 10,922.01566

Timestep Collection Time: 2.16130
Timestep Consumption Time: 2.41807
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.57937

Cumulative Model Updates: 48,272
Cumulative Timesteps: 402,628,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 402628926...
Checkpoint 402628926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.82941
Policy Entropy: 3.74523
Value Function Loss: 0.04879

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.47514
Value Function Update Magnitude: 0.78578

Collected Steps per Second: 22,882.81250
Overall Steps per Second: 10,673.64031

Timestep Collection Time: 2.18548
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.68537

Cumulative Model Updates: 48,278
Cumulative Timesteps: 402,678,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,543.76996
Policy Entropy: 3.74344
Value Function Loss: 0.05054

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.48173
Value Function Update Magnitude: 0.66099

Collected Steps per Second: 22,778.02137
Overall Steps per Second: 10,781.82433

Timestep Collection Time: 2.19563
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.63855

Cumulative Model Updates: 48,284
Cumulative Timesteps: 402,728,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 402728948...
Checkpoint 402728948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,327.45818
Policy Entropy: 3.74687
Value Function Loss: 0.05078

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.49254
Value Function Update Magnitude: 0.62406

Collected Steps per Second: 22,616.52311
Overall Steps per Second: 10,693.62944

Timestep Collection Time: 2.21175
Timestep Consumption Time: 2.46599
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.67774

Cumulative Model Updates: 48,290
Cumulative Timesteps: 402,778,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,034.96570
Policy Entropy: 3.74755
Value Function Loss: 0.05166

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.47375
Value Function Update Magnitude: 0.66665

Collected Steps per Second: 22,779.67917
Overall Steps per Second: 10,686.44481

Timestep Collection Time: 2.19590
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.68088

Cumulative Model Updates: 48,296
Cumulative Timesteps: 402,828,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 402828992...
Checkpoint 402828992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,410.12281
Policy Entropy: 3.74472
Value Function Loss: 0.05416

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.49541
Value Function Update Magnitude: 0.59582

Collected Steps per Second: 22,942.19311
Overall Steps per Second: 10,847.30090

Timestep Collection Time: 2.17939
Timestep Consumption Time: 2.43005
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.60944

Cumulative Model Updates: 48,302
Cumulative Timesteps: 402,878,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,151.61811
Policy Entropy: 3.74480
Value Function Loss: 0.05579

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.46913
Value Function Update Magnitude: 0.56249

Collected Steps per Second: 22,732.03112
Overall Steps per Second: 10,838.39633

Timestep Collection Time: 2.20042
Timestep Consumption Time: 2.41465
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.61507

Cumulative Model Updates: 48,308
Cumulative Timesteps: 402,929,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 402929012...
Checkpoint 402929012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,165.18505
Policy Entropy: 3.74084
Value Function Loss: 0.05519

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.47978
Value Function Update Magnitude: 0.58246

Collected Steps per Second: 22,732.89525
Overall Steps per Second: 10,709.96333

Timestep Collection Time: 2.20016
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.67004

Cumulative Model Updates: 48,314
Cumulative Timesteps: 402,979,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,357.91553
Policy Entropy: 3.74249
Value Function Loss: 0.05459

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.49125
Value Function Update Magnitude: 0.61777

Collected Steps per Second: 22,904.48430
Overall Steps per Second: 10,722.02035

Timestep Collection Time: 2.18507
Timestep Consumption Time: 2.48270
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.66778

Cumulative Model Updates: 48,320
Cumulative Timesteps: 403,029,076

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 403029076...
Checkpoint 403029076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,135.25762
Policy Entropy: 3.73687
Value Function Loss: 0.05462

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.48177
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 22,547.25346
Overall Steps per Second: 10,781.37291

Timestep Collection Time: 2.21774
Timestep Consumption Time: 2.42026
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.63800

Cumulative Model Updates: 48,326
Cumulative Timesteps: 403,079,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,021.14085
Policy Entropy: 3.72771
Value Function Loss: 0.05534

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.53755
Value Function Update Magnitude: 0.65141

Collected Steps per Second: 22,742.49547
Overall Steps per Second: 10,585.67061

Timestep Collection Time: 2.19976
Timestep Consumption Time: 2.52625
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.72601

Cumulative Model Updates: 48,332
Cumulative Timesteps: 403,129,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 403129108...
Checkpoint 403129108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,100.15498
Policy Entropy: 3.72117
Value Function Loss: 0.05625

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.62082
Value Function Update Magnitude: 0.61226

Collected Steps per Second: 22,717.91078
Overall Steps per Second: 10,630.92169

Timestep Collection Time: 2.20161
Timestep Consumption Time: 2.50316
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.70477

Cumulative Model Updates: 48,338
Cumulative Timesteps: 403,179,124

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,069.30089
Policy Entropy: 3.71704
Value Function Loss: 0.05950

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06682
Policy Update Magnitude: 0.65321
Value Function Update Magnitude: 0.57304

Collected Steps per Second: 23,026.92083
Overall Steps per Second: 10,870.28293

Timestep Collection Time: 2.17198
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.60098

Cumulative Model Updates: 48,344
Cumulative Timesteps: 403,229,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 403229138...
Checkpoint 403229138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,594.18012
Policy Entropy: 3.70868
Value Function Loss: 0.06324

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.62633
Value Function Update Magnitude: 0.52508

Collected Steps per Second: 22,812.74837
Overall Steps per Second: 10,612.71943

Timestep Collection Time: 2.19193
Timestep Consumption Time: 2.51977
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.71170

Cumulative Model Updates: 48,350
Cumulative Timesteps: 403,279,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,383.62599
Policy Entropy: 3.69923
Value Function Loss: 0.05744

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.50004
Value Function Update Magnitude: 0.57172

Collected Steps per Second: 22,970.21415
Overall Steps per Second: 10,833.22552

Timestep Collection Time: 2.17699
Timestep Consumption Time: 2.43899
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61598

Cumulative Model Updates: 48,356
Cumulative Timesteps: 403,329,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 403329148...
Checkpoint 403329148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,428.28356
Policy Entropy: 3.67966
Value Function Loss: 0.05598

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.45075
Value Function Update Magnitude: 0.64191

Collected Steps per Second: 22,725.97492
Overall Steps per Second: 10,692.66135

Timestep Collection Time: 2.20127
Timestep Consumption Time: 2.47727
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.67854

Cumulative Model Updates: 48,362
Cumulative Timesteps: 403,379,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,823.90228
Policy Entropy: 3.67672
Value Function Loss: 0.05432

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.46195
Value Function Update Magnitude: 0.71387

Collected Steps per Second: 22,676.23162
Overall Steps per Second: 10,644.05019

Timestep Collection Time: 2.20495
Timestep Consumption Time: 2.49251
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.69746

Cumulative Model Updates: 48,368
Cumulative Timesteps: 403,429,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 403429174...
Checkpoint 403429174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,553.41717
Policy Entropy: 3.67454
Value Function Loss: 0.05393

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11355
Policy Update Magnitude: 0.45219
Value Function Update Magnitude: 0.81268

Collected Steps per Second: 22,880.05728
Overall Steps per Second: 10,871.08200

Timestep Collection Time: 2.18662
Timestep Consumption Time: 2.41550
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.60212

Cumulative Model Updates: 48,374
Cumulative Timesteps: 403,479,204

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,766.36688
Policy Entropy: 3.67494
Value Function Loss: 0.05309

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.48527
Value Function Update Magnitude: 0.79396

Collected Steps per Second: 22,858.34146
Overall Steps per Second: 10,688.94389

Timestep Collection Time: 2.18922
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.68166

Cumulative Model Updates: 48,380
Cumulative Timesteps: 403,529,246

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 403529246...
Checkpoint 403529246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,559.27990
Policy Entropy: 3.68267
Value Function Loss: 0.05403

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.47172
Value Function Update Magnitude: 0.68065

Collected Steps per Second: 22,626.63322
Overall Steps per Second: 10,631.89555

Timestep Collection Time: 2.21014
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.70358

Cumulative Model Updates: 48,386
Cumulative Timesteps: 403,579,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,455.28072
Policy Entropy: 3.68702
Value Function Loss: 0.05318

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.50985
Value Function Update Magnitude: 0.69208

Collected Steps per Second: 22,688.35704
Overall Steps per Second: 10,812.37247

Timestep Collection Time: 2.20377
Timestep Consumption Time: 2.42056
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.62433

Cumulative Model Updates: 48,392
Cumulative Timesteps: 403,629,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 403629254...
Checkpoint 403629254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,597.55789
Policy Entropy: 3.68080
Value Function Loss: 0.05369

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.59818
Value Function Update Magnitude: 0.65677

Collected Steps per Second: 22,639.06227
Overall Steps per Second: 10,574.21523

Timestep Collection Time: 2.20972
Timestep Consumption Time: 2.52122
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.73094

Cumulative Model Updates: 48,398
Cumulative Timesteps: 403,679,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,484.95684
Policy Entropy: 3.70075
Value Function Loss: 0.05462

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.66314

Collected Steps per Second: 22,912.42234
Overall Steps per Second: 10,822.45648

Timestep Collection Time: 2.18257
Timestep Consumption Time: 2.43819
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.62076

Cumulative Model Updates: 48,404
Cumulative Timesteps: 403,729,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 403729288...
Checkpoint 403729288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,405.60546
Policy Entropy: 3.69860
Value Function Loss: 0.05587

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.52410
Value Function Update Magnitude: 0.61547

Collected Steps per Second: 22,495.07187
Overall Steps per Second: 10,773.54710

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.41993
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.64415

Cumulative Model Updates: 48,410
Cumulative Timesteps: 403,779,322

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,946.07755
Policy Entropy: 3.72220
Value Function Loss: 0.05747

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.49889
Value Function Update Magnitude: 0.61645

Collected Steps per Second: 22,892.49807
Overall Steps per Second: 10,838.66511

Timestep Collection Time: 2.18517
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61533

Cumulative Model Updates: 48,416
Cumulative Timesteps: 403,829,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 403829346...
Checkpoint 403829346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,960.17934
Policy Entropy: 3.72734
Value Function Loss: 0.05575

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.53297
Value Function Update Magnitude: 0.65910

Collected Steps per Second: 22,626.61512
Overall Steps per Second: 10,692.53532

Timestep Collection Time: 2.21085
Timestep Consumption Time: 2.46756
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.67840

Cumulative Model Updates: 48,422
Cumulative Timesteps: 403,879,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,324.97135
Policy Entropy: 3.73939
Value Function Loss: 0.05108

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07396
Policy Update Magnitude: 0.57448
Value Function Update Magnitude: 0.72164

Collected Steps per Second: 22,928.89196
Overall Steps per Second: 10,824.32652

Timestep Collection Time: 2.18074
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.61941

Cumulative Model Updates: 48,428
Cumulative Timesteps: 403,929,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 403929372...
Checkpoint 403929372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,813.17693
Policy Entropy: 3.72353
Value Function Loss: 0.05114

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.60873
Value Function Update Magnitude: 0.70446

Collected Steps per Second: 22,708.26422
Overall Steps per Second: 10,682.70128

Timestep Collection Time: 2.20272
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.68234

Cumulative Model Updates: 48,434
Cumulative Timesteps: 403,979,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,376.43510
Policy Entropy: 3.72685
Value Function Loss: 0.05173

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.52686
Value Function Update Magnitude: 0.70658

Collected Steps per Second: 22,826.77860
Overall Steps per Second: 10,850.95082

Timestep Collection Time: 2.19137
Timestep Consumption Time: 2.41855
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.60992

Cumulative Model Updates: 48,440
Cumulative Timesteps: 404,029,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 404029414...
Checkpoint 404029414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,533.25573
Policy Entropy: 3.71577
Value Function Loss: 0.05331

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.51138
Value Function Update Magnitude: 0.70083

Collected Steps per Second: 22,806.88490
Overall Steps per Second: 10,743.74067

Timestep Collection Time: 2.19285
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.65499

Cumulative Model Updates: 48,446
Cumulative Timesteps: 404,079,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,124.60778
Policy Entropy: 3.72094
Value Function Loss: 0.05221

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.46127
Value Function Update Magnitude: 0.68936

Collected Steps per Second: 22,339.18995
Overall Steps per Second: 10,844.43056

Timestep Collection Time: 2.23876
Timestep Consumption Time: 2.37301
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.61177

Cumulative Model Updates: 48,452
Cumulative Timesteps: 404,129,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 404129438...
Checkpoint 404129438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,591.84669
Policy Entropy: 3.71209
Value Function Loss: 0.05137

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.44928
Value Function Update Magnitude: 0.66757

Collected Steps per Second: 21,991.49665
Overall Steps per Second: 10,669.84757

Timestep Collection Time: 2.27452
Timestep Consumption Time: 2.41346
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.68798

Cumulative Model Updates: 48,458
Cumulative Timesteps: 404,179,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,063.98140
Policy Entropy: 3.72753
Value Function Loss: 0.05027

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.43058
Value Function Update Magnitude: 0.62311

Collected Steps per Second: 22,154.74300
Overall Steps per Second: 10,851.53996

Timestep Collection Time: 2.25749
Timestep Consumption Time: 2.35145
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.60893

Cumulative Model Updates: 48,464
Cumulative Timesteps: 404,229,472

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 404229472...
Checkpoint 404229472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,033.34473
Policy Entropy: 3.71012
Value Function Loss: 0.05158

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.45391
Value Function Update Magnitude: 0.58823

Collected Steps per Second: 21,903.33613
Overall Steps per Second: 10,718.32911

Timestep Collection Time: 2.28294
Timestep Consumption Time: 2.38234
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.66528

Cumulative Model Updates: 48,470
Cumulative Timesteps: 404,279,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,035.74067
Policy Entropy: 3.73220
Value Function Loss: 0.05277

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.49285
Value Function Update Magnitude: 0.56358

Collected Steps per Second: 22,210.41461
Overall Steps per Second: 10,837.50090

Timestep Collection Time: 2.25147
Timestep Consumption Time: 2.36270
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.61416

Cumulative Model Updates: 48,476
Cumulative Timesteps: 404,329,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 404329482...
Checkpoint 404329482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,200.79979
Policy Entropy: 3.72381
Value Function Loss: 0.05483

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.49570
Value Function Update Magnitude: 0.57811

Collected Steps per Second: 22,031.22367
Overall Steps per Second: 10,702.51839

Timestep Collection Time: 2.27023
Timestep Consumption Time: 2.40306
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.67329

Cumulative Model Updates: 48,482
Cumulative Timesteps: 404,379,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,188.40422
Policy Entropy: 3.75194
Value Function Loss: 0.05690

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.47556
Value Function Update Magnitude: 0.59649

Collected Steps per Second: 22,501.37125
Overall Steps per Second: 10,946.81719

Timestep Collection Time: 2.22315
Timestep Consumption Time: 2.34658
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.56973

Cumulative Model Updates: 48,488
Cumulative Timesteps: 404,429,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 404429522...
Checkpoint 404429522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,376.43338
Policy Entropy: 3.73795
Value Function Loss: 0.05603

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.43067
Value Function Update Magnitude: 0.60042

Collected Steps per Second: 22,046.92385
Overall Steps per Second: 10,607.38558

Timestep Collection Time: 2.26798
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.71389

Cumulative Model Updates: 48,494
Cumulative Timesteps: 404,479,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,897.78566
Policy Entropy: 3.75084
Value Function Loss: 0.05525

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.46720
Value Function Update Magnitude: 0.57724

Collected Steps per Second: 22,714.27242
Overall Steps per Second: 10,809.64669

Timestep Collection Time: 2.20135
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.62568

Cumulative Model Updates: 48,500
Cumulative Timesteps: 404,529,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 404529526...
Checkpoint 404529526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,822.20363
Policy Entropy: 3.75749
Value Function Loss: 0.05448

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.44743
Value Function Update Magnitude: 0.60685

Collected Steps per Second: 22,379.57490
Overall Steps per Second: 10,664.98558

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.45514
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.69030

Cumulative Model Updates: 48,506
Cumulative Timesteps: 404,579,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,535.18470
Policy Entropy: 3.76968
Value Function Loss: 0.05523

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.47266
Value Function Update Magnitude: 0.68477

Collected Steps per Second: 22,681.06099
Overall Steps per Second: 10,696.25958

Timestep Collection Time: 2.20581
Timestep Consumption Time: 2.47153
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.67734

Cumulative Model Updates: 48,512
Cumulative Timesteps: 404,629,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 404629578...
Checkpoint 404629578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,932.50687
Policy Entropy: 3.76759
Value Function Loss: 0.05284

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.46663
Value Function Update Magnitude: 0.73574

Collected Steps per Second: 23,001.87538
Overall Steps per Second: 10,845.70445

Timestep Collection Time: 2.17391
Timestep Consumption Time: 2.43658
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61049

Cumulative Model Updates: 48,518
Cumulative Timesteps: 404,679,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,713.06690
Policy Entropy: 3.77280
Value Function Loss: 0.05003

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.48552
Value Function Update Magnitude: 0.81393

Collected Steps per Second: 22,594.69084
Overall Steps per Second: 10,529.71956

Timestep Collection Time: 2.21326
Timestep Consumption Time: 2.53596
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.74922

Cumulative Model Updates: 48,524
Cumulative Timesteps: 404,729,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 404729590...
Checkpoint 404729590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,268.64273
Policy Entropy: 3.77355
Value Function Loss: 0.04948

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.51282
Value Function Update Magnitude: 0.81469

Collected Steps per Second: 22,691.88972
Overall Steps per Second: 10,597.88727

Timestep Collection Time: 2.20458
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.72037

Cumulative Model Updates: 48,530
Cumulative Timesteps: 404,779,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,361.40489
Policy Entropy: 3.76740
Value Function Loss: 0.05262

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.52375
Value Function Update Magnitude: 0.70948

Collected Steps per Second: 22,852.04064
Overall Steps per Second: 10,842.17288

Timestep Collection Time: 2.18930
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.61439

Cumulative Model Updates: 48,536
Cumulative Timesteps: 404,829,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 404829646...
Checkpoint 404829646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.24415
Policy Entropy: 3.77148
Value Function Loss: 0.05168

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.49707
Value Function Update Magnitude: 0.79735

Collected Steps per Second: 22,625.90813
Overall Steps per Second: 10,788.39953

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.42562
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.63628

Cumulative Model Updates: 48,542
Cumulative Timesteps: 404,879,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393.18963
Policy Entropy: 3.76258
Value Function Loss: 0.05212

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.46113
Value Function Update Magnitude: 0.86131

Collected Steps per Second: 22,745.37236
Overall Steps per Second: 10,776.90680

Timestep Collection Time: 2.19869
Timestep Consumption Time: 2.44179
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.64048

Cumulative Model Updates: 48,548
Cumulative Timesteps: 404,929,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 404929674...
Checkpoint 404929674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,993.99620
Policy Entropy: 3.77133
Value Function Loss: 0.04999

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.48389
Value Function Update Magnitude: 0.88367

Collected Steps per Second: 22,567.89234
Overall Steps per Second: 10,665.40439

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.68824

Cumulative Model Updates: 48,554
Cumulative Timesteps: 404,979,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,496.79545
Policy Entropy: 3.76354
Value Function Loss: 0.05037

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07400
Policy Update Magnitude: 0.56915
Value Function Update Magnitude: 0.88430

Collected Steps per Second: 22,706.09633
Overall Steps per Second: 10,640.71675

Timestep Collection Time: 2.20346
Timestep Consumption Time: 2.49848
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.70194

Cumulative Model Updates: 48,560
Cumulative Timesteps: 405,029,708

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 405029708...
Checkpoint 405029708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.42145
Policy Entropy: 3.76014
Value Function Loss: 0.05009

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.62734
Value Function Update Magnitude: 0.90258

Collected Steps per Second: 22,902.09781
Overall Steps per Second: 10,848.26273

Timestep Collection Time: 2.18347
Timestep Consumption Time: 2.42612
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.60959

Cumulative Model Updates: 48,566
Cumulative Timesteps: 405,079,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,162.18445
Policy Entropy: 3.74776
Value Function Loss: 0.05194

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.60970
Value Function Update Magnitude: 0.89917

Collected Steps per Second: 22,471.85054
Overall Steps per Second: 10,533.19409

Timestep Collection Time: 2.22572
Timestep Consumption Time: 2.52270
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.74842

Cumulative Model Updates: 48,572
Cumulative Timesteps: 405,129,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 405129730...
Checkpoint 405129730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,330.17864
Policy Entropy: 3.74718
Value Function Loss: 0.05406

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.87637

Collected Steps per Second: 22,344.60340
Overall Steps per Second: 10,573.62150

Timestep Collection Time: 2.23803
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.72951

Cumulative Model Updates: 48,578
Cumulative Timesteps: 405,179,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,592.58216
Policy Entropy: 3.75843
Value Function Loss: 0.05288

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.59463
Value Function Update Magnitude: 0.89666

Collected Steps per Second: 23,033.05870
Overall Steps per Second: 10,718.29319

Timestep Collection Time: 2.17192
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.66735

Cumulative Model Updates: 48,584
Cumulative Timesteps: 405,229,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 405229764...
Checkpoint 405229764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,928.26544
Policy Entropy: 3.76732
Value Function Loss: 0.05026

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.60712
Value Function Update Magnitude: 0.84018

Collected Steps per Second: 22,912.96791
Overall Steps per Second: 10,837.82534

Timestep Collection Time: 2.18339
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61606

Cumulative Model Updates: 48,590
Cumulative Timesteps: 405,279,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,609.89041
Policy Entropy: 3.76807
Value Function Loss: 0.04967

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.53283
Value Function Update Magnitude: 0.78906

Collected Steps per Second: 22,910.20211
Overall Steps per Second: 10,667.28111

Timestep Collection Time: 2.18322
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.68892

Cumulative Model Updates: 48,596
Cumulative Timesteps: 405,329,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 405329810...
Checkpoint 405329810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,193.25822
Policy Entropy: 3.76014
Value Function Loss: 0.04935

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.48949
Value Function Update Magnitude: 0.78580

Collected Steps per Second: 22,647.40219
Overall Steps per Second: 10,630.62747

Timestep Collection Time: 2.20917
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.70640

Cumulative Model Updates: 48,602
Cumulative Timesteps: 405,379,842

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,639.69204
Policy Entropy: 3.75473
Value Function Loss: 0.04852

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.46317
Value Function Update Magnitude: 0.83568

Collected Steps per Second: 23,287.87132
Overall Steps per Second: 10,803.73528

Timestep Collection Time: 2.14833
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.63081

Cumulative Model Updates: 48,608
Cumulative Timesteps: 405,429,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 405429872...
Checkpoint 405429872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,459.09821
Policy Entropy: 3.76739
Value Function Loss: 0.05116

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.48782
Value Function Update Magnitude: 0.87213

Collected Steps per Second: 22,732.62864
Overall Steps per Second: 10,718.49620

Timestep Collection Time: 2.20063
Timestep Consumption Time: 2.46663
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.66726

Cumulative Model Updates: 48,614
Cumulative Timesteps: 405,479,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,222.64419
Policy Entropy: 3.75180
Value Function Loss: 0.05191

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.50345
Value Function Update Magnitude: 0.89885

Collected Steps per Second: 23,040.89307
Overall Steps per Second: 10,850.86942

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.43904
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.61014

Cumulative Model Updates: 48,620
Cumulative Timesteps: 405,529,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 405529922...
Checkpoint 405529922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,072.69911
Policy Entropy: 3.74037
Value Function Loss: 0.05235

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.50447
Value Function Update Magnitude: 0.93492

Collected Steps per Second: 22,423.55391
Overall Steps per Second: 10,588.66732

Timestep Collection Time: 2.23194
Timestep Consumption Time: 2.49462
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.72656

Cumulative Model Updates: 48,626
Cumulative Timesteps: 405,579,970

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,763.47976
Policy Entropy: 3.72639
Value Function Loss: 0.04844

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.57388
Value Function Update Magnitude: 0.94423

Collected Steps per Second: 22,995.51071
Overall Steps per Second: 10,840.79410

Timestep Collection Time: 2.17547
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.61461

Cumulative Model Updates: 48,632
Cumulative Timesteps: 405,629,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 405629996...
Checkpoint 405629996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,168.13943
Policy Entropy: 3.72912
Value Function Loss: 0.04938

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.59264
Value Function Update Magnitude: 0.89744

Collected Steps per Second: 22,654.99813
Overall Steps per Second: 10,721.61693

Timestep Collection Time: 2.20702
Timestep Consumption Time: 2.45646
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.66348

Cumulative Model Updates: 48,638
Cumulative Timesteps: 405,679,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,718.45704
Policy Entropy: 3.72375
Value Function Loss: 0.05315

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.50959
Value Function Update Magnitude: 0.74949

Collected Steps per Second: 22,995.13415
Overall Steps per Second: 10,814.12176

Timestep Collection Time: 2.17524
Timestep Consumption Time: 2.45019
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.62543

Cumulative Model Updates: 48,644
Cumulative Timesteps: 405,730,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 405730016...
Checkpoint 405730016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,588.29492
Policy Entropy: 3.71958
Value Function Loss: 0.05700

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.46685
Value Function Update Magnitude: 0.68431

Collected Steps per Second: 22,265.85819
Overall Steps per Second: 10,686.22099

Timestep Collection Time: 2.24667
Timestep Consumption Time: 2.43450
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.68117

Cumulative Model Updates: 48,650
Cumulative Timesteps: 405,780,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,761.93849
Policy Entropy: 3.72560
Value Function Loss: 0.05649

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.48390
Value Function Update Magnitude: 0.72863

Collected Steps per Second: 22,799.39744
Overall Steps per Second: 10,879.32241

Timestep Collection Time: 2.19339
Timestep Consumption Time: 2.40322
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.59661

Cumulative Model Updates: 48,656
Cumulative Timesteps: 405,830,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 405830048...
Checkpoint 405830048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,144.74776
Policy Entropy: 3.72680
Value Function Loss: 0.05354

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.50715
Value Function Update Magnitude: 0.78852

Collected Steps per Second: 22,421.41915
Overall Steps per Second: 10,715.96037

Timestep Collection Time: 2.23126
Timestep Consumption Time: 2.43729
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.66855

Cumulative Model Updates: 48,662
Cumulative Timesteps: 405,880,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,388.27854
Policy Entropy: 3.72684
Value Function Loss: 0.05287

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.81220

Collected Steps per Second: 22,800.26089
Overall Steps per Second: 10,790.07104

Timestep Collection Time: 2.19313
Timestep Consumption Time: 2.44113
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.63426

Cumulative Model Updates: 48,668
Cumulative Timesteps: 405,930,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 405930080...
Checkpoint 405930080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,380.81667
Policy Entropy: 3.71611
Value Function Loss: 0.05399

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.49324
Value Function Update Magnitude: 0.82896

Collected Steps per Second: 22,323.31686
Overall Steps per Second: 10,705.88352

Timestep Collection Time: 2.24008
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.67089

Cumulative Model Updates: 48,674
Cumulative Timesteps: 405,980,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,772.69156
Policy Entropy: 3.69860
Value Function Loss: 0.05400

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.50148
Value Function Update Magnitude: 0.83229

Collected Steps per Second: 22,646.60731
Overall Steps per Second: 10,612.26687

Timestep Collection Time: 2.20898
Timestep Consumption Time: 2.50499
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.71398

Cumulative Model Updates: 48,680
Cumulative Timesteps: 406,030,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 406030112...
Checkpoint 406030112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,679.87597
Policy Entropy: 3.69483
Value Function Loss: 0.05212

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.51108
Value Function Update Magnitude: 0.82206

Collected Steps per Second: 22,734.72956
Overall Steps per Second: 10,663.88256

Timestep Collection Time: 2.19963
Timestep Consumption Time: 2.48984
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.68947

Cumulative Model Updates: 48,686
Cumulative Timesteps: 406,080,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,360.38460
Policy Entropy: 3.71222
Value Function Loss: 0.04948

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06958
Policy Update Magnitude: 0.55977
Value Function Update Magnitude: 0.81941

Collected Steps per Second: 23,120.07731
Overall Steps per Second: 10,800.56868

Timestep Collection Time: 2.16392
Timestep Consumption Time: 2.46824
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.63216

Cumulative Model Updates: 48,692
Cumulative Timesteps: 406,130,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 406130150...
Checkpoint 406130150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,766.96836
Policy Entropy: 3.72179
Value Function Loss: 0.04841

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06908
Policy Update Magnitude: 0.64157
Value Function Update Magnitude: 0.80697

Collected Steps per Second: 22,482.69590
Overall Steps per Second: 10,621.17682

Timestep Collection Time: 2.22473
Timestep Consumption Time: 2.48454
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.70927

Cumulative Model Updates: 48,698
Cumulative Timesteps: 406,180,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,108.54701
Policy Entropy: 3.73103
Value Function Loss: 0.04782

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07362
Policy Update Magnitude: 0.61734
Value Function Update Magnitude: 0.81216

Collected Steps per Second: 23,281.33664
Overall Steps per Second: 10,916.06229

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.58315

Cumulative Model Updates: 48,704
Cumulative Timesteps: 406,230,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 406230198...
Checkpoint 406230198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,963.36462
Policy Entropy: 3.71379
Value Function Loss: 0.05027

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06828
Policy Update Magnitude: 0.59849
Value Function Update Magnitude: 0.84147

Collected Steps per Second: 22,871.78527
Overall Steps per Second: 10,751.44992

Timestep Collection Time: 2.18715
Timestep Consumption Time: 2.46562
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.65277

Cumulative Model Updates: 48,710
Cumulative Timesteps: 406,280,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,024.97247
Policy Entropy: 3.72188
Value Function Loss: 0.05123

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.54613
Value Function Update Magnitude: 0.85663

Collected Steps per Second: 23,184.10640
Overall Steps per Second: 10,797.01881

Timestep Collection Time: 2.15682
Timestep Consumption Time: 2.47446
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.63128

Cumulative Model Updates: 48,716
Cumulative Timesteps: 406,330,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 406330226...
Checkpoint 406330226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,712.30605
Policy Entropy: 3.70884
Value Function Loss: 0.05203

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.60450
Value Function Update Magnitude: 0.80992

Collected Steps per Second: 22,654.82788
Overall Steps per Second: 10,600.06969

Timestep Collection Time: 2.20792
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.71884

Cumulative Model Updates: 48,722
Cumulative Timesteps: 406,380,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,568.32603
Policy Entropy: 3.73069
Value Function Loss: 0.04966

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.63355
Value Function Update Magnitude: 0.77766

Collected Steps per Second: 23,161.86607
Overall Steps per Second: 10,870.35631

Timestep Collection Time: 2.15958
Timestep Consumption Time: 2.44192
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.60151

Cumulative Model Updates: 48,728
Cumulative Timesteps: 406,430,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 406430266...
Checkpoint 406430266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,447.66338
Policy Entropy: 3.73984
Value Function Loss: 0.05097

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.61608
Value Function Update Magnitude: 0.74855

Collected Steps per Second: 22,224.39824
Overall Steps per Second: 10,669.14965

Timestep Collection Time: 2.24978
Timestep Consumption Time: 2.43663
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.68641

Cumulative Model Updates: 48,734
Cumulative Timesteps: 406,480,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,884.25153
Policy Entropy: 3.74695
Value Function Loss: 0.04956

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06280
Policy Update Magnitude: 0.63691
Value Function Update Magnitude: 0.69467

Collected Steps per Second: 22,680.62056
Overall Steps per Second: 10,622.02761

Timestep Collection Time: 2.20461
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.70739

Cumulative Model Updates: 48,740
Cumulative Timesteps: 406,530,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 406530268...
Checkpoint 406530268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,661.96654
Policy Entropy: 3.73693
Value Function Loss: 0.05113

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.60934
Value Function Update Magnitude: 0.61207

Collected Steps per Second: 22,650.09252
Overall Steps per Second: 10,656.92002

Timestep Collection Time: 2.20847
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.69385

Cumulative Model Updates: 48,746
Cumulative Timesteps: 406,580,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,642.70223
Policy Entropy: 3.73702
Value Function Loss: 0.05166

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.51532
Value Function Update Magnitude: 0.61609

Collected Steps per Second: 22,842.07151
Overall Steps per Second: 10,755.79727

Timestep Collection Time: 2.18921
Timestep Consumption Time: 2.46001
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.64921

Cumulative Model Updates: 48,752
Cumulative Timesteps: 406,630,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 406630296...
Checkpoint 406630296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,837.71489
Policy Entropy: 3.73377
Value Function Loss: 0.05470

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.48113
Value Function Update Magnitude: 0.65425

Collected Steps per Second: 22,660.86198
Overall Steps per Second: 10,602.69605

Timestep Collection Time: 2.20645
Timestep Consumption Time: 2.50933
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.71578

Cumulative Model Updates: 48,758
Cumulative Timesteps: 406,680,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,811.03655
Policy Entropy: 3.74250
Value Function Loss: 0.05210

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.48891
Value Function Update Magnitude: 0.70185

Collected Steps per Second: 22,637.84789
Overall Steps per Second: 10,621.76688

Timestep Collection Time: 2.20940
Timestep Consumption Time: 2.49942
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.70882

Cumulative Model Updates: 48,764
Cumulative Timesteps: 406,730,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 406730312...
Checkpoint 406730312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,828.68926
Policy Entropy: 3.72855
Value Function Loss: 0.05117

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.55310
Value Function Update Magnitude: 0.77903

Collected Steps per Second: 22,827.38962
Overall Steps per Second: 10,698.03971

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.48489
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.67656

Cumulative Model Updates: 48,770
Cumulative Timesteps: 406,780,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,866.19586
Policy Entropy: 3.71489
Value Function Loss: 0.05047

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.58142
Value Function Update Magnitude: 0.77464

Collected Steps per Second: 22,984.23609
Overall Steps per Second: 10,674.35528

Timestep Collection Time: 2.17627
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.68600

Cumulative Model Updates: 48,776
Cumulative Timesteps: 406,830,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 406830362...
Checkpoint 406830362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,081.17693
Policy Entropy: 3.70474
Value Function Loss: 0.05208

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.78896

Collected Steps per Second: 22,712.49163
Overall Steps per Second: 10,660.04580

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.48978
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.69191

Cumulative Model Updates: 48,782
Cumulative Timesteps: 406,880,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,430.52056
Policy Entropy: 3.70488
Value Function Loss: 0.05143

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.49891
Value Function Update Magnitude: 0.85796

Collected Steps per Second: 22,815.98969
Overall Steps per Second: 10,801.79840

Timestep Collection Time: 2.19267
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.63145

Cumulative Model Updates: 48,788
Cumulative Timesteps: 406,930,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 406930406...
Checkpoint 406930406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,312.08151
Policy Entropy: 3.69889
Value Function Loss: 0.05126

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.49396
Value Function Update Magnitude: 0.88411

Collected Steps per Second: 22,531.86844
Overall Steps per Second: 10,785.32450

Timestep Collection Time: 2.21926
Timestep Consumption Time: 2.41704
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.63630

Cumulative Model Updates: 48,794
Cumulative Timesteps: 406,980,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,103.70337
Policy Entropy: 3.69736
Value Function Loss: 0.05153

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.48826
Value Function Update Magnitude: 0.92795

Collected Steps per Second: 23,176.48551
Overall Steps per Second: 10,849.79149

Timestep Collection Time: 2.15762
Timestep Consumption Time: 2.45132
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.60894

Cumulative Model Updates: 48,800
Cumulative Timesteps: 407,030,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 407030416...
Checkpoint 407030416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,355.66145
Policy Entropy: 3.68725
Value Function Loss: 0.05153

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.45357
Value Function Update Magnitude: 0.90001

Collected Steps per Second: 22,520.54687
Overall Steps per Second: 10,633.48726

Timestep Collection Time: 2.22073
Timestep Consumption Time: 2.48253
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.70325

Cumulative Model Updates: 48,806
Cumulative Timesteps: 407,080,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,583.37643
Policy Entropy: 3.68862
Value Function Loss: 0.05261

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.41485
Value Function Update Magnitude: 0.86451

Collected Steps per Second: 22,725.45756
Overall Steps per Second: 10,805.44829

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.42819
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.62933

Cumulative Model Updates: 48,812
Cumulative Timesteps: 407,130,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 407130450...
Checkpoint 407130450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.51769
Policy Entropy: 3.68924
Value Function Loss: 0.05550

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.41879
Value Function Update Magnitude: 0.76582

Collected Steps per Second: 22,641.10859
Overall Steps per Second: 10,756.48132

Timestep Collection Time: 2.20855
Timestep Consumption Time: 2.44018
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.64873

Cumulative Model Updates: 48,818
Cumulative Timesteps: 407,180,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,602.48970
Policy Entropy: 3.71299
Value Function Loss: 0.05657

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.38779
Value Function Update Magnitude: 0.62444

Collected Steps per Second: 22,994.08464
Overall Steps per Second: 10,861.85856

Timestep Collection Time: 2.17569
Timestep Consumption Time: 2.43015
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.60584

Cumulative Model Updates: 48,824
Cumulative Timesteps: 407,230,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 407230482...
Checkpoint 407230482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,810.65887
Policy Entropy: 3.70656
Value Function Loss: 0.05844

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.41455
Value Function Update Magnitude: 0.64567

Collected Steps per Second: 22,517.21543
Overall Steps per Second: 10,682.20884

Timestep Collection Time: 2.22123
Timestep Consumption Time: 2.46094
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.68218

Cumulative Model Updates: 48,830
Cumulative Timesteps: 407,280,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,883.59654
Policy Entropy: 3.70966
Value Function Loss: 0.05518

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.45432
Value Function Update Magnitude: 0.75700

Collected Steps per Second: 22,273.61656
Overall Steps per Second: 10,549.40708

Timestep Collection Time: 2.24517
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.74036

Cumulative Model Updates: 48,836
Cumulative Timesteps: 407,330,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 407330506...
Checkpoint 407330506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,134.17238
Policy Entropy: 3.68810
Value Function Loss: 0.05278

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.46871
Value Function Update Magnitude: 0.77978

Collected Steps per Second: 22,655.95859
Overall Steps per Second: 10,644.92694

Timestep Collection Time: 2.20745
Timestep Consumption Time: 2.49075
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.69820

Cumulative Model Updates: 48,842
Cumulative Timesteps: 407,380,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,312.56577
Policy Entropy: 3.69235
Value Function Loss: 0.05087

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.49542
Value Function Update Magnitude: 0.72210

Collected Steps per Second: 22,572.49732
Overall Steps per Second: 10,767.36128

Timestep Collection Time: 2.21535
Timestep Consumption Time: 2.42887
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.64422

Cumulative Model Updates: 48,848
Cumulative Timesteps: 407,430,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 407430524...
Checkpoint 407430524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.99440
Policy Entropy: 3.68737
Value Function Loss: 0.05272

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.48928
Value Function Update Magnitude: 0.67726

Collected Steps per Second: 22,548.36064
Overall Steps per Second: 10,654.74186

Timestep Collection Time: 2.21781
Timestep Consumption Time: 2.47569
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.69350

Cumulative Model Updates: 48,854
Cumulative Timesteps: 407,480,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,879.13481
Policy Entropy: 3.69954
Value Function Loss: 0.05197

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.55263
Value Function Update Magnitude: 0.64924

Collected Steps per Second: 21,890.81355
Overall Steps per Second: 10,639.87939

Timestep Collection Time: 2.28534
Timestep Consumption Time: 2.41659
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.70193

Cumulative Model Updates: 48,860
Cumulative Timesteps: 407,530,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 407530560...
Checkpoint 407530560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,722.48451
Policy Entropy: 3.70098
Value Function Loss: 0.05107

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.62370

Collected Steps per Second: 22,069.24429
Overall Steps per Second: 10,830.92984

Timestep Collection Time: 2.26605
Timestep Consumption Time: 2.35128
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61733

Cumulative Model Updates: 48,866
Cumulative Timesteps: 407,580,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,223.92532
Policy Entropy: 3.69372
Value Function Loss: 0.05018

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.50254
Value Function Update Magnitude: 0.63973

Collected Steps per Second: 22,058.61796
Overall Steps per Second: 10,656.61483

Timestep Collection Time: 2.26778
Timestep Consumption Time: 2.42640
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.69417

Cumulative Model Updates: 48,872
Cumulative Timesteps: 407,630,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 407630594...
Checkpoint 407630594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,987.53767
Policy Entropy: 3.70981
Value Function Loss: 0.04899

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.46553
Value Function Update Magnitude: 0.66148

Collected Steps per Second: 22,072.57431
Overall Steps per Second: 10,700.06314

Timestep Collection Time: 2.26634
Timestep Consumption Time: 2.40877
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.67511

Cumulative Model Updates: 48,878
Cumulative Timesteps: 407,680,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,731.14467
Policy Entropy: 3.71034
Value Function Loss: 0.04936

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.51921
Value Function Update Magnitude: 0.62037

Collected Steps per Second: 22,502.79272
Overall Steps per Second: 10,761.79135

Timestep Collection Time: 2.22328
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.64885

Cumulative Model Updates: 48,884
Cumulative Timesteps: 407,730,648

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 407730648...
Checkpoint 407730648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,677.62422
Policy Entropy: 3.70870
Value Function Loss: 0.04712

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.53654
Value Function Update Magnitude: 0.64007

Collected Steps per Second: 22,015.88189
Overall Steps per Second: 10,627.08919

Timestep Collection Time: 2.27200
Timestep Consumption Time: 2.43484
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.70684

Cumulative Model Updates: 48,890
Cumulative Timesteps: 407,780,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,974.88477
Policy Entropy: 3.70556
Value Function Loss: 0.04823

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.52312
Value Function Update Magnitude: 0.60979

Collected Steps per Second: 22,019.41881
Overall Steps per Second: 10,794.73502

Timestep Collection Time: 2.27209
Timestep Consumption Time: 2.36258
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.63467

Cumulative Model Updates: 48,896
Cumulative Timesteps: 407,830,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 407830698...
Checkpoint 407830698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,256.97623
Policy Entropy: 3.70562
Value Function Loss: 0.04947

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.46692
Value Function Update Magnitude: 0.61295

Collected Steps per Second: 21,991.86283
Overall Steps per Second: 10,652.57913

Timestep Collection Time: 2.27357
Timestep Consumption Time: 2.42013
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.69370

Cumulative Model Updates: 48,902
Cumulative Timesteps: 407,880,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,613.16549
Policy Entropy: 3.72748
Value Function Loss: 0.04727

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.40114
Value Function Update Magnitude: 0.63080

Collected Steps per Second: 22,863.62466
Overall Steps per Second: 10,904.40472

Timestep Collection Time: 2.18810
Timestep Consumption Time: 2.39977
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.58787

Cumulative Model Updates: 48,908
Cumulative Timesteps: 407,930,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 407930726...
Checkpoint 407930726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,398.90806
Policy Entropy: 3.73312
Value Function Loss: 0.04611

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.40158
Value Function Update Magnitude: 0.70610

Collected Steps per Second: 22,635.50339
Overall Steps per Second: 10,720.97645

Timestep Collection Time: 2.20910
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.66413

Cumulative Model Updates: 48,914
Cumulative Timesteps: 407,980,730

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,659.25495
Policy Entropy: 3.74622
Value Function Loss: 0.04446

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07223
Policy Update Magnitude: 0.46906
Value Function Update Magnitude: 0.78014

Collected Steps per Second: 22,901.00866
Overall Steps per Second: 10,879.95188

Timestep Collection Time: 2.18453
Timestep Consumption Time: 2.41365
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.59818

Cumulative Model Updates: 48,920
Cumulative Timesteps: 408,030,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 408030758...
Checkpoint 408030758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,220.95936
Policy Entropy: 3.73795
Value Function Loss: 0.04476

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05727
Policy Update Magnitude: 0.57447
Value Function Update Magnitude: 0.78551

Collected Steps per Second: 22,616.76914
Overall Steps per Second: 10,656.96756

Timestep Collection Time: 2.21190
Timestep Consumption Time: 2.48231
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.69421

Cumulative Model Updates: 48,926
Cumulative Timesteps: 408,080,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,474.59988
Policy Entropy: 3.73540
Value Function Loss: 0.04288

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.54741
Value Function Update Magnitude: 0.77502

Collected Steps per Second: 23,071.97275
Overall Steps per Second: 10,877.53834

Timestep Collection Time: 2.16800
Timestep Consumption Time: 2.43047
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.59847

Cumulative Model Updates: 48,932
Cumulative Timesteps: 408,130,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 408130804...
Checkpoint 408130804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,793.34741
Policy Entropy: 3.72841
Value Function Loss: 0.04264

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05897
Policy Update Magnitude: 0.57748
Value Function Update Magnitude: 0.78237

Collected Steps per Second: 22,927.30652
Overall Steps per Second: 10,731.26251

Timestep Collection Time: 2.18089
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.65947

Cumulative Model Updates: 48,938
Cumulative Timesteps: 408,180,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,382.78843
Policy Entropy: 3.72691
Value Function Loss: 0.04329

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06040
Policy Update Magnitude: 0.62024
Value Function Update Magnitude: 0.79022

Collected Steps per Second: 22,876.79650
Overall Steps per Second: 10,801.42267

Timestep Collection Time: 2.18597
Timestep Consumption Time: 2.44379
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.62976

Cumulative Model Updates: 48,944
Cumulative Timesteps: 408,230,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 408230814...
Checkpoint 408230814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,060.39864
Policy Entropy: 3.72430
Value Function Loss: 0.04274

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.63806
Value Function Update Magnitude: 0.78416

Collected Steps per Second: 22,667.42303
Overall Steps per Second: 10,643.22655

Timestep Collection Time: 2.20704
Timestep Consumption Time: 2.49341
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.70045

Cumulative Model Updates: 48,950
Cumulative Timesteps: 408,280,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,819.06871
Policy Entropy: 3.72516
Value Function Loss: 0.04383

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.65246
Value Function Update Magnitude: 0.78623

Collected Steps per Second: 22,691.87712
Overall Steps per Second: 10,636.12600

Timestep Collection Time: 2.20405
Timestep Consumption Time: 2.49823
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.70228

Cumulative Model Updates: 48,956
Cumulative Timesteps: 408,330,856

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 408330856...
Checkpoint 408330856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,553.22746
Policy Entropy: 3.71664
Value Function Loss: 0.04483

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.63705
Value Function Update Magnitude: 0.79113

Collected Steps per Second: 22,831.87130
Overall Steps per Second: 10,698.40450

Timestep Collection Time: 2.19115
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.67621

Cumulative Model Updates: 48,962
Cumulative Timesteps: 408,380,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,580.17105
Policy Entropy: 3.71745
Value Function Loss: 0.04489

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.59149
Value Function Update Magnitude: 0.78862

Collected Steps per Second: 22,881.27523
Overall Steps per Second: 10,688.36780

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.49419
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.68060

Cumulative Model Updates: 48,968
Cumulative Timesteps: 408,430,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 408430912...
Checkpoint 408430912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,070.70584
Policy Entropy: 3.71821
Value Function Loss: 0.04741

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.52112
Value Function Update Magnitude: 0.78956

Collected Steps per Second: 22,374.04914
Overall Steps per Second: 10,624.75428

Timestep Collection Time: 2.23589
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.70844

Cumulative Model Updates: 48,974
Cumulative Timesteps: 408,480,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,008.79477
Policy Entropy: 3.74002
Value Function Loss: 0.04779

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.50048
Value Function Update Magnitude: 0.77172

Collected Steps per Second: 22,477.63509
Overall Steps per Second: 10,558.64391

Timestep Collection Time: 2.22443
Timestep Consumption Time: 2.51102
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.73546

Cumulative Model Updates: 48,980
Cumulative Timesteps: 408,530,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 408530938...
Checkpoint 408530938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,499.43060
Policy Entropy: 3.73524
Value Function Loss: 0.04835

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.48847
Value Function Update Magnitude: 0.75420

Collected Steps per Second: 22,788.05875
Overall Steps per Second: 10,654.22461

Timestep Collection Time: 2.19466
Timestep Consumption Time: 2.49944
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.69410

Cumulative Model Updates: 48,986
Cumulative Timesteps: 408,580,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,721.26096
Policy Entropy: 3.73679
Value Function Loss: 0.04920

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.56139
Value Function Update Magnitude: 0.68680

Collected Steps per Second: 22,975.24931
Overall Steps per Second: 10,851.08092

Timestep Collection Time: 2.17704
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.60949

Cumulative Model Updates: 48,992
Cumulative Timesteps: 408,630,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 408630968...
Checkpoint 408630968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,043.93937
Policy Entropy: 3.72747
Value Function Loss: 0.05136

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.65583

Collected Steps per Second: 22,449.07145
Overall Steps per Second: 10,607.30826

Timestep Collection Time: 2.22833
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.71599

Cumulative Model Updates: 48,998
Cumulative Timesteps: 408,680,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,616.70054
Policy Entropy: 3.71965
Value Function Loss: 0.05113

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.16961
Policy Update Magnitude: 0.42804
Value Function Update Magnitude: 0.65796

Collected Steps per Second: 21,672.70679
Overall Steps per Second: 10,497.63555

Timestep Collection Time: 2.30889
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.76679

Cumulative Model Updates: 49,004
Cumulative Timesteps: 408,731,032

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 408731032...
Checkpoint 408731032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,433.56059
Policy Entropy: 3.71937
Value Function Loss: 0.05190

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.41892
Value Function Update Magnitude: 0.62364

Collected Steps per Second: 22,237.59658
Overall Steps per Second: 10,576.55996

Timestep Collection Time: 2.24934
Timestep Consumption Time: 2.47998
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.72933

Cumulative Model Updates: 49,010
Cumulative Timesteps: 408,781,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.79871
Policy Entropy: 3.73389
Value Function Loss: 0.05267

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.15173
Policy Update Magnitude: 0.42130
Value Function Update Magnitude: 0.57337

Collected Steps per Second: 23,061.57910
Overall Steps per Second: 10,873.11940

Timestep Collection Time: 2.16863
Timestep Consumption Time: 2.43097
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.59960

Cumulative Model Updates: 49,016
Cumulative Timesteps: 408,831,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 408831064...
Checkpoint 408831064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,277.18502
Policy Entropy: 3.72401
Value Function Loss: 0.05156

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.39549
Value Function Update Magnitude: 0.60809

Collected Steps per Second: 22,572.72676
Overall Steps per Second: 10,676.42540

Timestep Collection Time: 2.21595
Timestep Consumption Time: 2.46914
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.68509

Cumulative Model Updates: 49,022
Cumulative Timesteps: 408,881,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421.36923
Policy Entropy: 3.74250
Value Function Loss: 0.04938

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.42810
Value Function Update Magnitude: 0.69222

Collected Steps per Second: 22,764.71606
Overall Steps per Second: 10,684.32664

Timestep Collection Time: 2.19726
Timestep Consumption Time: 2.48436
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.68162

Cumulative Model Updates: 49,028
Cumulative Timesteps: 408,931,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 408931104...
Checkpoint 408931104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,558.55414
Policy Entropy: 3.75969
Value Function Loss: 0.04654

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.42558
Value Function Update Magnitude: 0.69312

Collected Steps per Second: 22,067.21865
Overall Steps per Second: 10,837.45345

Timestep Collection Time: 2.26707
Timestep Consumption Time: 2.34914
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61621

Cumulative Model Updates: 49,034
Cumulative Timesteps: 408,981,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,143.98082
Policy Entropy: 3.77523
Value Function Loss: 0.04429

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12360
Policy Update Magnitude: 0.44828
Value Function Update Magnitude: 0.73592

Collected Steps per Second: 22,215.33586
Overall Steps per Second: 10,821.57174

Timestep Collection Time: 2.25115
Timestep Consumption Time: 2.37018
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62133

Cumulative Model Updates: 49,040
Cumulative Timesteps: 409,031,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 409031142...
Checkpoint 409031142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,839.18882
Policy Entropy: 3.77665
Value Function Loss: 0.04146

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.51025
Value Function Update Magnitude: 0.78611

Collected Steps per Second: 21,668.11473
Overall Steps per Second: 10,726.61343

Timestep Collection Time: 2.30837
Timestep Consumption Time: 2.35461
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.66298

Cumulative Model Updates: 49,046
Cumulative Timesteps: 409,081,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,074.04469
Policy Entropy: 3.76770
Value Function Loss: 0.04086

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.59200
Value Function Update Magnitude: 0.80743

Collected Steps per Second: 22,067.09769
Overall Steps per Second: 10,691.04039

Timestep Collection Time: 2.26618
Timestep Consumption Time: 2.41138
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.67756

Cumulative Model Updates: 49,052
Cumulative Timesteps: 409,131,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 409131168...
Checkpoint 409131168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.21847
Policy Entropy: 3.76815
Value Function Loss: 0.04040

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.62444
Value Function Update Magnitude: 0.79989

Collected Steps per Second: 21,822.72928
Overall Steps per Second: 10,665.25453

Timestep Collection Time: 2.29211
Timestep Consumption Time: 2.39789
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.69000

Cumulative Model Updates: 49,058
Cumulative Timesteps: 409,181,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,763.40162
Policy Entropy: 3.76085
Value Function Loss: 0.04026

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08652
Policy Update Magnitude: 0.57789
Value Function Update Magnitude: 0.78143

Collected Steps per Second: 22,439.90313
Overall Steps per Second: 10,687.68388

Timestep Collection Time: 2.22880
Timestep Consumption Time: 2.45079
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.67959

Cumulative Model Updates: 49,064
Cumulative Timesteps: 409,231,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 409231202...
Checkpoint 409231202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,538.88406
Policy Entropy: 3.77005
Value Function Loss: 0.04021

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.75593

Collected Steps per Second: 21,746.94988
Overall Steps per Second: 10,639.60111

Timestep Collection Time: 2.29917
Timestep Consumption Time: 2.40025
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.69942

Cumulative Model Updates: 49,070
Cumulative Timesteps: 409,281,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.99083
Policy Entropy: 3.77191
Value Function Loss: 0.04114

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09367
Policy Update Magnitude: 0.52409
Value Function Update Magnitude: 0.76095

Collected Steps per Second: 22,503.59461
Overall Steps per Second: 10,892.72566

Timestep Collection Time: 2.22347
Timestep Consumption Time: 2.37006
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.59352

Cumulative Model Updates: 49,076
Cumulative Timesteps: 409,331,238

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 409331238...
Checkpoint 409331238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,766.77673
Policy Entropy: 3.76947
Value Function Loss: 0.04127

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.50156
Value Function Update Magnitude: 0.76920

Collected Steps per Second: 21,868.43335
Overall Steps per Second: 10,667.00446

Timestep Collection Time: 2.28732
Timestep Consumption Time: 2.40191
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.68923

Cumulative Model Updates: 49,082
Cumulative Timesteps: 409,381,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,488.33110
Policy Entropy: 3.75612
Value Function Loss: 0.04278

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.53117
Value Function Update Magnitude: 0.73174

Collected Steps per Second: 22,309.39569
Overall Steps per Second: 10,603.68138

Timestep Collection Time: 2.24255
Timestep Consumption Time: 2.47562
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.71817

Cumulative Model Updates: 49,088
Cumulative Timesteps: 409,431,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 409431288...
Checkpoint 409431288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,397.11956
Policy Entropy: 3.75675
Value Function Loss: 0.04384

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.49024
Value Function Update Magnitude: 0.67516

Collected Steps per Second: 22,830.04798
Overall Steps per Second: 10,885.92144

Timestep Collection Time: 2.19141
Timestep Consumption Time: 2.40443
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.59584

Cumulative Model Updates: 49,094
Cumulative Timesteps: 409,481,318

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,858.67464
Policy Entropy: 3.75228
Value Function Loss: 0.04643

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06594
Policy Update Magnitude: 0.51629
Value Function Update Magnitude: 0.64783

Collected Steps per Second: 22,667.17483
Overall Steps per Second: 10,755.21462

Timestep Collection Time: 2.20663
Timestep Consumption Time: 2.44395
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.65058

Cumulative Model Updates: 49,100
Cumulative Timesteps: 409,531,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 409531336...
Checkpoint 409531336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,189.52852
Policy Entropy: 3.74719
Value Function Loss: 0.05059

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.51060
Value Function Update Magnitude: 0.61503

Collected Steps per Second: 22,681.33254
Overall Steps per Second: 10,920.28508

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.37513
PPO Batch Consumption Time: 0.27595
Total Iteration Time: 4.58047

Cumulative Model Updates: 49,106
Cumulative Timesteps: 409,581,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,179.20072
Policy Entropy: 3.74836
Value Function Loss: 0.04881

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.50923
Value Function Update Magnitude: 0.71674

Collected Steps per Second: 23,056.14430
Overall Steps per Second: 10,846.58263

Timestep Collection Time: 2.16897
Timestep Consumption Time: 2.44152
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.61048

Cumulative Model Updates: 49,112
Cumulative Timesteps: 409,631,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 409631364...
Checkpoint 409631364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,187.81322
Policy Entropy: 3.74925
Value Function Loss: 0.04728

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.51959
Value Function Update Magnitude: 0.77017

Collected Steps per Second: 22,183.52680
Overall Steps per Second: 10,625.47316

Timestep Collection Time: 2.25528
Timestep Consumption Time: 2.45322
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.70850

Cumulative Model Updates: 49,118
Cumulative Timesteps: 409,681,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,603.78660
Policy Entropy: 3.75935
Value Function Loss: 0.04699

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.76116

Collected Steps per Second: 23,042.96477
Overall Steps per Second: 10,855.65856

Timestep Collection Time: 2.17099
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.60829

Cumulative Model Updates: 49,124
Cumulative Timesteps: 409,731,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 409731420...
Checkpoint 409731420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,750.33218
Policy Entropy: 3.76100
Value Function Loss: 0.04743

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.78152

Collected Steps per Second: 22,225.30117
Overall Steps per Second: 10,760.49775

Timestep Collection Time: 2.24969
Timestep Consumption Time: 2.39694
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.64663

Cumulative Model Updates: 49,130
Cumulative Timesteps: 409,781,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,037.72546
Policy Entropy: 3.75420
Value Function Loss: 0.04715

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.80407

Collected Steps per Second: 22,907.99974
Overall Steps per Second: 10,790.17984

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.45218
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.63570

Cumulative Model Updates: 49,136
Cumulative Timesteps: 409,831,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 409831440...
Checkpoint 409831440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,704.37554
Policy Entropy: 3.75283
Value Function Loss: 0.04696

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.55572
Value Function Update Magnitude: 0.80820

Collected Steps per Second: 22,664.09449
Overall Steps per Second: 10,709.28790

Timestep Collection Time: 2.20710
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.67090

Cumulative Model Updates: 49,142
Cumulative Timesteps: 409,881,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,874.06439
Policy Entropy: 3.74842
Value Function Loss: 0.04774

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.57107
Value Function Update Magnitude: 0.82793

Collected Steps per Second: 22,721.16725
Overall Steps per Second: 10,793.92899

Timestep Collection Time: 2.20182
Timestep Consumption Time: 2.43300
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.63483

Cumulative Model Updates: 49,148
Cumulative Timesteps: 409,931,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 409931490...
Checkpoint 409931490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,875.52891
Policy Entropy: 3.73178
Value Function Loss: 0.04897

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.53717
Value Function Update Magnitude: 0.81957

Collected Steps per Second: 22,634.15860
Overall Steps per Second: 10,743.22785

Timestep Collection Time: 2.20958
Timestep Consumption Time: 2.44563
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.65521

Cumulative Model Updates: 49,154
Cumulative Timesteps: 409,981,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,083.57654
Policy Entropy: 3.73148
Value Function Loss: 0.04910

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.57764
Value Function Update Magnitude: 0.80023

Collected Steps per Second: 22,829.35731
Overall Steps per Second: 10,811.82327

Timestep Collection Time: 2.19016
Timestep Consumption Time: 2.43440
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.62457

Cumulative Model Updates: 49,160
Cumulative Timesteps: 410,031,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 410031502...
Checkpoint 410031502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,388.02029
Policy Entropy: 3.72762
Value Function Loss: 0.05045

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.53199
Value Function Update Magnitude: 0.74985

Collected Steps per Second: 22,483.16931
Overall Steps per Second: 10,739.18352

Timestep Collection Time: 2.22460
Timestep Consumption Time: 2.43274
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.65734

Cumulative Model Updates: 49,166
Cumulative Timesteps: 410,081,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,364.53861
Policy Entropy: 3.74331
Value Function Loss: 0.04958

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.51976
Value Function Update Magnitude: 0.74449

Collected Steps per Second: 22,695.95599
Overall Steps per Second: 10,800.39792

Timestep Collection Time: 2.20409
Timestep Consumption Time: 2.42759
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.63168

Cumulative Model Updates: 49,172
Cumulative Timesteps: 410,131,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 410131542...
Checkpoint 410131542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.23584
Policy Entropy: 3.73336
Value Function Loss: 0.04898

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.50710
Value Function Update Magnitude: 0.81341

Collected Steps per Second: 22,800.33345
Overall Steps per Second: 10,801.85716

Timestep Collection Time: 2.19400
Timestep Consumption Time: 2.43705
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.63106

Cumulative Model Updates: 49,178
Cumulative Timesteps: 410,181,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.71881
Policy Entropy: 3.73138
Value Function Loss: 0.04835

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06465
Policy Update Magnitude: 0.59132
Value Function Update Magnitude: 0.80578

Collected Steps per Second: 22,824.59471
Overall Steps per Second: 10,871.76994

Timestep Collection Time: 2.19097
Timestep Consumption Time: 2.40883
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.59980

Cumulative Model Updates: 49,184
Cumulative Timesteps: 410,231,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 410231574...
Checkpoint 410231574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,658.91915
Policy Entropy: 3.73300
Value Function Loss: 0.05185

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.57051
Value Function Update Magnitude: 0.66896

Collected Steps per Second: 22,885.15930
Overall Steps per Second: 10,682.38857

Timestep Collection Time: 2.18508
Timestep Consumption Time: 2.49608
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.68116

Cumulative Model Updates: 49,190
Cumulative Timesteps: 410,281,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,349.69962
Policy Entropy: 3.73666
Value Function Loss: 0.05466

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.48433
Value Function Update Magnitude: 0.64324

Collected Steps per Second: 22,902.00147
Overall Steps per Second: 10,812.85264

Timestep Collection Time: 2.18383
Timestep Consumption Time: 2.44159
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.62542

Cumulative Model Updates: 49,196
Cumulative Timesteps: 410,331,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 410331594...
Checkpoint 410331594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,617.69835
Policy Entropy: 3.73686
Value Function Loss: 0.05493

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.47624
Value Function Update Magnitude: 0.69108

Collected Steps per Second: 22,870.60539
Overall Steps per Second: 10,646.73133

Timestep Collection Time: 2.18630
Timestep Consumption Time: 2.51017
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.69646

Cumulative Model Updates: 49,202
Cumulative Timesteps: 410,381,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,615.92087
Policy Entropy: 3.73156
Value Function Loss: 0.05499

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.45944
Value Function Update Magnitude: 0.74354

Collected Steps per Second: 22,292.85012
Overall Steps per Second: 10,525.82356

Timestep Collection Time: 2.24359
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.75174

Cumulative Model Updates: 49,208
Cumulative Timesteps: 410,431,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 410431612...
Checkpoint 410431612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,348.38757
Policy Entropy: 3.73908
Value Function Loss: 0.05175

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07815
Policy Update Magnitude: 0.52157
Value Function Update Magnitude: 0.74176

Collected Steps per Second: 22,687.17532
Overall Steps per Second: 10,620.89292

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.70977

Cumulative Model Updates: 49,214
Cumulative Timesteps: 410,481,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,040.55415
Policy Entropy: 3.73535
Value Function Loss: 0.05040

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.49827
Value Function Update Magnitude: 0.76819

Collected Steps per Second: 22,748.03548
Overall Steps per Second: 10,791.18951

Timestep Collection Time: 2.19799
Timestep Consumption Time: 2.43542
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.63341

Cumulative Model Updates: 49,220
Cumulative Timesteps: 410,531,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 410531634...
Checkpoint 410531634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,177.87714
Policy Entropy: 3.73628
Value Function Loss: 0.04833

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.50295
Value Function Update Magnitude: 0.81972

Collected Steps per Second: 22,363.23539
Overall Steps per Second: 10,756.00310

Timestep Collection Time: 2.23706
Timestep Consumption Time: 2.41411
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.65117

Cumulative Model Updates: 49,226
Cumulative Timesteps: 410,581,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,586.15950
Policy Entropy: 3.72617
Value Function Loss: 0.05145

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.47760
Value Function Update Magnitude: 0.74369

Collected Steps per Second: 22,830.76472
Overall Steps per Second: 10,805.36145

Timestep Collection Time: 2.19108
Timestep Consumption Time: 2.43847
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62955

Cumulative Model Updates: 49,232
Cumulative Timesteps: 410,631,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 410631686...
Checkpoint 410631686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,447.88243
Policy Entropy: 3.73740
Value Function Loss: 0.05267

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.46933
Value Function Update Magnitude: 0.68842

Collected Steps per Second: 22,470.41611
Overall Steps per Second: 10,650.83224

Timestep Collection Time: 2.22613
Timestep Consumption Time: 2.47041
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.69653

Cumulative Model Updates: 49,238
Cumulative Timesteps: 410,681,708

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,839.27919
Policy Entropy: 3.73175
Value Function Loss: 0.05289

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.47241
Value Function Update Magnitude: 0.67658

Collected Steps per Second: 22,855.25220
Overall Steps per Second: 10,698.49730

Timestep Collection Time: 2.18821
Timestep Consumption Time: 2.48647
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.67468

Cumulative Model Updates: 49,244
Cumulative Timesteps: 410,731,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 410731720...
Checkpoint 410731720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,008.76933
Policy Entropy: 3.73198
Value Function Loss: 0.05337

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.48293
Value Function Update Magnitude: 0.71053

Collected Steps per Second: 22,623.04555
Overall Steps per Second: 10,809.83777

Timestep Collection Time: 2.21058
Timestep Consumption Time: 2.41576
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.62634

Cumulative Model Updates: 49,250
Cumulative Timesteps: 410,781,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,180.01537
Policy Entropy: 3.71317
Value Function Loss: 0.05195

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.44958
Value Function Update Magnitude: 0.78321

Collected Steps per Second: 22,770.26680
Overall Steps per Second: 10,665.99911

Timestep Collection Time: 2.19602
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.68817

Cumulative Model Updates: 49,256
Cumulative Timesteps: 410,831,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 410831734...
Checkpoint 410831734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,654.70307
Policy Entropy: 3.71884
Value Function Loss: 0.05240

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.45904
Value Function Update Magnitude: 0.79943

Collected Steps per Second: 22,653.74807
Overall Steps per Second: 10,628.38804

Timestep Collection Time: 2.20767
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.70551

Cumulative Model Updates: 49,262
Cumulative Timesteps: 410,881,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,571.96964
Policy Entropy: 3.72718
Value Function Loss: 0.05247

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.48076
Value Function Update Magnitude: 0.78498

Collected Steps per Second: 22,960.25490
Overall Steps per Second: 10,746.96592

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.47520
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.65322

Cumulative Model Updates: 49,268
Cumulative Timesteps: 410,931,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 410931754...
Checkpoint 410931754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,930.84481
Policy Entropy: 3.71856
Value Function Loss: 0.05517

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.46754
Value Function Update Magnitude: 0.67713

Collected Steps per Second: 22,744.83535
Overall Steps per Second: 10,649.95554

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69748

Cumulative Model Updates: 49,274
Cumulative Timesteps: 410,981,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,491.76667
Policy Entropy: 3.72432
Value Function Loss: 0.05381

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.48280
Value Function Update Magnitude: 0.66732

Collected Steps per Second: 22,931.90488
Overall Steps per Second: 10,843.74260

Timestep Collection Time: 2.18115
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61261

Cumulative Model Updates: 49,280
Cumulative Timesteps: 411,031,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 411031800...
Checkpoint 411031800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,860.64573
Policy Entropy: 3.70865
Value Function Loss: 0.05338

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.47400
Value Function Update Magnitude: 0.65650

Collected Steps per Second: 22,190.53554
Overall Steps per Second: 10,739.91969

Timestep Collection Time: 2.25366
Timestep Consumption Time: 2.40280
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.65646

Cumulative Model Updates: 49,286
Cumulative Timesteps: 411,081,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,068.14728
Policy Entropy: 3.73411
Value Function Loss: 0.05385

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.43858
Value Function Update Magnitude: 0.70633

Collected Steps per Second: 22,135.59348
Overall Steps per Second: 10,845.98910

Timestep Collection Time: 2.25935
Timestep Consumption Time: 2.35176
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61111

Cumulative Model Updates: 49,292
Cumulative Timesteps: 411,131,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 411131822...
Checkpoint 411131822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,983.67638
Policy Entropy: 3.70619
Value Function Loss: 0.05578

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.48034
Value Function Update Magnitude: 0.70308

Collected Steps per Second: 22,041.58325
Overall Steps per Second: 10,715.11172

Timestep Collection Time: 2.26944
Timestep Consumption Time: 2.39892
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.66836

Cumulative Model Updates: 49,298
Cumulative Timesteps: 411,181,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,039.28101
Policy Entropy: 3.72389
Value Function Loss: 0.05297

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.52774
Value Function Update Magnitude: 0.79870

Collected Steps per Second: 22,197.74249
Overall Steps per Second: 10,605.36832

Timestep Collection Time: 2.25329
Timestep Consumption Time: 2.46300
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.71629

Cumulative Model Updates: 49,304
Cumulative Timesteps: 411,231,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 411231862...
Checkpoint 411231862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,098.83896
Policy Entropy: 3.71216
Value Function Loss: 0.05124

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10821
Policy Update Magnitude: 0.48256
Value Function Update Magnitude: 0.79448

Collected Steps per Second: 22,726.08844
Overall Steps per Second: 10,846.93664

Timestep Collection Time: 2.20117
Timestep Consumption Time: 2.41064
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61181

Cumulative Model Updates: 49,310
Cumulative Timesteps: 411,281,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,538.22968
Policy Entropy: 3.70948
Value Function Loss: 0.05253

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.48065
Value Function Update Magnitude: 0.68349

Collected Steps per Second: 22,701.78254
Overall Steps per Second: 10,722.37162

Timestep Collection Time: 2.20397
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.66632

Cumulative Model Updates: 49,316
Cumulative Timesteps: 411,331,920

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 411331920...
Checkpoint 411331920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,324.53738
Policy Entropy: 3.70785
Value Function Loss: 0.05414

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.53598
Value Function Update Magnitude: 0.61818

Collected Steps per Second: 22,779.35460
Overall Steps per Second: 10,886.45677

Timestep Collection Time: 2.19506
Timestep Consumption Time: 2.39799
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.59305

Cumulative Model Updates: 49,322
Cumulative Timesteps: 411,381,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,164.73140
Policy Entropy: 3.69971
Value Function Loss: 0.05378

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.60329

Collected Steps per Second: 22,843.90705
Overall Steps per Second: 10,864.05649

Timestep Collection Time: 2.18973
Timestep Consumption Time: 2.41463
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.60436

Cumulative Model Updates: 49,328
Cumulative Timesteps: 411,431,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 411431944...
Checkpoint 411431944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,555.48097
Policy Entropy: 3.69799
Value Function Loss: 0.05442

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06022
Policy Update Magnitude: 0.61834
Value Function Update Magnitude: 0.59790

Collected Steps per Second: 22,575.95490
Overall Steps per Second: 10,703.51934

Timestep Collection Time: 2.21599
Timestep Consumption Time: 2.45799
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.67398

Cumulative Model Updates: 49,334
Cumulative Timesteps: 411,481,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,288.72658
Policy Entropy: 3.68094
Value Function Loss: 0.05461

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.60656
Value Function Update Magnitude: 0.58120

Collected Steps per Second: 22,789.40306
Overall Steps per Second: 10,810.41723

Timestep Collection Time: 2.19418
Timestep Consumption Time: 2.43136
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62554

Cumulative Model Updates: 49,340
Cumulative Timesteps: 411,531,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 411531976...
Checkpoint 411531976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,263.70617
Policy Entropy: 3.69189
Value Function Loss: 0.05372

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.52851
Value Function Update Magnitude: 0.59984

Collected Steps per Second: 22,610.45339
Overall Steps per Second: 10,781.29087

Timestep Collection Time: 2.21163
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.63822

Cumulative Model Updates: 49,346
Cumulative Timesteps: 411,581,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,474.04543
Policy Entropy: 3.69153
Value Function Loss: 0.05270

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.62102

Collected Steps per Second: 22,830.69903
Overall Steps per Second: 10,815.03078

Timestep Collection Time: 2.19082
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62486

Cumulative Model Updates: 49,352
Cumulative Timesteps: 411,632,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 411632000...
Checkpoint 411632000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,013.00956
Policy Entropy: 3.70561
Value Function Loss: 0.05444

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.50444
Value Function Update Magnitude: 0.61877

Collected Steps per Second: 22,471.20941
Overall Steps per Second: 10,670.64585

Timestep Collection Time: 2.22569
Timestep Consumption Time: 2.46137
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.68706

Cumulative Model Updates: 49,358
Cumulative Timesteps: 411,682,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,744.86378
Policy Entropy: 3.70735
Value Function Loss: 0.05547

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.49400
Value Function Update Magnitude: 0.63497

Collected Steps per Second: 22,610.65598
Overall Steps per Second: 10,608.09065

Timestep Collection Time: 2.21197
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.71470

Cumulative Model Updates: 49,364
Cumulative Timesteps: 411,732,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 411732028...
Checkpoint 411732028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,553.31930
Policy Entropy: 3.70476
Value Function Loss: 0.05460

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.49260
Value Function Update Magnitude: 0.65919

Collected Steps per Second: 22,815.41386
Overall Steps per Second: 10,700.25067

Timestep Collection Time: 2.19282
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.67559

Cumulative Model Updates: 49,370
Cumulative Timesteps: 411,782,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,297.43701
Policy Entropy: 3.70961
Value Function Loss: 0.05316

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.16195
Policy Update Magnitude: 0.43394
Value Function Update Magnitude: 0.68942

Collected Steps per Second: 23,049.32516
Overall Steps per Second: 10,707.29665

Timestep Collection Time: 2.16987
Timestep Consumption Time: 2.50115
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.67102

Cumulative Model Updates: 49,376
Cumulative Timesteps: 411,832,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 411832072...
Checkpoint 411832072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,171.10814
Policy Entropy: 3.70793
Value Function Loss: 0.05150

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.15717
Policy Update Magnitude: 0.43441
Value Function Update Magnitude: 0.69790

Collected Steps per Second: 22,799.34986
Overall Steps per Second: 10,619.98973

Timestep Collection Time: 2.19348
Timestep Consumption Time: 2.51556
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.70904

Cumulative Model Updates: 49,382
Cumulative Timesteps: 411,882,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,618.62444
Policy Entropy: 3.70964
Value Function Loss: 0.05007

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.44712
Value Function Update Magnitude: 0.71158

Collected Steps per Second: 22,301.53540
Overall Steps per Second: 10,506.36698

Timestep Collection Time: 2.24289
Timestep Consumption Time: 2.51803
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.76092

Cumulative Model Updates: 49,388
Cumulative Timesteps: 411,932,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 411932102...
Checkpoint 411932102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,909.11347
Policy Entropy: 3.70638
Value Function Loss: 0.04803

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.48837
Value Function Update Magnitude: 0.77212

Collected Steps per Second: 22,613.19021
Overall Steps per Second: 10,661.84376

Timestep Collection Time: 2.21110
Timestep Consumption Time: 2.47852
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.68962

Cumulative Model Updates: 49,394
Cumulative Timesteps: 411,982,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,363.95860
Policy Entropy: 3.71007
Value Function Loss: 0.04563

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.80583

Collected Steps per Second: 22,954.49826
Overall Steps per Second: 10,751.21999

Timestep Collection Time: 2.17822
Timestep Consumption Time: 2.47241
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.65063

Cumulative Model Updates: 49,400
Cumulative Timesteps: 412,032,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 412032102...
Checkpoint 412032102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,566.90038
Policy Entropy: 3.70468
Value Function Loss: 0.04677

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.61215
Value Function Update Magnitude: 0.82970

Collected Steps per Second: 22,354.61456
Overall Steps per Second: 10,707.67564

Timestep Collection Time: 2.23766
Timestep Consumption Time: 2.43394
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.67160

Cumulative Model Updates: 49,406
Cumulative Timesteps: 412,082,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,181.89744
Policy Entropy: 3.69206
Value Function Loss: 0.04781

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.58342
Value Function Update Magnitude: 0.81781

Collected Steps per Second: 22,769.37938
Overall Steps per Second: 10,802.03594

Timestep Collection Time: 2.19637
Timestep Consumption Time: 2.43331
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.62968

Cumulative Model Updates: 49,412
Cumulative Timesteps: 412,132,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 412132134...
Checkpoint 412132134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,059.72723
Policy Entropy: 3.69484
Value Function Loss: 0.04937

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.55351
Value Function Update Magnitude: 0.78845

Collected Steps per Second: 22,721.21065
Overall Steps per Second: 10,825.16005

Timestep Collection Time: 2.20147
Timestep Consumption Time: 2.41925
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.62072

Cumulative Model Updates: 49,418
Cumulative Timesteps: 412,182,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,003.57687
Policy Entropy: 3.71599
Value Function Loss: 0.04943

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.53976
Value Function Update Magnitude: 0.66266

Collected Steps per Second: 23,219.83759
Overall Steps per Second: 10,888.18403

Timestep Collection Time: 2.15445
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.59452

Cumulative Model Updates: 49,424
Cumulative Timesteps: 412,232,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 412232180...
Checkpoint 412232180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,557.12195
Policy Entropy: 3.73558
Value Function Loss: 0.05012

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.50073
Value Function Update Magnitude: 0.59256

Collected Steps per Second: 22,538.78630
Overall Steps per Second: 10,537.85397

Timestep Collection Time: 2.21946
Timestep Consumption Time: 2.52761
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.74708

Cumulative Model Updates: 49,430
Cumulative Timesteps: 412,282,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,390.04229
Policy Entropy: 3.73998
Value Function Loss: 0.04972

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.49923
Value Function Update Magnitude: 0.58833

Collected Steps per Second: 22,571.95754
Overall Steps per Second: 10,574.96034

Timestep Collection Time: 2.21576
Timestep Consumption Time: 2.51372
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.72947

Cumulative Model Updates: 49,436
Cumulative Timesteps: 412,332,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 412332218...
Checkpoint 412332218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,355.99982
Policy Entropy: 3.74453
Value Function Loss: 0.05026

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.50520
Value Function Update Magnitude: 0.59834

Collected Steps per Second: 22,722.35388
Overall Steps per Second: 10,632.04597

Timestep Collection Time: 2.20118
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.70427

Cumulative Model Updates: 49,442
Cumulative Timesteps: 412,382,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,005.28644
Policy Entropy: 3.75179
Value Function Loss: 0.04930

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.52944
Value Function Update Magnitude: 0.62597

Collected Steps per Second: 22,925.62330
Overall Steps per Second: 10,839.69249

Timestep Collection Time: 2.18123
Timestep Consumption Time: 2.43200
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.61323

Cumulative Model Updates: 49,448
Cumulative Timesteps: 412,432,240

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 412432240...
Checkpoint 412432240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,963.21594
Policy Entropy: 3.76122
Value Function Loss: 0.05060

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.57833
Value Function Update Magnitude: 0.60593

Collected Steps per Second: 22,489.00274
Overall Steps per Second: 10,633.76911

Timestep Collection Time: 2.22358
Timestep Consumption Time: 2.47899
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.70257

Cumulative Model Updates: 49,454
Cumulative Timesteps: 412,482,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,642.17788
Policy Entropy: 3.74773
Value Function Loss: 0.05634

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.61235
Value Function Update Magnitude: 0.52755

Collected Steps per Second: 22,758.36000
Overall Steps per Second: 10,664.64149

Timestep Collection Time: 2.19814
Timestep Consumption Time: 2.49269
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.69083

Cumulative Model Updates: 49,460
Cumulative Timesteps: 412,532,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 412532272...
Checkpoint 412532272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,340.88109
Policy Entropy: 3.74229
Value Function Loss: 0.06101

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06349
Policy Update Magnitude: 0.64284
Value Function Update Magnitude: 0.53325

Collected Steps per Second: 22,670.58843
Overall Steps per Second: 10,811.92465

Timestep Collection Time: 2.20612
Timestep Consumption Time: 2.41970
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.62582

Cumulative Model Updates: 49,466
Cumulative Timesteps: 412,582,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,952.83131
Policy Entropy: 3.72214
Value Function Loss: 0.06557

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06418
Policy Update Magnitude: 0.67027
Value Function Update Magnitude: 0.55408

Collected Steps per Second: 23,080.96286
Overall Steps per Second: 10,733.53898

Timestep Collection Time: 2.16672
Timestep Consumption Time: 2.49251
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.65923

Cumulative Model Updates: 49,472
Cumulative Timesteps: 412,632,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 412632296...
Checkpoint 412632296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.77952
Policy Entropy: 3.72266
Value Function Loss: 0.06255

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.59812
Value Function Update Magnitude: 0.49293

Collected Steps per Second: 22,932.23865
Overall Steps per Second: 10,829.51227

Timestep Collection Time: 2.18077
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.61794

Cumulative Model Updates: 49,478
Cumulative Timesteps: 412,682,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,504.83149
Policy Entropy: 3.72696
Value Function Loss: 0.05545

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.51092
Value Function Update Magnitude: 0.55464

Collected Steps per Second: 23,004.94544
Overall Steps per Second: 10,735.71436

Timestep Collection Time: 2.17388
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.65828

Cumulative Model Updates: 49,484
Cumulative Timesteps: 412,732,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 412732316...
Checkpoint 412732316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,504.89554
Policy Entropy: 3.73836
Value Function Loss: 0.05210

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.50177
Value Function Update Magnitude: 0.60703

Collected Steps per Second: 22,964.30876
Overall Steps per Second: 10,886.55861

Timestep Collection Time: 2.17781
Timestep Consumption Time: 2.41611
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.59392

Cumulative Model Updates: 49,490
Cumulative Timesteps: 412,782,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,724.50721
Policy Entropy: 3.73359
Value Function Loss: 0.05147

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06343
Policy Update Magnitude: 0.52457
Value Function Update Magnitude: 0.64758

Collected Steps per Second: 22,781.93153
Overall Steps per Second: 10,654.84170

Timestep Collection Time: 2.19490
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.69308

Cumulative Model Updates: 49,496
Cumulative Timesteps: 412,832,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 412832332...
Checkpoint 412832332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,485.40721
Policy Entropy: 3.70895
Value Function Loss: 0.05420

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.51404
Value Function Update Magnitude: 0.67280

Collected Steps per Second: 22,756.96029
Overall Steps per Second: 10,780.73666

Timestep Collection Time: 2.19827
Timestep Consumption Time: 2.44204
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.64031

Cumulative Model Updates: 49,502
Cumulative Timesteps: 412,882,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,001.46902
Policy Entropy: 3.71708
Value Function Loss: 0.05411

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09620
Policy Update Magnitude: 0.50341
Value Function Update Magnitude: 0.64900

Collected Steps per Second: 22,753.38215
Overall Steps per Second: 10,668.62429

Timestep Collection Time: 2.19818
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.68814

Cumulative Model Updates: 49,508
Cumulative Timesteps: 412,932,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 412932374...
Checkpoint 412932374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,861.11500
Policy Entropy: 3.71411
Value Function Loss: 0.05374

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.50503
Value Function Update Magnitude: 0.67202

Collected Steps per Second: 22,637.87443
Overall Steps per Second: 10,616.74921

Timestep Collection Time: 2.20975
Timestep Consumption Time: 2.50205
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.71180

Cumulative Model Updates: 49,514
Cumulative Timesteps: 412,982,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,716.71487
Policy Entropy: 3.74891
Value Function Loss: 0.05240

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 0.55823
Value Function Update Magnitude: 0.63938

Collected Steps per Second: 22,890.13376
Overall Steps per Second: 10,808.51480

Timestep Collection Time: 2.18575
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62894

Cumulative Model Updates: 49,520
Cumulative Timesteps: 413,032,430

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 413032430...
Checkpoint 413032430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,256.36463
Policy Entropy: 3.76581
Value Function Loss: 0.05128

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.64325
Value Function Update Magnitude: 0.70586

Collected Steps per Second: 22,501.15694
Overall Steps per Second: 10,652.07628

Timestep Collection Time: 2.22246
Timestep Consumption Time: 2.47221
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.69467

Cumulative Model Updates: 49,526
Cumulative Timesteps: 413,082,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,519.38076
Policy Entropy: 3.76944
Value Function Loss: 0.05044

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.66472
Value Function Update Magnitude: 0.70754

Collected Steps per Second: 22,638.42001
Overall Steps per Second: 10,693.29477

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.67788

Cumulative Model Updates: 49,532
Cumulative Timesteps: 413,132,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 413132460...
Checkpoint 413132460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,172.50544
Policy Entropy: 3.75874
Value Function Loss: 0.05352

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.57807
Value Function Update Magnitude: 0.59239

Collected Steps per Second: 22,787.48555
Overall Steps per Second: 10,861.57087

Timestep Collection Time: 2.19419
Timestep Consumption Time: 2.40920
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.60339

Cumulative Model Updates: 49,538
Cumulative Timesteps: 413,182,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,627.08997
Policy Entropy: 3.73954
Value Function Loss: 0.05257

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.52038
Value Function Update Magnitude: 0.57079

Collected Steps per Second: 22,633.55980
Overall Steps per Second: 10,771.79767

Timestep Collection Time: 2.20929
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.64212

Cumulative Model Updates: 49,544
Cumulative Timesteps: 413,232,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 413232464...
Checkpoint 413232464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,969.81367
Policy Entropy: 3.73780
Value Function Loss: 0.05313

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.48451
Value Function Update Magnitude: 0.59885

Collected Steps per Second: 22,679.55269
Overall Steps per Second: 10,708.13815

Timestep Collection Time: 2.20533
Timestep Consumption Time: 2.46551
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.67084

Cumulative Model Updates: 49,550
Cumulative Timesteps: 413,282,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,332.39780
Policy Entropy: 3.73068
Value Function Loss: 0.05393

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.52228
Value Function Update Magnitude: 0.62400

Collected Steps per Second: 21,983.12628
Overall Steps per Second: 10,676.47578

Timestep Collection Time: 2.27474
Timestep Consumption Time: 2.40901
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.68376

Cumulative Model Updates: 49,556
Cumulative Timesteps: 413,332,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 413332486...
Checkpoint 413332486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,703.88013
Policy Entropy: 3.72593
Value Function Loss: 0.05341

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.55808
Value Function Update Magnitude: 0.63053

Collected Steps per Second: 22,696.12813
Overall Steps per Second: 10,917.52932

Timestep Collection Time: 2.20372
Timestep Consumption Time: 2.37753
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.58126

Cumulative Model Updates: 49,562
Cumulative Timesteps: 413,382,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,804.52573
Policy Entropy: 3.72411
Value Function Loss: 0.05161

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.56520
Value Function Update Magnitude: 0.64389

Collected Steps per Second: 22,201.43208
Overall Steps per Second: 10,856.96300

Timestep Collection Time: 2.25310
Timestep Consumption Time: 2.35427
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60737

Cumulative Model Updates: 49,568
Cumulative Timesteps: 413,432,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 413432524...
Checkpoint 413432524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,106.07328
Policy Entropy: 3.71204
Value Function Loss: 0.05368

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.52834
Value Function Update Magnitude: 0.64869

Collected Steps per Second: 22,136.78887
Overall Steps per Second: 10,723.24064

Timestep Collection Time: 2.25904
Timestep Consumption Time: 2.40447
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.66352

Cumulative Model Updates: 49,574
Cumulative Timesteps: 413,482,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,740.93020
Policy Entropy: 3.70580
Value Function Loss: 0.05299

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.52848
Value Function Update Magnitude: 0.70895

Collected Steps per Second: 22,605.24985
Overall Steps per Second: 10,810.95964

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.41412
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.62697

Cumulative Model Updates: 49,580
Cumulative Timesteps: 413,532,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 413532554...
Checkpoint 413532554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,461.35029
Policy Entropy: 3.71977
Value Function Loss: 0.05460

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.49437
Value Function Update Magnitude: 0.79797

Collected Steps per Second: 22,687.26668
Overall Steps per Second: 10,683.49573

Timestep Collection Time: 2.20450
Timestep Consumption Time: 2.47693
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.68143

Cumulative Model Updates: 49,586
Cumulative Timesteps: 413,582,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,845.55305
Policy Entropy: 3.72289
Value Function Loss: 0.05301

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.50313
Value Function Update Magnitude: 0.77392

Collected Steps per Second: 23,319.28424
Overall Steps per Second: 10,928.14429

Timestep Collection Time: 2.14526
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.57772

Cumulative Model Updates: 49,592
Cumulative Timesteps: 413,632,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 413632594...
Checkpoint 413632594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,041.35942
Policy Entropy: 3.72137
Value Function Loss: 0.05450

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.48216
Value Function Update Magnitude: 0.71420

Collected Steps per Second: 22,626.30787
Overall Steps per Second: 10,612.08572

Timestep Collection Time: 2.21114
Timestep Consumption Time: 2.50329
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.71444

Cumulative Model Updates: 49,598
Cumulative Timesteps: 413,682,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,415.01401
Policy Entropy: 3.72487
Value Function Loss: 0.05231

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.56782
Value Function Update Magnitude: 0.75474

Collected Steps per Second: 22,869.96420
Overall Steps per Second: 10,842.54605

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.42567
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.61239

Cumulative Model Updates: 49,604
Cumulative Timesteps: 413,732,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 413732634...
Checkpoint 413732634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.82650
Policy Entropy: 3.71955
Value Function Loss: 0.05396

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.62065
Value Function Update Magnitude: 0.65782

Collected Steps per Second: 22,621.14258
Overall Steps per Second: 10,730.33953

Timestep Collection Time: 2.21103
Timestep Consumption Time: 2.45015
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.66118

Cumulative Model Updates: 49,610
Cumulative Timesteps: 413,782,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,143.43557
Policy Entropy: 3.71921
Value Function Loss: 0.05209

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.62446
Value Function Update Magnitude: 0.62503

Collected Steps per Second: 22,932.09488
Overall Steps per Second: 10,832.61632

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.43602
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.61698

Cumulative Model Updates: 49,616
Cumulative Timesteps: 413,832,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 413832664...
Checkpoint 413832664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,503.26565
Policy Entropy: 3.70539
Value Function Loss: 0.05683

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.54181
Value Function Update Magnitude: 0.65291

Collected Steps per Second: 22,687.41731
Overall Steps per Second: 10,703.07802

Timestep Collection Time: 2.20422
Timestep Consumption Time: 2.46808
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.67230

Cumulative Model Updates: 49,622
Cumulative Timesteps: 413,882,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,577.70831
Policy Entropy: 3.69606
Value Function Loss: 0.05738

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.48630
Value Function Update Magnitude: 0.68961

Collected Steps per Second: 22,728.94070
Overall Steps per Second: 10,674.99767

Timestep Collection Time: 2.20054
Timestep Consumption Time: 2.48480
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.68534

Cumulative Model Updates: 49,628
Cumulative Timesteps: 413,932,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 413932688...
Checkpoint 413932688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,614.36622
Policy Entropy: 3.68873
Value Function Loss: 0.05838

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.46063
Value Function Update Magnitude: 0.68867

Collected Steps per Second: 22,799.22836
Overall Steps per Second: 10,804.96025

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.43542
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.62936

Cumulative Model Updates: 49,634
Cumulative Timesteps: 413,982,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,546.94466
Policy Entropy: 3.69950
Value Function Loss: 0.05611

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.43581
Value Function Update Magnitude: 0.67939

Collected Steps per Second: 23,217.44793
Overall Steps per Second: 10,899.10844

Timestep Collection Time: 2.15355
Timestep Consumption Time: 2.43398
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.58753

Cumulative Model Updates: 49,640
Cumulative Timesteps: 414,032,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 414032708...
Checkpoint 414032708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,740.90668
Policy Entropy: 3.69697
Value Function Loss: 0.05720

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.41157
Value Function Update Magnitude: 0.67469

Collected Steps per Second: 22,627.36032
Overall Steps per Second: 10,679.24384

Timestep Collection Time: 2.21069
Timestep Consumption Time: 2.47335
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.68404

Cumulative Model Updates: 49,646
Cumulative Timesteps: 414,082,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,853.60397
Policy Entropy: 3.69983
Value Function Loss: 0.05696

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10252
Policy Update Magnitude: 0.43600
Value Function Update Magnitude: 0.66619

Collected Steps per Second: 22,784.75822
Overall Steps per Second: 10,684.73776

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.48532
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.67995

Cumulative Model Updates: 49,652
Cumulative Timesteps: 414,132,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 414132734...
Checkpoint 414132734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,127.75278
Policy Entropy: 3.69888
Value Function Loss: 0.05647

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.49902
Value Function Update Magnitude: 0.64726

Collected Steps per Second: 22,490.12551
Overall Steps per Second: 10,650.37974

Timestep Collection Time: 2.22444
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.69730

Cumulative Model Updates: 49,658
Cumulative Timesteps: 414,182,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,225.07288
Policy Entropy: 3.70771
Value Function Loss: 0.05658

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.47952
Value Function Update Magnitude: 0.67178

Collected Steps per Second: 23,006.76569
Overall Steps per Second: 10,702.32831

Timestep Collection Time: 2.17397
Timestep Consumption Time: 2.49941
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.67338

Cumulative Model Updates: 49,664
Cumulative Timesteps: 414,232,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 414232778...
Checkpoint 414232778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,937.88960
Policy Entropy: 3.72292
Value Function Loss: 0.05618

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.47002
Value Function Update Magnitude: 0.77952

Collected Steps per Second: 22,644.36108
Overall Steps per Second: 10,626.62436

Timestep Collection Time: 2.20912
Timestep Consumption Time: 2.49831
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.70742

Cumulative Model Updates: 49,670
Cumulative Timesteps: 414,282,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,754.39436
Policy Entropy: 3.72136
Value Function Loss: 0.05543

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.84393

Collected Steps per Second: 22,850.59010
Overall Steps per Second: 10,840.74570

Timestep Collection Time: 2.18848
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.61297

Cumulative Model Updates: 49,676
Cumulative Timesteps: 414,332,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 414332810...
Checkpoint 414332810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,058.13472
Policy Entropy: 3.72745
Value Function Loss: 0.05259

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.60970
Value Function Update Magnitude: 0.84640

Collected Steps per Second: 22,508.23284
Overall Steps per Second: 10,778.48793

Timestep Collection Time: 2.22141
Timestep Consumption Time: 2.41746
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.63887

Cumulative Model Updates: 49,682
Cumulative Timesteps: 414,382,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,563.65544
Policy Entropy: 3.72283
Value Function Loss: 0.05309

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11054
Policy Update Magnitude: 0.53355
Value Function Update Magnitude: 0.83959

Collected Steps per Second: 22,781.14395
Overall Steps per Second: 10,785.79813

Timestep Collection Time: 2.19585
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.63795

Cumulative Model Updates: 49,688
Cumulative Timesteps: 414,432,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 414432834...
Checkpoint 414432834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,762.63857
Policy Entropy: 3.73075
Value Function Loss: 0.05485

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.53162
Value Function Update Magnitude: 0.80049

Collected Steps per Second: 20,922.71902
Overall Steps per Second: 10,242.15953

Timestep Collection Time: 2.39032
Timestep Consumption Time: 2.49263
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.88295

Cumulative Model Updates: 49,694
Cumulative Timesteps: 414,482,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,752.24381
Policy Entropy: 3.72499
Value Function Loss: 0.05500

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.71179

Collected Steps per Second: 22,310.29282
Overall Steps per Second: 10,508.73893

Timestep Collection Time: 2.24201
Timestep Consumption Time: 2.51783
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.75985

Cumulative Model Updates: 49,700
Cumulative Timesteps: 414,532,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 414532866...
Checkpoint 414532866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,735.63528
Policy Entropy: 3.72725
Value Function Loss: 0.05524

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.49203
Value Function Update Magnitude: 0.79400

Collected Steps per Second: 22,570.41885
Overall Steps per Second: 10,647.65826

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.69793

Cumulative Model Updates: 49,706
Cumulative Timesteps: 414,582,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,385.58087
Policy Entropy: 3.72931
Value Function Loss: 0.05584

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.47386
Value Function Update Magnitude: 0.71515

Collected Steps per Second: 22,751.08805
Overall Steps per Second: 10,654.38741

Timestep Collection Time: 2.19893
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.69553

Cumulative Model Updates: 49,712
Cumulative Timesteps: 414,632,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 414632916...
Checkpoint 414632916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,578.22626
Policy Entropy: 3.71798
Value Function Loss: 0.05705

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.49096
Value Function Update Magnitude: 0.64469

Collected Steps per Second: 22,868.40327
Overall Steps per Second: 10,817.73720

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.62407

Cumulative Model Updates: 49,718
Cumulative Timesteps: 414,682,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,851.19663
Policy Entropy: 3.71397
Value Function Loss: 0.05728

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.46867
Value Function Update Magnitude: 0.61009

Collected Steps per Second: 23,143.84666
Overall Steps per Second: 10,891.62299

Timestep Collection Time: 2.16118
Timestep Consumption Time: 2.43116
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59234

Cumulative Model Updates: 49,724
Cumulative Timesteps: 414,732,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 414732956...
Checkpoint 414732956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,741.94199
Policy Entropy: 3.71068
Value Function Loss: 0.05747

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.50053
Value Function Update Magnitude: 0.62816

Collected Steps per Second: 21,949.34095
Overall Steps per Second: 10,732.61700

Timestep Collection Time: 2.27834
Timestep Consumption Time: 2.38110
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.65944

Cumulative Model Updates: 49,730
Cumulative Timesteps: 414,782,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,361.61636
Policy Entropy: 3.70859
Value Function Loss: 0.05672

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.60578

Collected Steps per Second: 22,125.25254
Overall Steps per Second: 10,798.13913

Timestep Collection Time: 2.26004
Timestep Consumption Time: 2.37076
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.63080

Cumulative Model Updates: 49,736
Cumulative Timesteps: 414,832,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 414832968...
Checkpoint 414832968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,340.71455
Policy Entropy: 3.71614
Value Function Loss: 0.05603

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.52547
Value Function Update Magnitude: 0.62952

Collected Steps per Second: 21,734.40216
Overall Steps per Second: 10,684.82703

Timestep Collection Time: 2.30068
Timestep Consumption Time: 2.37922
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.67991

Cumulative Model Updates: 49,742
Cumulative Timesteps: 414,882,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,955.69579
Policy Entropy: 3.72439
Value Function Loss: 0.05493

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.49599
Value Function Update Magnitude: 0.64716

Collected Steps per Second: 22,111.98168
Overall Steps per Second: 10,689.85044

Timestep Collection Time: 2.26140
Timestep Consumption Time: 2.41631
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.67771

Cumulative Model Updates: 49,748
Cumulative Timesteps: 414,932,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 414932976...
Checkpoint 414932976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.00921
Policy Entropy: 3.72812
Value Function Loss: 0.05530

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.53204
Value Function Update Magnitude: 0.67297

Collected Steps per Second: 22,128.82109
Overall Steps per Second: 10,857.08063

Timestep Collection Time: 2.25986
Timestep Consumption Time: 2.34617
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.60603

Cumulative Model Updates: 49,754
Cumulative Timesteps: 414,982,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,082.44496
Policy Entropy: 3.72790
Value Function Loss: 0.05499

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.55719
Value Function Update Magnitude: 0.68554

Collected Steps per Second: 22,239.67173
Overall Steps per Second: 10,534.98145

Timestep Collection Time: 2.24877
Timestep Consumption Time: 2.49846
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.74723

Cumulative Model Updates: 49,760
Cumulative Timesteps: 415,032,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 415032996...
Checkpoint 415032996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,834.15073
Policy Entropy: 3.74222
Value Function Loss: 0.05401

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.51043
Value Function Update Magnitude: 0.70985

Collected Steps per Second: 22,637.90047
Overall Steps per Second: 10,675.25546

Timestep Collection Time: 2.21001
Timestep Consumption Time: 2.47653
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.68654

Cumulative Model Updates: 49,766
Cumulative Timesteps: 415,083,026

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,194.77170
Policy Entropy: 3.74214
Value Function Loss: 0.05453

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.52900
Value Function Update Magnitude: 0.65703

Collected Steps per Second: 22,635.48758
Overall Steps per Second: 10,763.15611

Timestep Collection Time: 2.20919
Timestep Consumption Time: 2.43685
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.64603

Cumulative Model Updates: 49,772
Cumulative Timesteps: 415,133,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 415133032...
Checkpoint 415133032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,768.24886
Policy Entropy: 3.73806
Value Function Loss: 0.05243

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.71655

Collected Steps per Second: 22,684.17761
Overall Steps per Second: 10,723.94247

Timestep Collection Time: 2.20427
Timestep Consumption Time: 2.45838
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.66265

Cumulative Model Updates: 49,778
Cumulative Timesteps: 415,183,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,204.64290
Policy Entropy: 3.72254
Value Function Loss: 0.05205

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.54216
Value Function Update Magnitude: 0.78587

Collected Steps per Second: 22,909.66696
Overall Steps per Second: 10,821.95674

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.62135

Cumulative Model Updates: 49,784
Cumulative Timesteps: 415,233,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 415233046...
Checkpoint 415233046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,747.29642
Policy Entropy: 3.71242
Value Function Loss: 0.05435

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11390
Policy Update Magnitude: 0.48878
Value Function Update Magnitude: 0.76454

Collected Steps per Second: 22,553.01155
Overall Steps per Second: 10,748.47501

Timestep Collection Time: 2.21797
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.65387

Cumulative Model Updates: 49,790
Cumulative Timesteps: 415,283,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,439.29246
Policy Entropy: 3.73215
Value Function Loss: 0.05516

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.43044
Value Function Update Magnitude: 0.69330

Collected Steps per Second: 22,770.85827
Overall Steps per Second: 10,842.48177

Timestep Collection Time: 2.19719
Timestep Consumption Time: 2.41725
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61444

Cumulative Model Updates: 49,796
Cumulative Timesteps: 415,333,100

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 415333100...
Checkpoint 415333100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,113.40702
Policy Entropy: 3.72926
Value Function Loss: 0.05569

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.47799
Value Function Update Magnitude: 0.70035

Collected Steps per Second: 22,750.58222
Overall Steps per Second: 10,694.30470

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.47913
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.67819

Cumulative Model Updates: 49,802
Cumulative Timesteps: 415,383,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,578.05309
Policy Entropy: 3.73018
Value Function Loss: 0.05512

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.51196
Value Function Update Magnitude: 0.78681

Collected Steps per Second: 23,094.54744
Overall Steps per Second: 10,855.48187

Timestep Collection Time: 2.16545
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.60689

Cumulative Model Updates: 49,808
Cumulative Timesteps: 415,433,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 415433140...
Checkpoint 415433140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,366.12045
Policy Entropy: 3.72116
Value Function Loss: 0.05448

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.54421
Value Function Update Magnitude: 0.81333

Collected Steps per Second: 22,592.49616
Overall Steps per Second: 10,686.99058

Timestep Collection Time: 2.21419
Timestep Consumption Time: 2.46664
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.68083

Cumulative Model Updates: 49,814
Cumulative Timesteps: 415,483,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,960.17790
Policy Entropy: 3.71876
Value Function Loss: 0.05668

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.50979
Value Function Update Magnitude: 0.73448

Collected Steps per Second: 22,809.25096
Overall Steps per Second: 10,815.18822

Timestep Collection Time: 2.19332
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62572

Cumulative Model Updates: 49,820
Cumulative Timesteps: 415,533,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 415533192...
Checkpoint 415533192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,115.27945
Policy Entropy: 3.72010
Value Function Loss: 0.05405

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.46760
Value Function Update Magnitude: 0.73733

Collected Steps per Second: 22,111.85555
Overall Steps per Second: 10,654.23488

Timestep Collection Time: 2.26141
Timestep Consumption Time: 2.43193
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.69335

Cumulative Model Updates: 49,826
Cumulative Timesteps: 415,583,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,248.34986
Policy Entropy: 3.71479
Value Function Loss: 0.05181

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.49139
Value Function Update Magnitude: 0.77805

Collected Steps per Second: 22,730.27197
Overall Steps per Second: 10,621.95969

Timestep Collection Time: 2.19980
Timestep Consumption Time: 2.50762
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.70742

Cumulative Model Updates: 49,832
Cumulative Timesteps: 415,633,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 415633198...
Checkpoint 415633198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,044.83081
Policy Entropy: 3.71501
Value Function Loss: 0.04812

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.51119
Value Function Update Magnitude: 0.79780

Collected Steps per Second: 22,730.25611
Overall Steps per Second: 10,674.97098

Timestep Collection Time: 2.20006
Timestep Consumption Time: 2.48454
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.68460

Cumulative Model Updates: 49,838
Cumulative Timesteps: 415,683,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,113.12667
Policy Entropy: 3.69833
Value Function Loss: 0.05078

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.48510
Value Function Update Magnitude: 0.76738

Collected Steps per Second: 23,107.86461
Overall Steps per Second: 10,786.52902

Timestep Collection Time: 2.16515
Timestep Consumption Time: 2.47323
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.63838

Cumulative Model Updates: 49,844
Cumulative Timesteps: 415,733,238

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 415733238...
Checkpoint 415733238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,315.35125
Policy Entropy: 3.70124
Value Function Loss: 0.05127

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.44109
Value Function Update Magnitude: 0.80215

Collected Steps per Second: 22,609.26182
Overall Steps per Second: 10,628.18088

Timestep Collection Time: 2.21166
Timestep Consumption Time: 2.49319
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.70485

Cumulative Model Updates: 49,850
Cumulative Timesteps: 415,783,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,195.12131
Policy Entropy: 3.70119
Value Function Loss: 0.05251

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.50259
Value Function Update Magnitude: 0.80272

Collected Steps per Second: 22,950.29655
Overall Steps per Second: 10,861.38652

Timestep Collection Time: 2.17923
Timestep Consumption Time: 2.42552
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.60475

Cumulative Model Updates: 49,856
Cumulative Timesteps: 415,833,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 415833256...
Checkpoint 415833256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,387.27000
Policy Entropy: 3.70468
Value Function Loss: 0.05220

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06513
Policy Update Magnitude: 0.58996
Value Function Update Magnitude: 0.82694

Collected Steps per Second: 21,939.03859
Overall Steps per Second: 10,670.94944

Timestep Collection Time: 2.27913
Timestep Consumption Time: 2.40667
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.68581

Cumulative Model Updates: 49,862
Cumulative Timesteps: 415,883,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,055.25515
Policy Entropy: 3.69936
Value Function Loss: 0.05286

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.60051
Value Function Update Magnitude: 0.82736

Collected Steps per Second: 22,225.38322
Overall Steps per Second: 10,875.19363

Timestep Collection Time: 2.25175
Timestep Consumption Time: 2.35010
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.60185

Cumulative Model Updates: 49,868
Cumulative Timesteps: 415,933,304

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 415933304...
Checkpoint 415933304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,620.70259
Policy Entropy: 3.69722
Value Function Loss: 0.05412

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.48281
Value Function Update Magnitude: 0.83245

Collected Steps per Second: 21,978.68043
Overall Steps per Second: 10,694.42955

Timestep Collection Time: 2.27639
Timestep Consumption Time: 2.40194
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.67832

Cumulative Model Updates: 49,874
Cumulative Timesteps: 415,983,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,233.98392
Policy Entropy: 3.69767
Value Function Loss: 0.05417

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.14434
Policy Update Magnitude: 0.41953
Value Function Update Magnitude: 0.75716

Collected Steps per Second: 22,132.18126
Overall Steps per Second: 10,795.57196

Timestep Collection Time: 2.25979
Timestep Consumption Time: 2.37304
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.63283

Cumulative Model Updates: 49,880
Cumulative Timesteps: 416,033,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 416033350...
Checkpoint 416033350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,713.17027
Policy Entropy: 3.70604
Value Function Loss: 0.05349

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.38841
Value Function Update Magnitude: 0.71533

Collected Steps per Second: 21,859.58913
Overall Steps per Second: 10,671.27438

Timestep Collection Time: 2.28733
Timestep Consumption Time: 2.39815
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.68548

Cumulative Model Updates: 49,886
Cumulative Timesteps: 416,083,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.12683
Policy Entropy: 3.70209
Value Function Loss: 0.05346

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.45757
Value Function Update Magnitude: 0.69332

Collected Steps per Second: 22,140.28411
Overall Steps per Second: 10,503.29639

Timestep Collection Time: 2.25959
Timestep Consumption Time: 2.50348
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.76308

Cumulative Model Updates: 49,892
Cumulative Timesteps: 416,133,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 416133378...
Checkpoint 416133378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,779.62149
Policy Entropy: 3.70530
Value Function Loss: 0.05469

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.57282
Value Function Update Magnitude: 0.68796

Collected Steps per Second: 22,474.11650
Overall Steps per Second: 10,670.56981

Timestep Collection Time: 2.22540
Timestep Consumption Time: 2.46169
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68710

Cumulative Model Updates: 49,898
Cumulative Timesteps: 416,183,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,010.53007
Policy Entropy: 3.70295
Value Function Loss: 0.05773

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.58116
Value Function Update Magnitude: 0.65802

Collected Steps per Second: 23,099.94054
Overall Steps per Second: 10,919.85860

Timestep Collection Time: 2.16555
Timestep Consumption Time: 2.41547
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.58101

Cumulative Model Updates: 49,904
Cumulative Timesteps: 416,233,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 416233416...
Checkpoint 416233416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,300.59756
Policy Entropy: 3.71500
Value Function Loss: 0.05666

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.48995
Value Function Update Magnitude: 0.68701

Collected Steps per Second: 22,775.52851
Overall Steps per Second: 10,734.99570

Timestep Collection Time: 2.19639
Timestep Consumption Time: 2.46351
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.65990

Cumulative Model Updates: 49,910
Cumulative Timesteps: 416,283,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,963.70691
Policy Entropy: 3.71604
Value Function Loss: 0.05507

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.50595
Value Function Update Magnitude: 0.74190

Collected Steps per Second: 22,856.22547
Overall Steps per Second: 10,806.97451

Timestep Collection Time: 2.18759
Timestep Consumption Time: 2.43905
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.62664

Cumulative Model Updates: 49,916
Cumulative Timesteps: 416,333,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 416333440...
Checkpoint 416333440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,615.40973
Policy Entropy: 3.72339
Value Function Loss: 0.05260

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.73080

Collected Steps per Second: 22,823.48012
Overall Steps per Second: 10,655.19570

Timestep Collection Time: 2.19169
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.69461

Cumulative Model Updates: 49,922
Cumulative Timesteps: 416,383,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,949.97314
Policy Entropy: 3.72236
Value Function Loss: 0.05238

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.53953
Value Function Update Magnitude: 0.73063

Collected Steps per Second: 22,593.22223
Overall Steps per Second: 10,633.28640

Timestep Collection Time: 2.21314
Timestep Consumption Time: 2.48926
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.70240

Cumulative Model Updates: 49,928
Cumulative Timesteps: 416,433,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 416433464...
Checkpoint 416433464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,582.47656
Policy Entropy: 3.72714
Value Function Loss: 0.05170

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08455
Policy Update Magnitude: 0.49967
Value Function Update Magnitude: 0.79304

Collected Steps per Second: 22,797.60273
Overall Steps per Second: 10,804.71544

Timestep Collection Time: 2.19427
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.62983

Cumulative Model Updates: 49,934
Cumulative Timesteps: 416,483,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,161.45029
Policy Entropy: 3.72220
Value Function Loss: 0.05193

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.50546
Value Function Update Magnitude: 0.86488

Collected Steps per Second: 22,956.35352
Overall Steps per Second: 10,715.62540

Timestep Collection Time: 2.17979
Timestep Consumption Time: 2.49003
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.66982

Cumulative Model Updates: 49,940
Cumulative Timesteps: 416,533,528

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 416533528...
Checkpoint 416533528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,691.14024
Policy Entropy: 3.72379
Value Function Loss: 0.05181

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07964
Policy Update Magnitude: 0.56379
Value Function Update Magnitude: 0.90598

Collected Steps per Second: 22,710.73957
Overall Steps per Second: 10,694.99466

Timestep Collection Time: 2.20301
Timestep Consumption Time: 2.47507
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.67808

Cumulative Model Updates: 49,946
Cumulative Timesteps: 416,583,560

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,898.84973
Policy Entropy: 3.72622
Value Function Loss: 0.05220

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.90280

Collected Steps per Second: 23,271.27149
Overall Steps per Second: 10,740.91642

Timestep Collection Time: 2.14917
Timestep Consumption Time: 2.50723
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.65640

Cumulative Model Updates: 49,952
Cumulative Timesteps: 416,633,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 416633574...
Checkpoint 416633574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,616.38180
Policy Entropy: 3.73040
Value Function Loss: 0.05189

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.48054
Value Function Update Magnitude: 0.91886

Collected Steps per Second: 22,800.14939
Overall Steps per Second: 10,766.82730

Timestep Collection Time: 2.19349
Timestep Consumption Time: 2.45151
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.64501

Cumulative Model Updates: 49,958
Cumulative Timesteps: 416,683,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,074.86175
Policy Entropy: 3.73793
Value Function Loss: 0.05184

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.47116
Value Function Update Magnitude: 0.93714

Collected Steps per Second: 23,000.87546
Overall Steps per Second: 10,705.48481

Timestep Collection Time: 2.17383
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.67050

Cumulative Model Updates: 49,964
Cumulative Timesteps: 416,733,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 416733586...
Checkpoint 416733586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,333.31246
Policy Entropy: 3.71988
Value Function Loss: 0.05359

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.45039
Value Function Update Magnitude: 0.93925

Collected Steps per Second: 22,816.52487
Overall Steps per Second: 10,634.91986

Timestep Collection Time: 2.19157
Timestep Consumption Time: 2.51030
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.70187

Cumulative Model Updates: 49,970
Cumulative Timesteps: 416,783,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,513.97409
Policy Entropy: 3.71644
Value Function Loss: 0.05335

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.48192
Value Function Update Magnitude: 0.93112

Collected Steps per Second: 23,080.33454
Overall Steps per Second: 10,862.35757

Timestep Collection Time: 2.16713
Timestep Consumption Time: 2.43758
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60471

Cumulative Model Updates: 49,976
Cumulative Timesteps: 416,833,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 416833608...
Checkpoint 416833608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,084.01389
Policy Entropy: 3.71594
Value Function Loss: 0.05409

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.45467
Value Function Update Magnitude: 0.84978

Collected Steps per Second: 22,330.70831
Overall Steps per Second: 10,691.26450

Timestep Collection Time: 2.24014
Timestep Consumption Time: 2.43882
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.67896

Cumulative Model Updates: 49,982
Cumulative Timesteps: 416,883,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,123.72652
Policy Entropy: 3.71415
Value Function Loss: 0.05294

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.46051
Value Function Update Magnitude: 0.77425

Collected Steps per Second: 22,966.57696
Overall Steps per Second: 10,890.88668

Timestep Collection Time: 2.17769
Timestep Consumption Time: 2.41459
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.59228

Cumulative Model Updates: 49,988
Cumulative Timesteps: 416,933,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 416933646...
Checkpoint 416933646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,389.04240
Policy Entropy: 3.73009
Value Function Loss: 0.05308

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.48327
Value Function Update Magnitude: 0.73187

Collected Steps per Second: 22,673.27618
Overall Steps per Second: 10,649.61298

Timestep Collection Time: 2.20603
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.69670

Cumulative Model Updates: 49,994
Cumulative Timesteps: 416,983,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,397.06229
Policy Entropy: 3.72860
Value Function Loss: 0.05343

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09093
Policy Update Magnitude: 0.48468
Value Function Update Magnitude: 0.71836

Collected Steps per Second: 22,863.27923
Overall Steps per Second: 10,805.83238

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.44100
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.62861

Cumulative Model Updates: 50,000
Cumulative Timesteps: 417,033,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 417033680...
Checkpoint 417033680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,871.40348
Policy Entropy: 3.73816
Value Function Loss: 0.05229

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.48712
Value Function Update Magnitude: 0.80673

Collected Steps per Second: 22,387.04197
Overall Steps per Second: 10,713.18391

Timestep Collection Time: 2.23352
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.66733

Cumulative Model Updates: 50,006
Cumulative Timesteps: 417,083,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,011.60240
Policy Entropy: 3.73656
Value Function Loss: 0.05324

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.49644
Value Function Update Magnitude: 0.79895

Collected Steps per Second: 22,821.76832
Overall Steps per Second: 10,696.23035

Timestep Collection Time: 2.19212
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.67716

Cumulative Model Updates: 50,012
Cumulative Timesteps: 417,133,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 417133710...
Checkpoint 417133710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,067.02859
Policy Entropy: 3.73510
Value Function Loss: 0.05188

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.53492
Value Function Update Magnitude: 0.73292

Collected Steps per Second: 22,804.89645
Overall Steps per Second: 10,835.67593

Timestep Collection Time: 2.19251
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.61439

Cumulative Model Updates: 50,018
Cumulative Timesteps: 417,183,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,648.64438
Policy Entropy: 3.73812
Value Function Loss: 0.05198

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.57891
Value Function Update Magnitude: 0.81508

Collected Steps per Second: 22,600.04149
Overall Steps per Second: 10,619.33745

Timestep Collection Time: 2.21469
Timestep Consumption Time: 2.49860
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.71329

Cumulative Model Updates: 50,024
Cumulative Timesteps: 417,233,762

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 417233762...
Checkpoint 417233762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,091.45466
Policy Entropy: 3.73807
Value Function Loss: 0.05239

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.58653
Value Function Update Magnitude: 0.76365

Collected Steps per Second: 22,905.92226
Overall Steps per Second: 10,725.85784

Timestep Collection Time: 2.18284
Timestep Consumption Time: 2.47879
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.66163

Cumulative Model Updates: 50,030
Cumulative Timesteps: 417,283,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,389.69270
Policy Entropy: 3.72838
Value Function Loss: 0.05773

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06000
Policy Update Magnitude: 0.65771
Value Function Update Magnitude: 0.68995

Collected Steps per Second: 23,117.88220
Overall Steps per Second: 10,733.35376

Timestep Collection Time: 2.16300
Timestep Consumption Time: 2.49575
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.65875

Cumulative Model Updates: 50,036
Cumulative Timesteps: 417,333,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 417333766...
Checkpoint 417333766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,984.67930
Policy Entropy: 3.72911
Value Function Loss: 0.05972

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.67131
Value Function Update Magnitude: 0.77463

Collected Steps per Second: 22,880.60430
Overall Steps per Second: 10,640.69423

Timestep Collection Time: 2.18552
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.69951

Cumulative Model Updates: 50,042
Cumulative Timesteps: 417,383,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,678.15442
Policy Entropy: 3.72889
Value Function Loss: 0.05980

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.65244
Value Function Update Magnitude: 0.79212

Collected Steps per Second: 23,044.61981
Overall Steps per Second: 10,886.06391

Timestep Collection Time: 2.16996
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.59358

Cumulative Model Updates: 50,048
Cumulative Timesteps: 417,433,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 417433778...
Checkpoint 417433778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,717.82317
Policy Entropy: 3.74310
Value Function Loss: 0.05927

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.64438
Value Function Update Magnitude: 0.74132

Collected Steps per Second: 22,107.51960
Overall Steps per Second: 10,635.57760

Timestep Collection Time: 2.26276
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.70346

Cumulative Model Updates: 50,054
Cumulative Timesteps: 417,483,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,822.85373
Policy Entropy: 3.73458
Value Function Loss: 0.05576

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.62887
Value Function Update Magnitude: 0.73752

Collected Steps per Second: 22,245.39816
Overall Steps per Second: 10,854.30236

Timestep Collection Time: 2.24793
Timestep Consumption Time: 2.35910
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.60702

Cumulative Model Updates: 50,060
Cumulative Timesteps: 417,533,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 417533808...
Checkpoint 417533808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,976.75874
Policy Entropy: 3.71319
Value Function Loss: 0.05629

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.58874
Value Function Update Magnitude: 0.77028

Collected Steps per Second: 22,110.81277
Overall Steps per Second: 10,676.79488

Timestep Collection Time: 2.26278
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.68605

Cumulative Model Updates: 50,066
Cumulative Timesteps: 417,583,840

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,888.89816
Policy Entropy: 3.69706
Value Function Loss: 0.05539

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.51755
Value Function Update Magnitude: 0.81892

Collected Steps per Second: 22,316.05190
Overall Steps per Second: 10,869.86769

Timestep Collection Time: 2.24224
Timestep Consumption Time: 2.36113
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.60337

Cumulative Model Updates: 50,072
Cumulative Timesteps: 417,633,878

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 417633878...
Checkpoint 417633878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,509.53612
Policy Entropy: 3.70151
Value Function Loss: 0.05448

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.48784
Value Function Update Magnitude: 0.83332

Collected Steps per Second: 22,123.99656
Overall Steps per Second: 10,725.68163

Timestep Collection Time: 2.26080
Timestep Consumption Time: 2.40258
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.66339

Cumulative Model Updates: 50,078
Cumulative Timesteps: 417,683,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,735.70515
Policy Entropy: 3.70105
Value Function Loss: 0.05546

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.50886
Value Function Update Magnitude: 0.82671

Collected Steps per Second: 22,646.34865
Overall Steps per Second: 10,819.73584

Timestep Collection Time: 2.20821
Timestep Consumption Time: 2.41371
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.62192

Cumulative Model Updates: 50,084
Cumulative Timesteps: 417,733,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 417733904...
Checkpoint 417733904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.06074
Policy Entropy: 3.71171
Value Function Loss: 0.05666

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.52892
Value Function Update Magnitude: 0.75482

Collected Steps per Second: 22,892.85999
Overall Steps per Second: 10,726.56086

Timestep Collection Time: 2.18479
Timestep Consumption Time: 2.47803
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.66282

Cumulative Model Updates: 50,090
Cumulative Timesteps: 417,783,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,446.46483
Policy Entropy: 3.70283
Value Function Loss: 0.05722

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.53023
Value Function Update Magnitude: 0.75638

Collected Steps per Second: 22,840.43162
Overall Steps per Second: 10,904.46398

Timestep Collection Time: 2.18980
Timestep Consumption Time: 2.39694
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.58675

Cumulative Model Updates: 50,096
Cumulative Timesteps: 417,833,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 417833936...
Checkpoint 417833936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,385.13535
Policy Entropy: 3.70870
Value Function Loss: 0.05603

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.50054
Value Function Update Magnitude: 0.76322

Collected Steps per Second: 22,440.93663
Overall Steps per Second: 10,585.57636

Timestep Collection Time: 2.22887
Timestep Consumption Time: 2.49624
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.72511

Cumulative Model Updates: 50,102
Cumulative Timesteps: 417,883,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,363.49219
Policy Entropy: 3.70082
Value Function Loss: 0.05652

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.44797
Value Function Update Magnitude: 0.74214

Collected Steps per Second: 22,893.19427
Overall Steps per Second: 10,829.72009

Timestep Collection Time: 2.18406
Timestep Consumption Time: 2.43287
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.61692

Cumulative Model Updates: 50,108
Cumulative Timesteps: 417,933,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 417933954...
Checkpoint 417933954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,300.03364
Policy Entropy: 3.70904
Value Function Loss: 0.05496

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.44297
Value Function Update Magnitude: 0.81644

Collected Steps per Second: 22,538.63683
Overall Steps per Second: 10,789.77172

Timestep Collection Time: 2.21895
Timestep Consumption Time: 2.41619
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.63513

Cumulative Model Updates: 50,114
Cumulative Timesteps: 417,983,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,161.57361
Policy Entropy: 3.71121
Value Function Loss: 0.05496

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.46023
Value Function Update Magnitude: 0.79275

Collected Steps per Second: 22,657.21341
Overall Steps per Second: 10,741.13302

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.44859
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.65575

Cumulative Model Updates: 50,120
Cumulative Timesteps: 418,033,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 418033974...
Checkpoint 418033974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,102.07389
Policy Entropy: 3.72930
Value Function Loss: 0.05580

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.45617
Value Function Update Magnitude: 0.81438

Collected Steps per Second: 22,477.32134
Overall Steps per Second: 10,743.97113

Timestep Collection Time: 2.22509
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.65508

Cumulative Model Updates: 50,126
Cumulative Timesteps: 418,083,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,015.37223
Policy Entropy: 3.72286
Value Function Loss: 0.05410

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06521
Policy Update Magnitude: 0.59813
Value Function Update Magnitude: 0.82674

Collected Steps per Second: 22,894.39040
Overall Steps per Second: 10,846.49538

Timestep Collection Time: 2.18516
Timestep Consumption Time: 2.42720
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.61237

Cumulative Model Updates: 50,132
Cumulative Timesteps: 418,134,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 418134016...
Checkpoint 418134016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,701.03288
Policy Entropy: 3.72386
Value Function Loss: 0.05448

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06820
Policy Update Magnitude: 0.67732
Value Function Update Magnitude: 0.85509

Collected Steps per Second: 22,719.05383
Overall Steps per Second: 10,712.07521

Timestep Collection Time: 2.20141
Timestep Consumption Time: 2.46752
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.66894

Cumulative Model Updates: 50,138
Cumulative Timesteps: 418,184,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,706.18225
Policy Entropy: 3.72428
Value Function Loss: 0.05048

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.59911
Value Function Update Magnitude: 0.87879

Collected Steps per Second: 23,000.94554
Overall Steps per Second: 10,836.19734

Timestep Collection Time: 2.17452
Timestep Consumption Time: 2.44112
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.61564

Cumulative Model Updates: 50,144
Cumulative Timesteps: 418,234,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 418234046...
Checkpoint 418234046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,953.92347
Policy Entropy: 3.72634
Value Function Loss: 0.05103

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.51913
Value Function Update Magnitude: 0.88470

Collected Steps per Second: 22,217.37760
Overall Steps per Second: 10,660.17754

Timestep Collection Time: 2.25175
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.69298

Cumulative Model Updates: 50,150
Cumulative Timesteps: 418,284,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,319.65646
Policy Entropy: 3.72768
Value Function Loss: 0.04902

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 0.51496
Value Function Update Magnitude: 0.88592

Collected Steps per Second: 22,600.27743
Overall Steps per Second: 10,614.17774

Timestep Collection Time: 2.21272
Timestep Consumption Time: 2.49872
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.71143

Cumulative Model Updates: 50,156
Cumulative Timesteps: 418,334,082

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 418334082...
Checkpoint 418334082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,109.73413
Policy Entropy: 3.72834
Value Function Loss: 0.04892

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.16987
Policy Update Magnitude: 0.47198
Value Function Update Magnitude: 0.86800

Collected Steps per Second: 22,711.07174
Overall Steps per Second: 10,694.86989

Timestep Collection Time: 2.20175
Timestep Consumption Time: 2.47377
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.67551

Cumulative Model Updates: 50,162
Cumulative Timesteps: 418,384,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,303.65211
Policy Entropy: 3.74695
Value Function Loss: 0.04827

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.42017
Value Function Update Magnitude: 0.86350

Collected Steps per Second: 22,863.43236
Overall Steps per Second: 10,707.84026

Timestep Collection Time: 2.18777
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.67134

Cumulative Model Updates: 50,168
Cumulative Timesteps: 418,434,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 418434106...
Checkpoint 418434106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,360.39415
Policy Entropy: 3.76000
Value Function Loss: 0.04941

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.54601
Value Function Update Magnitude: 0.89448

Collected Steps per Second: 22,644.39937
Overall Steps per Second: 10,628.37504

Timestep Collection Time: 2.20805
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.70439

Cumulative Model Updates: 50,174
Cumulative Timesteps: 418,484,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,208.75723
Policy Entropy: 3.76620
Value Function Loss: 0.05363

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.62798
Value Function Update Magnitude: 0.85853

Collected Steps per Second: 22,925.89579
Overall Steps per Second: 10,841.74165

Timestep Collection Time: 2.18172
Timestep Consumption Time: 2.43174
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.61347

Cumulative Model Updates: 50,180
Cumulative Timesteps: 418,534,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 418534124...
Checkpoint 418534124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,881.77855
Policy Entropy: 3.76292
Value Function Loss: 0.05613

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.71754

Collected Steps per Second: 22,724.24092
Overall Steps per Second: 10,719.36535

Timestep Collection Time: 2.20091
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.66576

Cumulative Model Updates: 50,186
Cumulative Timesteps: 418,584,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,503.04718
Policy Entropy: 3.74997
Value Function Loss: 0.05614

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.49874
Value Function Update Magnitude: 0.73811

Collected Steps per Second: 22,880.85595
Overall Steps per Second: 10,828.62260

Timestep Collection Time: 2.18584
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.61869

Cumulative Model Updates: 50,192
Cumulative Timesteps: 418,634,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 418634152...
Checkpoint 418634152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,620.23876
Policy Entropy: 3.75217
Value Function Loss: 0.05055

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.51059
Value Function Update Magnitude: 0.84151

Collected Steps per Second: 22,295.37724
Overall Steps per Second: 10,698.31269

Timestep Collection Time: 2.24342
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.67532

Cumulative Model Updates: 50,198
Cumulative Timesteps: 418,684,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.40532
Policy Entropy: 3.75505
Value Function Loss: 0.04930

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.57113
Value Function Update Magnitude: 0.90210

Collected Steps per Second: 22,652.65343
Overall Steps per Second: 10,666.55773

Timestep Collection Time: 2.20848
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.69017

Cumulative Model Updates: 50,204
Cumulative Timesteps: 418,734,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 418734198...
Checkpoint 418734198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,898.19341
Policy Entropy: 3.76596
Value Function Loss: 0.04811

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.55645
Value Function Update Magnitude: 0.94646

Collected Steps per Second: 22,422.78205
Overall Steps per Second: 10,614.79956

Timestep Collection Time: 2.23077
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.71229

Cumulative Model Updates: 50,210
Cumulative Timesteps: 418,784,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157.99947
Policy Entropy: 3.76625
Value Function Loss: 0.04719

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.53777
Value Function Update Magnitude: 0.95927

Collected Steps per Second: 22,940.06548
Overall Steps per Second: 10,752.80217

Timestep Collection Time: 2.17977
Timestep Consumption Time: 2.47056
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.65032

Cumulative Model Updates: 50,216
Cumulative Timesteps: 418,834,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 418834222...
Checkpoint 418834222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,141.61988
Policy Entropy: 3.77277
Value Function Loss: 0.04691

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.55225
Value Function Update Magnitude: 0.95165

Collected Steps per Second: 22,632.27999
Overall Steps per Second: 10,634.15535

Timestep Collection Time: 2.20950
Timestep Consumption Time: 2.49290
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.70240

Cumulative Model Updates: 50,222
Cumulative Timesteps: 418,884,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,918.95308
Policy Entropy: 3.76322
Value Function Loss: 0.04991

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.59230
Value Function Update Magnitude: 0.93811

Collected Steps per Second: 22,879.23526
Overall Steps per Second: 10,845.13598

Timestep Collection Time: 2.18635
Timestep Consumption Time: 2.42604
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61239

Cumulative Model Updates: 50,228
Cumulative Timesteps: 418,934,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 418934250...
Checkpoint 418934250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,158.16912
Policy Entropy: 3.75537
Value Function Loss: 0.05089

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.60625
Value Function Update Magnitude: 0.90854

Collected Steps per Second: 22,822.72046
Overall Steps per Second: 10,695.90419

Timestep Collection Time: 2.19080
Timestep Consumption Time: 2.48389
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.67469

Cumulative Model Updates: 50,234
Cumulative Timesteps: 418,984,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,454.31097
Policy Entropy: 3.74484
Value Function Loss: 0.05317

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.62291
Value Function Update Magnitude: 0.83116

Collected Steps per Second: 22,849.94847
Overall Steps per Second: 10,874.60345

Timestep Collection Time: 2.18933
Timestep Consumption Time: 2.41093
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.60026

Cumulative Model Updates: 50,240
Cumulative Timesteps: 419,034,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 419034276...
Checkpoint 419034276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,558.96797
Policy Entropy: 3.72325
Value Function Loss: 0.05561

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.58394
Value Function Update Magnitude: 0.68307

Collected Steps per Second: 22,069.79241
Overall Steps per Second: 10,664.29212

Timestep Collection Time: 2.26590
Timestep Consumption Time: 2.42339
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.68929

Cumulative Model Updates: 50,246
Cumulative Timesteps: 419,084,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,140.54012
Policy Entropy: 3.71989
Value Function Loss: 0.05567

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.59962
Value Function Update Magnitude: 0.63505

Collected Steps per Second: 22,297.26383
Overall Steps per Second: 10,882.72866

Timestep Collection Time: 2.24270
Timestep Consumption Time: 2.35229
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.59499

Cumulative Model Updates: 50,252
Cumulative Timesteps: 419,134,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 419134290...
Checkpoint 419134290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,595.76131
Policy Entropy: 3.71839
Value Function Loss: 0.05516

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.58467
Value Function Update Magnitude: 0.63089

Collected Steps per Second: 21,937.91140
Overall Steps per Second: 10,677.81500

Timestep Collection Time: 2.28034
Timestep Consumption Time: 2.40470
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.68504

Cumulative Model Updates: 50,258
Cumulative Timesteps: 419,184,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,457.21774
Policy Entropy: 3.72543
Value Function Loss: 0.05401

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.72107

Collected Steps per Second: 21,992.99885
Overall Steps per Second: 10,790.63511

Timestep Collection Time: 2.27354
Timestep Consumption Time: 2.36029
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.63383

Cumulative Model Updates: 50,264
Cumulative Timesteps: 419,234,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 419234318...
Checkpoint 419234318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,894.15025
Policy Entropy: 3.73585
Value Function Loss: 0.05376

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.51698
Value Function Update Magnitude: 0.73112

Collected Steps per Second: 22,156.45242
Overall Steps per Second: 10,687.83120

Timestep Collection Time: 2.25794
Timestep Consumption Time: 2.42289
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.68084

Cumulative Model Updates: 50,270
Cumulative Timesteps: 419,284,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,902.77867
Policy Entropy: 3.73528
Value Function Loss: 0.05363

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.51183
Value Function Update Magnitude: 0.70591

Collected Steps per Second: 22,197.81725
Overall Steps per Second: 10,546.67894

Timestep Collection Time: 2.25419
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.74443

Cumulative Model Updates: 50,276
Cumulative Timesteps: 419,334,384

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 419334384...
Checkpoint 419334384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,947.65868
Policy Entropy: 3.73105
Value Function Loss: 0.05114

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.56819
Value Function Update Magnitude: 0.66858

Collected Steps per Second: 22,750.17988
Overall Steps per Second: 10,721.01356

Timestep Collection Time: 2.19840
Timestep Consumption Time: 2.46664
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.66504

Cumulative Model Updates: 50,282
Cumulative Timesteps: 419,384,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.38173
Policy Entropy: 3.71006
Value Function Loss: 0.05452

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.59639
Value Function Update Magnitude: 0.59127

Collected Steps per Second: 23,062.96371
Overall Steps per Second: 10,779.62260

Timestep Collection Time: 2.16893
Timestep Consumption Time: 2.47149
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.64042

Cumulative Model Updates: 50,288
Cumulative Timesteps: 419,434,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 419434420...
Checkpoint 419434420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,137.37219
Policy Entropy: 3.70655
Value Function Loss: 0.05417

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.14936
Policy Update Magnitude: 0.52703
Value Function Update Magnitude: 0.57277

Collected Steps per Second: 22,699.05754
Overall Steps per Second: 10,640.66568

Timestep Collection Time: 2.20344
Timestep Consumption Time: 2.49702
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.70046

Cumulative Model Updates: 50,294
Cumulative Timesteps: 419,484,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,181.31504
Policy Entropy: 3.71676
Value Function Loss: 0.05570

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.16009
Policy Update Magnitude: 0.48043
Value Function Update Magnitude: 0.61119

Collected Steps per Second: 22,870.58600
Overall Steps per Second: 10,833.08734

Timestep Collection Time: 2.18656
Timestep Consumption Time: 2.42966
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61623

Cumulative Model Updates: 50,300
Cumulative Timesteps: 419,534,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 419534444...
Checkpoint 419534444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,882.22466
Policy Entropy: 3.72870
Value Function Loss: 0.04918

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.51583
Value Function Update Magnitude: 0.72685

Collected Steps per Second: 22,558.61406
Overall Steps per Second: 10,795.64462

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.41602
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.63335

Cumulative Model Updates: 50,306
Cumulative Timesteps: 419,584,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,606.99131
Policy Entropy: 3.73198
Value Function Loss: 0.04645

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.59006
Value Function Update Magnitude: 0.79234

Collected Steps per Second: 22,715.82887
Overall Steps per Second: 10,771.37014

Timestep Collection Time: 2.20225
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.64435

Cumulative Model Updates: 50,312
Cumulative Timesteps: 419,634,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 419634490...
Checkpoint 419634490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,332.72518
Policy Entropy: 3.73567
Value Function Loss: 0.04776

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.63431
Value Function Update Magnitude: 0.68120

Collected Steps per Second: 22,592.28133
Overall Steps per Second: 10,640.39262

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.48653
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.70020

Cumulative Model Updates: 50,318
Cumulative Timesteps: 419,684,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,009.68928
Policy Entropy: 3.72885
Value Function Loss: 0.04630

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.60996
Value Function Update Magnitude: 0.68515

Collected Steps per Second: 22,794.23354
Overall Steps per Second: 10,692.66456

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.48296
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.67685

Cumulative Model Updates: 50,324
Cumulative Timesteps: 419,734,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 419734510...
Checkpoint 419734510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,262.28929
Policy Entropy: 3.73391
Value Function Loss: 0.04683

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.55950
Value Function Update Magnitude: 0.74322

Collected Steps per Second: 22,876.82580
Overall Steps per Second: 10,831.24663

Timestep Collection Time: 2.18597
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61701

Cumulative Model Updates: 50,330
Cumulative Timesteps: 419,784,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,325.84853
Policy Entropy: 3.73777
Value Function Loss: 0.04571

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.54235
Value Function Update Magnitude: 0.75662

Collected Steps per Second: 22,608.27349
Overall Steps per Second: 10,605.85889

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.50350
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.71570

Cumulative Model Updates: 50,336
Cumulative Timesteps: 419,834,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 419834532...
Checkpoint 419834532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,140.93370
Policy Entropy: 3.75056
Value Function Loss: 0.04622

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.48394
Value Function Update Magnitude: 0.76256

Collected Steps per Second: 22,745.95830
Overall Steps per Second: 10,661.50345

Timestep Collection Time: 2.19907
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.69165

Cumulative Model Updates: 50,342
Cumulative Timesteps: 419,884,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,762.91503
Policy Entropy: 3.75124
Value Function Loss: 0.04521

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.45425
Value Function Update Magnitude: 0.74035

Collected Steps per Second: 22,605.30118
Overall Steps per Second: 10,781.77688

Timestep Collection Time: 2.21311
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.64005

Cumulative Model Updates: 50,348
Cumulative Timesteps: 419,934,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 419934580...
Checkpoint 419934580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,638.69049
Policy Entropy: 3.75586
Value Function Loss: 0.04647

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.50534
Value Function Update Magnitude: 0.71585

Collected Steps per Second: 22,558.11638
Overall Steps per Second: 10,660.86083

Timestep Collection Time: 2.21721
Timestep Consumption Time: 2.47435
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.69155

Cumulative Model Updates: 50,354
Cumulative Timesteps: 419,984,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.76111
Policy Entropy: 3.76315
Value Function Loss: 0.04574

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05982
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.67135

Collected Steps per Second: 22,818.60107
Overall Steps per Second: 10,682.15813

Timestep Collection Time: 2.19119
Timestep Consumption Time: 2.48951
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.68070

Cumulative Model Updates: 50,360
Cumulative Timesteps: 420,034,596

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 420034596...
Checkpoint 420034596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,288.54046
Policy Entropy: 3.75721
Value Function Loss: 0.04450

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06510
Policy Update Magnitude: 0.62992
Value Function Update Magnitude: 0.72542

Collected Steps per Second: 22,528.40323
Overall Steps per Second: 10,779.16588

Timestep Collection Time: 2.22057
Timestep Consumption Time: 2.42042
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.64099

Cumulative Model Updates: 50,366
Cumulative Timesteps: 420,084,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,627.78642
Policy Entropy: 3.75666
Value Function Loss: 0.04399

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06216
Policy Update Magnitude: 0.61911
Value Function Update Magnitude: 0.74252

Collected Steps per Second: 22,767.24147
Overall Steps per Second: 10,667.34676

Timestep Collection Time: 2.19649
Timestep Consumption Time: 2.49146
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.68795

Cumulative Model Updates: 50,372
Cumulative Timesteps: 420,134,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 420134630...
Checkpoint 420134630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,924.18344
Policy Entropy: 3.74296
Value Function Loss: 0.04547

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.56822
Value Function Update Magnitude: 0.71709

Collected Steps per Second: 22,874.07025
Overall Steps per Second: 10,838.92819

Timestep Collection Time: 2.18614
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.61356

Cumulative Model Updates: 50,378
Cumulative Timesteps: 420,184,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,558.27910
Policy Entropy: 3.73699
Value Function Loss: 0.05047

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.46883
Value Function Update Magnitude: 0.60500

Collected Steps per Second: 22,751.30008
Overall Steps per Second: 10,666.54067

Timestep Collection Time: 2.19882
Timestep Consumption Time: 2.49117
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.68999

Cumulative Model Updates: 50,384
Cumulative Timesteps: 420,234,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 420234662...
Checkpoint 420234662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,760.38359
Policy Entropy: 3.75190
Value Function Loss: 0.05225

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.49510
Value Function Update Magnitude: 0.55156

Collected Steps per Second: 22,487.70128
Overall Steps per Second: 10,585.30860

Timestep Collection Time: 2.22397
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.72466

Cumulative Model Updates: 50,390
Cumulative Timesteps: 420,284,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,361.42588
Policy Entropy: 3.75410
Value Function Loss: 0.05224

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.51402
Value Function Update Magnitude: 0.57758

Collected Steps per Second: 23,048.61262
Overall Steps per Second: 10,865.21213

Timestep Collection Time: 2.17020
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60368

Cumulative Model Updates: 50,396
Cumulative Timesteps: 420,334,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 420334694...
Checkpoint 420334694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,552.65320
Policy Entropy: 3.75675
Value Function Loss: 0.05300

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.51223
Value Function Update Magnitude: 0.53310

Collected Steps per Second: 22,659.41489
Overall Steps per Second: 10,607.40447

Timestep Collection Time: 2.20685
Timestep Consumption Time: 2.50740
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.71425

Cumulative Model Updates: 50,402
Cumulative Timesteps: 420,384,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,436.20412
Policy Entropy: 3.74622
Value Function Loss: 0.05244

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.53202
Value Function Update Magnitude: 0.50540

Collected Steps per Second: 23,049.66075
Overall Steps per Second: 10,859.45479

Timestep Collection Time: 2.16958
Timestep Consumption Time: 2.43544
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.60502

Cumulative Model Updates: 50,408
Cumulative Timesteps: 420,434,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 420434708...
Checkpoint 420434708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,909.05919
Policy Entropy: 3.75217
Value Function Loss: 0.05357

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.55372

Collected Steps per Second: 22,714.16256
Overall Steps per Second: 10,723.11256

Timestep Collection Time: 2.20162
Timestep Consumption Time: 2.46195
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.66357

Cumulative Model Updates: 50,414
Cumulative Timesteps: 420,484,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,121.65651
Policy Entropy: 3.75389
Value Function Loss: 0.05184

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.52823
Value Function Update Magnitude: 0.60699

Collected Steps per Second: 23,029.75786
Overall Steps per Second: 10,837.96166

Timestep Collection Time: 2.17223
Timestep Consumption Time: 2.44358
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61581

Cumulative Model Updates: 50,420
Cumulative Timesteps: 420,534,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 420534742...
Checkpoint 420534742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.45388
Policy Entropy: 3.76496
Value Function Loss: 0.04848

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.47878
Value Function Update Magnitude: 0.70522

Collected Steps per Second: 22,607.41335
Overall Steps per Second: 10,695.88655

Timestep Collection Time: 2.21246
Timestep Consumption Time: 2.46392
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.67638

Cumulative Model Updates: 50,426
Cumulative Timesteps: 420,584,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,367.36488
Policy Entropy: 3.77887
Value Function Loss: 0.04658

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.48057
Value Function Update Magnitude: 0.72718

Collected Steps per Second: 23,075.15879
Overall Steps per Second: 10,939.75377

Timestep Collection Time: 2.16692
Timestep Consumption Time: 2.40375
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.57067

Cumulative Model Updates: 50,432
Cumulative Timesteps: 420,634,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 420634762...
Checkpoint 420634762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.33108
Policy Entropy: 3.77218
Value Function Loss: 0.04566

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06056
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.78697

Collected Steps per Second: 22,619.16206
Overall Steps per Second: 10,595.95074

Timestep Collection Time: 2.21166
Timestep Consumption Time: 2.50957
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.72124

Cumulative Model Updates: 50,438
Cumulative Timesteps: 420,684,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,275.36985
Policy Entropy: 3.76229
Value Function Loss: 0.04535

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.53755
Value Function Update Magnitude: 0.78713

Collected Steps per Second: 22,589.07262
Overall Steps per Second: 10,650.57466

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.48212
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.69646

Cumulative Model Updates: 50,444
Cumulative Timesteps: 420,734,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 420734808...
Checkpoint 420734808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,626.58589
Policy Entropy: 3.75106
Value Function Loss: 0.04699

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.51781
Value Function Update Magnitude: 0.76444

Collected Steps per Second: 22,893.56902
Overall Steps per Second: 10,859.98216

Timestep Collection Time: 2.18524
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.60664

Cumulative Model Updates: 50,450
Cumulative Timesteps: 420,784,836

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,705.72540
Policy Entropy: 3.73499
Value Function Loss: 0.04933

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.53569
Value Function Update Magnitude: 0.72088

Collected Steps per Second: 23,198.61717
Overall Steps per Second: 10,905.46136

Timestep Collection Time: 2.15616
Timestep Consumption Time: 2.43053
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.58669

Cumulative Model Updates: 50,456
Cumulative Timesteps: 420,834,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 420834856...
Checkpoint 420834856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,093.52149
Policy Entropy: 3.74158
Value Function Loss: 0.05265

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.53113
Value Function Update Magnitude: 0.76654

Collected Steps per Second: 22,552.00441
Overall Steps per Second: 10,727.62953

Timestep Collection Time: 2.21781
Timestep Consumption Time: 2.44455
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.66235

Cumulative Model Updates: 50,462
Cumulative Timesteps: 420,884,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,342.27231
Policy Entropy: 3.74093
Value Function Loss: 0.05398

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.54272
Value Function Update Magnitude: 0.81090

Collected Steps per Second: 22,858.59449
Overall Steps per Second: 10,813.02656

Timestep Collection Time: 2.18867
Timestep Consumption Time: 2.43815
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.62683

Cumulative Model Updates: 50,468
Cumulative Timesteps: 420,934,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 420934902...
Checkpoint 420934902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,314.03701
Policy Entropy: 3.73640
Value Function Loss: 0.05463

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.62147
Value Function Update Magnitude: 0.81205

Collected Steps per Second: 22,894.64427
Overall Steps per Second: 10,694.18658

Timestep Collection Time: 2.18488
Timestep Consumption Time: 2.49262
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.67749

Cumulative Model Updates: 50,474
Cumulative Timesteps: 420,984,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,003.26264
Policy Entropy: 3.74403
Value Function Loss: 0.05300

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.66381
Value Function Update Magnitude: 0.83639

Collected Steps per Second: 22,665.97661
Overall Steps per Second: 10,653.61471

Timestep Collection Time: 2.20639
Timestep Consumption Time: 2.48779
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.69418

Cumulative Model Updates: 50,480
Cumulative Timesteps: 421,034,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 421034934...
Checkpoint 421034934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,187.67478
Policy Entropy: 3.75121
Value Function Loss: 0.05298

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.65065
Value Function Update Magnitude: 0.77907

Collected Steps per Second: 22,676.85674
Overall Steps per Second: 10,795.08798

Timestep Collection Time: 2.20524
Timestep Consumption Time: 2.42723
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.63248

Cumulative Model Updates: 50,486
Cumulative Timesteps: 421,084,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,470.74421
Policy Entropy: 3.75188
Value Function Loss: 0.05612

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.64742
Value Function Update Magnitude: 0.71353

Collected Steps per Second: 22,748.99396
Overall Steps per Second: 10,614.63930

Timestep Collection Time: 2.19904
Timestep Consumption Time: 2.51388
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.71293

Cumulative Model Updates: 50,492
Cumulative Timesteps: 421,134,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 421134968...
Checkpoint 421134968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,728.54762
Policy Entropy: 3.75268
Value Function Loss: 0.05591

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.55741
Value Function Update Magnitude: 0.71547

Collected Steps per Second: 22,727.05384
Overall Steps per Second: 10,640.91905

Timestep Collection Time: 2.20125
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.70147

Cumulative Model Updates: 50,498
Cumulative Timesteps: 421,184,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,604.79825
Policy Entropy: 3.74635
Value Function Loss: 0.05681

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.48610
Value Function Update Magnitude: 0.68175

Collected Steps per Second: 22,789.75034
Overall Steps per Second: 10,789.26754

Timestep Collection Time: 2.19450
Timestep Consumption Time: 2.44085
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.63535

Cumulative Model Updates: 50,504
Cumulative Timesteps: 421,235,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 421235008...
Checkpoint 421235008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,321.32078
Policy Entropy: 3.72849
Value Function Loss: 0.05509

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.46459
Value Function Update Magnitude: 0.67248

Collected Steps per Second: 22,588.70130
Overall Steps per Second: 10,698.73683

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.46044
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.67438

Cumulative Model Updates: 50,510
Cumulative Timesteps: 421,285,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,941.00992
Policy Entropy: 3.72814
Value Function Loss: 0.05511

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.42882
Value Function Update Magnitude: 0.73434

Collected Steps per Second: 22,530.29417
Overall Steps per Second: 10,616.15954

Timestep Collection Time: 2.22048
Timestep Consumption Time: 2.49196
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.71244

Cumulative Model Updates: 50,516
Cumulative Timesteps: 421,335,046

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 421335046...
Checkpoint 421335046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,012.20809
Policy Entropy: 3.74177
Value Function Loss: 0.05474

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.47212
Value Function Update Magnitude: 0.75469

Collected Steps per Second: 22,653.91810
Overall Steps per Second: 10,669.82961

Timestep Collection Time: 2.20783
Timestep Consumption Time: 2.47978
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.68761

Cumulative Model Updates: 50,522
Cumulative Timesteps: 421,385,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,394.00088
Policy Entropy: 3.75130
Value Function Loss: 0.05491

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.52164
Value Function Update Magnitude: 0.81126

Collected Steps per Second: 23,216.71042
Overall Steps per Second: 10,722.84324

Timestep Collection Time: 2.15379
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.66332

Cumulative Model Updates: 50,528
Cumulative Timesteps: 421,435,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 421435066...
Checkpoint 421435066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,772.89660
Policy Entropy: 3.75231
Value Function Loss: 0.05305

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.61096
Value Function Update Magnitude: 0.78136

Collected Steps per Second: 22,449.33896
Overall Steps per Second: 10,648.31944

Timestep Collection Time: 2.22786
Timestep Consumption Time: 2.46903
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.69689

Cumulative Model Updates: 50,534
Cumulative Timesteps: 421,485,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,256.21959
Policy Entropy: 3.74550
Value Function Loss: 0.05554

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.59067
Value Function Update Magnitude: 0.73690

Collected Steps per Second: 22,579.85627
Overall Steps per Second: 10,634.19651

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.48775
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.70238

Cumulative Model Updates: 50,540
Cumulative Timesteps: 421,535,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 421535086...
Checkpoint 421535086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,129.61259
Policy Entropy: 3.75202
Value Function Loss: 0.05460

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.53243
Value Function Update Magnitude: 0.74880

Collected Steps per Second: 22,557.18743
Overall Steps per Second: 10,788.55001

Timestep Collection Time: 2.21659
Timestep Consumption Time: 2.41795
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.63454

Cumulative Model Updates: 50,546
Cumulative Timesteps: 421,585,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,545.80877
Policy Entropy: 3.75303
Value Function Loss: 0.05531

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.48439
Value Function Update Magnitude: 0.78972

Collected Steps per Second: 22,951.07492
Overall Steps per Second: 10,691.73585

Timestep Collection Time: 2.17855
Timestep Consumption Time: 2.49796
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.67651

Cumulative Model Updates: 50,552
Cumulative Timesteps: 421,635,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 421635086...
Checkpoint 421635086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,955.38827
Policy Entropy: 3.75882
Value Function Loss: 0.05559

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.46742
Value Function Update Magnitude: 0.66893

Collected Steps per Second: 22,927.23853
Overall Steps per Second: 10,842.32887

Timestep Collection Time: 2.18099
Timestep Consumption Time: 2.43094
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.61192

Cumulative Model Updates: 50,558
Cumulative Timesteps: 421,685,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.57072
Policy Entropy: 3.76251
Value Function Loss: 0.05604

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.49401
Value Function Update Magnitude: 0.64378

Collected Steps per Second: 22,787.46492
Overall Steps per Second: 10,657.33610

Timestep Collection Time: 2.19551
Timestep Consumption Time: 2.49891
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.69442

Cumulative Model Updates: 50,564
Cumulative Timesteps: 421,735,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 421735120...
Checkpoint 421735120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,453.47953
Policy Entropy: 3.77397
Value Function Loss: 0.05561

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.56015
Value Function Update Magnitude: 0.66045

Collected Steps per Second: 22,642.66199
Overall Steps per Second: 10,620.88664

Timestep Collection Time: 2.20937
Timestep Consumption Time: 2.50078
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.71015

Cumulative Model Updates: 50,570
Cumulative Timesteps: 421,785,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,015.62830
Policy Entropy: 3.77210
Value Function Loss: 0.05345

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.56004
Value Function Update Magnitude: 0.68415

Collected Steps per Second: 23,144.83179
Overall Steps per Second: 10,852.01962

Timestep Collection Time: 2.16031
Timestep Consumption Time: 2.44713
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.60744

Cumulative Model Updates: 50,576
Cumulative Timesteps: 421,835,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 421835146...
Checkpoint 421835146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,543.75294
Policy Entropy: 3.76586
Value Function Loss: 0.05077

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.70955

Collected Steps per Second: 21,982.68271
Overall Steps per Second: 10,633.81569

Timestep Collection Time: 2.27479
Timestep Consumption Time: 2.42775
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.70255

Cumulative Model Updates: 50,582
Cumulative Timesteps: 421,885,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,856.27852
Policy Entropy: 3.76411
Value Function Loss: 0.05026

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.56440
Value Function Update Magnitude: 0.64061

Collected Steps per Second: 22,252.33756
Overall Steps per Second: 10,829.52396

Timestep Collection Time: 2.24839
Timestep Consumption Time: 2.37157
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.61996

Cumulative Model Updates: 50,588
Cumulative Timesteps: 421,935,184

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 421935184...
Checkpoint 421935184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,252.53662
Policy Entropy: 3.78105
Value Function Loss: 0.05163

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.55462
Value Function Update Magnitude: 0.63291

Collected Steps per Second: 21,861.25190
Overall Steps per Second: 10,677.97795

Timestep Collection Time: 2.28798
Timestep Consumption Time: 2.39625
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.68422

Cumulative Model Updates: 50,594
Cumulative Timesteps: 421,985,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,239.17437
Policy Entropy: 3.77928
Value Function Loss: 0.05212

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.53627
Value Function Update Magnitude: 0.66424

Collected Steps per Second: 22,348.27882
Overall Steps per Second: 10,864.45253

Timestep Collection Time: 2.23802
Timestep Consumption Time: 2.36561
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60364

Cumulative Model Updates: 50,600
Cumulative Timesteps: 422,035,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 422035218...
Checkpoint 422035218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,257.87892
Policy Entropy: 3.78339
Value Function Loss: 0.05155

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.63160
Value Function Update Magnitude: 0.69510

Collected Steps per Second: 21,533.88756
Overall Steps per Second: 10,591.68026

Timestep Collection Time: 2.32257
Timestep Consumption Time: 2.39944
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.72201

Cumulative Model Updates: 50,606
Cumulative Timesteps: 422,085,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,605.03774
Policy Entropy: 3.78269
Value Function Loss: 0.04831

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.67990
Value Function Update Magnitude: 0.71771

Collected Steps per Second: 22,421.58397
Overall Steps per Second: 10,628.91720

Timestep Collection Time: 2.23062
Timestep Consumption Time: 2.47485
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.70547

Cumulative Model Updates: 50,612
Cumulative Timesteps: 422,135,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 422135246...
Checkpoint 422135246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,424.28513
Policy Entropy: 3.77132
Value Function Loss: 0.04929

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06943
Policy Update Magnitude: 0.67858
Value Function Update Magnitude: 0.68988

Collected Steps per Second: 22,546.99842
Overall Steps per Second: 10,664.59135

Timestep Collection Time: 2.21812
Timestep Consumption Time: 2.47142
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.68954

Cumulative Model Updates: 50,618
Cumulative Timesteps: 422,185,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,910.76093
Policy Entropy: 3.77198
Value Function Loss: 0.04808

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.63280
Value Function Update Magnitude: 0.76481

Collected Steps per Second: 23,099.91148
Overall Steps per Second: 10,840.16456

Timestep Collection Time: 2.16477
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.61303

Cumulative Model Updates: 50,624
Cumulative Timesteps: 422,235,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 422235264...
Checkpoint 422235264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729.56107
Policy Entropy: 3.77220
Value Function Loss: 0.04978

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.56442
Value Function Update Magnitude: 0.82488

Collected Steps per Second: 22,905.32636
Overall Steps per Second: 10,799.88019

Timestep Collection Time: 2.18351
Timestep Consumption Time: 2.44747
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.63098

Cumulative Model Updates: 50,630
Cumulative Timesteps: 422,285,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,091.35668
Policy Entropy: 3.78014
Value Function Loss: 0.04782

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.52120
Value Function Update Magnitude: 0.83214

Collected Steps per Second: 22,838.96656
Overall Steps per Second: 10,691.00889

Timestep Collection Time: 2.18985
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.67814

Cumulative Model Updates: 50,636
Cumulative Timesteps: 422,335,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 422335292...
Checkpoint 422335292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,320.62955
Policy Entropy: 3.76880
Value Function Loss: 0.04965

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.50441
Value Function Update Magnitude: 0.85616

Collected Steps per Second: 22,688.05387
Overall Steps per Second: 10,643.95978

Timestep Collection Time: 2.20389
Timestep Consumption Time: 2.49380
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.69769

Cumulative Model Updates: 50,642
Cumulative Timesteps: 422,385,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,395.92285
Policy Entropy: 3.76284
Value Function Loss: 0.04945

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11306
Policy Update Magnitude: 0.54923
Value Function Update Magnitude: 0.81138

Collected Steps per Second: 22,756.50044
Overall Steps per Second: 10,677.09986

Timestep Collection Time: 2.19779
Timestep Consumption Time: 2.48644
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.68423

Cumulative Model Updates: 50,648
Cumulative Timesteps: 422,435,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 422435308...
Checkpoint 422435308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,063.62441
Policy Entropy: 3.76323
Value Function Loss: 0.04755

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.57661
Value Function Update Magnitude: 0.70005

Collected Steps per Second: 22,600.91880
Overall Steps per Second: 10,666.57612

Timestep Collection Time: 2.21274
Timestep Consumption Time: 2.47574
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.68848

Cumulative Model Updates: 50,654
Cumulative Timesteps: 422,485,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,310.91319
Policy Entropy: 3.77228
Value Function Loss: 0.04579

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.62372
Value Function Update Magnitude: 0.69176

Collected Steps per Second: 22,543.14646
Overall Steps per Second: 10,680.75328

Timestep Collection Time: 2.21939
Timestep Consumption Time: 2.46493
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.68431

Cumulative Model Updates: 50,660
Cumulative Timesteps: 422,535,350

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 422535350...
Checkpoint 422535350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,122.96415
Policy Entropy: 3.78286
Value Function Loss: 0.04622

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.66578
Value Function Update Magnitude: 0.71284

Collected Steps per Second: 22,621.34407
Overall Steps per Second: 10,627.90449

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.49669
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.70911

Cumulative Model Updates: 50,666
Cumulative Timesteps: 422,585,398

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,902.02575
Policy Entropy: 3.79465
Value Function Loss: 0.04695

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07085
Policy Update Magnitude: 0.68105
Value Function Update Magnitude: 0.73189

Collected Steps per Second: 23,017.12804
Overall Steps per Second: 10,871.45647

Timestep Collection Time: 2.17273
Timestep Consumption Time: 2.42739
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.60012

Cumulative Model Updates: 50,672
Cumulative Timesteps: 422,635,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 422635408...
Checkpoint 422635408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,910.83802
Policy Entropy: 3.80721
Value Function Loss: 0.04729

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06677
Policy Update Magnitude: 0.66782
Value Function Update Magnitude: 0.72192

Collected Steps per Second: 22,739.62147
Overall Steps per Second: 10,715.91542

Timestep Collection Time: 2.19916
Timestep Consumption Time: 2.46755
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.66670

Cumulative Model Updates: 50,678
Cumulative Timesteps: 422,685,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,106.53025
Policy Entropy: 3.81340
Value Function Loss: 0.04823

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05968
Policy Update Magnitude: 0.66103
Value Function Update Magnitude: 0.69097

Collected Steps per Second: 22,838.15916
Overall Steps per Second: 10,795.04806

Timestep Collection Time: 2.19063
Timestep Consumption Time: 2.44390
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.63453

Cumulative Model Updates: 50,684
Cumulative Timesteps: 422,735,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 422735446...
Checkpoint 422735446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,311.23586
Policy Entropy: 3.79600
Value Function Loss: 0.04773

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07134
Policy Update Magnitude: 0.62063
Value Function Update Magnitude: 0.69940

Collected Steps per Second: 22,683.93356
Overall Steps per Second: 10,697.30691

Timestep Collection Time: 2.20544
Timestep Consumption Time: 2.47125
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.67669

Cumulative Model Updates: 50,690
Cumulative Timesteps: 422,785,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.42137
Policy Entropy: 3.79392
Value Function Loss: 0.04894

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06117
Policy Update Magnitude: 0.62738
Value Function Update Magnitude: 0.74449

Collected Steps per Second: 22,565.96000
Overall Steps per Second: 10,617.18890

Timestep Collection Time: 2.21635
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.71066

Cumulative Model Updates: 50,696
Cumulative Timesteps: 422,835,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 422835488...
Checkpoint 422835488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,585.33581
Policy Entropy: 3.78448
Value Function Loss: 0.04976

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06701
Policy Update Magnitude: 0.65625
Value Function Update Magnitude: 0.78392

Collected Steps per Second: 22,727.97291
Overall Steps per Second: 10,664.30851

Timestep Collection Time: 2.20072
Timestep Consumption Time: 2.48950
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.69022

Cumulative Model Updates: 50,702
Cumulative Timesteps: 422,885,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,097.14658
Policy Entropy: 3.78969
Value Function Loss: 0.04933

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.66657
Value Function Update Magnitude: 0.81274

Collected Steps per Second: 22,830.92102
Overall Steps per Second: 10,743.29833

Timestep Collection Time: 2.19115
Timestep Consumption Time: 2.46533
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.65648

Cumulative Model Updates: 50,708
Cumulative Timesteps: 422,935,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 422935532...
Checkpoint 422935532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,610.45517
Policy Entropy: 3.78788
Value Function Loss: 0.04796

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06768
Policy Update Magnitude: 0.65503
Value Function Update Magnitude: 0.84916

Collected Steps per Second: 22,883.10252
Overall Steps per Second: 10,638.22726

Timestep Collection Time: 2.18528
Timestep Consumption Time: 2.51531
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.70060

Cumulative Model Updates: 50,714
Cumulative Timesteps: 422,985,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,439.55489
Policy Entropy: 3.78858
Value Function Loss: 0.04762

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.65771
Value Function Update Magnitude: 0.81934

Collected Steps per Second: 22,773.81415
Overall Steps per Second: 10,836.79556

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.41986
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.61668

Cumulative Model Updates: 50,720
Cumulative Timesteps: 423,035,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 423035568...
Checkpoint 423035568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,281.17857
Policy Entropy: 3.78842
Value Function Loss: 0.04777

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.54927
Value Function Update Magnitude: 0.80468

Collected Steps per Second: 22,620.06510
Overall Steps per Second: 10,746.76729

Timestep Collection Time: 2.21052
Timestep Consumption Time: 2.44223
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.65275

Cumulative Model Updates: 50,726
Cumulative Timesteps: 423,085,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,534.36017
Policy Entropy: 3.77605
Value Function Loss: 0.04675

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.46567
Value Function Update Magnitude: 0.81695

Collected Steps per Second: 22,785.39631
Overall Steps per Second: 10,811.13360

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.43242
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62856

Cumulative Model Updates: 50,732
Cumulative Timesteps: 423,135,610

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 423135610...
Checkpoint 423135610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,603.90221
Policy Entropy: 3.79220
Value Function Loss: 0.04865

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.47426
Value Function Update Magnitude: 0.81863

Collected Steps per Second: 22,630.54595
Overall Steps per Second: 10,730.77648

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.45039
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.66005

Cumulative Model Updates: 50,738
Cumulative Timesteps: 423,185,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,675.31570
Policy Entropy: 3.77268
Value Function Loss: 0.05001

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.49964
Value Function Update Magnitude: 0.83323

Collected Steps per Second: 22,555.89515
Overall Steps per Second: 10,649.49708

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.47864
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.69562

Cumulative Model Updates: 50,744
Cumulative Timesteps: 423,235,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 423235622...
Checkpoint 423235622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,537.35859
Policy Entropy: 3.76552
Value Function Loss: 0.04943

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.49278
Value Function Update Magnitude: 0.84782

Collected Steps per Second: 22,684.39988
Overall Steps per Second: 10,810.86246

Timestep Collection Time: 2.20451
Timestep Consumption Time: 2.42121
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.62572

Cumulative Model Updates: 50,750
Cumulative Timesteps: 423,285,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,065.96523
Policy Entropy: 3.75635
Value Function Loss: 0.04981

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.49912
Value Function Update Magnitude: 0.83433

Collected Steps per Second: 21,972.51793
Overall Steps per Second: 10,650.41216

Timestep Collection Time: 2.27684
Timestep Consumption Time: 2.42044
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.69728

Cumulative Model Updates: 50,756
Cumulative Timesteps: 423,335,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 423335658...
Checkpoint 423335658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,019.24001
Policy Entropy: 3.76259
Value Function Loss: 0.05082

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.52709
Value Function Update Magnitude: 0.81320

Collected Steps per Second: 22,175.46223
Overall Steps per Second: 10,877.50380

Timestep Collection Time: 2.25592
Timestep Consumption Time: 2.34312
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.59903

Cumulative Model Updates: 50,762
Cumulative Timesteps: 423,385,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,744.76852
Policy Entropy: 3.76389
Value Function Loss: 0.05144

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.51378
Value Function Update Magnitude: 0.78127

Collected Steps per Second: 22,231.54513
Overall Steps per Second: 10,736.61330

Timestep Collection Time: 2.24942
Timestep Consumption Time: 2.40829
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.65771

Cumulative Model Updates: 50,768
Cumulative Timesteps: 423,435,692

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 423435692...
Checkpoint 423435692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,918.24368
Policy Entropy: 3.77372
Value Function Loss: 0.04969

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.50982
Value Function Update Magnitude: 0.84843

Collected Steps per Second: 22,145.86947
Overall Steps per Second: 10,851.82414

Timestep Collection Time: 2.25803
Timestep Consumption Time: 2.35004
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60807

Cumulative Model Updates: 50,774
Cumulative Timesteps: 423,485,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,083.10843
Policy Entropy: 3.76544
Value Function Loss: 0.04845

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.56298
Value Function Update Magnitude: 0.88089

Collected Steps per Second: 22,207.68081
Overall Steps per Second: 10,741.12472

Timestep Collection Time: 2.25165
Timestep Consumption Time: 2.40372
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.65538

Cumulative Model Updates: 50,780
Cumulative Timesteps: 423,535,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 423535702...
Checkpoint 423535702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,333.31059
Policy Entropy: 3.75425
Value Function Loss: 0.04995

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07904
Policy Update Magnitude: 0.62979
Value Function Update Magnitude: 0.86710

Collected Steps per Second: 22,120.59413
Overall Steps per Second: 10,594.14531

Timestep Collection Time: 2.26088
Timestep Consumption Time: 2.45984
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.72072

Cumulative Model Updates: 50,786
Cumulative Timesteps: 423,585,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,966.26410
Policy Entropy: 3.74850
Value Function Loss: 0.05060

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06498
Policy Update Magnitude: 0.66094
Value Function Update Magnitude: 0.85149

Collected Steps per Second: 23,335.85164
Overall Steps per Second: 10,847.14412

Timestep Collection Time: 2.14271
Timestep Consumption Time: 2.46698
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.60969

Cumulative Model Updates: 50,792
Cumulative Timesteps: 423,635,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 423635716...
Checkpoint 423635716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,787.65856
Policy Entropy: 3.75156
Value Function Loss: 0.05175

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07100
Policy Update Magnitude: 0.66200
Value Function Update Magnitude: 0.87034

Collected Steps per Second: 22,657.80502
Overall Steps per Second: 10,860.45156

Timestep Collection Time: 2.20701
Timestep Consumption Time: 2.39740
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.60441

Cumulative Model Updates: 50,798
Cumulative Timesteps: 423,685,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,696.15981
Policy Entropy: 3.74702
Value Function Loss: 0.05149

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06764
Policy Update Magnitude: 0.64383
Value Function Update Magnitude: 0.88786

Collected Steps per Second: 22,871.49288
Overall Steps per Second: 10,743.38958

Timestep Collection Time: 2.18648
Timestep Consumption Time: 2.46829
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.65477

Cumulative Model Updates: 50,804
Cumulative Timesteps: 423,735,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 423735730...
Checkpoint 423735730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,460.74319
Policy Entropy: 3.74851
Value Function Loss: 0.04913

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.60812
Value Function Update Magnitude: 0.89020

Collected Steps per Second: 22,553.54075
Overall Steps per Second: 10,835.39979

Timestep Collection Time: 2.21695
Timestep Consumption Time: 2.39756
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.61450

Cumulative Model Updates: 50,810
Cumulative Timesteps: 423,785,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,079.26828
Policy Entropy: 3.75049
Value Function Loss: 0.04843

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.57126
Value Function Update Magnitude: 0.87131

Collected Steps per Second: 22,827.31864
Overall Steps per Second: 10,673.10218

Timestep Collection Time: 2.19036
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.68467

Cumulative Model Updates: 50,816
Cumulative Timesteps: 423,835,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 423835730...
Checkpoint 423835730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,317.39143
Policy Entropy: 3.75286
Value Function Loss: 0.04855

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.83243

Collected Steps per Second: 22,725.82402
Overall Steps per Second: 10,705.40737

Timestep Collection Time: 2.20102
Timestep Consumption Time: 2.47138
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.67241

Cumulative Model Updates: 50,822
Cumulative Timesteps: 423,885,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,690.42900
Policy Entropy: 3.75405
Value Function Loss: 0.05000

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.50437
Value Function Update Magnitude: 0.73653

Collected Steps per Second: 22,892.00570
Overall Steps per Second: 10,672.15828

Timestep Collection Time: 2.18574
Timestep Consumption Time: 2.50272
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.68846

Cumulative Model Updates: 50,828
Cumulative Timesteps: 423,935,786

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 423935786...
Checkpoint 423935786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,053.59806
Policy Entropy: 3.75033
Value Function Loss: 0.05213

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.51146
Value Function Update Magnitude: 0.68225

Collected Steps per Second: 22,635.49456
Overall Steps per Second: 10,655.33324

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.69530

Cumulative Model Updates: 50,834
Cumulative Timesteps: 423,985,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,181.62442
Policy Entropy: 3.74321
Value Function Loss: 0.05408

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.58223
Value Function Update Magnitude: 0.78644

Collected Steps per Second: 23,199.26229
Overall Steps per Second: 10,886.12330

Timestep Collection Time: 2.15662
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.59594

Cumulative Model Updates: 50,840
Cumulative Timesteps: 424,035,848

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 424035848...
Checkpoint 424035848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,455.61596
Policy Entropy: 3.73042
Value Function Loss: 0.05434

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.54935
Value Function Update Magnitude: 0.81366

Collected Steps per Second: 22,199.04755
Overall Steps per Second: 10,630.39487

Timestep Collection Time: 2.25361
Timestep Consumption Time: 2.45252
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.70613

Cumulative Model Updates: 50,846
Cumulative Timesteps: 424,085,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,814.81356
Policy Entropy: 3.71895
Value Function Loss: 0.05806

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.48738
Value Function Update Magnitude: 0.78977

Collected Steps per Second: 23,067.36445
Overall Steps per Second: 10,864.15973

Timestep Collection Time: 2.16800
Timestep Consumption Time: 2.43521
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60321

Cumulative Model Updates: 50,852
Cumulative Timesteps: 424,135,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 424135886...
Checkpoint 424135886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,913.28309
Policy Entropy: 3.72171
Value Function Loss: 0.06209

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.44777
Value Function Update Magnitude: 0.65711

Collected Steps per Second: 22,630.24779
Overall Steps per Second: 10,782.85637

Timestep Collection Time: 2.21014
Timestep Consumption Time: 2.42833
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.63847

Cumulative Model Updates: 50,858
Cumulative Timesteps: 424,185,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,968.85640
Policy Entropy: 3.72811
Value Function Loss: 0.06288

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.47703
Value Function Update Magnitude: 0.54722

Collected Steps per Second: 22,667.45766
Overall Steps per Second: 10,786.51623

Timestep Collection Time: 2.20669
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.63727

Cumulative Model Updates: 50,864
Cumulative Timesteps: 424,235,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 424235922...
Checkpoint 424235922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,795.72667
Policy Entropy: 3.72963
Value Function Loss: 0.06195

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.46639
Value Function Update Magnitude: 0.58835

Collected Steps per Second: 22,513.03269
Overall Steps per Second: 10,759.64857

Timestep Collection Time: 2.22191
Timestep Consumption Time: 2.42712
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.64904

Cumulative Model Updates: 50,870
Cumulative Timesteps: 424,285,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,514.04638
Policy Entropy: 3.72481
Value Function Loss: 0.05925

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.48268
Value Function Update Magnitude: 0.64128

Collected Steps per Second: 22,695.02259
Overall Steps per Second: 10,787.34018

Timestep Collection Time: 2.20401
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.63692

Cumulative Model Updates: 50,876
Cumulative Timesteps: 424,335,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 424335964...
Checkpoint 424335964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,228.86091
Policy Entropy: 3.72493
Value Function Loss: 0.05589

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.55575
Value Function Update Magnitude: 0.75084

Collected Steps per Second: 22,524.08951
Overall Steps per Second: 10,769.59660

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.64437

Cumulative Model Updates: 50,882
Cumulative Timesteps: 424,385,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,797.70417
Policy Entropy: 3.72737
Value Function Loss: 0.05167

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.63030
Value Function Update Magnitude: 0.80800

Collected Steps per Second: 22,806.28787
Overall Steps per Second: 10,820.37451

Timestep Collection Time: 2.19299
Timestep Consumption Time: 2.42921
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62221

Cumulative Model Updates: 50,888
Cumulative Timesteps: 424,435,996

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 424435996...
Checkpoint 424435996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,302.47605
Policy Entropy: 3.72485
Value Function Loss: 0.04947

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.67037
Value Function Update Magnitude: 0.79268

Collected Steps per Second: 22,573.86554
Overall Steps per Second: 10,699.35439

Timestep Collection Time: 2.21637
Timestep Consumption Time: 2.45980
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.67617

Cumulative Model Updates: 50,894
Cumulative Timesteps: 424,486,028

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,694.04088
Policy Entropy: 3.72791
Value Function Loss: 0.04972

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.77611

Collected Steps per Second: 22,632.34608
Overall Steps per Second: 10,646.98856

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.48803
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.69823

Cumulative Model Updates: 50,900
Cumulative Timesteps: 424,536,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 424536050...
Checkpoint 424536050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,469.03944
Policy Entropy: 3.72826
Value Function Loss: 0.05085

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06562
Policy Update Magnitude: 0.61358
Value Function Update Magnitude: 0.76212

Collected Steps per Second: 22,733.31876
Overall Steps per Second: 10,805.43122

Timestep Collection Time: 2.19941
Timestep Consumption Time: 2.42789
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62730

Cumulative Model Updates: 50,906
Cumulative Timesteps: 424,586,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,113.48196
Policy Entropy: 3.72327
Value Function Loss: 0.05134

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06847
Policy Update Magnitude: 0.64620
Value Function Update Magnitude: 0.69379

Collected Steps per Second: 22,750.67662
Overall Steps per Second: 10,616.54231

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.51260
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.71095

Cumulative Model Updates: 50,912
Cumulative Timesteps: 424,636,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 424636064...
Checkpoint 424636064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,233.56048
Policy Entropy: 3.71974
Value Function Loss: 0.05123

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.60777
Value Function Update Magnitude: 0.75208

Collected Steps per Second: 22,863.03821
Overall Steps per Second: 10,723.64138

Timestep Collection Time: 2.18904
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.66707

Cumulative Model Updates: 50,918
Cumulative Timesteps: 424,686,112

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,693.47257
Policy Entropy: 3.70917
Value Function Loss: 0.05037

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.50996
Value Function Update Magnitude: 0.81886

Collected Steps per Second: 23,018.88931
Overall Steps per Second: 10,719.78728

Timestep Collection Time: 2.17230
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.66464

Cumulative Model Updates: 50,924
Cumulative Timesteps: 424,736,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 424736116...
Checkpoint 424736116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,689.45183
Policy Entropy: 3.70241
Value Function Loss: 0.05092

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.49318
Value Function Update Magnitude: 0.82831

Collected Steps per Second: 21,764.45995
Overall Steps per Second: 10,659.77612

Timestep Collection Time: 2.29806
Timestep Consumption Time: 2.39397
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.69203

Cumulative Model Updates: 50,930
Cumulative Timesteps: 424,786,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,549.94149
Policy Entropy: 3.69619
Value Function Loss: 0.05207

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.56583
Value Function Update Magnitude: 0.82076

Collected Steps per Second: 22,407.22993
Overall Steps per Second: 10,911.02929

Timestep Collection Time: 2.23294
Timestep Consumption Time: 2.35270
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.58564

Cumulative Model Updates: 50,936
Cumulative Timesteps: 424,836,166

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 424836166...
Checkpoint 424836166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,383.91744
Policy Entropy: 3.70777
Value Function Loss: 0.05219

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.83964

Collected Steps per Second: 21,911.09069
Overall Steps per Second: 10,618.74602

Timestep Collection Time: 2.28231
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.70941

Cumulative Model Updates: 50,942
Cumulative Timesteps: 424,886,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,565.30719
Policy Entropy: 3.73023
Value Function Loss: 0.05064

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.51906
Value Function Update Magnitude: 0.87676

Collected Steps per Second: 22,045.06374
Overall Steps per Second: 10,820.48861

Timestep Collection Time: 2.26908
Timestep Consumption Time: 2.35382
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.62290

Cumulative Model Updates: 50,948
Cumulative Timesteps: 424,936,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 424936196...
Checkpoint 424936196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,939.34482
Policy Entropy: 3.74477
Value Function Loss: 0.05152

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.50927
Value Function Update Magnitude: 0.86102

Collected Steps per Second: 21,784.98862
Overall Steps per Second: 10,770.15129

Timestep Collection Time: 2.29635
Timestep Consumption Time: 2.34852
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.64487

Cumulative Model Updates: 50,954
Cumulative Timesteps: 424,986,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,758.94952
Policy Entropy: 3.73438
Value Function Loss: 0.05352

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.73555

Collected Steps per Second: 22,242.37202
Overall Steps per Second: 10,846.55423

Timestep Collection Time: 2.24805
Timestep Consumption Time: 2.36189
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.60994

Cumulative Model Updates: 50,960
Cumulative Timesteps: 425,036,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 425036224...
Checkpoint 425036224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,782.20342
Policy Entropy: 3.73078
Value Function Loss: 0.05484

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.51974
Value Function Update Magnitude: 0.75970

Collected Steps per Second: 21,817.44440
Overall Steps per Second: 10,649.65107

Timestep Collection Time: 2.29303
Timestep Consumption Time: 2.40459
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.69762

Cumulative Model Updates: 50,966
Cumulative Timesteps: 425,086,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,202.88758
Policy Entropy: 3.74650
Value Function Loss: 0.05306

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.16830
Policy Update Magnitude: 0.43779
Value Function Update Magnitude: 0.82173

Collected Steps per Second: 22,581.55301
Overall Steps per Second: 10,665.82157

Timestep Collection Time: 2.21473
Timestep Consumption Time: 2.47427
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.68900

Cumulative Model Updates: 50,972
Cumulative Timesteps: 425,136,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 425136264...
Checkpoint 425136264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,622.15992
Policy Entropy: 3.72898
Value Function Loss: 0.05419

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.43753
Value Function Update Magnitude: 0.82112

Collected Steps per Second: 22,799.25630
Overall Steps per Second: 10,886.78059

Timestep Collection Time: 2.19428
Timestep Consumption Time: 2.40102
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.59530

Cumulative Model Updates: 50,978
Cumulative Timesteps: 425,186,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,511.28877
Policy Entropy: 3.73888
Value Function Loss: 0.05979

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.42736
Value Function Update Magnitude: 0.69346

Collected Steps per Second: 22,948.54219
Overall Steps per Second: 10,918.62845

Timestep Collection Time: 2.17957
Timestep Consumption Time: 2.40141
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.58098

Cumulative Model Updates: 50,984
Cumulative Timesteps: 425,236,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 425236310...
Checkpoint 425236310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,201.86771
Policy Entropy: 3.72745
Value Function Loss: 0.06112

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.46373
Value Function Update Magnitude: 0.61772

Collected Steps per Second: 22,589.75255
Overall Steps per Second: 10,651.90008

Timestep Collection Time: 2.21366
Timestep Consumption Time: 2.48090
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.69456

Cumulative Model Updates: 50,990
Cumulative Timesteps: 425,286,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,633.88070
Policy Entropy: 3.73492
Value Function Loss: 0.05739

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.48777
Value Function Update Magnitude: 0.59508

Collected Steps per Second: 22,552.54428
Overall Steps per Second: 10,668.82794

Timestep Collection Time: 2.21731
Timestep Consumption Time: 2.46980
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.68711

Cumulative Model Updates: 50,996
Cumulative Timesteps: 425,336,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 425336322...
Checkpoint 425336322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,767.14458
Policy Entropy: 3.72574
Value Function Loss: 0.05350

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.51357
Value Function Update Magnitude: 0.69806

Collected Steps per Second: 22,663.60317
Overall Steps per Second: 10,787.24759

Timestep Collection Time: 2.20706
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.63696

Cumulative Model Updates: 51,002
Cumulative Timesteps: 425,386,342

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.74325
Policy Entropy: 3.72606
Value Function Loss: 0.05058

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.51743
Value Function Update Magnitude: 0.80260

Collected Steps per Second: 22,673.18716
Overall Steps per Second: 10,621.09622

Timestep Collection Time: 2.20728
Timestep Consumption Time: 2.50467
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.71194

Cumulative Model Updates: 51,008
Cumulative Timesteps: 425,436,388

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 425436388...
Checkpoint 425436388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,255.54824
Policy Entropy: 3.73192
Value Function Loss: 0.05048

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.52741
Value Function Update Magnitude: 0.81828

Collected Steps per Second: 22,685.02385
Overall Steps per Second: 10,642.66492

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.49427
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.69864

Cumulative Model Updates: 51,014
Cumulative Timesteps: 425,486,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,584.52739
Policy Entropy: 3.74382
Value Function Loss: 0.05058

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.48170
Value Function Update Magnitude: 0.83142

Collected Steps per Second: 22,917.34630
Overall Steps per Second: 10,792.99708

Timestep Collection Time: 2.18315
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.63560

Cumulative Model Updates: 51,020
Cumulative Timesteps: 425,536,426

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 425536426...
Checkpoint 425536426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,860.52859
Policy Entropy: 3.73347
Value Function Loss: 0.05449

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.50213
Value Function Update Magnitude: 0.76526

Collected Steps per Second: 22,357.27677
Overall Steps per Second: 10,658.19566

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.45668
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.69479

Cumulative Model Updates: 51,026
Cumulative Timesteps: 425,586,464

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,190.86797
Policy Entropy: 3.73345
Value Function Loss: 0.05744

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.53229
Value Function Update Magnitude: 0.60918

Collected Steps per Second: 22,936.19714
Overall Steps per Second: 10,852.75729

Timestep Collection Time: 2.18188
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61118

Cumulative Model Updates: 51,032
Cumulative Timesteps: 425,636,508

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 425636508...
Checkpoint 425636508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,428.19528
Policy Entropy: 3.72310
Value Function Loss: 0.05832

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.50460
Value Function Update Magnitude: 0.55908

Collected Steps per Second: 22,327.54679
Overall Steps per Second: 10,751.78583

Timestep Collection Time: 2.24082
Timestep Consumption Time: 2.41255
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.65337

Cumulative Model Updates: 51,038
Cumulative Timesteps: 425,686,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,721.00344
Policy Entropy: 3.74030
Value Function Loss: 0.05314

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11036
Policy Update Magnitude: 0.45767
Value Function Update Magnitude: 0.74066

Collected Steps per Second: 22,854.43754
Overall Steps per Second: 10,820.69235

Timestep Collection Time: 2.18828
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.62189

Cumulative Model Updates: 51,044
Cumulative Timesteps: 425,736,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 425736552...
Checkpoint 425736552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,998.15386
Policy Entropy: 3.74371
Value Function Loss: 0.05000

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.48824
Value Function Update Magnitude: 0.81395

Collected Steps per Second: 22,586.18452
Overall Steps per Second: 10,670.64603

Timestep Collection Time: 2.21401
Timestep Consumption Time: 2.47231
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.68631

Cumulative Model Updates: 51,050
Cumulative Timesteps: 425,786,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,226.43517
Policy Entropy: 3.74444
Value Function Loss: 0.04836

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.52671
Value Function Update Magnitude: 0.83208

Collected Steps per Second: 22,776.96229
Overall Steps per Second: 10,827.53274

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.61915

Cumulative Model Updates: 51,056
Cumulative Timesteps: 425,836,572

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 425836572...
Checkpoint 425836572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,827.40981
Policy Entropy: 3.75618
Value Function Loss: 0.05089

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.51916
Value Function Update Magnitude: 0.80370

Collected Steps per Second: 22,443.05708
Overall Steps per Second: 10,776.61853

Timestep Collection Time: 2.22920
Timestep Consumption Time: 2.41326
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.64246

Cumulative Model Updates: 51,062
Cumulative Timesteps: 425,886,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,800.31947
Policy Entropy: 3.74662
Value Function Loss: 0.05287

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.49747
Value Function Update Magnitude: 0.73938

Collected Steps per Second: 22,735.13935
Overall Steps per Second: 10,788.60129

Timestep Collection Time: 2.20003
Timestep Consumption Time: 2.43616
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.63619

Cumulative Model Updates: 51,068
Cumulative Timesteps: 425,936,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 425936620...
Checkpoint 425936620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,792.76452
Policy Entropy: 3.75516
Value Function Loss: 0.05374

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.51041
Value Function Update Magnitude: 0.66392

Collected Steps per Second: 22,717.87804
Overall Steps per Second: 10,713.33246

Timestep Collection Time: 2.20144
Timestep Consumption Time: 2.46676
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.66820

Cumulative Model Updates: 51,074
Cumulative Timesteps: 425,986,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,898.96043
Policy Entropy: 3.75522
Value Function Loss: 0.05229

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.50897
Value Function Update Magnitude: 0.64948

Collected Steps per Second: 22,268.89423
Overall Steps per Second: 10,869.61198

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.35583
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.60219

Cumulative Model Updates: 51,080
Cumulative Timesteps: 426,036,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 426036656...
Checkpoint 426036656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,849.11955
Policy Entropy: 3.76790
Value Function Loss: 0.05300

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.62449

Collected Steps per Second: 21,954.91724
Overall Steps per Second: 10,686.67700

Timestep Collection Time: 2.27840
Timestep Consumption Time: 2.40239
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.68078

Cumulative Model Updates: 51,086
Cumulative Timesteps: 426,086,678

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,574.68885
Policy Entropy: 3.76534
Value Function Loss: 0.05241

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.51833
Value Function Update Magnitude: 0.58779

Collected Steps per Second: 22,262.78256
Overall Steps per Second: 10,826.10258

Timestep Collection Time: 2.24653
Timestep Consumption Time: 2.37323
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.61976

Cumulative Model Updates: 51,092
Cumulative Timesteps: 426,136,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 426136692...
Checkpoint 426136692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,991.40940
Policy Entropy: 3.77656
Value Function Loss: 0.05201

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.51097
Value Function Update Magnitude: 0.59469

Collected Steps per Second: 21,851.57502
Overall Steps per Second: 10,700.83404

Timestep Collection Time: 2.28926
Timestep Consumption Time: 2.38551
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.67478

Cumulative Model Updates: 51,098
Cumulative Timesteps: 426,186,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,895.47821
Policy Entropy: 3.78053
Value Function Loss: 0.04989

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06684
Policy Update Magnitude: 0.59257
Value Function Update Magnitude: 0.64490

Collected Steps per Second: 22,353.46945
Overall Steps per Second: 10,896.66288

Timestep Collection Time: 2.23724
Timestep Consumption Time: 2.35224
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.58948

Cumulative Model Updates: 51,104
Cumulative Timesteps: 426,236,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 426236726...
Checkpoint 426236726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,997.46248
Policy Entropy: 3.77229
Value Function Loss: 0.04902

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07399
Policy Update Magnitude: 0.63328
Value Function Update Magnitude: 0.65265

Collected Steps per Second: 22,080.74493
Overall Steps per Second: 10,736.27720

Timestep Collection Time: 2.26541
Timestep Consumption Time: 2.39374
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.65916

Cumulative Model Updates: 51,110
Cumulative Timesteps: 426,286,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,266.08927
Policy Entropy: 3.76100
Value Function Loss: 0.04772

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.53809
Value Function Update Magnitude: 0.69312

Collected Steps per Second: 22,715.02102
Overall Steps per Second: 10,862.83410

Timestep Collection Time: 2.20136
Timestep Consumption Time: 2.40186
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.60322

Cumulative Model Updates: 51,116
Cumulative Timesteps: 426,336,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 426336752...
Checkpoint 426336752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,716.27696
Policy Entropy: 3.74442
Value Function Loss: 0.04667

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.47520
Value Function Update Magnitude: 0.77288

Collected Steps per Second: 22,399.44543
Overall Steps per Second: 10,593.57010

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.72173

Cumulative Model Updates: 51,122
Cumulative Timesteps: 426,386,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,329.53212
Policy Entropy: 3.74799
Value Function Loss: 0.04735

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.58772
Value Function Update Magnitude: 0.82702

Collected Steps per Second: 22,718.81300
Overall Steps per Second: 10,860.41334

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.40421
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.60609

Cumulative Model Updates: 51,128
Cumulative Timesteps: 426,436,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 426436796...
Checkpoint 426436796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,611.91817
Policy Entropy: 3.75990
Value Function Loss: 0.04791

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08502
Policy Update Magnitude: 0.58661
Value Function Update Magnitude: 0.75498

Collected Steps per Second: 22,638.47272
Overall Steps per Second: 10,721.44933

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.45610
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.66579

Cumulative Model Updates: 51,134
Cumulative Timesteps: 426,486,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,692.39851
Policy Entropy: 3.75625
Value Function Loss: 0.04926

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.63282
Value Function Update Magnitude: 0.66519

Collected Steps per Second: 23,113.61722
Overall Steps per Second: 10,854.60616

Timestep Collection Time: 2.16452
Timestep Consumption Time: 2.44458
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60910

Cumulative Model Updates: 51,140
Cumulative Timesteps: 426,536,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 426536850...
Checkpoint 426536850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,782.41050
Policy Entropy: 3.74191
Value Function Loss: 0.05114

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.63929
Value Function Update Magnitude: 0.63518

Collected Steps per Second: 22,581.79295
Overall Steps per Second: 10,686.68308

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.46474
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.67909

Cumulative Model Updates: 51,146
Cumulative Timesteps: 426,586,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,299.98876
Policy Entropy: 3.73471
Value Function Loss: 0.05216

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.59699
Value Function Update Magnitude: 0.56805

Collected Steps per Second: 22,954.62261
Overall Steps per Second: 10,818.60418

Timestep Collection Time: 2.17821
Timestep Consumption Time: 2.44346
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.62167

Cumulative Model Updates: 51,152
Cumulative Timesteps: 426,636,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 426636854...
Checkpoint 426636854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.44327
Policy Entropy: 3.72623
Value Function Loss: 0.05288

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.53101
Value Function Update Magnitude: 0.57312

Collected Steps per Second: 22,417.38898
Overall Steps per Second: 10,755.12691

Timestep Collection Time: 2.23148
Timestep Consumption Time: 2.41970
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.65118

Cumulative Model Updates: 51,158
Cumulative Timesteps: 426,686,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,042.50435
Policy Entropy: 3.72594
Value Function Loss: 0.05267

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.46340
Value Function Update Magnitude: 0.60992

Collected Steps per Second: 22,438.96962
Overall Steps per Second: 10,617.33905

Timestep Collection Time: 2.22853
Timestep Consumption Time: 2.48131
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.70984

Cumulative Model Updates: 51,164
Cumulative Timesteps: 426,736,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 426736884...
Checkpoint 426736884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,744.51572
Policy Entropy: 3.72607
Value Function Loss: 0.05210

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.46315
Value Function Update Magnitude: 0.73035

Collected Steps per Second: 22,906.28665
Overall Steps per Second: 10,823.77420

Timestep Collection Time: 2.18298
Timestep Consumption Time: 2.43685
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61983

Cumulative Model Updates: 51,170
Cumulative Timesteps: 426,786,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,370.84160
Policy Entropy: 3.72905
Value Function Loss: 0.05041

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.47116
Value Function Update Magnitude: 0.83636

Collected Steps per Second: 22,520.28708
Overall Steps per Second: 10,579.63418

Timestep Collection Time: 2.22058
Timestep Consumption Time: 2.50624
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.72682

Cumulative Model Updates: 51,176
Cumulative Timesteps: 426,836,896

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 426836896...
Checkpoint 426836896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,539.25806
Policy Entropy: 3.72864
Value Function Loss: 0.04955

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.47864
Value Function Update Magnitude: 0.83022

Collected Steps per Second: 22,852.75010
Overall Steps per Second: 10,678.49514

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.49568
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.68474

Cumulative Model Updates: 51,182
Cumulative Timesteps: 426,886,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,968.29491
Policy Entropy: 3.73183
Value Function Loss: 0.05125

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.51149
Value Function Update Magnitude: 0.71229

Collected Steps per Second: 23,003.84932
Overall Steps per Second: 10,873.74614

Timestep Collection Time: 2.17381
Timestep Consumption Time: 2.42497
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.59878

Cumulative Model Updates: 51,188
Cumulative Timesteps: 426,936,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 426936928...
Checkpoint 426936928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,304.18939
Policy Entropy: 3.72025
Value Function Loss: 0.05101

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06349
Policy Update Magnitude: 0.59963
Value Function Update Magnitude: 0.66229

Collected Steps per Second: 22,631.62890
Overall Steps per Second: 10,562.88957

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.52587
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.73658

Cumulative Model Updates: 51,194
Cumulative Timesteps: 426,986,960

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,878.97203
Policy Entropy: 3.71846
Value Function Loss: 0.05209

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07114
Policy Update Magnitude: 0.62689
Value Function Update Magnitude: 0.61423

Collected Steps per Second: 22,753.81083
Overall Steps per Second: 10,677.06779

Timestep Collection Time: 2.19770
Timestep Consumption Time: 2.48580
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.68350

Cumulative Model Updates: 51,200
Cumulative Timesteps: 427,036,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 427036966...
Checkpoint 427036966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,253.62683
Policy Entropy: 3.71490
Value Function Loss: 0.05352

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.63061
Value Function Update Magnitude: 0.59319

Collected Steps per Second: 22,786.24191
Overall Steps per Second: 10,817.46284

Timestep Collection Time: 2.19448
Timestep Consumption Time: 2.42804
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.62253

Cumulative Model Updates: 51,206
Cumulative Timesteps: 427,086,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,125.28076
Policy Entropy: 3.71526
Value Function Loss: 0.05538

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.57799
Value Function Update Magnitude: 0.63354

Collected Steps per Second: 22,850.38259
Overall Steps per Second: 10,680.19859

Timestep Collection Time: 2.18858
Timestep Consumption Time: 2.49391
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.68250

Cumulative Model Updates: 51,212
Cumulative Timesteps: 427,136,980

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 427136980...
Checkpoint 427136980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,255.63581
Policy Entropy: 3.71355
Value Function Loss: 0.05658

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.53050
Value Function Update Magnitude: 0.65965

Collected Steps per Second: 22,751.79370
Overall Steps per Second: 10,706.88215

Timestep Collection Time: 2.19886
Timestep Consumption Time: 2.47365
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.67251

Cumulative Model Updates: 51,218
Cumulative Timesteps: 427,187,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,294.88186
Policy Entropy: 3.70311
Value Function Loss: 0.05769

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.49176
Value Function Update Magnitude: 0.67783

Collected Steps per Second: 22,989.08706
Overall Steps per Second: 10,701.24280

Timestep Collection Time: 2.17503
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.67254

Cumulative Model Updates: 51,224
Cumulative Timesteps: 427,237,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 427237010...
Checkpoint 427237010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,686.20012
Policy Entropy: 3.71571
Value Function Loss: 0.05584

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10506
Policy Update Magnitude: 0.47952
Value Function Update Magnitude: 0.65909

Collected Steps per Second: 22,710.87548
Overall Steps per Second: 10,613.30242

Timestep Collection Time: 2.20159
Timestep Consumption Time: 2.50948
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.71107

Cumulative Model Updates: 51,230
Cumulative Timesteps: 427,287,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,908.15049
Policy Entropy: 3.71833
Value Function Loss: 0.05572

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.51160
Value Function Update Magnitude: 0.66412

Collected Steps per Second: 22,667.60059
Overall Steps per Second: 10,781.10371

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.63793

Cumulative Model Updates: 51,236
Cumulative Timesteps: 427,337,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 427337012...
Checkpoint 427337012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,541.61049
Policy Entropy: 3.72079
Value Function Loss: 0.05424

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.50574
Value Function Update Magnitude: 0.70237

Collected Steps per Second: 22,645.53663
Overall Steps per Second: 10,793.82321

Timestep Collection Time: 2.20838
Timestep Consumption Time: 2.42482
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.63321

Cumulative Model Updates: 51,242
Cumulative Timesteps: 427,387,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,014.47657
Policy Entropy: 3.71644
Value Function Loss: 0.05459

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.56130
Value Function Update Magnitude: 0.67829

Collected Steps per Second: 22,634.61302
Overall Steps per Second: 10,776.48712

Timestep Collection Time: 2.20962
Timestep Consumption Time: 2.43141
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.64103

Cumulative Model Updates: 51,248
Cumulative Timesteps: 427,437,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 427437036...
Checkpoint 427437036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,729.06902
Policy Entropy: 3.72275
Value Function Loss: 0.05295

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.54837
Value Function Update Magnitude: 0.72879

Collected Steps per Second: 22,552.59374
Overall Steps per Second: 10,711.43253

Timestep Collection Time: 2.21748
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.66884

Cumulative Model Updates: 51,254
Cumulative Timesteps: 427,487,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,181.10683
Policy Entropy: 3.72742
Value Function Loss: 0.05404

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.53548
Value Function Update Magnitude: 0.74220

Collected Steps per Second: 22,000.16882
Overall Steps per Second: 10,676.49273

Timestep Collection Time: 2.27344
Timestep Consumption Time: 2.41125
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.68468

Cumulative Model Updates: 51,260
Cumulative Timesteps: 427,537,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 427537062...
Checkpoint 427537062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,197.61624
Policy Entropy: 3.72541
Value Function Loss: 0.05325

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.61445
Value Function Update Magnitude: 0.73672

Collected Steps per Second: 22,153.91986
Overall Steps per Second: 10,849.47563

Timestep Collection Time: 2.25748
Timestep Consumption Time: 2.35215
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.60962

Cumulative Model Updates: 51,266
Cumulative Timesteps: 427,587,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,481.53527
Policy Entropy: 3.72603
Value Function Loss: 0.05733

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.63297
Value Function Update Magnitude: 0.66734

Collected Steps per Second: 21,892.37914
Overall Steps per Second: 10,648.67055

Timestep Collection Time: 2.28490
Timestep Consumption Time: 2.41258
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.69749

Cumulative Model Updates: 51,272
Cumulative Timesteps: 427,637,096

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 427637096...
Checkpoint 427637096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,243.06703
Policy Entropy: 3.72680
Value Function Loss: 0.05818

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.56469
Value Function Update Magnitude: 0.66774

Collected Steps per Second: 22,127.05447
Overall Steps per Second: 10,848.75169

Timestep Collection Time: 2.26022
Timestep Consumption Time: 2.34971
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.60993

Cumulative Model Updates: 51,278
Cumulative Timesteps: 427,687,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,972.82606
Policy Entropy: 3.71664
Value Function Loss: 0.05955

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.49902
Value Function Update Magnitude: 0.64606

Collected Steps per Second: 22,135.72929
Overall Steps per Second: 10,727.79533

Timestep Collection Time: 2.25997
Timestep Consumption Time: 2.40325
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.66321

Cumulative Model Updates: 51,284
Cumulative Timesteps: 427,737,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 427737134...
Checkpoint 427737134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,243.64330
Policy Entropy: 3.72069
Value Function Loss: 0.05599

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.54101
Value Function Update Magnitude: 0.66881

Collected Steps per Second: 22,308.03930
Overall Steps per Second: 10,660.75022

Timestep Collection Time: 2.24260
Timestep Consumption Time: 2.45013
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.69273

Cumulative Model Updates: 51,290
Cumulative Timesteps: 427,787,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,705.38900
Policy Entropy: 3.72025
Value Function Loss: 0.05266

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07315
Policy Update Magnitude: 0.63486
Value Function Update Magnitude: 0.75172

Collected Steps per Second: 22,703.12948
Overall Steps per Second: 10,701.24591

Timestep Collection Time: 2.20304
Timestep Consumption Time: 2.47080
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.67385

Cumulative Model Updates: 51,296
Cumulative Timesteps: 427,837,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 427837178...
Checkpoint 427837178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,249.44469
Policy Entropy: 3.71505
Value Function Loss: 0.05161

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.62491
Value Function Update Magnitude: 0.82839

Collected Steps per Second: 22,870.18017
Overall Steps per Second: 10,761.85886

Timestep Collection Time: 2.18643
Timestep Consumption Time: 2.45998
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.64641

Cumulative Model Updates: 51,302
Cumulative Timesteps: 427,887,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,142.23719
Policy Entropy: 3.70665
Value Function Loss: 0.05141

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06872
Policy Update Magnitude: 0.64168
Value Function Update Magnitude: 0.79830

Collected Steps per Second: 23,027.95406
Overall Steps per Second: 10,762.58371

Timestep Collection Time: 2.17214
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.64758

Cumulative Model Updates: 51,308
Cumulative Timesteps: 427,937,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 427937202...
Checkpoint 427937202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,180.85600
Policy Entropy: 3.69722
Value Function Loss: 0.05505

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.64004
Value Function Update Magnitude: 0.69399

Collected Steps per Second: 22,611.81517
Overall Steps per Second: 10,654.79153

Timestep Collection Time: 2.21238
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.69516

Cumulative Model Updates: 51,314
Cumulative Timesteps: 427,987,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,287.23709
Policy Entropy: 3.70559
Value Function Loss: 0.05475

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.60835
Value Function Update Magnitude: 0.69443

Collected Steps per Second: 23,167.25011
Overall Steps per Second: 10,891.53409

Timestep Collection Time: 2.15874
Timestep Consumption Time: 2.43309
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59182

Cumulative Model Updates: 51,320
Cumulative Timesteps: 428,037,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 428037240...
Checkpoint 428037240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,577.22025
Policy Entropy: 3.70620
Value Function Loss: 0.05604

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.50850
Value Function Update Magnitude: 0.75608

Collected Steps per Second: 22,705.34860
Overall Steps per Second: 10,655.22156

Timestep Collection Time: 2.20274
Timestep Consumption Time: 2.49111
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.69385

Cumulative Model Updates: 51,326
Cumulative Timesteps: 428,087,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,747.28125
Policy Entropy: 3.71064
Value Function Loss: 0.05591

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.51740
Value Function Update Magnitude: 0.70049

Collected Steps per Second: 22,733.17981
Overall Steps per Second: 10,636.68682

Timestep Collection Time: 2.20075
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.70353

Cumulative Model Updates: 51,332
Cumulative Timesteps: 428,137,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 428137284...
Checkpoint 428137284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,962.67103
Policy Entropy: 3.69627
Value Function Loss: 0.05866

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.63889

Collected Steps per Second: 22,725.91640
Overall Steps per Second: 10,787.51119

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.43486
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.63499

Cumulative Model Updates: 51,338
Cumulative Timesteps: 428,187,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,985.17979
Policy Entropy: 3.70353
Value Function Loss: 0.05794

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.53961
Value Function Update Magnitude: 0.62498

Collected Steps per Second: 22,709.47825
Overall Steps per Second: 10,621.85965

Timestep Collection Time: 2.20216
Timestep Consumption Time: 2.50605
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.70822

Cumulative Model Updates: 51,344
Cumulative Timesteps: 428,237,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 428237294...
Checkpoint 428237294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,559.53342
Policy Entropy: 3.69945
Value Function Loss: 0.06000

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.48380
Value Function Update Magnitude: 0.60855

Collected Steps per Second: 22,471.18227
Overall Steps per Second: 10,570.18478

Timestep Collection Time: 2.22605
Timestep Consumption Time: 2.50632
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.73237

Cumulative Model Updates: 51,350
Cumulative Timesteps: 428,287,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,615.86327
Policy Entropy: 3.70193
Value Function Loss: 0.05696

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.46024
Value Function Update Magnitude: 0.59497

Collected Steps per Second: 22,876.81845
Overall Steps per Second: 10,810.95097

Timestep Collection Time: 2.18702
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.62790

Cumulative Model Updates: 51,356
Cumulative Timesteps: 428,337,348

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 428337348...
Checkpoint 428337348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,413.98262
Policy Entropy: 3.70772
Value Function Loss: 0.05787

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.46902
Value Function Update Magnitude: 0.65646

Collected Steps per Second: 22,649.76438
Overall Steps per Second: 10,711.53840

Timestep Collection Time: 2.20885
Timestep Consumption Time: 2.46181
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.67066

Cumulative Model Updates: 51,362
Cumulative Timesteps: 428,387,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,052.94730
Policy Entropy: 3.70047
Value Function Loss: 0.05613

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.45918
Value Function Update Magnitude: 0.61594

Collected Steps per Second: 22,809.58276
Overall Steps per Second: 10,708.51781

Timestep Collection Time: 2.19276
Timestep Consumption Time: 2.47791
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.67067

Cumulative Model Updates: 51,368
Cumulative Timesteps: 428,437,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 428437394...
Checkpoint 428437394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,719.80085
Policy Entropy: 3.69348
Value Function Loss: 0.05748

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.44002
Value Function Update Magnitude: 0.60612

Collected Steps per Second: 22,778.22678
Overall Steps per Second: 10,835.37369

Timestep Collection Time: 2.19561
Timestep Consumption Time: 2.42002
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.61562

Cumulative Model Updates: 51,374
Cumulative Timesteps: 428,487,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,536.09374
Policy Entropy: 3.68126
Value Function Loss: 0.05919

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.48084
Value Function Update Magnitude: 0.58146

Collected Steps per Second: 22,573.64062
Overall Steps per Second: 10,655.05011

Timestep Collection Time: 2.21506
Timestep Consumption Time: 2.47774
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.69280

Cumulative Model Updates: 51,380
Cumulative Timesteps: 428,537,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 428537408...
Checkpoint 428537408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,803.32136
Policy Entropy: 3.67893
Value Function Loss: 0.05967

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.48922
Value Function Update Magnitude: 0.60193

Collected Steps per Second: 22,820.05580
Overall Steps per Second: 10,843.01304

Timestep Collection Time: 2.19123
Timestep Consumption Time: 2.42040
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.61163

Cumulative Model Updates: 51,386
Cumulative Timesteps: 428,587,412

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,868.47646
Policy Entropy: 3.67785
Value Function Loss: 0.05958

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.48946
Value Function Update Magnitude: 0.60406

Collected Steps per Second: 22,025.47745
Overall Steps per Second: 10,637.00423

Timestep Collection Time: 2.27128
Timestep Consumption Time: 2.43174
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.70302

Cumulative Model Updates: 51,392
Cumulative Timesteps: 428,637,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 428637438...
Checkpoint 428637438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,739.74386
Policy Entropy: 3.70038
Value Function Loss: 0.05828

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.48423
Value Function Update Magnitude: 0.64420

Collected Steps per Second: 22,053.61904
Overall Steps per Second: 10,686.50096

Timestep Collection Time: 2.26784
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68011

Cumulative Model Updates: 51,398
Cumulative Timesteps: 428,687,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,435.56367
Policy Entropy: 3.69876
Value Function Loss: 0.05691

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.53379
Value Function Update Magnitude: 0.70807

Collected Steps per Second: 22,463.81135
Overall Steps per Second: 10,770.52553

Timestep Collection Time: 2.22589
Timestep Consumption Time: 2.41659
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.64248

Cumulative Model Updates: 51,404
Cumulative Timesteps: 428,737,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 428737454...
Checkpoint 428737454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,317.37886
Policy Entropy: 3.70331
Value Function Loss: 0.05334

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.51151
Value Function Update Magnitude: 0.78520

Collected Steps per Second: 21,787.51845
Overall Steps per Second: 10,604.16874

Timestep Collection Time: 2.29526
Timestep Consumption Time: 2.42062
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.71588

Cumulative Model Updates: 51,410
Cumulative Timesteps: 428,787,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.72957
Policy Entropy: 3.71001
Value Function Loss: 0.05101

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.47318
Value Function Update Magnitude: 0.85643

Collected Steps per Second: 22,398.55233
Overall Steps per Second: 10,899.50517

Timestep Collection Time: 2.23255
Timestep Consumption Time: 2.35536
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.58791

Cumulative Model Updates: 51,416
Cumulative Timesteps: 428,837,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 428837468...
Checkpoint 428837468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,815.32102
Policy Entropy: 3.72205
Value Function Loss: 0.05028

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.48025
Value Function Update Magnitude: 0.87126

Collected Steps per Second: 21,969.93451
Overall Steps per Second: 10,663.78174

Timestep Collection Time: 2.27811
Timestep Consumption Time: 2.41534
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.69346

Cumulative Model Updates: 51,422
Cumulative Timesteps: 428,887,518

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,967.60369
Policy Entropy: 3.72652
Value Function Loss: 0.05266

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.47157
Value Function Update Magnitude: 0.86503

Collected Steps per Second: 22,105.60188
Overall Steps per Second: 10,832.41356

Timestep Collection Time: 2.26332
Timestep Consumption Time: 2.35541
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.61873

Cumulative Model Updates: 51,428
Cumulative Timesteps: 428,937,550

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 428937550...
Checkpoint 428937550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,061.19291
Policy Entropy: 3.72800
Value Function Loss: 0.05314

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.45090
Value Function Update Magnitude: 0.79767

Collected Steps per Second: 21,956.68298
Overall Steps per Second: 10,697.03094

Timestep Collection Time: 2.27721
Timestep Consumption Time: 2.39698
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.67419

Cumulative Model Updates: 51,434
Cumulative Timesteps: 428,987,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,302.36108
Policy Entropy: 3.73360
Value Function Loss: 0.05450

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09266
Policy Update Magnitude: 0.44930
Value Function Update Magnitude: 0.77082

Collected Steps per Second: 22,282.81584
Overall Steps per Second: 10,611.26312

Timestep Collection Time: 2.24424
Timestep Consumption Time: 2.46849
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.71273

Cumulative Model Updates: 51,440
Cumulative Timesteps: 429,037,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 429037558...
Checkpoint 429037558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,081.44671
Policy Entropy: 3.72304
Value Function Loss: 0.05296

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.46232
Value Function Update Magnitude: 0.73075

Collected Steps per Second: 22,902.79691
Overall Steps per Second: 10,899.56887

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.40429
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.58752

Cumulative Model Updates: 51,446
Cumulative Timesteps: 429,087,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,642.69708
Policy Entropy: 3.72438
Value Function Loss: 0.05266

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.47467
Value Function Update Magnitude: 0.74066

Collected Steps per Second: 22,755.04331
Overall Steps per Second: 10,853.58838

Timestep Collection Time: 2.19837
Timestep Consumption Time: 2.41061
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.60898

Cumulative Model Updates: 51,452
Cumulative Timesteps: 429,137,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 429137584...
Checkpoint 429137584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,647.51092
Policy Entropy: 3.72551
Value Function Loss: 0.05081

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.46686
Value Function Update Magnitude: 0.78205

Collected Steps per Second: 22,586.88106
Overall Steps per Second: 10,748.73022

Timestep Collection Time: 2.21465
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.65376

Cumulative Model Updates: 51,458
Cumulative Timesteps: 429,187,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,187.27294
Policy Entropy: 3.73711
Value Function Loss: 0.05362

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.48821
Value Function Update Magnitude: 0.79904

Collected Steps per Second: 22,776.05805
Overall Steps per Second: 10,828.14037

Timestep Collection Time: 2.19608
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.61926

Cumulative Model Updates: 51,464
Cumulative Timesteps: 429,237,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 429237624...
Checkpoint 429237624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,953.35098
Policy Entropy: 3.72362
Value Function Loss: 0.05542

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.52178
Value Function Update Magnitude: 0.87002

Collected Steps per Second: 22,587.97984
Overall Steps per Second: 10,749.14743

Timestep Collection Time: 2.21357
Timestep Consumption Time: 2.43796
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.65153

Cumulative Model Updates: 51,470
Cumulative Timesteps: 429,287,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,671.57852
Policy Entropy: 3.71594
Value Function Loss: 0.05677

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.53041
Value Function Update Magnitude: 0.80955

Collected Steps per Second: 22,652.30523
Overall Steps per Second: 10,604.12742

Timestep Collection Time: 2.20799
Timestep Consumption Time: 2.50867
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.71665

Cumulative Model Updates: 51,476
Cumulative Timesteps: 429,337,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 429337640...
Checkpoint 429337640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,356.08060
Policy Entropy: 3.70781
Value Function Loss: 0.05571

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.51695
Value Function Update Magnitude: 0.66474

Collected Steps per Second: 22,977.82947
Overall Steps per Second: 10,862.05076

Timestep Collection Time: 2.17627
Timestep Consumption Time: 2.42746
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.60373

Cumulative Model Updates: 51,482
Cumulative Timesteps: 429,387,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,727.14173
Policy Entropy: 3.71501
Value Function Loss: 0.05261

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.49848
Value Function Update Magnitude: 0.62685

Collected Steps per Second: 23,064.67778
Overall Steps per Second: 10,898.25566

Timestep Collection Time: 2.16799
Timestep Consumption Time: 2.42027
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.58826

Cumulative Model Updates: 51,488
Cumulative Timesteps: 429,437,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 429437650...
Checkpoint 429437650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,009.08203
Policy Entropy: 3.72353
Value Function Loss: 0.04872

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.49766
Value Function Update Magnitude: 0.67775

Collected Steps per Second: 22,390.59591
Overall Steps per Second: 10,759.65806

Timestep Collection Time: 2.23362
Timestep Consumption Time: 2.41449
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.64810

Cumulative Model Updates: 51,494
Cumulative Timesteps: 429,487,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,553.64808
Policy Entropy: 3.73481
Value Function Loss: 0.04903

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.51704
Value Function Update Magnitude: 0.67217

Collected Steps per Second: 23,019.78205
Overall Steps per Second: 10,829.64079

Timestep Collection Time: 2.17248
Timestep Consumption Time: 2.44540
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.61788

Cumulative Model Updates: 51,500
Cumulative Timesteps: 429,537,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 429537672...
Checkpoint 429537672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,407.49517
Policy Entropy: 3.73719
Value Function Loss: 0.04796

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.50980
Value Function Update Magnitude: 0.69254

Collected Steps per Second: 22,447.79409
Overall Steps per Second: 10,639.61768

Timestep Collection Time: 2.22846
Timestep Consumption Time: 2.47321
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.70167

Cumulative Model Updates: 51,506
Cumulative Timesteps: 429,587,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,591.36692
Policy Entropy: 3.73310
Value Function Loss: 0.04978

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.46189
Value Function Update Magnitude: 0.74006

Collected Steps per Second: 22,922.61405
Overall Steps per Second: 10,846.46551

Timestep Collection Time: 2.18247
Timestep Consumption Time: 2.42990
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.61238

Cumulative Model Updates: 51,512
Cumulative Timesteps: 429,637,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 429637724...
Checkpoint 429637724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,969.99740
Policy Entropy: 3.73454
Value Function Loss: 0.04842

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.47449
Value Function Update Magnitude: 0.79904

Collected Steps per Second: 22,570.29982
Overall Steps per Second: 10,723.11027

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.44870
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.66506

Cumulative Model Updates: 51,518
Cumulative Timesteps: 429,687,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,681.37376
Policy Entropy: 3.73684
Value Function Loss: 0.05005

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10612
Policy Update Magnitude: 0.46016
Value Function Update Magnitude: 0.83802

Collected Steps per Second: 22,834.50190
Overall Steps per Second: 10,818.44976

Timestep Collection Time: 2.19072
Timestep Consumption Time: 2.43323
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62395

Cumulative Model Updates: 51,524
Cumulative Timesteps: 429,737,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 429737772...
Checkpoint 429737772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,211.94677
Policy Entropy: 3.73524
Value Function Loss: 0.05322

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.46876
Value Function Update Magnitude: 0.83504

Collected Steps per Second: 22,531.88222
Overall Steps per Second: 10,772.06727

Timestep Collection Time: 2.22032
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.64423

Cumulative Model Updates: 51,530
Cumulative Timesteps: 429,787,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,900.77035
Policy Entropy: 3.72029
Value Function Loss: 0.05700

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.48718
Value Function Update Magnitude: 0.83791

Collected Steps per Second: 22,874.09418
Overall Steps per Second: 10,835.02108

Timestep Collection Time: 2.18710
Timestep Consumption Time: 2.43015
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.61725

Cumulative Model Updates: 51,536
Cumulative Timesteps: 429,837,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 429837828...
Checkpoint 429837828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,970.40563
Policy Entropy: 3.72430
Value Function Loss: 0.05746

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.50161
Value Function Update Magnitude: 0.78517

Collected Steps per Second: 22,683.17555
Overall Steps per Second: 10,673.71022

Timestep Collection Time: 2.20551
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.68703

Cumulative Model Updates: 51,542
Cumulative Timesteps: 429,887,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,315.91817
Policy Entropy: 3.72638
Value Function Loss: 0.05612

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.53954
Value Function Update Magnitude: 0.66620

Collected Steps per Second: 22,598.27663
Overall Steps per Second: 10,627.83895

Timestep Collection Time: 2.21256
Timestep Consumption Time: 2.49207
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.70463

Cumulative Model Updates: 51,548
Cumulative Timesteps: 429,937,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 429937856...
Checkpoint 429937856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,931.81782
Policy Entropy: 3.73149
Value Function Loss: 0.05487

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.51722
Value Function Update Magnitude: 0.65375

Collected Steps per Second: 22,453.48699
Overall Steps per Second: 10,606.54504

Timestep Collection Time: 2.22754
Timestep Consumption Time: 2.48804
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.71558

Cumulative Model Updates: 51,554
Cumulative Timesteps: 429,987,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,083.93857
Policy Entropy: 3.73606
Value Function Loss: 0.05409

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.51979
Value Function Update Magnitude: 0.70848

Collected Steps per Second: 23,329.75321
Overall Steps per Second: 10,742.96163

Timestep Collection Time: 2.14387
Timestep Consumption Time: 2.51183
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.65570

Cumulative Model Updates: 51,560
Cumulative Timesteps: 430,037,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 430037888...
Checkpoint 430037888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,769.31163
Policy Entropy: 3.73727
Value Function Loss: 0.05237

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.59354
Value Function Update Magnitude: 0.81984

Collected Steps per Second: 22,679.36040
Overall Steps per Second: 10,656.56859

Timestep Collection Time: 2.20597
Timestep Consumption Time: 2.48879
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.69476

Cumulative Model Updates: 51,566
Cumulative Timesteps: 430,087,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,603.45720
Policy Entropy: 3.73031
Value Function Loss: 0.05275

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.54145
Value Function Update Magnitude: 0.80914

Collected Steps per Second: 22,570.49014
Overall Steps per Second: 10,639.29029

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.48537
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.70163

Cumulative Model Updates: 51,572
Cumulative Timesteps: 430,137,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 430137940...
Checkpoint 430137940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,353.30736
Policy Entropy: 3.71803
Value Function Loss: 0.05430

Mean KL Divergence: 0.02044
SB3 Clip Fraction: 0.16136
Policy Update Magnitude: 0.44339
Value Function Update Magnitude: 0.71035

Collected Steps per Second: 22,696.09646
Overall Steps per Second: 10,823.09967

Timestep Collection Time: 2.20426
Timestep Consumption Time: 2.41808
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.62234

Cumulative Model Updates: 51,578
Cumulative Timesteps: 430,187,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.73173
Policy Entropy: 3.70921
Value Function Loss: 0.05923

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.43237
Value Function Update Magnitude: 0.71373

Collected Steps per Second: 22,883.57255
Overall Steps per Second: 10,717.51827

Timestep Collection Time: 2.18637
Timestep Consumption Time: 2.48187
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.66824

Cumulative Model Updates: 51,584
Cumulative Timesteps: 430,238,000

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 430238000...
Checkpoint 430238000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,283.30524
Policy Entropy: 3.70125
Value Function Loss: 0.05919

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.50985
Value Function Update Magnitude: 0.74662

Collected Steps per Second: 22,998.20334
Overall Steps per Second: 10,876.06078

Timestep Collection Time: 2.17426
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.59762

Cumulative Model Updates: 51,590
Cumulative Timesteps: 430,288,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,733.86972
Policy Entropy: 3.69261
Value Function Loss: 0.05809

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.51555
Value Function Update Magnitude: 0.72124

Collected Steps per Second: 22,783.08242
Overall Steps per Second: 10,666.76311

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.49384
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.68933

Cumulative Model Updates: 51,596
Cumulative Timesteps: 430,338,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 430338024...
Checkpoint 430338024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,356.82150
Policy Entropy: 3.68855
Value Function Loss: 0.05813

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07883
Policy Update Magnitude: 0.55320
Value Function Update Magnitude: 0.64937

Collected Steps per Second: 22,818.71896
Overall Steps per Second: 10,847.47321

Timestep Collection Time: 2.19215
Timestep Consumption Time: 2.41925
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.61140

Cumulative Model Updates: 51,602
Cumulative Timesteps: 430,388,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,924.57863
Policy Entropy: 3.67639
Value Function Loss: 0.05676

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.61804
Value Function Update Magnitude: 0.65408

Collected Steps per Second: 22,961.03651
Overall Steps per Second: 10,705.69691

Timestep Collection Time: 2.17882
Timestep Consumption Time: 2.49420
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.67303

Cumulative Model Updates: 51,608
Cumulative Timesteps: 430,438,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 430438074...
Checkpoint 430438074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,297.79770
Policy Entropy: 3.68782
Value Function Loss: 0.05461

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.51304
Value Function Update Magnitude: 0.69178

Collected Steps per Second: 23,052.60550
Overall Steps per Second: 10,935.30514

Timestep Collection Time: 2.16921
Timestep Consumption Time: 2.40368
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.57289

Cumulative Model Updates: 51,614
Cumulative Timesteps: 430,488,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,237.71633
Policy Entropy: 3.69208
Value Function Loss: 0.05250

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.45551
Value Function Update Magnitude: 0.63304

Collected Steps per Second: 22,854.55994
Overall Steps per Second: 10,817.35854

Timestep Collection Time: 2.18845
Timestep Consumption Time: 2.43523
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.62368

Cumulative Model Updates: 51,620
Cumulative Timesteps: 430,538,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 430538096...
Checkpoint 430538096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,629.25667
Policy Entropy: 3.69975
Value Function Loss: 0.05068

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06145
Policy Update Magnitude: 0.56061
Value Function Update Magnitude: 0.67155

Collected Steps per Second: 22,785.47201
Overall Steps per Second: 10,682.53946

Timestep Collection Time: 2.19473
Timestep Consumption Time: 2.48655
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.68128

Cumulative Model Updates: 51,626
Cumulative Timesteps: 430,588,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.98069
Policy Entropy: 3.69732
Value Function Loss: 0.04978

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06304
Policy Update Magnitude: 0.67328
Value Function Update Magnitude: 0.80680

Collected Steps per Second: 22,917.91969
Overall Steps per Second: 10,869.79863

Timestep Collection Time: 2.18222
Timestep Consumption Time: 2.41878
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60101

Cumulative Model Updates: 51,632
Cumulative Timesteps: 430,638,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 430638116...
Checkpoint 430638116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,387.29257
Policy Entropy: 3.69074
Value Function Loss: 0.05117

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06803
Policy Update Magnitude: 0.68181
Value Function Update Magnitude: 0.81977

Collected Steps per Second: 22,078.06034
Overall Steps per Second: 10,700.86996

Timestep Collection Time: 2.26469
Timestep Consumption Time: 2.40783
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.67252

Cumulative Model Updates: 51,638
Cumulative Timesteps: 430,688,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,776.26733
Policy Entropy: 3.67569
Value Function Loss: 0.05447

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.64538
Value Function Update Magnitude: 0.77195

Collected Steps per Second: 22,272.58238
Overall Steps per Second: 10,860.35212

Timestep Collection Time: 2.24653
Timestep Consumption Time: 2.36069
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60722

Cumulative Model Updates: 51,644
Cumulative Timesteps: 430,738,152

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 430738152...
Checkpoint 430738152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,421.84059
Policy Entropy: 3.67874
Value Function Loss: 0.05548

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.53303
Value Function Update Magnitude: 0.75556

Collected Steps per Second: 21,983.33373
Overall Steps per Second: 10,684.30517

Timestep Collection Time: 2.27445
Timestep Consumption Time: 2.40531
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.67976

Cumulative Model Updates: 51,650
Cumulative Timesteps: 430,788,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,759.30687
Policy Entropy: 3.67964
Value Function Loss: 0.05429

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.47362
Value Function Update Magnitude: 0.78984

Collected Steps per Second: 22,131.99942
Overall Steps per Second: 10,544.92678

Timestep Collection Time: 2.25971
Timestep Consumption Time: 2.48304
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.74275

Cumulative Model Updates: 51,656
Cumulative Timesteps: 430,838,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 430838164...
Checkpoint 430838164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,881.30099
Policy Entropy: 3.68499
Value Function Loss: 0.05222

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.49092
Value Function Update Magnitude: 0.83080

Collected Steps per Second: 22,674.45506
Overall Steps per Second: 10,695.44652

Timestep Collection Time: 2.20583
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.67638

Cumulative Model Updates: 51,662
Cumulative Timesteps: 430,888,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,054.04990
Policy Entropy: 3.69303
Value Function Loss: 0.05102

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.82177

Collected Steps per Second: 22,873.21625
Overall Steps per Second: 10,717.22287

Timestep Collection Time: 2.18640
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.66632

Cumulative Model Updates: 51,668
Cumulative Timesteps: 430,938,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 430938190...
Checkpoint 430938190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,060.88823
Policy Entropy: 3.70178
Value Function Loss: 0.04856

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11348
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.85535

Collected Steps per Second: 22,517.71960
Overall Steps per Second: 10,614.90491

Timestep Collection Time: 2.22181
Timestep Consumption Time: 2.49138
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.71318

Cumulative Model Updates: 51,674
Cumulative Timesteps: 430,988,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,851.74756
Policy Entropy: 3.70409
Value Function Loss: 0.04871

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.52556
Value Function Update Magnitude: 0.84322

Collected Steps per Second: 22,909.39623
Overall Steps per Second: 10,880.31521

Timestep Collection Time: 2.18347
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.59748

Cumulative Model Updates: 51,680
Cumulative Timesteps: 431,038,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 431038242...
Checkpoint 431038242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,072.18821
Policy Entropy: 3.71072
Value Function Loss: 0.04967

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.58854
Value Function Update Magnitude: 0.79516

Collected Steps per Second: 22,804.72189
Overall Steps per Second: 10,735.00956

Timestep Collection Time: 2.19384
Timestep Consumption Time: 2.46661
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.66045

Cumulative Model Updates: 51,686
Cumulative Timesteps: 431,088,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,470.50275
Policy Entropy: 3.71441
Value Function Loss: 0.05264

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.51969
Value Function Update Magnitude: 0.82315

Collected Steps per Second: 22,802.59517
Overall Steps per Second: 10,784.27861

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.44394
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.63694

Cumulative Model Updates: 51,692
Cumulative Timesteps: 431,138,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 431138278...
Checkpoint 431138278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,198.13190
Policy Entropy: 3.74427
Value Function Loss: 0.05099

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.47741
Value Function Update Magnitude: 0.85726

Collected Steps per Second: 22,741.79957
Overall Steps per Second: 10,728.82496

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.46175
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.66034

Cumulative Model Updates: 51,698
Cumulative Timesteps: 431,188,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,121.85430
Policy Entropy: 3.75560
Value Function Loss: 0.04852

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.51911
Value Function Update Magnitude: 0.87133

Collected Steps per Second: 22,865.38155
Overall Steps per Second: 10,824.51045

Timestep Collection Time: 2.18759
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62099

Cumulative Model Updates: 51,704
Cumulative Timesteps: 431,238,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 431238298...
Checkpoint 431238298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,250.98187
Policy Entropy: 3.76308
Value Function Loss: 0.04751

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.85567

Collected Steps per Second: 22,699.16702
Overall Steps per Second: 10,733.75892

Timestep Collection Time: 2.20369
Timestep Consumption Time: 2.45656
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.66025

Cumulative Model Updates: 51,710
Cumulative Timesteps: 431,288,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,861.83544
Policy Entropy: 3.74908
Value Function Loss: 0.04976

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.56004
Value Function Update Magnitude: 0.81769

Collected Steps per Second: 22,682.18029
Overall Steps per Second: 10,648.43996

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.49165
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.69646

Cumulative Model Updates: 51,716
Cumulative Timesteps: 431,338,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 431338330...
Checkpoint 431338330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,213.05544
Policy Entropy: 3.75010
Value Function Loss: 0.05165

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.55788
Value Function Update Magnitude: 0.71459

Collected Steps per Second: 22,561.46015
Overall Steps per Second: 10,627.43720

Timestep Collection Time: 2.21670
Timestep Consumption Time: 2.48923
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.70593

Cumulative Model Updates: 51,722
Cumulative Timesteps: 431,388,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,352.67537
Policy Entropy: 3.75518
Value Function Loss: 0.05177

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.70821

Collected Steps per Second: 23,038.69045
Overall Steps per Second: 10,731.46806

Timestep Collection Time: 2.17156
Timestep Consumption Time: 2.49043
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.66199

Cumulative Model Updates: 51,728
Cumulative Timesteps: 431,438,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 431438372...
Checkpoint 431438372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,690.08828
Policy Entropy: 3.75364
Value Function Loss: 0.05054

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.51557
Value Function Update Magnitude: 0.77937

Collected Steps per Second: 22,459.76509
Overall Steps per Second: 10,622.74928

Timestep Collection Time: 2.22665
Timestep Consumption Time: 2.48117
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.70782

Cumulative Model Updates: 51,734
Cumulative Timesteps: 431,488,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.11843
Policy Entropy: 3.74316
Value Function Loss: 0.05054

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.51198
Value Function Update Magnitude: 0.78281

Collected Steps per Second: 22,789.22428
Overall Steps per Second: 10,699.82091

Timestep Collection Time: 2.19490
Timestep Consumption Time: 2.47995
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.67484

Cumulative Model Updates: 51,740
Cumulative Timesteps: 431,538,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 431538402...
Checkpoint 431538402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,335.12469
Policy Entropy: 3.74420
Value Function Loss: 0.04889

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.57615
Value Function Update Magnitude: 0.81179

Collected Steps per Second: 22,441.59272
Overall Steps per Second: 10,627.18893

Timestep Collection Time: 2.22952
Timestep Consumption Time: 2.47859
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.70811

Cumulative Model Updates: 51,746
Cumulative Timesteps: 431,588,436

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,706.21225
Policy Entropy: 3.71484
Value Function Loss: 0.05232

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.60342
Value Function Update Magnitude: 0.77504

Collected Steps per Second: 22,842.24203
Overall Steps per Second: 10,706.65301

Timestep Collection Time: 2.18972
Timestep Consumption Time: 2.48196
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.67167

Cumulative Model Updates: 51,752
Cumulative Timesteps: 431,638,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 431638454...
Checkpoint 431638454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,494.39532
Policy Entropy: 3.69677
Value Function Loss: 0.05302

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.62853
Value Function Update Magnitude: 0.69008

Collected Steps per Second: 22,664.79645
Overall Steps per Second: 10,715.79497

Timestep Collection Time: 2.20695
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.66788

Cumulative Model Updates: 51,758
Cumulative Timesteps: 431,688,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,231.79169
Policy Entropy: 3.68914
Value Function Loss: 0.05401

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.67011
Value Function Update Magnitude: 0.63013

Collected Steps per Second: 22,912.79201
Overall Steps per Second: 10,834.31764

Timestep Collection Time: 2.18245
Timestep Consumption Time: 2.43307
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.61552

Cumulative Model Updates: 51,764
Cumulative Timesteps: 431,738,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 431738480...
Checkpoint 431738480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,279.99759
Policy Entropy: 3.69646
Value Function Loss: 0.05455

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.68431
Value Function Update Magnitude: 0.64933

Collected Steps per Second: 22,814.88065
Overall Steps per Second: 10,635.51508

Timestep Collection Time: 2.19252
Timestep Consumption Time: 2.51078
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.70330

Cumulative Model Updates: 51,770
Cumulative Timesteps: 431,788,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,454.09403
Policy Entropy: 3.69552
Value Function Loss: 0.05678

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.66824
Value Function Update Magnitude: 0.62042

Collected Steps per Second: 23,090.65416
Overall Steps per Second: 10,859.38511

Timestep Collection Time: 2.16746
Timestep Consumption Time: 2.44128
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60873

Cumulative Model Updates: 51,776
Cumulative Timesteps: 431,838,550

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 431838550...
Checkpoint 431838550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,511.27942
Policy Entropy: 3.69752
Value Function Loss: 0.05612

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.62290
Value Function Update Magnitude: 0.61606

Collected Steps per Second: 22,595.25292
Overall Steps per Second: 10,684.90949

Timestep Collection Time: 2.21294
Timestep Consumption Time: 2.46674
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.67968

Cumulative Model Updates: 51,782
Cumulative Timesteps: 431,888,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,844.29316
Policy Entropy: 3.70021
Value Function Loss: 0.05549

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.53378
Value Function Update Magnitude: 0.63913

Collected Steps per Second: 22,738.90693
Overall Steps per Second: 10,867.83317

Timestep Collection Time: 2.20002
Timestep Consumption Time: 2.40311
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.60313

Cumulative Model Updates: 51,788
Cumulative Timesteps: 431,938,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 431938578...
Checkpoint 431938578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,477.50099
Policy Entropy: 3.70803
Value Function Loss: 0.05293

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.53512
Value Function Update Magnitude: 0.66781

Collected Steps per Second: 22,837.26475
Overall Steps per Second: 10,683.24221

Timestep Collection Time: 2.19107
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.68378

Cumulative Model Updates: 51,794
Cumulative Timesteps: 431,988,616

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,766.66565
Policy Entropy: 3.69602
Value Function Loss: 0.05120

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.59699
Value Function Update Magnitude: 0.72839

Collected Steps per Second: 22,650.73359
Overall Steps per Second: 10,669.47238

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.47973
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.68795

Cumulative Model Updates: 51,800
Cumulative Timesteps: 432,038,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 432038634...
Checkpoint 432038634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,349.31805
Policy Entropy: 3.71283
Value Function Loss: 0.05110

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.57443
Value Function Update Magnitude: 0.73721

Collected Steps per Second: 23,001.28549
Overall Steps per Second: 10,859.44320

Timestep Collection Time: 2.17388
Timestep Consumption Time: 2.43059
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60447

Cumulative Model Updates: 51,806
Cumulative Timesteps: 432,088,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,719.48283
Policy Entropy: 3.70764
Value Function Loss: 0.05265

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.61787
Value Function Update Magnitude: 0.71337

Collected Steps per Second: 22,625.36569
Overall Steps per Second: 10,810.79819

Timestep Collection Time: 2.21070
Timestep Consumption Time: 2.41597
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.62667

Cumulative Model Updates: 51,812
Cumulative Timesteps: 432,138,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 432138654...
Checkpoint 432138654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,006.67669
Policy Entropy: 3.71467
Value Function Loss: 0.05155

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.63179
Value Function Update Magnitude: 0.64996

Collected Steps per Second: 22,253.20904
Overall Steps per Second: 10,771.15784

Timestep Collection Time: 2.24777
Timestep Consumption Time: 2.39612
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.64388

Cumulative Model Updates: 51,818
Cumulative Timesteps: 432,188,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,331.85492
Policy Entropy: 3.71356
Value Function Loss: 0.05119

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.60874
Value Function Update Magnitude: 0.72497

Collected Steps per Second: 22,917.94673
Overall Steps per Second: 10,856.21712

Timestep Collection Time: 2.18283
Timestep Consumption Time: 2.42522
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.60805

Cumulative Model Updates: 51,824
Cumulative Timesteps: 432,238,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 432238700...
Checkpoint 432238700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,775.43784
Policy Entropy: 3.70306
Value Function Loss: 0.05182

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.58146
Value Function Update Magnitude: 0.68755

Collected Steps per Second: 22,758.07558
Overall Steps per Second: 10,688.58109

Timestep Collection Time: 2.19711
Timestep Consumption Time: 2.48097
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.67808

Cumulative Model Updates: 51,830
Cumulative Timesteps: 432,288,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,996.84963
Policy Entropy: 3.70695
Value Function Loss: 0.05361

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.53559
Value Function Update Magnitude: 0.63827

Collected Steps per Second: 22,639.61959
Overall Steps per Second: 10,770.80721

Timestep Collection Time: 2.20922
Timestep Consumption Time: 2.43444
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.64366

Cumulative Model Updates: 51,836
Cumulative Timesteps: 432,338,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 432338718...
Checkpoint 432338718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,487.41124
Policy Entropy: 3.70773
Value Function Loss: 0.05545

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.64408

Collected Steps per Second: 22,655.44230
Overall Steps per Second: 10,779.02167

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.43273
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.64068

Cumulative Model Updates: 51,842
Cumulative Timesteps: 432,388,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,433.68098
Policy Entropy: 3.73823
Value Function Loss: 0.05273

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.66500
Value Function Update Magnitude: 0.67629

Collected Steps per Second: 22,998.04797
Overall Steps per Second: 10,835.40097

Timestep Collection Time: 2.17497
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61635

Cumulative Model Updates: 51,848
Cumulative Timesteps: 432,438,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 432438760...
Checkpoint 432438760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.41489
Policy Entropy: 3.74902
Value Function Loss: 0.04985

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.65329
Value Function Update Magnitude: 0.73675

Collected Steps per Second: 22,887.78159
Overall Steps per Second: 10,722.14500

Timestep Collection Time: 2.18510
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.66437

Cumulative Model Updates: 51,854
Cumulative Timesteps: 432,488,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,282.72752
Policy Entropy: 3.73185
Value Function Loss: 0.05083

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.63235
Value Function Update Magnitude: 0.73540

Collected Steps per Second: 23,173.84810
Overall Steps per Second: 10,882.57377

Timestep Collection Time: 2.15873
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.59689

Cumulative Model Updates: 51,860
Cumulative Timesteps: 432,538,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 432538798...
Checkpoint 432538798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,061.41688
Policy Entropy: 3.71418
Value Function Loss: 0.05389

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.64276
Value Function Update Magnitude: 0.68821

Collected Steps per Second: 22,711.64980
Overall Steps per Second: 10,607.90676

Timestep Collection Time: 2.20160
Timestep Consumption Time: 2.51205
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.71365

Cumulative Model Updates: 51,866
Cumulative Timesteps: 432,588,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,813.53879
Policy Entropy: 3.69282
Value Function Loss: 0.05746

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.62360
Value Function Update Magnitude: 0.71176

Collected Steps per Second: 22,997.94759
Overall Steps per Second: 10,859.83611

Timestep Collection Time: 2.17472
Timestep Consumption Time: 2.43069
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.60541

Cumulative Model Updates: 51,872
Cumulative Timesteps: 432,638,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 432638814...
Checkpoint 432638814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,069.91990
Policy Entropy: 3.70502
Value Function Loss: 0.05684

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.55060
Value Function Update Magnitude: 0.74505

Collected Steps per Second: 22,812.29927
Overall Steps per Second: 10,721.59838

Timestep Collection Time: 2.19276
Timestep Consumption Time: 2.47277
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.66554

Cumulative Model Updates: 51,878
Cumulative Timesteps: 432,688,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,820.17780
Policy Entropy: 3.69313
Value Function Loss: 0.05482

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07257
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.82559

Collected Steps per Second: 22,773.11859
Overall Steps per Second: 10,783.90310

Timestep Collection Time: 2.19575
Timestep Consumption Time: 2.44116
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.63691

Cumulative Model Updates: 51,884
Cumulative Timesteps: 432,738,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 432738840...
Checkpoint 432738840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,559.61226
Policy Entropy: 3.68395
Value Function Loss: 0.05453

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.58054
Value Function Update Magnitude: 0.87320

Collected Steps per Second: 22,407.55662
Overall Steps per Second: 10,715.47646

Timestep Collection Time: 2.23219
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.66783

Cumulative Model Updates: 51,890
Cumulative Timesteps: 432,788,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,248.29474
Policy Entropy: 3.68091
Value Function Loss: 0.05494

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.49848
Value Function Update Magnitude: 0.88222

Collected Steps per Second: 22,769.88096
Overall Steps per Second: 10,682.07981

Timestep Collection Time: 2.19703
Timestep Consumption Time: 2.48615
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.68317

Cumulative Model Updates: 51,896
Cumulative Timesteps: 432,838,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 432838884...
Checkpoint 432838884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,722.97466
Policy Entropy: 3.69422
Value Function Loss: 0.05493

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.45638
Value Function Update Magnitude: 0.83922

Collected Steps per Second: 22,862.97510
Overall Steps per Second: 10,850.93776

Timestep Collection Time: 2.18764
Timestep Consumption Time: 2.42173
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.60937

Cumulative Model Updates: 51,902
Cumulative Timesteps: 432,888,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,862.52326
Policy Entropy: 3.70557
Value Function Loss: 0.05592

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.46984
Value Function Update Magnitude: 0.82972

Collected Steps per Second: 22,590.22170
Overall Steps per Second: 10,592.97563

Timestep Collection Time: 2.21459
Timestep Consumption Time: 2.50817
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.72275

Cumulative Model Updates: 51,908
Cumulative Timesteps: 432,938,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 432938928...
Checkpoint 432938928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,898.42518
Policy Entropy: 3.69888
Value Function Loss: 0.05689

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.52109
Value Function Update Magnitude: 0.86324

Collected Steps per Second: 22,738.16273
Overall Steps per Second: 10,658.56719

Timestep Collection Time: 2.19947
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.69219

Cumulative Model Updates: 51,914
Cumulative Timesteps: 432,988,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,162.25170
Policy Entropy: 3.69670
Value Function Loss: 0.05659

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.59209
Value Function Update Magnitude: 0.88897

Collected Steps per Second: 23,117.29404
Overall Steps per Second: 10,819.34371

Timestep Collection Time: 2.16401
Timestep Consumption Time: 2.45975
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.62376

Cumulative Model Updates: 51,920
Cumulative Timesteps: 433,038,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 433038966...
Checkpoint 433038966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,071.99500
Policy Entropy: 3.69750
Value Function Loss: 0.05428

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.15371
Policy Update Magnitude: 0.52225
Value Function Update Magnitude: 0.88588

Collected Steps per Second: 22,564.63010
Overall Steps per Second: 10,630.60683

Timestep Collection Time: 2.21719
Timestep Consumption Time: 2.48904
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.70622

Cumulative Model Updates: 51,926
Cumulative Timesteps: 433,088,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,340.12111
Policy Entropy: 3.71241
Value Function Loss: 0.05289

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.16085
Policy Update Magnitude: 0.49545
Value Function Update Magnitude: 0.86720

Collected Steps per Second: 22,920.59185
Overall Steps per Second: 10,817.02292

Timestep Collection Time: 2.18153
Timestep Consumption Time: 2.44100
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.62253

Cumulative Model Updates: 51,932
Cumulative Timesteps: 433,138,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 433138998...
Checkpoint 433138998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,803.14508
Policy Entropy: 3.71993
Value Function Loss: 0.05295

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.83750

Collected Steps per Second: 22,576.51395
Overall Steps per Second: 10,705.59163

Timestep Collection Time: 2.21469
Timestep Consumption Time: 2.45577
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.67046

Cumulative Model Updates: 51,938
Cumulative Timesteps: 433,188,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,895.73500
Policy Entropy: 3.72921
Value Function Loss: 0.05380

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.61477
Value Function Update Magnitude: 0.86830

Collected Steps per Second: 22,987.67638
Overall Steps per Second: 10,878.06478

Timestep Collection Time: 2.17586
Timestep Consumption Time: 2.42220
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.59806

Cumulative Model Updates: 51,944
Cumulative Timesteps: 433,239,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 433239016...
Checkpoint 433239016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.36678
Policy Entropy: 3.73350
Value Function Loss: 0.05256

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.63309
Value Function Update Magnitude: 0.86950

Collected Steps per Second: 22,609.79956
Overall Steps per Second: 10,699.20040

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.46339
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.67624

Cumulative Model Updates: 51,950
Cumulative Timesteps: 433,289,048

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,338.27427
Policy Entropy: 3.74547
Value Function Loss: 0.05201

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.55048
Value Function Update Magnitude: 0.82368

Collected Steps per Second: 22,968.78214
Overall Steps per Second: 10,824.31336

Timestep Collection Time: 2.17756
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.62071

Cumulative Model Updates: 51,956
Cumulative Timesteps: 433,339,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 433339064...
Checkpoint 433339064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,861.03742
Policy Entropy: 3.72764
Value Function Loss: 0.05388

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.50126
Value Function Update Magnitude: 0.69059

Collected Steps per Second: 22,671.76528
Overall Steps per Second: 10,681.26599

Timestep Collection Time: 2.20609
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.68259

Cumulative Model Updates: 51,962
Cumulative Timesteps: 433,389,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,936.55049
Policy Entropy: 3.73897
Value Function Loss: 0.05283

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.52867
Value Function Update Magnitude: 0.65116

Collected Steps per Second: 23,014.21207
Overall Steps per Second: 10,863.21581

Timestep Collection Time: 2.17327
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60416

Cumulative Model Updates: 51,968
Cumulative Timesteps: 433,439,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 433439096...
Checkpoint 433439096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.67915
Policy Entropy: 3.74523
Value Function Loss: 0.04974

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.53149
Value Function Update Magnitude: 0.63087

Collected Steps per Second: 22,566.55171
Overall Steps per Second: 10,728.88456

Timestep Collection Time: 2.21700
Timestep Consumption Time: 2.44611
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.66311

Cumulative Model Updates: 51,974
Cumulative Timesteps: 433,489,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,063.43603
Policy Entropy: 3.76045
Value Function Loss: 0.04681

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.53080
Value Function Update Magnitude: 0.67584

Collected Steps per Second: 22,808.02774
Overall Steps per Second: 10,819.08260

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62294

Cumulative Model Updates: 51,980
Cumulative Timesteps: 433,539,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 433539142...
Checkpoint 433539142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,334.09936
Policy Entropy: 3.76107
Value Function Loss: 0.04791

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.56323
Value Function Update Magnitude: 0.67213

Collected Steps per Second: 22,379.06227
Overall Steps per Second: 10,749.07368

Timestep Collection Time: 2.23521
Timestep Consumption Time: 2.41840
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.65361

Cumulative Model Updates: 51,986
Cumulative Timesteps: 433,589,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,938.17053
Policy Entropy: 3.77520
Value Function Loss: 0.04901

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.55004
Value Function Update Magnitude: 0.66725

Collected Steps per Second: 22,952.40003
Overall Steps per Second: 10,855.38827

Timestep Collection Time: 2.17860
Timestep Consumption Time: 2.42778
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.60638

Cumulative Model Updates: 51,992
Cumulative Timesteps: 433,639,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 433639168...
Checkpoint 433639168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,408.42715
Policy Entropy: 3.77517
Value Function Loss: 0.04942

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.55698
Value Function Update Magnitude: 0.66565

Collected Steps per Second: 22,887.98308
Overall Steps per Second: 10,658.77827

Timestep Collection Time: 2.18490
Timestep Consumption Time: 2.50682
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.69172

Cumulative Model Updates: 51,998
Cumulative Timesteps: 433,689,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,122.21832
Policy Entropy: 3.76841
Value Function Loss: 0.04929

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.61503
Value Function Update Magnitude: 0.74219

Collected Steps per Second: 22,395.22025
Overall Steps per Second: 10,597.93472

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.48618
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.71960

Cumulative Model Updates: 52,004
Cumulative Timesteps: 433,739,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 433739194...
Checkpoint 433739194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,234.12393
Policy Entropy: 3.77393
Value Function Loss: 0.04823

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.58233
Value Function Update Magnitude: 0.80480

Collected Steps per Second: 22,716.22128
Overall Steps per Second: 10,672.26568

Timestep Collection Time: 2.20169
Timestep Consumption Time: 2.48467
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.68635

Cumulative Model Updates: 52,010
Cumulative Timesteps: 433,789,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,161.98077
Policy Entropy: 3.77702
Value Function Loss: 0.04798

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.54931
Value Function Update Magnitude: 0.82602

Collected Steps per Second: 22,935.55785
Overall Steps per Second: 10,733.41351

Timestep Collection Time: 2.18028
Timestep Consumption Time: 2.47863
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.65891

Cumulative Model Updates: 52,016
Cumulative Timesteps: 433,839,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 433839214...
Checkpoint 433839214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,322.76049
Policy Entropy: 3.78247
Value Function Loss: 0.04811

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.54672
Value Function Update Magnitude: 0.83398

Collected Steps per Second: 22,729.12426
Overall Steps per Second: 10,654.23780

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.49434
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.69522

Cumulative Model Updates: 52,022
Cumulative Timesteps: 433,889,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,046.49875
Policy Entropy: 3.76703
Value Function Loss: 0.04905

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.54256
Value Function Update Magnitude: 0.85040

Collected Steps per Second: 22,952.03972
Overall Steps per Second: 10,827.58485

Timestep Collection Time: 2.17863
Timestep Consumption Time: 2.43957
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61820

Cumulative Model Updates: 52,028
Cumulative Timesteps: 433,939,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 433939242...
Checkpoint 433939242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,533.44073
Policy Entropy: 3.76125
Value Function Loss: 0.04989

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.44141
Value Function Update Magnitude: 0.86563

Collected Steps per Second: 22,608.54255
Overall Steps per Second: 10,684.47706

Timestep Collection Time: 2.21164
Timestep Consumption Time: 2.46823
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.67987

Cumulative Model Updates: 52,034
Cumulative Timesteps: 433,989,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,289.89099
Policy Entropy: 3.75510
Value Function Loss: 0.04790

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.50787
Value Function Update Magnitude: 0.83639

Collected Steps per Second: 23,112.56939
Overall Steps per Second: 10,929.02909

Timestep Collection Time: 2.16402
Timestep Consumption Time: 2.41242
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.57644

Cumulative Model Updates: 52,040
Cumulative Timesteps: 434,039,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 434039260...
Checkpoint 434039260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,557.44226
Policy Entropy: 3.76068
Value Function Loss: 0.04779

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.85419

Collected Steps per Second: 22,710.92018
Overall Steps per Second: 10,626.12024

Timestep Collection Time: 2.20246
Timestep Consumption Time: 2.50480
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.70727

Cumulative Model Updates: 52,046
Cumulative Timesteps: 434,089,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,196.78874
Policy Entropy: 3.75496
Value Function Loss: 0.04772

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.55857
Value Function Update Magnitude: 0.85616

Collected Steps per Second: 21,940.89896
Overall Steps per Second: 10,765.06388

Timestep Collection Time: 2.28003
Timestep Consumption Time: 2.36704
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.64707

Cumulative Model Updates: 52,052
Cumulative Timesteps: 434,139,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 434139306...
Checkpoint 434139306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,887.19747
Policy Entropy: 3.75335
Value Function Loss: 0.04963

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.54558
Value Function Update Magnitude: 0.82214

Collected Steps per Second: 21,684.57788
Overall Steps per Second: 10,714.22772

Timestep Collection Time: 2.30643
Timestep Consumption Time: 2.36157
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.66800

Cumulative Model Updates: 52,058
Cumulative Timesteps: 434,189,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,787.38980
Policy Entropy: 3.74677
Value Function Loss: 0.05157

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.49873
Value Function Update Magnitude: 0.74798

Collected Steps per Second: 22,423.15276
Overall Steps per Second: 10,910.61237

Timestep Collection Time: 2.23100
Timestep Consumption Time: 2.35408
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.58508

Cumulative Model Updates: 52,064
Cumulative Timesteps: 434,239,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 434239346...
Checkpoint 434239346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,812.33390
Policy Entropy: 3.75370
Value Function Loss: 0.05182

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.48756
Value Function Update Magnitude: 0.77429

Collected Steps per Second: 21,881.38522
Overall Steps per Second: 10,690.21784

Timestep Collection Time: 2.28550
Timestep Consumption Time: 2.39260
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.67811

Cumulative Model Updates: 52,070
Cumulative Timesteps: 434,289,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,520.42902
Policy Entropy: 3.74250
Value Function Loss: 0.05222

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.49255
Value Function Update Magnitude: 0.70739

Collected Steps per Second: 22,295.14690
Overall Steps per Second: 10,850.54255

Timestep Collection Time: 2.24381
Timestep Consumption Time: 2.36665
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.61046

Cumulative Model Updates: 52,076
Cumulative Timesteps: 434,339,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 434339382...
Checkpoint 434339382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,143.40900
Policy Entropy: 3.73916
Value Function Loss: 0.05126

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.48056
Value Function Update Magnitude: 0.77229

Collected Steps per Second: 21,994.53527
Overall Steps per Second: 10,679.28648

Timestep Collection Time: 2.27429
Timestep Consumption Time: 2.40973
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.68402

Cumulative Model Updates: 52,082
Cumulative Timesteps: 434,389,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,784.64947
Policy Entropy: 3.74383
Value Function Loss: 0.04875

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.47334
Value Function Update Magnitude: 0.81554

Collected Steps per Second: 22,204.70375
Overall Steps per Second: 10,849.18556

Timestep Collection Time: 2.25223
Timestep Consumption Time: 2.35734
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60956

Cumulative Model Updates: 52,088
Cumulative Timesteps: 434,439,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 434439414...
Checkpoint 434439414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,595.05242
Policy Entropy: 3.74562
Value Function Loss: 0.04944

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06232
Policy Update Magnitude: 0.56375
Value Function Update Magnitude: 0.79597

Collected Steps per Second: 22,186.49633
Overall Steps per Second: 10,703.64598

Timestep Collection Time: 2.25489
Timestep Consumption Time: 2.41904
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.67392

Cumulative Model Updates: 52,094
Cumulative Timesteps: 434,489,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,718.82487
Policy Entropy: 3.74379
Value Function Loss: 0.04971

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06265
Policy Update Magnitude: 0.63059
Value Function Update Magnitude: 0.81374

Collected Steps per Second: 22,223.67411
Overall Steps per Second: 10,594.39139

Timestep Collection Time: 2.25147
Timestep Consumption Time: 2.47140
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.72288

Cumulative Model Updates: 52,100
Cumulative Timesteps: 434,539,478

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 434539478...
Checkpoint 434539478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,859.19453
Policy Entropy: 3.73053
Value Function Loss: 0.05100

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06633
Policy Update Magnitude: 0.66166
Value Function Update Magnitude: 0.84351

Collected Steps per Second: 22,705.61045
Overall Steps per Second: 10,865.71273

Timestep Collection Time: 2.20324
Timestep Consumption Time: 2.40078
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.60402

Cumulative Model Updates: 52,106
Cumulative Timesteps: 434,589,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,558.15555
Policy Entropy: 3.73940
Value Function Loss: 0.04886

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06691
Policy Update Magnitude: 0.65087
Value Function Update Magnitude: 0.84796

Collected Steps per Second: 22,936.08059
Overall Steps per Second: 10,943.10263

Timestep Collection Time: 2.18093
Timestep Consumption Time: 2.39017
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.57110

Cumulative Model Updates: 52,112
Cumulative Timesteps: 434,639,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 434639526...
Checkpoint 434639526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.75295
Policy Entropy: 3.74481
Value Function Loss: 0.04957

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06506
Policy Update Magnitude: 0.64245
Value Function Update Magnitude: 0.86642

Collected Steps per Second: 22,712.36016
Overall Steps per Second: 10,738.84794

Timestep Collection Time: 2.20162
Timestep Consumption Time: 2.45474
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.65637

Cumulative Model Updates: 52,118
Cumulative Timesteps: 434,689,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,597.43330
Policy Entropy: 3.75901
Value Function Loss: 0.04836

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06422
Policy Update Magnitude: 0.64601
Value Function Update Magnitude: 0.87232

Collected Steps per Second: 22,722.77510
Overall Steps per Second: 10,830.58376

Timestep Collection Time: 2.20167
Timestep Consumption Time: 2.41747
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.61914

Cumulative Model Updates: 52,124
Cumulative Timesteps: 434,739,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 434739558...
Checkpoint 434739558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,759.97122
Policy Entropy: 3.75471
Value Function Loss: 0.04829

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.58140
Value Function Update Magnitude: 0.85198

Collected Steps per Second: 22,553.89575
Overall Steps per Second: 10,679.17513

Timestep Collection Time: 2.21806
Timestep Consumption Time: 2.46638
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.68444

Cumulative Model Updates: 52,130
Cumulative Timesteps: 434,789,584

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,628.06820
Policy Entropy: 3.74855
Value Function Loss: 0.05087

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.53206
Value Function Update Magnitude: 0.86529

Collected Steps per Second: 22,551.60682
Overall Steps per Second: 10,620.57058

Timestep Collection Time: 2.21785
Timestep Consumption Time: 2.49151
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.70935

Cumulative Model Updates: 52,136
Cumulative Timesteps: 434,839,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 434839600...
Checkpoint 434839600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,450.30284
Policy Entropy: 3.73595
Value Function Loss: 0.05204

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.61434
Value Function Update Magnitude: 0.88910

Collected Steps per Second: 22,550.03492
Overall Steps per Second: 10,654.29460

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.47644
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.69444

Cumulative Model Updates: 52,142
Cumulative Timesteps: 434,889,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,535.59274
Policy Entropy: 3.73210
Value Function Loss: 0.05299

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.63141
Value Function Update Magnitude: 0.88912

Collected Steps per Second: 23,018.34529
Overall Steps per Second: 10,747.42005

Timestep Collection Time: 2.17331
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.65470

Cumulative Model Updates: 52,148
Cumulative Timesteps: 434,939,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 434939642...
Checkpoint 434939642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,064.08459
Policy Entropy: 3.71952
Value Function Loss: 0.05367

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.59894
Value Function Update Magnitude: 0.88844

Collected Steps per Second: 22,563.13413
Overall Steps per Second: 10,612.54056

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.71141

Cumulative Model Updates: 52,154
Cumulative Timesteps: 434,989,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,746.12941
Policy Entropy: 3.71523
Value Function Loss: 0.05421

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.52448
Value Function Update Magnitude: 0.84894

Collected Steps per Second: 23,122.84006
Overall Steps per Second: 10,867.82773

Timestep Collection Time: 2.16288
Timestep Consumption Time: 2.43896
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60184

Cumulative Model Updates: 52,160
Cumulative Timesteps: 435,039,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 435039654...
Checkpoint 435039654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,825.34017
Policy Entropy: 3.69814
Value Function Loss: 0.05665

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.49261
Value Function Update Magnitude: 0.70884

Collected Steps per Second: 22,581.69647
Overall Steps per Second: 10,691.15747

Timestep Collection Time: 2.21507
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.67863

Cumulative Model Updates: 52,166
Cumulative Timesteps: 435,089,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,042.63566
Policy Entropy: 3.69806
Value Function Loss: 0.05695

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.50019
Value Function Update Magnitude: 0.70838

Collected Steps per Second: 22,657.81906
Overall Steps per Second: 10,664.11280

Timestep Collection Time: 2.20798
Timestep Consumption Time: 2.48327
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.69125

Cumulative Model Updates: 52,172
Cumulative Timesteps: 435,139,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 435139702...
Checkpoint 435139702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,435.89340
Policy Entropy: 3.70211
Value Function Loss: 0.05562

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.51806
Value Function Update Magnitude: 0.78124

Collected Steps per Second: 22,690.16832
Overall Steps per Second: 10,803.45192

Timestep Collection Time: 2.20404
Timestep Consumption Time: 2.42504
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.62908

Cumulative Model Updates: 52,178
Cumulative Timesteps: 435,189,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,603.56886
Policy Entropy: 3.73102
Value Function Loss: 0.05373

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.45584
Value Function Update Magnitude: 0.78200

Collected Steps per Second: 22,788.55557
Overall Steps per Second: 10,662.01556

Timestep Collection Time: 2.19426
Timestep Consumption Time: 2.49566
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.68992

Cumulative Model Updates: 52,184
Cumulative Timesteps: 435,239,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 435239716...
Checkpoint 435239716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,810.26432
Policy Entropy: 3.72927
Value Function Loss: 0.05514

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.43457
Value Function Update Magnitude: 0.67072

Collected Steps per Second: 22,661.03306
Overall Steps per Second: 10,692.24894

Timestep Collection Time: 2.20714
Timestep Consumption Time: 2.47064
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.67778

Cumulative Model Updates: 52,190
Cumulative Timesteps: 435,289,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,662.95194
Policy Entropy: 3.74087
Value Function Loss: 0.05306

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.43967
Value Function Update Magnitude: 0.68746

Collected Steps per Second: 22,653.23990
Overall Steps per Second: 10,736.74820

Timestep Collection Time: 2.20931
Timestep Consumption Time: 2.45207
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.66137

Cumulative Model Updates: 52,196
Cumulative Timesteps: 435,339,780

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 435339780...
Checkpoint 435339780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,928.25747
Policy Entropy: 3.73014
Value Function Loss: 0.04988

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.44920
Value Function Update Magnitude: 0.69730

Collected Steps per Second: 22,650.76525
Overall Steps per Second: 10,612.96536

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.50519
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.71386

Cumulative Model Updates: 52,202
Cumulative Timesteps: 435,389,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,586.69157
Policy Entropy: 3.73874
Value Function Loss: 0.04705

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.46717
Value Function Update Magnitude: 0.69613

Collected Steps per Second: 22,811.11578
Overall Steps per Second: 10,833.50170

Timestep Collection Time: 2.19200
Timestep Consumption Time: 2.42350
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.61550

Cumulative Model Updates: 52,208
Cumulative Timesteps: 435,439,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 435439810...
Checkpoint 435439810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,316.55507
Policy Entropy: 3.71989
Value Function Loss: 0.04457

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.46964
Value Function Update Magnitude: 0.66006

Collected Steps per Second: 22,721.98972
Overall Steps per Second: 10,732.97593

Timestep Collection Time: 2.20174
Timestep Consumption Time: 2.45941
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.66115

Cumulative Model Updates: 52,214
Cumulative Timesteps: 435,489,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,843.66614
Policy Entropy: 3.72446
Value Function Loss: 0.04703

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.54196
Value Function Update Magnitude: 0.61472

Collected Steps per Second: 22,671.82370
Overall Steps per Second: 10,644.34466

Timestep Collection Time: 2.20600
Timestep Consumption Time: 2.49265
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.69865

Cumulative Model Updates: 52,220
Cumulative Timesteps: 435,539,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 435539852...
Checkpoint 435539852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,573.67559
Policy Entropy: 3.72571
Value Function Loss: 0.04479

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.58644
Value Function Update Magnitude: 0.56003

Collected Steps per Second: 22,888.90204
Overall Steps per Second: 10,852.69272

Timestep Collection Time: 2.18473
Timestep Consumption Time: 2.42298
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.60770

Cumulative Model Updates: 52,226
Cumulative Timesteps: 435,589,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,039.28626
Policy Entropy: 3.73204
Value Function Loss: 0.04678

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.62852

Collected Steps per Second: 22,720.10281
Overall Steps per Second: 10,715.00511

Timestep Collection Time: 2.20175
Timestep Consumption Time: 2.46684
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.66859

Cumulative Model Updates: 52,232
Cumulative Timesteps: 435,639,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 435639882...
Checkpoint 435639882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,609.53767
Policy Entropy: 3.72980
Value Function Loss: 0.04931

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.48510
Value Function Update Magnitude: 0.62003

Collected Steps per Second: 22,816.86275
Overall Steps per Second: 10,867.62124

Timestep Collection Time: 2.19259
Timestep Consumption Time: 2.41081
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.60340

Cumulative Model Updates: 52,238
Cumulative Timesteps: 435,689,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,045.11163
Policy Entropy: 3.72853
Value Function Loss: 0.05093

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.45993
Value Function Update Magnitude: 0.62071

Collected Steps per Second: 22,830.33413
Overall Steps per Second: 10,835.46938

Timestep Collection Time: 2.19033
Timestep Consumption Time: 2.42470
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61503

Cumulative Model Updates: 52,244
Cumulative Timesteps: 435,739,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 435739916...
Checkpoint 435739916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,861.81200
Policy Entropy: 3.71765
Value Function Loss: 0.05089

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09778
Policy Update Magnitude: 0.46854
Value Function Update Magnitude: 0.66972

Collected Steps per Second: 21,879.21404
Overall Steps per Second: 10,702.80811

Timestep Collection Time: 2.28655
Timestep Consumption Time: 2.38773
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.67429

Cumulative Model Updates: 52,250
Cumulative Timesteps: 435,789,944

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,166.02587
Policy Entropy: 3.71108
Value Function Loss: 0.04993

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.46155
Value Function Update Magnitude: 0.69482

Collected Steps per Second: 22,209.79612
Overall Steps per Second: 10,861.51926

Timestep Collection Time: 2.25207
Timestep Consumption Time: 2.35300
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60506

Cumulative Model Updates: 52,256
Cumulative Timesteps: 435,839,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 435839962...
Checkpoint 435839962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,868.64022
Policy Entropy: 3.72669
Value Function Loss: 0.05065

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.49054
Value Function Update Magnitude: 0.68031

Collected Steps per Second: 21,890.31880
Overall Steps per Second: 10,709.20806

Timestep Collection Time: 2.28475
Timestep Consumption Time: 2.38543
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.67019

Cumulative Model Updates: 52,262
Cumulative Timesteps: 435,889,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,905.75711
Policy Entropy: 3.73758
Value Function Loss: 0.04938

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.53683
Value Function Update Magnitude: 0.71324

Collected Steps per Second: 22,082.40369
Overall Steps per Second: 10,799.16451

Timestep Collection Time: 2.26533
Timestep Consumption Time: 2.36688
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.63221

Cumulative Model Updates: 52,268
Cumulative Timesteps: 435,940,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 435940000...
Checkpoint 435940000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,310.43628
Policy Entropy: 3.74265
Value Function Loss: 0.04976

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.49234
Value Function Update Magnitude: 0.69153

Collected Steps per Second: 21,878.39895
Overall Steps per Second: 10,716.94686

Timestep Collection Time: 2.28545
Timestep Consumption Time: 2.38024
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.66569

Cumulative Model Updates: 52,274
Cumulative Timesteps: 435,990,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.92593
Policy Entropy: 3.73483
Value Function Loss: 0.05013

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.49585
Value Function Update Magnitude: 0.64823

Collected Steps per Second: 22,300.36553
Overall Steps per Second: 10,871.37807

Timestep Collection Time: 2.24337
Timestep Consumption Time: 2.35844
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60181

Cumulative Model Updates: 52,280
Cumulative Timesteps: 436,040,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 436040030...
Checkpoint 436040030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,011.29094
Policy Entropy: 3.73847
Value Function Loss: 0.04952

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.52115
Value Function Update Magnitude: 0.59589

Collected Steps per Second: 22,018.60039
Overall Steps per Second: 10,721.60253

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.39277
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.66367

Cumulative Model Updates: 52,286
Cumulative Timesteps: 436,090,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,899.54594
Policy Entropy: 3.73332
Value Function Loss: 0.04887

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.47864
Value Function Update Magnitude: 0.56441

Collected Steps per Second: 22,957.24554
Overall Steps per Second: 10,868.48112

Timestep Collection Time: 2.17875
Timestep Consumption Time: 2.42337
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.60211

Cumulative Model Updates: 52,292
Cumulative Timesteps: 436,140,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 436140050...
Checkpoint 436140050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,182.20423
Policy Entropy: 3.73926
Value Function Loss: 0.04885

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.44427
Value Function Update Magnitude: 0.55982

Collected Steps per Second: 22,844.74787
Overall Steps per Second: 10,725.87773

Timestep Collection Time: 2.18983
Timestep Consumption Time: 2.47422
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.66405

Cumulative Model Updates: 52,298
Cumulative Timesteps: 436,190,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,212.98949
Policy Entropy: 3.73604
Value Function Loss: 0.05040

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.48082
Value Function Update Magnitude: 0.56687

Collected Steps per Second: 22,999.83572
Overall Steps per Second: 10,868.63872

Timestep Collection Time: 2.17489
Timestep Consumption Time: 2.42753
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.60242

Cumulative Model Updates: 52,304
Cumulative Timesteps: 436,240,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 436240098...
Checkpoint 436240098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,118.74855
Policy Entropy: 3.73269
Value Function Loss: 0.05049

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.55312
Value Function Update Magnitude: 0.58788

Collected Steps per Second: 22,520.74325
Overall Steps per Second: 10,642.89134

Timestep Collection Time: 2.22026
Timestep Consumption Time: 2.47790
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.69816

Cumulative Model Updates: 52,310
Cumulative Timesteps: 436,290,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,698.14619
Policy Entropy: 3.73968
Value Function Loss: 0.05036

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.53205
Value Function Update Magnitude: 0.59578

Collected Steps per Second: 22,957.04404
Overall Steps per Second: 10,843.68466

Timestep Collection Time: 2.17911
Timestep Consumption Time: 2.43426
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61338

Cumulative Model Updates: 52,316
Cumulative Timesteps: 436,340,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 436340126...
Checkpoint 436340126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,763.97105
Policy Entropy: 3.73020
Value Function Loss: 0.04950

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.56788
Value Function Update Magnitude: 0.61348

Collected Steps per Second: 22,375.39236
Overall Steps per Second: 10,692.47126

Timestep Collection Time: 2.23674
Timestep Consumption Time: 2.44393
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.68068

Cumulative Model Updates: 52,322
Cumulative Timesteps: 436,390,174

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,040.73652
Policy Entropy: 3.72309
Value Function Loss: 0.05026

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.61418
Value Function Update Magnitude: 0.63122

Collected Steps per Second: 22,190.37743
Overall Steps per Second: 10,819.91529

Timestep Collection Time: 2.25350
Timestep Consumption Time: 2.36816
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62166

Cumulative Model Updates: 52,328
Cumulative Timesteps: 436,440,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 436440180...
Checkpoint 436440180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,760.28090
Policy Entropy: 3.73121
Value Function Loss: 0.05318

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.53536
Value Function Update Magnitude: 0.59510

Collected Steps per Second: 22,914.04210
Overall Steps per Second: 10,734.92923

Timestep Collection Time: 2.18250
Timestep Consumption Time: 2.47612
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.65862

Cumulative Model Updates: 52,334
Cumulative Timesteps: 436,490,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,441.84558
Policy Entropy: 3.72035
Value Function Loss: 0.05525

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.56474
Value Function Update Magnitude: 0.60641

Collected Steps per Second: 22,942.13103
Overall Steps per Second: 10,771.34254

Timestep Collection Time: 2.17975
Timestep Consumption Time: 2.46294
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.64269

Cumulative Model Updates: 52,340
Cumulative Timesteps: 436,540,198

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 436540198...
Checkpoint 436540198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,903.40360
Policy Entropy: 3.71385
Value Function Loss: 0.05789

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.57146
Value Function Update Magnitude: 0.57058

Collected Steps per Second: 22,484.11628
Overall Steps per Second: 10,723.92452

Timestep Collection Time: 2.22415
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.66322

Cumulative Model Updates: 52,346
Cumulative Timesteps: 436,590,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,126.65613
Policy Entropy: 3.71258
Value Function Loss: 0.05571

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.52167
Value Function Update Magnitude: 0.53187

Collected Steps per Second: 22,962.15888
Overall Steps per Second: 10,850.36440

Timestep Collection Time: 2.17898
Timestep Consumption Time: 2.43230
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61127

Cumulative Model Updates: 52,352
Cumulative Timesteps: 436,640,240

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 436640240...
Checkpoint 436640240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,186.59962
Policy Entropy: 3.71974
Value Function Loss: 0.05513

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.49153
Value Function Update Magnitude: 0.53768

Collected Steps per Second: 22,406.46289
Overall Steps per Second: 10,768.47465

Timestep Collection Time: 2.23266
Timestep Consumption Time: 2.41294
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.64560

Cumulative Model Updates: 52,358
Cumulative Timesteps: 436,690,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,581.69024
Policy Entropy: 3.72725
Value Function Loss: 0.05351

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.48021
Value Function Update Magnitude: 0.54788

Collected Steps per Second: 22,999.59030
Overall Steps per Second: 10,816.97913

Timestep Collection Time: 2.17430
Timestep Consumption Time: 2.44880
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62310

Cumulative Model Updates: 52,364
Cumulative Timesteps: 436,740,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 436740274...
Checkpoint 436740274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,449.50965
Policy Entropy: 3.72768
Value Function Loss: 0.05355

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.48375
Value Function Update Magnitude: 0.62441

Collected Steps per Second: 22,679.36685
Overall Steps per Second: 10,670.79786

Timestep Collection Time: 2.20518
Timestep Consumption Time: 2.48163
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.68681

Cumulative Model Updates: 52,370
Cumulative Timesteps: 436,790,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,825.41723
Policy Entropy: 3.71608
Value Function Loss: 0.05400

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.58831
Value Function Update Magnitude: 0.74838

Collected Steps per Second: 23,043.80983
Overall Steps per Second: 10,878.26617

Timestep Collection Time: 2.16978
Timestep Consumption Time: 2.42654
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.59632

Cumulative Model Updates: 52,376
Cumulative Timesteps: 436,840,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 436840286...
Checkpoint 436840286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,241.93829
Policy Entropy: 3.72392
Value Function Loss: 0.05325

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.63873
Value Function Update Magnitude: 0.80066

Collected Steps per Second: 22,699.63982
Overall Steps per Second: 10,669.97945

Timestep Collection Time: 2.20365
Timestep Consumption Time: 2.48446
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.68811

Cumulative Model Updates: 52,382
Cumulative Timesteps: 436,890,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,663.87207
Policy Entropy: 3.70708
Value Function Loss: 0.05205

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.63506
Value Function Update Magnitude: 0.81395

Collected Steps per Second: 22,674.86103
Overall Steps per Second: 10,647.66693

Timestep Collection Time: 2.20561
Timestep Consumption Time: 2.49138
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.69699

Cumulative Model Updates: 52,388
Cumulative Timesteps: 436,940,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 436940320...
Checkpoint 436940320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,698.12043
Policy Entropy: 3.70906
Value Function Loss: 0.05472

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.77465

Collected Steps per Second: 22,745.87708
Overall Steps per Second: 10,800.69079

Timestep Collection Time: 2.19829
Timestep Consumption Time: 2.43123
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62952

Cumulative Model Updates: 52,394
Cumulative Timesteps: 436,990,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,748.43645
Policy Entropy: 3.70370
Value Function Loss: 0.05523

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.53793
Value Function Update Magnitude: 0.69469

Collected Steps per Second: 22,767.82536
Overall Steps per Second: 10,648.19951

Timestep Collection Time: 2.19670
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.69694

Cumulative Model Updates: 52,400
Cumulative Timesteps: 437,040,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 437040336...
Checkpoint 437040336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,664.10086
Policy Entropy: 3.70274
Value Function Loss: 0.05807

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.51110
Value Function Update Magnitude: 0.71573

Collected Steps per Second: 23,039.58416
Overall Steps per Second: 10,764.96245

Timestep Collection Time: 2.17191
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.64841

Cumulative Model Updates: 52,406
Cumulative Timesteps: 437,090,376

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,892.01932
Policy Entropy: 3.71095
Value Function Loss: 0.05479

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.72270

Collected Steps per Second: 22,730.55496
Overall Steps per Second: 10,688.32638

Timestep Collection Time: 2.19986
Timestep Consumption Time: 2.47852
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.67838

Cumulative Model Updates: 52,412
Cumulative Timesteps: 437,140,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 437140380...
Checkpoint 437140380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,422.83219
Policy Entropy: 3.71317
Value Function Loss: 0.05406

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11645
Policy Update Magnitude: 0.51956
Value Function Update Magnitude: 0.71455

Collected Steps per Second: 22,638.14375
Overall Steps per Second: 10,627.75443

Timestep Collection Time: 2.20875
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.70485

Cumulative Model Updates: 52,418
Cumulative Timesteps: 437,190,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,066.93724
Policy Entropy: 3.70478
Value Function Loss: 0.05288

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.49755
Value Function Update Magnitude: 0.73549

Collected Steps per Second: 23,038.05521
Overall Steps per Second: 10,940.60649

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.40067
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57178

Cumulative Model Updates: 52,424
Cumulative Timesteps: 437,240,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 437240400...
Checkpoint 437240400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,726.31657
Policy Entropy: 3.69347
Value Function Loss: 0.05355

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.50266
Value Function Update Magnitude: 0.75944

Collected Steps per Second: 22,829.61061
Overall Steps per Second: 10,674.66054

Timestep Collection Time: 2.19014
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.68399

Cumulative Model Updates: 52,430
Cumulative Timesteps: 437,290,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,116.51764
Policy Entropy: 3.69062
Value Function Loss: 0.05360

Mean KL Divergence: 0.01834
SB3 Clip Fraction: 0.15745
Policy Update Magnitude: 0.47807
Value Function Update Magnitude: 0.77597

Collected Steps per Second: 22,738.05367
Overall Steps per Second: 10,753.27000

Timestep Collection Time: 2.19896
Timestep Consumption Time: 2.45079
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.64975

Cumulative Model Updates: 52,436
Cumulative Timesteps: 437,340,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 437340400...
Checkpoint 437340400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,811.25087
Policy Entropy: 3.70924
Value Function Loss: 0.05161

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.44016
Value Function Update Magnitude: 0.78991

Collected Steps per Second: 22,373.12170
Overall Steps per Second: 10,677.43754

Timestep Collection Time: 2.23581
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.68483

Cumulative Model Updates: 52,442
Cumulative Timesteps: 437,390,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,403.66840
Policy Entropy: 3.72118
Value Function Loss: 0.04963

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.48946
Value Function Update Magnitude: 0.82192

Collected Steps per Second: 23,023.48681
Overall Steps per Second: 10,846.08245

Timestep Collection Time: 2.17300
Timestep Consumption Time: 2.43973
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61273

Cumulative Model Updates: 52,448
Cumulative Timesteps: 437,440,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 437440452...
Checkpoint 437440452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,892.52996
Policy Entropy: 3.72968
Value Function Loss: 0.04768

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.48634
Value Function Update Magnitude: 0.82466

Collected Steps per Second: 22,353.06493
Overall Steps per Second: 10,712.53704

Timestep Collection Time: 2.23790
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.66967

Cumulative Model Updates: 52,454
Cumulative Timesteps: 437,490,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,699.76388
Policy Entropy: 3.70863
Value Function Loss: 0.04698

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.56355
Value Function Update Magnitude: 0.80728

Collected Steps per Second: 22,623.34519
Overall Steps per Second: 10,624.84998

Timestep Collection Time: 2.21011
Timestep Consumption Time: 2.49584
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.70595

Cumulative Model Updates: 52,460
Cumulative Timesteps: 437,540,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 437540476...
Checkpoint 437540476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,655.91981
Policy Entropy: 3.71675
Value Function Loss: 0.04543

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.61300
Value Function Update Magnitude: 0.79695

Collected Steps per Second: 22,934.05919
Overall Steps per Second: 10,849.12153

Timestep Collection Time: 2.18077
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.60996

Cumulative Model Updates: 52,466
Cumulative Timesteps: 437,590,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,314.02018
Policy Entropy: 3.72281
Value Function Loss: 0.04456

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06409
Policy Update Magnitude: 0.63311
Value Function Update Magnitude: 0.80025

Collected Steps per Second: 22,961.15446
Overall Steps per Second: 10,722.91306

Timestep Collection Time: 2.17864
Timestep Consumption Time: 2.48651
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.66515

Cumulative Model Updates: 52,472
Cumulative Timesteps: 437,640,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 437640514...
Checkpoint 437640514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,117.01800
Policy Entropy: 3.72993
Value Function Loss: 0.04372

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06104
Policy Update Magnitude: 0.64348
Value Function Update Magnitude: 0.79271

Collected Steps per Second: 22,641.60954
Overall Steps per Second: 10,720.10587

Timestep Collection Time: 2.20894
Timestep Consumption Time: 2.45650
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.66544

Cumulative Model Updates: 52,478
Cumulative Timesteps: 437,690,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,017.61319
Policy Entropy: 3.73229
Value Function Loss: 0.04410

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06727
Policy Update Magnitude: 0.62773
Value Function Update Magnitude: 0.78541

Collected Steps per Second: 22,616.01796
Overall Steps per Second: 10,678.21750

Timestep Collection Time: 2.21206
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.68505

Cumulative Model Updates: 52,484
Cumulative Timesteps: 437,740,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 437740556...
Checkpoint 437740556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.89947
Policy Entropy: 3.72819
Value Function Loss: 0.04529

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.61521
Value Function Update Magnitude: 0.78937

Collected Steps per Second: 22,603.43570
Overall Steps per Second: 10,609.24750

Timestep Collection Time: 2.21205
Timestep Consumption Time: 2.50082
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.71287

Cumulative Model Updates: 52,490
Cumulative Timesteps: 437,790,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,220.20106
Policy Entropy: 3.72977
Value Function Loss: 0.04427

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06036
Policy Update Magnitude: 0.60334
Value Function Update Magnitude: 0.76082

Collected Steps per Second: 22,648.57491
Overall Steps per Second: 10,676.30673

Timestep Collection Time: 2.20888
Timestep Consumption Time: 2.47701
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.68589

Cumulative Model Updates: 52,496
Cumulative Timesteps: 437,840,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 437840584...
Checkpoint 437840584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,417.71843
Policy Entropy: 3.73316
Value Function Loss: 0.04442

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05920
Policy Update Magnitude: 0.63622
Value Function Update Magnitude: 0.77509

Collected Steps per Second: 22,743.20162
Overall Steps per Second: 10,807.89139

Timestep Collection Time: 2.19969
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.62884

Cumulative Model Updates: 52,502
Cumulative Timesteps: 437,890,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,131.06658
Policy Entropy: 3.74212
Value Function Loss: 0.04452

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.60750
Value Function Update Magnitude: 0.81153

Collected Steps per Second: 22,776.59464
Overall Steps per Second: 10,627.11379

Timestep Collection Time: 2.19638
Timestep Consumption Time: 2.51102
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.70739

Cumulative Model Updates: 52,508
Cumulative Timesteps: 437,940,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 437940638...
Checkpoint 437940638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,416.90400
Policy Entropy: 3.74820
Value Function Loss: 0.04685

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.49325
Value Function Update Magnitude: 0.82920

Collected Steps per Second: 22,639.50240
Overall Steps per Second: 10,638.01712

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.70238

Cumulative Model Updates: 52,514
Cumulative Timesteps: 437,990,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,702.74010
Policy Entropy: 3.75044
Value Function Loss: 0.04829

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.49634
Value Function Update Magnitude: 0.83802

Collected Steps per Second: 23,094.85458
Overall Steps per Second: 10,827.07337

Timestep Collection Time: 2.16568
Timestep Consumption Time: 2.45385
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.61953

Cumulative Model Updates: 52,520
Cumulative Timesteps: 438,040,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 438040678...
Checkpoint 438040678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,072.37937
Policy Entropy: 3.75699
Value Function Loss: 0.04738

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.53449
Value Function Update Magnitude: 0.84335

Collected Steps per Second: 22,677.65813
Overall Steps per Second: 10,616.00652

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.70987

Cumulative Model Updates: 52,526
Cumulative Timesteps: 438,090,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.90725
Policy Entropy: 3.75235
Value Function Loss: 0.04827

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.48522
Value Function Update Magnitude: 0.81827

Collected Steps per Second: 22,784.73469
Overall Steps per Second: 10,787.20496

Timestep Collection Time: 2.19489
Timestep Consumption Time: 2.44116
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.63605

Cumulative Model Updates: 52,532
Cumulative Timesteps: 438,140,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 438140688...
Checkpoint 438140688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,523.28667
Policy Entropy: 3.74628
Value Function Loss: 0.05035

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.51642
Value Function Update Magnitude: 0.81173

Collected Steps per Second: 22,785.36508
Overall Steps per Second: 10,682.60541

Timestep Collection Time: 2.19474
Timestep Consumption Time: 2.48651
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.68125

Cumulative Model Updates: 52,538
Cumulative Timesteps: 438,190,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,643.84518
Policy Entropy: 3.74065
Value Function Loss: 0.04978

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06196
Policy Update Magnitude: 0.59984
Value Function Update Magnitude: 0.79992

Collected Steps per Second: 22,773.40584
Overall Steps per Second: 10,653.82704

Timestep Collection Time: 2.19651
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69521

Cumulative Model Updates: 52,544
Cumulative Timesteps: 438,240,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 438240718...
Checkpoint 438240718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,191.35364
Policy Entropy: 3.73625
Value Function Loss: 0.05077

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06416
Policy Update Magnitude: 0.63209
Value Function Update Magnitude: 0.79230

Collected Steps per Second: 22,952.11768
Overall Steps per Second: 10,866.93067

Timestep Collection Time: 2.17862
Timestep Consumption Time: 2.42286
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60148

Cumulative Model Updates: 52,550
Cumulative Timesteps: 438,290,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,997.83716
Policy Entropy: 3.72122
Value Function Loss: 0.05136

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.58307
Value Function Update Magnitude: 0.81762

Collected Steps per Second: 22,639.07135
Overall Steps per Second: 10,595.24266

Timestep Collection Time: 2.20928
Timestep Consumption Time: 2.51133
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.72061

Cumulative Model Updates: 52,556
Cumulative Timesteps: 438,340,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 438340738...
Checkpoint 438340738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,751.72593
Policy Entropy: 3.70715
Value Function Loss: 0.05239

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11723
Policy Update Magnitude: 0.53036
Value Function Update Magnitude: 0.84057

Collected Steps per Second: 22,714.60509
Overall Steps per Second: 10,626.24806

Timestep Collection Time: 2.20228
Timestep Consumption Time: 2.50530
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.70759

Cumulative Model Updates: 52,562
Cumulative Timesteps: 438,390,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,452.22641
Policy Entropy: 3.72157
Value Function Loss: 0.05236

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.53118
Value Function Update Magnitude: 0.80016

Collected Steps per Second: 22,948.28568
Overall Steps per Second: 10,833.35370

Timestep Collection Time: 2.17916
Timestep Consumption Time: 2.43695
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.61611

Cumulative Model Updates: 52,568
Cumulative Timesteps: 438,440,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 438440770...
Checkpoint 438440770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,828.64552
Policy Entropy: 3.75125
Value Function Loss: 0.04928

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.52593
Value Function Update Magnitude: 0.78248

Collected Steps per Second: 22,864.69752
Overall Steps per Second: 10,738.20168

Timestep Collection Time: 2.18809
Timestep Consumption Time: 2.47098
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.65907

Cumulative Model Updates: 52,574
Cumulative Timesteps: 438,490,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,036.42681
Policy Entropy: 3.76889
Value Function Loss: 0.04905

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.47788
Value Function Update Magnitude: 0.80316

Collected Steps per Second: 22,538.07452
Overall Steps per Second: 10,745.88735

Timestep Collection Time: 2.21909
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.65425

Cumulative Model Updates: 52,580
Cumulative Timesteps: 438,540,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 438540814...
Checkpoint 438540814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,116.30490
Policy Entropy: 3.76544
Value Function Loss: 0.04991

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.50950
Value Function Update Magnitude: 0.80299

Collected Steps per Second: 22,767.46651
Overall Steps per Second: 10,733.59798

Timestep Collection Time: 2.19629
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.65864

Cumulative Model Updates: 52,586
Cumulative Timesteps: 438,590,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.20891
Policy Entropy: 3.76285
Value Function Loss: 0.05178

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.57197
Value Function Update Magnitude: 0.76580

Collected Steps per Second: 22,523.57815
Overall Steps per Second: 10,616.51305

Timestep Collection Time: 2.22105
Timestep Consumption Time: 2.49104
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.71209

Cumulative Model Updates: 52,592
Cumulative Timesteps: 438,640,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 438640844...
Checkpoint 438640844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,236.90762
Policy Entropy: 3.75586
Value Function Loss: 0.05335

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.59551
Value Function Update Magnitude: 0.68989

Collected Steps per Second: 22,866.87356
Overall Steps per Second: 10,859.35854

Timestep Collection Time: 2.18666
Timestep Consumption Time: 2.41785
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60451

Cumulative Model Updates: 52,598
Cumulative Timesteps: 438,690,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,199.49525
Policy Entropy: 3.76731
Value Function Loss: 0.05359

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.53113
Value Function Update Magnitude: 0.63470

Collected Steps per Second: 23,000.01959
Overall Steps per Second: 10,718.69150

Timestep Collection Time: 2.17469
Timestep Consumption Time: 2.49173
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.66643

Cumulative Model Updates: 52,604
Cumulative Timesteps: 438,740,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 438740864...
Checkpoint 438740864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,510.83926
Policy Entropy: 3.76177
Value Function Loss: 0.05034

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.52444
Value Function Update Magnitude: 0.71848

Collected Steps per Second: 22,823.19572
Overall Steps per Second: 10,817.05306

Timestep Collection Time: 2.19110
Timestep Consumption Time: 2.43197
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62307

Cumulative Model Updates: 52,610
Cumulative Timesteps: 438,790,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,553.94735
Policy Entropy: 3.76078
Value Function Loss: 0.05032

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.78372

Collected Steps per Second: 23,134.55939
Overall Steps per Second: 10,894.76746

Timestep Collection Time: 2.16257
Timestep Consumption Time: 2.42955
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59211

Cumulative Model Updates: 52,616
Cumulative Timesteps: 438,840,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 438840902...
Checkpoint 438840902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,245.68672
Policy Entropy: 3.75480
Value Function Loss: 0.05235

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.76137

Collected Steps per Second: 22,658.92948
Overall Steps per Second: 10,764.64417

Timestep Collection Time: 2.20761
Timestep Consumption Time: 2.43927
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.64688

Cumulative Model Updates: 52,622
Cumulative Timesteps: 438,890,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,860.56886
Policy Entropy: 3.75804
Value Function Loss: 0.05274

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.49545
Value Function Update Magnitude: 0.78013

Collected Steps per Second: 22,828.34246
Overall Steps per Second: 10,800.43028

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.44045
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.63185

Cumulative Model Updates: 52,628
Cumulative Timesteps: 438,940,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 438940950...
Checkpoint 438940950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,747.36729
Policy Entropy: 3.75115
Value Function Loss: 0.05194

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.50626
Value Function Update Magnitude: 0.83767

Collected Steps per Second: 22,700.30205
Overall Steps per Second: 10,790.70524

Timestep Collection Time: 2.20332
Timestep Consumption Time: 2.43178
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.63510

Cumulative Model Updates: 52,634
Cumulative Timesteps: 438,990,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,182.26515
Policy Entropy: 3.75130
Value Function Loss: 0.04874

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.46446
Value Function Update Magnitude: 0.85189

Collected Steps per Second: 22,660.90263
Overall Steps per Second: 10,826.33644

Timestep Collection Time: 2.20653
Timestep Consumption Time: 2.41202
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.61855

Cumulative Model Updates: 52,640
Cumulative Timesteps: 439,040,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 439040968...
Checkpoint 439040968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.84095
Policy Entropy: 3.73594
Value Function Loss: 0.04947

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.47198
Value Function Update Magnitude: 0.84881

Collected Steps per Second: 22,717.82833
Overall Steps per Second: 10,712.04887

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.46781
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.66969

Cumulative Model Updates: 52,646
Cumulative Timesteps: 439,090,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,893.95632
Policy Entropy: 3.74484
Value Function Loss: 0.04863

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.44373
Value Function Update Magnitude: 0.82612

Collected Steps per Second: 22,562.11064
Overall Steps per Second: 10,561.17154

Timestep Collection Time: 2.21726
Timestep Consumption Time: 2.51953
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.73679

Cumulative Model Updates: 52,652
Cumulative Timesteps: 439,141,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 439141016...
Checkpoint 439141016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,737.45391
Policy Entropy: 3.74398
Value Function Loss: 0.04852

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.45976
Value Function Update Magnitude: 0.83430

Collected Steps per Second: 22,775.52960
Overall Steps per Second: 10,674.27138

Timestep Collection Time: 2.19578
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.68510

Cumulative Model Updates: 52,658
Cumulative Timesteps: 439,191,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,380.47920
Policy Entropy: 3.75846
Value Function Loss: 0.04870

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.46847
Value Function Update Magnitude: 0.84205

Collected Steps per Second: 22,992.69628
Overall Steps per Second: 10,787.92956

Timestep Collection Time: 2.17513
Timestep Consumption Time: 2.46080
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.63592

Cumulative Model Updates: 52,664
Cumulative Timesteps: 439,241,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 439241038...
Checkpoint 439241038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,810.48114
Policy Entropy: 3.73961
Value Function Loss: 0.04809

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.47977
Value Function Update Magnitude: 0.82301

Collected Steps per Second: 22,664.15123
Overall Steps per Second: 10,630.67784

Timestep Collection Time: 2.20754
Timestep Consumption Time: 2.49884
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.70638

Cumulative Model Updates: 52,670
Cumulative Timesteps: 439,291,070

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,535.55132
Policy Entropy: 3.73829
Value Function Loss: 0.04936

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.54012
Value Function Update Magnitude: 0.78518

Collected Steps per Second: 22,832.76635
Overall Steps per Second: 10,811.38668

Timestep Collection Time: 2.19115
Timestep Consumption Time: 2.43638
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.62753

Cumulative Model Updates: 52,676
Cumulative Timesteps: 439,341,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 439341100...
Checkpoint 439341100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,027.29962
Policy Entropy: 3.73404
Value Function Loss: 0.05533

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.62576
Value Function Update Magnitude: 0.66700

Collected Steps per Second: 22,489.88358
Overall Steps per Second: 10,773.91959

Timestep Collection Time: 2.22438
Timestep Consumption Time: 2.41887
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.64325

Cumulative Model Updates: 52,682
Cumulative Timesteps: 439,391,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,323.73833
Policy Entropy: 3.73992
Value Function Loss: 0.05673

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06865
Policy Update Magnitude: 0.64513
Value Function Update Magnitude: 0.51293

Collected Steps per Second: 22,957.00465
Overall Steps per Second: 10,900.93806

Timestep Collection Time: 2.17894
Timestep Consumption Time: 2.40984
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.58878

Cumulative Model Updates: 52,688
Cumulative Timesteps: 439,441,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 439441148...
Checkpoint 439441148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,913.98406
Policy Entropy: 3.72808
Value Function Loss: 0.05818

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.61358
Value Function Update Magnitude: 0.55599

Collected Steps per Second: 22,749.83346
Overall Steps per Second: 10,624.95775

Timestep Collection Time: 2.19791
Timestep Consumption Time: 2.50818
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.70609

Cumulative Model Updates: 52,694
Cumulative Timesteps: 439,491,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,349.38484
Policy Entropy: 3.71534
Value Function Loss: 0.05680

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06441
Policy Update Magnitude: 0.62021
Value Function Update Magnitude: 0.63584

Collected Steps per Second: 22,861.49569
Overall Steps per Second: 10,820.48259

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.43437
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.62198

Cumulative Model Updates: 52,700
Cumulative Timesteps: 439,541,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 439541162...
Checkpoint 439541162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,798.44126
Policy Entropy: 3.70203
Value Function Loss: 0.05471

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.59854
Value Function Update Magnitude: 0.65916

Collected Steps per Second: 22,394.11612
Overall Steps per Second: 10,673.50376

Timestep Collection Time: 2.23335
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.68581

Cumulative Model Updates: 52,706
Cumulative Timesteps: 439,591,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,009.66153
Policy Entropy: 3.70770
Value Function Loss: 0.05250

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.49740
Value Function Update Magnitude: 0.70555

Collected Steps per Second: 23,242.63097
Overall Steps per Second: 10,928.62956

Timestep Collection Time: 2.15182
Timestep Consumption Time: 2.42460
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.57642

Cumulative Model Updates: 52,712
Cumulative Timesteps: 439,641,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 439641190...
Checkpoint 439641190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,794.09380
Policy Entropy: 3.72500
Value Function Loss: 0.05067

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.46739
Value Function Update Magnitude: 0.77664

Collected Steps per Second: 21,877.03299
Overall Steps per Second: 10,648.80220

Timestep Collection Time: 2.28696
Timestep Consumption Time: 2.41140
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.69837

Cumulative Model Updates: 52,718
Cumulative Timesteps: 439,691,222

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,850.56538
Policy Entropy: 3.73440
Value Function Loss: 0.05193

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.48647
Value Function Update Magnitude: 0.74049

Collected Steps per Second: 22,158.76592
Overall Steps per Second: 10,837.53012

Timestep Collection Time: 2.25762
Timestep Consumption Time: 2.35838
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.61600

Cumulative Model Updates: 52,724
Cumulative Timesteps: 439,741,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 439741248...
Checkpoint 439741248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,893.54127
Policy Entropy: 3.72600
Value Function Loss: 0.05439

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.48336
Value Function Update Magnitude: 0.61068

Collected Steps per Second: 22,079.26663
Overall Steps per Second: 10,681.44446

Timestep Collection Time: 2.26493
Timestep Consumption Time: 2.41683
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.68176

Cumulative Model Updates: 52,730
Cumulative Timesteps: 439,791,256

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,668.36166
Policy Entropy: 3.72332
Value Function Loss: 0.05665

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.45551
Value Function Update Magnitude: 0.58786

Collected Steps per Second: 22,472.27775
Overall Steps per Second: 10,905.31283

Timestep Collection Time: 2.22496
Timestep Consumption Time: 2.35996
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.58492

Cumulative Model Updates: 52,736
Cumulative Timesteps: 439,841,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 439841256...
Checkpoint 439841256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.48149
Policy Entropy: 3.71381
Value Function Loss: 0.05461

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.45206
Value Function Update Magnitude: 0.59668

Collected Steps per Second: 21,979.83650
Overall Steps per Second: 10,676.87330

Timestep Collection Time: 2.27590
Timestep Consumption Time: 2.40936
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.68527

Cumulative Model Updates: 52,742
Cumulative Timesteps: 439,891,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,132.77355
Policy Entropy: 3.71321
Value Function Loss: 0.05473

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.45396
Value Function Update Magnitude: 0.60352

Collected Steps per Second: 22,291.04607
Overall Steps per Second: 10,835.75312

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.37215
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.61602

Cumulative Model Updates: 52,748
Cumulative Timesteps: 439,941,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 439941298...
Checkpoint 439941298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,326.85366
Policy Entropy: 3.70883
Value Function Loss: 0.05448

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.45534
Value Function Update Magnitude: 0.60407

Collected Steps per Second: 22,187.33731
Overall Steps per Second: 10,745.01484

Timestep Collection Time: 2.25408
Timestep Consumption Time: 2.40036
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.65444

Cumulative Model Updates: 52,754
Cumulative Timesteps: 439,991,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,451.43388
Policy Entropy: 3.70972
Value Function Loss: 0.05454

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.46881
Value Function Update Magnitude: 0.59885

Collected Steps per Second: 22,711.53557
Overall Steps per Second: 10,862.54176

Timestep Collection Time: 2.20223
Timestep Consumption Time: 2.40222
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.60445

Cumulative Model Updates: 52,760
Cumulative Timesteps: 440,041,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 440041326...
Checkpoint 440041326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,074.70233
Policy Entropy: 3.71356
Value Function Loss: 0.05305

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.49170
Value Function Update Magnitude: 0.62699

Collected Steps per Second: 22,747.33623
Overall Steps per Second: 10,696.07284

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.67573

Cumulative Model Updates: 52,766
Cumulative Timesteps: 440,091,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,686.71186
Policy Entropy: 3.71765
Value Function Loss: 0.05183

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.57556
Value Function Update Magnitude: 0.67884

Collected Steps per Second: 22,636.33218
Overall Steps per Second: 10,824.22250

Timestep Collection Time: 2.20981
Timestep Consumption Time: 2.41149
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.62130

Cumulative Model Updates: 52,772
Cumulative Timesteps: 440,141,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 440141360...
Checkpoint 440141360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,014.97301
Policy Entropy: 3.71478
Value Function Loss: 0.05114

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07415
Policy Update Magnitude: 0.64883
Value Function Update Magnitude: 0.76568

Collected Steps per Second: 22,700.25647
Overall Steps per Second: 10,670.90698

Timestep Collection Time: 2.20288
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.68620

Cumulative Model Updates: 52,778
Cumulative Timesteps: 440,191,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,347.36396
Policy Entropy: 3.72079
Value Function Loss: 0.05263

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.57909
Value Function Update Magnitude: 0.79818

Collected Steps per Second: 22,593.99112
Overall Steps per Second: 10,860.35491

Timestep Collection Time: 2.21360
Timestep Consumption Time: 2.39159
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.60519

Cumulative Model Updates: 52,784
Cumulative Timesteps: 440,241,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 440241380...
Checkpoint 440241380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,124.91732
Policy Entropy: 3.71825
Value Function Loss: 0.05285

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.52031
Value Function Update Magnitude: 0.81041

Collected Steps per Second: 22,907.08437
Overall Steps per Second: 10,721.23044

Timestep Collection Time: 2.18404
Timestep Consumption Time: 2.48240
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.66644

Cumulative Model Updates: 52,790
Cumulative Timesteps: 440,291,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,301.81426
Policy Entropy: 3.71721
Value Function Loss: 0.05189

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.49330
Value Function Update Magnitude: 0.81708

Collected Steps per Second: 22,947.42092
Overall Steps per Second: 10,806.73890

Timestep Collection Time: 2.17968
Timestep Consumption Time: 2.44873
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.62841

Cumulative Model Updates: 52,796
Cumulative Timesteps: 440,341,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 440341428...
Checkpoint 440341428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,374.47784
Policy Entropy: 3.71614
Value Function Loss: 0.05162

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.50056
Value Function Update Magnitude: 0.80082

Collected Steps per Second: 22,527.82759
Overall Steps per Second: 10,776.34486

Timestep Collection Time: 2.22081
Timestep Consumption Time: 2.42177
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.64258

Cumulative Model Updates: 52,802
Cumulative Timesteps: 440,391,458

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,591.30764
Policy Entropy: 3.72424
Value Function Loss: 0.05102

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.47253
Value Function Update Magnitude: 0.78933

Collected Steps per Second: 22,860.95541
Overall Steps per Second: 10,805.08677

Timestep Collection Time: 2.18766
Timestep Consumption Time: 2.44090
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.62856

Cumulative Model Updates: 52,808
Cumulative Timesteps: 440,441,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 440441470...
Checkpoint 440441470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,746.23963
Policy Entropy: 3.72855
Value Function Loss: 0.05173

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.47477
Value Function Update Magnitude: 0.80400

Collected Steps per Second: 22,741.38657
Overall Steps per Second: 10,694.54405

Timestep Collection Time: 2.19916
Timestep Consumption Time: 2.47724
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.67640

Cumulative Model Updates: 52,814
Cumulative Timesteps: 440,491,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,882.97804
Policy Entropy: 3.72554
Value Function Loss: 0.05213

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.48813
Value Function Update Magnitude: 0.82499

Collected Steps per Second: 22,860.05861
Overall Steps per Second: 10,798.13983

Timestep Collection Time: 2.18792
Timestep Consumption Time: 2.44399
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.63191

Cumulative Model Updates: 52,820
Cumulative Timesteps: 440,541,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 440541498...
Checkpoint 440541498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,828.86851
Policy Entropy: 3.71871
Value Function Loss: 0.05160

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.52126
Value Function Update Magnitude: 0.84648

Collected Steps per Second: 22,417.17209
Overall Steps per Second: 10,720.09256

Timestep Collection Time: 2.23052
Timestep Consumption Time: 2.43380
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.66433

Cumulative Model Updates: 52,826
Cumulative Timesteps: 440,591,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,396.66851
Policy Entropy: 3.71640
Value Function Loss: 0.05065

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.51774
Value Function Update Magnitude: 0.86204

Collected Steps per Second: 22,661.68878
Overall Steps per Second: 10,852.15234

Timestep Collection Time: 2.20734
Timestep Consumption Time: 2.40207
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60941

Cumulative Model Updates: 52,832
Cumulative Timesteps: 440,641,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 440641522...
Checkpoint 440641522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,241.53873
Policy Entropy: 3.72698
Value Function Loss: 0.04935

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.56979
Value Function Update Magnitude: 0.84771

Collected Steps per Second: 22,515.20138
Overall Steps per Second: 10,740.88566

Timestep Collection Time: 2.22268
Timestep Consumption Time: 2.43653
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.65921

Cumulative Model Updates: 52,838
Cumulative Timesteps: 440,691,566

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,217.77099
Policy Entropy: 3.72110
Value Function Loss: 0.05127

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.60425
Value Function Update Magnitude: 0.81593

Collected Steps per Second: 22,834.72286
Overall Steps per Second: 10,785.01123

Timestep Collection Time: 2.19009
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.63699

Cumulative Model Updates: 52,844
Cumulative Timesteps: 440,741,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 440741576...
Checkpoint 440741576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,623.49781
Policy Entropy: 3.71630
Value Function Loss: 0.05182

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08102
Policy Update Magnitude: 0.62396
Value Function Update Magnitude: 0.80854

Collected Steps per Second: 22,546.68061
Overall Steps per Second: 10,776.36207

Timestep Collection Time: 2.21877
Timestep Consumption Time: 2.42342
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.64220

Cumulative Model Updates: 52,850
Cumulative Timesteps: 440,791,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,669.33173
Policy Entropy: 3.70568
Value Function Loss: 0.05497

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.64554
Value Function Update Magnitude: 0.77616

Collected Steps per Second: 22,857.04883
Overall Steps per Second: 10,820.08573

Timestep Collection Time: 2.18777
Timestep Consumption Time: 2.43382
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62159

Cumulative Model Updates: 52,856
Cumulative Timesteps: 440,841,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 440841608...
Checkpoint 440841608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,706.43425
Policy Entropy: 3.71304
Value Function Loss: 0.05330

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06956
Policy Update Magnitude: 0.62811
Value Function Update Magnitude: 0.73593

Collected Steps per Second: 22,377.45293
Overall Steps per Second: 10,732.42158

Timestep Collection Time: 2.23520
Timestep Consumption Time: 2.42526
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.66046

Cumulative Model Updates: 52,862
Cumulative Timesteps: 440,891,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,619.21416
Policy Entropy: 3.72281
Value Function Loss: 0.05251

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06973
Policy Update Magnitude: 0.59670
Value Function Update Magnitude: 0.77444

Collected Steps per Second: 22,932.88690
Overall Steps per Second: 10,819.56695

Timestep Collection Time: 2.18106
Timestep Consumption Time: 2.44186
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.62292

Cumulative Model Updates: 52,868
Cumulative Timesteps: 440,941,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 440941644...
Checkpoint 440941644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,897.62890
Policy Entropy: 3.73688
Value Function Loss: 0.05235

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.51195
Value Function Update Magnitude: 0.80339

Collected Steps per Second: 22,639.52965
Overall Steps per Second: 10,688.03881

Timestep Collection Time: 2.20950
Timestep Consumption Time: 2.47069
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.68019

Cumulative Model Updates: 52,874
Cumulative Timesteps: 440,991,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.12164
Policy Entropy: 3.74336
Value Function Loss: 0.05219

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.46207
Value Function Update Magnitude: 0.81399

Collected Steps per Second: 22,914.54445
Overall Steps per Second: 10,832.56159

Timestep Collection Time: 2.18315
Timestep Consumption Time: 2.43496
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.61811

Cumulative Model Updates: 52,880
Cumulative Timesteps: 441,041,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 441041692...
Checkpoint 441041692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,299.60566
Policy Entropy: 3.73669
Value Function Loss: 0.05298

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.50615
Value Function Update Magnitude: 0.83043

Collected Steps per Second: 22,592.15016
Overall Steps per Second: 10,729.61719

Timestep Collection Time: 2.21351
Timestep Consumption Time: 2.44723
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.66074

Cumulative Model Updates: 52,886
Cumulative Timesteps: 441,091,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,963.21266
Policy Entropy: 3.72458
Value Function Loss: 0.05254

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.49233
Value Function Update Magnitude: 0.83566

Collected Steps per Second: 22,935.99127
Overall Steps per Second: 10,814.61991

Timestep Collection Time: 2.18024
Timestep Consumption Time: 2.44368
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.62393

Cumulative Model Updates: 52,892
Cumulative Timesteps: 441,141,706

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 441141706...
Checkpoint 441141706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,115.11244
Policy Entropy: 3.74994
Value Function Loss: 0.05231

Mean KL Divergence: 0.02088
SB3 Clip Fraction: 0.16773
Policy Update Magnitude: 0.43588
Value Function Update Magnitude: 0.82865

Collected Steps per Second: 22,532.06667
Overall Steps per Second: 10,688.54471

Timestep Collection Time: 2.22012
Timestep Consumption Time: 2.46003
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.68015

Cumulative Model Updates: 52,898
Cumulative Timesteps: 441,191,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,869.92810
Policy Entropy: 3.75890
Value Function Loss: 0.05277

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.49150
Value Function Update Magnitude: 0.82463

Collected Steps per Second: 22,798.92901
Overall Steps per Second: 10,848.53861

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.41718
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61150

Cumulative Model Updates: 52,904
Cumulative Timesteps: 441,241,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 441241758...
Checkpoint 441241758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,127.80651
Policy Entropy: 3.77786
Value Function Loss: 0.05522

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.61946
Value Function Update Magnitude: 0.73409

Collected Steps per Second: 22,603.59041
Overall Steps per Second: 10,727.94723

Timestep Collection Time: 2.21328
Timestep Consumption Time: 2.45006
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.66333

Cumulative Model Updates: 52,910
Cumulative Timesteps: 441,291,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,662.14070
Policy Entropy: 3.77848
Value Function Loss: 0.05503

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.63009
Value Function Update Magnitude: 0.69011

Collected Steps per Second: 21,946.04051
Overall Steps per Second: 10,685.77427

Timestep Collection Time: 2.27914
Timestep Consumption Time: 2.40167
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.68080

Cumulative Model Updates: 52,916
Cumulative Timesteps: 441,341,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 441341804...
Checkpoint 441341804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,102.20686
Policy Entropy: 3.76240
Value Function Loss: 0.05648

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.56115
Value Function Update Magnitude: 0.62789

Collected Steps per Second: 21,940.49190
Overall Steps per Second: 10,787.44719

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.35650
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.63576

Cumulative Model Updates: 52,922
Cumulative Timesteps: 441,391,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,764.87354
Policy Entropy: 3.76987
Value Function Loss: 0.05388

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.56827
Value Function Update Magnitude: 0.65810

Collected Steps per Second: 22,294.87240
Overall Steps per Second: 10,892.80209

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.34836
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.59184

Cumulative Model Updates: 52,928
Cumulative Timesteps: 441,441,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 441441830...
Checkpoint 441441830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,174.30240
Policy Entropy: 3.76954
Value Function Loss: 0.05385

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.53808
Value Function Update Magnitude: 0.64239

Collected Steps per Second: 22,044.13853
Overall Steps per Second: 10,726.69383

Timestep Collection Time: 2.26872
Timestep Consumption Time: 2.39367
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.66239

Cumulative Model Updates: 52,934
Cumulative Timesteps: 441,491,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,460.14844
Policy Entropy: 3.78438
Value Function Loss: 0.05219

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.53669
Value Function Update Magnitude: 0.62700

Collected Steps per Second: 21,906.49697
Overall Steps per Second: 10,635.05467

Timestep Collection Time: 2.28261
Timestep Consumption Time: 2.41920
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.70181

Cumulative Model Updates: 52,940
Cumulative Timesteps: 441,541,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 441541846...
Checkpoint 441541846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,144.90772
Policy Entropy: 3.79613
Value Function Loss: 0.05212

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.62033

Collected Steps per Second: 22,242.79088
Overall Steps per Second: 10,876.47260

Timestep Collection Time: 2.24819
Timestep Consumption Time: 2.34944
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.59763

Cumulative Model Updates: 52,946
Cumulative Timesteps: 441,591,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,597.45354
Policy Entropy: 3.79427
Value Function Loss: 0.05428

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.56965
Value Function Update Magnitude: 0.67201

Collected Steps per Second: 22,303.50587
Overall Steps per Second: 10,589.80084

Timestep Collection Time: 2.24252
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.72304

Cumulative Model Updates: 52,952
Cumulative Timesteps: 441,641,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 441641868...
Checkpoint 441641868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,761.31056
Policy Entropy: 3.78064
Value Function Loss: 0.05371

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10506
Policy Update Magnitude: 0.52074
Value Function Update Magnitude: 0.68427

Collected Steps per Second: 22,767.85275
Overall Steps per Second: 10,744.77492

Timestep Collection Time: 2.19678
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.65491

Cumulative Model Updates: 52,958
Cumulative Timesteps: 441,691,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,348.32729
Policy Entropy: 3.75273
Value Function Loss: 0.05457

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.54012
Value Function Update Magnitude: 0.67100

Collected Steps per Second: 22,937.50077
Overall Steps per Second: 10,724.79886

Timestep Collection Time: 2.18036
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.66321

Cumulative Model Updates: 52,964
Cumulative Timesteps: 441,741,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 441741896...
Checkpoint 441741896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.83083
Policy Entropy: 3.75394
Value Function Loss: 0.05156

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.50615
Value Function Update Magnitude: 0.69579

Collected Steps per Second: 22,671.57874
Overall Steps per Second: 10,674.47979

Timestep Collection Time: 2.20637
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.68613

Cumulative Model Updates: 52,970
Cumulative Timesteps: 441,791,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,611.45946
Policy Entropy: 3.74259
Value Function Loss: 0.05287

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.48726
Value Function Update Magnitude: 0.73583

Collected Steps per Second: 22,976.98310
Overall Steps per Second: 10,831.36543

Timestep Collection Time: 2.17722
Timestep Consumption Time: 2.44140
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.61862

Cumulative Model Updates: 52,976
Cumulative Timesteps: 441,841,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 441841944...
Checkpoint 441841944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,938.06649
Policy Entropy: 3.73574
Value Function Loss: 0.05354

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.50417
Value Function Update Magnitude: 0.73106

Collected Steps per Second: 22,865.36289
Overall Steps per Second: 10,666.25663

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.68768

Cumulative Model Updates: 52,982
Cumulative Timesteps: 441,891,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,373.47317
Policy Entropy: 3.71865
Value Function Loss: 0.05558

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.47127
Value Function Update Magnitude: 0.68178

Collected Steps per Second: 22,747.47749
Overall Steps per Second: 10,777.76043

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.44241
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.64160

Cumulative Model Updates: 52,988
Cumulative Timesteps: 441,941,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 441941970...
Checkpoint 441941970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,159.40432
Policy Entropy: 3.72432
Value Function Loss: 0.05499

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.50645
Value Function Update Magnitude: 0.65673

Collected Steps per Second: 22,440.76316
Overall Steps per Second: 10,755.14888

Timestep Collection Time: 2.22916
Timestep Consumption Time: 2.42201
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.65117

Cumulative Model Updates: 52,994
Cumulative Timesteps: 441,991,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,826.34821
Policy Entropy: 3.73204
Value Function Loss: 0.05282

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.46429
Value Function Update Magnitude: 0.64161

Collected Steps per Second: 22,870.74686
Overall Steps per Second: 10,820.19023

Timestep Collection Time: 2.18742
Timestep Consumption Time: 2.43616
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.62358

Cumulative Model Updates: 53,000
Cumulative Timesteps: 442,042,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 442042022...
Checkpoint 442042022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,225.96449
Policy Entropy: 3.73435
Value Function Loss: 0.05234

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.47778
Value Function Update Magnitude: 0.66927

Collected Steps per Second: 22,335.07270
Overall Steps per Second: 10,749.71425

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.41410
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.65408

Cumulative Model Updates: 53,006
Cumulative Timesteps: 442,092,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,874.56200
Policy Entropy: 3.72516
Value Function Loss: 0.05361

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.48962
Value Function Update Magnitude: 0.67594

Collected Steps per Second: 22,747.14857
Overall Steps per Second: 10,718.34889

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.46682
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.66490

Cumulative Model Updates: 53,012
Cumulative Timesteps: 442,142,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 442142052...
Checkpoint 442142052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,768.07147
Policy Entropy: 3.71814
Value Function Loss: 0.05629

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.47345
Value Function Update Magnitude: 0.67429

Collected Steps per Second: 22,495.19507
Overall Steps per Second: 10,725.45669

Timestep Collection Time: 2.22287
Timestep Consumption Time: 2.43930
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.66218

Cumulative Model Updates: 53,018
Cumulative Timesteps: 442,192,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,231.46218
Policy Entropy: 3.70621
Value Function Loss: 0.05597

Mean KL Divergence: 0.02182
SB3 Clip Fraction: 0.17066
Policy Update Magnitude: 0.40703
Value Function Update Magnitude: 0.70600

Collected Steps per Second: 22,661.55511
Overall Steps per Second: 10,642.78515

Timestep Collection Time: 2.20700
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.69933

Cumulative Model Updates: 53,024
Cumulative Timesteps: 442,242,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 442242070...
Checkpoint 442242070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,122.52557
Policy Entropy: 3.72332
Value Function Loss: 0.05460

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.38815
Value Function Update Magnitude: 0.67266

Collected Steps per Second: 22,597.61326
Overall Steps per Second: 10,667.65191

Timestep Collection Time: 2.21351
Timestep Consumption Time: 2.47543
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.68894

Cumulative Model Updates: 53,030
Cumulative Timesteps: 442,292,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,315.39304
Policy Entropy: 3.72878
Value Function Loss: 0.05136

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.42908
Value Function Update Magnitude: 0.65458

Collected Steps per Second: 22,668.47174
Overall Steps per Second: 10,756.97500

Timestep Collection Time: 2.20571
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.64815

Cumulative Model Updates: 53,036
Cumulative Timesteps: 442,342,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 442342090...
Checkpoint 442342090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,951.90790
Policy Entropy: 3.73880
Value Function Loss: 0.05019

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06594
Policy Update Magnitude: 0.50071
Value Function Update Magnitude: 0.58483

Collected Steps per Second: 22,594.05396
Overall Steps per Second: 10,612.01542

Timestep Collection Time: 2.21386
Timestep Consumption Time: 2.49967
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.71352

Cumulative Model Updates: 53,042
Cumulative Timesteps: 442,392,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,431.69311
Policy Entropy: 3.73793
Value Function Loss: 0.05253

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06533
Policy Update Magnitude: 0.58871
Value Function Update Magnitude: 0.56937

Collected Steps per Second: 22,888.32523
Overall Steps per Second: 10,815.04228

Timestep Collection Time: 2.18504
Timestep Consumption Time: 2.43926
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.62430

Cumulative Model Updates: 53,048
Cumulative Timesteps: 442,442,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 442442122...
Checkpoint 442442122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,790.94858
Policy Entropy: 3.73825
Value Function Loss: 0.05237

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07026
Policy Update Magnitude: 0.63059
Value Function Update Magnitude: 0.57846

Collected Steps per Second: 22,190.93671
Overall Steps per Second: 10,668.01731

Timestep Collection Time: 2.25443
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.68953

Cumulative Model Updates: 53,054
Cumulative Timesteps: 442,492,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,085.07347
Policy Entropy: 3.72587
Value Function Loss: 0.05385

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.63740
Value Function Update Magnitude: 0.59386

Collected Steps per Second: 22,960.17795
Overall Steps per Second: 10,721.28467

Timestep Collection Time: 2.17803
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.66437

Cumulative Model Updates: 53,060
Cumulative Timesteps: 442,542,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 442542158...
Checkpoint 442542158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,445.78427
Policy Entropy: 3.73003
Value Function Loss: 0.05175

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.58039
Value Function Update Magnitude: 0.58227

Collected Steps per Second: 22,621.16766
Overall Steps per Second: 10,816.09588

Timestep Collection Time: 2.21138
Timestep Consumption Time: 2.41358
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.62496

Cumulative Model Updates: 53,066
Cumulative Timesteps: 442,592,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,852.40333
Policy Entropy: 3.72123
Value Function Loss: 0.05325

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06689
Policy Update Magnitude: 0.60630
Value Function Update Magnitude: 0.56197

Collected Steps per Second: 22,764.01521
Overall Steps per Second: 10,675.49466

Timestep Collection Time: 2.19680
Timestep Consumption Time: 2.48757
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.68437

Cumulative Model Updates: 53,072
Cumulative Timesteps: 442,642,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 442642190...
Checkpoint 442642190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.95444
Policy Entropy: 3.72661
Value Function Loss: 0.05407

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06429
Policy Update Magnitude: 0.64354
Value Function Update Magnitude: 0.62446

Collected Steps per Second: 22,715.87646
Overall Steps per Second: 10,699.36954

Timestep Collection Time: 2.20128
Timestep Consumption Time: 2.47227
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.67355

Cumulative Model Updates: 53,078
Cumulative Timesteps: 442,692,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,295.12196
Policy Entropy: 3.71704
Value Function Loss: 0.05593

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.63209
Value Function Update Magnitude: 0.67009

Collected Steps per Second: 22,282.37330
Overall Steps per Second: 10,683.64955

Timestep Collection Time: 2.24464
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.68155

Cumulative Model Updates: 53,084
Cumulative Timesteps: 442,742,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 442742210...
Checkpoint 442742210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,365.73835
Policy Entropy: 3.70187
Value Function Loss: 0.05549

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06712
Policy Update Magnitude: 0.63287
Value Function Update Magnitude: 0.64136

Collected Steps per Second: 21,715.30130
Overall Steps per Second: 10,674.15019

Timestep Collection Time: 2.30354
Timestep Consumption Time: 2.38274
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.68627

Cumulative Model Updates: 53,090
Cumulative Timesteps: 442,792,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,908.61988
Policy Entropy: 3.69314
Value Function Loss: 0.05301

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06366
Policy Update Magnitude: 0.63840
Value Function Update Magnitude: 0.70821

Collected Steps per Second: 22,321.02318
Overall Steps per Second: 10,887.41272

Timestep Collection Time: 2.24103
Timestep Consumption Time: 2.35345
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.59448

Cumulative Model Updates: 53,096
Cumulative Timesteps: 442,842,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 442842254...
Checkpoint 442842254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,376.90786
Policy Entropy: 3.68840
Value Function Loss: 0.05140

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.55484
Value Function Update Magnitude: 0.73765

Collected Steps per Second: 21,942.78702
Overall Steps per Second: 10,672.33604

Timestep Collection Time: 2.27902
Timestep Consumption Time: 2.40674
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.68576

Cumulative Model Updates: 53,102
Cumulative Timesteps: 442,892,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,031.19546
Policy Entropy: 3.70593
Value Function Loss: 0.05205

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.51992
Value Function Update Magnitude: 0.67675

Collected Steps per Second: 22,066.26765
Overall Steps per Second: 10,816.76085

Timestep Collection Time: 2.26590
Timestep Consumption Time: 2.35655
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.62246

Cumulative Model Updates: 53,108
Cumulative Timesteps: 442,942,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 442942262...
Checkpoint 442942262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,298.18054
Policy Entropy: 3.70250
Value Function Loss: 0.05215

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.56014
Value Function Update Magnitude: 0.67850

Collected Steps per Second: 22,107.31575
Overall Steps per Second: 10,663.18997

Timestep Collection Time: 2.26296
Timestep Consumption Time: 2.42869
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.69165

Cumulative Model Updates: 53,114
Cumulative Timesteps: 442,992,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,038.55841
Policy Entropy: 3.70909
Value Function Loss: 0.05025

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.52988
Value Function Update Magnitude: 0.71429

Collected Steps per Second: 22,838.55341
Overall Steps per Second: 10,876.45762

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.40886
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.59911

Cumulative Model Updates: 53,120
Cumulative Timesteps: 443,042,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 443042312...
Checkpoint 443042312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.55345
Policy Entropy: 3.70280
Value Function Loss: 0.05113

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.52411
Value Function Update Magnitude: 0.69194

Collected Steps per Second: 22,685.68803
Overall Steps per Second: 10,749.10612

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.44771
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.65192

Cumulative Model Updates: 53,126
Cumulative Timesteps: 443,092,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,219.27530
Policy Entropy: 3.70539
Value Function Loss: 0.05031

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.51922
Value Function Update Magnitude: 0.70437

Collected Steps per Second: 22,591.04131
Overall Steps per Second: 10,815.23423

Timestep Collection Time: 2.21406
Timestep Consumption Time: 2.41071
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.62477

Cumulative Model Updates: 53,132
Cumulative Timesteps: 443,142,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 443142334...
Checkpoint 443142334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,456.80189
Policy Entropy: 3.70552
Value Function Loss: 0.05081

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.48260
Value Function Update Magnitude: 0.74018

Collected Steps per Second: 22,482.65058
Overall Steps per Second: 10,717.34892

Timestep Collection Time: 2.22492
Timestep Consumption Time: 2.44247
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.66739

Cumulative Model Updates: 53,138
Cumulative Timesteps: 443,192,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,787.59871
Policy Entropy: 3.70039
Value Function Loss: 0.05301

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.48381
Value Function Update Magnitude: 0.75259

Collected Steps per Second: 22,772.39346
Overall Steps per Second: 10,820.84078

Timestep Collection Time: 2.19678
Timestep Consumption Time: 2.42633
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62312

Cumulative Model Updates: 53,144
Cumulative Timesteps: 443,242,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 443242382...
Checkpoint 443242382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,515.28614
Policy Entropy: 3.69408
Value Function Loss: 0.05485

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.48226
Value Function Update Magnitude: 0.73284

Collected Steps per Second: 22,622.55303
Overall Steps per Second: 10,794.25780

Timestep Collection Time: 2.21151
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.63487

Cumulative Model Updates: 53,150
Cumulative Timesteps: 443,292,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,754.52838
Policy Entropy: 3.69847
Value Function Loss: 0.05797

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.49904
Value Function Update Magnitude: 0.63898

Collected Steps per Second: 22,582.80010
Overall Steps per Second: 10,742.52727

Timestep Collection Time: 2.21531
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.65700

Cumulative Model Updates: 53,156
Cumulative Timesteps: 443,342,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 443342440...
Checkpoint 443342440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,034.16842
Policy Entropy: 3.70166
Value Function Loss: 0.05892

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.48252
Value Function Update Magnitude: 0.60637

Collected Steps per Second: 22,336.23935
Overall Steps per Second: 10,700.76673

Timestep Collection Time: 2.23941
Timestep Consumption Time: 2.43502
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.67443

Cumulative Model Updates: 53,162
Cumulative Timesteps: 443,392,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,829.78977
Policy Entropy: 3.70953
Value Function Loss: 0.05570

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.47060
Value Function Update Magnitude: 0.67643

Collected Steps per Second: 22,854.60195
Overall Steps per Second: 10,884.89020

Timestep Collection Time: 2.18774
Timestep Consumption Time: 2.40578
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.59352

Cumulative Model Updates: 53,168
Cumulative Timesteps: 443,442,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 443442460...
Checkpoint 443442460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,708.47379
Policy Entropy: 3.70560
Value Function Loss: 0.05467

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.48535
Value Function Update Magnitude: 0.75469

Collected Steps per Second: 22,741.49159
Overall Steps per Second: 10,701.17840

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.47425
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.67332

Cumulative Model Updates: 53,174
Cumulative Timesteps: 443,492,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,994.20423
Policy Entropy: 3.71106
Value Function Loss: 0.05390

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.50821
Value Function Update Magnitude: 0.77770

Collected Steps per Second: 22,806.18188
Overall Steps per Second: 10,790.86349

Timestep Collection Time: 2.19283
Timestep Consumption Time: 2.44165
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.63448

Cumulative Model Updates: 53,180
Cumulative Timesteps: 443,542,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 443542480...
Checkpoint 443542480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,891.77623
Policy Entropy: 3.72081
Value Function Loss: 0.05334

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.49782
Value Function Update Magnitude: 0.80105

Collected Steps per Second: 22,417.92300
Overall Steps per Second: 10,728.50575

Timestep Collection Time: 2.23054
Timestep Consumption Time: 2.43032
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.66085

Cumulative Model Updates: 53,186
Cumulative Timesteps: 443,592,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,312.01212
Policy Entropy: 3.72978
Value Function Loss: 0.05125

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.45411
Value Function Update Magnitude: 0.77542

Collected Steps per Second: 23,172.49518
Overall Steps per Second: 10,896.29273

Timestep Collection Time: 2.15851
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59037

Cumulative Model Updates: 53,192
Cumulative Timesteps: 443,642,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 443642502...
Checkpoint 443642502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,106.04235
Policy Entropy: 3.73575
Value Function Loss: 0.04883

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.49210
Value Function Update Magnitude: 0.78207

Collected Steps per Second: 22,826.23012
Overall Steps per Second: 10,693.89722

Timestep Collection Time: 2.19116
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.67706

Cumulative Model Updates: 53,198
Cumulative Timesteps: 443,692,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,632.31788
Policy Entropy: 3.72157
Value Function Loss: 0.05245

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.52586
Value Function Update Magnitude: 0.75529

Collected Steps per Second: 22,600.32158
Overall Steps per Second: 10,618.08172

Timestep Collection Time: 2.21236
Timestep Consumption Time: 2.49659
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.70895

Cumulative Model Updates: 53,204
Cumulative Timesteps: 443,742,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 443742518...
Checkpoint 443742518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,660.01353
Policy Entropy: 3.70849
Value Function Loss: 0.05703

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.55250
Value Function Update Magnitude: 0.66641

Collected Steps per Second: 22,689.58533
Overall Steps per Second: 10,793.74246

Timestep Collection Time: 2.20365
Timestep Consumption Time: 2.42866
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.63231

Cumulative Model Updates: 53,210
Cumulative Timesteps: 443,792,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,687.73585
Policy Entropy: 3.70105
Value Function Loss: 0.06179

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06727
Policy Update Magnitude: 0.60449
Value Function Update Magnitude: 0.63083

Collected Steps per Second: 22,687.69489
Overall Steps per Second: 10,612.05445

Timestep Collection Time: 2.20463
Timestep Consumption Time: 2.50869
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.71332

Cumulative Model Updates: 53,216
Cumulative Timesteps: 443,842,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 443842536...
Checkpoint 443842536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,100.87208
Policy Entropy: 3.71030
Value Function Loss: 0.06009

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06887
Policy Update Magnitude: 0.61900
Value Function Update Magnitude: 0.52630

Collected Steps per Second: 22,600.23501
Overall Steps per Second: 10,610.06652

Timestep Collection Time: 2.21361
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.71514

Cumulative Model Updates: 53,222
Cumulative Timesteps: 443,892,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,784.51347
Policy Entropy: 3.69836
Value Function Loss: 0.05860

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.57275
Value Function Update Magnitude: 0.53528

Collected Steps per Second: 22,849.68248
Overall Steps per Second: 10,808.27789

Timestep Collection Time: 2.18848
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.62664

Cumulative Model Updates: 53,228
Cumulative Timesteps: 443,942,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 443942570...
Checkpoint 443942570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,498.93738
Policy Entropy: 3.69959
Value Function Loss: 0.05709

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.51534
Value Function Update Magnitude: 0.54382

Collected Steps per Second: 22,778.44064
Overall Steps per Second: 10,706.65461

Timestep Collection Time: 2.19611
Timestep Consumption Time: 2.47612
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.67223

Cumulative Model Updates: 53,234
Cumulative Timesteps: 443,992,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,781.11941
Policy Entropy: 3.70542
Value Function Loss: 0.05477

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.51016
Value Function Update Magnitude: 0.56595

Collected Steps per Second: 22,651.34321
Overall Steps per Second: 10,672.42806

Timestep Collection Time: 2.20764
Timestep Consumption Time: 2.47789
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.68553

Cumulative Model Updates: 53,240
Cumulative Timesteps: 444,042,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 444042600...
Checkpoint 444042600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,896.63638
Policy Entropy: 3.72390
Value Function Loss: 0.05440

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.52487
Value Function Update Magnitude: 0.58808

Collected Steps per Second: 22,604.00834
Overall Steps per Second: 10,650.76638

Timestep Collection Time: 2.21226
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.69506

Cumulative Model Updates: 53,246
Cumulative Timesteps: 444,092,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,465.91871
Policy Entropy: 3.72456
Value Function Loss: 0.05343

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.50667
Value Function Update Magnitude: 0.67118

Collected Steps per Second: 23,073.82475
Overall Steps per Second: 10,689.93066

Timestep Collection Time: 2.16817
Timestep Consumption Time: 2.51175
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.67992

Cumulative Model Updates: 53,252
Cumulative Timesteps: 444,142,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 444142634...
Checkpoint 444142634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,736.81122
Policy Entropy: 3.73078
Value Function Loss: 0.05432

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.49153
Value Function Update Magnitude: 0.67913

Collected Steps per Second: 22,576.56466
Overall Steps per Second: 10,644.24028

Timestep Collection Time: 2.21486
Timestep Consumption Time: 2.48289
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.69775

Cumulative Model Updates: 53,258
Cumulative Timesteps: 444,192,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,043.03621
Policy Entropy: 3.73391
Value Function Loss: 0.05130

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.55829
Value Function Update Magnitude: 0.74875

Collected Steps per Second: 22,992.24025
Overall Steps per Second: 10,828.83169

Timestep Collection Time: 2.17543
Timestep Consumption Time: 2.44354
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.61897

Cumulative Model Updates: 53,264
Cumulative Timesteps: 444,242,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 444242656...
Checkpoint 444242656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,272.03578
Policy Entropy: 3.73311
Value Function Loss: 0.04726

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07153
Policy Update Magnitude: 0.57545
Value Function Update Magnitude: 0.78568

Collected Steps per Second: 22,575.72966
Overall Steps per Second: 10,714.26751

Timestep Collection Time: 2.21610
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.66947

Cumulative Model Updates: 53,270
Cumulative Timesteps: 444,292,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,585.16289
Policy Entropy: 3.72354
Value Function Loss: 0.04652

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.52848
Value Function Update Magnitude: 0.77473

Collected Steps per Second: 22,678.31971
Overall Steps per Second: 10,661.44508

Timestep Collection Time: 2.20545
Timestep Consumption Time: 2.48584
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.69130

Cumulative Model Updates: 53,276
Cumulative Timesteps: 444,342,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 444342702...
Checkpoint 444342702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,517.97166
Policy Entropy: 3.71444
Value Function Loss: 0.04937

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.48188
Value Function Update Magnitude: 0.77454

Collected Steps per Second: 22,950.48739
Overall Steps per Second: 10,831.85573

Timestep Collection Time: 2.17965
Timestep Consumption Time: 2.43858
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.61823

Cumulative Model Updates: 53,282
Cumulative Timesteps: 444,392,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,892.07041
Policy Entropy: 3.71371
Value Function Loss: 0.05193

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.48302
Value Function Update Magnitude: 0.79904

Collected Steps per Second: 22,981.49725
Overall Steps per Second: 10,851.37321

Timestep Collection Time: 2.17601
Timestep Consumption Time: 2.43244
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60845

Cumulative Model Updates: 53,288
Cumulative Timesteps: 444,442,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 444442734...
Checkpoint 444442734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,842.43115
Policy Entropy: 3.70337
Value Function Loss: 0.05268

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.49548
Value Function Update Magnitude: 0.81014

Collected Steps per Second: 22,367.70207
Overall Steps per Second: 10,723.30237

Timestep Collection Time: 2.23617
Timestep Consumption Time: 2.42825
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.66442

Cumulative Model Updates: 53,294
Cumulative Timesteps: 444,492,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,520.49737
Policy Entropy: 3.70268
Value Function Loss: 0.05265

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.49825
Value Function Update Magnitude: 0.75217

Collected Steps per Second: 22,943.72928
Overall Steps per Second: 10,832.53813

Timestep Collection Time: 2.17977
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.61683

Cumulative Model Updates: 53,300
Cumulative Timesteps: 444,542,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 444542764...
Checkpoint 444542764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,055.81361
Policy Entropy: 3.70315
Value Function Loss: 0.05221

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.46298
Value Function Update Magnitude: 0.76642

Collected Steps per Second: 22,599.46228
Overall Steps per Second: 10,735.96502

Timestep Collection Time: 2.21324
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.65892

Cumulative Model Updates: 53,306
Cumulative Timesteps: 444,592,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,278.43675
Policy Entropy: 3.71117
Value Function Loss: 0.05183

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.45865
Value Function Update Magnitude: 0.82176

Collected Steps per Second: 23,160.26463
Overall Steps per Second: 10,906.04349

Timestep Collection Time: 2.16017
Timestep Consumption Time: 2.42720
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58736

Cumulative Model Updates: 53,312
Cumulative Timesteps: 444,642,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 444642812...
Checkpoint 444642812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,737.35230
Policy Entropy: 3.72952
Value Function Loss: 0.05242

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10233
Policy Update Magnitude: 0.47927
Value Function Update Magnitude: 0.77814

Collected Steps per Second: 22,803.58677
Overall Steps per Second: 10,673.22563

Timestep Collection Time: 2.19387
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.68724

Cumulative Model Updates: 53,318
Cumulative Timesteps: 444,692,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,741.87969
Policy Entropy: 3.73491
Value Function Loss: 0.05347

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.48836
Value Function Update Magnitude: 0.75830

Collected Steps per Second: 22,637.53376
Overall Steps per Second: 10,799.03863

Timestep Collection Time: 2.21005
Timestep Consumption Time: 2.42277
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.63282

Cumulative Model Updates: 53,324
Cumulative Timesteps: 444,742,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 444742870...
Checkpoint 444742870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,210.97138
Policy Entropy: 3.73660
Value Function Loss: 0.05433

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08057
Policy Update Magnitude: 0.53545
Value Function Update Magnitude: 0.80080

Collected Steps per Second: 21,454.66895
Overall Steps per Second: 10,678.98975

Timestep Collection Time: 2.33068
Timestep Consumption Time: 2.35178
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.68247

Cumulative Model Updates: 53,330
Cumulative Timesteps: 444,792,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,326.95718
Policy Entropy: 3.73258
Value Function Loss: 0.05507

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.52973
Value Function Update Magnitude: 0.84356

Collected Steps per Second: 22,294.48848
Overall Steps per Second: 10,863.66176

Timestep Collection Time: 2.24316
Timestep Consumption Time: 2.36026
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.60342

Cumulative Model Updates: 53,336
Cumulative Timesteps: 444,842,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 444842884...
Checkpoint 444842884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,854.36604
Policy Entropy: 3.72737
Value Function Loss: 0.05568

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.49766
Value Function Update Magnitude: 0.86384

Collected Steps per Second: 22,039.80395
Overall Steps per Second: 10,734.44438

Timestep Collection Time: 2.26899
Timestep Consumption Time: 2.38966
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.65865

Cumulative Model Updates: 53,342
Cumulative Timesteps: 444,892,892

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,112.51151
Policy Entropy: 3.72123
Value Function Loss: 0.05571

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.48097
Value Function Update Magnitude: 0.89119

Collected Steps per Second: 22,147.05549
Overall Steps per Second: 10,832.03566

Timestep Collection Time: 2.25827
Timestep Consumption Time: 2.35896
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61723

Cumulative Model Updates: 53,348
Cumulative Timesteps: 444,942,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 444942906...
Checkpoint 444942906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,320.32024
Policy Entropy: 3.71888
Value Function Loss: 0.05492

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.49455
Value Function Update Magnitude: 0.89215

Collected Steps per Second: 21,216.14488
Overall Steps per Second: 10,339.40684

Timestep Collection Time: 2.35764
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.83780

Cumulative Model Updates: 53,354
Cumulative Timesteps: 444,992,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,651.04394
Policy Entropy: 3.70299
Value Function Loss: 0.05414

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.52157
Value Function Update Magnitude: 0.88343

Collected Steps per Second: 23,024.32131
Overall Steps per Second: 10,856.10726

Timestep Collection Time: 2.17327
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.60920

Cumulative Model Updates: 53,360
Cumulative Timesteps: 445,042,964

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 445042964...
Checkpoint 445042964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,862.25562
Policy Entropy: 3.68391
Value Function Loss: 0.05607

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.49586
Value Function Update Magnitude: 0.90059

Collected Steps per Second: 22,614.67495
Overall Steps per Second: 10,683.89077

Timestep Collection Time: 2.21157
Timestep Consumption Time: 2.46968
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.68125

Cumulative Model Updates: 53,366
Cumulative Timesteps: 445,092,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,474.86218
Policy Entropy: 3.66910
Value Function Loss: 0.05664

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.50745
Value Function Update Magnitude: 0.90741

Collected Steps per Second: 23,140.55844
Overall Steps per Second: 10,824.58443

Timestep Collection Time: 2.16088
Timestep Consumption Time: 2.45860
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.61948

Cumulative Model Updates: 53,372
Cumulative Timesteps: 445,142,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 445142982...
Checkpoint 445142982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,080.74467
Policy Entropy: 3.66863
Value Function Loss: 0.05729

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11457
Policy Update Magnitude: 0.46421
Value Function Update Magnitude: 0.85799

Collected Steps per Second: 22,828.67506
Overall Steps per Second: 10,627.61496

Timestep Collection Time: 2.19067
Timestep Consumption Time: 2.51500
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.70567

Cumulative Model Updates: 53,378
Cumulative Timesteps: 445,192,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,345.41161
Policy Entropy: 3.67855
Value Function Loss: 0.05871

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.45764
Value Function Update Magnitude: 0.77687

Collected Steps per Second: 22,976.42511
Overall Steps per Second: 10,730.78044

Timestep Collection Time: 2.17675
Timestep Consumption Time: 2.48405
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.66080

Cumulative Model Updates: 53,384
Cumulative Timesteps: 445,243,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 445243006...
Checkpoint 445243006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,543.21809
Policy Entropy: 3.69759
Value Function Loss: 0.05770

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.46429
Value Function Update Magnitude: 0.69930

Collected Steps per Second: 22,595.39930
Overall Steps per Second: 10,803.79272

Timestep Collection Time: 2.21381
Timestep Consumption Time: 2.41623
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.63004

Cumulative Model Updates: 53,390
Cumulative Timesteps: 445,293,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,880.39567
Policy Entropy: 3.71273
Value Function Loss: 0.05658

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.47902
Value Function Update Magnitude: 0.65780

Collected Steps per Second: 22,806.21020
Overall Steps per Second: 10,665.57724

Timestep Collection Time: 2.19239
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.68798

Cumulative Model Updates: 53,396
Cumulative Timesteps: 445,343,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 445343028...
Checkpoint 445343028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,366.81983
Policy Entropy: 3.71410
Value Function Loss: 0.05808

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.45796
Value Function Update Magnitude: 0.66607

Collected Steps per Second: 22,298.37541
Overall Steps per Second: 10,538.70827

Timestep Collection Time: 2.24258
Timestep Consumption Time: 2.50240
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.74498

Cumulative Model Updates: 53,402
Cumulative Timesteps: 445,393,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,340.82969
Policy Entropy: 3.72446
Value Function Loss: 0.05506

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.46411
Value Function Update Magnitude: 0.72561

Collected Steps per Second: 22,826.08998
Overall Steps per Second: 10,810.62841

Timestep Collection Time: 2.19232
Timestep Consumption Time: 2.43665
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62896

Cumulative Model Updates: 53,408
Cumulative Timesteps: 445,443,076

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 445443076...
Checkpoint 445443076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,470.39587
Policy Entropy: 3.72030
Value Function Loss: 0.05783

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.48802
Value Function Update Magnitude: 0.71829

Collected Steps per Second: 22,099.38210
Overall Steps per Second: 10,668.71302

Timestep Collection Time: 2.26350
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.68866

Cumulative Model Updates: 53,414
Cumulative Timesteps: 445,493,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,648.85991
Policy Entropy: 3.71369
Value Function Loss: 0.05842

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.46026
Value Function Update Magnitude: 0.76792

Collected Steps per Second: 22,977.29235
Overall Steps per Second: 10,844.10136

Timestep Collection Time: 2.17658
Timestep Consumption Time: 2.43532
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61191

Cumulative Model Updates: 53,420
Cumulative Timesteps: 445,543,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 445543110...
Checkpoint 445543110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,923.19905
Policy Entropy: 3.70272
Value Function Loss: 0.05998

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.48707
Value Function Update Magnitude: 0.74480

Collected Steps per Second: 22,334.11096
Overall Steps per Second: 10,708.37057

Timestep Collection Time: 2.24070
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.67335

Cumulative Model Updates: 53,426
Cumulative Timesteps: 445,593,154

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,536.49925
Policy Entropy: 3.70010
Value Function Loss: 0.05863

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.58118
Value Function Update Magnitude: 0.70142

Collected Steps per Second: 22,642.39963
Overall Steps per Second: 10,649.38310

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.48815
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.69755

Cumulative Model Updates: 53,432
Cumulative Timesteps: 445,643,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 445643180...
Checkpoint 445643180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,562.57543
Policy Entropy: 3.71153
Value Function Loss: 0.05679

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.60049
Value Function Update Magnitude: 0.68032

Collected Steps per Second: 22,706.09413
Overall Steps per Second: 10,640.51246

Timestep Collection Time: 2.20205
Timestep Consumption Time: 2.49697
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.69902

Cumulative Model Updates: 53,438
Cumulative Timesteps: 445,693,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,921.92096
Policy Entropy: 3.71764
Value Function Loss: 0.05732

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.63661
Value Function Update Magnitude: 0.64493

Collected Steps per Second: 22,715.78910
Overall Steps per Second: 10,695.08401

Timestep Collection Time: 2.20155
Timestep Consumption Time: 2.47443
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.67598

Cumulative Model Updates: 53,444
Cumulative Timesteps: 445,743,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 445743190...
Checkpoint 445743190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,761.30609
Policy Entropy: 3.72210
Value Function Loss: 0.05628

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06700
Policy Update Magnitude: 0.66760
Value Function Update Magnitude: 0.68031

Collected Steps per Second: 22,485.53777
Overall Steps per Second: 10,659.17347

Timestep Collection Time: 2.22499
Timestep Consumption Time: 2.46862
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.69361

Cumulative Model Updates: 53,450
Cumulative Timesteps: 445,793,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,108.28557
Policy Entropy: 3.71934
Value Function Loss: 0.05828

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06339
Policy Update Magnitude: 0.66874
Value Function Update Magnitude: 0.71812

Collected Steps per Second: 23,236.68282
Overall Steps per Second: 10,938.11258

Timestep Collection Time: 2.15186
Timestep Consumption Time: 2.41950
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.57136

Cumulative Model Updates: 53,456
Cumulative Timesteps: 445,843,222

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 445843222...
Checkpoint 445843222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,777.32428
Policy Entropy: 3.72278
Value Function Loss: 0.05856

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05893
Policy Update Magnitude: 0.70156
Value Function Update Magnitude: 0.71701

Collected Steps per Second: 22,499.51395
Overall Steps per Second: 10,588.94229

Timestep Collection Time: 2.22351
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.72455

Cumulative Model Updates: 53,462
Cumulative Timesteps: 445,893,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,451.25519
Policy Entropy: 3.71707
Value Function Loss: 0.05867

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.69458
Value Function Update Magnitude: 0.66344

Collected Steps per Second: 22,974.40577
Overall Steps per Second: 10,833.95253

Timestep Collection Time: 2.17755
Timestep Consumption Time: 2.44015
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61771

Cumulative Model Updates: 53,468
Cumulative Timesteps: 445,943,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 445943278...
Checkpoint 445943278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,620.58787
Policy Entropy: 3.72003
Value Function Loss: 0.05938

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.65614
Value Function Update Magnitude: 0.66550

Collected Steps per Second: 22,642.07438
Overall Steps per Second: 10,777.37139

Timestep Collection Time: 2.20960
Timestep Consumption Time: 2.43253
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.64213

Cumulative Model Updates: 53,474
Cumulative Timesteps: 445,993,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,480.93515
Policy Entropy: 3.73215
Value Function Loss: 0.05575

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.64126
Value Function Update Magnitude: 0.73373

Collected Steps per Second: 22,948.22539
Overall Steps per Second: 10,841.55319

Timestep Collection Time: 2.17995
Timestep Consumption Time: 2.43433
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61428

Cumulative Model Updates: 53,480
Cumulative Timesteps: 446,043,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 446043334...
Checkpoint 446043334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,332.44983
Policy Entropy: 3.73684
Value Function Loss: 0.05488

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07825
Policy Update Magnitude: 0.65272
Value Function Update Magnitude: 0.83681

Collected Steps per Second: 22,685.65723
Overall Steps per Second: 10,682.49580

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.47721
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.68186

Cumulative Model Updates: 53,486
Cumulative Timesteps: 446,093,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,344.55644
Policy Entropy: 3.72333
Value Function Loss: 0.05537

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.61971
Value Function Update Magnitude: 0.86599

Collected Steps per Second: 23,377.93924
Overall Steps per Second: 10,910.26055

Timestep Collection Time: 2.13894
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.58321

Cumulative Model Updates: 53,492
Cumulative Timesteps: 446,143,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 446143352...
Checkpoint 446143352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,333.91036
Policy Entropy: 3.69700
Value Function Loss: 0.05383

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.53080
Value Function Update Magnitude: 0.86863

Collected Steps per Second: 21,990.34371
Overall Steps per Second: 10,637.86259

Timestep Collection Time: 2.27473
Timestep Consumption Time: 2.42753
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.70226

Cumulative Model Updates: 53,498
Cumulative Timesteps: 446,193,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,555.46888
Policy Entropy: 3.68933
Value Function Loss: 0.05517

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07486
Policy Update Magnitude: 0.52608
Value Function Update Magnitude: 0.83877

Collected Steps per Second: 22,465.23863
Overall Steps per Second: 10,940.03520

Timestep Collection Time: 2.22682
Timestep Consumption Time: 2.34593
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.57275

Cumulative Model Updates: 53,504
Cumulative Timesteps: 446,243,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 446243400...
Checkpoint 446243400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,200.97332
Policy Entropy: 3.69366
Value Function Loss: 0.05267

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.56292
Value Function Update Magnitude: 0.85976

Collected Steps per Second: 22,161.33003
Overall Steps per Second: 10,723.60929

Timestep Collection Time: 2.25699
Timestep Consumption Time: 2.40729
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.66429

Cumulative Model Updates: 53,510
Cumulative Timesteps: 446,293,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,113.54204
Policy Entropy: 3.71977
Value Function Loss: 0.05212

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.46316
Value Function Update Magnitude: 0.89059

Collected Steps per Second: 22,100.48435
Overall Steps per Second: 10,662.47346

Timestep Collection Time: 2.26357
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.69178

Cumulative Model Updates: 53,516
Cumulative Timesteps: 446,343,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 446343444...
Checkpoint 446343444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,983.67016
Policy Entropy: 3.70900
Value Function Loss: 0.05125

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.15360
Policy Update Magnitude: 0.39742
Value Function Update Magnitude: 0.85948

Collected Steps per Second: 22,521.07491
Overall Steps per Second: 10,730.04516

Timestep Collection Time: 2.22174
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.66317

Cumulative Model Updates: 53,522
Cumulative Timesteps: 446,393,480

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,635.60109
Policy Entropy: 3.70889
Value Function Loss: 0.05314

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.40279
Value Function Update Magnitude: 0.82094

Collected Steps per Second: 22,855.25391
Overall Steps per Second: 10,868.28210

Timestep Collection Time: 2.18777
Timestep Consumption Time: 2.41296
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60073

Cumulative Model Updates: 53,528
Cumulative Timesteps: 446,443,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 446443482...
Checkpoint 446443482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,174.59104
Policy Entropy: 3.69834
Value Function Loss: 0.05419

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.49145
Value Function Update Magnitude: 0.83183

Collected Steps per Second: 22,431.00327
Overall Steps per Second: 10,710.45780

Timestep Collection Time: 2.22924
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.66871

Cumulative Model Updates: 53,534
Cumulative Timesteps: 446,493,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,785.55942
Policy Entropy: 3.70244
Value Function Loss: 0.05422

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.51834
Value Function Update Magnitude: 0.83356

Collected Steps per Second: 22,735.70464
Overall Steps per Second: 10,818.70083

Timestep Collection Time: 2.19998
Timestep Consumption Time: 2.42332
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.62329

Cumulative Model Updates: 53,540
Cumulative Timesteps: 446,543,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 446543504...
Checkpoint 446543504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,464.18113
Policy Entropy: 3.69367
Value Function Loss: 0.05407

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.45981
Value Function Update Magnitude: 0.70734

Collected Steps per Second: 22,346.10311
Overall Steps per Second: 10,693.62701

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.67662

Cumulative Model Updates: 53,546
Cumulative Timesteps: 446,593,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.30432
Policy Entropy: 3.71229
Value Function Loss: 0.05252

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.40973
Value Function Update Magnitude: 0.60920

Collected Steps per Second: 22,872.31359
Overall Steps per Second: 10,848.12273

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.42518
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61315

Cumulative Model Updates: 53,552
Cumulative Timesteps: 446,643,558

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 446643558...
Checkpoint 446643558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,033.23571
Policy Entropy: 3.71048
Value Function Loss: 0.05120

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.43935
Value Function Update Magnitude: 0.60880

Collected Steps per Second: 22,391.27577
Overall Steps per Second: 10,715.90330

Timestep Collection Time: 2.23319
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.66634

Cumulative Model Updates: 53,558
Cumulative Timesteps: 446,693,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,886.09028
Policy Entropy: 3.72848
Value Function Loss: 0.04852

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05706
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.68122

Collected Steps per Second: 22,995.70867
Overall Steps per Second: 10,838.14551

Timestep Collection Time: 2.17441
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61352

Cumulative Model Updates: 53,564
Cumulative Timesteps: 446,743,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 446743564...
Checkpoint 446743564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,732.47048
Policy Entropy: 3.72262
Value Function Loss: 0.04853

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07070
Policy Update Magnitude: 0.62449
Value Function Update Magnitude: 0.75351

Collected Steps per Second: 22,567.38887
Overall Steps per Second: 10,738.79186

Timestep Collection Time: 2.21594
Timestep Consumption Time: 2.44082
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.65676

Cumulative Model Updates: 53,570
Cumulative Timesteps: 446,793,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,709.79587
Policy Entropy: 3.72222
Value Function Loss: 0.04892

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10713
Policy Update Magnitude: 0.56458
Value Function Update Magnitude: 0.67530

Collected Steps per Second: 22,855.41800
Overall Steps per Second: 10,815.08857

Timestep Collection Time: 2.18784
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.62354

Cumulative Model Updates: 53,576
Cumulative Timesteps: 446,843,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 446843576...
Checkpoint 446843576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,667.25256
Policy Entropy: 3.71777
Value Function Loss: 0.05013

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.47429
Value Function Update Magnitude: 0.63863

Collected Steps per Second: 22,470.58022
Overall Steps per Second: 10,709.99359

Timestep Collection Time: 2.22540
Timestep Consumption Time: 2.44370
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.66910

Cumulative Model Updates: 53,582
Cumulative Timesteps: 446,893,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,459.85387
Policy Entropy: 3.71663
Value Function Loss: 0.04972

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.50834
Value Function Update Magnitude: 0.65883

Collected Steps per Second: 22,634.53231
Overall Steps per Second: 10,647.69527

Timestep Collection Time: 2.20981
Timestep Consumption Time: 2.48773
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.69754

Cumulative Model Updates: 53,588
Cumulative Timesteps: 446,943,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 446943600...
Checkpoint 446943600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,286.29657
Policy Entropy: 3.71555
Value Function Loss: 0.04852

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.55966
Value Function Update Magnitude: 0.69546

Collected Steps per Second: 22,787.60534
Overall Steps per Second: 10,865.32359

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.40781
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60216

Cumulative Model Updates: 53,594
Cumulative Timesteps: 446,993,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,647.38821
Policy Entropy: 3.71362
Value Function Loss: 0.04758

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.50707
Value Function Update Magnitude: 0.76574

Collected Steps per Second: 23,034.04746
Overall Steps per Second: 10,865.89995

Timestep Collection Time: 2.17131
Timestep Consumption Time: 2.43153
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60284

Cumulative Model Updates: 53,600
Cumulative Timesteps: 447,043,618

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 447043618...
Checkpoint 447043618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,423.49962
Policy Entropy: 3.71990
Value Function Loss: 0.04818

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.48017
Value Function Update Magnitude: 0.80824

Collected Steps per Second: 22,675.42744
Overall Steps per Second: 10,718.24342

Timestep Collection Time: 2.20512
Timestep Consumption Time: 2.46001
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.66513

Cumulative Model Updates: 53,606
Cumulative Timesteps: 447,093,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,538.25681
Policy Entropy: 3.71651
Value Function Loss: 0.04801

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.47309
Value Function Update Magnitude: 0.81283

Collected Steps per Second: 23,143.16761
Overall Steps per Second: 10,833.64258

Timestep Collection Time: 2.16072
Timestep Consumption Time: 2.45508
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.61581

Cumulative Model Updates: 53,612
Cumulative Timesteps: 447,143,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 447143626...
Checkpoint 447143626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,336.39496
Policy Entropy: 3.71668
Value Function Loss: 0.04655

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.49153
Value Function Update Magnitude: 0.78886

Collected Steps per Second: 22,618.66354
Overall Steps per Second: 10,679.79630

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.47226
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.68380

Cumulative Model Updates: 53,618
Cumulative Timesteps: 447,193,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,588.55069
Policy Entropy: 3.70924
Value Function Loss: 0.04800

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.48141
Value Function Update Magnitude: 0.77340

Collected Steps per Second: 22,736.12520
Overall Steps per Second: 10,649.14987

Timestep Collection Time: 2.20046
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69803

Cumulative Model Updates: 53,624
Cumulative Timesteps: 447,243,678

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 447243678...
Checkpoint 447243678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,271.09388
Policy Entropy: 3.70686
Value Function Loss: 0.04791

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07174
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.78120

Collected Steps per Second: 22,562.60261
Overall Steps per Second: 10,655.35277

Timestep Collection Time: 2.21668
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.69379

Cumulative Model Updates: 53,630
Cumulative Timesteps: 447,293,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,091.80617
Policy Entropy: 3.70125
Value Function Loss: 0.04846

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.55436
Value Function Update Magnitude: 0.77859

Collected Steps per Second: 23,055.50114
Overall Steps per Second: 10,682.25822

Timestep Collection Time: 2.16920
Timestep Consumption Time: 2.51258
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68178

Cumulative Model Updates: 53,636
Cumulative Timesteps: 447,343,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 447343704...
Checkpoint 447343704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,374.93411
Policy Entropy: 3.70626
Value Function Loss: 0.05039

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.50747
Value Function Update Magnitude: 0.74962

Collected Steps per Second: 22,234.74326
Overall Steps per Second: 10,675.25957

Timestep Collection Time: 2.24990
Timestep Consumption Time: 2.43626
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.68616

Cumulative Model Updates: 53,642
Cumulative Timesteps: 447,393,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,629.20041
Policy Entropy: 3.71088
Value Function Loss: 0.05312

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.66570

Collected Steps per Second: 23,188.23593
Overall Steps per Second: 10,901.21000

Timestep Collection Time: 2.15678
Timestep Consumption Time: 2.43096
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.58775

Cumulative Model Updates: 53,648
Cumulative Timesteps: 447,443,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 447443742...
Checkpoint 447443742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,144.13967
Policy Entropy: 3.71617
Value Function Loss: 0.05383

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.46930
Value Function Update Magnitude: 0.64673

Collected Steps per Second: 22,761.59104
Overall Steps per Second: 10,637.69076

Timestep Collection Time: 2.19721
Timestep Consumption Time: 2.50419
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.70140

Cumulative Model Updates: 53,654
Cumulative Timesteps: 447,493,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,497.95872
Policy Entropy: 3.71770
Value Function Loss: 0.05362

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.43787
Value Function Update Magnitude: 0.73103

Collected Steps per Second: 22,938.87978
Overall Steps per Second: 10,873.79259

Timestep Collection Time: 2.18040
Timestep Consumption Time: 2.41928
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.59968

Cumulative Model Updates: 53,660
Cumulative Timesteps: 447,543,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 447543770...
Checkpoint 447543770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,329.64583
Policy Entropy: 3.73546
Value Function Loss: 0.05109

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.40969
Value Function Update Magnitude: 0.79069

Collected Steps per Second: 22,605.70083
Overall Steps per Second: 10,685.11366

Timestep Collection Time: 2.21298
Timestep Consumption Time: 2.46886
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.68184

Cumulative Model Updates: 53,666
Cumulative Timesteps: 447,593,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.86097
Policy Entropy: 3.74226
Value Function Loss: 0.05120

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07578
Policy Update Magnitude: 0.45091
Value Function Update Magnitude: 0.77202

Collected Steps per Second: 22,848.33812
Overall Steps per Second: 10,820.64210

Timestep Collection Time: 2.18869
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62154

Cumulative Model Updates: 53,672
Cumulative Timesteps: 447,643,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 447643804...
Checkpoint 447643804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,260.90713
Policy Entropy: 3.73732
Value Function Loss: 0.05170

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.53981
Value Function Update Magnitude: 0.61380

Collected Steps per Second: 22,696.02199
Overall Steps per Second: 10,727.28233

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.45828
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.66157

Cumulative Model Updates: 53,678
Cumulative Timesteps: 447,693,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,175.52509
Policy Entropy: 3.73326
Value Function Loss: 0.05179

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.50146
Value Function Update Magnitude: 0.53490

Collected Steps per Second: 22,802.61589
Overall Steps per Second: 10,800.34004

Timestep Collection Time: 2.19387
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.63189

Cumulative Model Updates: 53,684
Cumulative Timesteps: 447,743,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 447743836...
Checkpoint 447743836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,048.75255
Policy Entropy: 3.72377
Value Function Loss: 0.05477

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.51726
Value Function Update Magnitude: 0.59632

Collected Steps per Second: 22,530.69414
Overall Steps per Second: 10,714.82097

Timestep Collection Time: 2.21928
Timestep Consumption Time: 2.44734
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.66662

Cumulative Model Updates: 53,690
Cumulative Timesteps: 447,793,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,099.27568
Policy Entropy: 3.72621
Value Function Loss: 0.05424

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07691
Policy Update Magnitude: 0.60371
Value Function Update Magnitude: 0.62564

Collected Steps per Second: 23,181.73857
Overall Steps per Second: 10,873.62188

Timestep Collection Time: 2.15808
Timestep Consumption Time: 2.44278
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.60086

Cumulative Model Updates: 53,696
Cumulative Timesteps: 447,843,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 447843866...
Checkpoint 447843866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,472.82654
Policy Entropy: 3.72677
Value Function Loss: 0.05324

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.57674
Value Function Update Magnitude: 0.59595

Collected Steps per Second: 22,710.98612
Overall Steps per Second: 10,700.89103

Timestep Collection Time: 2.20175
Timestep Consumption Time: 2.47113
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.67288

Cumulative Model Updates: 53,702
Cumulative Timesteps: 447,893,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,909.50927
Policy Entropy: 3.73437
Value Function Loss: 0.04996

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.49246
Value Function Update Magnitude: 0.65200

Collected Steps per Second: 22,916.49192
Overall Steps per Second: 10,830.89840

Timestep Collection Time: 2.18288
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.61864

Cumulative Model Updates: 53,708
Cumulative Timesteps: 447,943,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 447943894...
Checkpoint 447943894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,008.45751
Policy Entropy: 3.73400
Value Function Loss: 0.04831

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.43866
Value Function Update Magnitude: 0.74663

Collected Steps per Second: 22,203.08830
Overall Steps per Second: 10,681.13939

Timestep Collection Time: 2.25266
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.68265

Cumulative Model Updates: 53,714
Cumulative Timesteps: 447,993,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,239.76293
Policy Entropy: 3.72671
Value Function Loss: 0.04922

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.43468
Value Function Update Magnitude: 0.79414

Collected Steps per Second: 23,185.51962
Overall Steps per Second: 10,972.52781

Timestep Collection Time: 2.15721
Timestep Consumption Time: 2.40108
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.55829

Cumulative Model Updates: 53,720
Cumulative Timesteps: 448,043,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 448043926...
Checkpoint 448043926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,901.60604
Policy Entropy: 3.72861
Value Function Loss: 0.04954

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06604
Policy Update Magnitude: 0.49996
Value Function Update Magnitude: 0.80315

Collected Steps per Second: 22,771.88560
Overall Steps per Second: 10,644.84175

Timestep Collection Time: 2.19622
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.69824

Cumulative Model Updates: 53,726
Cumulative Timesteps: 448,093,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,449.71770
Policy Entropy: 3.73907
Value Function Loss: 0.04803

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.49196
Value Function Update Magnitude: 0.79341

Collected Steps per Second: 22,733.47107
Overall Steps per Second: 10,792.41090

Timestep Collection Time: 2.20037
Timestep Consumption Time: 2.43456
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.63492

Cumulative Model Updates: 53,732
Cumulative Timesteps: 448,143,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 448143960...
Checkpoint 448143960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,162.16816
Policy Entropy: 3.74488
Value Function Loss: 0.04693

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.45434
Value Function Update Magnitude: 0.79630

Collected Steps per Second: 22,337.73657
Overall Steps per Second: 10,699.14690

Timestep Collection Time: 2.23926
Timestep Consumption Time: 2.43588
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.67514

Cumulative Model Updates: 53,738
Cumulative Timesteps: 448,193,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,898.78358
Policy Entropy: 3.74056
Value Function Loss: 0.04587

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.47129
Value Function Update Magnitude: 0.82131

Collected Steps per Second: 22,933.47563
Overall Steps per Second: 10,846.53737

Timestep Collection Time: 2.18092
Timestep Consumption Time: 2.43032
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.61124

Cumulative Model Updates: 53,744
Cumulative Timesteps: 448,243,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 448243996...
Checkpoint 448243996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,898.41144
Policy Entropy: 3.74198
Value Function Loss: 0.04769

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07279
Policy Update Magnitude: 0.52093
Value Function Update Magnitude: 0.80750

Collected Steps per Second: 22,384.52896
Overall Steps per Second: 10,808.68787

Timestep Collection Time: 2.23369
Timestep Consumption Time: 2.39222
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.62591

Cumulative Model Updates: 53,750
Cumulative Timesteps: 448,293,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,848.87628
Policy Entropy: 3.74003
Value Function Loss: 0.04836

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07111
Policy Update Magnitude: 0.60226
Value Function Update Magnitude: 0.81103

Collected Steps per Second: 23,000.55756
Overall Steps per Second: 10,805.12836

Timestep Collection Time: 2.17395
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.62762

Cumulative Model Updates: 53,756
Cumulative Timesteps: 448,343,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 448343998...
Checkpoint 448343998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,769.66524
Policy Entropy: 3.74487
Value Function Loss: 0.04862

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06508
Policy Update Magnitude: 0.66050
Value Function Update Magnitude: 0.82320

Collected Steps per Second: 22,441.08576
Overall Steps per Second: 10,669.47250

Timestep Collection Time: 2.22930
Timestep Consumption Time: 2.45959
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.68889

Cumulative Model Updates: 53,762
Cumulative Timesteps: 448,394,026

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,536.75732
Policy Entropy: 3.73775
Value Function Loss: 0.04878

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.67602
Value Function Update Magnitude: 0.82880

Collected Steps per Second: 22,957.68123
Overall Steps per Second: 10,849.87505

Timestep Collection Time: 2.17792
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.60835

Cumulative Model Updates: 53,768
Cumulative Timesteps: 448,444,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 448444026...
Checkpoint 448444026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,328.60310
Policy Entropy: 3.72744
Value Function Loss: 0.05108

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.64862
Value Function Update Magnitude: 0.80330

Collected Steps per Second: 22,553.52009
Overall Steps per Second: 10,709.39430

Timestep Collection Time: 2.21828
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.67160

Cumulative Model Updates: 53,774
Cumulative Timesteps: 448,494,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,764.84223
Policy Entropy: 3.72261
Value Function Loss: 0.05390

Mean KL Divergence: 0.01980
SB3 Clip Fraction: 0.16624
Policy Update Magnitude: 0.54983
Value Function Update Magnitude: 0.76927

Collected Steps per Second: 23,344.97299
Overall Steps per Second: 10,945.14749

Timestep Collection Time: 2.14247
Timestep Consumption Time: 2.42722
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.56970

Cumulative Model Updates: 53,780
Cumulative Timesteps: 448,544,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 448544072...
Checkpoint 448544072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,054.38368
Policy Entropy: 3.74579
Value Function Loss: 0.05314

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.15101
Policy Update Magnitude: 0.39952
Value Function Update Magnitude: 0.81790

Collected Steps per Second: 22,709.18971
Overall Steps per Second: 10,696.07622

Timestep Collection Time: 2.20184
Timestep Consumption Time: 2.47296
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.67480

Cumulative Model Updates: 53,786
Cumulative Timesteps: 448,594,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,137.43813
Policy Entropy: 3.74596
Value Function Loss: 0.04977

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.41290
Value Function Update Magnitude: 0.87686

Collected Steps per Second: 23,031.24857
Overall Steps per Second: 10,807.60919

Timestep Collection Time: 2.17096
Timestep Consumption Time: 2.45541
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.62637

Cumulative Model Updates: 53,792
Cumulative Timesteps: 448,644,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 448644074...
Checkpoint 448644074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,049.23563
Policy Entropy: 3.75934
Value Function Loss: 0.04866

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.48054
Value Function Update Magnitude: 0.83703

Collected Steps per Second: 22,286.91326
Overall Steps per Second: 10,638.27547

Timestep Collection Time: 2.24383
Timestep Consumption Time: 2.45693
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.70076

Cumulative Model Updates: 53,798
Cumulative Timesteps: 448,694,082

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,967.79000
Policy Entropy: 3.73734
Value Function Loss: 0.04949

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07127
Policy Update Magnitude: 0.59621
Value Function Update Magnitude: 0.77659

Collected Steps per Second: 23,057.93231
Overall Steps per Second: 10,855.40048

Timestep Collection Time: 2.16923
Timestep Consumption Time: 2.43843
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.60766

Cumulative Model Updates: 53,804
Cumulative Timesteps: 448,744,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 448744100...
Checkpoint 448744100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,230.69410
Policy Entropy: 3.73117
Value Function Loss: 0.04996

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.64706
Value Function Update Magnitude: 0.77649

Collected Steps per Second: 22,383.74985
Overall Steps per Second: 10,685.08487

Timestep Collection Time: 2.23421
Timestep Consumption Time: 2.44615
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.68036

Cumulative Model Updates: 53,810
Cumulative Timesteps: 448,794,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,221.61936
Policy Entropy: 3.71884
Value Function Loss: 0.04906

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07122
Policy Update Magnitude: 0.61569
Value Function Update Magnitude: 0.77252

Collected Steps per Second: 23,149.52146
Overall Steps per Second: 10,875.90968

Timestep Collection Time: 2.16091
Timestep Consumption Time: 2.43861
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.59952

Cumulative Model Updates: 53,816
Cumulative Timesteps: 448,844,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 448844134...
Checkpoint 448844134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,234.59231
Policy Entropy: 3.72277
Value Function Loss: 0.05129

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.56632
Value Function Update Magnitude: 0.76379

Collected Steps per Second: 22,406.25175
Overall Steps per Second: 10,684.39500

Timestep Collection Time: 2.23277
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.68234

Cumulative Model Updates: 53,822
Cumulative Timesteps: 448,894,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,895.85736
Policy Entropy: 3.73137
Value Function Loss: 0.05228

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07079
Policy Update Magnitude: 0.58916
Value Function Update Magnitude: 0.76023

Collected Steps per Second: 22,897.14870
Overall Steps per Second: 10,820.37783

Timestep Collection Time: 2.18385
Timestep Consumption Time: 2.43743
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.62128

Cumulative Model Updates: 53,828
Cumulative Timesteps: 448,944,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 448944166...
Checkpoint 448944166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,842.44609
Policy Entropy: 3.74302
Value Function Loss: 0.05419

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.60382
Value Function Update Magnitude: 0.79869

Collected Steps per Second: 22,392.54767
Overall Steps per Second: 10,729.13056

Timestep Collection Time: 2.23333
Timestep Consumption Time: 2.42781
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.66114

Cumulative Model Updates: 53,834
Cumulative Timesteps: 448,994,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,583.68514
Policy Entropy: 3.74397
Value Function Loss: 0.05365

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.51848
Value Function Update Magnitude: 0.82285

Collected Steps per Second: 22,901.98319
Overall Steps per Second: 10,847.58955

Timestep Collection Time: 2.18400
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61098

Cumulative Model Updates: 53,840
Cumulative Timesteps: 449,044,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 449044194...
Checkpoint 449044194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,532.64286
Policy Entropy: 3.73740
Value Function Loss: 0.05337

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08049
Policy Update Magnitude: 0.53502
Value Function Update Magnitude: 0.81926

Collected Steps per Second: 22,626.24405
Overall Steps per Second: 10,685.26174

Timestep Collection Time: 2.21035
Timestep Consumption Time: 2.47011
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.68047

Cumulative Model Updates: 53,846
Cumulative Timesteps: 449,094,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,341.34633
Policy Entropy: 3.71998
Value Function Loss: 0.05284

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.58082
Value Function Update Magnitude: 0.80092

Collected Steps per Second: 23,454.74355
Overall Steps per Second: 10,856.87454

Timestep Collection Time: 2.13304
Timestep Consumption Time: 2.47510
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.60814

Cumulative Model Updates: 53,852
Cumulative Timesteps: 449,144,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 449144236...
Checkpoint 449144236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,475.79373
Policy Entropy: 3.71137
Value Function Loss: 0.05447

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.48977
Value Function Update Magnitude: 0.74747

Collected Steps per Second: 22,525.28035
Overall Steps per Second: 10,657.49292

Timestep Collection Time: 2.21973
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.69153

Cumulative Model Updates: 53,858
Cumulative Timesteps: 449,194,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.12305
Policy Entropy: 3.72569
Value Function Loss: 0.05410

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.43156
Value Function Update Magnitude: 0.81011

Collected Steps per Second: 22,922.81149
Overall Steps per Second: 10,826.06615

Timestep Collection Time: 2.18263
Timestep Consumption Time: 2.43881
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62144

Cumulative Model Updates: 53,864
Cumulative Timesteps: 449,244,268

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 449244268...
Checkpoint 449244268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,524.96564
Policy Entropy: 3.71774
Value Function Loss: 0.05305

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.44617
Value Function Update Magnitude: 0.78927

Collected Steps per Second: 22,426.47760
Overall Steps per Second: 10,746.41989

Timestep Collection Time: 2.22951
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.65271

Cumulative Model Updates: 53,870
Cumulative Timesteps: 449,294,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,639.31318
Policy Entropy: 3.72445
Value Function Loss: 0.05463

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.48751
Value Function Update Magnitude: 0.73284

Collected Steps per Second: 22,943.94401
Overall Steps per Second: 10,820.06682

Timestep Collection Time: 2.17975
Timestep Consumption Time: 2.44241
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.62215

Cumulative Model Updates: 53,876
Cumulative Timesteps: 449,344,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 449344280...
Checkpoint 449344280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,120.27076
Policy Entropy: 3.71696
Value Function Loss: 0.05339

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.49829
Value Function Update Magnitude: 0.73951

Collected Steps per Second: 22,548.89094
Overall Steps per Second: 10,755.09772

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.65175

Cumulative Model Updates: 53,882
Cumulative Timesteps: 449,394,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,854.07150
Policy Entropy: 3.71574
Value Function Loss: 0.05681

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.47224
Value Function Update Magnitude: 0.70021

Collected Steps per Second: 22,962.42990
Overall Steps per Second: 10,859.46366

Timestep Collection Time: 2.17764
Timestep Consumption Time: 2.42700
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.60465

Cumulative Model Updates: 53,888
Cumulative Timesteps: 449,444,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 449444314...
Checkpoint 449444314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,590.32508
Policy Entropy: 3.72413
Value Function Loss: 0.05663

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.49949
Value Function Update Magnitude: 0.71732

Collected Steps per Second: 22,575.07295
Overall Steps per Second: 10,680.63192

Timestep Collection Time: 2.21572
Timestep Consumption Time: 2.46753
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.68324

Cumulative Model Updates: 53,894
Cumulative Timesteps: 449,494,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.25376
Policy Entropy: 3.72414
Value Function Loss: 0.05756

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.55961
Value Function Update Magnitude: 0.70118

Collected Steps per Second: 23,013.39794
Overall Steps per Second: 10,827.25187

Timestep Collection Time: 2.17360
Timestep Consumption Time: 2.44641
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.62001

Cumulative Model Updates: 53,900
Cumulative Timesteps: 449,544,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 449544356...
Checkpoint 449544356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,093.69512
Policy Entropy: 3.74114
Value Function Loss: 0.05673

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.55162
Value Function Update Magnitude: 0.69484

Collected Steps per Second: 22,432.21397
Overall Steps per Second: 10,704.02648

Timestep Collection Time: 2.22929
Timestep Consumption Time: 2.44259
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.67189

Cumulative Model Updates: 53,906
Cumulative Timesteps: 449,594,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,205.40188
Policy Entropy: 3.74720
Value Function Loss: 0.05652

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.53490
Value Function Update Magnitude: 0.69017

Collected Steps per Second: 23,125.11958
Overall Steps per Second: 10,870.31582

Timestep Collection Time: 2.16328
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60207

Cumulative Model Updates: 53,912
Cumulative Timesteps: 449,644,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 449644390...
Checkpoint 449644390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506.59668
Policy Entropy: 3.74793
Value Function Loss: 0.05477

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.57969
Value Function Update Magnitude: 0.67644

Collected Steps per Second: 22,548.62498
Overall Steps per Second: 10,647.36934

Timestep Collection Time: 2.21778
Timestep Consumption Time: 2.47896
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.69675

Cumulative Model Updates: 53,918
Cumulative Timesteps: 449,694,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,730.19096
Policy Entropy: 3.74484
Value Function Loss: 0.05499

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.55269
Value Function Update Magnitude: 0.67469

Collected Steps per Second: 23,114.30172
Overall Steps per Second: 10,844.09828

Timestep Collection Time: 2.16446
Timestep Consumption Time: 2.44911
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61357

Cumulative Model Updates: 53,924
Cumulative Timesteps: 449,744,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 449744428...
Checkpoint 449744428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,915.83688
Policy Entropy: 3.74070
Value Function Loss: 0.05434

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.56953
Value Function Update Magnitude: 0.65959

Collected Steps per Second: 22,241.84177
Overall Steps per Second: 10,678.93447

Timestep Collection Time: 2.24900
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.68418

Cumulative Model Updates: 53,930
Cumulative Timesteps: 449,794,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,178.30812
Policy Entropy: 3.73171
Value Function Loss: 0.05576

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.59905
Value Function Update Magnitude: 0.66212

Collected Steps per Second: 23,099.26125
Overall Steps per Second: 10,912.53077

Timestep Collection Time: 2.16552
Timestep Consumption Time: 2.41838
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.58390

Cumulative Model Updates: 53,936
Cumulative Timesteps: 449,844,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 449844472...
Checkpoint 449844472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,298.09748
Policy Entropy: 3.71657
Value Function Loss: 0.05777

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.63651
Value Function Update Magnitude: 0.66855

Collected Steps per Second: 22,215.58751
Overall Steps per Second: 10,731.86467

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.40883
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.65995

Cumulative Model Updates: 53,942
Cumulative Timesteps: 449,894,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,244.69789
Policy Entropy: 3.69927
Value Function Loss: 0.05967

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.54050
Value Function Update Magnitude: 0.66775

Collected Steps per Second: 23,089.71365
Overall Steps per Second: 10,893.33846

Timestep Collection Time: 2.16668
Timestep Consumption Time: 2.42585
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.59253

Cumulative Model Updates: 53,948
Cumulative Timesteps: 449,944,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 449944510...
Checkpoint 449944510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.28333
Policy Entropy: 3.70768
Value Function Loss: 0.05798

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.48088
Value Function Update Magnitude: 0.66840

Collected Steps per Second: 22,587.88160
Overall Steps per Second: 10,592.92998

Timestep Collection Time: 2.21393
Timestep Consumption Time: 2.50695
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.72088

Cumulative Model Updates: 53,954
Cumulative Timesteps: 449,994,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,557.10824
Policy Entropy: 3.71342
Value Function Loss: 0.05638

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.51713
Value Function Update Magnitude: 0.70463

Collected Steps per Second: 23,158.70788
Overall Steps per Second: 10,889.83570

Timestep Collection Time: 2.15902
Timestep Consumption Time: 2.43242
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59144

Cumulative Model Updates: 53,960
Cumulative Timesteps: 450,044,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 450044518...
Checkpoint 450044518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,621.24982
Policy Entropy: 3.71747
Value Function Loss: 0.05363

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.56474
Value Function Update Magnitude: 0.66499

Collected Steps per Second: 22,739.48423
Overall Steps per Second: 10,676.57946

Timestep Collection Time: 2.20005
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.68577

Cumulative Model Updates: 53,966
Cumulative Timesteps: 450,094,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,718.28603
Policy Entropy: 3.70333
Value Function Loss: 0.05582

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.62254
Value Function Update Magnitude: 0.74061

Collected Steps per Second: 22,726.53839
Overall Steps per Second: 10,787.28012

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.63602

Cumulative Model Updates: 53,972
Cumulative Timesteps: 450,144,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 450144556...
Checkpoint 450144556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,247.76207
Policy Entropy: 3.69184
Value Function Loss: 0.05518

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.61588
Value Function Update Magnitude: 0.83073

Collected Steps per Second: 22,280.35276
Overall Steps per Second: 10,680.44343

Timestep Collection Time: 2.24449
Timestep Consumption Time: 2.43771
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.68220

Cumulative Model Updates: 53,978
Cumulative Timesteps: 450,194,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,869.25102
Policy Entropy: 3.69019
Value Function Loss: 0.05708

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.86376

Collected Steps per Second: 22,987.54318
Overall Steps per Second: 10,899.45880

Timestep Collection Time: 2.17570
Timestep Consumption Time: 2.41297
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.58867

Cumulative Model Updates: 53,984
Cumulative Timesteps: 450,244,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 450244578...
Checkpoint 450244578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,460.49379
Policy Entropy: 3.69652
Value Function Loss: 0.05640

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.49554
Value Function Update Magnitude: 0.83335

Collected Steps per Second: 21,723.53098
Overall Steps per Second: 10,759.73809

Timestep Collection Time: 2.30276
Timestep Consumption Time: 2.34643
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.64918

Cumulative Model Updates: 53,990
Cumulative Timesteps: 450,294,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,494.22361
Policy Entropy: 3.70791
Value Function Loss: 0.05566

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.47066
Value Function Update Magnitude: 0.77351

Collected Steps per Second: 22,252.78387
Overall Steps per Second: 10,846.47849

Timestep Collection Time: 2.24799
Timestep Consumption Time: 2.36402
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61200

Cumulative Model Updates: 53,996
Cumulative Timesteps: 450,344,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 450344626...
Checkpoint 450344626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,426.34955
Policy Entropy: 3.70540
Value Function Loss: 0.05532

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.45621
Value Function Update Magnitude: 0.68831

Collected Steps per Second: 21,744.62395
Overall Steps per Second: 10,635.24565

Timestep Collection Time: 2.30034
Timestep Consumption Time: 2.40289
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.70323

Cumulative Model Updates: 54,002
Cumulative Timesteps: 450,394,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,502.60490
Policy Entropy: 3.70832
Value Function Loss: 0.05380

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.47170
Value Function Update Magnitude: 0.65942

Collected Steps per Second: 22,365.51947
Overall Steps per Second: 10,891.17800

Timestep Collection Time: 2.23630
Timestep Consumption Time: 2.35604
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.59234

Cumulative Model Updates: 54,008
Cumulative Timesteps: 450,444,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 450444662...
Checkpoint 450444662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,146.67351
Policy Entropy: 3.70568
Value Function Loss: 0.05279

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.54717
Value Function Update Magnitude: 0.70783

Collected Steps per Second: 21,620.87845
Overall Steps per Second: 10,590.15821

Timestep Collection Time: 2.31295
Timestep Consumption Time: 2.40917
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.72212

Cumulative Model Updates: 54,014
Cumulative Timesteps: 450,494,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,524.02577
Policy Entropy: 3.70770
Value Function Loss: 0.05180

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.58247
Value Function Update Magnitude: 0.78498

Collected Steps per Second: 22,704.22482
Overall Steps per Second: 10,705.98983

Timestep Collection Time: 2.20391
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.67383

Cumulative Model Updates: 54,020
Cumulative Timesteps: 450,544,708

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 450544708...
Checkpoint 450544708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.65329
Policy Entropy: 3.71592
Value Function Loss: 0.05263

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.58838
Value Function Update Magnitude: 0.82258

Collected Steps per Second: 22,299.13804
Overall Steps per Second: 10,617.10000

Timestep Collection Time: 2.24341
Timestep Consumption Time: 2.46843
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.71183

Cumulative Model Updates: 54,026
Cumulative Timesteps: 450,594,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,737.49824
Policy Entropy: 3.72326
Value Function Loss: 0.05364

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.58218
Value Function Update Magnitude: 0.82124

Collected Steps per Second: 23,127.34211
Overall Steps per Second: 10,764.83901

Timestep Collection Time: 2.16194
Timestep Consumption Time: 2.48281
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.64475

Cumulative Model Updates: 54,032
Cumulative Timesteps: 450,644,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 450644734...
Checkpoint 450644734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,967.23736
Policy Entropy: 3.72038
Value Function Loss: 0.05342

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.58460
Value Function Update Magnitude: 0.80928

Collected Steps per Second: 22,828.96610
Overall Steps per Second: 10,654.98634

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.50454
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.69658

Cumulative Model Updates: 54,038
Cumulative Timesteps: 450,694,776

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,718.13482
Policy Entropy: 3.71363
Value Function Loss: 0.05368

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.57832
Value Function Update Magnitude: 0.72474

Collected Steps per Second: 23,128.62561
Overall Steps per Second: 10,947.99207

Timestep Collection Time: 2.16286
Timestep Consumption Time: 2.40638
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.56924

Cumulative Model Updates: 54,044
Cumulative Timesteps: 450,744,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 450744800...
Checkpoint 450744800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,159.54778
Policy Entropy: 3.70923
Value Function Loss: 0.05348

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07339
Policy Update Magnitude: 0.62149
Value Function Update Magnitude: 0.68225

Collected Steps per Second: 22,520.77235
Overall Steps per Second: 10,602.43928

Timestep Collection Time: 2.22115
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.71797

Cumulative Model Updates: 54,050
Cumulative Timesteps: 450,794,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,969.48678
Policy Entropy: 3.72390
Value Function Loss: 0.05242

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.62288
Value Function Update Magnitude: 0.72838

Collected Steps per Second: 23,327.30629
Overall Steps per Second: 10,927.91803

Timestep Collection Time: 2.14461
Timestep Consumption Time: 2.43339
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.57800

Cumulative Model Updates: 54,056
Cumulative Timesteps: 450,844,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 450844850...
Checkpoint 450844850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,093.36924
Policy Entropy: 3.72820
Value Function Loss: 0.05000

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.62841
Value Function Update Magnitude: 0.77493

Collected Steps per Second: 22,450.53619
Overall Steps per Second: 10,645.18281

Timestep Collection Time: 2.22712
Timestep Consumption Time: 2.46984
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.69696

Cumulative Model Updates: 54,062
Cumulative Timesteps: 450,894,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,058.02131
Policy Entropy: 3.71795
Value Function Loss: 0.04988

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.54543
Value Function Update Magnitude: 0.77027

Collected Steps per Second: 22,980.81545
Overall Steps per Second: 10,924.68439

Timestep Collection Time: 2.17590
Timestep Consumption Time: 2.40126
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.57716

Cumulative Model Updates: 54,068
Cumulative Timesteps: 450,944,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 450944854...
Checkpoint 450944854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.93819
Policy Entropy: 3.71977
Value Function Loss: 0.05159

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.49329
Value Function Update Magnitude: 0.76744

Collected Steps per Second: 22,520.75127
Overall Steps per Second: 10,596.70946

Timestep Collection Time: 2.22142
Timestep Consumption Time: 2.49967
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.72109

Cumulative Model Updates: 54,074
Cumulative Timesteps: 450,994,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.40025
Policy Entropy: 3.73048
Value Function Loss: 0.05122

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.49423
Value Function Update Magnitude: 0.82578

Collected Steps per Second: 22,900.41629
Overall Steps per Second: 10,836.26895

Timestep Collection Time: 2.18407
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61561

Cumulative Model Updates: 54,080
Cumulative Timesteps: 451,044,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 451044898...
Checkpoint 451044898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,397.80241
Policy Entropy: 3.73245
Value Function Loss: 0.05050

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.10938
Policy Update Magnitude: 0.54935
Value Function Update Magnitude: 0.83551

Collected Steps per Second: 22,477.36240
Overall Steps per Second: 10,681.41799

Timestep Collection Time: 2.22482
Timestep Consumption Time: 2.45696
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.68178

Cumulative Model Updates: 54,086
Cumulative Timesteps: 451,094,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,293.00958
Policy Entropy: 3.73148
Value Function Loss: 0.05249

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.58864
Value Function Update Magnitude: 0.84850

Collected Steps per Second: 22,840.26977
Overall Steps per Second: 10,683.64905

Timestep Collection Time: 2.18912
Timestep Consumption Time: 2.49093
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.68005

Cumulative Model Updates: 54,092
Cumulative Timesteps: 451,144,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 451144906...
Checkpoint 451144906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,885.76417
Policy Entropy: 3.73365
Value Function Loss: 0.05280

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.56194
Value Function Update Magnitude: 0.87746

Collected Steps per Second: 22,470.87863
Overall Steps per Second: 10,614.00306

Timestep Collection Time: 2.22653
Timestep Consumption Time: 2.48725
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.71377

Cumulative Model Updates: 54,098
Cumulative Timesteps: 451,194,938

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,163.16673
Policy Entropy: 3.72024
Value Function Loss: 0.05385

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10606
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.85256

Collected Steps per Second: 23,004.88210
Overall Steps per Second: 10,742.35341

Timestep Collection Time: 2.17415
Timestep Consumption Time: 2.48182
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.65596

Cumulative Model Updates: 54,104
Cumulative Timesteps: 451,244,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 451244954...
Checkpoint 451244954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.63206
Policy Entropy: 3.70326
Value Function Loss: 0.05483

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.49384
Value Function Update Magnitude: 0.81931

Collected Steps per Second: 22,352.44313
Overall Steps per Second: 10,644.01324

Timestep Collection Time: 2.23743
Timestep Consumption Time: 2.46117
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.69860

Cumulative Model Updates: 54,110
Cumulative Timesteps: 451,294,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,270.84660
Policy Entropy: 3.68692
Value Function Loss: 0.05580

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.44373
Value Function Update Magnitude: 0.82377

Collected Steps per Second: 22,988.59554
Overall Steps per Second: 10,850.02512

Timestep Collection Time: 2.17621
Timestep Consumption Time: 2.43466
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61086

Cumulative Model Updates: 54,116
Cumulative Timesteps: 451,344,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 451344994...
Checkpoint 451344994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,348.64069
Policy Entropy: 3.67266
Value Function Loss: 0.05725

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10570
Policy Update Magnitude: 0.42532
Value Function Update Magnitude: 0.79597

Collected Steps per Second: 22,358.01161
Overall Steps per Second: 10,659.86627

Timestep Collection Time: 2.23696
Timestep Consumption Time: 2.45484
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.69180

Cumulative Model Updates: 54,122
Cumulative Timesteps: 451,395,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,786.15697
Policy Entropy: 3.68683
Value Function Loss: 0.05756

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.46326
Value Function Update Magnitude: 0.70833

Collected Steps per Second: 23,214.95630
Overall Steps per Second: 10,878.53986

Timestep Collection Time: 2.15456
Timestep Consumption Time: 2.44330
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59786

Cumulative Model Updates: 54,128
Cumulative Timesteps: 451,445,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 451445026...
Checkpoint 451445026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,327.40981
Policy Entropy: 3.70757
Value Function Loss: 0.05641

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.53413
Value Function Update Magnitude: 0.69859

Collected Steps per Second: 22,529.29301
Overall Steps per Second: 10,759.87134

Timestep Collection Time: 2.22049
Timestep Consumption Time: 2.42883
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.64931

Cumulative Model Updates: 54,134
Cumulative Timesteps: 451,495,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,655.30789
Policy Entropy: 3.71117
Value Function Loss: 0.05633

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.16894
Policy Update Magnitude: 0.46547
Value Function Update Magnitude: 0.69827

Collected Steps per Second: 23,157.99104
Overall Steps per Second: 10,826.86672

Timestep Collection Time: 2.15986
Timestep Consumption Time: 2.45994
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.61980

Cumulative Model Updates: 54,140
Cumulative Timesteps: 451,545,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 451545070...
Checkpoint 451545070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,902.83025
Policy Entropy: 3.71080
Value Function Loss: 0.05588

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.43873
Value Function Update Magnitude: 0.68494

Collected Steps per Second: 22,782.79111
Overall Steps per Second: 10,761.49759

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.45303
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.64898

Cumulative Model Updates: 54,146
Cumulative Timesteps: 451,595,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,748.31529
Policy Entropy: 3.69655
Value Function Loss: 0.05775

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.47456
Value Function Update Magnitude: 0.63053

Collected Steps per Second: 22,946.55029
Overall Steps per Second: 10,845.62528

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.61181

Cumulative Model Updates: 54,152
Cumulative Timesteps: 451,645,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 451645118...
Checkpoint 451645118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,415.56411
Policy Entropy: 3.70089
Value Function Loss: 0.05759

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.48803
Value Function Update Magnitude: 0.57661

Collected Steps per Second: 22,354.90060
Overall Steps per Second: 10,748.17975

Timestep Collection Time: 2.23781
Timestep Consumption Time: 2.41656
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.65437

Cumulative Model Updates: 54,158
Cumulative Timesteps: 451,695,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841.76052
Policy Entropy: 3.71712
Value Function Loss: 0.05637

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.47754
Value Function Update Magnitude: 0.59312

Collected Steps per Second: 22,997.47136
Overall Steps per Second: 10,875.84093

Timestep Collection Time: 2.17485
Timestep Consumption Time: 2.42397
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.59882

Cumulative Model Updates: 54,164
Cumulative Timesteps: 451,745,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 451745160...
Checkpoint 451745160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,139.65033
Policy Entropy: 3.71023
Value Function Loss: 0.05482

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.49257
Value Function Update Magnitude: 0.61849

Collected Steps per Second: 22,347.48126
Overall Steps per Second: 10,615.26346

Timestep Collection Time: 2.23757
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.71058

Cumulative Model Updates: 54,170
Cumulative Timesteps: 451,795,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,383.07345
Policy Entropy: 3.70974
Value Function Loss: 0.05434

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.49453
Value Function Update Magnitude: 0.70374

Collected Steps per Second: 22,569.56191
Overall Steps per Second: 10,642.21767

Timestep Collection Time: 2.21546
Timestep Consumption Time: 2.48300
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.69846

Cumulative Model Updates: 54,176
Cumulative Timesteps: 451,845,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 451845166...
Checkpoint 451845166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,531.47992
Policy Entropy: 3.71174
Value Function Loss: 0.05531

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07136
Policy Update Magnitude: 0.57853
Value Function Update Magnitude: 0.69440

Collected Steps per Second: 22,552.36336
Overall Steps per Second: 10,649.57398

Timestep Collection Time: 2.21777
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.69653

Cumulative Model Updates: 54,182
Cumulative Timesteps: 451,895,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,355.56712
Policy Entropy: 3.72794
Value Function Loss: 0.05284

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.63766
Value Function Update Magnitude: 0.69644

Collected Steps per Second: 23,101.21876
Overall Steps per Second: 10,711.26032

Timestep Collection Time: 2.16499
Timestep Consumption Time: 2.50430
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.66929

Cumulative Model Updates: 54,188
Cumulative Timesteps: 451,945,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 451945196...
Checkpoint 451945196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,387.58787
Policy Entropy: 3.73081
Value Function Loss: 0.05252

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.60023
Value Function Update Magnitude: 0.75647

Collected Steps per Second: 22,348.79609
Overall Steps per Second: 10,641.51669

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.46211
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.70008

Cumulative Model Updates: 54,194
Cumulative Timesteps: 451,995,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,018.65515
Policy Entropy: 3.73375
Value Function Loss: 0.05360

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.56430
Value Function Update Magnitude: 0.75497

Collected Steps per Second: 23,005.20110
Overall Steps per Second: 10,863.78374

Timestep Collection Time: 2.17446
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.60466

Cumulative Model Updates: 54,200
Cumulative Timesteps: 452,045,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 452045236...
Checkpoint 452045236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,750.94329
Policy Entropy: 3.72860
Value Function Loss: 0.05503

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.64094
Value Function Update Magnitude: 0.70374

Collected Steps per Second: 21,989.22893
Overall Steps per Second: 10,690.11272

Timestep Collection Time: 2.27430
Timestep Consumption Time: 2.40386
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.67815

Cumulative Model Updates: 54,206
Cumulative Timesteps: 452,095,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,125.94363
Policy Entropy: 3.73123
Value Function Loss: 0.05648

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.68594
Value Function Update Magnitude: 0.68166

Collected Steps per Second: 22,340.97396
Overall Steps per Second: 10,879.22150

Timestep Collection Time: 2.23929
Timestep Consumption Time: 2.35920
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.59849

Cumulative Model Updates: 54,212
Cumulative Timesteps: 452,145,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 452145274...
Checkpoint 452145274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,982.52742
Policy Entropy: 3.74263
Value Function Loss: 0.05423

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.59999
Value Function Update Magnitude: 0.68399

Collected Steps per Second: 22,006.55418
Overall Steps per Second: 10,656.57523

Timestep Collection Time: 2.27250
Timestep Consumption Time: 2.42037
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.69288

Cumulative Model Updates: 54,218
Cumulative Timesteps: 452,195,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,628.56669
Policy Entropy: 3.72432
Value Function Loss: 0.05516

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08046
Policy Update Magnitude: 0.59075
Value Function Update Magnitude: 0.66737

Collected Steps per Second: 22,274.36956
Overall Steps per Second: 10,855.05975

Timestep Collection Time: 2.24509
Timestep Consumption Time: 2.36179
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60688

Cumulative Model Updates: 54,224
Cumulative Timesteps: 452,245,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 452245292...
Checkpoint 452245292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,446.63355
Policy Entropy: 3.72537
Value Function Loss: 0.05575

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.59690
Value Function Update Magnitude: 0.65150

Collected Steps per Second: 22,103.55396
Overall Steps per Second: 10,748.27990

Timestep Collection Time: 2.26298
Timestep Consumption Time: 2.39078
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.65377

Cumulative Model Updates: 54,230
Cumulative Timesteps: 452,295,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,763.99512
Policy Entropy: 3.72907
Value Function Loss: 0.05534

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.50567
Value Function Update Magnitude: 0.70215

Collected Steps per Second: 22,476.64088
Overall Steps per Second: 10,775.33641

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.41618
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.64115

Cumulative Model Updates: 54,236
Cumulative Timesteps: 452,345,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 452345322...
Checkpoint 452345322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,750.49905
Policy Entropy: 3.72405
Value Function Loss: 0.05471

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.52570
Value Function Update Magnitude: 0.78590

Collected Steps per Second: 22,270.32068
Overall Steps per Second: 10,781.65629

Timestep Collection Time: 2.24595
Timestep Consumption Time: 2.39323
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.63918

Cumulative Model Updates: 54,242
Cumulative Timesteps: 452,395,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,392.52272
Policy Entropy: 3.73365
Value Function Loss: 0.05357

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.60779
Value Function Update Magnitude: 0.81353

Collected Steps per Second: 23,084.58380
Overall Steps per Second: 10,900.08056

Timestep Collection Time: 2.16629
Timestep Consumption Time: 2.42156
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.58786

Cumulative Model Updates: 54,248
Cumulative Timesteps: 452,445,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 452445348...
Checkpoint 452445348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.26286
Policy Entropy: 3.72135
Value Function Loss: 0.05461

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.62886
Value Function Update Magnitude: 0.80906

Collected Steps per Second: 22,429.93035
Overall Steps per Second: 10,621.83346

Timestep Collection Time: 2.22970
Timestep Consumption Time: 2.47872
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.70842

Cumulative Model Updates: 54,254
Cumulative Timesteps: 452,495,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,268.94556
Policy Entropy: 3.73392
Value Function Loss: 0.05461

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.59791
Value Function Update Magnitude: 0.84942

Collected Steps per Second: 22,785.64513
Overall Steps per Second: 10,862.80046

Timestep Collection Time: 2.19480
Timestep Consumption Time: 2.40898
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.60379

Cumulative Model Updates: 54,260
Cumulative Timesteps: 452,545,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 452545370...
Checkpoint 452545370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,288.46621
Policy Entropy: 3.74623
Value Function Loss: 0.05436

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.88877

Collected Steps per Second: 22,579.20425
Overall Steps per Second: 10,686.51252

Timestep Collection Time: 2.21567
Timestep Consumption Time: 2.46575
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.68142

Cumulative Model Updates: 54,266
Cumulative Timesteps: 452,595,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,972.50237
Policy Entropy: 3.75791
Value Function Loss: 0.05494

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.54801
Value Function Update Magnitude: 0.87241

Collected Steps per Second: 22,887.19356
Overall Steps per Second: 10,822.19040

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62051

Cumulative Model Updates: 54,272
Cumulative Timesteps: 452,645,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 452645402...
Checkpoint 452645402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,459.81351
Policy Entropy: 3.76249
Value Function Loss: 0.05386

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.52633
Value Function Update Magnitude: 0.87772

Collected Steps per Second: 21,672.03592
Overall Steps per Second: 10,300.42940

Timestep Collection Time: 2.30758
Timestep Consumption Time: 2.54756
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.85514

Cumulative Model Updates: 54,278
Cumulative Timesteps: 452,695,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,487.52840
Policy Entropy: 3.76166
Value Function Loss: 0.05207

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.54507
Value Function Update Magnitude: 0.89538

Collected Steps per Second: 22,314.66760
Overall Steps per Second: 10,495.19083

Timestep Collection Time: 2.24140
Timestep Consumption Time: 2.52422
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.76561

Cumulative Model Updates: 54,284
Cumulative Timesteps: 452,745,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 452745428...
Checkpoint 452745428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,695.33155
Policy Entropy: 3.76105
Value Function Loss: 0.05086

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.56958
Value Function Update Magnitude: 0.86956

Collected Steps per Second: 22,272.00250
Overall Steps per Second: 10,592.56488

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.72237

Cumulative Model Updates: 54,290
Cumulative Timesteps: 452,795,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,108.00964
Policy Entropy: 3.76904
Value Function Loss: 0.05102

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07343
Policy Update Magnitude: 0.63186
Value Function Update Magnitude: 0.84337

Collected Steps per Second: 23,121.69522
Overall Steps per Second: 10,883.33169

Timestep Collection Time: 2.16247
Timestep Consumption Time: 2.43171
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59418

Cumulative Model Updates: 54,296
Cumulative Timesteps: 452,845,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 452845450...
Checkpoint 452845450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,985.93224
Policy Entropy: 3.75508
Value Function Loss: 0.05282

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07183
Policy Update Magnitude: 0.64891
Value Function Update Magnitude: 0.87725

Collected Steps per Second: 22,749.40613
Overall Steps per Second: 10,686.82902

Timestep Collection Time: 2.19804
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.67903

Cumulative Model Updates: 54,302
Cumulative Timesteps: 452,895,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.56874
Policy Entropy: 3.75038
Value Function Loss: 0.05186

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.87698

Collected Steps per Second: 23,086.24383
Overall Steps per Second: 10,781.81226

Timestep Collection Time: 2.16605
Timestep Consumption Time: 2.47194
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.63800

Cumulative Model Updates: 54,308
Cumulative Timesteps: 452,945,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 452945460...
Checkpoint 452945460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,593.05027
Policy Entropy: 3.73434
Value Function Loss: 0.05316

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.53110
Value Function Update Magnitude: 0.81079

Collected Steps per Second: 22,367.01969
Overall Steps per Second: 10,711.46064

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.66827

Cumulative Model Updates: 54,314
Cumulative Timesteps: 452,995,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,554.58385
Policy Entropy: 3.74456
Value Function Loss: 0.05392

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07711
Policy Update Magnitude: 0.56040
Value Function Update Magnitude: 0.69695

Collected Steps per Second: 23,242.09739
Overall Steps per Second: 10,896.73027

Timestep Collection Time: 2.15187
Timestep Consumption Time: 2.43795
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.58982

Cumulative Model Updates: 54,320
Cumulative Timesteps: 453,045,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 453045478...
Checkpoint 453045478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,401.25094
Policy Entropy: 3.74533
Value Function Loss: 0.05464

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.75244

Collected Steps per Second: 22,560.94508
Overall Steps per Second: 10,691.79761

Timestep Collection Time: 2.21728
Timestep Consumption Time: 2.46144
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.67873

Cumulative Model Updates: 54,326
Cumulative Timesteps: 453,095,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,972.69041
Policy Entropy: 3.74394
Value Function Loss: 0.05426

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.49609
Value Function Update Magnitude: 0.85325

Collected Steps per Second: 22,867.00480
Overall Steps per Second: 10,804.60355

Timestep Collection Time: 2.18699
Timestep Consumption Time: 2.44159
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62858

Cumulative Model Updates: 54,332
Cumulative Timesteps: 453,145,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 453145512...
Checkpoint 453145512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,553.30523
Policy Entropy: 3.74635
Value Function Loss: 0.05453

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.47126
Value Function Update Magnitude: 0.82140

Collected Steps per Second: 22,285.12509
Overall Steps per Second: 10,684.41240

Timestep Collection Time: 2.24392
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.68028

Cumulative Model Updates: 54,338
Cumulative Timesteps: 453,195,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,374.12060
Policy Entropy: 3.74370
Value Function Loss: 0.05544

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.47871
Value Function Update Magnitude: 0.72388

Collected Steps per Second: 22,959.70109
Overall Steps per Second: 10,831.36778

Timestep Collection Time: 2.17869
Timestep Consumption Time: 2.43957
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.61825

Cumulative Model Updates: 54,344
Cumulative Timesteps: 453,245,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 453245540...
Checkpoint 453245540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,391.11525
Policy Entropy: 3.74526
Value Function Loss: 0.05317

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.46261
Value Function Update Magnitude: 0.68085

Collected Steps per Second: 22,552.23712
Overall Steps per Second: 10,772.76968

Timestep Collection Time: 2.21734
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.64189

Cumulative Model Updates: 54,350
Cumulative Timesteps: 453,295,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,409.30603
Policy Entropy: 3.74276
Value Function Loss: 0.05310

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.49408
Value Function Update Magnitude: 0.67189

Collected Steps per Second: 23,089.37052
Overall Steps per Second: 10,861.72218

Timestep Collection Time: 2.16585
Timestep Consumption Time: 2.43821
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60406

Cumulative Model Updates: 54,356
Cumulative Timesteps: 453,345,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 453345554...
Checkpoint 453345554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.86585
Policy Entropy: 3.73553
Value Function Loss: 0.05489

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.50388
Value Function Update Magnitude: 0.65107

Collected Steps per Second: 22,335.03163
Overall Steps per Second: 10,649.90016

Timestep Collection Time: 2.24034
Timestep Consumption Time: 2.45811
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.69845

Cumulative Model Updates: 54,362
Cumulative Timesteps: 453,395,592

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,030.58769
Policy Entropy: 3.72337
Value Function Loss: 0.05724

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.49753
Value Function Update Magnitude: 0.63930

Collected Steps per Second: 22,525.56607
Overall Steps per Second: 10,521.10226

Timestep Collection Time: 2.22077
Timestep Consumption Time: 2.53387
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.75463

Cumulative Model Updates: 54,368
Cumulative Timesteps: 453,445,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 453445616...
Checkpoint 453445616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,964.67756
Policy Entropy: 3.72454
Value Function Loss: 0.05723

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06714
Policy Update Magnitude: 0.59340
Value Function Update Magnitude: 0.65744

Collected Steps per Second: 22,684.61484
Overall Steps per Second: 10,648.90093

Timestep Collection Time: 2.20528
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.69776

Cumulative Model Updates: 54,374
Cumulative Timesteps: 453,495,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,505.83425
Policy Entropy: 3.73888
Value Function Loss: 0.05596

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.67484
Value Function Update Magnitude: 0.63059

Collected Steps per Second: 22,591.63879
Overall Steps per Second: 10,749.40168

Timestep Collection Time: 2.21480
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.65477

Cumulative Model Updates: 54,380
Cumulative Timesteps: 453,545,678

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 453545678...
Checkpoint 453545678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,558.29926
Policy Entropy: 3.73694
Value Function Loss: 0.05454

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05701
Policy Update Magnitude: 0.70180
Value Function Update Magnitude: 0.62562

Collected Steps per Second: 22,292.73166
Overall Steps per Second: 10,698.83369

Timestep Collection Time: 2.24288
Timestep Consumption Time: 2.43052
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.67341

Cumulative Model Updates: 54,386
Cumulative Timesteps: 453,595,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,468.09928
Policy Entropy: 3.72647
Value Function Loss: 0.05346

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06355
Policy Update Magnitude: 0.70358
Value Function Update Magnitude: 0.66509

Collected Steps per Second: 23,180.48165
Overall Steps per Second: 10,888.71815

Timestep Collection Time: 2.15785
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.59375

Cumulative Model Updates: 54,392
Cumulative Timesteps: 453,645,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 453645698...
Checkpoint 453645698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,178.97097
Policy Entropy: 3.72398
Value Function Loss: 0.05327

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.66350
Value Function Update Magnitude: 0.72186

Collected Steps per Second: 22,268.95613
Overall Steps per Second: 10,695.59825

Timestep Collection Time: 2.24672
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.67781

Cumulative Model Updates: 54,398
Cumulative Timesteps: 453,695,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,120.00766
Policy Entropy: 3.73350
Value Function Loss: 0.05332

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.55998
Value Function Update Magnitude: 0.71299

Collected Steps per Second: 23,004.41739
Overall Steps per Second: 10,888.97851

Timestep Collection Time: 2.17393
Timestep Consumption Time: 2.41879
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.59272

Cumulative Model Updates: 54,404
Cumulative Timesteps: 453,745,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 453745740...
Checkpoint 453745740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,382.14192
Policy Entropy: 3.73027
Value Function Loss: 0.05395

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.48708
Value Function Update Magnitude: 0.73085

Collected Steps per Second: 22,408.97011
Overall Steps per Second: 10,648.05971

Timestep Collection Time: 2.23134
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69588

Cumulative Model Updates: 54,410
Cumulative Timesteps: 453,795,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,958.77890
Policy Entropy: 3.72429
Value Function Loss: 0.05506

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.45755
Value Function Update Magnitude: 0.74118

Collected Steps per Second: 22,948.80592
Overall Steps per Second: 10,834.62983

Timestep Collection Time: 2.17911
Timestep Consumption Time: 2.43646
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61557

Cumulative Model Updates: 54,416
Cumulative Timesteps: 453,845,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 453845750...
Checkpoint 453845750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,450.65991
Policy Entropy: 3.72209
Value Function Loss: 0.05294

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.43142
Value Function Update Magnitude: 0.79811

Collected Steps per Second: 22,521.84706
Overall Steps per Second: 10,783.90870

Timestep Collection Time: 2.22069
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.63784

Cumulative Model Updates: 54,422
Cumulative Timesteps: 453,895,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,863.86013
Policy Entropy: 3.73148
Value Function Loss: 0.05357

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.47655
Value Function Update Magnitude: 0.79400

Collected Steps per Second: 23,280.28322
Overall Steps per Second: 10,840.35248

Timestep Collection Time: 2.14869
Timestep Consumption Time: 2.46574
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.61443

Cumulative Model Updates: 54,428
Cumulative Timesteps: 453,945,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 453945786...
Checkpoint 453945786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,234.42621
Policy Entropy: 3.73921
Value Function Loss: 0.05520

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.60229
Value Function Update Magnitude: 0.68343

Collected Steps per Second: 22,480.99106
Overall Steps per Second: 10,636.87146

Timestep Collection Time: 2.22419
Timestep Consumption Time: 2.47663
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.70082

Cumulative Model Updates: 54,434
Cumulative Timesteps: 453,995,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,258.84856
Policy Entropy: 3.73626
Value Function Loss: 0.05576

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05852
Policy Update Magnitude: 0.67688
Value Function Update Magnitude: 0.64705

Collected Steps per Second: 22,820.89390
Overall Steps per Second: 10,842.33554

Timestep Collection Time: 2.19176
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61321

Cumulative Model Updates: 54,440
Cumulative Timesteps: 454,045,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 454045806...
Checkpoint 454045806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,424.44034
Policy Entropy: 3.73199
Value Function Loss: 0.05568

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.67179
Value Function Update Magnitude: 0.62859

Collected Steps per Second: 22,189.53874
Overall Steps per Second: 10,686.52587

Timestep Collection Time: 2.25449
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.68122

Cumulative Model Updates: 54,446
Cumulative Timesteps: 454,095,832

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,201.64210
Policy Entropy: 3.72626
Value Function Loss: 0.05655

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.58735
Value Function Update Magnitude: 0.68630

Collected Steps per Second: 22,502.66131
Overall Steps per Second: 10,583.70274

Timestep Collection Time: 2.22240
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.72519

Cumulative Model Updates: 54,452
Cumulative Timesteps: 454,145,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 454145842...
Checkpoint 454145842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,549.29503
Policy Entropy: 3.72945
Value Function Loss: 0.05835

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.52554
Value Function Update Magnitude: 0.81019

Collected Steps per Second: 22,457.00692
Overall Steps per Second: 10,568.01964

Timestep Collection Time: 2.22665
Timestep Consumption Time: 2.50498
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.73163

Cumulative Model Updates: 54,458
Cumulative Timesteps: 454,195,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,440.47028
Policy Entropy: 3.73262
Value Function Loss: 0.05804

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.47303
Value Function Update Magnitude: 0.83319

Collected Steps per Second: 23,009.80248
Overall Steps per Second: 10,855.82071

Timestep Collection Time: 2.17420
Timestep Consumption Time: 2.43420
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60840

Cumulative Model Updates: 54,464
Cumulative Timesteps: 454,245,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 454245874...
Checkpoint 454245874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,536.68171
Policy Entropy: 3.73772
Value Function Loss: 0.05782

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.51642
Value Function Update Magnitude: 0.85399

Collected Steps per Second: 22,374.23484
Overall Steps per Second: 10,708.54051

Timestep Collection Time: 2.23543
Timestep Consumption Time: 2.43524
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.67066

Cumulative Model Updates: 54,470
Cumulative Timesteps: 454,295,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,021.59217
Policy Entropy: 3.73981
Value Function Loss: 0.05677

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.82768

Collected Steps per Second: 22,954.96951
Overall Steps per Second: 10,859.34559

Timestep Collection Time: 2.17887
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60580

Cumulative Model Updates: 54,476
Cumulative Timesteps: 454,345,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 454345906...
Checkpoint 454345906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,828.47946
Policy Entropy: 3.72920
Value Function Loss: 0.05762

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.83495

Collected Steps per Second: 22,356.66215
Overall Steps per Second: 10,669.03191

Timestep Collection Time: 2.23736
Timestep Consumption Time: 2.45097
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.68834

Cumulative Model Updates: 54,482
Cumulative Timesteps: 454,395,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,034.98534
Policy Entropy: 3.73069
Value Function Loss: 0.05376

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.49379
Value Function Update Magnitude: 0.83688

Collected Steps per Second: 22,851.60520
Overall Steps per Second: 10,826.50374

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61830

Cumulative Model Updates: 54,488
Cumulative Timesteps: 454,445,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 454445926...
Checkpoint 454445926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,697.85973
Policy Entropy: 3.73762
Value Function Loss: 0.05315

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.47749
Value Function Update Magnitude: 0.84335

Collected Steps per Second: 22,412.84577
Overall Steps per Second: 10,772.35772

Timestep Collection Time: 2.23185
Timestep Consumption Time: 2.41171
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.64355

Cumulative Model Updates: 54,494
Cumulative Timesteps: 454,495,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.77209
Policy Entropy: 3.74453
Value Function Loss: 0.05348

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.51794
Value Function Update Magnitude: 0.88438

Collected Steps per Second: 23,251.88524
Overall Steps per Second: 10,839.55078

Timestep Collection Time: 2.15054
Timestep Consumption Time: 2.46257
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.61311

Cumulative Model Updates: 54,500
Cumulative Timesteps: 454,545,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 454545952...
Checkpoint 454545952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,327.92530
Policy Entropy: 3.73145
Value Function Loss: 0.05381

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.51434
Value Function Update Magnitude: 0.88865

Collected Steps per Second: 21,546.77838
Overall Steps per Second: 10,648.64955

Timestep Collection Time: 2.32174
Timestep Consumption Time: 2.37613
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.69787

Cumulative Model Updates: 54,506
Cumulative Timesteps: 454,595,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,091.54638
Policy Entropy: 3.72093
Value Function Loss: 0.05334

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.53492
Value Function Update Magnitude: 0.86939

Collected Steps per Second: 22,451.70217
Overall Steps per Second: 10,919.56857

Timestep Collection Time: 2.22718
Timestep Consumption Time: 2.35212
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.57930

Cumulative Model Updates: 54,512
Cumulative Timesteps: 454,645,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 454645982...
Checkpoint 454645982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,637.58907
Policy Entropy: 3.72276
Value Function Loss: 0.05289

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.53208
Value Function Update Magnitude: 0.79813

Collected Steps per Second: 21,728.47976
Overall Steps per Second: 10,650.08486

Timestep Collection Time: 2.30196
Timestep Consumption Time: 2.39453
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.69649

Cumulative Model Updates: 54,518
Cumulative Timesteps: 454,696,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,905.13566
Policy Entropy: 3.72727
Value Function Loss: 0.05545

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.53375
Value Function Update Magnitude: 0.72109

Collected Steps per Second: 22,535.93535
Overall Steps per Second: 10,941.47536

Timestep Collection Time: 2.21903
Timestep Consumption Time: 2.35147
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.57050

Cumulative Model Updates: 54,524
Cumulative Timesteps: 454,746,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 454746008...
Checkpoint 454746008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,109.36154
Policy Entropy: 3.72522
Value Function Loss: 0.05628

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.56469
Value Function Update Magnitude: 0.74230

Collected Steps per Second: 21,965.66388
Overall Steps per Second: 10,594.79652

Timestep Collection Time: 2.27728
Timestep Consumption Time: 2.44409
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.72137

Cumulative Model Updates: 54,530
Cumulative Timesteps: 454,796,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,488.73866
Policy Entropy: 3.70469
Value Function Loss: 0.05748

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.15993
Policy Update Magnitude: 0.50148
Value Function Update Magnitude: 0.72373

Collected Steps per Second: 23,360.14252
Overall Steps per Second: 10,926.06103

Timestep Collection Time: 2.14040
Timestep Consumption Time: 2.43582
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.57621

Cumulative Model Updates: 54,536
Cumulative Timesteps: 454,846,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 454846030...
Checkpoint 454846030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,098.81921
Policy Entropy: 3.70920
Value Function Loss: 0.05484

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.38931
Value Function Update Magnitude: 0.76625

Collected Steps per Second: 22,640.51299
Overall Steps per Second: 10,679.13913

Timestep Collection Time: 2.20861
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.68240

Cumulative Model Updates: 54,542
Cumulative Timesteps: 454,896,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,856.31432
Policy Entropy: 3.71668
Value Function Loss: 0.05388

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.44132
Value Function Update Magnitude: 0.83363

Collected Steps per Second: 23,281.12863
Overall Steps per Second: 10,835.49085

Timestep Collection Time: 2.14895
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.61723

Cumulative Model Updates: 54,548
Cumulative Timesteps: 454,946,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 454946064...
Checkpoint 454946064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,979.28324
Policy Entropy: 3.72179
Value Function Loss: 0.05364

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.51064
Value Function Update Magnitude: 0.85798

Collected Steps per Second: 22,325.51278
Overall Steps per Second: 10,637.83435

Timestep Collection Time: 2.23968
Timestep Consumption Time: 2.46071
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.70039

Cumulative Model Updates: 54,554
Cumulative Timesteps: 454,996,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,839.69730
Policy Entropy: 3.72787
Value Function Loss: 0.05254

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.50354
Value Function Update Magnitude: 0.86125

Collected Steps per Second: 22,802.17958
Overall Steps per Second: 10,661.74850

Timestep Collection Time: 2.19409
Timestep Consumption Time: 2.49839
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.69248

Cumulative Model Updates: 54,560
Cumulative Timesteps: 455,046,096

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 455046096...
Checkpoint 455046096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,993.83051
Policy Entropy: 3.72655
Value Function Loss: 0.05344

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.48990
Value Function Update Magnitude: 0.78088

Collected Steps per Second: 22,496.32279
Overall Steps per Second: 10,837.48624

Timestep Collection Time: 2.22356
Timestep Consumption Time: 2.39208
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.61565

Cumulative Model Updates: 54,566
Cumulative Timesteps: 455,096,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,785.45826
Policy Entropy: 3.72166
Value Function Loss: 0.05612

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.51033
Value Function Update Magnitude: 0.70539

Collected Steps per Second: 23,112.65364
Overall Steps per Second: 10,878.84515

Timestep Collection Time: 2.16557
Timestep Consumption Time: 2.43529
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60086

Cumulative Model Updates: 54,572
Cumulative Timesteps: 455,146,170

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 455146170...
Checkpoint 455146170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,382.19830
Policy Entropy: 3.71455
Value Function Loss: 0.05917

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.49141
Value Function Update Magnitude: 0.68791

Collected Steps per Second: 22,240.25173
Overall Steps per Second: 10,687.51510

Timestep Collection Time: 2.24854
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.67910

Cumulative Model Updates: 54,578
Cumulative Timesteps: 455,196,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,383.98926
Policy Entropy: 3.70813
Value Function Loss: 0.05761

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.53554
Value Function Update Magnitude: 0.70648

Collected Steps per Second: 22,759.53725
Overall Steps per Second: 10,689.92931

Timestep Collection Time: 2.19802
Timestep Consumption Time: 2.48171
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.67973

Cumulative Model Updates: 54,584
Cumulative Timesteps: 455,246,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 455246204...
Checkpoint 455246204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,034.31449
Policy Entropy: 3.71685
Value Function Loss: 0.05565

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.50390
Value Function Update Magnitude: 0.68871

Collected Steps per Second: 22,612.16320
Overall Steps per Second: 10,658.23712

Timestep Collection Time: 2.21226
Timestep Consumption Time: 2.48120
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.69346

Cumulative Model Updates: 54,590
Cumulative Timesteps: 455,296,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,793.73924
Policy Entropy: 3.73198
Value Function Loss: 0.05486

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.51802
Value Function Update Magnitude: 0.74579

Collected Steps per Second: 23,308.47903
Overall Steps per Second: 10,749.03939

Timestep Collection Time: 2.14643
Timestep Consumption Time: 2.50794
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.65437

Cumulative Model Updates: 54,596
Cumulative Timesteps: 455,346,258

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 455346258...
Checkpoint 455346258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,808.82261
Policy Entropy: 3.73862
Value Function Loss: 0.05314

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.60800
Value Function Update Magnitude: 0.83994

Collected Steps per Second: 22,553.42854
Overall Steps per Second: 10,572.08036

Timestep Collection Time: 2.21749
Timestep Consumption Time: 2.51308
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.73057

Cumulative Model Updates: 54,602
Cumulative Timesteps: 455,396,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,234.64063
Policy Entropy: 3.74272
Value Function Loss: 0.05284

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.63993
Value Function Update Magnitude: 0.85340

Collected Steps per Second: 22,961.19323
Overall Steps per Second: 10,849.11671

Timestep Collection Time: 2.17811
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.60978

Cumulative Model Updates: 54,608
Cumulative Timesteps: 455,446,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 455446282...
Checkpoint 455446282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,083.68697
Policy Entropy: 3.72949
Value Function Loss: 0.05434

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.61228
Value Function Update Magnitude: 0.87535

Collected Steps per Second: 22,607.22500
Overall Steps per Second: 10,731.33098

Timestep Collection Time: 2.21257
Timestep Consumption Time: 2.44855
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.66112

Cumulative Model Updates: 54,614
Cumulative Timesteps: 455,496,302

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,301.14330
Policy Entropy: 3.73382
Value Function Loss: 0.05518

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.50299
Value Function Update Magnitude: 0.86358

Collected Steps per Second: 23,259.80964
Overall Steps per Second: 10,916.62959

Timestep Collection Time: 2.15058
Timestep Consumption Time: 2.43161
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.58218

Cumulative Model Updates: 54,620
Cumulative Timesteps: 455,546,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 455546324...
Checkpoint 455546324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,718.86011
Policy Entropy: 3.73482
Value Function Loss: 0.05581

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.44700
Value Function Update Magnitude: 0.87127

Collected Steps per Second: 22,457.38168
Overall Steps per Second: 10,592.56175

Timestep Collection Time: 2.22671
Timestep Consumption Time: 2.49415
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.72086

Cumulative Model Updates: 54,626
Cumulative Timesteps: 455,596,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,683.62827
Policy Entropy: 3.74726
Value Function Loss: 0.05378

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.49220
Value Function Update Magnitude: 0.90374

Collected Steps per Second: 23,148.30889
Overall Steps per Second: 10,962.23505

Timestep Collection Time: 2.16007
Timestep Consumption Time: 2.40122
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.56130

Cumulative Model Updates: 54,632
Cumulative Timesteps: 455,646,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 455646332...
Checkpoint 455646332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,642.44472
Policy Entropy: 3.75400
Value Function Loss: 0.05301

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.54404
Value Function Update Magnitude: 0.87822

Collected Steps per Second: 22,453.60924
Overall Steps per Second: 10,626.33145

Timestep Collection Time: 2.22744
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.70661

Cumulative Model Updates: 54,638
Cumulative Timesteps: 455,696,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,001.78036
Policy Entropy: 3.75431
Value Function Loss: 0.05328

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.51607
Value Function Update Magnitude: 0.87720

Collected Steps per Second: 23,042.00337
Overall Steps per Second: 10,851.28349

Timestep Collection Time: 2.17030
Timestep Consumption Time: 2.43819
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.60849

Cumulative Model Updates: 54,644
Cumulative Timesteps: 455,746,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 455746354...
Checkpoint 455746354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,716.97747
Policy Entropy: 3.75116
Value Function Loss: 0.05363

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.51832
Value Function Update Magnitude: 0.82982

Collected Steps per Second: 22,517.65797
Overall Steps per Second: 10,665.09390

Timestep Collection Time: 2.22190
Timestep Consumption Time: 2.46929
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.69119

Cumulative Model Updates: 54,650
Cumulative Timesteps: 455,796,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,172.13429
Policy Entropy: 3.74216
Value Function Loss: 0.05425

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.55617
Value Function Update Magnitude: 0.73701

Collected Steps per Second: 22,917.45875
Overall Steps per Second: 10,848.31653

Timestep Collection Time: 2.18253
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61067

Cumulative Model Updates: 54,656
Cumulative Timesteps: 455,846,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 455846404...
Checkpoint 455846404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.74011
Policy Entropy: 3.74026
Value Function Loss: 0.05368

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07535
Policy Update Magnitude: 0.57892
Value Function Update Magnitude: 0.70350

Collected Steps per Second: 22,372.41958
Overall Steps per Second: 10,739.50787

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.42110
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.65627

Cumulative Model Updates: 54,662
Cumulative Timesteps: 455,896,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,147.72867
Policy Entropy: 3.73805
Value Function Loss: 0.05384

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.57176
Value Function Update Magnitude: 0.78674

Collected Steps per Second: 22,934.36662
Overall Steps per Second: 10,828.35978

Timestep Collection Time: 2.18127
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61991

Cumulative Model Updates: 54,668
Cumulative Timesteps: 455,946,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 455946436...
Checkpoint 455946436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,543.60279
Policy Entropy: 3.74813
Value Function Loss: 0.05295

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.56696
Value Function Update Magnitude: 0.86724

Collected Steps per Second: 22,327.14817
Overall Steps per Second: 10,715.75827

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.67069

Cumulative Model Updates: 54,674
Cumulative Timesteps: 455,996,486

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,339.66943
Policy Entropy: 3.74579
Value Function Loss: 0.05368

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.49616
Value Function Update Magnitude: 0.89744

Collected Steps per Second: 23,090.50638
Overall Steps per Second: 10,856.49183

Timestep Collection Time: 2.16652
Timestep Consumption Time: 2.44142
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60793

Cumulative Model Updates: 54,680
Cumulative Timesteps: 456,046,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 456046512...
Checkpoint 456046512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,145.05788
Policy Entropy: 3.73760
Value Function Loss: 0.05523

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.52321
Value Function Update Magnitude: 0.89343

Collected Steps per Second: 22,508.53713
Overall Steps per Second: 10,675.47367

Timestep Collection Time: 2.22191
Timestep Consumption Time: 2.46284
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.68476

Cumulative Model Updates: 54,686
Cumulative Timesteps: 456,096,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,795.13538
Policy Entropy: 3.72490
Value Function Loss: 0.05440

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07568
Policy Update Magnitude: 0.62643
Value Function Update Magnitude: 0.91155

Collected Steps per Second: 23,387.70610
Overall Steps per Second: 10,937.81928

Timestep Collection Time: 2.13882
Timestep Consumption Time: 2.43449
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.57331

Cumulative Model Updates: 54,692
Cumulative Timesteps: 456,146,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 456146546...
Checkpoint 456146546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,720.86878
Policy Entropy: 3.72152
Value Function Loss: 0.05458

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.65619
Value Function Update Magnitude: 0.90081

Collected Steps per Second: 22,488.03266
Overall Steps per Second: 10,590.73882

Timestep Collection Time: 2.22412
Timestep Consumption Time: 2.49850
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.72262

Cumulative Model Updates: 54,698
Cumulative Timesteps: 456,196,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,041.54008
Policy Entropy: 3.73176
Value Function Loss: 0.05214

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.87808

Collected Steps per Second: 23,104.61309
Overall Steps per Second: 10,971.14050

Timestep Collection Time: 2.16476
Timestep Consumption Time: 2.39411
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.55887

Cumulative Model Updates: 54,704
Cumulative Timesteps: 456,246,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 456246578...
Checkpoint 456246578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,957.27300
Policy Entropy: 3.74245
Value Function Loss: 0.05096

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.50750
Value Function Update Magnitude: 0.84961

Collected Steps per Second: 22,746.99854
Overall Steps per Second: 10,711.42174

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.47150
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.67109

Cumulative Model Updates: 54,710
Cumulative Timesteps: 456,296,612

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,682.05983
Policy Entropy: 3.75126
Value Function Loss: 0.05258

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.50841
Value Function Update Magnitude: 0.75477

Collected Steps per Second: 23,013.14961
Overall Steps per Second: 10,791.01558

Timestep Collection Time: 2.17293
Timestep Consumption Time: 2.46111
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.63404

Cumulative Model Updates: 54,716
Cumulative Timesteps: 456,346,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 456346618...
Checkpoint 456346618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,343.56607
Policy Entropy: 3.74133
Value Function Loss: 0.05409

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.53166
Value Function Update Magnitude: 0.76496

Collected Steps per Second: 22,471.49512
Overall Steps per Second: 10,628.54027

Timestep Collection Time: 2.22558
Timestep Consumption Time: 2.47987
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.70544

Cumulative Model Updates: 54,722
Cumulative Timesteps: 456,396,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,451.92114
Policy Entropy: 3.74369
Value Function Loss: 0.05359

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.57077
Value Function Update Magnitude: 0.80545

Collected Steps per Second: 23,006.46684
Overall Steps per Second: 10,866.15384

Timestep Collection Time: 2.17443
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60384

Cumulative Model Updates: 54,728
Cumulative Timesteps: 456,446,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 456446656...
Checkpoint 456446656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,905.29493
Policy Entropy: 3.74347
Value Function Loss: 0.05459

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.48674
Value Function Update Magnitude: 0.69406

Collected Steps per Second: 22,381.08472
Overall Steps per Second: 10,700.67657

Timestep Collection Time: 2.23528
Timestep Consumption Time: 2.43994
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.67522

Cumulative Model Updates: 54,734
Cumulative Timesteps: 456,496,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,503.33048
Policy Entropy: 3.74308
Value Function Loss: 0.05629

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.45454
Value Function Update Magnitude: 0.59748

Collected Steps per Second: 23,007.05492
Overall Steps per Second: 10,841.44650

Timestep Collection Time: 2.17403
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61359

Cumulative Model Updates: 54,740
Cumulative Timesteps: 456,546,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 456546702...
Checkpoint 456546702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,745.85713
Policy Entropy: 3.75351
Value Function Loss: 0.06102

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.49992
Value Function Update Magnitude: 0.59695

Collected Steps per Second: 21,999.72445
Overall Steps per Second: 10,625.11346

Timestep Collection Time: 2.27330
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.70696

Cumulative Model Updates: 54,746
Cumulative Timesteps: 456,596,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,227.84909
Policy Entropy: 3.74883
Value Function Loss: 0.06185

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.50839
Value Function Update Magnitude: 0.61119

Collected Steps per Second: 22,917.96766
Overall Steps per Second: 10,893.64314

Timestep Collection Time: 2.18231
Timestep Consumption Time: 2.40881
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.59112

Cumulative Model Updates: 54,752
Cumulative Timesteps: 456,646,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 456646728...
Checkpoint 456646728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,282.08321
Policy Entropy: 3.75808
Value Function Loss: 0.06063

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.66443

Collected Steps per Second: 22,611.48143
Overall Steps per Second: 10,800.00149

Timestep Collection Time: 2.21180
Timestep Consumption Time: 2.41894
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.63074

Cumulative Model Updates: 54,758
Cumulative Timesteps: 456,696,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.80145
Policy Entropy: 3.75275
Value Function Loss: 0.06039

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.54294
Value Function Update Magnitude: 0.70977

Collected Steps per Second: 22,720.46436
Overall Steps per Second: 10,772.57693

Timestep Collection Time: 2.20084
Timestep Consumption Time: 2.44095
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.64179

Cumulative Model Updates: 54,764
Cumulative Timesteps: 456,746,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 456746744...
Checkpoint 456746744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,103.68836
Policy Entropy: 3.75322
Value Function Loss: 0.05897

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.55368
Value Function Update Magnitude: 0.80689

Collected Steps per Second: 22,271.54332
Overall Steps per Second: 10,683.41443

Timestep Collection Time: 2.24529
Timestep Consumption Time: 2.43543
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.68071

Cumulative Model Updates: 54,770
Cumulative Timesteps: 456,796,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.77345
Policy Entropy: 3.73390
Value Function Loss: 0.06029

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.54553
Value Function Update Magnitude: 0.81511

Collected Steps per Second: 23,063.15752
Overall Steps per Second: 10,864.00511

Timestep Collection Time: 2.16857
Timestep Consumption Time: 2.43508
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.60364

Cumulative Model Updates: 54,776
Cumulative Timesteps: 456,846,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 456846764...
Checkpoint 456846764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,290.02276
Policy Entropy: 3.72143
Value Function Loss: 0.06134

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.48507
Value Function Update Magnitude: 0.66793

Collected Steps per Second: 22,455.42259
Overall Steps per Second: 10,698.96663

Timestep Collection Time: 2.22681
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.67372

Cumulative Model Updates: 54,782
Cumulative Timesteps: 456,896,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,958.50453
Policy Entropy: 3.72661
Value Function Loss: 0.05833

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.45640
Value Function Update Magnitude: 0.63166

Collected Steps per Second: 22,772.61247
Overall Steps per Second: 10,802.34917

Timestep Collection Time: 2.19615
Timestep Consumption Time: 2.43359
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.62973

Cumulative Model Updates: 54,788
Cumulative Timesteps: 456,946,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 456946780...
Checkpoint 456946780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,943.80399
Policy Entropy: 3.72597
Value Function Loss: 0.05691

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.48017
Value Function Update Magnitude: 0.62491

Collected Steps per Second: 22,236.88578
Overall Steps per Second: 10,685.98901

Timestep Collection Time: 2.24942
Timestep Consumption Time: 2.43148
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.68090

Cumulative Model Updates: 54,794
Cumulative Timesteps: 456,996,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,769.26928
Policy Entropy: 3.72070
Value Function Loss: 0.05635

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.49702
Value Function Update Magnitude: 0.68819

Collected Steps per Second: 22,959.71288
Overall Steps per Second: 10,738.04724

Timestep Collection Time: 2.17886
Timestep Consumption Time: 2.47990
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.65876

Cumulative Model Updates: 54,800
Cumulative Timesteps: 457,046,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 457046826...
Checkpoint 457046826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,517.24570
Policy Entropy: 3.70811
Value Function Loss: 0.05971

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.51786
Value Function Update Magnitude: 0.70581

Collected Steps per Second: 22,501.98881
Overall Steps per Second: 10,770.17590

Timestep Collection Time: 2.22256
Timestep Consumption Time: 2.42100
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.64356

Cumulative Model Updates: 54,806
Cumulative Timesteps: 457,096,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,778.88966
Policy Entropy: 3.71082
Value Function Loss: 0.06018

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.15929
Policy Update Magnitude: 0.40171
Value Function Update Magnitude: 0.75010

Collected Steps per Second: 23,099.16579
Overall Steps per Second: 10,923.11885

Timestep Collection Time: 2.16527
Timestep Consumption Time: 2.41364
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.57891

Cumulative Model Updates: 54,812
Cumulative Timesteps: 457,146,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 457146854...
Checkpoint 457146854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,931.60503
Policy Entropy: 3.72465
Value Function Loss: 0.05784

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.42150
Value Function Update Magnitude: 0.81590

Collected Steps per Second: 22,460.97271
Overall Steps per Second: 10,737.55750

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.43144
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.65842

Cumulative Model Updates: 54,818
Cumulative Timesteps: 457,196,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,596.11340
Policy Entropy: 3.72725
Value Function Loss: 0.05534

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.49477
Value Function Update Magnitude: 0.85093

Collected Steps per Second: 22,941.19616
Overall Steps per Second: 10,842.10991

Timestep Collection Time: 2.18079
Timestep Consumption Time: 2.43362
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.61442

Cumulative Model Updates: 54,824
Cumulative Timesteps: 457,246,904

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 457246904...
Checkpoint 457246904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,551.53337
Policy Entropy: 3.74770
Value Function Loss: 0.05370

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.47663
Value Function Update Magnitude: 0.80309

Collected Steps per Second: 22,451.83135
Overall Steps per Second: 10,749.50373

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.42594
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.65435

Cumulative Model Updates: 54,830
Cumulative Timesteps: 457,296,936

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,063.81770
Policy Entropy: 3.73954
Value Function Loss: 0.05585

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.47612
Value Function Update Magnitude: 0.81062

Collected Steps per Second: 22,968.49051
Overall Steps per Second: 10,827.55159

Timestep Collection Time: 2.17777
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61970

Cumulative Model Updates: 54,836
Cumulative Timesteps: 457,346,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 457346956...
Checkpoint 457346956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.40206
Policy Entropy: 3.75108
Value Function Loss: 0.05434

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.46988
Value Function Update Magnitude: 0.84997

Collected Steps per Second: 22,409.85202
Overall Steps per Second: 10,645.29187

Timestep Collection Time: 2.23223
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.69917

Cumulative Model Updates: 54,842
Cumulative Timesteps: 457,396,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,584.71267
Policy Entropy: 3.73607
Value Function Loss: 0.05278

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.48180
Value Function Update Magnitude: 0.86172

Collected Steps per Second: 22,751.98354
Overall Steps per Second: 10,682.33717

Timestep Collection Time: 2.19779
Timestep Consumption Time: 2.48321
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.68100

Cumulative Model Updates: 54,848
Cumulative Timesteps: 457,446,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 457446984...
Checkpoint 457446984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.89551
Policy Entropy: 3.73813
Value Function Loss: 0.05240

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.46664
Value Function Update Magnitude: 0.83944

Collected Steps per Second: 22,234.33618
Overall Steps per Second: 10,565.08578

Timestep Collection Time: 2.25066
Timestep Consumption Time: 2.48588
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.73654

Cumulative Model Updates: 54,854
Cumulative Timesteps: 457,497,026

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,034.83844
Policy Entropy: 3.72948
Value Function Loss: 0.05343

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.47406
Value Function Update Magnitude: 0.83208

Collected Steps per Second: 22,978.96434
Overall Steps per Second: 10,756.46028

Timestep Collection Time: 2.17660
Timestep Consumption Time: 2.47326
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.64986

Cumulative Model Updates: 54,860
Cumulative Timesteps: 457,547,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 457547042...
Checkpoint 457547042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,570.85316
Policy Entropy: 3.72589
Value Function Loss: 0.05266

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.50083
Value Function Update Magnitude: 0.81323

Collected Steps per Second: 22,471.67387
Overall Steps per Second: 10,638.39743

Timestep Collection Time: 2.22582
Timestep Consumption Time: 2.47582
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.70165

Cumulative Model Updates: 54,866
Cumulative Timesteps: 457,597,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,807.66515
Policy Entropy: 3.71761
Value Function Loss: 0.05213

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.52746
Value Function Update Magnitude: 0.78650

Collected Steps per Second: 22,813.83670
Overall Steps per Second: 10,690.47455

Timestep Collection Time: 2.19192
Timestep Consumption Time: 2.48571
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.67762

Cumulative Model Updates: 54,872
Cumulative Timesteps: 457,647,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 457647066...
Checkpoint 457647066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,216.84243
Policy Entropy: 3.73016
Value Function Loss: 0.05129

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.50423
Value Function Update Magnitude: 0.79112

Collected Steps per Second: 22,504.56732
Overall Steps per Second: 10,794.08326

Timestep Collection Time: 2.22275
Timestep Consumption Time: 2.41146
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.63421

Cumulative Model Updates: 54,878
Cumulative Timesteps: 457,697,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.77466
Policy Entropy: 3.74710
Value Function Loss: 0.05240

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06370
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.83157

Collected Steps per Second: 22,678.66992
Overall Steps per Second: 10,617.29239

Timestep Collection Time: 2.20498
Timestep Consumption Time: 2.50488
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.70986

Cumulative Model Updates: 54,884
Cumulative Timesteps: 457,747,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 457747094...
Checkpoint 457747094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,931.30192
Policy Entropy: 3.74941
Value Function Loss: 0.05252

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06559
Policy Update Magnitude: 0.64602
Value Function Update Magnitude: 0.85319

Collected Steps per Second: 22,386.36784
Overall Steps per Second: 10,563.62172

Timestep Collection Time: 2.23457
Timestep Consumption Time: 2.50092
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.73550

Cumulative Model Updates: 54,890
Cumulative Timesteps: 457,797,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,092.31471
Policy Entropy: 3.75084
Value Function Loss: 0.05444

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06040
Policy Update Magnitude: 0.68228
Value Function Update Magnitude: 0.80457

Collected Steps per Second: 22,873.07019
Overall Steps per Second: 10,831.17204

Timestep Collection Time: 2.18650
Timestep Consumption Time: 2.43091
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.61741

Cumulative Model Updates: 54,896
Cumulative Timesteps: 457,847,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 457847130...
Checkpoint 457847130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,871.91450
Policy Entropy: 3.74005
Value Function Loss: 0.05445

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06933
Policy Update Magnitude: 0.67259
Value Function Update Magnitude: 0.68683

Collected Steps per Second: 22,310.21440
Overall Steps per Second: 10,697.41558

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.43348
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.67515

Cumulative Model Updates: 54,902
Cumulative Timesteps: 457,897,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,465.61590
Policy Entropy: 3.75555
Value Function Loss: 0.05451

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.57996
Value Function Update Magnitude: 0.61925

Collected Steps per Second: 22,867.61669
Overall Steps per Second: 10,828.77546

Timestep Collection Time: 2.18711
Timestep Consumption Time: 2.43151
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.61862

Cumulative Model Updates: 54,908
Cumulative Timesteps: 457,947,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 457947156...
Checkpoint 457947156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,206.09762
Policy Entropy: 3.75058
Value Function Loss: 0.05379

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.57598
Value Function Update Magnitude: 0.62019

Collected Steps per Second: 22,223.66656
Overall Steps per Second: 10,690.10569

Timestep Collection Time: 2.25093
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.67947

Cumulative Model Updates: 54,914
Cumulative Timesteps: 457,997,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,511.76175
Policy Entropy: 3.75939
Value Function Loss: 0.05314

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.54482
Value Function Update Magnitude: 0.75308

Collected Steps per Second: 23,254.42130
Overall Steps per Second: 10,921.38461

Timestep Collection Time: 2.15082
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.57964

Cumulative Model Updates: 54,920
Cumulative Timesteps: 458,047,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 458047196...
Checkpoint 458047196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,388.28613
Policy Entropy: 3.75212
Value Function Loss: 0.05355

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.56832
Value Function Update Magnitude: 0.81362

Collected Steps per Second: 22,383.53906
Overall Steps per Second: 10,737.33100

Timestep Collection Time: 2.23486
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.65889

Cumulative Model Updates: 54,926
Cumulative Timesteps: 458,097,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,381.93951
Policy Entropy: 3.75867
Value Function Loss: 0.05470

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.52357
Value Function Update Magnitude: 0.81313

Collected Steps per Second: 23,034.56995
Overall Steps per Second: 10,836.42734

Timestep Collection Time: 2.17143
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61573

Cumulative Model Updates: 54,932
Cumulative Timesteps: 458,147,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 458147238...
Checkpoint 458147238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,606.12648
Policy Entropy: 3.75297
Value Function Loss: 0.05532

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.52700
Value Function Update Magnitude: 0.83592

Collected Steps per Second: 22,636.69766
Overall Steps per Second: 10,675.44785

Timestep Collection Time: 2.20889
Timestep Consumption Time: 2.47494
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.68383

Cumulative Model Updates: 54,938
Cumulative Timesteps: 458,197,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,861.37928
Policy Entropy: 3.73742
Value Function Loss: 0.05470

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.51906
Value Function Update Magnitude: 0.86382

Collected Steps per Second: 22,910.20648
Overall Steps per Second: 10,833.36094

Timestep Collection Time: 2.18270
Timestep Consumption Time: 2.43323
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.61593

Cumulative Model Updates: 54,944
Cumulative Timesteps: 458,247,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 458247246...
Checkpoint 458247246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,229.28906
Policy Entropy: 3.73830
Value Function Loss: 0.05248

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.49767
Value Function Update Magnitude: 0.83080

Collected Steps per Second: 22,496.63023
Overall Steps per Second: 10,722.24332

Timestep Collection Time: 2.22300
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.66414

Cumulative Model Updates: 54,950
Cumulative Timesteps: 458,297,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,627.68657
Policy Entropy: 3.74523
Value Function Loss: 0.05349

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.53916
Value Function Update Magnitude: 0.80906

Collected Steps per Second: 22,480.81704
Overall Steps per Second: 10,933.12710

Timestep Collection Time: 2.22501
Timestep Consumption Time: 2.35008
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.57509

Cumulative Model Updates: 54,956
Cumulative Timesteps: 458,347,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 458347276...
Checkpoint 458347276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,977.89072
Policy Entropy: 3.74990
Value Function Loss: 0.05337

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.48422
Value Function Update Magnitude: 0.82450

Collected Steps per Second: 21,857.71997
Overall Steps per Second: 10,575.53679

Timestep Collection Time: 2.28752
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.72789

Cumulative Model Updates: 54,962
Cumulative Timesteps: 458,397,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,417.59514
Policy Entropy: 3.75872
Value Function Loss: 0.05392

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.48947
Value Function Update Magnitude: 0.78449

Collected Steps per Second: 22,435.34841
Overall Steps per Second: 10,909.97042

Timestep Collection Time: 2.22889
Timestep Consumption Time: 2.35462
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.58351

Cumulative Model Updates: 54,968
Cumulative Timesteps: 458,447,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 458447282...
Checkpoint 458447282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,560.95850
Policy Entropy: 3.75504
Value Function Loss: 0.05472

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.47317
Value Function Update Magnitude: 0.72971

Collected Steps per Second: 21,733.16188
Overall Steps per Second: 10,672.37885

Timestep Collection Time: 2.30192
Timestep Consumption Time: 2.38569
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.68761

Cumulative Model Updates: 54,974
Cumulative Timesteps: 458,497,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,383.31557
Policy Entropy: 3.76273
Value Function Loss: 0.05572

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.51752
Value Function Update Magnitude: 0.69192

Collected Steps per Second: 22,606.35990
Overall Steps per Second: 10,918.27666

Timestep Collection Time: 2.21256
Timestep Consumption Time: 2.36856
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.58113

Cumulative Model Updates: 54,980
Cumulative Timesteps: 458,547,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 458547328...
Checkpoint 458547328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,637.56917
Policy Entropy: 3.73901
Value Function Loss: 0.05580

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.57283
Value Function Update Magnitude: 0.73709

Collected Steps per Second: 21,768.84508
Overall Steps per Second: 10,642.05354

Timestep Collection Time: 2.29787
Timestep Consumption Time: 2.40254
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.70041

Cumulative Model Updates: 54,986
Cumulative Timesteps: 458,597,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,419.01386
Policy Entropy: 3.73203
Value Function Loss: 0.05541

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.62164
Value Function Update Magnitude: 0.77426

Collected Steps per Second: 23,273.08401
Overall Steps per Second: 10,907.02722

Timestep Collection Time: 2.15038
Timestep Consumption Time: 2.43804
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.58842

Cumulative Model Updates: 54,992
Cumulative Timesteps: 458,647,396

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 458647396...
Checkpoint 458647396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,843.57577
Policy Entropy: 3.71930
Value Function Loss: 0.05602

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.60012
Value Function Update Magnitude: 0.80090

Collected Steps per Second: 22,381.46482
Overall Steps per Second: 10,639.56687

Timestep Collection Time: 2.23488
Timestep Consumption Time: 2.46643
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.70132

Cumulative Model Updates: 54,998
Cumulative Timesteps: 458,697,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,517.75333
Policy Entropy: 3.74113
Value Function Loss: 0.05556

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.50768
Value Function Update Magnitude: 0.80733

Collected Steps per Second: 23,107.20600
Overall Steps per Second: 10,879.13592

Timestep Collection Time: 2.16487
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.59816

Cumulative Model Updates: 55,004
Cumulative Timesteps: 458,747,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 458747440...
Checkpoint 458747440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,416.03648
Policy Entropy: 3.76343
Value Function Loss: 0.05567

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.56721
Value Function Update Magnitude: 0.81496

Collected Steps per Second: 22,761.21831
Overall Steps per Second: 10,646.28459

Timestep Collection Time: 2.19804
Timestep Consumption Time: 2.50125
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.69929

Cumulative Model Updates: 55,010
Cumulative Timesteps: 458,797,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,979.43092
Policy Entropy: 3.76657
Value Function Loss: 0.05649

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.65277
Value Function Update Magnitude: 0.72874

Collected Steps per Second: 22,923.26741
Overall Steps per Second: 10,839.80515

Timestep Collection Time: 2.18224
Timestep Consumption Time: 2.43261
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.61484

Cumulative Model Updates: 55,016
Cumulative Timesteps: 458,847,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 458847494...
Checkpoint 458847494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,675.95514
Policy Entropy: 3.75310
Value Function Loss: 0.05688

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.58959
Value Function Update Magnitude: 0.72988

Collected Steps per Second: 22,663.80436
Overall Steps per Second: 10,716.45766

Timestep Collection Time: 2.20722
Timestep Consumption Time: 2.46074
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.66796

Cumulative Model Updates: 55,022
Cumulative Timesteps: 458,897,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,825.41658
Policy Entropy: 3.74509
Value Function Loss: 0.05614

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.68771

Collected Steps per Second: 23,057.31325
Overall Steps per Second: 10,857.48753

Timestep Collection Time: 2.16920
Timestep Consumption Time: 2.43739
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.60659

Cumulative Model Updates: 55,028
Cumulative Timesteps: 458,947,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 458947534...
Checkpoint 458947534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,898.66084
Policy Entropy: 3.74419
Value Function Loss: 0.05367

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.47041
Value Function Update Magnitude: 0.73377

Collected Steps per Second: 22,440.66560
Overall Steps per Second: 10,698.51565

Timestep Collection Time: 2.22845
Timestep Consumption Time: 2.44584
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.67429

Cumulative Model Updates: 55,034
Cumulative Timesteps: 458,997,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,530.10637
Policy Entropy: 3.75404
Value Function Loss: 0.05063

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.48481
Value Function Update Magnitude: 0.83979

Collected Steps per Second: 22,797.69789
Overall Steps per Second: 10,821.45942

Timestep Collection Time: 2.19382
Timestep Consumption Time: 2.42792
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62174

Cumulative Model Updates: 55,040
Cumulative Timesteps: 459,047,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 459047556...
Checkpoint 459047556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,104.30606
Policy Entropy: 3.73440
Value Function Loss: 0.05265

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.58513
Value Function Update Magnitude: 0.84702

Collected Steps per Second: 22,729.72547
Overall Steps per Second: 10,721.16196

Timestep Collection Time: 2.19976
Timestep Consumption Time: 2.46391
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.66367

Cumulative Model Updates: 55,046
Cumulative Timesteps: 459,097,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,917.32410
Policy Entropy: 3.74386
Value Function Loss: 0.05244

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.63203
Value Function Update Magnitude: 0.86012

Collected Steps per Second: 23,161.70895
Overall Steps per Second: 10,856.90378

Timestep Collection Time: 2.15951
Timestep Consumption Time: 2.44751
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60702

Cumulative Model Updates: 55,052
Cumulative Timesteps: 459,147,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 459147574...
Checkpoint 459147574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,783.77952
Policy Entropy: 3.73427
Value Function Loss: 0.05386

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.64253
Value Function Update Magnitude: 0.85602

Collected Steps per Second: 22,434.50448
Overall Steps per Second: 10,669.69538

Timestep Collection Time: 2.22871
Timestep Consumption Time: 2.45746
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.68617

Cumulative Model Updates: 55,058
Cumulative Timesteps: 459,197,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,831.63949
Policy Entropy: 3.73350
Value Function Loss: 0.05234

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.61892
Value Function Update Magnitude: 0.85298

Collected Steps per Second: 23,033.61657
Overall Steps per Second: 10,855.49936

Timestep Collection Time: 2.17100
Timestep Consumption Time: 2.43551
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60651

Cumulative Model Updates: 55,064
Cumulative Timesteps: 459,247,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 459247580...
Checkpoint 459247580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,346.72042
Policy Entropy: 3.72870
Value Function Loss: 0.05342

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.58381
Value Function Update Magnitude: 0.87316

Collected Steps per Second: 22,681.94194
Overall Steps per Second: 10,715.74855

Timestep Collection Time: 2.20545
Timestep Consumption Time: 2.46281
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.66827

Cumulative Model Updates: 55,070
Cumulative Timesteps: 459,297,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.60316
Policy Entropy: 3.72667
Value Function Loss: 0.05262

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.52868
Value Function Update Magnitude: 0.83468

Collected Steps per Second: 22,889.49904
Overall Steps per Second: 10,834.45750

Timestep Collection Time: 2.18511
Timestep Consumption Time: 2.43128
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61638

Cumulative Model Updates: 55,076
Cumulative Timesteps: 459,347,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 459347620...
Checkpoint 459347620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,544.18516
Policy Entropy: 3.73635
Value Function Loss: 0.05484

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.45056
Value Function Update Magnitude: 0.76304

Collected Steps per Second: 22,566.88815
Overall Steps per Second: 10,651.95104

Timestep Collection Time: 2.21750
Timestep Consumption Time: 2.48042
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.69792

Cumulative Model Updates: 55,082
Cumulative Timesteps: 459,397,662

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,374.41308
Policy Entropy: 3.75509
Value Function Loss: 0.05590

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.16040
Policy Update Magnitude: 0.41931
Value Function Update Magnitude: 0.71149

Collected Steps per Second: 23,034.19799
Overall Steps per Second: 10,881.70798

Timestep Collection Time: 2.17095
Timestep Consumption Time: 2.42447
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.59542

Cumulative Model Updates: 55,088
Cumulative Timesteps: 459,447,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 459447668...
Checkpoint 459447668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,177.25479
Policy Entropy: 3.76092
Value Function Loss: 0.05612

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.40582
Value Function Update Magnitude: 0.71947

Collected Steps per Second: 22,423.81513
Overall Steps per Second: 10,752.40308

Timestep Collection Time: 2.22995
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.65050

Cumulative Model Updates: 55,094
Cumulative Timesteps: 459,497,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,509.78424
Policy Entropy: 3.76508
Value Function Loss: 0.05419

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.46316
Value Function Update Magnitude: 0.69496

Collected Steps per Second: 22,970.70173
Overall Steps per Second: 10,898.08142

Timestep Collection Time: 2.17799
Timestep Consumption Time: 2.41272
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.59072

Cumulative Model Updates: 55,100
Cumulative Timesteps: 459,547,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 459547702...
Checkpoint 459547702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,899.81651
Policy Entropy: 3.76318
Value Function Loss: 0.05294

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.48761
Value Function Update Magnitude: 0.70016

Collected Steps per Second: 22,378.21528
Overall Steps per Second: 10,625.00438

Timestep Collection Time: 2.23530
Timestep Consumption Time: 2.47265
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.70795

Cumulative Model Updates: 55,106
Cumulative Timesteps: 459,597,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,649.32093
Policy Entropy: 3.75762
Value Function Loss: 0.05299

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11896
Policy Update Magnitude: 0.47841
Value Function Update Magnitude: 0.73319

Collected Steps per Second: 22,943.38661
Overall Steps per Second: 10,854.75285

Timestep Collection Time: 2.17936
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60646

Cumulative Model Updates: 55,112
Cumulative Timesteps: 459,647,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 459647726...
Checkpoint 459647726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,445.28997
Policy Entropy: 3.76924
Value Function Loss: 0.05069

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.49536
Value Function Update Magnitude: 0.78293

Collected Steps per Second: 22,149.28876
Overall Steps per Second: 10,679.62388

Timestep Collection Time: 2.25813
Timestep Consumption Time: 2.42518
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.68331

Cumulative Model Updates: 55,118
Cumulative Timesteps: 459,697,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,977.65259
Policy Entropy: 3.75428
Value Function Loss: 0.05271

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.46993
Value Function Update Magnitude: 0.79693

Collected Steps per Second: 23,201.80449
Overall Steps per Second: 10,883.19506

Timestep Collection Time: 2.15578
Timestep Consumption Time: 2.44011
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.59589

Cumulative Model Updates: 55,124
Cumulative Timesteps: 459,747,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 459747760...
Checkpoint 459747760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,178.59385
Policy Entropy: 3.73609
Value Function Loss: 0.05202

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.47540
Value Function Update Magnitude: 0.75706

Collected Steps per Second: 22,248.33054
Overall Steps per Second: 10,698.73505

Timestep Collection Time: 2.24952
Timestep Consumption Time: 2.42842
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.67794

Cumulative Model Updates: 55,130
Cumulative Timesteps: 459,797,808

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,032.81848
Policy Entropy: 3.72860
Value Function Loss: 0.04907

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.17013
Policy Update Magnitude: 0.40430
Value Function Update Magnitude: 0.66208

Collected Steps per Second: 22,804.05124
Overall Steps per Second: 10,818.79926

Timestep Collection Time: 2.19347
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62343

Cumulative Model Updates: 55,136
Cumulative Timesteps: 459,847,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 459847828...
Checkpoint 459847828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,868.69550
Policy Entropy: 3.75095
Value Function Loss: 0.04552

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.42516
Value Function Update Magnitude: 0.69816

Collected Steps per Second: 22,296.59769
Overall Steps per Second: 10,712.73475

Timestep Collection Time: 2.24384
Timestep Consumption Time: 2.42630
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.67014

Cumulative Model Updates: 55,142
Cumulative Timesteps: 459,897,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,757.93471
Policy Entropy: 3.74757
Value Function Loss: 0.04572

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10545
Policy Update Magnitude: 0.50793
Value Function Update Magnitude: 0.73637

Collected Steps per Second: 23,114.37686
Overall Steps per Second: 10,868.75273

Timestep Collection Time: 2.16523
Timestep Consumption Time: 2.43953
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60476

Cumulative Model Updates: 55,148
Cumulative Timesteps: 459,947,906

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 459947906...
Checkpoint 459947906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,413.69575
Policy Entropy: 3.75168
Value Function Loss: 0.04972

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.50619
Value Function Update Magnitude: 0.71792

Collected Steps per Second: 22,395.08684
Overall Steps per Second: 10,665.53461

Timestep Collection Time: 2.23335
Timestep Consumption Time: 2.45615
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.68950

Cumulative Model Updates: 55,154
Cumulative Timesteps: 459,997,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,088.56088
Policy Entropy: 3.72624
Value Function Loss: 0.05281

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.49043
Value Function Update Magnitude: 0.72757

Collected Steps per Second: 22,991.82555
Overall Steps per Second: 10,852.45628

Timestep Collection Time: 2.17573
Timestep Consumption Time: 2.43373
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.60946

Cumulative Model Updates: 55,160
Cumulative Timesteps: 460,047,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 460047946...
Checkpoint 460047946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,344.71483
Policy Entropy: 3.72151
Value Function Loss: 0.05555

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.46402
Value Function Update Magnitude: 0.67417

Collected Steps per Second: 22,290.82744
Overall Steps per Second: 10,684.99795

Timestep Collection Time: 2.24424
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.68189

Cumulative Model Updates: 55,166
Cumulative Timesteps: 460,097,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,702.34702
Policy Entropy: 3.72220
Value Function Loss: 0.05506

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06674
Policy Update Magnitude: 0.54360
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 23,055.99721
Overall Steps per Second: 10,853.84837

Timestep Collection Time: 2.16967
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.60887

Cumulative Model Updates: 55,172
Cumulative Timesteps: 460,147,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 460147996...
Checkpoint 460147996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,357.12515
Policy Entropy: 3.73468
Value Function Loss: 0.05501

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06598
Policy Update Magnitude: 0.63198
Value Function Update Magnitude: 0.64663

Collected Steps per Second: 22,267.01270
Overall Steps per Second: 10,651.10763

Timestep Collection Time: 2.24601
Timestep Consumption Time: 2.44946
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.69547

Cumulative Model Updates: 55,178
Cumulative Timesteps: 460,198,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.62732
Policy Entropy: 3.74342
Value Function Loss: 0.05568

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05535
Policy Update Magnitude: 0.66034
Value Function Update Magnitude: 0.65442

Collected Steps per Second: 22,658.53775
Overall Steps per Second: 10,628.76363

Timestep Collection Time: 2.20782
Timestep Consumption Time: 2.49884
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.70666

Cumulative Model Updates: 55,184
Cumulative Timesteps: 460,248,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 460248034...
Checkpoint 460248034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,212.47606
Policy Entropy: 3.74549
Value Function Loss: 0.05587

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06628
Policy Update Magnitude: 0.66146
Value Function Update Magnitude: 0.69695

Collected Steps per Second: 22,747.30245
Overall Steps per Second: 10,684.52787

Timestep Collection Time: 2.19912
Timestep Consumption Time: 2.48279
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.68191

Cumulative Model Updates: 55,190
Cumulative Timesteps: 460,298,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,315.95957
Policy Entropy: 3.74787
Value Function Loss: 0.05584

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.62184
Value Function Update Magnitude: 0.68161

Collected Steps per Second: 22,878.27389
Overall Steps per Second: 10,770.44014

Timestep Collection Time: 2.18565
Timestep Consumption Time: 2.45705
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.64271

Cumulative Model Updates: 55,196
Cumulative Timesteps: 460,348,062

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 460348062...
Checkpoint 460348062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,086.18074
Policy Entropy: 3.74025
Value Function Loss: 0.05574

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.62169
Value Function Update Magnitude: 0.60769

Collected Steps per Second: 22,399.17047
Overall Steps per Second: 10,612.68587

Timestep Collection Time: 2.23240
Timestep Consumption Time: 2.47932
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.71172

Cumulative Model Updates: 55,202
Cumulative Timesteps: 460,398,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,429.31338
Policy Entropy: 3.73502
Value Function Loss: 0.05654

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05800
Policy Update Magnitude: 0.66028
Value Function Update Magnitude: 0.58828

Collected Steps per Second: 22,984.25513
Overall Steps per Second: 10,831.29331

Timestep Collection Time: 2.17575
Timestep Consumption Time: 2.44124
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61699

Cumulative Model Updates: 55,208
Cumulative Timesteps: 460,448,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 460448074...
Checkpoint 460448074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,574.29032
Policy Entropy: 3.71696
Value Function Loss: 0.05923

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.66669
Value Function Update Magnitude: 0.54499

Collected Steps per Second: 22,519.55948
Overall Steps per Second: 10,782.37751

Timestep Collection Time: 2.22029
Timestep Consumption Time: 2.41690
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.63720

Cumulative Model Updates: 55,214
Cumulative Timesteps: 460,498,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,854.71157
Policy Entropy: 3.71681
Value Function Loss: 0.05879

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.57265
Value Function Update Magnitude: 0.57196

Collected Steps per Second: 22,745.44868
Overall Steps per Second: 10,806.97923

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.42947
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62868

Cumulative Model Updates: 55,220
Cumulative Timesteps: 460,548,096

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 460548096...
Checkpoint 460548096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,207.13936
Policy Entropy: 3.72713
Value Function Loss: 0.05662

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.52118
Value Function Update Magnitude: 0.63403

Collected Steps per Second: 22,416.53953
Overall Steps per Second: 10,664.39082

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.69019

Cumulative Model Updates: 55,226
Cumulative Timesteps: 460,598,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,260.89655
Policy Entropy: 3.72147
Value Function Loss: 0.05396

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.52334
Value Function Update Magnitude: 0.67025

Collected Steps per Second: 22,782.07764
Overall Steps per Second: 10,842.39781

Timestep Collection Time: 2.19506
Timestep Consumption Time: 2.41721
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.61226

Cumulative Model Updates: 55,232
Cumulative Timesteps: 460,648,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 460648122...
Checkpoint 460648122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,923.24474
Policy Entropy: 3.71991
Value Function Loss: 0.05279

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.53948
Value Function Update Magnitude: 0.67861

Collected Steps per Second: 22,628.97343
Overall Steps per Second: 10,719.91776

Timestep Collection Time: 2.21009
Timestep Consumption Time: 2.45525
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.66533

Cumulative Model Updates: 55,238
Cumulative Timesteps: 460,698,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,632.75466
Policy Entropy: 3.71377
Value Function Loss: 0.05547

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06686
Policy Update Magnitude: 0.61200
Value Function Update Magnitude: 0.65843

Collected Steps per Second: 22,992.84306
Overall Steps per Second: 10,874.02669

Timestep Collection Time: 2.17572
Timestep Consumption Time: 2.42478
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60050

Cumulative Model Updates: 55,244
Cumulative Timesteps: 460,748,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 460748160...
Checkpoint 460748160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,125.45317
Policy Entropy: 3.70986
Value Function Loss: 0.05693

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.64508
Value Function Update Magnitude: 0.64974

Collected Steps per Second: 21,800.94365
Overall Steps per Second: 10,644.87758

Timestep Collection Time: 2.29394
Timestep Consumption Time: 2.40410
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.69803

Cumulative Model Updates: 55,250
Cumulative Timesteps: 460,798,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,168.30966
Policy Entropy: 3.70280
Value Function Loss: 0.05656

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.62795
Value Function Update Magnitude: 0.72072

Collected Steps per Second: 22,357.52087
Overall Steps per Second: 10,897.20273

Timestep Collection Time: 2.23701
Timestep Consumption Time: 2.35261
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.58962

Cumulative Model Updates: 55,256
Cumulative Timesteps: 460,848,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 460848184...
Checkpoint 460848184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,453.60111
Policy Entropy: 3.70609
Value Function Loss: 0.05490

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.54404
Value Function Update Magnitude: 0.80598

Collected Steps per Second: 22,052.03411
Overall Steps per Second: 10,654.99954

Timestep Collection Time: 2.26791
Timestep Consumption Time: 2.42585
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69376

Cumulative Model Updates: 55,262
Cumulative Timesteps: 460,898,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,701.93623
Policy Entropy: 3.71364
Value Function Loss: 0.05474

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.45326
Value Function Update Magnitude: 0.81627

Collected Steps per Second: 22,597.64486
Overall Steps per Second: 10,960.07092

Timestep Collection Time: 2.21342
Timestep Consumption Time: 2.35024
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.56366

Cumulative Model Updates: 55,268
Cumulative Timesteps: 460,948,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 460948214...
Checkpoint 460948214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,624.77190
Policy Entropy: 3.73110
Value Function Loss: 0.05337

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.44296
Value Function Update Magnitude: 0.76573

Collected Steps per Second: 21,910.71548
Overall Steps per Second: 10,592.92694

Timestep Collection Time: 2.28318
Timestep Consumption Time: 2.43941
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.72259

Cumulative Model Updates: 55,274
Cumulative Timesteps: 460,998,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,962.01338
Policy Entropy: 3.74195
Value Function Loss: 0.05062

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.42503
Value Function Update Magnitude: 0.80073

Collected Steps per Second: 22,261.44341
Overall Steps per Second: 10,858.02732

Timestep Collection Time: 2.24657
Timestep Consumption Time: 2.35942
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.60599

Cumulative Model Updates: 55,280
Cumulative Timesteps: 461,048,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 461048252...
Checkpoint 461048252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,713.49888
Policy Entropy: 3.74920
Value Function Loss: 0.04624

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.45622
Value Function Update Magnitude: 0.82969

Collected Steps per Second: 21,880.32962
Overall Steps per Second: 10,663.76512

Timestep Collection Time: 2.28616
Timestep Consumption Time: 2.40468
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.69084

Cumulative Model Updates: 55,286
Cumulative Timesteps: 461,098,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,051.22977
Policy Entropy: 3.75621
Value Function Loss: 0.04417

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.49105
Value Function Update Magnitude: 0.83632

Collected Steps per Second: 22,942.68219
Overall Steps per Second: 10,883.47890

Timestep Collection Time: 2.18048
Timestep Consumption Time: 2.41603
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.59651

Cumulative Model Updates: 55,292
Cumulative Timesteps: 461,148,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 461148300...
Checkpoint 461148300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.05610
Policy Entropy: 3.76369
Value Function Loss: 0.04296

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.52894
Value Function Update Magnitude: 0.81533

Collected Steps per Second: 22,265.52198
Overall Steps per Second: 10,763.28253

Timestep Collection Time: 2.24733
Timestep Consumption Time: 2.40162
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.64895

Cumulative Model Updates: 55,298
Cumulative Timesteps: 461,198,338

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,872.26217
Policy Entropy: 3.75900
Value Function Loss: 0.04329

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.53638
Value Function Update Magnitude: 0.82430

Collected Steps per Second: 22,972.93815
Overall Steps per Second: 10,897.68640

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.41233
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58941

Cumulative Model Updates: 55,304
Cumulative Timesteps: 461,248,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 461248352...
Checkpoint 461248352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,646.76494
Policy Entropy: 3.75043
Value Function Loss: 0.04509

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.57872
Value Function Update Magnitude: 0.81932

Collected Steps per Second: 22,420.40679
Overall Steps per Second: 10,603.04697

Timestep Collection Time: 2.23038
Timestep Consumption Time: 2.48581
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.71619

Cumulative Model Updates: 55,310
Cumulative Timesteps: 461,298,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,666.52140
Policy Entropy: 3.76178
Value Function Loss: 0.04425

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.55063
Value Function Update Magnitude: 0.82341

Collected Steps per Second: 22,942.74671
Overall Steps per Second: 10,899.00776

Timestep Collection Time: 2.18004
Timestep Consumption Time: 2.40901
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.58904

Cumulative Model Updates: 55,316
Cumulative Timesteps: 461,348,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 461348374...
Checkpoint 461348374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,701.74604
Policy Entropy: 3.75353
Value Function Loss: 0.04326

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.51992
Value Function Update Magnitude: 0.81548

Collected Steps per Second: 22,439.99167
Overall Steps per Second: 10,669.01573

Timestep Collection Time: 2.22843
Timestep Consumption Time: 2.45860
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.68703

Cumulative Model Updates: 55,322
Cumulative Timesteps: 461,398,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,908.03409
Policy Entropy: 3.75617
Value Function Loss: 0.04412

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06056
Policy Update Magnitude: 0.56695
Value Function Update Magnitude: 0.81228

Collected Steps per Second: 22,717.18010
Overall Steps per Second: 10,607.42665

Timestep Collection Time: 2.20098
Timestep Consumption Time: 2.51270
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.71368

Cumulative Model Updates: 55,328
Cumulative Timesteps: 461,448,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 461448380...
Checkpoint 461448380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,381.43319
Policy Entropy: 3.74911
Value Function Loss: 0.04463

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.59696
Value Function Update Magnitude: 0.80494

Collected Steps per Second: 22,630.19170
Overall Steps per Second: 10,653.58262

Timestep Collection Time: 2.21006
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.69457

Cumulative Model Updates: 55,334
Cumulative Timesteps: 461,498,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,006.38744
Policy Entropy: 3.75052
Value Function Loss: 0.04478

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.78398

Collected Steps per Second: 23,322.26832
Overall Steps per Second: 10,726.65193

Timestep Collection Time: 2.14387
Timestep Consumption Time: 2.51741
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.66129

Cumulative Model Updates: 55,340
Cumulative Timesteps: 461,548,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 461548394...
Checkpoint 461548394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,748.95698
Policy Entropy: 3.75358
Value Function Loss: 0.04564

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.50591
Value Function Update Magnitude: 0.76340

Collected Steps per Second: 22,366.43876
Overall Steps per Second: 10,592.95084

Timestep Collection Time: 2.23764
Timestep Consumption Time: 2.48701
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.72465

Cumulative Model Updates: 55,346
Cumulative Timesteps: 461,598,442

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,854.87534
Policy Entropy: 3.75130
Value Function Loss: 0.04659

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07998
Policy Update Magnitude: 0.51274
Value Function Update Magnitude: 0.77749

Collected Steps per Second: 22,989.44405
Overall Steps per Second: 10,941.43267

Timestep Collection Time: 2.17561
Timestep Consumption Time: 2.39564
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.57125

Cumulative Model Updates: 55,352
Cumulative Timesteps: 461,648,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 461648458...
Checkpoint 461648458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,800.96031
Policy Entropy: 3.74746
Value Function Loss: 0.04851

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.59030
Value Function Update Magnitude: 0.78350

Collected Steps per Second: 22,684.76240
Overall Steps per Second: 10,625.06132

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.50233
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70698

Cumulative Model Updates: 55,358
Cumulative Timesteps: 461,698,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,670.74739
Policy Entropy: 3.74292
Value Function Loss: 0.05026

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.60585
Value Function Update Magnitude: 0.77644

Collected Steps per Second: 22,847.35387
Overall Steps per Second: 10,821.10143

Timestep Collection Time: 2.18905
Timestep Consumption Time: 2.43285
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62190

Cumulative Model Updates: 55,364
Cumulative Timesteps: 461,748,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 461748484...
Checkpoint 461748484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,836.62765
Policy Entropy: 3.74506
Value Function Loss: 0.05132

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.53282
Value Function Update Magnitude: 0.79537

Collected Steps per Second: 22,477.94521
Overall Steps per Second: 10,715.40459

Timestep Collection Time: 2.22556
Timestep Consumption Time: 2.44305
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.66861

Cumulative Model Updates: 55,370
Cumulative Timesteps: 461,798,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,296.84762
Policy Entropy: 3.76410
Value Function Loss: 0.04870

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.15903
Policy Update Magnitude: 0.46991
Value Function Update Magnitude: 0.81318

Collected Steps per Second: 22,982.33504
Overall Steps per Second: 10,856.37736

Timestep Collection Time: 2.17602
Timestep Consumption Time: 2.43049
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60651

Cumulative Model Updates: 55,376
Cumulative Timesteps: 461,848,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 461848520...
Checkpoint 461848520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,329.20901
Policy Entropy: 3.78079
Value Function Loss: 0.04731

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.53759
Value Function Update Magnitude: 0.80397

Collected Steps per Second: 22,654.02095
Overall Steps per Second: 10,733.10360

Timestep Collection Time: 2.20711
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.65848

Cumulative Model Updates: 55,382
Cumulative Timesteps: 461,898,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,751.68636
Policy Entropy: 3.78835
Value Function Loss: 0.04606

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.64131
Value Function Update Magnitude: 0.80128

Collected Steps per Second: 23,149.79149
Overall Steps per Second: 10,924.61364

Timestep Collection Time: 2.16080
Timestep Consumption Time: 2.41804
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.57883

Cumulative Model Updates: 55,388
Cumulative Timesteps: 461,948,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 461948542...
Checkpoint 461948542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,497.57881
Policy Entropy: 3.79367
Value Function Loss: 0.04435

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.66665
Value Function Update Magnitude: 0.79658

Collected Steps per Second: 22,676.69914
Overall Steps per Second: 10,595.48278

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.51519
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.72107

Cumulative Model Updates: 55,394
Cumulative Timesteps: 461,998,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,567.35369
Policy Entropy: 3.80709
Value Function Loss: 0.04210

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.66996
Value Function Update Magnitude: 0.79015

Collected Steps per Second: 22,760.22540
Overall Steps per Second: 10,670.80113

Timestep Collection Time: 2.19681
Timestep Consumption Time: 2.48887
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.68568

Cumulative Model Updates: 55,400
Cumulative Timesteps: 462,048,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 462048564...
Checkpoint 462048564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,578.80485
Policy Entropy: 3.80440
Value Function Loss: 0.04534

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06226
Policy Update Magnitude: 0.67951
Value Function Update Magnitude: 0.75685

Collected Steps per Second: 22,565.72460
Overall Steps per Second: 10,654.59796

Timestep Collection Time: 2.21690
Timestep Consumption Time: 2.47835
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.69525

Cumulative Model Updates: 55,406
Cumulative Timesteps: 462,098,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,797.50433
Policy Entropy: 3.78678
Value Function Loss: 0.04741

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06489
Policy Update Magnitude: 0.69069
Value Function Update Magnitude: 0.74902

Collected Steps per Second: 22,927.04299
Overall Steps per Second: 10,718.83753

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.48495
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.66674

Cumulative Model Updates: 55,412
Cumulative Timesteps: 462,148,612

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 462148612...
Checkpoint 462148612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,466.50681
Policy Entropy: 3.77258
Value Function Loss: 0.05054

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06861
Policy Update Magnitude: 0.67453
Value Function Update Magnitude: 0.67392

Collected Steps per Second: 22,653.37125
Overall Steps per Second: 10,592.62024

Timestep Collection Time: 2.20718
Timestep Consumption Time: 2.51309
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.72027

Cumulative Model Updates: 55,418
Cumulative Timesteps: 462,198,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,965.03302
Policy Entropy: 3.76631
Value Function Loss: 0.05096

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.64711
Value Function Update Magnitude: 0.70900

Collected Steps per Second: 22,633.63303
Overall Steps per Second: 10,629.89559

Timestep Collection Time: 2.20990
Timestep Consumption Time: 2.49551
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.70541

Cumulative Model Updates: 55,424
Cumulative Timesteps: 462,248,630

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 462248630...
Checkpoint 462248630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,728.26565
Policy Entropy: 3.75815
Value Function Loss: 0.05053

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07212
Policy Update Magnitude: 0.64712
Value Function Update Magnitude: 0.75684

Collected Steps per Second: 22,715.16693
Overall Steps per Second: 10,683.95309

Timestep Collection Time: 2.20161
Timestep Consumption Time: 2.47924
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.68085

Cumulative Model Updates: 55,430
Cumulative Timesteps: 462,298,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,242.77684
Policy Entropy: 3.74561
Value Function Loss: 0.05204

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.65669
Value Function Update Magnitude: 0.71214

Collected Steps per Second: 23,172.54631
Overall Steps per Second: 10,740.50584

Timestep Collection Time: 2.15911
Timestep Consumption Time: 2.49915
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.65825

Cumulative Model Updates: 55,436
Cumulative Timesteps: 462,348,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 462348672...
Checkpoint 462348672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,992.40247
Policy Entropy: 3.74973
Value Function Loss: 0.05246

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.65139
Value Function Update Magnitude: 0.65296

Collected Steps per Second: 22,651.07575
Overall Steps per Second: 10,617.57809

Timestep Collection Time: 2.20917
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.71294

Cumulative Model Updates: 55,442
Cumulative Timesteps: 462,398,712

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,049.03483
Policy Entropy: 3.74385
Value Function Loss: 0.05400

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07339
Policy Update Magnitude: 0.65610
Value Function Update Magnitude: 0.65127

Collected Steps per Second: 22,789.62237
Overall Steps per Second: 10,800.48436

Timestep Collection Time: 2.19477
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.63109

Cumulative Model Updates: 55,448
Cumulative Timesteps: 462,448,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 462448730...
Checkpoint 462448730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,392.43344
Policy Entropy: 3.75389
Value Function Loss: 0.05263

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.66446
Value Function Update Magnitude: 0.66273

Collected Steps per Second: 22,755.57516
Overall Steps per Second: 10,736.38354

Timestep Collection Time: 2.19849
Timestep Consumption Time: 2.46118
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.65967

Cumulative Model Updates: 55,454
Cumulative Timesteps: 462,498,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,509.38420
Policy Entropy: 3.75998
Value Function Loss: 0.05385

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06260
Policy Update Magnitude: 0.68388
Value Function Update Magnitude: 0.68623

Collected Steps per Second: 23,169.29533
Overall Steps per Second: 10,878.79416

Timestep Collection Time: 2.15837
Timestep Consumption Time: 2.43846
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.59683

Cumulative Model Updates: 55,460
Cumulative Timesteps: 462,548,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 462548766...
Checkpoint 462548766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,068.75365
Policy Entropy: 3.75697
Value Function Loss: 0.05337

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.65681
Value Function Update Magnitude: 0.70449

Collected Steps per Second: 22,521.52885
Overall Steps per Second: 10,653.73912

Timestep Collection Time: 2.22125
Timestep Consumption Time: 2.47438
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.69563

Cumulative Model Updates: 55,466
Cumulative Timesteps: 462,598,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,440.49502
Policy Entropy: 3.73677
Value Function Loss: 0.05447

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.60038
Value Function Update Magnitude: 0.75630

Collected Steps per Second: 22,832.46996
Overall Steps per Second: 10,833.96435

Timestep Collection Time: 2.19188
Timestep Consumption Time: 2.42748
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61936

Cumulative Model Updates: 55,472
Cumulative Timesteps: 462,648,838

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 462648838...
Checkpoint 462648838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,897.20699
Policy Entropy: 3.74224
Value Function Loss: 0.05262

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10970
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.81043

Collected Steps per Second: 22,446.69214
Overall Steps per Second: 10,767.97875

Timestep Collection Time: 2.22830
Timestep Consumption Time: 2.41677
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.64507

Cumulative Model Updates: 55,478
Cumulative Timesteps: 462,698,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,194.97670
Policy Entropy: 3.74667
Value Function Loss: 0.05127

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.52937
Value Function Update Magnitude: 0.81974

Collected Steps per Second: 23,072.28631
Overall Steps per Second: 10,902.69815

Timestep Collection Time: 2.16762
Timestep Consumption Time: 2.41950
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.58712

Cumulative Model Updates: 55,484
Cumulative Timesteps: 462,748,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 462748868...
Checkpoint 462748868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,698.68154
Policy Entropy: 3.76795
Value Function Loss: 0.04999

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.53035
Value Function Update Magnitude: 0.82367

Collected Steps per Second: 22,394.20972
Overall Steps per Second: 10,617.04107

Timestep Collection Time: 2.23370
Timestep Consumption Time: 2.47778
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.71148

Cumulative Model Updates: 55,490
Cumulative Timesteps: 462,798,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,216.85107
Policy Entropy: 3.75420
Value Function Loss: 0.05067

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.48709
Value Function Update Magnitude: 0.82717

Collected Steps per Second: 22,939.26785
Overall Steps per Second: 10,835.40242

Timestep Collection Time: 2.18045
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61616

Cumulative Model Updates: 55,496
Cumulative Timesteps: 462,848,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 462848908...
Checkpoint 462848908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,337.64035
Policy Entropy: 3.74455
Value Function Loss: 0.05323

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.49840
Value Function Update Magnitude: 0.83769

Collected Steps per Second: 22,442.12832
Overall Steps per Second: 10,758.91564

Timestep Collection Time: 2.22902
Timestep Consumption Time: 2.42052
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.64954

Cumulative Model Updates: 55,502
Cumulative Timesteps: 462,898,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,890.85665
Policy Entropy: 3.73222
Value Function Loss: 0.05268

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.49024
Value Function Update Magnitude: 0.83455

Collected Steps per Second: 23,022.07984
Overall Steps per Second: 10,827.79358

Timestep Collection Time: 2.17313
Timestep Consumption Time: 2.44739
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.62052

Cumulative Model Updates: 55,508
Cumulative Timesteps: 462,948,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 462948962...
Checkpoint 462948962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,686.34745
Policy Entropy: 3.72960
Value Function Loss: 0.05335

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.50691
Value Function Update Magnitude: 0.79127

Collected Steps per Second: 22,619.59998
Overall Steps per Second: 10,680.52046

Timestep Collection Time: 2.21171
Timestep Consumption Time: 2.47233
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.68404

Cumulative Model Updates: 55,514
Cumulative Timesteps: 462,998,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,507.53240
Policy Entropy: 3.73067
Value Function Loss: 0.05398

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.51995
Value Function Update Magnitude: 0.69057

Collected Steps per Second: 22,787.92267
Overall Steps per Second: 10,808.62326

Timestep Collection Time: 2.19520
Timestep Consumption Time: 2.43296
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62816

Cumulative Model Updates: 55,520
Cumulative Timesteps: 463,049,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 463049014...
Checkpoint 463049014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,849.61558
Policy Entropy: 3.71939
Value Function Loss: 0.05644

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.58473
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 22,395.54002
Overall Steps per Second: 10,700.82234

Timestep Collection Time: 2.23312
Timestep Consumption Time: 2.44054
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.67366

Cumulative Model Updates: 55,526
Cumulative Timesteps: 463,099,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,448.32002
Policy Entropy: 3.73343
Value Function Loss: 0.05524

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.49562
Value Function Update Magnitude: 0.61526

Collected Steps per Second: 23,047.69667
Overall Steps per Second: 10,873.08664

Timestep Collection Time: 2.17046
Timestep Consumption Time: 2.43026
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.60072

Cumulative Model Updates: 55,532
Cumulative Timesteps: 463,149,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 463149050...
Checkpoint 463149050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,684.52634
Policy Entropy: 3.73302
Value Function Loss: 0.05666

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.45696
Value Function Update Magnitude: 0.63709

Collected Steps per Second: 22,552.11540
Overall Steps per Second: 10,700.25305

Timestep Collection Time: 2.21718
Timestep Consumption Time: 2.45580
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.67297

Cumulative Model Updates: 55,538
Cumulative Timesteps: 463,199,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,997.56247
Policy Entropy: 3.72130
Value Function Loss: 0.05635

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.46357
Value Function Update Magnitude: 0.65502

Collected Steps per Second: 22,813.36281
Overall Steps per Second: 10,815.06086

Timestep Collection Time: 2.19205
Timestep Consumption Time: 2.43187
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.62392

Cumulative Model Updates: 55,544
Cumulative Timesteps: 463,249,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 463249060...
Checkpoint 463249060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.07197
Policy Entropy: 3.70505
Value Function Loss: 0.05731

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.48676
Value Function Update Magnitude: 0.68990

Collected Steps per Second: 22,590.31962
Overall Steps per Second: 10,742.62272

Timestep Collection Time: 2.21431
Timestep Consumption Time: 2.44209
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.65640

Cumulative Model Updates: 55,550
Cumulative Timesteps: 463,299,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,836.51866
Policy Entropy: 3.70812
Value Function Loss: 0.05484

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.54792
Value Function Update Magnitude: 0.65685

Collected Steps per Second: 22,947.82906
Overall Steps per Second: 10,855.10699

Timestep Collection Time: 2.18103
Timestep Consumption Time: 2.42970
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61073

Cumulative Model Updates: 55,556
Cumulative Timesteps: 463,349,132

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 463349132...
Checkpoint 463349132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,527.82945
Policy Entropy: 3.71106
Value Function Loss: 0.05561

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.52451
Value Function Update Magnitude: 0.67004

Collected Steps per Second: 22,490.98241
Overall Steps per Second: 10,687.99137

Timestep Collection Time: 2.22418
Timestep Consumption Time: 2.45621
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.68039

Cumulative Model Updates: 55,562
Cumulative Timesteps: 463,399,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,990.02665
Policy Entropy: 3.70862
Value Function Loss: 0.05456

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.50749
Value Function Update Magnitude: 0.70043

Collected Steps per Second: 23,055.33049
Overall Steps per Second: 10,865.43689

Timestep Collection Time: 2.16948
Timestep Consumption Time: 2.43393
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60340

Cumulative Model Updates: 55,568
Cumulative Timesteps: 463,449,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 463449174...
Checkpoint 463449174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,622.05020
Policy Entropy: 3.70261
Value Function Loss: 0.05623

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08760
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.66516

Collected Steps per Second: 22,453.41852
Overall Steps per Second: 10,683.17412

Timestep Collection Time: 2.22719
Timestep Consumption Time: 2.45382
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.68101

Cumulative Model Updates: 55,574
Cumulative Timesteps: 463,499,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,858.02955
Policy Entropy: 3.72567
Value Function Loss: 0.05354

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.52980
Value Function Update Magnitude: 0.63747

Collected Steps per Second: 22,928.96408
Overall Steps per Second: 10,868.55371

Timestep Collection Time: 2.18161
Timestep Consumption Time: 2.42084
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60245

Cumulative Model Updates: 55,580
Cumulative Timesteps: 463,549,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 463549204...
Checkpoint 463549204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,157.80093
Policy Entropy: 3.72861
Value Function Loss: 0.05417

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.52936
Value Function Update Magnitude: 0.61363

Collected Steps per Second: 22,520.81420
Overall Steps per Second: 10,692.65470

Timestep Collection Time: 2.22150
Timestep Consumption Time: 2.45741
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.67891

Cumulative Model Updates: 55,586
Cumulative Timesteps: 463,599,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,690.38111
Policy Entropy: 3.73141
Value Function Loss: 0.05404

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.50765
Value Function Update Magnitude: 0.67906

Collected Steps per Second: 22,969.50693
Overall Steps per Second: 10,835.30569

Timestep Collection Time: 2.17715
Timestep Consumption Time: 2.43814
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61528

Cumulative Model Updates: 55,592
Cumulative Timesteps: 463,649,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 463649242...
Checkpoint 463649242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,511.80135
Policy Entropy: 3.71711
Value Function Loss: 0.05500

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.50956
Value Function Update Magnitude: 0.73679

Collected Steps per Second: 22,626.56361
Overall Steps per Second: 10,674.80873

Timestep Collection Time: 2.21015
Timestep Consumption Time: 2.47453
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.68467

Cumulative Model Updates: 55,598
Cumulative Timesteps: 463,699,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,830.47807
Policy Entropy: 3.71071
Value Function Loss: 0.05424

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.49430
Value Function Update Magnitude: 0.72518

Collected Steps per Second: 22,685.20676
Overall Steps per Second: 10,644.12632

Timestep Collection Time: 2.20417
Timestep Consumption Time: 2.49345
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.69761

Cumulative Model Updates: 55,604
Cumulative Timesteps: 463,749,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 463749252...
Checkpoint 463749252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,125.12606
Policy Entropy: 3.73136
Value Function Loss: 0.05177

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.51277
Value Function Update Magnitude: 0.76468

Collected Steps per Second: 22,649.41141
Overall Steps per Second: 10,815.61857

Timestep Collection Time: 2.20809
Timestep Consumption Time: 2.41596
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.62405

Cumulative Model Updates: 55,610
Cumulative Timesteps: 463,799,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,365.78573
Policy Entropy: 3.72348
Value Function Loss: 0.05090

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.60714
Value Function Update Magnitude: 0.77013

Collected Steps per Second: 23,062.94710
Overall Steps per Second: 10,721.72724

Timestep Collection Time: 2.16911
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.66585

Cumulative Model Updates: 55,616
Cumulative Timesteps: 463,849,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 463849290...
Checkpoint 463849290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,210.56364
Policy Entropy: 3.71280
Value Function Loss: 0.05135

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.76077

Collected Steps per Second: 22,410.94180
Overall Steps per Second: 10,581.59257

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.49473
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.72632

Cumulative Model Updates: 55,622
Cumulative Timesteps: 463,899,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,214.01428
Policy Entropy: 3.70394
Value Function Loss: 0.05151

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.51317
Value Function Update Magnitude: 0.78419

Collected Steps per Second: 23,056.83164
Overall Steps per Second: 10,785.80450

Timestep Collection Time: 2.16881
Timestep Consumption Time: 2.46746
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.63628

Cumulative Model Updates: 55,628
Cumulative Timesteps: 463,949,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 463949308...
Checkpoint 463949308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,397.34430
Policy Entropy: 3.71958
Value Function Loss: 0.05090

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.49576
Value Function Update Magnitude: 0.80203

Collected Steps per Second: 22,699.79227
Overall Steps per Second: 10,612.77702

Timestep Collection Time: 2.20363
Timestep Consumption Time: 2.50974
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.71338

Cumulative Model Updates: 55,634
Cumulative Timesteps: 463,999,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,147.20926
Policy Entropy: 3.72220
Value Function Loss: 0.05099

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.52442
Value Function Update Magnitude: 0.79883

Collected Steps per Second: 22,700.98835
Overall Steps per Second: 10,700.27810

Timestep Collection Time: 2.20378
Timestep Consumption Time: 2.47161
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.67539

Cumulative Model Updates: 55,640
Cumulative Timesteps: 464,049,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 464049358...
Checkpoint 464049358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.82931
Policy Entropy: 3.73334
Value Function Loss: 0.05147

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.52960
Value Function Update Magnitude: 0.77944

Collected Steps per Second: 22,503.70271
Overall Steps per Second: 10,797.34771

Timestep Collection Time: 2.22283
Timestep Consumption Time: 2.40997
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.63280

Cumulative Model Updates: 55,646
Cumulative Timesteps: 464,099,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,413.59724
Policy Entropy: 3.73437
Value Function Loss: 0.05187

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.50119
Value Function Update Magnitude: 0.77887

Collected Steps per Second: 22,941.30107
Overall Steps per Second: 10,720.04100

Timestep Collection Time: 2.17965
Timestep Consumption Time: 2.48488
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.66453

Cumulative Model Updates: 55,652
Cumulative Timesteps: 464,149,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 464149384...
Checkpoint 464149384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,119.44503
Policy Entropy: 3.73660
Value Function Loss: 0.05116

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.50139
Value Function Update Magnitude: 0.78552

Collected Steps per Second: 22,784.35618
Overall Steps per Second: 10,841.05980

Timestep Collection Time: 2.19563
Timestep Consumption Time: 2.41886
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61449

Cumulative Model Updates: 55,658
Cumulative Timesteps: 464,199,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,715.80884
Policy Entropy: 3.74179
Value Function Loss: 0.05110

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.14766
Policy Update Magnitude: 0.43433
Value Function Update Magnitude: 0.78919

Collected Steps per Second: 22,659.55442
Overall Steps per Second: 10,651.36827

Timestep Collection Time: 2.20710
Timestep Consumption Time: 2.48825
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.69536

Cumulative Model Updates: 55,664
Cumulative Timesteps: 464,249,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 464249422...
Checkpoint 464249422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,714.97208
Policy Entropy: 3.73598
Value Function Loss: 0.05092

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.47456
Value Function Update Magnitude: 0.75782

Collected Steps per Second: 22,505.32199
Overall Steps per Second: 10,604.70002

Timestep Collection Time: 2.22285
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.71734

Cumulative Model Updates: 55,670
Cumulative Timesteps: 464,299,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,662.61246
Policy Entropy: 3.74557
Value Function Loss: 0.05164

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.53229
Value Function Update Magnitude: 0.61924

Collected Steps per Second: 23,344.40032
Overall Steps per Second: 10,789.71142

Timestep Collection Time: 2.14304
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.63664

Cumulative Model Updates: 55,676
Cumulative Timesteps: 464,349,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 464349476...
Checkpoint 464349476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,344.38171
Policy Entropy: 3.74346
Value Function Loss: 0.05249

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.64288

Collected Steps per Second: 22,340.91809
Overall Steps per Second: 10,610.43175

Timestep Collection Time: 2.23930
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.71498

Cumulative Model Updates: 55,682
Cumulative Timesteps: 464,399,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,561.00555
Policy Entropy: 3.74999
Value Function Loss: 0.05192

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07085
Policy Update Magnitude: 0.62944
Value Function Update Magnitude: 0.65338

Collected Steps per Second: 22,875.77141
Overall Steps per Second: 10,845.37201

Timestep Collection Time: 2.18651
Timestep Consumption Time: 2.42542
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.61192

Cumulative Model Updates: 55,688
Cumulative Timesteps: 464,449,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 464449522...
Checkpoint 464449522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,687.19295
Policy Entropy: 3.74762
Value Function Loss: 0.05303

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.61813
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 22,517.84302
Overall Steps per Second: 10,720.86945

Timestep Collection Time: 2.22073
Timestep Consumption Time: 2.44363
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.66436

Cumulative Model Updates: 55,694
Cumulative Timesteps: 464,499,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,538.72353
Policy Entropy: 3.75401
Value Function Loss: 0.05227

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.53378
Value Function Update Magnitude: 0.53720

Collected Steps per Second: 22,986.82573
Overall Steps per Second: 10,858.07164

Timestep Collection Time: 2.17568
Timestep Consumption Time: 2.43029
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.60597

Cumulative Model Updates: 55,700
Cumulative Timesteps: 464,549,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 464549540...
Checkpoint 464549540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,159.39286
Policy Entropy: 3.74301
Value Function Loss: 0.05284

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.50688
Value Function Update Magnitude: 0.49261

Collected Steps per Second: 22,224.20900
Overall Steps per Second: 10,658.10007

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.44215
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.69258

Cumulative Model Updates: 55,706
Cumulative Timesteps: 464,599,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,546.79426
Policy Entropy: 3.75161
Value Function Loss: 0.05172

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.50655
Value Function Update Magnitude: 0.52707

Collected Steps per Second: 22,657.33632
Overall Steps per Second: 10,638.30964

Timestep Collection Time: 2.20785
Timestep Consumption Time: 2.49440
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.70225

Cumulative Model Updates: 55,712
Cumulative Timesteps: 464,649,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 464649578...
Checkpoint 464649578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,459.57432
Policy Entropy: 3.75881
Value Function Loss: 0.05055

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.52254
Value Function Update Magnitude: 0.58151

Collected Steps per Second: 22,666.22442
Overall Steps per Second: 10,622.05035

Timestep Collection Time: 2.20690
Timestep Consumption Time: 2.50236
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.70926

Cumulative Model Updates: 55,718
Cumulative Timesteps: 464,699,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,257.59545
Policy Entropy: 3.76395
Value Function Loss: 0.04932

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.51199
Value Function Update Magnitude: 0.66603

Collected Steps per Second: 23,112.28311
Overall Steps per Second: 10,819.66328

Timestep Collection Time: 2.16352
Timestep Consumption Time: 2.45806
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.62159

Cumulative Model Updates: 55,724
Cumulative Timesteps: 464,749,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 464749604...
Checkpoint 464749604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,026.86300
Policy Entropy: 3.76536
Value Function Loss: 0.04825

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.51614
Value Function Update Magnitude: 0.72117

Collected Steps per Second: 22,704.04814
Overall Steps per Second: 10,622.39624

Timestep Collection Time: 2.20348
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.70967

Cumulative Model Updates: 55,730
Cumulative Timesteps: 464,799,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,386.45396
Policy Entropy: 3.75706
Value Function Loss: 0.04776

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.53179
Value Function Update Magnitude: 0.73081

Collected Steps per Second: 22,905.78014
Overall Steps per Second: 10,862.57044

Timestep Collection Time: 2.18382
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60499

Cumulative Model Updates: 55,736
Cumulative Timesteps: 464,849,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 464849654...
Checkpoint 464849654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,361.34480
Policy Entropy: 3.75577
Value Function Loss: 0.04740

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.55514
Value Function Update Magnitude: 0.74914

Collected Steps per Second: 22,356.38176
Overall Steps per Second: 10,769.58905

Timestep Collection Time: 2.23775
Timestep Consumption Time: 2.40755
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.64530

Cumulative Model Updates: 55,742
Cumulative Timesteps: 464,899,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,903.68384
Policy Entropy: 3.74718
Value Function Loss: 0.04870

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06423
Policy Update Magnitude: 0.62811
Value Function Update Magnitude: 0.77361

Collected Steps per Second: 23,203.06119
Overall Steps per Second: 10,815.25110

Timestep Collection Time: 2.15644
Timestep Consumption Time: 2.46999
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.62643

Cumulative Model Updates: 55,748
Cumulative Timesteps: 464,949,718

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 464949718...
Checkpoint 464949718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,091.38802
Policy Entropy: 3.75434
Value Function Loss: 0.04966

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06358
Policy Update Magnitude: 0.68338
Value Function Update Magnitude: 0.78311

Collected Steps per Second: 22,344.24806
Overall Steps per Second: 10,661.35445

Timestep Collection Time: 2.23816
Timestep Consumption Time: 2.45261
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.69077

Cumulative Model Updates: 55,754
Cumulative Timesteps: 464,999,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,877.15613
Policy Entropy: 3.75082
Value Function Loss: 0.05003

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06794
Policy Update Magnitude: 0.68270
Value Function Update Magnitude: 0.79723

Collected Steps per Second: 22,801.67375
Overall Steps per Second: 10,835.07261

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.61778

Cumulative Model Updates: 55,760
Cumulative Timesteps: 465,049,762

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 465049762...
Checkpoint 465049762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,951.26671
Policy Entropy: 3.75896
Value Function Loss: 0.05102

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05797
Policy Update Magnitude: 0.70713
Value Function Update Magnitude: 0.80242

Collected Steps per Second: 21,993.65747
Overall Steps per Second: 10,763.25967

Timestep Collection Time: 2.27420
Timestep Consumption Time: 2.37290
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.64711

Cumulative Model Updates: 55,766
Cumulative Timesteps: 465,099,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,362.70658
Policy Entropy: 3.74841
Value Function Loss: 0.05247

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.71634
Value Function Update Magnitude: 0.80401

Collected Steps per Second: 22,213.68469
Overall Steps per Second: 10,832.48142

Timestep Collection Time: 2.25150
Timestep Consumption Time: 2.36555
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.61704

Cumulative Model Updates: 55,772
Cumulative Timesteps: 465,149,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 465149794...
Checkpoint 465149794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.97416
Policy Entropy: 3.74458
Value Function Loss: 0.05270

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.61652
Value Function Update Magnitude: 0.81954

Collected Steps per Second: 22,004.70422
Overall Steps per Second: 10,711.14967

Timestep Collection Time: 2.27315
Timestep Consumption Time: 2.39675
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.66990

Cumulative Model Updates: 55,778
Cumulative Timesteps: 465,199,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,797.69561
Policy Entropy: 3.74692
Value Function Loss: 0.05304

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.56348
Value Function Update Magnitude: 0.81376

Collected Steps per Second: 22,083.92926
Overall Steps per Second: 10,836.30990

Timestep Collection Time: 2.26445
Timestep Consumption Time: 2.35040
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.61486

Cumulative Model Updates: 55,784
Cumulative Timesteps: 465,249,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 465249822...
Checkpoint 465249822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,080.96970
Policy Entropy: 3.73225
Value Function Loss: 0.05565

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.59609
Value Function Update Magnitude: 0.80619

Collected Steps per Second: 22,010.46062
Overall Steps per Second: 10,716.08676

Timestep Collection Time: 2.27283
Timestep Consumption Time: 2.39548
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.66831

Cumulative Model Updates: 55,790
Cumulative Timesteps: 465,299,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,922.87546
Policy Entropy: 3.73281
Value Function Loss: 0.05569

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.55809
Value Function Update Magnitude: 0.80941

Collected Steps per Second: 22,264.97916
Overall Steps per Second: 10,605.64702

Timestep Collection Time: 2.24676
Timestep Consumption Time: 2.46998
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.71673

Cumulative Model Updates: 55,796
Cumulative Timesteps: 465,349,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 465349872...
Checkpoint 465349872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,312.87251
Policy Entropy: 3.72677
Value Function Loss: 0.05488

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.54088
Value Function Update Magnitude: 0.72392

Collected Steps per Second: 22,726.91430
Overall Steps per Second: 10,858.09667

Timestep Collection Time: 2.20030
Timestep Consumption Time: 2.40511
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60541

Cumulative Model Updates: 55,802
Cumulative Timesteps: 465,399,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,001.46167
Policy Entropy: 3.73537
Value Function Loss: 0.05325

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.53214
Value Function Update Magnitude: 0.75462

Collected Steps per Second: 23,005.99704
Overall Steps per Second: 10,882.51131

Timestep Collection Time: 2.17395
Timestep Consumption Time: 2.42186
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.59581

Cumulative Model Updates: 55,808
Cumulative Timesteps: 465,449,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 465449892...
Checkpoint 465449892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,131.10172
Policy Entropy: 3.73291
Value Function Loss: 0.05118

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.52685
Value Function Update Magnitude: 0.79400

Collected Steps per Second: 22,684.47459
Overall Steps per Second: 10,742.92359

Timestep Collection Time: 2.20539
Timestep Consumption Time: 2.45145
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.65683

Cumulative Model Updates: 55,814
Cumulative Timesteps: 465,499,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,912.96078
Policy Entropy: 3.72577
Value Function Loss: 0.05235

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.57077
Value Function Update Magnitude: 0.79946

Collected Steps per Second: 23,090.04147
Overall Steps per Second: 10,952.98935

Timestep Collection Time: 2.16596
Timestep Consumption Time: 2.40010
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.56606

Cumulative Model Updates: 55,820
Cumulative Timesteps: 465,549,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 465549932...
Checkpoint 465549932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,986.95151
Policy Entropy: 3.72188
Value Function Loss: 0.05403

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.60560
Value Function Update Magnitude: 0.79360

Collected Steps per Second: 22,644.45481
Overall Steps per Second: 10,629.89636

Timestep Collection Time: 2.20928
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.70635

Cumulative Model Updates: 55,826
Cumulative Timesteps: 465,599,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,292.94726
Policy Entropy: 3.72460
Value Function Loss: 0.05578

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07523
Policy Update Magnitude: 0.66878
Value Function Update Magnitude: 0.77253

Collected Steps per Second: 22,941.10236
Overall Steps per Second: 10,834.33455

Timestep Collection Time: 2.17958
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61514

Cumulative Model Updates: 55,832
Cumulative Timesteps: 465,649,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 465649962...
Checkpoint 465649962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,156.53975
Policy Entropy: 3.72307
Value Function Loss: 0.05438

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.67463
Value Function Update Magnitude: 0.82172

Collected Steps per Second: 22,399.52567
Overall Steps per Second: 10,645.12787

Timestep Collection Time: 2.23237
Timestep Consumption Time: 2.46499
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.69736

Cumulative Model Updates: 55,838
Cumulative Timesteps: 465,699,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,502.25154
Policy Entropy: 3.72583
Value Function Loss: 0.05409

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07290
Policy Update Magnitude: 0.64804
Value Function Update Magnitude: 0.79910

Collected Steps per Second: 22,928.84653
Overall Steps per Second: 10,830.84877

Timestep Collection Time: 2.18101
Timestep Consumption Time: 2.43617
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61718

Cumulative Model Updates: 55,844
Cumulative Timesteps: 465,749,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 465749974...
Checkpoint 465749974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,525.08685
Policy Entropy: 3.72277
Value Function Loss: 0.05456

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.62015
Value Function Update Magnitude: 0.79227

Collected Steps per Second: 22,644.67243
Overall Steps per Second: 10,799.05422

Timestep Collection Time: 2.20855
Timestep Consumption Time: 2.42259
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.63115

Cumulative Model Updates: 55,850
Cumulative Timesteps: 465,799,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,320.40113
Policy Entropy: 3.73126
Value Function Loss: 0.05386

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.80103

Collected Steps per Second: 23,055.91664
Overall Steps per Second: 10,873.44934

Timestep Collection Time: 2.16933
Timestep Consumption Time: 2.43049
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.59983

Cumulative Model Updates: 55,856
Cumulative Timesteps: 465,850,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 465850002...
Checkpoint 465850002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,287.94047
Policy Entropy: 3.71680
Value Function Loss: 0.05675

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.53461
Value Function Update Magnitude: 0.76614

Collected Steps per Second: 22,454.83408
Overall Steps per Second: 10,604.83050

Timestep Collection Time: 2.22732
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.71615

Cumulative Model Updates: 55,862
Cumulative Timesteps: 465,900,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,644.36765
Policy Entropy: 3.72215
Value Function Loss: 0.05566

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07177
Policy Update Magnitude: 0.62434
Value Function Update Magnitude: 0.70227

Collected Steps per Second: 23,007.59506
Overall Steps per Second: 10,861.84936

Timestep Collection Time: 2.17441
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60585

Cumulative Model Updates: 55,868
Cumulative Timesteps: 465,950,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 465950044...
Checkpoint 465950044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,370.39826
Policy Entropy: 3.70319
Value Function Loss: 0.05918

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07618
Policy Update Magnitude: 0.68045
Value Function Update Magnitude: 0.64811

Collected Steps per Second: 22,334.75854
Overall Steps per Second: 10,710.87005

Timestep Collection Time: 2.24019
Timestep Consumption Time: 2.43114
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.67133

Cumulative Model Updates: 55,874
Cumulative Timesteps: 466,000,078

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,327.49870
Policy Entropy: 3.71416
Value Function Loss: 0.05832

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.66718
Value Function Update Magnitude: 0.60747

Collected Steps per Second: 22,744.17169
Overall Steps per Second: 10,809.71758

Timestep Collection Time: 2.19863
Timestep Consumption Time: 2.42739
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.62602

Cumulative Model Updates: 55,880
Cumulative Timesteps: 466,050,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 466050084...
Checkpoint 466050084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,355.68598
Policy Entropy: 3.72085
Value Function Loss: 0.05765

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.57639
Value Function Update Magnitude: 0.70168

Collected Steps per Second: 22,809.12009
Overall Steps per Second: 10,732.11191

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.46809
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.66134

Cumulative Model Updates: 55,886
Cumulative Timesteps: 466,100,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,791.42795
Policy Entropy: 3.73644
Value Function Loss: 0.05518

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.51489
Value Function Update Magnitude: 0.79250

Collected Steps per Second: 22,976.00085
Overall Steps per Second: 10,848.08606

Timestep Collection Time: 2.17662
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.61003

Cumulative Model Updates: 55,892
Cumulative Timesteps: 466,150,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 466150120...
Checkpoint 466150120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,447.81761
Policy Entropy: 3.74607
Value Function Loss: 0.05276

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.53954
Value Function Update Magnitude: 0.79905

Collected Steps per Second: 22,749.55767
Overall Steps per Second: 10,672.36975

Timestep Collection Time: 2.19828
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.68593

Cumulative Model Updates: 55,898
Cumulative Timesteps: 466,200,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,700.91621
Policy Entropy: 3.73800
Value Function Loss: 0.05280

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11708
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.72969

Collected Steps per Second: 23,320.78287
Overall Steps per Second: 10,911.97952

Timestep Collection Time: 2.14478
Timestep Consumption Time: 2.43899
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.58377

Cumulative Model Updates: 55,904
Cumulative Timesteps: 466,250,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 466250148...
Checkpoint 466250148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,833.34140
Policy Entropy: 3.73843
Value Function Loss: 0.05524

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.57012
Value Function Update Magnitude: 0.65501

Collected Steps per Second: 22,601.47281
Overall Steps per Second: 10,645.44280

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.48569
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.69891

Cumulative Model Updates: 55,910
Cumulative Timesteps: 466,300,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,217.34970
Policy Entropy: 3.73166
Value Function Loss: 0.05877

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.55029
Value Function Update Magnitude: 0.64457

Collected Steps per Second: 23,057.75414
Overall Steps per Second: 10,853.06902

Timestep Collection Time: 2.16934
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60883

Cumulative Model Updates: 55,916
Cumulative Timesteps: 466,350,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 466350190...
Checkpoint 466350190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,782.78136
Policy Entropy: 3.74422
Value Function Loss: 0.05940

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11024
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.67268

Collected Steps per Second: 22,615.67100
Overall Steps per Second: 10,649.40778

Timestep Collection Time: 2.21174
Timestep Consumption Time: 2.48523
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.69697

Cumulative Model Updates: 55,922
Cumulative Timesteps: 466,400,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,717.62506
Policy Entropy: 3.74548
Value Function Loss: 0.05650

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.75427

Collected Steps per Second: 22,995.87658
Overall Steps per Second: 10,893.26469

Timestep Collection Time: 2.17509
Timestep Consumption Time: 2.41656
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.59164

Cumulative Model Updates: 55,928
Cumulative Timesteps: 466,450,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 466450228...
Checkpoint 466450228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,047.47175
Policy Entropy: 3.75862
Value Function Loss: 0.05399

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.83803

Collected Steps per Second: 22,992.20552
Overall Steps per Second: 10,692.75343

Timestep Collection Time: 2.17535
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.67756

Cumulative Model Updates: 55,934
Cumulative Timesteps: 466,500,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,996.22327
Policy Entropy: 3.77192
Value Function Loss: 0.05320

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.56774
Value Function Update Magnitude: 0.86921

Collected Steps per Second: 23,196.94325
Overall Steps per Second: 10,882.36623

Timestep Collection Time: 2.15589
Timestep Consumption Time: 2.43962
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.59551

Cumulative Model Updates: 55,940
Cumulative Timesteps: 466,550,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 466550254...
Checkpoint 466550254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,416.50836
Policy Entropy: 3.77271
Value Function Loss: 0.05673

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.82331

Collected Steps per Second: 22,625.31758
Overall Steps per Second: 10,670.44111

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.47682
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.68753

Cumulative Model Updates: 55,946
Cumulative Timesteps: 466,600,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,995.80244
Policy Entropy: 3.78058
Value Function Loss: 0.05997

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.53962
Value Function Update Magnitude: 0.75124

Collected Steps per Second: 22,843.76972
Overall Steps per Second: 10,869.19637

Timestep Collection Time: 2.18878
Timestep Consumption Time: 2.41138
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60016

Cumulative Model Updates: 55,952
Cumulative Timesteps: 466,650,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 466650272...
Checkpoint 466650272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,191.06506
Policy Entropy: 3.78042
Value Function Loss: 0.05938

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.59232
Value Function Update Magnitude: 0.67045

Collected Steps per Second: 22,768.87093
Overall Steps per Second: 10,694.59661

Timestep Collection Time: 2.19721
Timestep Consumption Time: 2.48067
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.67788

Cumulative Model Updates: 55,958
Cumulative Timesteps: 466,700,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,645.15746
Policy Entropy: 3.77691
Value Function Loss: 0.05860

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.56924
Value Function Update Magnitude: 0.68413

Collected Steps per Second: 22,996.09317
Overall Steps per Second: 10,841.50730

Timestep Collection Time: 2.17480
Timestep Consumption Time: 2.43821
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61301

Cumulative Model Updates: 55,964
Cumulative Timesteps: 466,750,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 466750312...
Checkpoint 466750312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,787.32184
Policy Entropy: 3.76190
Value Function Loss: 0.05501

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.57678
Value Function Update Magnitude: 0.68090

Collected Steps per Second: 22,900.02645
Overall Steps per Second: 10,674.47295

Timestep Collection Time: 2.18367
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.68463

Cumulative Model Updates: 55,970
Cumulative Timesteps: 466,800,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,578.64461
Policy Entropy: 3.76089
Value Function Loss: 0.05167

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.55980
Value Function Update Magnitude: 0.69415

Collected Steps per Second: 22,822.44023
Overall Steps per Second: 10,686.67120

Timestep Collection Time: 2.19083
Timestep Consumption Time: 2.48790
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.67873

Cumulative Model Updates: 55,976
Cumulative Timesteps: 466,850,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 466850318...
Checkpoint 466850318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,144.83069
Policy Entropy: 3.77160
Value Function Loss: 0.04804

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.53677
Value Function Update Magnitude: 0.65682

Collected Steps per Second: 22,427.59829
Overall Steps per Second: 10,650.06742

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.46620
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.69631

Cumulative Model Updates: 55,982
Cumulative Timesteps: 466,900,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,959.25876
Policy Entropy: 3.77709
Value Function Loss: 0.05111

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.58465
Value Function Update Magnitude: 0.61846

Collected Steps per Second: 22,941.61941
Overall Steps per Second: 10,750.08041

Timestep Collection Time: 2.17945
Timestep Consumption Time: 2.47168
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.65113

Cumulative Model Updates: 55,988
Cumulative Timesteps: 466,950,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 466950334...
Checkpoint 466950334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,946.21145
Policy Entropy: 3.77692
Value Function Loss: 0.05461

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.63136
Value Function Update Magnitude: 0.62864

Collected Steps per Second: 22,591.16497
Overall Steps per Second: 10,619.01515

Timestep Collection Time: 2.21352
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.70910

Cumulative Model Updates: 55,994
Cumulative Timesteps: 467,000,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,739.00944
Policy Entropy: 3.76376
Value Function Loss: 0.05647

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.66816
Value Function Update Magnitude: 0.72174

Collected Steps per Second: 22,779.05884
Overall Steps per Second: 10,794.11669

Timestep Collection Time: 2.19561
Timestep Consumption Time: 2.43784
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.63345

Cumulative Model Updates: 56,000
Cumulative Timesteps: 467,050,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 467050354...
Checkpoint 467050354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,034.41747
Policy Entropy: 3.76477
Value Function Loss: 0.05454

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.64544
Value Function Update Magnitude: 0.77192

Collected Steps per Second: 22,666.17614
Overall Steps per Second: 10,699.40488

Timestep Collection Time: 2.20690
Timestep Consumption Time: 2.46831
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.67521

Cumulative Model Updates: 56,006
Cumulative Timesteps: 467,100,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,189.78269
Policy Entropy: 3.74820
Value Function Loss: 0.05484

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.66114
Value Function Update Magnitude: 0.68502

Collected Steps per Second: 22,900.76650
Overall Steps per Second: 10,814.94042

Timestep Collection Time: 2.18429
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.62527

Cumulative Model Updates: 56,012
Cumulative Timesteps: 467,150,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 467150398...
Checkpoint 467150398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,224.52095
Policy Entropy: 3.74154
Value Function Loss: 0.05675

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.67065
Value Function Update Magnitude: 0.62161

Collected Steps per Second: 22,766.29607
Overall Steps per Second: 10,720.39669

Timestep Collection Time: 2.19781
Timestep Consumption Time: 2.46955
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.66736

Cumulative Model Updates: 56,018
Cumulative Timesteps: 467,200,434

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,801.09548
Policy Entropy: 3.73336
Value Function Loss: 0.05869

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.66575
Value Function Update Magnitude: 0.64000

Collected Steps per Second: 23,054.94468
Overall Steps per Second: 10,878.31346

Timestep Collection Time: 2.17003
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.59906

Cumulative Model Updates: 56,024
Cumulative Timesteps: 467,250,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 467250464...
Checkpoint 467250464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,499.72085
Policy Entropy: 3.72696
Value Function Loss: 0.05970

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06880
Policy Update Magnitude: 0.69250
Value Function Update Magnitude: 0.75102

Collected Steps per Second: 22,520.92697
Overall Steps per Second: 10,683.15081

Timestep Collection Time: 2.22042
Timestep Consumption Time: 2.46041
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.68083

Cumulative Model Updates: 56,030
Cumulative Timesteps: 467,300,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,213.98751
Policy Entropy: 3.71539
Value Function Loss: 0.05872

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.67026
Value Function Update Magnitude: 0.79053

Collected Steps per Second: 23,020.94990
Overall Steps per Second: 10,844.48506

Timestep Collection Time: 2.17272
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.61230

Cumulative Model Updates: 56,036
Cumulative Timesteps: 467,350,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 467350488...
Checkpoint 467350488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,569.97847
Policy Entropy: 3.71752
Value Function Loss: 0.05714

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.62910
Value Function Update Magnitude: 0.80934

Collected Steps per Second: 22,386.16124
Overall Steps per Second: 10,718.63362

Timestep Collection Time: 2.23433
Timestep Consumption Time: 2.43213
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.66645

Cumulative Model Updates: 56,042
Cumulative Timesteps: 467,400,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,329.98840
Policy Entropy: 3.72105
Value Function Loss: 0.05598

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.63788
Value Function Update Magnitude: 0.83324

Collected Steps per Second: 22,945.09622
Overall Steps per Second: 10,837.52652

Timestep Collection Time: 2.17999
Timestep Consumption Time: 2.43546
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.61544

Cumulative Model Updates: 56,048
Cumulative Timesteps: 467,450,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 467450526...
Checkpoint 467450526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,733.51701
Policy Entropy: 3.73222
Value Function Loss: 0.05532

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.65754
Value Function Update Magnitude: 0.85256

Collected Steps per Second: 22,547.32075
Overall Steps per Second: 10,673.74209

Timestep Collection Time: 2.21845
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.68627

Cumulative Model Updates: 56,054
Cumulative Timesteps: 467,500,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,282.65749
Policy Entropy: 3.73507
Value Function Loss: 0.05715

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.60140
Value Function Update Magnitude: 0.87260

Collected Steps per Second: 22,944.15639
Overall Steps per Second: 10,839.86200

Timestep Collection Time: 2.18034
Timestep Consumption Time: 2.43467
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61500

Cumulative Model Updates: 56,060
Cumulative Timesteps: 467,550,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 467550572...
Checkpoint 467550572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,843.41206
Policy Entropy: 3.72998
Value Function Loss: 0.05761

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.15639
Policy Update Magnitude: 0.50769
Value Function Update Magnitude: 0.86588

Collected Steps per Second: 22,557.89909
Overall Steps per Second: 10,706.10902

Timestep Collection Time: 2.21758
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.67247

Cumulative Model Updates: 56,066
Cumulative Timesteps: 467,600,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,604.16679
Policy Entropy: 3.73308
Value Function Loss: 0.05607

Mean KL Divergence: 0.02230
SB3 Clip Fraction: 0.17532
Policy Update Magnitude: 0.48751
Value Function Update Magnitude: 0.86773

Collected Steps per Second: 23,081.49971
Overall Steps per Second: 10,922.53834

Timestep Collection Time: 2.16736
Timestep Consumption Time: 2.41271
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.58007

Cumulative Model Updates: 56,072
Cumulative Timesteps: 467,650,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 467650622...
Checkpoint 467650622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,707.38645
Policy Entropy: 3.74457
Value Function Loss: 0.05122

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.57313
Value Function Update Magnitude: 0.85175

Collected Steps per Second: 21,915.75366
Overall Steps per Second: 10,636.03272

Timestep Collection Time: 2.28292
Timestep Consumption Time: 2.42109
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.70401

Cumulative Model Updates: 56,078
Cumulative Timesteps: 467,700,654

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,591.65608
Policy Entropy: 3.76137
Value Function Loss: 0.04589

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.62708
Value Function Update Magnitude: 0.81633

Collected Steps per Second: 22,481.17535
Overall Steps per Second: 10,943.30516

Timestep Collection Time: 2.22506
Timestep Consumption Time: 2.34595
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.57101

Cumulative Model Updates: 56,084
Cumulative Timesteps: 467,750,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 467750676...
Checkpoint 467750676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,677.14872
Policy Entropy: 3.76831
Value Function Loss: 0.04419

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.61994
Value Function Update Magnitude: 0.79546

Collected Steps per Second: 22,160.73210
Overall Steps per Second: 10,647.09678

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.69630

Cumulative Model Updates: 56,090
Cumulative Timesteps: 467,800,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,880.98230
Policy Entropy: 3.76444
Value Function Loss: 0.04554

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06742
Policy Update Magnitude: 0.64105
Value Function Update Magnitude: 0.78316

Collected Steps per Second: 21,830.18522
Overall Steps per Second: 10,523.33398

Timestep Collection Time: 2.29105
Timestep Consumption Time: 2.46163
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.75268

Cumulative Model Updates: 56,096
Cumulative Timesteps: 467,850,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 467850692...
Checkpoint 467850692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,614.32339
Policy Entropy: 3.77031
Value Function Loss: 0.04854

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06687
Policy Update Magnitude: 0.62383
Value Function Update Magnitude: 0.77496

Collected Steps per Second: 22,268.76146
Overall Steps per Second: 10,900.67307

Timestep Collection Time: 2.24718
Timestep Consumption Time: 2.34354
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.59073

Cumulative Model Updates: 56,102
Cumulative Timesteps: 467,900,734

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,042.84209
Policy Entropy: 3.75999
Value Function Loss: 0.05244

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06894
Policy Update Magnitude: 0.64162
Value Function Update Magnitude: 0.78493

Collected Steps per Second: 22,255.57651
Overall Steps per Second: 10,585.59925

Timestep Collection Time: 2.24699
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.72415

Cumulative Model Updates: 56,108
Cumulative Timesteps: 467,950,742

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 467950742...
Checkpoint 467950742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,263.38544
Policy Entropy: 3.76356
Value Function Loss: 0.05400

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.62248
Value Function Update Magnitude: 0.82550

Collected Steps per Second: 22,337.68210
Overall Steps per Second: 10,576.91659

Timestep Collection Time: 2.23962
Timestep Consumption Time: 2.49030
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.72992

Cumulative Model Updates: 56,114
Cumulative Timesteps: 468,000,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,907.81676
Policy Entropy: 3.76016
Value Function Loss: 0.05492

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.53914
Value Function Update Magnitude: 0.82057

Collected Steps per Second: 22,934.05661
Overall Steps per Second: 10,894.58392

Timestep Collection Time: 2.18016
Timestep Consumption Time: 2.40927
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.58944

Cumulative Model Updates: 56,120
Cumulative Timesteps: 468,050,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 468050770...
Checkpoint 468050770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,581.32993
Policy Entropy: 3.75110
Value Function Loss: 0.05625

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.51658
Value Function Update Magnitude: 0.81534

Collected Steps per Second: 22,685.88236
Overall Steps per Second: 10,678.41661

Timestep Collection Time: 2.20445
Timestep Consumption Time: 2.47882
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.68328

Cumulative Model Updates: 56,126
Cumulative Timesteps: 468,100,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,350.83412
Policy Entropy: 3.74786
Value Function Loss: 0.05382

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.81869

Collected Steps per Second: 23,129.84716
Overall Steps per Second: 10,876.46105

Timestep Collection Time: 2.16240
Timestep Consumption Time: 2.43615
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.59855

Cumulative Model Updates: 56,132
Cumulative Timesteps: 468,150,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 468150796...
Checkpoint 468150796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,759.46435
Policy Entropy: 3.75039
Value Function Loss: 0.05159

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.15650
Policy Update Magnitude: 0.48947
Value Function Update Magnitude: 0.79931

Collected Steps per Second: 22,842.19031
Overall Steps per Second: 10,776.60087

Timestep Collection Time: 2.18963
Timestep Consumption Time: 2.45153
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.64117

Cumulative Model Updates: 56,138
Cumulative Timesteps: 468,200,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,440.43936
Policy Entropy: 3.77307
Value Function Loss: 0.04980

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.48655
Value Function Update Magnitude: 0.70842

Collected Steps per Second: 22,572.83478
Overall Steps per Second: 10,751.58164

Timestep Collection Time: 2.21612
Timestep Consumption Time: 2.43660
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.65271

Cumulative Model Updates: 56,144
Cumulative Timesteps: 468,250,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 468250836...
Checkpoint 468250836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,425.00198
Policy Entropy: 3.77437
Value Function Loss: 0.04765

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.52418
Value Function Update Magnitude: 0.72321

Collected Steps per Second: 22,690.86451
Overall Steps per Second: 10,674.65091

Timestep Collection Time: 2.20424
Timestep Consumption Time: 2.48126
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.68549

Cumulative Model Updates: 56,150
Cumulative Timesteps: 468,300,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640.70819
Policy Entropy: 3.76960
Value Function Loss: 0.04796

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.53681
Value Function Update Magnitude: 0.76462

Collected Steps per Second: 22,603.47295
Overall Steps per Second: 10,639.28336

Timestep Collection Time: 2.21231
Timestep Consumption Time: 2.48781
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.70013

Cumulative Model Updates: 56,156
Cumulative Timesteps: 468,350,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 468350858...
Checkpoint 468350858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,124.28723
Policy Entropy: 3.76400
Value Function Loss: 0.04857

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.51722
Value Function Update Magnitude: 0.81443

Collected Steps per Second: 22,724.91751
Overall Steps per Second: 10,791.76356

Timestep Collection Time: 2.20111
Timestep Consumption Time: 2.43391
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.63502

Cumulative Model Updates: 56,162
Cumulative Timesteps: 468,400,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,054.17667
Policy Entropy: 3.76343
Value Function Loss: 0.04982

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.50574
Value Function Update Magnitude: 0.81971

Collected Steps per Second: 22,710.46504
Overall Steps per Second: 10,622.20949

Timestep Collection Time: 2.20286
Timestep Consumption Time: 2.50689
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.70975

Cumulative Model Updates: 56,168
Cumulative Timesteps: 468,450,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 468450906...
Checkpoint 468450906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,557.84388
Policy Entropy: 3.75459
Value Function Loss: 0.04924

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.51881
Value Function Update Magnitude: 0.79349

Collected Steps per Second: 22,438.91913
Overall Steps per Second: 10,566.62686

Timestep Collection Time: 2.22907
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.73358

Cumulative Model Updates: 56,174
Cumulative Timesteps: 468,500,924

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,249.79826
Policy Entropy: 3.75735
Value Function Loss: 0.04607

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.52156
Value Function Update Magnitude: 0.75983

Collected Steps per Second: 23,010.17829
Overall Steps per Second: 10,888.55986

Timestep Collection Time: 2.17373
Timestep Consumption Time: 2.41989
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.59363

Cumulative Model Updates: 56,180
Cumulative Timesteps: 468,550,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 468550942...
Checkpoint 468550942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.75147
Policy Entropy: 3.76476
Value Function Loss: 0.04524

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.52475
Value Function Update Magnitude: 0.73647

Collected Steps per Second: 22,644.56317
Overall Steps per Second: 10,660.32685

Timestep Collection Time: 2.20874
Timestep Consumption Time: 2.48305
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.69179

Cumulative Model Updates: 56,186
Cumulative Timesteps: 468,600,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,524.19448
Policy Entropy: 3.76817
Value Function Loss: 0.04485

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.53210
Value Function Update Magnitude: 0.73710

Collected Steps per Second: 23,131.12963
Overall Steps per Second: 10,867.15625

Timestep Collection Time: 2.16159
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.60102

Cumulative Model Updates: 56,192
Cumulative Timesteps: 468,650,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 468650958...
Checkpoint 468650958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,522.19557
Policy Entropy: 3.76981
Value Function Loss: 0.04839

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.55440
Value Function Update Magnitude: 0.75208

Collected Steps per Second: 22,679.40343
Overall Steps per Second: 10,675.43406

Timestep Collection Time: 2.20482
Timestep Consumption Time: 2.47921
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.68402

Cumulative Model Updates: 56,198
Cumulative Timesteps: 468,700,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,776.47719
Policy Entropy: 3.77469
Value Function Loss: 0.04906

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.52588
Value Function Update Magnitude: 0.72935

Collected Steps per Second: 22,999.41483
Overall Steps per Second: 10,817.16289

Timestep Collection Time: 2.17492
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.62432

Cumulative Model Updates: 56,204
Cumulative Timesteps: 468,750,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 468750984...
Checkpoint 468750984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,321.71754
Policy Entropy: 3.77962
Value Function Loss: 0.05025

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.52471
Value Function Update Magnitude: 0.75810

Collected Steps per Second: 22,589.36041
Overall Steps per Second: 10,786.92989

Timestep Collection Time: 2.21458
Timestep Consumption Time: 2.42307
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.63765

Cumulative Model Updates: 56,210
Cumulative Timesteps: 468,801,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,043.55926
Policy Entropy: 3.78058
Value Function Loss: 0.04871

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06427
Policy Update Magnitude: 0.61384
Value Function Update Magnitude: 0.77614

Collected Steps per Second: 22,851.68258
Overall Steps per Second: 10,825.83785

Timestep Collection Time: 2.18890
Timestep Consumption Time: 2.43153
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.62043

Cumulative Model Updates: 56,216
Cumulative Timesteps: 468,851,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 468851030...
Checkpoint 468851030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,930.05000
Policy Entropy: 3.78767
Value Function Loss: 0.04783

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.62844
Value Function Update Magnitude: 0.79955

Collected Steps per Second: 22,456.43437
Overall Steps per Second: 10,672.15228

Timestep Collection Time: 2.22733
Timestep Consumption Time: 2.45944
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.68678

Cumulative Model Updates: 56,222
Cumulative Timesteps: 468,901,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,372.10369
Policy Entropy: 3.79122
Value Function Loss: 0.04784

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07174
Policy Update Magnitude: 0.62917
Value Function Update Magnitude: 0.79451

Collected Steps per Second: 23,027.82411
Overall Steps per Second: 10,853.10977

Timestep Collection Time: 2.17172
Timestep Consumption Time: 2.43618
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.60790

Cumulative Model Updates: 56,228
Cumulative Timesteps: 468,951,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 468951058...
Checkpoint 468951058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,725.26322
Policy Entropy: 3.78473
Value Function Loss: 0.04928

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.79308

Collected Steps per Second: 22,679.86245
Overall Steps per Second: 10,656.62704

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.69436

Cumulative Model Updates: 56,234
Cumulative Timesteps: 469,001,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,390.16355
Policy Entropy: 3.77809
Value Function Loss: 0.04991

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.53534
Value Function Update Magnitude: 0.79497

Collected Steps per Second: 23,077.51320
Overall Steps per Second: 10,886.56166

Timestep Collection Time: 2.16774
Timestep Consumption Time: 2.42747
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.59521

Cumulative Model Updates: 56,240
Cumulative Timesteps: 469,051,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 469051110...
Checkpoint 469051110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,981.88089
Policy Entropy: 3.77385
Value Function Loss: 0.04903

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.51766
Value Function Update Magnitude: 0.80300

Collected Steps per Second: 22,493.38038
Overall Steps per Second: 10,706.28983

Timestep Collection Time: 2.22403
Timestep Consumption Time: 2.44855
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.67258

Cumulative Model Updates: 56,246
Cumulative Timesteps: 469,101,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,994.45310
Policy Entropy: 3.75592
Value Function Loss: 0.04826

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.47080
Value Function Update Magnitude: 0.81530

Collected Steps per Second: 22,933.99911
Overall Steps per Second: 10,830.45438

Timestep Collection Time: 2.18061
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.61753

Cumulative Model Updates: 56,252
Cumulative Timesteps: 469,151,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 469151146...
Checkpoint 469151146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,301.13350
Policy Entropy: 3.74637
Value Function Loss: 0.04794

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.44772
Value Function Update Magnitude: 0.79262

Collected Steps per Second: 22,514.33142
Overall Steps per Second: 10,668.41477

Timestep Collection Time: 2.22143
Timestep Consumption Time: 2.46661
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.68804

Cumulative Model Updates: 56,258
Cumulative Timesteps: 469,201,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,559.60142
Policy Entropy: 3.74200
Value Function Loss: 0.05056

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.48252
Value Function Update Magnitude: 0.77631

Collected Steps per Second: 22,518.23867
Overall Steps per Second: 10,592.06510

Timestep Collection Time: 2.22131
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.72240

Cumulative Model Updates: 56,264
Cumulative Timesteps: 469,251,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 469251180...
Checkpoint 469251180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,880.45245
Policy Entropy: 3.75573
Value Function Loss: 0.05271

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07658
Policy Update Magnitude: 0.54643
Value Function Update Magnitude: 0.76233

Collected Steps per Second: 22,699.70450
Overall Steps per Second: 10,678.24125

Timestep Collection Time: 2.20338
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.68392

Cumulative Model Updates: 56,270
Cumulative Timesteps: 469,301,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,396.03800
Policy Entropy: 3.75819
Value Function Loss: 0.05266

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.52110
Value Function Update Magnitude: 0.75600

Collected Steps per Second: 23,131.67737
Overall Steps per Second: 10,734.91974

Timestep Collection Time: 2.16180
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.65826

Cumulative Model Updates: 56,276
Cumulative Timesteps: 469,351,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 469351202...
Checkpoint 469351202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,367.26017
Policy Entropy: 3.76275
Value Function Loss: 0.05132

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.49651
Value Function Update Magnitude: 0.78827

Collected Steps per Second: 22,461.11924
Overall Steps per Second: 10,630.65908

Timestep Collection Time: 2.22723
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.70582

Cumulative Model Updates: 56,282
Cumulative Timesteps: 469,401,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,522.39146
Policy Entropy: 3.75659
Value Function Loss: 0.05062

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.45844
Value Function Update Magnitude: 0.81456

Collected Steps per Second: 22,857.42486
Overall Steps per Second: 10,688.68102

Timestep Collection Time: 2.18844
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.67990

Cumulative Model Updates: 56,288
Cumulative Timesteps: 469,451,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 469451250...
Checkpoint 469451250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,974.60462
Policy Entropy: 3.76004
Value Function Loss: 0.05163

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.49159
Value Function Update Magnitude: 0.82954

Collected Steps per Second: 22,651.34290
Overall Steps per Second: 10,797.75292

Timestep Collection Time: 2.20817
Timestep Consumption Time: 2.42409
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.63226

Cumulative Model Updates: 56,294
Cumulative Timesteps: 469,501,268

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.48695
Policy Entropy: 3.75656
Value Function Loss: 0.05202

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.60990
Value Function Update Magnitude: 0.82773

Collected Steps per Second: 22,643.75534
Overall Steps per Second: 10,601.93275

Timestep Collection Time: 2.20847
Timestep Consumption Time: 2.50841
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.71688

Cumulative Model Updates: 56,300
Cumulative Timesteps: 469,551,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 469551276...
Checkpoint 469551276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,543.88119
Policy Entropy: 3.77046
Value Function Loss: 0.05181

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.55775
Value Function Update Magnitude: 0.82107

Collected Steps per Second: 22,544.05668
Overall Steps per Second: 10,677.65086

Timestep Collection Time: 2.21877
Timestep Consumption Time: 2.46578
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.68455

Cumulative Model Updates: 56,306
Cumulative Timesteps: 469,601,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,229.85559
Policy Entropy: 3.76830
Value Function Loss: 0.05301

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.59976
Value Function Update Magnitude: 0.82526

Collected Steps per Second: 22,742.04679
Overall Steps per Second: 10,832.67760

Timestep Collection Time: 2.19857
Timestep Consumption Time: 2.41709
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.61566

Cumulative Model Updates: 56,312
Cumulative Timesteps: 469,651,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 469651296...
Checkpoint 469651296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,217.59260
Policy Entropy: 3.76419
Value Function Loss: 0.05271

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.56377
Value Function Update Magnitude: 0.80755

Collected Steps per Second: 22,480.46951
Overall Steps per Second: 10,584.00297

Timestep Collection Time: 2.22451
Timestep Consumption Time: 2.50036
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.72487

Cumulative Model Updates: 56,318
Cumulative Timesteps: 469,701,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,104.53117
Policy Entropy: 3.75202
Value Function Loss: 0.05419

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.56405
Value Function Update Magnitude: 0.76465

Collected Steps per Second: 22,753.46297
Overall Steps per Second: 10,794.85927

Timestep Collection Time: 2.19764
Timestep Consumption Time: 2.43456
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.63220

Cumulative Model Updates: 56,324
Cumulative Timesteps: 469,751,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 469751308...
Checkpoint 469751308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,732.43326
Policy Entropy: 3.74762
Value Function Loss: 0.05309

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.58709
Value Function Update Magnitude: 0.78654

Collected Steps per Second: 22,601.15669
Overall Steps per Second: 10,779.69166

Timestep Collection Time: 2.21281
Timestep Consumption Time: 2.42666
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.63946

Cumulative Model Updates: 56,330
Cumulative Timesteps: 469,801,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,864.09290
Policy Entropy: 3.75222
Value Function Loss: 0.05141

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.79201

Collected Steps per Second: 22,861.11932
Overall Steps per Second: 10,793.31211

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.63380

Cumulative Model Updates: 56,336
Cumulative Timesteps: 469,851,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 469851334...
Checkpoint 469851334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,997.96371
Policy Entropy: 3.74347
Value Function Loss: 0.05078

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07189
Policy Update Magnitude: 0.60576
Value Function Update Magnitude: 0.73692

Collected Steps per Second: 22,374.53000
Overall Steps per Second: 10,744.19828

Timestep Collection Time: 2.23477
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.65386

Cumulative Model Updates: 56,342
Cumulative Timesteps: 469,901,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,926.31129
Policy Entropy: 3.75095
Value Function Loss: 0.05083

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07177
Policy Update Magnitude: 0.61783
Value Function Update Magnitude: 0.63874

Collected Steps per Second: 23,055.64038
Overall Steps per Second: 10,836.00709

Timestep Collection Time: 2.16919
Timestep Consumption Time: 2.44617
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.61535

Cumulative Model Updates: 56,348
Cumulative Timesteps: 469,951,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 469951348...
Checkpoint 469951348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,522.47847
Policy Entropy: 3.76172
Value Function Loss: 0.05344

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.62135
Value Function Update Magnitude: 0.66732

Collected Steps per Second: 22,692.78696
Overall Steps per Second: 10,647.67624

Timestep Collection Time: 2.20440
Timestep Consumption Time: 2.49371
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.69811

Cumulative Model Updates: 56,354
Cumulative Timesteps: 470,001,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,502.08163
Policy Entropy: 3.76365
Value Function Loss: 0.05458

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.53243
Value Function Update Magnitude: 0.71313

Collected Steps per Second: 22,866.57193
Overall Steps per Second: 10,700.13250

Timestep Collection Time: 2.18704
Timestep Consumption Time: 2.48674
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.67377

Cumulative Model Updates: 56,360
Cumulative Timesteps: 470,051,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 470051382...
Checkpoint 470051382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,511.22974
Policy Entropy: 3.76474
Value Function Loss: 0.05440

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.50845
Value Function Update Magnitude: 0.72249

Collected Steps per Second: 23,106.26757
Overall Steps per Second: 10,918.51857

Timestep Collection Time: 2.16400
Timestep Consumption Time: 2.41556
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.57956

Cumulative Model Updates: 56,366
Cumulative Timesteps: 470,101,384

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,795.20382
Policy Entropy: 3.76351
Value Function Loss: 0.05451

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.55151
Value Function Update Magnitude: 0.66965

Collected Steps per Second: 22,972.10773
Overall Steps per Second: 10,814.06020

Timestep Collection Time: 2.17716
Timestep Consumption Time: 2.44774
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.62490

Cumulative Model Updates: 56,372
Cumulative Timesteps: 470,151,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 470151398...
Checkpoint 470151398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,693.85512
Policy Entropy: 3.76455
Value Function Loss: 0.05592

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06691
Policy Update Magnitude: 0.58548
Value Function Update Magnitude: 0.65427

Collected Steps per Second: 22,626.94263
Overall Steps per Second: 10,694.49093

Timestep Collection Time: 2.21082
Timestep Consumption Time: 2.46673
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.67755

Cumulative Model Updates: 56,378
Cumulative Timesteps: 470,201,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,361.39382
Policy Entropy: 3.76150
Value Function Loss: 0.05519

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05716
Policy Update Magnitude: 0.63762
Value Function Update Magnitude: 0.74091

Collected Steps per Second: 22,764.59047
Overall Steps per Second: 10,815.34212

Timestep Collection Time: 2.19771
Timestep Consumption Time: 2.42812
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.62584

Cumulative Model Updates: 56,384
Cumulative Timesteps: 470,251,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 470251452...
Checkpoint 470251452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,765.04098
Policy Entropy: 3.76483
Value Function Loss: 0.05374

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06773
Policy Update Magnitude: 0.64250
Value Function Update Magnitude: 0.81517

Collected Steps per Second: 22,449.55215
Overall Steps per Second: 10,777.58634

Timestep Collection Time: 2.22739
Timestep Consumption Time: 2.41223
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.63963

Cumulative Model Updates: 56,390
Cumulative Timesteps: 470,301,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,848.46792
Policy Entropy: 3.75569
Value Function Loss: 0.05263

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.63484
Value Function Update Magnitude: 0.82536

Collected Steps per Second: 22,920.43593
Overall Steps per Second: 10,843.35932

Timestep Collection Time: 2.18373
Timestep Consumption Time: 2.43218
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.61591

Cumulative Model Updates: 56,396
Cumulative Timesteps: 470,351,508

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 470351508...
Checkpoint 470351508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,914.64500
Policy Entropy: 3.74839
Value Function Loss: 0.05400

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.82931

Collected Steps per Second: 22,473.55375
Overall Steps per Second: 10,638.96308

Timestep Collection Time: 2.22582
Timestep Consumption Time: 2.47596
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.70177

Cumulative Model Updates: 56,402
Cumulative Timesteps: 470,401,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,419.61184
Policy Entropy: 3.74290
Value Function Loss: 0.05385

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.49922
Value Function Update Magnitude: 0.83424

Collected Steps per Second: 22,763.12781
Overall Steps per Second: 10,819.29054

Timestep Collection Time: 2.19812
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62470

Cumulative Model Updates: 56,408
Cumulative Timesteps: 470,451,566

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 470451566...
Checkpoint 470451566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,229.36751
Policy Entropy: 3.73973
Value Function Loss: 0.05703

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.52644
Value Function Update Magnitude: 0.73278

Collected Steps per Second: 22,276.37361
Overall Steps per Second: 10,707.28835

Timestep Collection Time: 2.24453
Timestep Consumption Time: 2.42519
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.66972

Cumulative Model Updates: 56,414
Cumulative Timesteps: 470,501,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,652.14568
Policy Entropy: 3.73659
Value Function Loss: 0.05800

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.48468
Value Function Update Magnitude: 0.69342

Collected Steps per Second: 22,957.60958
Overall Steps per Second: 10,838.81228

Timestep Collection Time: 2.17845
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61416

Cumulative Model Updates: 56,420
Cumulative Timesteps: 470,551,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 470551578...
Checkpoint 470551578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,087.69361
Policy Entropy: 3.72207
Value Function Loss: 0.05900

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.16278
Policy Update Magnitude: 0.43222
Value Function Update Magnitude: 0.70649

Collected Steps per Second: 22,357.07156
Overall Steps per Second: 10,752.39651

Timestep Collection Time: 2.23759
Timestep Consumption Time: 2.41495
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.65254

Cumulative Model Updates: 56,426
Cumulative Timesteps: 470,601,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,079.57537
Policy Entropy: 3.72475
Value Function Loss: 0.05802

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.38448
Value Function Update Magnitude: 0.77041

Collected Steps per Second: 22,857.76220
Overall Steps per Second: 10,836.42848

Timestep Collection Time: 2.18849
Timestep Consumption Time: 2.42779
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61628

Cumulative Model Updates: 56,432
Cumulative Timesteps: 470,651,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 470651628...
Checkpoint 470651628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,085.09767
Policy Entropy: 3.72035
Value Function Loss: 0.05775

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.83073

Collected Steps per Second: 22,638.57609
Overall Steps per Second: 10,689.92130

Timestep Collection Time: 2.20986
Timestep Consumption Time: 2.47007
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.67992

Cumulative Model Updates: 56,438
Cumulative Timesteps: 470,701,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,746.22420
Policy Entropy: 3.70660
Value Function Loss: 0.05958

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.64903
Value Function Update Magnitude: 0.83894

Collected Steps per Second: 22,836.79442
Overall Steps per Second: 10,840.26632

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61280

Cumulative Model Updates: 56,444
Cumulative Timesteps: 470,751,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 470751660...
Checkpoint 470751660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,409.74433
Policy Entropy: 3.69168
Value Function Loss: 0.05888

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.59644
Value Function Update Magnitude: 0.84717

Collected Steps per Second: 22,514.62845
Overall Steps per Second: 10,690.72385

Timestep Collection Time: 2.22113
Timestep Consumption Time: 2.45657
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.67770

Cumulative Model Updates: 56,450
Cumulative Timesteps: 470,801,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,807.39456
Policy Entropy: 3.69833
Value Function Loss: 0.05917

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.16970
Policy Update Magnitude: 0.43122
Value Function Update Magnitude: 0.82593

Collected Steps per Second: 22,814.53689
Overall Steps per Second: 10,834.25073

Timestep Collection Time: 2.19264
Timestep Consumption Time: 2.42457
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61721

Cumulative Model Updates: 56,456
Cumulative Timesteps: 470,851,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 470851692...
Checkpoint 470851692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,331.46252
Policy Entropy: 3.70473
Value Function Loss: 0.05664

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15923
Policy Update Magnitude: 0.40157
Value Function Update Magnitude: 0.78524

Collected Steps per Second: 22,769.30578
Overall Steps per Second: 10,733.59323

Timestep Collection Time: 2.19708
Timestep Consumption Time: 2.46361
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.66069

Cumulative Model Updates: 56,462
Cumulative Timesteps: 470,901,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,130.81573
Policy Entropy: 3.70438
Value Function Loss: 0.05943

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.39933
Value Function Update Magnitude: 0.69587

Collected Steps per Second: 23,017.30882
Overall Steps per Second: 10,849.49733

Timestep Collection Time: 2.17306
Timestep Consumption Time: 2.43711
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61017

Cumulative Model Updates: 56,468
Cumulative Timesteps: 470,951,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 470951736...
Checkpoint 470951736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,629.83515
Policy Entropy: 3.71108
Value Function Loss: 0.06059

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.41222
Value Function Update Magnitude: 0.65030

Collected Steps per Second: 21,988.61952
Overall Steps per Second: 10,682.61267

Timestep Collection Time: 2.27463
Timestep Consumption Time: 2.40737
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.68200

Cumulative Model Updates: 56,474
Cumulative Timesteps: 471,001,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,748.26554
Policy Entropy: 3.71402
Value Function Loss: 0.05966

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.44851
Value Function Update Magnitude: 0.64201

Collected Steps per Second: 22,362.74350
Overall Steps per Second: 10,891.23587

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.35574
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.59232

Cumulative Model Updates: 56,480
Cumulative Timesteps: 471,051,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 471051768...
Checkpoint 471051768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,202.80094
Policy Entropy: 3.72473
Value Function Loss: 0.05848

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.12408
Policy Update Magnitude: 0.41908
Value Function Update Magnitude: 0.62500

Collected Steps per Second: 22,077.76647
Overall Steps per Second: 10,660.22903

Timestep Collection Time: 2.26508
Timestep Consumption Time: 2.42600
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.69108

Cumulative Model Updates: 56,486
Cumulative Timesteps: 471,101,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,930.79995
Policy Entropy: 3.72954
Value Function Loss: 0.05908

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.43203
Value Function Update Magnitude: 0.57412

Collected Steps per Second: 22,169.20984
Overall Steps per Second: 10,867.55693

Timestep Collection Time: 2.25574
Timestep Consumption Time: 2.34584
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.60159

Cumulative Model Updates: 56,492
Cumulative Timesteps: 471,151,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 471151784...
Checkpoint 471151784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,441.39022
Policy Entropy: 3.73760
Value Function Loss: 0.05661

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.46395
Value Function Update Magnitude: 0.66399

Collected Steps per Second: 22,063.62415
Overall Steps per Second: 10,676.00643

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.41829
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.68546

Cumulative Model Updates: 56,498
Cumulative Timesteps: 471,201,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,250.00192
Policy Entropy: 3.74782
Value Function Loss: 0.05529

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.47585
Value Function Update Magnitude: 0.66888

Collected Steps per Second: 22,261.76526
Overall Steps per Second: 10,873.73290

Timestep Collection Time: 2.24627
Timestep Consumption Time: 2.35252
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.59879

Cumulative Model Updates: 56,504
Cumulative Timesteps: 471,251,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 471251812...
Checkpoint 471251812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.23107
Policy Entropy: 3.75487
Value Function Loss: 0.05105

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.47753
Value Function Update Magnitude: 0.69828

Collected Steps per Second: 21,943.14070
Overall Steps per Second: 10,699.19292

Timestep Collection Time: 2.27925
Timestep Consumption Time: 2.39530
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.67456

Cumulative Model Updates: 56,510
Cumulative Timesteps: 471,301,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,043.15749
Policy Entropy: 3.75730
Value Function Loss: 0.04841

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.44188
Value Function Update Magnitude: 0.65998

Collected Steps per Second: 22,718.52788
Overall Steps per Second: 10,837.50385

Timestep Collection Time: 2.20182
Timestep Consumption Time: 2.41382
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61564

Cumulative Model Updates: 56,516
Cumulative Timesteps: 471,351,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 471351848...
Checkpoint 471351848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,115.83638
Policy Entropy: 3.75199
Value Function Loss: 0.04741

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.47161
Value Function Update Magnitude: 0.59572

Collected Steps per Second: 22,572.73687
Overall Steps per Second: 10,653.36023

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.47899
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.69467

Cumulative Model Updates: 56,522
Cumulative Timesteps: 471,401,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,294.81887
Policy Entropy: 3.74674
Value Function Loss: 0.04814

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.52194
Value Function Update Magnitude: 0.55448

Collected Steps per Second: 22,588.52623
Overall Steps per Second: 10,843.63347

Timestep Collection Time: 2.21404
Timestep Consumption Time: 2.39806
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61211

Cumulative Model Updates: 56,528
Cumulative Timesteps: 471,451,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 471451874...
Checkpoint 471451874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,372.79533
Policy Entropy: 3.73994
Value Function Loss: 0.04828

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05833
Policy Update Magnitude: 0.60517
Value Function Update Magnitude: 0.59139

Collected Steps per Second: 22,739.43681
Overall Steps per Second: 10,737.05149

Timestep Collection Time: 2.19891
Timestep Consumption Time: 2.45805
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.65696

Cumulative Model Updates: 56,534
Cumulative Timesteps: 471,501,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,727.91289
Policy Entropy: 3.75085
Value Function Loss: 0.04686

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06225
Policy Update Magnitude: 0.63925
Value Function Update Magnitude: 0.58901

Collected Steps per Second: 22,956.03872
Overall Steps per Second: 10,828.48376

Timestep Collection Time: 2.17947
Timestep Consumption Time: 2.44094
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.62041

Cumulative Model Updates: 56,540
Cumulative Timesteps: 471,551,908

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 471551908...
Checkpoint 471551908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,901.53402
Policy Entropy: 3.75781
Value Function Loss: 0.04656

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06487
Policy Update Magnitude: 0.63723
Value Function Update Magnitude: 0.58405

Collected Steps per Second: 22,626.24165
Overall Steps per Second: 10,684.45487

Timestep Collection Time: 2.21080
Timestep Consumption Time: 2.47096
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.68175

Cumulative Model Updates: 56,546
Cumulative Timesteps: 471,601,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,522.25257
Policy Entropy: 3.75952
Value Function Loss: 0.04810

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07044
Policy Update Magnitude: 0.59727
Value Function Update Magnitude: 0.59360

Collected Steps per Second: 23,052.31963
Overall Steps per Second: 10,872.93897

Timestep Collection Time: 2.16924
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.59912

Cumulative Model Updates: 56,552
Cumulative Timesteps: 471,651,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 471651936...
Checkpoint 471651936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,000.38113
Policy Entropy: 3.76472
Value Function Loss: 0.04658

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.58121
Value Function Update Magnitude: 0.65817

Collected Steps per Second: 22,648.53981
Overall Steps per Second: 10,677.49450

Timestep Collection Time: 2.20853
Timestep Consumption Time: 2.47609
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.68462

Cumulative Model Updates: 56,558
Cumulative Timesteps: 471,701,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,793.66322
Policy Entropy: 3.76614
Value Function Loss: 0.04693

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.52440
Value Function Update Magnitude: 0.70218

Collected Steps per Second: 23,068.78808
Overall Steps per Second: 10,849.36592

Timestep Collection Time: 2.16812
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61004

Cumulative Model Updates: 56,564
Cumulative Timesteps: 471,751,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 471751972...
Checkpoint 471751972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,646.60781
Policy Entropy: 3.77486
Value Function Loss: 0.04574

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.47674
Value Function Update Magnitude: 0.69610

Collected Steps per Second: 22,407.58127
Overall Steps per Second: 10,747.62821

Timestep Collection Time: 2.23148
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.65238

Cumulative Model Updates: 56,570
Cumulative Timesteps: 471,801,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,903.24523
Policy Entropy: 3.76881
Value Function Loss: 0.04795

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.43740
Value Function Update Magnitude: 0.70837

Collected Steps per Second: 23,105.86724
Overall Steps per Second: 10,877.33624

Timestep Collection Time: 2.16464
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.59818

Cumulative Model Updates: 56,576
Cumulative Timesteps: 471,851,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 471851990...
Checkpoint 471851990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,368.89269
Policy Entropy: 3.77167
Value Function Loss: 0.04737

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.47885
Value Function Update Magnitude: 0.73101

Collected Steps per Second: 22,483.14203
Overall Steps per Second: 10,630.71698

Timestep Collection Time: 2.22460
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.70486

Cumulative Model Updates: 56,582
Cumulative Timesteps: 471,902,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,057.97538
Policy Entropy: 3.76242
Value Function Loss: 0.04975

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.60151
Value Function Update Magnitude: 0.76049

Collected Steps per Second: 23,237.99994
Overall Steps per Second: 10,914.57117

Timestep Collection Time: 2.15182
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.58140

Cumulative Model Updates: 56,588
Cumulative Timesteps: 471,952,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 471952010...
Checkpoint 471952010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,773.99362
Policy Entropy: 3.75844
Value Function Loss: 0.04959

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.57483
Value Function Update Magnitude: 0.77217

Collected Steps per Second: 22,701.40244
Overall Steps per Second: 10,596.28240

Timestep Collection Time: 2.20321
Timestep Consumption Time: 2.51693
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.72015

Cumulative Model Updates: 56,594
Cumulative Timesteps: 472,002,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.72128
Policy Entropy: 3.75808
Value Function Loss: 0.04931

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.46838
Value Function Update Magnitude: 0.76839

Collected Steps per Second: 22,923.62198
Overall Steps per Second: 10,842.12785

Timestep Collection Time: 2.18212
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.61367

Cumulative Model Updates: 56,600
Cumulative Timesteps: 472,052,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 472052048...
Checkpoint 472052048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,022.03785
Policy Entropy: 3.76193
Value Function Loss: 0.04951

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.42738
Value Function Update Magnitude: 0.77054

Collected Steps per Second: 22,859.88599
Overall Steps per Second: 10,741.31340

Timestep Collection Time: 2.18811
Timestep Consumption Time: 2.46867
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.65679

Cumulative Model Updates: 56,606
Cumulative Timesteps: 472,102,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,157.78656
Policy Entropy: 3.76440
Value Function Loss: 0.05103

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.43266
Value Function Update Magnitude: 0.76212

Collected Steps per Second: 23,122.01385
Overall Steps per Second: 10,864.30406

Timestep Collection Time: 2.16244
Timestep Consumption Time: 2.43979
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.60223

Cumulative Model Updates: 56,612
Cumulative Timesteps: 472,152,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 472152068...
Checkpoint 472152068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,087.48916
Policy Entropy: 3.76227
Value Function Loss: 0.05303

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10410
Policy Update Magnitude: 0.44642
Value Function Update Magnitude: 0.73133

Collected Steps per Second: 22,629.72270
Overall Steps per Second: 10,655.30464

Timestep Collection Time: 2.21054
Timestep Consumption Time: 2.48421
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.69475

Cumulative Model Updates: 56,618
Cumulative Timesteps: 472,202,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,008.21935
Policy Entropy: 3.75185
Value Function Loss: 0.05449

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.47187
Value Function Update Magnitude: 0.63785

Collected Steps per Second: 22,893.23616
Overall Steps per Second: 10,883.82130

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.41069
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.59544

Cumulative Model Updates: 56,624
Cumulative Timesteps: 472,252,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 472252108...
Checkpoint 472252108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,792.34798
Policy Entropy: 3.74371
Value Function Loss: 0.05163

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.47033
Value Function Update Magnitude: 0.66963

Collected Steps per Second: 22,556.13804
Overall Steps per Second: 10,691.41043

Timestep Collection Time: 2.21758
Timestep Consumption Time: 2.46094
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.67852

Cumulative Model Updates: 56,630
Cumulative Timesteps: 472,302,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,125.39494
Policy Entropy: 3.73859
Value Function Loss: 0.04935

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.47034
Value Function Update Magnitude: 0.75575

Collected Steps per Second: 22,831.43483
Overall Steps per Second: 10,735.46846

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.46809
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.65858

Cumulative Model Updates: 56,636
Cumulative Timesteps: 472,352,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 472352140...
Checkpoint 472352140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,054.95339
Policy Entropy: 3.73980
Value Function Loss: 0.05036

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06638
Policy Update Magnitude: 0.53029
Value Function Update Magnitude: 0.69129

Collected Steps per Second: 22,350.39432
Overall Steps per Second: 10,757.73870

Timestep Collection Time: 2.23763
Timestep Consumption Time: 2.41130
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.64893

Cumulative Model Updates: 56,642
Cumulative Timesteps: 472,402,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,682.75148
Policy Entropy: 3.74775
Value Function Loss: 0.05368

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.54300
Value Function Update Magnitude: 0.57247

Collected Steps per Second: 22,322.92423
Overall Steps per Second: 10,542.44557

Timestep Collection Time: 2.24012
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.74330

Cumulative Model Updates: 56,648
Cumulative Timesteps: 472,452,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 472452158...
Checkpoint 472452158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33519
Policy Entropy: 3.76162
Value Function Loss: 0.05481

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.46865
Value Function Update Magnitude: 0.59557

Collected Steps per Second: 23,085.90880
Overall Steps per Second: 10,979.37086

Timestep Collection Time: 2.16626
Timestep Consumption Time: 2.38865
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.55491

Cumulative Model Updates: 56,654
Cumulative Timesteps: 472,502,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.39581
Policy Entropy: 3.76913
Value Function Loss: 0.05074

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.45299
Value Function Update Magnitude: 0.65829

Collected Steps per Second: 23,179.85020
Overall Steps per Second: 10,896.09856

Timestep Collection Time: 2.15782
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59045

Cumulative Model Updates: 56,660
Cumulative Timesteps: 472,552,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 472552186...
Checkpoint 472552186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,352.35720
Policy Entropy: 3.78920
Value Function Loss: 0.04905

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.45962
Value Function Update Magnitude: 0.72432

Collected Steps per Second: 22,781.13105
Overall Steps per Second: 10,689.61825

Timestep Collection Time: 2.19524
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.67837

Cumulative Model Updates: 56,666
Cumulative Timesteps: 472,602,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,097.01898
Policy Entropy: 3.78509
Value Function Loss: 0.04633

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.48065
Value Function Update Magnitude: 0.74488

Collected Steps per Second: 22,558.59457
Overall Steps per Second: 10,624.86172

Timestep Collection Time: 2.21716
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.70745

Cumulative Model Updates: 56,672
Cumulative Timesteps: 472,652,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 472652212...
Checkpoint 472652212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,460.50882
Policy Entropy: 3.78870
Value Function Loss: 0.04740

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.49250
Value Function Update Magnitude: 0.77173

Collected Steps per Second: 22,801.59223
Overall Steps per Second: 10,716.84788

Timestep Collection Time: 2.19336
Timestep Consumption Time: 2.47332
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.66667

Cumulative Model Updates: 56,678
Cumulative Timesteps: 472,702,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,483.30568
Policy Entropy: 3.78339
Value Function Loss: 0.04706

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.50894
Value Function Update Magnitude: 0.80023

Collected Steps per Second: 23,254.24379
Overall Steps per Second: 10,722.73185

Timestep Collection Time: 2.15058
Timestep Consumption Time: 2.51335
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.66392

Cumulative Model Updates: 56,684
Cumulative Timesteps: 472,752,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 472752234...
Checkpoint 472752234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,588.65790
Policy Entropy: 3.78979
Value Function Loss: 0.04724

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.52665
Value Function Update Magnitude: 0.80482

Collected Steps per Second: 22,705.33757
Overall Steps per Second: 10,694.54539

Timestep Collection Time: 2.20257
Timestep Consumption Time: 2.47365
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.67622

Cumulative Model Updates: 56,690
Cumulative Timesteps: 472,802,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,751.57617
Policy Entropy: 3.78723
Value Function Loss: 0.04788

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05513
Policy Update Magnitude: 0.60802
Value Function Update Magnitude: 0.76715

Collected Steps per Second: 22,839.78949
Overall Steps per Second: 10,832.09661

Timestep Collection Time: 2.18925
Timestep Consumption Time: 2.42685
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.61610

Cumulative Model Updates: 56,696
Cumulative Timesteps: 472,852,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 472852246...
Checkpoint 472852246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,363.15134
Policy Entropy: 3.79031
Value Function Loss: 0.04813

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07498
Policy Update Magnitude: 0.64194
Value Function Update Magnitude: 0.76231

Collected Steps per Second: 22,754.55642
Overall Steps per Second: 10,736.48781

Timestep Collection Time: 2.19745
Timestep Consumption Time: 2.45975
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.65720

Cumulative Model Updates: 56,702
Cumulative Timesteps: 472,902,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,613.30696
Policy Entropy: 3.79055
Value Function Loss: 0.05139

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08998
Policy Update Magnitude: 0.57288
Value Function Update Magnitude: 0.73855

Collected Steps per Second: 22,904.69143
Overall Steps per Second: 10,761.14157

Timestep Collection Time: 2.18296
Timestep Consumption Time: 2.46339
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.64635

Cumulative Model Updates: 56,708
Cumulative Timesteps: 472,952,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 472952248...
Checkpoint 472952248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,008.30093
Policy Entropy: 3.79244
Value Function Loss: 0.04932

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.70960

Collected Steps per Second: 23,038.90551
Overall Steps per Second: 10,706.81892

Timestep Collection Time: 2.17128
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.67216

Cumulative Model Updates: 56,714
Cumulative Timesteps: 473,002,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.82905
Policy Entropy: 3.77790
Value Function Loss: 0.04968

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.51663
Value Function Update Magnitude: 0.76341

Collected Steps per Second: 22,804.70421
Overall Steps per Second: 10,793.60504

Timestep Collection Time: 2.19385
Timestep Consumption Time: 2.44131
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.63515

Cumulative Model Updates: 56,720
Cumulative Timesteps: 473,052,302

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 473052302...
Checkpoint 473052302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,383.76244
Policy Entropy: 3.77381
Value Function Loss: 0.04893

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.50101
Value Function Update Magnitude: 0.77597

Collected Steps per Second: 22,648.89860
Overall Steps per Second: 10,716.22519

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.66713

Cumulative Model Updates: 56,726
Cumulative Timesteps: 473,102,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.72884
Policy Entropy: 3.76919
Value Function Loss: 0.05176

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.57116
Value Function Update Magnitude: 0.78070

Collected Steps per Second: 23,216.48680
Overall Steps per Second: 10,888.43910

Timestep Collection Time: 2.15373
Timestep Consumption Time: 2.43848
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.59221

Cumulative Model Updates: 56,732
Cumulative Timesteps: 473,152,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 473152318...
Checkpoint 473152318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,063.51482
Policy Entropy: 3.76647
Value Function Loss: 0.05198

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.61002
Value Function Update Magnitude: 0.76550

Collected Steps per Second: 22,586.88995
Overall Steps per Second: 10,647.07305

Timestep Collection Time: 2.21403
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.69688

Cumulative Model Updates: 56,738
Cumulative Timesteps: 473,202,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,358.82692
Policy Entropy: 3.76067
Value Function Loss: 0.05265

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.57847
Value Function Update Magnitude: 0.76883

Collected Steps per Second: 22,582.94563
Overall Steps per Second: 10,604.70641

Timestep Collection Time: 2.21441
Timestep Consumption Time: 2.50123
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.71564

Cumulative Model Updates: 56,744
Cumulative Timesteps: 473,252,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 473252334...
Checkpoint 473252334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,004.60678
Policy Entropy: 3.75866
Value Function Loss: 0.05163

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.78021

Collected Steps per Second: 22,878.47592
Overall Steps per Second: 10,862.80673

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.41760
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.60323

Cumulative Model Updates: 56,750
Cumulative Timesteps: 473,302,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,336.88340
Policy Entropy: 3.76109
Value Function Loss: 0.05294

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.60237
Value Function Update Magnitude: 0.77749

Collected Steps per Second: 22,761.24141
Overall Steps per Second: 10,639.59065

Timestep Collection Time: 2.19795
Timestep Consumption Time: 2.50411
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.70206

Cumulative Model Updates: 56,756
Cumulative Timesteps: 473,352,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 473352366...
Checkpoint 473352366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,821.30254
Policy Entropy: 3.74596
Value Function Loss: 0.05122

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.80468

Collected Steps per Second: 22,634.43830
Overall Steps per Second: 10,655.16188

Timestep Collection Time: 2.21000
Timestep Consumption Time: 2.48463
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.69463

Cumulative Model Updates: 56,762
Cumulative Timesteps: 473,402,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,103.55956
Policy Entropy: 3.73555
Value Function Loss: 0.05351

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.60973
Value Function Update Magnitude: 0.82914

Collected Steps per Second: 23,106.65396
Overall Steps per Second: 10,781.97749

Timestep Collection Time: 2.16457
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.63885

Cumulative Model Updates: 56,768
Cumulative Timesteps: 473,452,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 473452404...
Checkpoint 473452404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,704.20052
Policy Entropy: 3.72106
Value Function Loss: 0.05584

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.63893
Value Function Update Magnitude: 0.83155

Collected Steps per Second: 22,791.65619
Overall Steps per Second: 10,656.88716

Timestep Collection Time: 2.19466
Timestep Consumption Time: 2.49902
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.69368

Cumulative Model Updates: 56,774
Cumulative Timesteps: 473,502,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,064.64087
Policy Entropy: 3.71984
Value Function Loss: 0.05765

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.62232
Value Function Update Magnitude: 0.82229

Collected Steps per Second: 22,956.25827
Overall Steps per Second: 10,855.97071

Timestep Collection Time: 2.17806
Timestep Consumption Time: 2.42771
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.60576

Cumulative Model Updates: 56,780
Cumulative Timesteps: 473,552,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 473552424...
Checkpoint 473552424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,153.81436
Policy Entropy: 3.71432
Value Function Loss: 0.05778

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07535
Policy Update Magnitude: 0.62336
Value Function Update Magnitude: 0.76548

Collected Steps per Second: 22,744.44410
Overall Steps per Second: 10,639.55736

Timestep Collection Time: 2.19843
Timestep Consumption Time: 2.50120
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.69963

Cumulative Model Updates: 56,786
Cumulative Timesteps: 473,602,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,286.87854
Policy Entropy: 3.71295
Value Function Loss: 0.05725

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.64676
Value Function Update Magnitude: 0.73729

Collected Steps per Second: 23,044.80964
Overall Steps per Second: 10,862.88141

Timestep Collection Time: 2.17081
Timestep Consumption Time: 2.43441
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.60522

Cumulative Model Updates: 56,792
Cumulative Timesteps: 473,652,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 473652452...
Checkpoint 473652452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,921.28327
Policy Entropy: 3.72232
Value Function Loss: 0.06001

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.68192

Collected Steps per Second: 22,703.55415
Overall Steps per Second: 10,703.00103

Timestep Collection Time: 2.20291
Timestep Consumption Time: 2.46998
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.67289

Cumulative Model Updates: 56,798
Cumulative Timesteps: 473,702,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,147.24134
Policy Entropy: 3.72926
Value Function Loss: 0.06171

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.53193
Value Function Update Magnitude: 0.68896

Collected Steps per Second: 23,158.58243
Overall Steps per Second: 10,903.85287

Timestep Collection Time: 2.15946
Timestep Consumption Time: 2.42699
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.58645

Cumulative Model Updates: 56,804
Cumulative Timesteps: 473,752,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 473752476...
Checkpoint 473752476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,506.91931
Policy Entropy: 3.71521
Value Function Loss: 0.06167

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11570
Policy Update Magnitude: 0.51401
Value Function Update Magnitude: 0.75229

Collected Steps per Second: 21,747.56045
Overall Steps per Second: 10,649.93613

Timestep Collection Time: 2.29975
Timestep Consumption Time: 2.39643
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.69618

Cumulative Model Updates: 56,810
Cumulative Timesteps: 473,802,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,284.42978
Policy Entropy: 3.71448
Value Function Loss: 0.05933

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.50056
Value Function Update Magnitude: 0.80889

Collected Steps per Second: 22,083.52146
Overall Steps per Second: 10,824.42871

Timestep Collection Time: 2.26558
Timestep Consumption Time: 2.35656
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62214

Cumulative Model Updates: 56,816
Cumulative Timesteps: 473,852,522

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 473852522...
Checkpoint 473852522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,110.24750
Policy Entropy: 3.70400
Value Function Loss: 0.05766

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.50312
Value Function Update Magnitude: 0.81954

Collected Steps per Second: 21,845.42802
Overall Steps per Second: 10,740.66865

Timestep Collection Time: 2.28927
Timestep Consumption Time: 2.36687
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.65613

Cumulative Model Updates: 56,822
Cumulative Timesteps: 473,902,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,597.98078
Policy Entropy: 3.70070
Value Function Loss: 0.05839

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.51918
Value Function Update Magnitude: 0.81761

Collected Steps per Second: 22,307.10311
Overall Steps per Second: 10,840.13754

Timestep Collection Time: 2.24189
Timestep Consumption Time: 2.37152
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61341

Cumulative Model Updates: 56,828
Cumulative Timesteps: 473,952,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 473952542...
Checkpoint 473952542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,175.03504
Policy Entropy: 3.71490
Value Function Loss: 0.05773

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.48597
Value Function Update Magnitude: 0.76144

Collected Steps per Second: 21,932.54261
Overall Steps per Second: 10,649.04444

Timestep Collection Time: 2.28008
Timestep Consumption Time: 2.41593
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.69601

Cumulative Model Updates: 56,834
Cumulative Timesteps: 474,002,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,961.55760
Policy Entropy: 3.72778
Value Function Loss: 0.05933

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.45921
Value Function Update Magnitude: 0.66405

Collected Steps per Second: 22,484.95500
Overall Steps per Second: 10,690.93922

Timestep Collection Time: 2.22602
Timestep Consumption Time: 2.45570
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.68172

Cumulative Model Updates: 56,840
Cumulative Timesteps: 474,052,602

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 474052602...
Checkpoint 474052602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,719.91171
Policy Entropy: 3.73619
Value Function Loss: 0.05827

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.44699
Value Function Update Magnitude: 0.67108

Collected Steps per Second: 22,848.98133
Overall Steps per Second: 10,874.48411

Timestep Collection Time: 2.18951
Timestep Consumption Time: 2.41099
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.60049

Cumulative Model Updates: 56,846
Cumulative Timesteps: 474,102,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,223.51451
Policy Entropy: 3.72995
Value Function Loss: 0.05769

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.45104
Value Function Update Magnitude: 0.66897

Collected Steps per Second: 22,088.34996
Overall Steps per Second: 10,475.37670

Timestep Collection Time: 2.26499
Timestep Consumption Time: 2.51097
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.77596

Cumulative Model Updates: 56,852
Cumulative Timesteps: 474,152,660

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 474152660...
Checkpoint 474152660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,683.86433
Policy Entropy: 3.73343
Value Function Loss: 0.05670

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.47498
Value Function Update Magnitude: 0.70398

Collected Steps per Second: 22,545.77641
Overall Steps per Second: 10,606.15493

Timestep Collection Time: 2.21798
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.71481

Cumulative Model Updates: 56,858
Cumulative Timesteps: 474,202,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,711.54011
Policy Entropy: 3.72751
Value Function Loss: 0.05565

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.49476
Value Function Update Magnitude: 0.72755

Collected Steps per Second: 23,009.18541
Overall Steps per Second: 10,857.25587

Timestep Collection Time: 2.17383
Timestep Consumption Time: 2.43305
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.60687

Cumulative Model Updates: 56,864
Cumulative Timesteps: 474,252,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 474252684...
Checkpoint 474252684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,732.22604
Policy Entropy: 3.72456
Value Function Loss: 0.05650

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.50882
Value Function Update Magnitude: 0.68243

Collected Steps per Second: 22,857.96998
Overall Steps per Second: 10,726.23686

Timestep Collection Time: 2.18865
Timestep Consumption Time: 2.47543
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.66408

Cumulative Model Updates: 56,870
Cumulative Timesteps: 474,302,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,278.76549
Policy Entropy: 3.73499
Value Function Loss: 0.05548

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.65315

Collected Steps per Second: 22,836.65592
Overall Steps per Second: 10,806.60378

Timestep Collection Time: 2.19078
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.62958

Cumulative Model Updates: 56,876
Cumulative Timesteps: 474,352,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 474352742...
Checkpoint 474352742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,125.38275
Policy Entropy: 3.74067
Value Function Loss: 0.05577

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.58827
Value Function Update Magnitude: 0.64677

Collected Steps per Second: 22,591.65862
Overall Steps per Second: 10,711.06283

Timestep Collection Time: 2.21462
Timestep Consumption Time: 2.45644
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.67106

Cumulative Model Updates: 56,882
Cumulative Timesteps: 474,402,774

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,280.72451
Policy Entropy: 3.74845
Value Function Loss: 0.05852

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.51629
Value Function Update Magnitude: 0.62972

Collected Steps per Second: 23,028.02669
Overall Steps per Second: 10,873.46684

Timestep Collection Time: 2.17222
Timestep Consumption Time: 2.42815
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60037

Cumulative Model Updates: 56,888
Cumulative Timesteps: 474,452,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 474452796...
Checkpoint 474452796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,717.39975
Policy Entropy: 3.74730
Value Function Loss: 0.06167

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.48504
Value Function Update Magnitude: 0.60651

Collected Steps per Second: 22,518.30490
Overall Steps per Second: 10,702.12414

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.45214
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.67309

Cumulative Model Updates: 56,894
Cumulative Timesteps: 474,502,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,792.54930
Policy Entropy: 3.75026
Value Function Loss: 0.06116

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.52361
Value Function Update Magnitude: 0.64656

Collected Steps per Second: 22,791.24074
Overall Steps per Second: 10,797.85659

Timestep Collection Time: 2.19453
Timestep Consumption Time: 2.43750
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.63203

Cumulative Model Updates: 56,900
Cumulative Timesteps: 474,552,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 474552824...
Checkpoint 474552824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,896.93127
Policy Entropy: 3.76280
Value Function Loss: 0.05625

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.53430
Value Function Update Magnitude: 0.73100

Collected Steps per Second: 22,739.87390
Overall Steps per Second: 10,727.66313

Timestep Collection Time: 2.20001
Timestep Consumption Time: 2.46345
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.66346

Cumulative Model Updates: 56,906
Cumulative Timesteps: 474,602,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,764.95846
Policy Entropy: 3.76834
Value Function Loss: 0.05462

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.56993
Value Function Update Magnitude: 0.77057

Collected Steps per Second: 22,725.50284
Overall Steps per Second: 10,663.52754

Timestep Collection Time: 2.20096
Timestep Consumption Time: 2.48960
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69057

Cumulative Model Updates: 56,912
Cumulative Timesteps: 474,652,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 474652870...
Checkpoint 474652870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,139.19943
Policy Entropy: 3.76661
Value Function Loss: 0.05412

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.53760
Value Function Update Magnitude: 0.77683

Collected Steps per Second: 22,739.21836
Overall Steps per Second: 10,824.35037

Timestep Collection Time: 2.19955
Timestep Consumption Time: 2.42115
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.62069

Cumulative Model Updates: 56,918
Cumulative Timesteps: 474,702,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,055.13585
Policy Entropy: 3.75828
Value Function Loss: 0.05338

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.50801
Value Function Update Magnitude: 0.76756

Collected Steps per Second: 22,962.72908
Overall Steps per Second: 10,726.89302

Timestep Collection Time: 2.17866
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.66379

Cumulative Model Updates: 56,924
Cumulative Timesteps: 474,752,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 474752914...
Checkpoint 474752914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,122.58795
Policy Entropy: 3.74621
Value Function Loss: 0.05416

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.52010
Value Function Update Magnitude: 0.79574

Collected Steps per Second: 22,813.88446
Overall Steps per Second: 10,826.37460

Timestep Collection Time: 2.19323
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62168

Cumulative Model Updates: 56,930
Cumulative Timesteps: 474,802,950

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,348.31898
Policy Entropy: 3.74334
Value Function Loss: 0.05367

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.50878
Value Function Update Magnitude: 0.81188

Collected Steps per Second: 22,808.95058
Overall Steps per Second: 10,699.59334

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.48224
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.67550

Cumulative Model Updates: 56,936
Cumulative Timesteps: 474,852,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 474852976...
Checkpoint 474852976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,242.33459
Policy Entropy: 3.73115
Value Function Loss: 0.05824

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.49059
Value Function Update Magnitude: 0.82005

Collected Steps per Second: 22,622.63166
Overall Steps per Second: 10,685.76026

Timestep Collection Time: 2.21133
Timestep Consumption Time: 2.47023
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.68156

Cumulative Model Updates: 56,942
Cumulative Timesteps: 474,903,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,709.00060
Policy Entropy: 3.72902
Value Function Loss: 0.05665

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.52189
Value Function Update Magnitude: 0.85362

Collected Steps per Second: 22,810.64457
Overall Steps per Second: 10,690.22374

Timestep Collection Time: 2.19319
Timestep Consumption Time: 2.48660
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.67979

Cumulative Model Updates: 56,948
Cumulative Timesteps: 474,953,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 474953030...
Checkpoint 474953030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,695.76390
Policy Entropy: 3.72607
Value Function Loss: 0.05867

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09836
Policy Update Magnitude: 0.51068
Value Function Update Magnitude: 0.86640

Collected Steps per Second: 22,685.60142
Overall Steps per Second: 10,617.79021

Timestep Collection Time: 2.20448
Timestep Consumption Time: 2.50554
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.71002

Cumulative Model Updates: 56,954
Cumulative Timesteps: 475,003,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,455.62935
Policy Entropy: 3.73654
Value Function Loss: 0.05508

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.47662
Value Function Update Magnitude: 0.87935

Collected Steps per Second: 22,839.15286
Overall Steps per Second: 10,837.75124

Timestep Collection Time: 2.18966
Timestep Consumption Time: 2.42477
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.61443

Cumulative Model Updates: 56,960
Cumulative Timesteps: 475,053,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 475053050...
Checkpoint 475053050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.19636
Policy Entropy: 3.73769
Value Function Loss: 0.05273

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.50648
Value Function Update Magnitude: 0.89288

Collected Steps per Second: 22,713.37333
Overall Steps per Second: 10,725.63139

Timestep Collection Time: 2.20170
Timestep Consumption Time: 2.46078
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.66248

Cumulative Model Updates: 56,966
Cumulative Timesteps: 475,103,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.49703
Policy Entropy: 3.73244
Value Function Loss: 0.05218

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.51939
Value Function Update Magnitude: 0.89418

Collected Steps per Second: 22,916.71621
Overall Steps per Second: 10,827.73876

Timestep Collection Time: 2.18234
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61888

Cumulative Model Updates: 56,972
Cumulative Timesteps: 475,153,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 475153070...
Checkpoint 475153070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,365.75461
Policy Entropy: 3.73432
Value Function Loss: 0.05337

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.54289
Value Function Update Magnitude: 0.92636

Collected Steps per Second: 22,806.04968
Overall Steps per Second: 10,707.95750

Timestep Collection Time: 2.19310
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.67092

Cumulative Model Updates: 56,978
Cumulative Timesteps: 475,203,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,473.37552
Policy Entropy: 3.72994
Value Function Loss: 0.05585

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.51476
Value Function Update Magnitude: 0.91524

Collected Steps per Second: 22,619.27658
Overall Steps per Second: 10,669.27933

Timestep Collection Time: 2.21077
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.68691

Cumulative Model Updates: 56,984
Cumulative Timesteps: 475,253,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 475253092...
Checkpoint 475253092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,356.89434
Policy Entropy: 3.71706
Value Function Loss: 0.05592

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.51165
Value Function Update Magnitude: 0.90675

Collected Steps per Second: 22,705.88788
Overall Steps per Second: 10,823.57512

Timestep Collection Time: 2.20260
Timestep Consumption Time: 2.41805
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.62065

Cumulative Model Updates: 56,990
Cumulative Timesteps: 475,303,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.13686
Policy Entropy: 3.71601
Value Function Loss: 0.05422

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.51896
Value Function Update Magnitude: 0.92294

Collected Steps per Second: 22,722.97430
Overall Steps per Second: 10,698.47931

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.47453
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.67618

Cumulative Model Updates: 56,996
Cumulative Timesteps: 475,353,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 475353132...
Checkpoint 475353132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,338.47696
Policy Entropy: 3.72194
Value Function Loss: 0.05374

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.49003
Value Function Update Magnitude: 0.90130

Collected Steps per Second: 22,050.58348
Overall Steps per Second: 10,827.52915

Timestep Collection Time: 2.26860
Timestep Consumption Time: 2.35147
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.62008

Cumulative Model Updates: 57,002
Cumulative Timesteps: 475,403,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,520.84360
Policy Entropy: 3.72259
Value Function Loss: 0.05249

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.51705
Value Function Update Magnitude: 0.90994

Collected Steps per Second: 21,884.90410
Overall Steps per Second: 10,650.91210

Timestep Collection Time: 2.28523
Timestep Consumption Time: 2.41033
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.69556

Cumulative Model Updates: 57,008
Cumulative Timesteps: 475,453,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 475453168...
Checkpoint 475453168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,029.60984
Policy Entropy: 3.72380
Value Function Loss: 0.05252

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.55232
Value Function Update Magnitude: 0.87661

Collected Steps per Second: 22,039.93012
Overall Steps per Second: 10,727.13739

Timestep Collection Time: 2.26997
Timestep Consumption Time: 2.39390
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.66387

Cumulative Model Updates: 57,014
Cumulative Timesteps: 475,503,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,723.60904
Policy Entropy: 3.71713
Value Function Loss: 0.05423

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.65212
Value Function Update Magnitude: 0.80697

Collected Steps per Second: 22,639.44280
Overall Steps per Second: 10,827.36354

Timestep Collection Time: 2.20977
Timestep Consumption Time: 2.41074
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.62052

Cumulative Model Updates: 57,020
Cumulative Timesteps: 475,553,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 475553226...
Checkpoint 475553226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,793.40019
Policy Entropy: 3.72300
Value Function Loss: 0.05449

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.67978
Value Function Update Magnitude: 0.75355

Collected Steps per Second: 21,947.07210
Overall Steps per Second: 10,481.08494

Timestep Collection Time: 2.27912
Timestep Consumption Time: 2.49329
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.77241

Cumulative Model Updates: 57,026
Cumulative Timesteps: 475,603,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,603.01092
Policy Entropy: 3.70790
Value Function Loss: 0.05330

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.64062
Value Function Update Magnitude: 0.76047

Collected Steps per Second: 22,571.32995
Overall Steps per Second: 10,709.13456

Timestep Collection Time: 2.21573
Timestep Consumption Time: 2.45430
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.67003

Cumulative Model Updates: 57,032
Cumulative Timesteps: 475,653,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 475653258...
Checkpoint 475653258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,395.59976
Policy Entropy: 3.69894
Value Function Loss: 0.05127

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06631
Policy Update Magnitude: 0.63797
Value Function Update Magnitude: 0.80360

Collected Steps per Second: 22,579.84965
Overall Steps per Second: 10,836.02365

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.39997
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.61442

Cumulative Model Updates: 57,038
Cumulative Timesteps: 475,703,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,732.71600
Policy Entropy: 3.70314
Value Function Loss: 0.05080

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06608
Policy Update Magnitude: 0.67451
Value Function Update Magnitude: 0.83248

Collected Steps per Second: 22,697.36635
Overall Steps per Second: 10,843.16786

Timestep Collection Time: 2.20316
Timestep Consumption Time: 2.40859
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61175

Cumulative Model Updates: 57,044
Cumulative Timesteps: 475,753,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 475753266...
Checkpoint 475753266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,491.97436
Policy Entropy: 3.71954
Value Function Loss: 0.05274

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.68165
Value Function Update Magnitude: 0.86016

Collected Steps per Second: 22,828.50696
Overall Steps per Second: 10,701.12018

Timestep Collection Time: 2.19130
Timestep Consumption Time: 2.48336
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.67465

Cumulative Model Updates: 57,050
Cumulative Timesteps: 475,803,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,044.42316
Policy Entropy: 3.71949
Value Function Loss: 0.05505

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.67376
Value Function Update Magnitude: 0.85853

Collected Steps per Second: 22,834.31389
Overall Steps per Second: 10,816.09250

Timestep Collection Time: 2.19030
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.62404

Cumulative Model Updates: 57,056
Cumulative Timesteps: 475,853,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 475853304...
Checkpoint 475853304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,041.38090
Policy Entropy: 3.72134
Value Function Loss: 0.05464

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07256
Policy Update Magnitude: 0.66018
Value Function Update Magnitude: 0.86214

Collected Steps per Second: 22,441.04044
Overall Steps per Second: 10,745.24009

Timestep Collection Time: 2.22851
Timestep Consumption Time: 2.42565
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.65415

Cumulative Model Updates: 57,062
Cumulative Timesteps: 475,903,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,339.55222
Policy Entropy: 3.71748
Value Function Loss: 0.05461

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06879
Policy Update Magnitude: 0.64815
Value Function Update Magnitude: 0.83183

Collected Steps per Second: 22,902.82005
Overall Steps per Second: 10,857.63204

Timestep Collection Time: 2.18427
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.60745

Cumulative Model Updates: 57,068
Cumulative Timesteps: 475,953,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 475953340...
Checkpoint 475953340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,859.70439
Policy Entropy: 3.71839
Value Function Loss: 0.05503

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.62725
Value Function Update Magnitude: 0.87352

Collected Steps per Second: 22,682.12242
Overall Steps per Second: 10,669.81421

Timestep Collection Time: 2.20456
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.68649

Cumulative Model Updates: 57,074
Cumulative Timesteps: 476,003,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,221.97887
Policy Entropy: 3.71159
Value Function Loss: 0.05629

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.53809
Value Function Update Magnitude: 0.91364

Collected Steps per Second: 22,564.27703
Overall Steps per Second: 10,621.46735

Timestep Collection Time: 2.21625
Timestep Consumption Time: 2.49195
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.70820

Cumulative Model Updates: 57,080
Cumulative Timesteps: 476,053,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 476053352...
Checkpoint 476053352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,606.46653
Policy Entropy: 3.72107
Value Function Loss: 0.05532

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.50916
Value Function Update Magnitude: 0.92816

Collected Steps per Second: 22,669.60548
Overall Steps per Second: 10,700.63536

Timestep Collection Time: 2.20674
Timestep Consumption Time: 2.46831
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.67505

Cumulative Model Updates: 57,086
Cumulative Timesteps: 476,103,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,677.66676
Policy Entropy: 3.73108
Value Function Loss: 0.05381

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.50011
Value Function Update Magnitude: 0.87815

Collected Steps per Second: 23,148.46423
Overall Steps per Second: 10,714.45788

Timestep Collection Time: 2.16040
Timestep Consumption Time: 2.50712
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.66752

Cumulative Model Updates: 57,092
Cumulative Timesteps: 476,153,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 476153388...
Checkpoint 476153388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,285.48462
Policy Entropy: 3.73615
Value Function Loss: 0.05404

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.55452
Value Function Update Magnitude: 0.85945

Collected Steps per Second: 22,628.73897
Overall Steps per Second: 10,620.98928

Timestep Collection Time: 2.20958
Timestep Consumption Time: 2.49808
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.70766

Cumulative Model Updates: 57,098
Cumulative Timesteps: 476,203,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,230.99033
Policy Entropy: 3.73170
Value Function Loss: 0.05352

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.54717
Value Function Update Magnitude: 0.86887

Collected Steps per Second: 22,560.38543
Overall Steps per Second: 10,644.73678

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.48168
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.69866

Cumulative Model Updates: 57,104
Cumulative Timesteps: 476,253,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 476253404...
Checkpoint 476253404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,807.57426
Policy Entropy: 3.73039
Value Function Loss: 0.05564

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.47730
Value Function Update Magnitude: 0.87987

Collected Steps per Second: 22,644.61082
Overall Steps per Second: 10,807.79415

Timestep Collection Time: 2.20936
Timestep Consumption Time: 2.41971
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.62907

Cumulative Model Updates: 57,110
Cumulative Timesteps: 476,303,434

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.83593
Policy Entropy: 3.73602
Value Function Loss: 0.05327

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.50976
Value Function Update Magnitude: 0.88975

Collected Steps per Second: 22,851.99601
Overall Steps per Second: 10,638.89634

Timestep Collection Time: 2.18808
Timestep Consumption Time: 2.51184
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.69992

Cumulative Model Updates: 57,116
Cumulative Timesteps: 476,353,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 476353436...
Checkpoint 476353436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,956.92898
Policy Entropy: 3.74225
Value Function Loss: 0.05256

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07096
Policy Update Magnitude: 0.57954
Value Function Update Magnitude: 0.83977

Collected Steps per Second: 22,808.44399
Overall Steps per Second: 10,676.47146

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.49242
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.68582

Cumulative Model Updates: 57,122
Cumulative Timesteps: 476,403,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,194.69773
Policy Entropy: 3.74577
Value Function Loss: 0.05077

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.84125

Collected Steps per Second: 22,926.87028
Overall Steps per Second: 10,777.18190

Timestep Collection Time: 2.18146
Timestep Consumption Time: 2.45927
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.64073

Cumulative Model Updates: 57,128
Cumulative Timesteps: 476,453,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 476453478...
Checkpoint 476453478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,955.73795
Policy Entropy: 3.73616
Value Function Loss: 0.04938

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.49107
Value Function Update Magnitude: 0.85452

Collected Steps per Second: 22,507.14557
Overall Steps per Second: 10,628.98087

Timestep Collection Time: 2.22267
Timestep Consumption Time: 2.48389
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.70657

Cumulative Model Updates: 57,134
Cumulative Timesteps: 476,503,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,951.41030
Policy Entropy: 3.72531
Value Function Loss: 0.04745

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06510
Policy Update Magnitude: 0.56829
Value Function Update Magnitude: 0.84678

Collected Steps per Second: 22,975.75534
Overall Steps per Second: 10,907.92680

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.40858
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.58566

Cumulative Model Updates: 57,140
Cumulative Timesteps: 476,553,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 476553524...
Checkpoint 476553524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,057.16208
Policy Entropy: 3.73328
Value Function Loss: 0.04588

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05990
Policy Update Magnitude: 0.65761
Value Function Update Magnitude: 0.84380

Collected Steps per Second: 22,608.59805
Overall Steps per Second: 10,618.15682

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.49897
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.71193

Cumulative Model Updates: 57,146
Cumulative Timesteps: 476,603,556

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,620.01762
Policy Entropy: 3.74146
Value Function Loss: 0.04542

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.65358
Value Function Update Magnitude: 0.83763

Collected Steps per Second: 22,698.78987
Overall Steps per Second: 10,647.32295

Timestep Collection Time: 2.20276
Timestep Consumption Time: 2.49326
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.69602

Cumulative Model Updates: 57,152
Cumulative Timesteps: 476,653,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 476653556...
Checkpoint 476653556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,757.77757
Policy Entropy: 3.74462
Value Function Loss: 0.04791

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06563
Policy Update Magnitude: 0.65465
Value Function Update Magnitude: 0.82972

Collected Steps per Second: 22,787.17652
Overall Steps per Second: 10,842.66264

Timestep Collection Time: 2.19466
Timestep Consumption Time: 2.41768
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61234

Cumulative Model Updates: 57,158
Cumulative Timesteps: 476,703,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,398.10486
Policy Entropy: 3.74049
Value Function Loss: 0.04771

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.62201
Value Function Update Magnitude: 0.84561

Collected Steps per Second: 22,916.58847
Overall Steps per Second: 10,705.77206

Timestep Collection Time: 2.18191
Timestep Consumption Time: 2.48865
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.67056

Cumulative Model Updates: 57,164
Cumulative Timesteps: 476,753,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 476753568...
Checkpoint 476753568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,851.17500
Policy Entropy: 3.73326
Value Function Loss: 0.04923

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07340
Policy Update Magnitude: 0.61853
Value Function Update Magnitude: 0.83413

Collected Steps per Second: 22,909.70161
Overall Steps per Second: 10,844.28746

Timestep Collection Time: 2.18283
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.61146

Cumulative Model Updates: 57,170
Cumulative Timesteps: 476,803,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,401.46679
Policy Entropy: 3.73649
Value Function Loss: 0.05243

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.61373
Value Function Update Magnitude: 0.72856

Collected Steps per Second: 23,019.89723
Overall Steps per Second: 10,730.24044

Timestep Collection Time: 2.17308
Timestep Consumption Time: 2.48889
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.66196

Cumulative Model Updates: 57,176
Cumulative Timesteps: 476,853,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 476853600...
Checkpoint 476853600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,298.07232
Policy Entropy: 3.72844
Value Function Loss: 0.05786

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07146
Policy Update Magnitude: 0.65058
Value Function Update Magnitude: 0.63967

Collected Steps per Second: 22,503.79136
Overall Steps per Second: 10,666.62025

Timestep Collection Time: 2.22229
Timestep Consumption Time: 2.46617
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.68846

Cumulative Model Updates: 57,182
Cumulative Timesteps: 476,903,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,005.50552
Policy Entropy: 3.73825
Value Function Loss: 0.05920

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.61834
Value Function Update Magnitude: 0.63984

Collected Steps per Second: 22,772.10092
Overall Steps per Second: 10,682.52699

Timestep Collection Time: 2.19576
Timestep Consumption Time: 2.48497
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.68073

Cumulative Model Updates: 57,188
Cumulative Timesteps: 476,953,612

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 476953612...
Checkpoint 476953612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,452.40611
Policy Entropy: 3.75149
Value Function Loss: 0.06106

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.70341

Collected Steps per Second: 22,805.81898
Overall Steps per Second: 10,732.68577

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.46654
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.65923

Cumulative Model Updates: 57,194
Cumulative Timesteps: 477,003,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,062.54619
Policy Entropy: 3.74984
Value Function Loss: 0.05974

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06369
Policy Update Magnitude: 0.60720
Value Function Update Magnitude: 0.64142

Collected Steps per Second: 22,971.33455
Overall Steps per Second: 10,882.87053

Timestep Collection Time: 2.17793
Timestep Consumption Time: 2.41920
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.59713

Cumulative Model Updates: 57,200
Cumulative Timesteps: 477,053,648

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 477053648...
Checkpoint 477053648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,741.97159
Policy Entropy: 3.75276
Value Function Loss: 0.05812

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.63850
Value Function Update Magnitude: 0.63073

Collected Steps per Second: 22,676.14523
Overall Steps per Second: 10,643.84943

Timestep Collection Time: 2.20496
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.69755

Cumulative Model Updates: 57,206
Cumulative Timesteps: 477,103,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,303.45168
Policy Entropy: 3.74745
Value Function Loss: 0.05763

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07279
Policy Update Magnitude: 0.62741
Value Function Update Magnitude: 0.61741

Collected Steps per Second: 23,130.70954
Overall Steps per Second: 10,791.97110

Timestep Collection Time: 2.16301
Timestep Consumption Time: 2.47303
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.63604

Cumulative Model Updates: 57,212
Cumulative Timesteps: 477,153,680

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 477153680...
Checkpoint 477153680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,957.97096
Policy Entropy: 3.75782
Value Function Loss: 0.05529

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.62379
Value Function Update Magnitude: 0.61951

Collected Steps per Second: 22,723.93338
Overall Steps per Second: 10,651.54302

Timestep Collection Time: 2.20103
Timestep Consumption Time: 2.49463
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.69566

Cumulative Model Updates: 57,218
Cumulative Timesteps: 477,203,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,334.20636
Policy Entropy: 3.75727
Value Function Loss: 0.05699

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.57752
Value Function Update Magnitude: 0.63872

Collected Steps per Second: 22,913.02360
Overall Steps per Second: 10,847.27111

Timestep Collection Time: 2.18400
Timestep Consumption Time: 2.42933
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.61333

Cumulative Model Updates: 57,224
Cumulative Timesteps: 477,253,738

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 477253738...
Checkpoint 477253738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,703.41182
Policy Entropy: 3.74752
Value Function Loss: 0.05663

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.50915
Value Function Update Magnitude: 0.65550

Collected Steps per Second: 22,653.30786
Overall Steps per Second: 10,722.60614

Timestep Collection Time: 2.20771
Timestep Consumption Time: 2.45645
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.66416

Cumulative Model Updates: 57,230
Cumulative Timesteps: 477,303,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,128.86217
Policy Entropy: 3.73921
Value Function Loss: 0.05757

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.15408
Policy Update Magnitude: 0.46198
Value Function Update Magnitude: 0.67959

Collected Steps per Second: 22,903.13887
Overall Steps per Second: 10,829.84083

Timestep Collection Time: 2.18354
Timestep Consumption Time: 2.43425
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61780

Cumulative Model Updates: 57,236
Cumulative Timesteps: 477,353,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 477353760...
Checkpoint 477353760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.70295
Policy Entropy: 3.75611
Value Function Loss: 0.05848

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.44475
Value Function Update Magnitude: 0.70043

Collected Steps per Second: 22,391.52020
Overall Steps per Second: 10,742.25429

Timestep Collection Time: 2.23352
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.65563

Cumulative Model Updates: 57,242
Cumulative Timesteps: 477,403,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,825.92595
Policy Entropy: 3.75962
Value Function Loss: 0.05658

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10541
Policy Update Magnitude: 0.45523
Value Function Update Magnitude: 0.73760

Collected Steps per Second: 22,736.97443
Overall Steps per Second: 10,790.26550

Timestep Collection Time: 2.19994
Timestep Consumption Time: 2.43572
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.63566

Cumulative Model Updates: 57,248
Cumulative Timesteps: 477,453,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 477453792...
Checkpoint 477453792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.50002
Policy Entropy: 3.76287
Value Function Loss: 0.05513

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.45608
Value Function Update Magnitude: 0.70649

Collected Steps per Second: 22,683.63758
Overall Steps per Second: 10,729.01651

Timestep Collection Time: 2.20511
Timestep Consumption Time: 2.45701
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.66212

Cumulative Model Updates: 57,254
Cumulative Timesteps: 477,503,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,375.25811
Policy Entropy: 3.74358
Value Function Loss: 0.05336

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.47498
Value Function Update Magnitude: 0.72015

Collected Steps per Second: 22,798.10443
Overall Steps per Second: 10,813.71169

Timestep Collection Time: 2.19352
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.62450

Cumulative Model Updates: 57,260
Cumulative Timesteps: 477,553,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 477553820...
Checkpoint 477553820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,602.27874
Policy Entropy: 3.73982
Value Function Loss: 0.05507

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.49169
Value Function Update Magnitude: 0.68451

Collected Steps per Second: 22,410.53621
Overall Steps per Second: 10,747.18095

Timestep Collection Time: 2.23145
Timestep Consumption Time: 2.42168
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.65313

Cumulative Model Updates: 57,266
Cumulative Timesteps: 477,603,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,118.29765
Policy Entropy: 3.72955
Value Function Loss: 0.05510

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.59428
Value Function Update Magnitude: 0.69660

Collected Steps per Second: 22,700.13959
Overall Steps per Second: 10,681.89901

Timestep Collection Time: 2.20386
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.68344

Cumulative Model Updates: 57,272
Cumulative Timesteps: 477,653,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 477653856...
Checkpoint 477653856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,740.76020
Policy Entropy: 3.74096
Value Function Loss: 0.05658

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.55484
Value Function Update Magnitude: 0.69181

Collected Steps per Second: 22,659.73050
Overall Steps per Second: 10,806.16558

Timestep Collection Time: 2.20673
Timestep Consumption Time: 2.42062
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.62736

Cumulative Model Updates: 57,278
Cumulative Timesteps: 477,703,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,224.15294
Policy Entropy: 3.73973
Value Function Loss: 0.05262

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.52231
Value Function Update Magnitude: 0.74592

Collected Steps per Second: 22,915.81455
Overall Steps per Second: 10,849.72643

Timestep Collection Time: 2.18303
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61081

Cumulative Model Updates: 57,284
Cumulative Timesteps: 477,753,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 477753886...
Checkpoint 477753886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,094.93458
Policy Entropy: 3.75013
Value Function Loss: 0.04969

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.61516
Value Function Update Magnitude: 0.80920

Collected Steps per Second: 22,172.70027
Overall Steps per Second: 10,742.18358

Timestep Collection Time: 2.25530
Timestep Consumption Time: 2.39981
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.65511

Cumulative Model Updates: 57,290
Cumulative Timesteps: 477,803,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,569.46592
Policy Entropy: 3.75160
Value Function Loss: 0.04620

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.60417
Value Function Update Magnitude: 0.80738

Collected Steps per Second: 22,115.85476
Overall Steps per Second: 10,844.55942

Timestep Collection Time: 2.26136
Timestep Consumption Time: 2.35035
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.61171

Cumulative Model Updates: 57,296
Cumulative Timesteps: 477,853,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 477853904...
Checkpoint 477853904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,806.26827
Policy Entropy: 3.74856
Value Function Loss: 0.04789

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.57147
Value Function Update Magnitude: 0.77729

Collected Steps per Second: 22,022.09150
Overall Steps per Second: 10,700.63111

Timestep Collection Time: 2.27054
Timestep Consumption Time: 2.40227
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.67281

Cumulative Model Updates: 57,302
Cumulative Timesteps: 477,903,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,611.32480
Policy Entropy: 3.75939
Value Function Loss: 0.04944

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.55757
Value Function Update Magnitude: 0.78223

Collected Steps per Second: 22,292.12749
Overall Steps per Second: 10,867.59747

Timestep Collection Time: 2.24402
Timestep Consumption Time: 2.35902
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.60304

Cumulative Model Updates: 57,308
Cumulative Timesteps: 477,953,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 477953930...
Checkpoint 477953930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,841.01268
Policy Entropy: 3.74901
Value Function Loss: 0.05131

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.51029
Value Function Update Magnitude: 0.80636

Collected Steps per Second: 22,043.52870
Overall Steps per Second: 10,696.59375

Timestep Collection Time: 2.26951
Timestep Consumption Time: 2.40749
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.67700

Cumulative Model Updates: 57,314
Cumulative Timesteps: 478,003,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,026.77159
Policy Entropy: 3.76173
Value Function Loss: 0.05153

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.46065
Value Function Update Magnitude: 0.80898

Collected Steps per Second: 22,947.47449
Overall Steps per Second: 10,898.40118

Timestep Collection Time: 2.17950
Timestep Consumption Time: 2.40961
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.58911

Cumulative Model Updates: 57,320
Cumulative Timesteps: 478,053,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 478053972...
Checkpoint 478053972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,846.01728
Policy Entropy: 3.73669
Value Function Loss: 0.05101

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.45514
Value Function Update Magnitude: 0.81294

Collected Steps per Second: 22,645.32083
Overall Steps per Second: 10,661.01353

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.48282
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.69149

Cumulative Model Updates: 57,326
Cumulative Timesteps: 478,103,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,481.84482
Policy Entropy: 3.74566
Value Function Loss: 0.05082

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.47285
Value Function Update Magnitude: 0.80539

Collected Steps per Second: 22,976.08642
Overall Steps per Second: 10,940.27132

Timestep Collection Time: 2.17644
Timestep Consumption Time: 2.39438
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.57082

Cumulative Model Updates: 57,332
Cumulative Timesteps: 478,153,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 478153994...
Checkpoint 478153994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,254.80296
Policy Entropy: 3.73684
Value Function Loss: 0.05040

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.46521
Value Function Update Magnitude: 0.81310

Collected Steps per Second: 23,095.45336
Overall Steps per Second: 10,968.61731

Timestep Collection Time: 2.16718
Timestep Consumption Time: 2.39602
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.56320

Cumulative Model Updates: 57,338
Cumulative Timesteps: 478,204,046

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,786.25828
Policy Entropy: 3.74784
Value Function Loss: 0.05022

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.47899
Value Function Update Magnitude: 0.81990

Collected Steps per Second: 22,666.00130
Overall Steps per Second: 10,625.32996

Timestep Collection Time: 2.20709
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.70818

Cumulative Model Updates: 57,344
Cumulative Timesteps: 478,254,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 478254072...
Checkpoint 478254072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,942.73387
Policy Entropy: 3.74422
Value Function Loss: 0.05255

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.56085
Value Function Update Magnitude: 0.81674

Collected Steps per Second: 22,720.41633
Overall Steps per Second: 10,632.92078

Timestep Collection Time: 2.20066
Timestep Consumption Time: 2.50171
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.70238

Cumulative Model Updates: 57,350
Cumulative Timesteps: 478,304,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,547.77795
Policy Entropy: 3.76068
Value Function Loss: 0.05444

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.54406
Value Function Update Magnitude: 0.79807

Collected Steps per Second: 23,138.74820
Overall Steps per Second: 10,821.18020

Timestep Collection Time: 2.16166
Timestep Consumption Time: 2.46058
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.62223

Cumulative Model Updates: 57,356
Cumulative Timesteps: 478,354,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 478354090...
Checkpoint 478354090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,329.18467
Policy Entropy: 3.77048
Value Function Loss: 0.05362

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.53291
Value Function Update Magnitude: 0.79359

Collected Steps per Second: 22,655.16731
Overall Steps per Second: 10,633.96293

Timestep Collection Time: 2.20797
Timestep Consumption Time: 2.49601
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.70398

Cumulative Model Updates: 57,362
Cumulative Timesteps: 478,404,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,367.16917
Policy Entropy: 3.76578
Value Function Loss: 0.05391

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07436
Policy Update Magnitude: 0.62342
Value Function Update Magnitude: 0.80477

Collected Steps per Second: 22,914.29485
Overall Steps per Second: 10,845.05778

Timestep Collection Time: 2.18213
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.61058

Cumulative Model Updates: 57,368
Cumulative Timesteps: 478,454,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 478454114...
Checkpoint 478454114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,563.94475
Policy Entropy: 3.77064
Value Function Loss: 0.05470

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.65763
Value Function Update Magnitude: 0.80091

Collected Steps per Second: 22,850.75166
Overall Steps per Second: 10,715.74877

Timestep Collection Time: 2.18872
Timestep Consumption Time: 2.47861
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.66734

Cumulative Model Updates: 57,374
Cumulative Timesteps: 478,504,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,679.55961
Policy Entropy: 3.76929
Value Function Loss: 0.05572

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.54341
Value Function Update Magnitude: 0.80178

Collected Steps per Second: 22,827.46038
Overall Steps per Second: 10,810.24050

Timestep Collection Time: 2.19034
Timestep Consumption Time: 2.43490
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.62524

Cumulative Model Updates: 57,380
Cumulative Timesteps: 478,554,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 478554128...
Checkpoint 478554128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,157.69484
Policy Entropy: 3.76535
Value Function Loss: 0.05589

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.49547
Value Function Update Magnitude: 0.76831

Collected Steps per Second: 22,524.47542
Overall Steps per Second: 10,770.91756

Timestep Collection Time: 2.22007
Timestep Consumption Time: 2.42261
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.64269

Cumulative Model Updates: 57,386
Cumulative Timesteps: 478,604,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,111.28565
Policy Entropy: 3.76711
Value Function Loss: 0.05490

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.50251
Value Function Update Magnitude: 0.75445

Collected Steps per Second: 23,037.94599
Overall Steps per Second: 10,883.81004

Timestep Collection Time: 2.17051
Timestep Consumption Time: 2.42384
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.59435

Cumulative Model Updates: 57,392
Cumulative Timesteps: 478,654,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 478654138...
Checkpoint 478654138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,033.31619
Policy Entropy: 3.76077
Value Function Loss: 0.05763

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.49032
Value Function Update Magnitude: 0.69708

Collected Steps per Second: 22,435.35737
Overall Steps per Second: 10,620.51297

Timestep Collection Time: 2.22907
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.70881

Cumulative Model Updates: 57,398
Cumulative Timesteps: 478,704,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,940.93921
Policy Entropy: 3.76399
Value Function Loss: 0.05870

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.46868
Value Function Update Magnitude: 0.58061

Collected Steps per Second: 23,210.81880
Overall Steps per Second: 10,875.58599

Timestep Collection Time: 2.15512
Timestep Consumption Time: 2.44436
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.59948

Cumulative Model Updates: 57,404
Cumulative Timesteps: 478,754,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 478754170...
Checkpoint 478754170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,945.33379
Policy Entropy: 3.75538
Value Function Loss: 0.06103

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.49550
Value Function Update Magnitude: 0.59433

Collected Steps per Second: 22,557.72334
Overall Steps per Second: 10,633.17487

Timestep Collection Time: 2.21778
Timestep Consumption Time: 2.48712
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.70490

Cumulative Model Updates: 57,410
Cumulative Timesteps: 478,804,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,447.08203
Policy Entropy: 3.76453
Value Function Loss: 0.06095

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.49422
Value Function Update Magnitude: 0.59757

Collected Steps per Second: 22,708.25619
Overall Steps per Second: 10,643.42987

Timestep Collection Time: 2.20299
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.70018

Cumulative Model Updates: 57,416
Cumulative Timesteps: 478,854,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 478854224...
Checkpoint 478854224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,294.08281
Policy Entropy: 3.76680
Value Function Loss: 0.05971

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.46756
Value Function Update Magnitude: 0.61445

Collected Steps per Second: 22,947.49543
Overall Steps per Second: 10,841.25188

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.43361
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61294

Cumulative Model Updates: 57,422
Cumulative Timesteps: 478,904,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,154.93808
Policy Entropy: 3.75191
Value Function Loss: 0.05968

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.50062
Value Function Update Magnitude: 0.62848

Collected Steps per Second: 22,897.59525
Overall Steps per Second: 10,703.64243

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.48916
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.67411

Cumulative Model Updates: 57,428
Cumulative Timesteps: 478,954,264

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 478954264...
Checkpoint 478954264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,269.09751
Policy Entropy: 3.75449
Value Function Loss: 0.05737

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.51172
Value Function Update Magnitude: 0.68389

Collected Steps per Second: 22,697.25780
Overall Steps per Second: 10,647.19294

Timestep Collection Time: 2.20405
Timestep Consumption Time: 2.49446
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.69852

Cumulative Model Updates: 57,434
Cumulative Timesteps: 479,004,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,312.39744
Policy Entropy: 3.74193
Value Function Loss: 0.05694

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.53640
Value Function Update Magnitude: 0.76230

Collected Steps per Second: 22,930.56131
Overall Steps per Second: 10,755.85689

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.46902
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.65030

Cumulative Model Updates: 57,440
Cumulative Timesteps: 479,054,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 479054308...
Checkpoint 479054308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,464.11881
Policy Entropy: 3.75553
Value Function Loss: 0.05539

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.78139

Collected Steps per Second: 22,710.32773
Overall Steps per Second: 10,713.67450

Timestep Collection Time: 2.20164
Timestep Consumption Time: 2.46529
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.66693

Cumulative Model Updates: 57,446
Cumulative Timesteps: 479,104,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,487.44438
Policy Entropy: 3.75892
Value Function Loss: 0.05365

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.51010
Value Function Update Magnitude: 0.79327

Collected Steps per Second: 22,966.88942
Overall Steps per Second: 10,852.57591

Timestep Collection Time: 2.17800
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.60923

Cumulative Model Updates: 57,452
Cumulative Timesteps: 479,154,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 479154330...
Checkpoint 479154330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,040.75934
Policy Entropy: 3.76199
Value Function Loss: 0.05264

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.49959
Value Function Update Magnitude: 0.80506

Collected Steps per Second: 22,631.00189
Overall Steps per Second: 10,613.18758

Timestep Collection Time: 2.21060
Timestep Consumption Time: 2.50316
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.71376

Cumulative Model Updates: 57,458
Cumulative Timesteps: 479,204,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,914.30040
Policy Entropy: 3.75458
Value Function Loss: 0.05236

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.47686
Value Function Update Magnitude: 0.80562

Collected Steps per Second: 22,889.82430
Overall Steps per Second: 10,825.61037

Timestep Collection Time: 2.18490
Timestep Consumption Time: 2.43488
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61979

Cumulative Model Updates: 57,464
Cumulative Timesteps: 479,254,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479254370...
Checkpoint 479254370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,712.45795
Policy Entropy: 3.74954
Value Function Loss: 0.05635

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.46012
Value Function Update Magnitude: 0.69264

Collected Steps per Second: 22,758.50878
Overall Steps per Second: 10,710.36358

Timestep Collection Time: 2.19698
Timestep Consumption Time: 2.47140
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.66838

Cumulative Model Updates: 57,470
Cumulative Timesteps: 479,304,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,445.89762
Policy Entropy: 3.74839
Value Function Loss: 0.05767

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06400
Policy Update Magnitude: 0.53039
Value Function Update Magnitude: 0.67513

Collected Steps per Second: 22,797.08760
Overall Steps per Second: 10,803.08606

Timestep Collection Time: 2.19379
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.62942

Cumulative Model Updates: 57,476
Cumulative Timesteps: 479,354,382

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479354382...
Checkpoint 479354382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,599.65356
Policy Entropy: 3.74117
Value Function Loss: 0.05790

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.70662

Collected Steps per Second: 22,285.62663
Overall Steps per Second: 10,694.93944

Timestep Collection Time: 2.24387
Timestep Consumption Time: 2.43180
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.67567

Cumulative Model Updates: 57,482
Cumulative Timesteps: 479,404,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,834.87046
Policy Entropy: 3.75268
Value Function Loss: 0.05720

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09497
Policy Update Magnitude: 0.50532
Value Function Update Magnitude: 0.69639

Collected Steps per Second: 22,442.90107
Overall Steps per Second: 10,579.96081

Timestep Collection Time: 2.22805
Timestep Consumption Time: 2.49824
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.72629

Cumulative Model Updates: 57,488
Cumulative Timesteps: 479,454,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 479454392...
Checkpoint 479454392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,025.33316
Policy Entropy: 3.77006
Value Function Loss: 0.05481

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.52540
Value Function Update Magnitude: 0.71998

Collected Steps per Second: 22,865.96520
Overall Steps per Second: 10,713.21263

Timestep Collection Time: 2.18666
Timestep Consumption Time: 2.48048
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.66713

Cumulative Model Updates: 57,494
Cumulative Timesteps: 479,504,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,922.81403
Policy Entropy: 3.76564
Value Function Loss: 0.05430

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.53583
Value Function Update Magnitude: 0.71118

Collected Steps per Second: 22,979.32045
Overall Steps per Second: 10,698.32451

Timestep Collection Time: 2.17639
Timestep Consumption Time: 2.49836
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.67475

Cumulative Model Updates: 57,500
Cumulative Timesteps: 479,554,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479554404...
Checkpoint 479554404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,060.45515
Policy Entropy: 3.77252
Value Function Loss: 0.05461

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.52558
Value Function Update Magnitude: 0.66178

Collected Steps per Second: 22,767.59746
Overall Steps per Second: 10,625.73669

Timestep Collection Time: 2.19654
Timestep Consumption Time: 2.50995
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.70650

Cumulative Model Updates: 57,506
Cumulative Timesteps: 479,604,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,884.50511
Policy Entropy: 3.77114
Value Function Loss: 0.05750

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.48304
Value Function Update Magnitude: 0.65670

Collected Steps per Second: 22,979.33950
Overall Steps per Second: 10,862.66401

Timestep Collection Time: 2.17665
Timestep Consumption Time: 2.42793
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.60458

Cumulative Model Updates: 57,512
Cumulative Timesteps: 479,654,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 479654432...
Checkpoint 479654432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,009.13442
Policy Entropy: 3.76657
Value Function Loss: 0.05822

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06615
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.63237

Collected Steps per Second: 22,542.82833
Overall Steps per Second: 10,704.01283

Timestep Collection Time: 2.21844
Timestep Consumption Time: 2.45364
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.67208

Cumulative Model Updates: 57,518
Cumulative Timesteps: 479,704,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,745.10848
Policy Entropy: 3.76252
Value Function Loss: 0.05855

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06031
Policy Update Magnitude: 0.65437
Value Function Update Magnitude: 0.60012

Collected Steps per Second: 22,850.54366
Overall Steps per Second: 10,810.55057

Timestep Collection Time: 2.18936
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.62770

Cumulative Model Updates: 57,524
Cumulative Timesteps: 479,754,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 479754470...
Checkpoint 479754470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,223.39401
Policy Entropy: 3.74967
Value Function Loss: 0.05681

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07321
Policy Update Magnitude: 0.67225
Value Function Update Magnitude: 0.58512

Collected Steps per Second: 22,730.57653
Overall Steps per Second: 10,740.42039

Timestep Collection Time: 2.19994
Timestep Consumption Time: 2.45593
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.65587

Cumulative Model Updates: 57,530
Cumulative Timesteps: 479,804,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,715.34160
Policy Entropy: 3.74457
Value Function Loss: 0.05705

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.65478
Value Function Update Magnitude: 0.59111

Collected Steps per Second: 22,412.60090
Overall Steps per Second: 10,583.46118

Timestep Collection Time: 2.23116
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.72492

Cumulative Model Updates: 57,536
Cumulative Timesteps: 479,854,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 479854482...
Checkpoint 479854482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,149.17340
Policy Entropy: 3.73548
Value Function Loss: 0.05881

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.58262
Value Function Update Magnitude: 0.61076

Collected Steps per Second: 22,733.79860
Overall Steps per Second: 10,733.00635

Timestep Collection Time: 2.19998
Timestep Consumption Time: 2.45985
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.65983

Cumulative Model Updates: 57,542
Cumulative Timesteps: 479,904,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,779.55135
Policy Entropy: 3.72716
Value Function Loss: 0.05962

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.52918
Value Function Update Magnitude: 0.61951

Collected Steps per Second: 23,369.98273
Overall Steps per Second: 10,798.41618

Timestep Collection Time: 2.13975
Timestep Consumption Time: 2.49111
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.63086

Cumulative Model Updates: 57,548
Cumulative Timesteps: 479,954,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 479954502...
Checkpoint 479954502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,977.80194
Policy Entropy: 3.72329
Value Function Loss: 0.06116

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.53610
Value Function Update Magnitude: 0.59249

Collected Steps per Second: 22,824.57048
Overall Steps per Second: 10,756.02778

Timestep Collection Time: 2.19159
Timestep Consumption Time: 2.45902
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.65060

Cumulative Model Updates: 57,554
Cumulative Timesteps: 480,004,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,880.71805
Policy Entropy: 3.73481
Value Function Loss: 0.05813

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.53077
Value Function Update Magnitude: 0.59492

Collected Steps per Second: 22,675.43874
Overall Steps per Second: 10,665.85822

Timestep Collection Time: 2.20503
Timestep Consumption Time: 2.48283
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.68786

Cumulative Model Updates: 57,560
Cumulative Timesteps: 480,054,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 480054524...
Checkpoint 480054524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,443.80942
Policy Entropy: 3.73591
Value Function Loss: 0.05702

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.50485
Value Function Update Magnitude: 0.63887

Collected Steps per Second: 22,180.24952
Overall Steps per Second: 10,706.95718

Timestep Collection Time: 2.25480
Timestep Consumption Time: 2.41618
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.67098

Cumulative Model Updates: 57,566
Cumulative Timesteps: 480,104,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,608.46681
Policy Entropy: 3.73817
Value Function Loss: 0.05445

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.53060
Value Function Update Magnitude: 0.67193

Collected Steps per Second: 22,240.20947
Overall Steps per Second: 10,818.48724

Timestep Collection Time: 2.24863
Timestep Consumption Time: 2.37401
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.62264

Cumulative Model Updates: 57,572
Cumulative Timesteps: 480,154,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 480154546...
Checkpoint 480154546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,374.37541
Policy Entropy: 3.72909
Value Function Loss: 0.05498

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.56953
Value Function Update Magnitude: 0.73445

Collected Steps per Second: 21,897.51176
Overall Steps per Second: 10,655.94295

Timestep Collection Time: 2.28428
Timestep Consumption Time: 2.40982
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.69409

Cumulative Model Updates: 57,578
Cumulative Timesteps: 480,204,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.09620
Policy Entropy: 3.74425
Value Function Loss: 0.05461

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.49947
Value Function Update Magnitude: 0.76048

Collected Steps per Second: 22,007.89541
Overall Steps per Second: 10,821.64173

Timestep Collection Time: 2.27355
Timestep Consumption Time: 2.35015
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.62370

Cumulative Model Updates: 57,584
Cumulative Timesteps: 480,254,602

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 480254602...
Checkpoint 480254602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,961.08517
Policy Entropy: 3.73793
Value Function Loss: 0.05411

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.53485
Value Function Update Magnitude: 0.79666

Collected Steps per Second: 21,507.13620
Overall Steps per Second: 10,700.63003

Timestep Collection Time: 2.32546
Timestep Consumption Time: 2.34847
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.67393

Cumulative Model Updates: 57,590
Cumulative Timesteps: 480,304,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,219.61917
Policy Entropy: 3.74476
Value Function Loss: 0.05271

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.78432

Collected Steps per Second: 22,382.83156
Overall Steps per Second: 10,619.50556

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.47466
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.70869

Cumulative Model Updates: 57,596
Cumulative Timesteps: 480,354,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 480354620...
Checkpoint 480354620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,349.65671
Policy Entropy: 3.75001
Value Function Loss: 0.05623

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.59647
Value Function Update Magnitude: 0.68920

Collected Steps per Second: 22,639.49113
Overall Steps per Second: 10,862.70328

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.39552
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.60512

Cumulative Model Updates: 57,602
Cumulative Timesteps: 480,404,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,761.33278
Policy Entropy: 3.73958
Value Function Loss: 0.05718

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.59075
Value Function Update Magnitude: 0.69870

Collected Steps per Second: 22,776.07822
Overall Steps per Second: 10,743.35532

Timestep Collection Time: 2.19643
Timestep Consumption Time: 2.46003
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.65646

Cumulative Model Updates: 57,608
Cumulative Timesteps: 480,454,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 480454670...
Checkpoint 480454670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,708.48643
Policy Entropy: 3.72801
Value Function Loss: 0.05821

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.15056
Policy Update Magnitude: 0.53171
Value Function Update Magnitude: 0.75504

Collected Steps per Second: 22,815.85537
Overall Steps per Second: 10,898.79993

Timestep Collection Time: 2.19207
Timestep Consumption Time: 2.39687
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.58895

Cumulative Model Updates: 57,614
Cumulative Timesteps: 480,504,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,433.30097
Policy Entropy: 3.73035
Value Function Loss: 0.05607

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.15552
Policy Update Magnitude: 0.41228
Value Function Update Magnitude: 0.76926

Collected Steps per Second: 23,014.92901
Overall Steps per Second: 10,836.48119

Timestep Collection Time: 2.17320
Timestep Consumption Time: 2.44232
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.61552

Cumulative Model Updates: 57,620
Cumulative Timesteps: 480,554,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 480554700...
Checkpoint 480554700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,590.75637
Policy Entropy: 3.73564
Value Function Loss: 0.05737

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.43424
Value Function Update Magnitude: 0.73893

Collected Steps per Second: 23,006.32971
Overall Steps per Second: 10,707.50028

Timestep Collection Time: 2.17375
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.67056

Cumulative Model Updates: 57,626
Cumulative Timesteps: 480,604,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,291.70777
Policy Entropy: 3.73148
Value Function Loss: 0.05626

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.52346
Value Function Update Magnitude: 0.69977

Collected Steps per Second: 22,712.47793
Overall Steps per Second: 10,815.59844

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.42259
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.62499

Cumulative Model Updates: 57,632
Cumulative Timesteps: 480,654,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 480654732...
Checkpoint 480654732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,782.80366
Policy Entropy: 3.73681
Value Function Loss: 0.05563

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.55905
Value Function Update Magnitude: 0.77991

Collected Steps per Second: 22,517.47880
Overall Steps per Second: 10,784.55259

Timestep Collection Time: 2.22112
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.63756

Cumulative Model Updates: 57,638
Cumulative Timesteps: 480,704,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,253.23656
Policy Entropy: 3.74721
Value Function Loss: 0.05497

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.53726
Value Function Update Magnitude: 0.83607

Collected Steps per Second: 22,825.30057
Overall Steps per Second: 10,806.71097

Timestep Collection Time: 2.19152
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.62879

Cumulative Model Updates: 57,644
Cumulative Timesteps: 480,754,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 480754768...
Checkpoint 480754768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,834.77483
Policy Entropy: 3.74422
Value Function Loss: 0.05524

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.52847
Value Function Update Magnitude: 0.83956

Collected Steps per Second: 22,486.70795
Overall Steps per Second: 10,676.25687

Timestep Collection Time: 2.22398
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.68423

Cumulative Model Updates: 57,650
Cumulative Timesteps: 480,804,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,406.79717
Policy Entropy: 3.74243
Value Function Loss: 0.05656

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11820
Policy Update Magnitude: 0.52867
Value Function Update Magnitude: 0.82877

Collected Steps per Second: 22,599.36942
Overall Steps per Second: 10,653.46386

Timestep Collection Time: 2.21298
Timestep Consumption Time: 2.48145
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.69444

Cumulative Model Updates: 57,656
Cumulative Timesteps: 480,854,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 480854790...
Checkpoint 480854790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,284.57754
Policy Entropy: 3.74680
Value Function Loss: 0.05721

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.52096
Value Function Update Magnitude: 0.79986

Collected Steps per Second: 22,518.85157
Overall Steps per Second: 10,788.08622

Timestep Collection Time: 2.22161
Timestep Consumption Time: 2.41573
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.63734

Cumulative Model Updates: 57,662
Cumulative Timesteps: 480,904,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,389.91151
Policy Entropy: 3.75411
Value Function Loss: 0.05498

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.53754
Value Function Update Magnitude: 0.78720

Collected Steps per Second: 22,828.28621
Overall Steps per Second: 10,627.14381

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.51598
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.70738

Cumulative Model Updates: 57,668
Cumulative Timesteps: 480,954,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 480954844...
Checkpoint 480954844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,432.01533
Policy Entropy: 3.75850
Value Function Loss: 0.05271

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11760
Policy Update Magnitude: 0.54255
Value Function Update Magnitude: 0.77909

Collected Steps per Second: 22,653.93868
Overall Steps per Second: 10,643.68993

Timestep Collection Time: 2.20721
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.69781

Cumulative Model Updates: 57,674
Cumulative Timesteps: 481,004,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,097.47739
Policy Entropy: 3.75155
Value Function Loss: 0.05178

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.50631
Value Function Update Magnitude: 0.76875

Collected Steps per Second: 22,741.78186
Overall Steps per Second: 10,849.12004

Timestep Collection Time: 2.19877
Timestep Consumption Time: 2.41027
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.60904

Cumulative Model Updates: 57,680
Cumulative Timesteps: 481,054,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 481054850...
Checkpoint 481054850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,901.97130
Policy Entropy: 3.74433
Value Function Loss: 0.05062

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.77961

Collected Steps per Second: 22,586.93756
Overall Steps per Second: 10,604.80724

Timestep Collection Time: 2.21491
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.71748

Cumulative Model Updates: 57,686
Cumulative Timesteps: 481,104,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,011.88192
Policy Entropy: 3.74532
Value Function Loss: 0.05161

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07698
Policy Update Magnitude: 0.60188
Value Function Update Magnitude: 0.78711

Collected Steps per Second: 23,108.93840
Overall Steps per Second: 10,868.97390

Timestep Collection Time: 2.16488
Timestep Consumption Time: 2.43795
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60283

Cumulative Model Updates: 57,692
Cumulative Timesteps: 481,154,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 481154906...
Checkpoint 481154906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,967.16209
Policy Entropy: 3.74309
Value Function Loss: 0.05128

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.58493
Value Function Update Magnitude: 0.80527

Collected Steps per Second: 22,468.04855
Overall Steps per Second: 10,673.85485

Timestep Collection Time: 2.22592
Timestep Consumption Time: 2.45955
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.68547

Cumulative Model Updates: 57,698
Cumulative Timesteps: 481,204,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,137.74625
Policy Entropy: 3.73760
Value Function Loss: 0.05106

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.52351
Value Function Update Magnitude: 0.82970

Collected Steps per Second: 22,079.68921
Overall Steps per Second: 10,821.86744

Timestep Collection Time: 2.26561
Timestep Consumption Time: 2.35688
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62249

Cumulative Model Updates: 57,704
Cumulative Timesteps: 481,254,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 481254942...
Checkpoint 481254942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,890.83436
Policy Entropy: 3.72854
Value Function Loss: 0.05018

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.50187
Value Function Update Magnitude: 0.79381

Collected Steps per Second: 22,160.69870
Overall Steps per Second: 10,743.91433

Timestep Collection Time: 2.25634
Timestep Consumption Time: 2.39765
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.65398

Cumulative Model Updates: 57,710
Cumulative Timesteps: 481,304,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,141.90946
Policy Entropy: 3.71192
Value Function Loss: 0.05303

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.52952
Value Function Update Magnitude: 0.79086

Collected Steps per Second: 22,446.65890
Overall Steps per Second: 10,931.14777

Timestep Collection Time: 2.22893
Timestep Consumption Time: 2.34808
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.57701

Cumulative Model Updates: 57,716
Cumulative Timesteps: 481,354,976

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 481354976...
Checkpoint 481354976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,447.11360
Policy Entropy: 3.70481
Value Function Loss: 0.05451

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.50328
Value Function Update Magnitude: 0.77859

Collected Steps per Second: 21,934.24759
Overall Steps per Second: 10,568.07669

Timestep Collection Time: 2.28073
Timestep Consumption Time: 2.45296
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.73369

Cumulative Model Updates: 57,722
Cumulative Timesteps: 481,405,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,149.79724
Policy Entropy: 3.71693
Value Function Loss: 0.05628

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.50575
Value Function Update Magnitude: 0.78192

Collected Steps per Second: 22,787.88257
Overall Steps per Second: 10,903.60201

Timestep Collection Time: 2.19485
Timestep Consumption Time: 2.39226
PPO Batch Consumption Time: 0.27654
Total Iteration Time: 4.58711

Cumulative Model Updates: 57,728
Cumulative Timesteps: 481,455,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 481455018...
Checkpoint 481455018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,209.33010
Policy Entropy: 3.72747
Value Function Loss: 0.05459

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.48259
Value Function Update Magnitude: 0.78186

Collected Steps per Second: 22,654.25037
Overall Steps per Second: 10,666.15111

Timestep Collection Time: 2.20736
Timestep Consumption Time: 2.48093
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.68829

Cumulative Model Updates: 57,734
Cumulative Timesteps: 481,505,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,129.38600
Policy Entropy: 3.72496
Value Function Loss: 0.05413

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.49076
Value Function Update Magnitude: 0.78700

Collected Steps per Second: 22,921.52095
Overall Steps per Second: 10,874.15046

Timestep Collection Time: 2.18197
Timestep Consumption Time: 2.41738
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.59935

Cumulative Model Updates: 57,740
Cumulative Timesteps: 481,555,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 481555038...
Checkpoint 481555038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,562.49803
Policy Entropy: 3.71000
Value Function Loss: 0.05528

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.50235
Value Function Update Magnitude: 0.78771

Collected Steps per Second: 22,523.61664
Overall Steps per Second: 10,664.93576

Timestep Collection Time: 2.22114
Timestep Consumption Time: 2.46975
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.69089

Cumulative Model Updates: 57,746
Cumulative Timesteps: 481,605,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,493.46973
Policy Entropy: 3.71037
Value Function Loss: 0.05566

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.53054
Value Function Update Magnitude: 0.78326

Collected Steps per Second: 22,672.67281
Overall Steps per Second: 10,665.65027

Timestep Collection Time: 2.20530
Timestep Consumption Time: 2.48265
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68795

Cumulative Model Updates: 57,752
Cumulative Timesteps: 481,655,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 481655066...
Checkpoint 481655066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,920.91328
Policy Entropy: 3.71884
Value Function Loss: 0.05770

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.49199
Value Function Update Magnitude: 0.72233

Collected Steps per Second: 22,963.42810
Overall Steps per Second: 10,863.53011

Timestep Collection Time: 2.17825
Timestep Consumption Time: 2.42615
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.60440

Cumulative Model Updates: 57,758
Cumulative Timesteps: 481,705,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,589.87634
Policy Entropy: 3.73868
Value Function Loss: 0.05744

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.49706
Value Function Update Magnitude: 0.64401

Collected Steps per Second: 23,046.78710
Overall Steps per Second: 10,861.06488

Timestep Collection Time: 2.17037
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.60544

Cumulative Model Updates: 57,764
Cumulative Timesteps: 481,755,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 481755106...
Checkpoint 481755106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,665.41903
Policy Entropy: 3.73550
Value Function Loss: 0.05842

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.52818
Value Function Update Magnitude: 0.65837

Collected Steps per Second: 22,627.80296
Overall Steps per Second: 10,706.33435

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.46046
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.67013

Cumulative Model Updates: 57,770
Cumulative Timesteps: 481,805,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,515.70729
Policy Entropy: 3.73112
Value Function Loss: 0.05890

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.57671
Value Function Update Magnitude: 0.60385

Collected Steps per Second: 22,837.04971
Overall Steps per Second: 10,839.27919

Timestep Collection Time: 2.18969
Timestep Consumption Time: 2.42372
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.61341

Cumulative Model Updates: 57,776
Cumulative Timesteps: 481,855,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 481855112...
Checkpoint 481855112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,361.66302
Policy Entropy: 3.71463
Value Function Loss: 0.05971

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.59506
Value Function Update Magnitude: 0.64655

Collected Steps per Second: 22,776.07775
Overall Steps per Second: 10,708.59316

Timestep Collection Time: 2.19608
Timestep Consumption Time: 2.47475
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.67083

Cumulative Model Updates: 57,782
Cumulative Timesteps: 481,905,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,602.74341
Policy Entropy: 3.72775
Value Function Loss: 0.05872

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.60633
Value Function Update Magnitude: 0.71399

Collected Steps per Second: 22,944.33237
Overall Steps per Second: 10,834.69023

Timestep Collection Time: 2.17919
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.61481

Cumulative Model Updates: 57,788
Cumulative Timesteps: 481,955,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 481955130...
Checkpoint 481955130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,930.78266
Policy Entropy: 3.74832
Value Function Loss: 0.05805

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.52099
Value Function Update Magnitude: 0.74774

Collected Steps per Second: 22,552.84945
Overall Steps per Second: 10,713.52377

Timestep Collection Time: 2.21772
Timestep Consumption Time: 2.45077
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.66849

Cumulative Model Updates: 57,794
Cumulative Timesteps: 482,005,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,735.35891
Policy Entropy: 3.76458
Value Function Loss: 0.05445

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.51169
Value Function Update Magnitude: 0.77073

Collected Steps per Second: 22,850.99989
Overall Steps per Second: 10,815.25230

Timestep Collection Time: 2.18861
Timestep Consumption Time: 2.43560
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.62421

Cumulative Model Updates: 57,800
Cumulative Timesteps: 482,055,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 482055158...
Checkpoint 482055158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,604.99920
Policy Entropy: 3.77207
Value Function Loss: 0.05529

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.81677

Collected Steps per Second: 22,355.37301
Overall Steps per Second: 10,748.11778

Timestep Collection Time: 2.23705
Timestep Consumption Time: 2.41586
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.65291

Cumulative Model Updates: 57,806
Cumulative Timesteps: 482,105,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,805.62090
Policy Entropy: 3.77473
Value Function Loss: 0.05534

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.57986
Value Function Update Magnitude: 0.83449

Collected Steps per Second: 22,817.14046
Overall Steps per Second: 10,810.27180

Timestep Collection Time: 2.19221
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62708

Cumulative Model Updates: 57,812
Cumulative Timesteps: 482,155,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 482155188...
Checkpoint 482155188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.04685
Policy Entropy: 3.75823
Value Function Loss: 0.05819

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.61696
Value Function Update Magnitude: 0.85001

Collected Steps per Second: 22,630.77410
Overall Steps per Second: 10,699.37907

Timestep Collection Time: 2.21009
Timestep Consumption Time: 2.46458
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.67466

Cumulative Model Updates: 57,818
Cumulative Timesteps: 482,205,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,782.75823
Policy Entropy: 3.76259
Value Function Loss: 0.05654

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.59193
Value Function Update Magnitude: 0.85720

Collected Steps per Second: 22,885.68679
Overall Steps per Second: 10,896.45654

Timestep Collection Time: 2.18538
Timestep Consumption Time: 2.40455
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.58993

Cumulative Model Updates: 57,824
Cumulative Timesteps: 482,255,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 482255218...
Checkpoint 482255218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,384.48967
Policy Entropy: 3.75087
Value Function Loss: 0.05569

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10925
Policy Update Magnitude: 0.54927
Value Function Update Magnitude: 0.85007

Collected Steps per Second: 22,565.01348
Overall Steps per Second: 10,672.08077

Timestep Collection Time: 2.21653
Timestep Consumption Time: 2.47009
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.68662

Cumulative Model Updates: 57,830
Cumulative Timesteps: 482,305,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,837.80955
Policy Entropy: 3.74880
Value Function Loss: 0.05531

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.52899
Value Function Update Magnitude: 0.86124

Collected Steps per Second: 22,900.28387
Overall Steps per Second: 10,817.10490

Timestep Collection Time: 2.18425
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62416

Cumulative Model Updates: 57,836
Cumulative Timesteps: 482,355,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 482355254...
Checkpoint 482355254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,037.53427
Policy Entropy: 3.74482
Value Function Loss: 0.05312

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.84453

Collected Steps per Second: 22,465.83265
Overall Steps per Second: 10,736.25127

Timestep Collection Time: 2.22631
Timestep Consumption Time: 2.43230
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.65861

Cumulative Model Updates: 57,842
Cumulative Timesteps: 482,405,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,049.61017
Policy Entropy: 3.74209
Value Function Loss: 0.05153

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.82432

Collected Steps per Second: 22,743.78902
Overall Steps per Second: 10,803.37100

Timestep Collection Time: 2.19893
Timestep Consumption Time: 2.43037
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.62930

Cumulative Model Updates: 57,848
Cumulative Timesteps: 482,455,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 482455282...
Checkpoint 482455282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.54148
Policy Entropy: 3.75713
Value Function Loss: 0.05182

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.51547
Value Function Update Magnitude: 0.81841

Collected Steps per Second: 22,680.46995
Overall Steps per Second: 10,737.90908

Timestep Collection Time: 2.20577
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.65901

Cumulative Model Updates: 57,854
Cumulative Timesteps: 482,505,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,879.89925
Policy Entropy: 3.74966
Value Function Loss: 0.05317

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.56270
Value Function Update Magnitude: 0.80114

Collected Steps per Second: 22,809.60907
Overall Steps per Second: 10,786.27792

Timestep Collection Time: 2.19311
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.63774

Cumulative Model Updates: 57,860
Cumulative Timesteps: 482,555,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 482555334...
Checkpoint 482555334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,388.80396
Policy Entropy: 3.73504
Value Function Loss: 0.05566

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.57665
Value Function Update Magnitude: 0.81003

Collected Steps per Second: 22,750.73400
Overall Steps per Second: 10,720.44950

Timestep Collection Time: 2.19782
Timestep Consumption Time: 2.46635
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.66417

Cumulative Model Updates: 57,866
Cumulative Timesteps: 482,605,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,706.06307
Policy Entropy: 3.72055
Value Function Loss: 0.05699

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.54482
Value Function Update Magnitude: 0.78541

Collected Steps per Second: 22,795.94832
Overall Steps per Second: 10,667.67635

Timestep Collection Time: 2.19355
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.68743

Cumulative Model Updates: 57,872
Cumulative Timesteps: 482,655,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 482655340...
Checkpoint 482655340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,223.96761
Policy Entropy: 3.70976
Value Function Loss: 0.05902

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.52201
Value Function Update Magnitude: 0.74392

Collected Steps per Second: 22,940.59868
Overall Steps per Second: 10,869.44189

Timestep Collection Time: 2.17989
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.60079

Cumulative Model Updates: 57,878
Cumulative Timesteps: 482,705,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,677.16663
Policy Entropy: 3.71877
Value Function Loss: 0.05714

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.53587
Value Function Update Magnitude: 0.74511

Collected Steps per Second: 22,798.06278
Overall Steps per Second: 10,680.80224

Timestep Collection Time: 2.19317
Timestep Consumption Time: 2.48813
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.68130

Cumulative Model Updates: 57,884
Cumulative Timesteps: 482,755,348

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 482755348...
Checkpoint 482755348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,479.80858
Policy Entropy: 3.73038
Value Function Loss: 0.05624

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.53169
Value Function Update Magnitude: 0.74730

Collected Steps per Second: 22,872.44832
Overall Steps per Second: 10,840.57375

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.42627
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.61230

Cumulative Model Updates: 57,890
Cumulative Timesteps: 482,805,348

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,180.96852
Policy Entropy: 3.72804
Value Function Loss: 0.05627

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.51419
Value Function Update Magnitude: 0.76248

Collected Steps per Second: 22,854.84237
Overall Steps per Second: 10,714.08111

Timestep Collection Time: 2.18886
Timestep Consumption Time: 2.48032
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.66918

Cumulative Model Updates: 57,896
Cumulative Timesteps: 482,855,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 482855374...
Checkpoint 482855374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,538.70733
Policy Entropy: 3.72365
Value Function Loss: 0.05809

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.54328
Value Function Update Magnitude: 0.74435

Collected Steps per Second: 22,798.27284
Overall Steps per Second: 10,853.22761

Timestep Collection Time: 2.19385
Timestep Consumption Time: 2.41455
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.60840

Cumulative Model Updates: 57,902
Cumulative Timesteps: 482,905,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,589.39502
Policy Entropy: 3.72157
Value Function Loss: 0.05953

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.16544
Policy Update Magnitude: 0.50678
Value Function Update Magnitude: 0.71329

Collected Steps per Second: 23,000.89421
Overall Steps per Second: 10,865.99202

Timestep Collection Time: 2.17444
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.60280

Cumulative Model Updates: 57,908
Cumulative Timesteps: 482,955,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 482955404...
Checkpoint 482955404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,899.46499
Policy Entropy: 3.70646
Value Function Loss: 0.05973

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.14930
Policy Update Magnitude: 0.44968
Value Function Update Magnitude: 0.76643

Collected Steps per Second: 22,468.10619
Overall Steps per Second: 10,773.22518

Timestep Collection Time: 2.22538
Timestep Consumption Time: 2.41576
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.64114

Cumulative Model Updates: 57,914
Cumulative Timesteps: 483,005,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,533.18764
Policy Entropy: 3.72224
Value Function Loss: 0.05969

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.51081
Value Function Update Magnitude: 0.73680

Collected Steps per Second: 22,764.69752
Overall Steps per Second: 10,786.44351

Timestep Collection Time: 2.19744
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.63767

Cumulative Model Updates: 57,920
Cumulative Timesteps: 483,055,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 483055428...
Checkpoint 483055428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,987.16930
Policy Entropy: 3.72819
Value Function Loss: 0.05778

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.56543
Value Function Update Magnitude: 0.69608

Collected Steps per Second: 22,708.37130
Overall Steps per Second: 10,735.82498

Timestep Collection Time: 2.20342
Timestep Consumption Time: 2.45724
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.66066

Cumulative Model Updates: 57,926
Cumulative Timesteps: 483,105,464

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,661.23400
Policy Entropy: 3.73650
Value Function Loss: 0.05696

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.54003
Value Function Update Magnitude: 0.66894

Collected Steps per Second: 23,355.24251
Overall Steps per Second: 10,935.23192

Timestep Collection Time: 2.14145
Timestep Consumption Time: 2.43221
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.57366

Cumulative Model Updates: 57,932
Cumulative Timesteps: 483,155,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 483155478...
Checkpoint 483155478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,079.61114
Policy Entropy: 3.72191
Value Function Loss: 0.05695

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.54120
Value Function Update Magnitude: 0.62243

Collected Steps per Second: 22,635.33507
Overall Steps per Second: 10,597.61567

Timestep Collection Time: 2.20938
Timestep Consumption Time: 2.50961
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.71899

Cumulative Model Updates: 57,938
Cumulative Timesteps: 483,205,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,063.57511
Policy Entropy: 3.71291
Value Function Loss: 0.05722

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.60898

Collected Steps per Second: 22,941.74008
Overall Steps per Second: 10,843.89539

Timestep Collection Time: 2.17996
Timestep Consumption Time: 2.43204
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61200

Cumulative Model Updates: 57,944
Cumulative Timesteps: 483,255,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 483255500...
Checkpoint 483255500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,154.39208
Policy Entropy: 3.70967
Value Function Loss: 0.05807

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06487
Policy Update Magnitude: 0.61578
Value Function Update Magnitude: 0.61747

Collected Steps per Second: 22,633.46886
Overall Steps per Second: 10,706.12657

Timestep Collection Time: 2.20974
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.67153

Cumulative Model Updates: 57,950
Cumulative Timesteps: 483,305,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,962.33605
Policy Entropy: 3.72412
Value Function Loss: 0.05943

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06877
Policy Update Magnitude: 0.69047
Value Function Update Magnitude: 0.65829

Collected Steps per Second: 22,914.24169
Overall Steps per Second: 10,814.83770

Timestep Collection Time: 2.18292
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.62513

Cumulative Model Updates: 57,956
Cumulative Timesteps: 483,355,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 483355534...
Checkpoint 483355534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,148.50281
Policy Entropy: 3.73489
Value Function Loss: 0.06080

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.61981
Value Function Update Magnitude: 0.65711

Collected Steps per Second: 22,669.85379
Overall Steps per Second: 10,726.50986

Timestep Collection Time: 2.20584
Timestep Consumption Time: 2.45607
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.66191

Cumulative Model Updates: 57,962
Cumulative Timesteps: 483,405,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,693.31471
Policy Entropy: 3.74758
Value Function Loss: 0.06067

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.57446
Value Function Update Magnitude: 0.67518

Collected Steps per Second: 22,790.51781
Overall Steps per Second: 10,829.39193

Timestep Collection Time: 2.19442
Timestep Consumption Time: 2.42375
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61817

Cumulative Model Updates: 57,968
Cumulative Timesteps: 483,455,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 483455552...
Checkpoint 483455552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,617.98348
Policy Entropy: 3.74356
Value Function Loss: 0.05866

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.58804
Value Function Update Magnitude: 0.73186

Collected Steps per Second: 22,346.63834
Overall Steps per Second: 10,727.35781

Timestep Collection Time: 2.23774
Timestep Consumption Time: 2.42380
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.66154

Cumulative Model Updates: 57,974
Cumulative Timesteps: 483,505,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,796.70050
Policy Entropy: 3.74795
Value Function Loss: 0.05586

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.59335
Value Function Update Magnitude: 0.76556

Collected Steps per Second: 23,213.83912
Overall Steps per Second: 10,908.79435

Timestep Collection Time: 2.15561
Timestep Consumption Time: 2.43151
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.58712

Cumulative Model Updates: 57,980
Cumulative Timesteps: 483,555,598

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 483555598...
Checkpoint 483555598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,503.00295
Policy Entropy: 3.73758
Value Function Loss: 0.05417

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.59420
Value Function Update Magnitude: 0.83935

Collected Steps per Second: 22,387.16262
Overall Steps per Second: 9,912.54229

Timestep Collection Time: 2.23360
Timestep Consumption Time: 2.81092
PPO Batch Consumption Time: 0.33245
Total Iteration Time: 5.04452

Cumulative Model Updates: 57,986
Cumulative Timesteps: 483,605,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,829.49351
Policy Entropy: 3.73772
Value Function Loss: 0.05484

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.64693
Value Function Update Magnitude: 0.87544

Collected Steps per Second: 23,041.85578
Overall Steps per Second: 10,774.36069

Timestep Collection Time: 2.17040
Timestep Consumption Time: 2.47118
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.64157

Cumulative Model Updates: 57,992
Cumulative Timesteps: 483,655,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 483655612...
Checkpoint 483655612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.98764
Policy Entropy: 3.73808
Value Function Loss: 0.05240

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.70193
Value Function Update Magnitude: 0.88795

Collected Steps per Second: 22,773.77683
Overall Steps per Second: 10,613.15504

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.51714
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.71396

Cumulative Model Updates: 57,998
Cumulative Timesteps: 483,705,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,606.94841
Policy Entropy: 3.74512
Value Function Loss: 0.05473

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07509
Policy Update Magnitude: 0.70365
Value Function Update Magnitude: 0.84411

Collected Steps per Second: 22,500.24728
Overall Steps per Second: 10,534.50609

Timestep Collection Time: 2.22220
Timestep Consumption Time: 2.52411
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.74631

Cumulative Model Updates: 58,004
Cumulative Timesteps: 483,755,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 483755642...
Checkpoint 483755642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,504.91832
Policy Entropy: 3.74153
Value Function Loss: 0.05392

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.62588
Value Function Update Magnitude: 0.79025

Collected Steps per Second: 22,796.53062
Overall Steps per Second: 10,828.60502

Timestep Collection Time: 2.19384
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.61851

Cumulative Model Updates: 58,010
Cumulative Timesteps: 483,805,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,965.32189
Policy Entropy: 3.74692
Value Function Loss: 0.05427

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.59658
Value Function Update Magnitude: 0.79018

Collected Steps per Second: 22,984.32302
Overall Steps per Second: 10,837.90663

Timestep Collection Time: 2.17644
Timestep Consumption Time: 2.43921
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.61565

Cumulative Model Updates: 58,016
Cumulative Timesteps: 483,855,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 483855678...
Checkpoint 483855678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,510.54449
Policy Entropy: 3.74137
Value Function Loss: 0.05404

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.60730
Value Function Update Magnitude: 0.79625

Collected Steps per Second: 22,474.57490
Overall Steps per Second: 10,651.07984

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.47041
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.69586

Cumulative Model Updates: 58,022
Cumulative Timesteps: 483,905,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,689.55906
Policy Entropy: 3.73363
Value Function Loss: 0.05239

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.56671
Value Function Update Magnitude: 0.81222

Collected Steps per Second: 23,019.23247
Overall Steps per Second: 10,848.57504

Timestep Collection Time: 2.17236
Timestep Consumption Time: 2.43710
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.60945

Cumulative Model Updates: 58,028
Cumulative Timesteps: 483,955,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 483955700...
Checkpoint 483955700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,703.72912
Policy Entropy: 3.72904
Value Function Loss: 0.05505

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.56313
Value Function Update Magnitude: 0.81980

Collected Steps per Second: 22,663.97349
Overall Steps per Second: 10,692.74419

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.47062
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.67738

Cumulative Model Updates: 58,034
Cumulative Timesteps: 484,005,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,639.41341
Policy Entropy: 3.72988
Value Function Loss: 0.05669

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.51047
Value Function Update Magnitude: 0.82302

Collected Steps per Second: 22,784.79491
Overall Steps per Second: 10,826.55956

Timestep Collection Time: 2.19646
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.62252

Cumulative Model Updates: 58,040
Cumulative Timesteps: 484,055,760

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 484055760...
Checkpoint 484055760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,234.75980
Policy Entropy: 3.72904
Value Function Loss: 0.05745

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.51513
Value Function Update Magnitude: 0.78858

Collected Steps per Second: 22,729.09085
Overall Steps per Second: 10,715.84083

Timestep Collection Time: 2.20132
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.66916

Cumulative Model Updates: 58,046
Cumulative Timesteps: 484,105,794

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,228.32508
Policy Entropy: 3.72637
Value Function Loss: 0.05878

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.66875

Collected Steps per Second: 22,831.64952
Overall Steps per Second: 10,816.37600

Timestep Collection Time: 2.19056
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.62391

Cumulative Model Updates: 58,052
Cumulative Timesteps: 484,155,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 484155808...
Checkpoint 484155808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,272.53277
Policy Entropy: 3.73382
Value Function Loss: 0.05667

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.62334
Value Function Update Magnitude: 0.62907

Collected Steps per Second: 21,754.85069
Overall Steps per Second: 10,760.60003

Timestep Collection Time: 2.29917
Timestep Consumption Time: 2.34909
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.64825

Cumulative Model Updates: 58,058
Cumulative Timesteps: 484,205,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,444.06763
Policy Entropy: 3.72303
Value Function Loss: 0.05975

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.57088
Value Function Update Magnitude: 0.65561

Collected Steps per Second: 22,353.78908
Overall Steps per Second: 10,858.91725

Timestep Collection Time: 2.23694
Timestep Consumption Time: 2.36794
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60488

Cumulative Model Updates: 58,064
Cumulative Timesteps: 484,255,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 484255830...
Checkpoint 484255830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,447.98391
Policy Entropy: 3.73127
Value Function Loss: 0.05600

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.51706
Value Function Update Magnitude: 0.70715

Collected Steps per Second: 22,017.90993
Overall Steps per Second: 10,638.81463

Timestep Collection Time: 2.27197
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.70203

Cumulative Model Updates: 58,070
Cumulative Timesteps: 484,305,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,441.55095
Policy Entropy: 3.73747
Value Function Loss: 0.05693

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.51824
Value Function Update Magnitude: 0.69229

Collected Steps per Second: 22,118.20300
Overall Steps per Second: 10,821.92876

Timestep Collection Time: 2.26067
Timestep Consumption Time: 2.35976
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.62043

Cumulative Model Updates: 58,076
Cumulative Timesteps: 484,355,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 484355856...
Checkpoint 484355856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,433.86786
Policy Entropy: 3.74648
Value Function Loss: 0.05281

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06299
Policy Update Magnitude: 0.62244
Value Function Update Magnitude: 0.73966

Collected Steps per Second: 22,145.89684
Overall Steps per Second: 10,729.93446

Timestep Collection Time: 2.25794
Timestep Consumption Time: 2.40230
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.66023

Cumulative Model Updates: 58,082
Cumulative Timesteps: 484,405,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,805.43131
Policy Entropy: 3.74696
Value Function Loss: 0.05477

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.62008
Value Function Update Magnitude: 0.80942

Collected Steps per Second: 22,192.75827
Overall Steps per Second: 10,856.18119

Timestep Collection Time: 2.25398
Timestep Consumption Time: 2.35372
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60770

Cumulative Model Updates: 58,088
Cumulative Timesteps: 484,455,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 484455882...
Checkpoint 484455882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,415.38698
Policy Entropy: 3.74281
Value Function Loss: 0.05509

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.17313
Policy Update Magnitude: 0.51769
Value Function Update Magnitude: 0.84369

Collected Steps per Second: 21,904.13359
Overall Steps per Second: 10,705.92893

Timestep Collection Time: 2.28304
Timestep Consumption Time: 2.38802
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.67106

Cumulative Model Updates: 58,094
Cumulative Timesteps: 484,505,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,573.70104
Policy Entropy: 3.75954
Value Function Loss: 0.05538

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.49440
Value Function Update Magnitude: 0.85313

Collected Steps per Second: 22,352.46759
Overall Steps per Second: 10,618.27456

Timestep Collection Time: 2.23725
Timestep Consumption Time: 2.47237
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.70962

Cumulative Model Updates: 58,100
Cumulative Timesteps: 484,555,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 484555898...
Checkpoint 484555898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,608.32497
Policy Entropy: 3.77442
Value Function Loss: 0.05270

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.61008
Value Function Update Magnitude: 0.84438

Collected Steps per Second: 22,938.20850
Overall Steps per Second: 10,887.42979

Timestep Collection Time: 2.18055
Timestep Consumption Time: 2.41355
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.59411

Cumulative Model Updates: 58,106
Cumulative Timesteps: 484,605,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,074.77958
Policy Entropy: 3.78134
Value Function Loss: 0.05414

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.62167
Value Function Update Magnitude: 0.83257

Collected Steps per Second: 22,859.35415
Overall Steps per Second: 10,878.51098

Timestep Collection Time: 2.18825
Timestep Consumption Time: 2.40999
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.59824

Cumulative Model Updates: 58,112
Cumulative Timesteps: 484,655,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 484655938...
Checkpoint 484655938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,150.85172
Policy Entropy: 3.78594
Value Function Loss: 0.05338

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.57940
Value Function Update Magnitude: 0.83208

Collected Steps per Second: 22,460.43652
Overall Steps per Second: 10,719.26444

Timestep Collection Time: 2.22729
Timestep Consumption Time: 2.43963
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.66692

Cumulative Model Updates: 58,118
Cumulative Timesteps: 484,705,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,869.99748
Policy Entropy: 3.77857
Value Function Loss: 0.05301

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.62509
Value Function Update Magnitude: 0.82854

Collected Steps per Second: 22,981.55167
Overall Steps per Second: 10,846.68303

Timestep Collection Time: 2.17618
Timestep Consumption Time: 2.43463
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.61081

Cumulative Model Updates: 58,124
Cumulative Timesteps: 484,755,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 484755976...
Checkpoint 484755976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,884.52123
Policy Entropy: 3.78185
Value Function Loss: 0.05265

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.61497
Value Function Update Magnitude: 0.82665

Collected Steps per Second: 22,717.56200
Overall Steps per Second: 10,674.22778

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.48324
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.68418

Cumulative Model Updates: 58,130
Cumulative Timesteps: 484,805,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,128.80801
Policy Entropy: 3.77615
Value Function Loss: 0.05263

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06608
Policy Update Magnitude: 0.64173
Value Function Update Magnitude: 0.84335

Collected Steps per Second: 22,897.59373
Overall Steps per Second: 10,822.01827

Timestep Collection Time: 2.18390
Timestep Consumption Time: 2.43687
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.62076

Cumulative Model Updates: 58,136
Cumulative Timesteps: 484,855,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 484855982...
Checkpoint 484855982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,763.60158
Policy Entropy: 3.75244
Value Function Loss: 0.05539

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07274
Policy Update Magnitude: 0.68182
Value Function Update Magnitude: 0.84528

Collected Steps per Second: 22,560.30861
Overall Steps per Second: 10,803.90114

Timestep Collection Time: 2.21708
Timestep Consumption Time: 2.41254
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.62962

Cumulative Model Updates: 58,142
Cumulative Timesteps: 484,906,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,503.64603
Policy Entropy: 3.73314
Value Function Loss: 0.05773

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.66360
Value Function Update Magnitude: 0.81925

Collected Steps per Second: 22,588.07980
Overall Steps per Second: 10,735.34333

Timestep Collection Time: 2.21418
Timestep Consumption Time: 2.44464
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.65882

Cumulative Model Updates: 58,148
Cumulative Timesteps: 484,956,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 484956014...
Checkpoint 484956014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,046.53012
Policy Entropy: 3.73537
Value Function Loss: 0.06010

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.56906
Value Function Update Magnitude: 0.83630

Collected Steps per Second: 22,275.16589
Overall Steps per Second: 10,690.85996

Timestep Collection Time: 2.24591
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.67951

Cumulative Model Updates: 58,154
Cumulative Timesteps: 485,006,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,386.77126
Policy Entropy: 3.73729
Value Function Loss: 0.05860

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.49973
Value Function Update Magnitude: 0.83989

Collected Steps per Second: 22,926.82714
Overall Steps per Second: 10,741.90489

Timestep Collection Time: 2.18094
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.65485

Cumulative Model Updates: 58,160
Cumulative Timesteps: 485,056,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 485056044...
Checkpoint 485056044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,875.94165
Policy Entropy: 3.74868
Value Function Loss: 0.05604

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.46847
Value Function Update Magnitude: 0.82614

Collected Steps per Second: 22,834.86181
Overall Steps per Second: 10,864.56715

Timestep Collection Time: 2.19051
Timestep Consumption Time: 2.41345
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.60396

Cumulative Model Updates: 58,166
Cumulative Timesteps: 485,106,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,549.08286
Policy Entropy: 3.73419
Value Function Loss: 0.05412

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.50651
Value Function Update Magnitude: 0.82084

Collected Steps per Second: 23,100.16966
Overall Steps per Second: 10,835.22059

Timestep Collection Time: 2.16561
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.61698

Cumulative Model Updates: 58,172
Cumulative Timesteps: 485,156,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 485156090...
Checkpoint 485156090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,879.66914
Policy Entropy: 3.75005
Value Function Loss: 0.05357

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.50071
Value Function Update Magnitude: 0.84675

Collected Steps per Second: 22,588.41460
Overall Steps per Second: 10,703.74112

Timestep Collection Time: 2.21397
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.67220

Cumulative Model Updates: 58,178
Cumulative Timesteps: 485,206,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,993.01694
Policy Entropy: 3.73338
Value Function Loss: 0.05476

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.49060
Value Function Update Magnitude: 0.86093

Collected Steps per Second: 22,694.07236
Overall Steps per Second: 10,680.33964

Timestep Collection Time: 2.20445
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.68412

Cumulative Model Updates: 58,184
Cumulative Timesteps: 485,256,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 485256128...
Checkpoint 485256128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,422.58085
Policy Entropy: 3.74944
Value Function Loss: 0.05536

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.47321
Value Function Update Magnitude: 0.83975

Collected Steps per Second: 22,478.32906
Overall Steps per Second: 10,772.80866

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.41705
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.64150

Cumulative Model Updates: 58,190
Cumulative Timesteps: 485,306,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,631.99604
Policy Entropy: 3.72657
Value Function Loss: 0.05627

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.48785
Value Function Update Magnitude: 0.82507

Collected Steps per Second: 23,157.73088
Overall Steps per Second: 10,771.51029

Timestep Collection Time: 2.15980
Timestep Consumption Time: 2.48356
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.64336

Cumulative Model Updates: 58,196
Cumulative Timesteps: 485,356,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 485356146...
Checkpoint 485356146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,282.62288
Policy Entropy: 3.73101
Value Function Loss: 0.05326

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.52031
Value Function Update Magnitude: 0.84156

Collected Steps per Second: 22,642.83932
Overall Steps per Second: 10,765.53358

Timestep Collection Time: 2.20873
Timestep Consumption Time: 2.43683
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.64557

Cumulative Model Updates: 58,202
Cumulative Timesteps: 485,406,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,370.74563
Policy Entropy: 3.72174
Value Function Loss: 0.05414

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.51775
Value Function Update Magnitude: 0.86560

Collected Steps per Second: 22,516.00742
Overall Steps per Second: 10,571.59610

Timestep Collection Time: 2.22180
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.73211

Cumulative Model Updates: 58,208
Cumulative Timesteps: 485,456,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 485456184...
Checkpoint 485456184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.56032
Policy Entropy: 3.71962
Value Function Loss: 0.05543

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.49578
Value Function Update Magnitude: 0.84824

Collected Steps per Second: 22,823.62101
Overall Steps per Second: 10,644.04879

Timestep Collection Time: 2.19176
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.69972

Cumulative Model Updates: 58,214
Cumulative Timesteps: 485,506,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,355.24535
Policy Entropy: 3.72043
Value Function Loss: 0.05720

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06973
Policy Update Magnitude: 0.58070
Value Function Update Magnitude: 0.80673

Collected Steps per Second: 22,864.59676
Overall Steps per Second: 10,821.45663

Timestep Collection Time: 2.18792
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.62285

Cumulative Model Updates: 58,220
Cumulative Timesteps: 485,556,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 485556234...
Checkpoint 485556234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,081.05214
Policy Entropy: 3.72444
Value Function Loss: 0.05541

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08763
Policy Update Magnitude: 0.64642
Value Function Update Magnitude: 0.83896

Collected Steps per Second: 22,665.73560
Overall Steps per Second: 10,666.76267

Timestep Collection Time: 2.20650
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68858

Cumulative Model Updates: 58,226
Cumulative Timesteps: 485,606,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,373.40221
Policy Entropy: 3.73669
Value Function Loss: 0.05556

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.82730

Collected Steps per Second: 22,062.91425
Overall Steps per Second: 10,670.79830

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.41963
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68606

Cumulative Model Updates: 58,232
Cumulative Timesteps: 485,656,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 485656250...
Checkpoint 485656250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,618.13186
Policy Entropy: 3.73027
Value Function Loss: 0.05781

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06989
Policy Update Magnitude: 0.57465
Value Function Update Magnitude: 0.81883

Collected Steps per Second: 22,297.65460
Overall Steps per Second: 10,918.09702

Timestep Collection Time: 2.24257
Timestep Consumption Time: 2.33735
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.57992

Cumulative Model Updates: 58,238
Cumulative Timesteps: 485,706,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,056.76146
Policy Entropy: 3.73329
Value Function Loss: 0.06024

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.63541
Value Function Update Magnitude: 0.80714

Collected Steps per Second: 22,328.66069
Overall Steps per Second: 10,847.40629

Timestep Collection Time: 2.24044
Timestep Consumption Time: 2.37135
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.61179

Cumulative Model Updates: 58,244
Cumulative Timesteps: 485,756,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 485756280...
Checkpoint 485756280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,020.05403
Policy Entropy: 3.72968
Value Function Loss: 0.06021

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.63034
Value Function Update Magnitude: 0.82040

Collected Steps per Second: 22,286.29085
Overall Steps per Second: 10,693.50434

Timestep Collection Time: 2.24353
Timestep Consumption Time: 2.43220
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.67574

Cumulative Model Updates: 58,250
Cumulative Timesteps: 485,806,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,304.27155
Policy Entropy: 3.73806
Value Function Loss: 0.06248

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07354
Policy Update Magnitude: 0.65489
Value Function Update Magnitude: 0.75486

Collected Steps per Second: 22,180.64214
Overall Steps per Second: 10,869.60466

Timestep Collection Time: 2.25530
Timestep Consumption Time: 2.34689
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60219

Cumulative Model Updates: 58,256
Cumulative Timesteps: 485,856,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 485856304...
Checkpoint 485856304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,454.39599
Policy Entropy: 3.73734
Value Function Loss: 0.06139

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.63154
Value Function Update Magnitude: 0.66952

Collected Steps per Second: 22,016.43612
Overall Steps per Second: 10,732.80737

Timestep Collection Time: 2.27148
Timestep Consumption Time: 2.38806
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.65955

Cumulative Model Updates: 58,262
Cumulative Timesteps: 485,906,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,249.54283
Policy Entropy: 3.73468
Value Function Loss: 0.06332

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.61104
Value Function Update Magnitude: 0.61331

Collected Steps per Second: 22,640.27541
Overall Steps per Second: 10,793.14576

Timestep Collection Time: 2.20845
Timestep Consumption Time: 2.42412
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.63257

Cumulative Model Updates: 58,268
Cumulative Timesteps: 485,956,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 485956314...
Checkpoint 485956314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,973.59789
Policy Entropy: 3.73694
Value Function Loss: 0.06372

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10246
Policy Update Magnitude: 0.55580
Value Function Update Magnitude: 0.66693

Collected Steps per Second: 22,559.82671
Overall Steps per Second: 10,654.68742

Timestep Collection Time: 2.21686
Timestep Consumption Time: 2.47704
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.69390

Cumulative Model Updates: 58,274
Cumulative Timesteps: 486,006,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,052.68607
Policy Entropy: 3.74347
Value Function Loss: 0.06418

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.50980
Value Function Update Magnitude: 0.74809

Collected Steps per Second: 22,720.21998
Overall Steps per Second: 10,847.45580

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.40898
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.60993

Cumulative Model Updates: 58,280
Cumulative Timesteps: 486,056,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 486056332...
Checkpoint 486056332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,101.35208
Policy Entropy: 3.74119
Value Function Loss: 0.06242

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.11694
Policy Update Magnitude: 0.50585
Value Function Update Magnitude: 0.74276

Collected Steps per Second: 22,632.88025
Overall Steps per Second: 10,730.79006

Timestep Collection Time: 2.20944
Timestep Consumption Time: 2.45061
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.66005

Cumulative Model Updates: 58,286
Cumulative Timesteps: 486,106,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,144.85722
Policy Entropy: 3.73047
Value Function Loss: 0.06245

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.47465
Value Function Update Magnitude: 0.68181

Collected Steps per Second: 23,069.83191
Overall Steps per Second: 10,857.73077

Timestep Collection Time: 2.16803
Timestep Consumption Time: 2.43846
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.60649

Cumulative Model Updates: 58,292
Cumulative Timesteps: 486,156,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 486156354...
Checkpoint 486156354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,759.68460
Policy Entropy: 3.71936
Value Function Loss: 0.06604

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.15994
Policy Update Magnitude: 0.47570
Value Function Update Magnitude: 0.66978

Collected Steps per Second: 22,405.50479
Overall Steps per Second: 10,688.59940

Timestep Collection Time: 2.23293
Timestep Consumption Time: 2.44775
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.68069

Cumulative Model Updates: 58,298
Cumulative Timesteps: 486,206,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,962.06019
Policy Entropy: 3.71432
Value Function Loss: 0.06699

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.51920
Value Function Update Magnitude: 0.61217

Collected Steps per Second: 22,951.21968
Overall Steps per Second: 10,817.88929

Timestep Collection Time: 2.17862
Timestep Consumption Time: 2.44354
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.62216

Cumulative Model Updates: 58,304
Cumulative Timesteps: 486,256,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 486256386...
Checkpoint 486256386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.57944
Policy Entropy: 3.69733
Value Function Loss: 0.06921

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.47050
Value Function Update Magnitude: 0.60437

Collected Steps per Second: 22,710.87556
Overall Steps per Second: 10,709.45515

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.46797
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.67027

Cumulative Model Updates: 58,310
Cumulative Timesteps: 486,306,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,778.05608
Policy Entropy: 3.68992
Value Function Loss: 0.06845

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.45440
Value Function Update Magnitude: 0.55683

Collected Steps per Second: 23,255.70260
Overall Steps per Second: 10,891.37633

Timestep Collection Time: 2.15104
Timestep Consumption Time: 2.44195
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.59299

Cumulative Model Updates: 58,316
Cumulative Timesteps: 486,356,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 486356426...
Checkpoint 486356426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,811.01096
Policy Entropy: 3.69234
Value Function Loss: 0.06671

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.45246
Value Function Update Magnitude: 0.55032

Collected Steps per Second: 22,707.34839
Overall Steps per Second: 10,650.56449

Timestep Collection Time: 2.20219
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.69515

Cumulative Model Updates: 58,322
Cumulative Timesteps: 486,406,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,958.86621
Policy Entropy: 3.68899
Value Function Loss: 0.06382

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.45068
Value Function Update Magnitude: 0.53525

Collected Steps per Second: 22,757.72615
Overall Steps per Second: 10,648.58952

Timestep Collection Time: 2.19732
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69602

Cumulative Model Updates: 58,328
Cumulative Timesteps: 486,456,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 486456438...
Checkpoint 486456438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,621.41104
Policy Entropy: 3.69013
Value Function Loss: 0.06384

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.52560
Value Function Update Magnitude: 0.56514

Collected Steps per Second: 22,711.51621
Overall Steps per Second: 10,819.76131

Timestep Collection Time: 2.20241
Timestep Consumption Time: 2.42062
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.62302

Cumulative Model Updates: 58,334
Cumulative Timesteps: 486,506,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,831.68893
Policy Entropy: 3.69101
Value Function Loss: 0.06388

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.51964
Value Function Update Magnitude: 0.51990

Collected Steps per Second: 23,011.22103
Overall Steps per Second: 10,749.61957

Timestep Collection Time: 2.17303
Timestep Consumption Time: 2.47867
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.65170

Cumulative Model Updates: 58,340
Cumulative Timesteps: 486,556,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 486556462...
Checkpoint 486556462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,904.94771
Policy Entropy: 3.71985
Value Function Loss: 0.06197

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.47627
Value Function Update Magnitude: 0.51090

Collected Steps per Second: 22,638.74175
Overall Steps per Second: 10,783.70356

Timestep Collection Time: 2.20878
Timestep Consumption Time: 2.42822
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.63700

Cumulative Model Updates: 58,346
Cumulative Timesteps: 486,606,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,830.38708
Policy Entropy: 3.72648
Value Function Loss: 0.05835

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.45267
Value Function Update Magnitude: 0.54759

Collected Steps per Second: 22,817.38412
Overall Steps per Second: 10,648.78581

Timestep Collection Time: 2.19254
Timestep Consumption Time: 2.50546
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.69800

Cumulative Model Updates: 58,352
Cumulative Timesteps: 486,656,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 486656494...
Checkpoint 486656494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,641.92452
Policy Entropy: 3.73677
Value Function Loss: 0.05578

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.44543
Value Function Update Magnitude: 0.59235

Collected Steps per Second: 22,769.37367
Overall Steps per Second: 10,653.13870

Timestep Collection Time: 2.19672
Timestep Consumption Time: 2.49842
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.69514

Cumulative Model Updates: 58,358
Cumulative Timesteps: 486,706,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,744.83900
Policy Entropy: 3.72623
Value Function Loss: 0.05618

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.43912
Value Function Update Magnitude: 0.63096

Collected Steps per Second: 22,830.46458
Overall Steps per Second: 10,845.62083

Timestep Collection Time: 2.19093
Timestep Consumption Time: 2.42107
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.61200

Cumulative Model Updates: 58,364
Cumulative Timesteps: 486,756,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 486756532...
Checkpoint 486756532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,773.18520
Policy Entropy: 3.73569
Value Function Loss: 0.05510

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07913
Policy Update Magnitude: 0.51291
Value Function Update Magnitude: 0.68222

Collected Steps per Second: 22,841.86449
Overall Steps per Second: 10,697.33819

Timestep Collection Time: 2.18931
Timestep Consumption Time: 2.48549
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.67481

Cumulative Model Updates: 58,370
Cumulative Timesteps: 486,806,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,319.10604
Policy Entropy: 3.72291
Value Function Loss: 0.05642

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.54300
Value Function Update Magnitude: 0.62465

Collected Steps per Second: 22,204.58474
Overall Steps per Second: 10,557.93096

Timestep Collection Time: 2.25215
Timestep Consumption Time: 2.48439
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.73653

Cumulative Model Updates: 58,376
Cumulative Timesteps: 486,856,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 486856548...
Checkpoint 486856548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,732.85951
Policy Entropy: 3.72210
Value Function Loss: 0.05814

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.60329
Value Function Update Magnitude: 0.59021

Collected Steps per Second: 22,651.56804
Overall Steps per Second: 10,808.15970

Timestep Collection Time: 2.20744
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.62632

Cumulative Model Updates: 58,382
Cumulative Timesteps: 486,906,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,376.85918
Policy Entropy: 3.71112
Value Function Loss: 0.05968

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.54133

Collected Steps per Second: 22,867.73840
Overall Steps per Second: 10,714.45205

Timestep Collection Time: 2.18701
Timestep Consumption Time: 2.48070
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.66771

Cumulative Model Updates: 58,388
Cumulative Timesteps: 486,956,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 486956562...
Checkpoint 486956562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,998.98760
Policy Entropy: 3.74459
Value Function Loss: 0.06038

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.46368
Value Function Update Magnitude: 0.53228

Collected Steps per Second: 22,763.47887
Overall Steps per Second: 10,826.83806

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.42243
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61963

Cumulative Model Updates: 58,394
Cumulative Timesteps: 487,006,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,823.98770
Policy Entropy: 3.75349
Value Function Loss: 0.05717

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07106
Policy Update Magnitude: 0.45961
Value Function Update Magnitude: 0.56936

Collected Steps per Second: 22,028.67040
Overall Steps per Second: 10,678.03470

Timestep Collection Time: 2.26986
Timestep Consumption Time: 2.41284
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.68270

Cumulative Model Updates: 58,400
Cumulative Timesteps: 487,056,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 487056580...
Checkpoint 487056580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,431.30183
Policy Entropy: 3.77498
Value Function Loss: 0.05462

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.48473
Value Function Update Magnitude: 0.59803

Collected Steps per Second: 22,212.49333
Overall Steps per Second: 10,886.37389

Timestep Collection Time: 2.25126
Timestep Consumption Time: 2.34219
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59345

Cumulative Model Updates: 58,406
Cumulative Timesteps: 487,106,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,283.88808
Policy Entropy: 3.79198
Value Function Loss: 0.05302

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.47823
Value Function Update Magnitude: 0.59883

Collected Steps per Second: 21,970.99033
Overall Steps per Second: 10,684.66452

Timestep Collection Time: 2.27637
Timestep Consumption Time: 2.40455
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.68091

Cumulative Model Updates: 58,412
Cumulative Timesteps: 487,156,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 487156600...
Checkpoint 487156600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,464.63512
Policy Entropy: 3.78124
Value Function Loss: 0.05175

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.68549

Collected Steps per Second: 22,028.58968
Overall Steps per Second: 10,821.97564

Timestep Collection Time: 2.27005
Timestep Consumption Time: 2.35073
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62078

Cumulative Model Updates: 58,418
Cumulative Timesteps: 487,206,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,643.70527
Policy Entropy: 3.76605
Value Function Loss: 0.05169

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.70188

Collected Steps per Second: 21,970.27516
Overall Steps per Second: 10,669.79036

Timestep Collection Time: 2.27644
Timestep Consumption Time: 2.41100
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.68744

Cumulative Model Updates: 58,424
Cumulative Timesteps: 487,256,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 487256620...
Checkpoint 487256620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,208.40336
Policy Entropy: 3.77225
Value Function Loss: 0.05216

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.50574
Value Function Update Magnitude: 0.72295

Collected Steps per Second: 22,183.11983
Overall Steps per Second: 10,582.31167

Timestep Collection Time: 2.25505
Timestep Consumption Time: 2.47209
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.72713

Cumulative Model Updates: 58,430
Cumulative Timesteps: 487,306,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,919.74403
Policy Entropy: 3.78599
Value Function Loss: 0.05142

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.47385
Value Function Update Magnitude: 0.76011

Collected Steps per Second: 22,875.60038
Overall Steps per Second: 10,821.54828

Timestep Collection Time: 2.18608
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.62115

Cumulative Model Updates: 58,436
Cumulative Timesteps: 487,356,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 487356652...
Checkpoint 487356652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,177.63980
Policy Entropy: 3.79123
Value Function Loss: 0.04992

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06484
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.77264

Collected Steps per Second: 22,812.69290
Overall Steps per Second: 10,730.74608

Timestep Collection Time: 2.19203
Timestep Consumption Time: 2.46804
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.66007

Cumulative Model Updates: 58,442
Cumulative Timesteps: 487,406,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,823.55666
Policy Entropy: 3.77996
Value Function Loss: 0.05026

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.75613

Collected Steps per Second: 22,633.47344
Overall Steps per Second: 10,803.18411

Timestep Collection Time: 2.20912
Timestep Consumption Time: 2.41915
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.62827

Cumulative Model Updates: 58,448
Cumulative Timesteps: 487,456,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 487456658...
Checkpoint 487456658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,024.00161
Policy Entropy: 3.77826
Value Function Loss: 0.05203

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.50852
Value Function Update Magnitude: 0.76310

Collected Steps per Second: 22,672.21453
Overall Steps per Second: 10,697.20712

Timestep Collection Time: 2.20614
Timestep Consumption Time: 2.46966
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.67580

Cumulative Model Updates: 58,454
Cumulative Timesteps: 487,506,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,492.99346
Policy Entropy: 3.77550
Value Function Loss: 0.05412

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.53186
Value Function Update Magnitude: 0.78388

Collected Steps per Second: 22,988.01974
Overall Steps per Second: 10,819.03219

Timestep Collection Time: 2.17583
Timestep Consumption Time: 2.44732
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.62315

Cumulative Model Updates: 58,460
Cumulative Timesteps: 487,556,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 487556694...
Checkpoint 487556694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,114.87873
Policy Entropy: 3.76274
Value Function Loss: 0.05633

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.57479
Value Function Update Magnitude: 0.80072

Collected Steps per Second: 23,115.58602
Overall Steps per Second: 10,720.55520

Timestep Collection Time: 2.16417
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.66636

Cumulative Model Updates: 58,466
Cumulative Timesteps: 487,606,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,848.28030
Policy Entropy: 3.76663
Value Function Loss: 0.05814

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.15843
Policy Update Magnitude: 0.48200
Value Function Update Magnitude: 0.73580

Collected Steps per Second: 22,847.80917
Overall Steps per Second: 10,788.07105

Timestep Collection Time: 2.18979
Timestep Consumption Time: 2.44792
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.63772

Cumulative Model Updates: 58,472
Cumulative Timesteps: 487,656,752

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 487656752...
Checkpoint 487656752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,047.48813
Policy Entropy: 3.77442
Value Function Loss: 0.05741

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.40298
Value Function Update Magnitude: 0.63962

Collected Steps per Second: 22,655.91287
Overall Steps per Second: 10,682.69259

Timestep Collection Time: 2.20728
Timestep Consumption Time: 2.47393
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.68122

Cumulative Model Updates: 58,478
Cumulative Timesteps: 487,706,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,548.44180
Policy Entropy: 3.78658
Value Function Loss: 0.05482

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.44365
Value Function Update Magnitude: 0.71459

Collected Steps per Second: 22,779.92632
Overall Steps per Second: 10,674.99080

Timestep Collection Time: 2.19527
Timestep Consumption Time: 2.48933
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.68459

Cumulative Model Updates: 58,484
Cumulative Timesteps: 487,756,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 487756768...
Checkpoint 487756768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,627.63257
Policy Entropy: 3.77440
Value Function Loss: 0.05450

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.46737
Value Function Update Magnitude: 0.78286

Collected Steps per Second: 22,903.35266
Overall Steps per Second: 10,838.07049

Timestep Collection Time: 2.18309
Timestep Consumption Time: 2.43028
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61337

Cumulative Model Updates: 58,490
Cumulative Timesteps: 487,806,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,224.19846
Policy Entropy: 3.76208
Value Function Loss: 0.05590

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.49518
Value Function Update Magnitude: 0.77628

Collected Steps per Second: 22,752.81605
Overall Steps per Second: 10,679.57443

Timestep Collection Time: 2.19885
Timestep Consumption Time: 2.48579
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.68464

Cumulative Model Updates: 58,496
Cumulative Timesteps: 487,856,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 487856798...
Checkpoint 487856798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,708.19951
Policy Entropy: 3.74700
Value Function Loss: 0.05747

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.53474
Value Function Update Magnitude: 0.78264

Collected Steps per Second: 22,540.83927
Overall Steps per Second: 10,676.39373

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.46602
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.68510

Cumulative Model Updates: 58,502
Cumulative Timesteps: 487,906,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,280.48935
Policy Entropy: 3.74486
Value Function Loss: 0.05547

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06612
Policy Update Magnitude: 0.63321
Value Function Update Magnitude: 0.77488

Collected Steps per Second: 23,080.19732
Overall Steps per Second: 10,705.98607

Timestep Collection Time: 2.16844
Timestep Consumption Time: 2.50633
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.67477

Cumulative Model Updates: 58,508
Cumulative Timesteps: 487,956,866

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 487956866...
Checkpoint 487956866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,552.16073
Policy Entropy: 3.74994
Value Function Loss: 0.05527

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.58605
Value Function Update Magnitude: 0.73444

Collected Steps per Second: 22,707.24608
Overall Steps per Second: 10,626.15706

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.50383
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70612

Cumulative Model Updates: 58,514
Cumulative Timesteps: 488,006,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,596.16219
Policy Entropy: 3.75536
Value Function Loss: 0.05445

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.50212
Value Function Update Magnitude: 0.65060

Collected Steps per Second: 23,070.72982
Overall Steps per Second: 10,892.87019

Timestep Collection Time: 2.16812
Timestep Consumption Time: 2.42388
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.59199

Cumulative Model Updates: 58,520
Cumulative Timesteps: 488,056,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 488056894...
Checkpoint 488056894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,215.18875
Policy Entropy: 3.74968
Value Function Loss: 0.05806

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.15010
Policy Update Magnitude: 0.44965
Value Function Update Magnitude: 0.64027

Collected Steps per Second: 21,706.48836
Overall Steps per Second: 10,694.79873

Timestep Collection Time: 2.30484
Timestep Consumption Time: 2.37313
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.67797

Cumulative Model Updates: 58,526
Cumulative Timesteps: 488,106,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,862.64954
Policy Entropy: 3.73943
Value Function Loss: 0.06082

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.43322
Value Function Update Magnitude: 0.61890

Collected Steps per Second: 22,108.75662
Overall Steps per Second: 10,802.08646

Timestep Collection Time: 2.26191
Timestep Consumption Time: 2.36757
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.62948

Cumulative Model Updates: 58,532
Cumulative Timesteps: 488,156,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 488156932...
Checkpoint 488156932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,898.67214
Policy Entropy: 3.72645
Value Function Loss: 0.06216

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.47711
Value Function Update Magnitude: 0.59284

Collected Steps per Second: 21,979.81217
Overall Steps per Second: 10,711.46450

Timestep Collection Time: 2.27491
Timestep Consumption Time: 2.39318
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.66808

Cumulative Model Updates: 58,538
Cumulative Timesteps: 488,206,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,546.33752
Policy Entropy: 3.72367
Value Function Loss: 0.06241

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.49873
Value Function Update Magnitude: 0.60287

Collected Steps per Second: 22,310.11407
Overall Steps per Second: 10,895.58511

Timestep Collection Time: 2.24132
Timestep Consumption Time: 2.34807
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.58938

Cumulative Model Updates: 58,544
Cumulative Timesteps: 488,256,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 488256938...
Checkpoint 488256938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,802.29251
Policy Entropy: 3.72222
Value Function Loss: 0.06077

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.46122
Value Function Update Magnitude: 0.68474

Collected Steps per Second: 22,191.42865
Overall Steps per Second: 10,678.08053

Timestep Collection Time: 2.25393
Timestep Consumption Time: 2.43024
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.68418

Cumulative Model Updates: 58,550
Cumulative Timesteps: 488,306,956

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,366.08492
Policy Entropy: 3.71717
Value Function Loss: 0.05971

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.49263
Value Function Update Magnitude: 0.66647

Collected Steps per Second: 22,931.83007
Overall Steps per Second: 10,914.68823

Timestep Collection Time: 2.18107
Timestep Consumption Time: 2.40138
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.58245

Cumulative Model Updates: 58,556
Cumulative Timesteps: 488,356,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 488356972...
Checkpoint 488356972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,687.71996
Policy Entropy: 3.72093
Value Function Loss: 0.05793

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.48367
Value Function Update Magnitude: 0.61942

Collected Steps per Second: 22,730.60929
Overall Steps per Second: 10,719.46129

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.46602
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.66684

Cumulative Model Updates: 58,562
Cumulative Timesteps: 488,406,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,199.48699
Policy Entropy: 3.72253
Value Function Loss: 0.05788

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.50208
Value Function Update Magnitude: 0.62524

Collected Steps per Second: 23,071.28832
Overall Steps per Second: 10,810.19126

Timestep Collection Time: 2.16746
Timestep Consumption Time: 2.45836
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.62582

Cumulative Model Updates: 58,568
Cumulative Timesteps: 488,457,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 488457004...
Checkpoint 488457004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,569.51577
Policy Entropy: 3.73206
Value Function Loss: 0.05459

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.53375
Value Function Update Magnitude: 0.66989

Collected Steps per Second: 22,815.32040
Overall Steps per Second: 10,742.21179

Timestep Collection Time: 2.19212
Timestep Consumption Time: 2.46371
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.65584

Cumulative Model Updates: 58,574
Cumulative Timesteps: 488,507,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,416.81754
Policy Entropy: 3.72704
Value Function Loss: 0.05470

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.64022
Value Function Update Magnitude: 0.70993

Collected Steps per Second: 23,069.54065
Overall Steps per Second: 10,762.73821

Timestep Collection Time: 2.16762
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.64622

Cumulative Model Updates: 58,580
Cumulative Timesteps: 488,557,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 488557024...
Checkpoint 488557024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,625.20425
Policy Entropy: 3.72334
Value Function Loss: 0.05621

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.64306
Value Function Update Magnitude: 0.65339

Collected Steps per Second: 22,700.47019
Overall Steps per Second: 10,649.71069

Timestep Collection Time: 2.20374
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.69740

Cumulative Model Updates: 58,586
Cumulative Timesteps: 488,607,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,142.86578
Policy Entropy: 3.72143
Value Function Loss: 0.05706

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.64536

Collected Steps per Second: 22,728.49254
Overall Steps per Second: 10,687.55248

Timestep Collection Time: 2.20041
Timestep Consumption Time: 2.47905
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.67946

Cumulative Model Updates: 58,592
Cumulative Timesteps: 488,657,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 488657062...
Checkpoint 488657062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,843.96409
Policy Entropy: 3.71536
Value Function Loss: 0.05790

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.15672
Policy Update Magnitude: 0.45135
Value Function Update Magnitude: 0.62954

Collected Steps per Second: 22,683.95639
Overall Steps per Second: 10,900.44907

Timestep Collection Time: 2.20455
Timestep Consumption Time: 2.38315
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.58770

Cumulative Model Updates: 58,598
Cumulative Timesteps: 488,707,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,185.98568
Policy Entropy: 3.73981
Value Function Loss: 0.05463

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.41743
Value Function Update Magnitude: 0.67333

Collected Steps per Second: 22,881.57365
Overall Steps per Second: 10,775.28501

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.45518
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.64043

Cumulative Model Updates: 58,604
Cumulative Timesteps: 488,757,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 488757072...
Checkpoint 488757072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,331.43244
Policy Entropy: 3.75434
Value Function Loss: 0.05179

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.42763
Value Function Update Magnitude: 0.74512

Collected Steps per Second: 22,639.01205
Overall Steps per Second: 10,798.08357

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.42246
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.63156

Cumulative Model Updates: 58,610
Cumulative Timesteps: 488,807,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,417.08858
Policy Entropy: 3.76090
Value Function Loss: 0.04933

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.44184
Value Function Update Magnitude: 0.79231

Collected Steps per Second: 22,529.76177
Overall Steps per Second: 10,748.69062

Timestep Collection Time: 2.21982
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.65285

Cumulative Model Updates: 58,616
Cumulative Timesteps: 488,857,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 488857096...
Checkpoint 488857096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,307.15269
Policy Entropy: 3.76033
Value Function Loss: 0.04842

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 0.57169
Value Function Update Magnitude: 0.80148

Collected Steps per Second: 22,356.56645
Overall Steps per Second: 10,720.92302

Timestep Collection Time: 2.23711
Timestep Consumption Time: 2.42798
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.66508

Cumulative Model Updates: 58,622
Cumulative Timesteps: 488,907,110

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,563.90617
Policy Entropy: 3.75559
Value Function Loss: 0.05026

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06965
Policy Update Magnitude: 0.63987
Value Function Update Magnitude: 0.81458

Collected Steps per Second: 22,787.20417
Overall Steps per Second: 10,661.55496

Timestep Collection Time: 2.19448
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.69031

Cumulative Model Updates: 58,628
Cumulative Timesteps: 488,957,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 488957116...
Checkpoint 488957116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,861.40425
Policy Entropy: 3.75696
Value Function Loss: 0.05213

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.64786
Value Function Update Magnitude: 0.82961

Collected Steps per Second: 22,658.10434
Overall Steps per Second: 10,821.36023

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.41513
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62308

Cumulative Model Updates: 58,634
Cumulative Timesteps: 489,007,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,471.81060
Policy Entropy: 3.75222
Value Function Loss: 0.05316

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.57807
Value Function Update Magnitude: 0.81362

Collected Steps per Second: 22,696.71931
Overall Steps per Second: 10,617.11673

Timestep Collection Time: 2.20367
Timestep Consumption Time: 2.50722
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.71088

Cumulative Model Updates: 58,640
Cumulative Timesteps: 489,057,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 489057160...
Checkpoint 489057160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,301.71875
Policy Entropy: 3.76461
Value Function Loss: 0.05146

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.53956
Value Function Update Magnitude: 0.79920

Collected Steps per Second: 22,874.57215
Overall Steps per Second: 10,738.90591

Timestep Collection Time: 2.18653
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.65746

Cumulative Model Updates: 58,646
Cumulative Timesteps: 489,107,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,517.38567
Policy Entropy: 3.75760
Value Function Loss: 0.04850

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07269
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.81112

Collected Steps per Second: 23,087.28767
Overall Steps per Second: 10,761.32237

Timestep Collection Time: 2.16699
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.64906

Cumulative Model Updates: 58,652
Cumulative Timesteps: 489,157,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 489157206...
Checkpoint 489157206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,273.20829
Policy Entropy: 3.76210
Value Function Loss: 0.04756

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.61171
Value Function Update Magnitude: 0.80528

Collected Steps per Second: 22,786.17440
Overall Steps per Second: 10,640.32437

Timestep Collection Time: 2.19545
Timestep Consumption Time: 2.50609
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.70155

Cumulative Model Updates: 58,658
Cumulative Timesteps: 489,207,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,485.29061
Policy Entropy: 3.75439
Value Function Loss: 0.04986

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.56294
Value Function Update Magnitude: 0.80905

Collected Steps per Second: 22,613.53675
Overall Steps per Second: 10,838.43900

Timestep Collection Time: 2.21186
Timestep Consumption Time: 2.40301
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.61487

Cumulative Model Updates: 58,664
Cumulative Timesteps: 489,257,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 489257250...
Checkpoint 489257250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,806.91918
Policy Entropy: 3.74713
Value Function Loss: 0.05026

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.54944
Value Function Update Magnitude: 0.80525

Collected Steps per Second: 22,582.77510
Overall Steps per Second: 10,675.69259

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.68541

Cumulative Model Updates: 58,670
Cumulative Timesteps: 489,307,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,831.53933
Policy Entropy: 3.75008
Value Function Loss: 0.04944

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.55061
Value Function Update Magnitude: 0.78389

Collected Steps per Second: 22,882.68401
Overall Steps per Second: 10,852.78219

Timestep Collection Time: 2.18654
Timestep Consumption Time: 2.42370
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.61025

Cumulative Model Updates: 58,676
Cumulative Timesteps: 489,357,304

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 489357304...
Checkpoint 489357304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.15204
Policy Entropy: 3.75999
Value Function Loss: 0.04947

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.52401
Value Function Update Magnitude: 0.76180

Collected Steps per Second: 22,416.36390
Overall Steps per Second: 10,685.69788

Timestep Collection Time: 2.23096
Timestep Consumption Time: 2.44913
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.68009

Cumulative Model Updates: 58,682
Cumulative Timesteps: 489,407,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,623.41025
Policy Entropy: 3.77453
Value Function Loss: 0.05158

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.51324
Value Function Update Magnitude: 0.70689

Collected Steps per Second: 23,080.73819
Overall Steps per Second: 10,874.07515

Timestep Collection Time: 2.16709
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.59975

Cumulative Model Updates: 58,688
Cumulative Timesteps: 489,457,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 489457332...
Checkpoint 489457332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.26299
Policy Entropy: 3.76425
Value Function Loss: 0.05329

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.56817
Value Function Update Magnitude: 0.68311

Collected Steps per Second: 22,123.64625
Overall Steps per Second: 10,655.92499

Timestep Collection Time: 2.26102
Timestep Consumption Time: 2.43327
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.69429

Cumulative Model Updates: 58,694
Cumulative Timesteps: 489,507,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,867.58301
Policy Entropy: 3.76070
Value Function Loss: 0.05163

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.61245
Value Function Update Magnitude: 0.73336

Collected Steps per Second: 22,996.51539
Overall Steps per Second: 10,833.83343

Timestep Collection Time: 2.17468
Timestep Consumption Time: 2.44142
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.61609

Cumulative Model Updates: 58,700
Cumulative Timesteps: 489,557,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 489557364...
Checkpoint 489557364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,078.57563
Policy Entropy: 3.75919
Value Function Loss: 0.05169

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.63155
Value Function Update Magnitude: 0.76991

Collected Steps per Second: 22,637.50000
Overall Steps per Second: 10,791.94313

Timestep Collection Time: 2.20970
Timestep Consumption Time: 2.42543
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.63512

Cumulative Model Updates: 58,706
Cumulative Timesteps: 489,607,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,880.81967
Policy Entropy: 3.77012
Value Function Loss: 0.05197

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05993
Policy Update Magnitude: 0.65290
Value Function Update Magnitude: 0.78087

Collected Steps per Second: 22,841.03973
Overall Steps per Second: 10,892.39548

Timestep Collection Time: 2.18974
Timestep Consumption Time: 2.40208
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.59183

Cumulative Model Updates: 58,712
Cumulative Timesteps: 489,657,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 489657402...
Checkpoint 489657402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,898.09796
Policy Entropy: 3.77359
Value Function Loss: 0.05343

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.66643
Value Function Update Magnitude: 0.80986

Collected Steps per Second: 22,841.63929
Overall Steps per Second: 10,640.71701

Timestep Collection Time: 2.18995
Timestep Consumption Time: 2.51105
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.70100

Cumulative Model Updates: 58,718
Cumulative Timesteps: 489,707,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,420.31969
Policy Entropy: 3.77333
Value Function Loss: 0.05268

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.63133
Value Function Update Magnitude: 0.84076

Collected Steps per Second: 23,061.07903
Overall Steps per Second: 10,882.26962

Timestep Collection Time: 2.16859
Timestep Consumption Time: 2.42696
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.59555

Cumulative Model Updates: 58,724
Cumulative Timesteps: 489,757,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 489757434...
Checkpoint 489757434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.62856
Policy Entropy: 3.77843
Value Function Loss: 0.05335

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.85339

Collected Steps per Second: 22,829.91979
Overall Steps per Second: 10,735.62301

Timestep Collection Time: 2.19133
Timestep Consumption Time: 2.46866
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.66000

Cumulative Model Updates: 58,730
Cumulative Timesteps: 489,807,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,576.22771
Policy Entropy: 3.76206
Value Function Loss: 0.05509

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.48558
Value Function Update Magnitude: 0.78248

Collected Steps per Second: 22,850.34182
Overall Steps per Second: 10,845.37063

Timestep Collection Time: 2.18824
Timestep Consumption Time: 2.42221
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.61045

Cumulative Model Updates: 58,736
Cumulative Timesteps: 489,857,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 489857464...
Checkpoint 489857464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,223.08245
Policy Entropy: 3.75045
Value Function Loss: 0.05720

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.49999
Value Function Update Magnitude: 0.69092

Collected Steps per Second: 22,701.78373
Overall Steps per Second: 10,729.85961

Timestep Collection Time: 2.20282
Timestep Consumption Time: 2.45782
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.66064

Cumulative Model Updates: 58,742
Cumulative Timesteps: 489,907,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,551.01943
Policy Entropy: 3.74216
Value Function Loss: 0.06048

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.55869
Value Function Update Magnitude: 0.64932

Collected Steps per Second: 22,886.82670
Overall Steps per Second: 10,773.57439

Timestep Collection Time: 2.18562
Timestep Consumption Time: 2.45740
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.64303

Cumulative Model Updates: 58,748
Cumulative Timesteps: 489,957,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 489957494...
Checkpoint 489957494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,634.05886
Policy Entropy: 3.75678
Value Function Loss: 0.05971

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.69870

Collected Steps per Second: 22,862.89348
Overall Steps per Second: 10,636.56660

Timestep Collection Time: 2.18809
Timestep Consumption Time: 2.51512
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.70321

Cumulative Model Updates: 58,754
Cumulative Timesteps: 490,007,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,805.84366
Policy Entropy: 3.76410
Value Function Loss: 0.05871

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.50579
Value Function Update Magnitude: 0.73656

Collected Steps per Second: 23,076.11848
Overall Steps per Second: 10,870.61016

Timestep Collection Time: 2.16735
Timestep Consumption Time: 2.43350
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.60085

Cumulative Model Updates: 58,760
Cumulative Timesteps: 490,057,534

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 490057534...
Checkpoint 490057534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,981.80978
Policy Entropy: 3.76410
Value Function Loss: 0.05849

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.58234
Value Function Update Magnitude: 0.72077

Collected Steps per Second: 22,756.26490
Overall Steps per Second: 10,710.96509

Timestep Collection Time: 2.19816
Timestep Consumption Time: 2.47200
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.67017

Cumulative Model Updates: 58,766
Cumulative Timesteps: 490,107,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,332.44014
Policy Entropy: 3.75519
Value Function Loss: 0.05917

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.65931
Value Function Update Magnitude: 0.76430

Collected Steps per Second: 22,378.91879
Overall Steps per Second: 10,549.88069

Timestep Collection Time: 2.23532
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.74166

Cumulative Model Updates: 58,772
Cumulative Timesteps: 490,157,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 490157580...
Checkpoint 490157580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,339.23157
Policy Entropy: 3.75359
Value Function Loss: 0.05704

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.64909
Value Function Update Magnitude: 0.81726

Collected Steps per Second: 22,870.48343
Overall Steps per Second: 10,726.42769

Timestep Collection Time: 2.18710
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.66325

Cumulative Model Updates: 58,778
Cumulative Timesteps: 490,207,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,944.68946
Policy Entropy: 3.74758
Value Function Loss: 0.05626

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.60012
Value Function Update Magnitude: 0.83160

Collected Steps per Second: 22,832.71484
Overall Steps per Second: 10,727.38615

Timestep Collection Time: 2.19037
Timestep Consumption Time: 2.47172
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.66209

Cumulative Model Updates: 58,784
Cumulative Timesteps: 490,257,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 490257612...
Checkpoint 490257612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,122.60228
Policy Entropy: 3.73961
Value Function Loss: 0.05725

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.78491

Collected Steps per Second: 22,556.87239
Overall Steps per Second: 10,624.32894

Timestep Collection Time: 2.21777
Timestep Consumption Time: 2.49085
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.70863

Cumulative Model Updates: 58,790
Cumulative Timesteps: 490,307,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,782.72842
Policy Entropy: 3.71368
Value Function Loss: 0.05797

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.49482
Value Function Update Magnitude: 0.78755

Collected Steps per Second: 23,063.40191
Overall Steps per Second: 10,851.59147

Timestep Collection Time: 2.16993
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.61186

Cumulative Model Updates: 58,796
Cumulative Timesteps: 490,357,684

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 490357684...
Checkpoint 490357684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,785.37425
Policy Entropy: 3.72390
Value Function Loss: 0.06062

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.49149
Value Function Update Magnitude: 0.72752

Collected Steps per Second: 22,437.30962
Overall Steps per Second: 10,669.58231

Timestep Collection Time: 2.22923
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.68791

Cumulative Model Updates: 58,802
Cumulative Timesteps: 490,407,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,676.63923
Policy Entropy: 3.72585
Value Function Loss: 0.06205

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.51901
Value Function Update Magnitude: 0.71119

Collected Steps per Second: 22,869.37212
Overall Steps per Second: 10,698.36680

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.48738
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.67380

Cumulative Model Updates: 58,808
Cumulative Timesteps: 490,457,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 490457704...
Checkpoint 490457704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,987.84677
Policy Entropy: 3.73557
Value Function Loss: 0.06214

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.50262
Value Function Update Magnitude: 0.74143

Collected Steps per Second: 22,719.51360
Overall Steps per Second: 10,819.29948

Timestep Collection Time: 2.20093
Timestep Consumption Time: 2.42081
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.62174

Cumulative Model Updates: 58,814
Cumulative Timesteps: 490,507,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,480.94745
Policy Entropy: 3.74395
Value Function Loss: 0.05927

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.16556
Policy Update Magnitude: 0.44989
Value Function Update Magnitude: 0.73381

Collected Steps per Second: 22,837.25011
Overall Steps per Second: 10,700.61135

Timestep Collection Time: 2.19072
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.67543

Cumulative Model Updates: 58,820
Cumulative Timesteps: 490,557,738

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 490557738...
Checkpoint 490557738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,608.43381
Policy Entropy: 3.74184
Value Function Loss: 0.05811

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.47419
Value Function Update Magnitude: 0.74854

Collected Steps per Second: 22,703.92965
Overall Steps per Second: 10,794.41901

Timestep Collection Time: 2.20350
Timestep Consumption Time: 2.43112
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.63462

Cumulative Model Updates: 58,826
Cumulative Timesteps: 490,607,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,975.88817
Policy Entropy: 3.74312
Value Function Loss: 0.05697

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.53888
Value Function Update Magnitude: 0.85010

Collected Steps per Second: 22,545.33801
Overall Steps per Second: 10,581.33096

Timestep Collection Time: 2.21864
Timestep Consumption Time: 2.50855
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.72719

Cumulative Model Updates: 58,832
Cumulative Timesteps: 490,657,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 490657786...
Checkpoint 490657786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,243.03155
Policy Entropy: 3.74939
Value Function Loss: 0.05698

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.58174
Value Function Update Magnitude: 0.83283

Collected Steps per Second: 22,485.07875
Overall Steps per Second: 10,591.13414

Timestep Collection Time: 2.22387
Timestep Consumption Time: 2.49743
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.72131

Cumulative Model Updates: 58,838
Cumulative Timesteps: 490,707,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,037.36839
Policy Entropy: 3.75720
Value Function Loss: 0.05687

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.61553
Value Function Update Magnitude: 0.79371

Collected Steps per Second: 22,888.23453
Overall Steps per Second: 10,828.67044

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.43528
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62199

Cumulative Model Updates: 58,844
Cumulative Timesteps: 490,757,840

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 490757840...
Checkpoint 490757840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.04539
Policy Entropy: 3.76129
Value Function Loss: 0.05492

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.58760
Value Function Update Magnitude: 0.71727

Collected Steps per Second: 22,421.33674
Overall Steps per Second: 10,723.24405

Timestep Collection Time: 2.23109
Timestep Consumption Time: 2.43392
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.66501

Cumulative Model Updates: 58,850
Cumulative Timesteps: 490,807,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,668.12519
Policy Entropy: 3.76992
Value Function Loss: 0.05188

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.56752
Value Function Update Magnitude: 0.68013

Collected Steps per Second: 22,967.93201
Overall Steps per Second: 10,845.95288

Timestep Collection Time: 2.17764
Timestep Consumption Time: 2.43384
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.61149

Cumulative Model Updates: 58,856
Cumulative Timesteps: 490,857,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 490857880...
Checkpoint 490857880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,073.27731
Policy Entropy: 3.76873
Value Function Loss: 0.04901

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.59067
Value Function Update Magnitude: 0.73635

Collected Steps per Second: 21,618.24925
Overall Steps per Second: 10,236.83342

Timestep Collection Time: 2.31323
Timestep Consumption Time: 2.57187
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.88510

Cumulative Model Updates: 58,862
Cumulative Timesteps: 490,907,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,471.21409
Policy Entropy: 3.78484
Value Function Loss: 0.04966

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.58624
Value Function Update Magnitude: 0.78464

Collected Steps per Second: 21,955.58965
Overall Steps per Second: 10,430.62480

Timestep Collection Time: 2.27860
Timestep Consumption Time: 2.51766
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.79626

Cumulative Model Updates: 58,868
Cumulative Timesteps: 490,957,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 490957916...
Checkpoint 490957916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,240.73832
Policy Entropy: 3.77890
Value Function Loss: 0.04974

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.62514
Value Function Update Magnitude: 0.80784

Collected Steps per Second: 22,373.53524
Overall Steps per Second: 10,723.84403

Timestep Collection Time: 2.23550
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.66400

Cumulative Model Updates: 58,874
Cumulative Timesteps: 491,007,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,447.09504
Policy Entropy: 3.76488
Value Function Loss: 0.05130

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.66415
Value Function Update Magnitude: 0.80662

Collected Steps per Second: 22,922.18915
Overall Steps per Second: 10,911.91185

Timestep Collection Time: 2.18225
Timestep Consumption Time: 2.40191
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.58416

Cumulative Model Updates: 58,880
Cumulative Timesteps: 491,057,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 491057954...
Checkpoint 491057954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,722.90631
Policy Entropy: 3.75110
Value Function Loss: 0.05422

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.62938
Value Function Update Magnitude: 0.81848

Collected Steps per Second: 22,591.12245
Overall Steps per Second: 10,611.54219

Timestep Collection Time: 2.21450
Timestep Consumption Time: 2.49999
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.71449

Cumulative Model Updates: 58,886
Cumulative Timesteps: 491,107,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,059.77836
Policy Entropy: 3.76187
Value Function Loss: 0.05539

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11098
Policy Update Magnitude: 0.52539
Value Function Update Magnitude: 0.82229

Collected Steps per Second: 22,911.62133
Overall Steps per Second: 10,833.27511

Timestep Collection Time: 2.18378
Timestep Consumption Time: 2.43477
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61855

Cumulative Model Updates: 58,892
Cumulative Timesteps: 491,158,016

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 491158016...
Checkpoint 491158016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,507.00336
Policy Entropy: 3.76030
Value Function Loss: 0.05378

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.81811

Collected Steps per Second: 22,407.04680
Overall Steps per Second: 10,751.76575

Timestep Collection Time: 2.23180
Timestep Consumption Time: 2.41935
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.65114

Cumulative Model Updates: 58,898
Cumulative Timesteps: 491,208,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,747.70698
Policy Entropy: 3.76985
Value Function Loss: 0.05159

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.78109

Collected Steps per Second: 22,819.93244
Overall Steps per Second: 10,823.50332

Timestep Collection Time: 2.19238
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62235

Cumulative Model Updates: 58,904
Cumulative Timesteps: 491,258,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 491258054...
Checkpoint 491258054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,134.33253
Policy Entropy: 3.76260
Value Function Loss: 0.05128

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.49337
Value Function Update Magnitude: 0.71925

Collected Steps per Second: 22,429.85793
Overall Steps per Second: 10,708.05740

Timestep Collection Time: 2.22997
Timestep Consumption Time: 2.44109
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.67106

Cumulative Model Updates: 58,910
Cumulative Timesteps: 491,308,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,608.26722
Policy Entropy: 3.76524
Value Function Loss: 0.05241

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.52010
Value Function Update Magnitude: 0.71387

Collected Steps per Second: 22,840.18974
Overall Steps per Second: 10,781.63141

Timestep Collection Time: 2.18930
Timestep Consumption Time: 2.44859
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.63789

Cumulative Model Updates: 58,916
Cumulative Timesteps: 491,358,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 491358076...
Checkpoint 491358076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,847.63363
Policy Entropy: 3.76481
Value Function Loss: 0.05412

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.51781
Value Function Update Magnitude: 0.67969

Collected Steps per Second: 22,715.21233
Overall Steps per Second: 10,736.36708

Timestep Collection Time: 2.20161
Timestep Consumption Time: 2.45639
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.65800

Cumulative Model Updates: 58,922
Cumulative Timesteps: 491,408,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,153.18452
Policy Entropy: 3.76409
Value Function Loss: 0.05332

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.49102
Value Function Update Magnitude: 0.68209

Collected Steps per Second: 22,798.73035
Overall Steps per Second: 10,823.04733

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.62143

Cumulative Model Updates: 58,928
Cumulative Timesteps: 491,458,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 491458104...
Checkpoint 491458104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,124.47788
Policy Entropy: 3.76332
Value Function Loss: 0.05552

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07509
Policy Update Magnitude: 0.53117
Value Function Update Magnitude: 0.71972

Collected Steps per Second: 22,364.37668
Overall Steps per Second: 10,708.88548

Timestep Collection Time: 2.23650
Timestep Consumption Time: 2.43420
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.67070

Cumulative Model Updates: 58,934
Cumulative Timesteps: 491,508,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,641.54758
Policy Entropy: 3.75968
Value Function Loss: 0.05569

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.56298
Value Function Update Magnitude: 0.77658

Collected Steps per Second: 22,783.50531
Overall Steps per Second: 10,693.42113

Timestep Collection Time: 2.19518
Timestep Consumption Time: 2.48190
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.67708

Cumulative Model Updates: 58,940
Cumulative Timesteps: 491,558,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 491558136...
Checkpoint 491558136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,942.06729
Policy Entropy: 3.74449
Value Function Loss: 0.05627

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.51525
Value Function Update Magnitude: 0.78675

Collected Steps per Second: 22,886.25265
Overall Steps per Second: 10,832.40072

Timestep Collection Time: 2.18507
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61652

Cumulative Model Updates: 58,946
Cumulative Timesteps: 491,608,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,401.93495
Policy Entropy: 3.74572
Value Function Loss: 0.05589

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.51329
Value Function Update Magnitude: 0.77403

Collected Steps per Second: 23,014.58379
Overall Steps per Second: 10,850.53316

Timestep Collection Time: 2.17332
Timestep Consumption Time: 2.43641
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.60973

Cumulative Model Updates: 58,952
Cumulative Timesteps: 491,658,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 491658162...
Checkpoint 491658162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,943.31957
Policy Entropy: 3.74586
Value Function Loss: 0.05607

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.58923
Value Function Update Magnitude: 0.78338

Collected Steps per Second: 22,237.01745
Overall Steps per Second: 10,757.00734

Timestep Collection Time: 2.24877
Timestep Consumption Time: 2.39992
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.64869

Cumulative Model Updates: 58,958
Cumulative Timesteps: 491,708,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,852.39548
Policy Entropy: 3.74562
Value Function Loss: 0.05955

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.52025
Value Function Update Magnitude: 0.77281

Collected Steps per Second: 22,663.47530
Overall Steps per Second: 10,653.99632

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.48798
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.69514

Cumulative Model Updates: 58,964
Cumulative Timesteps: 491,758,190

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 491758190...
Checkpoint 491758190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,067.54326
Policy Entropy: 3.74149
Value Function Loss: 0.06158

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.47239
Value Function Update Magnitude: 0.71978

Collected Steps per Second: 21,824.69531
Overall Steps per Second: 10,407.27795

Timestep Collection Time: 2.29208
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.80664

Cumulative Model Updates: 58,970
Cumulative Timesteps: 491,808,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,458.01881
Policy Entropy: 3.72717
Value Function Loss: 0.06148

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.47544
Value Function Update Magnitude: 0.79860

Collected Steps per Second: 21,069.22084
Overall Steps per Second: 10,187.63380

Timestep Collection Time: 2.37427
Timestep Consumption Time: 2.53600
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.91027

Cumulative Model Updates: 58,976
Cumulative Timesteps: 491,858,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 491858238...
Checkpoint 491858238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,073.71574
Policy Entropy: 3.71715
Value Function Loss: 0.06072

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.77951

Collected Steps per Second: 22,909.21687
Overall Steps per Second: 10,853.84263

Timestep Collection Time: 2.18392
Timestep Consumption Time: 2.42569
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.60961

Cumulative Model Updates: 58,982
Cumulative Timesteps: 491,908,270

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,071.35919
Policy Entropy: 3.72352
Value Function Loss: 0.06006

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10983
Policy Update Magnitude: 0.51802
Value Function Update Magnitude: 0.71055

Collected Steps per Second: 22,874.02668
Overall Steps per Second: 10,615.85345

Timestep Collection Time: 2.18624
Timestep Consumption Time: 2.52446
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.71069

Cumulative Model Updates: 58,988
Cumulative Timesteps: 491,958,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 491958278...
Checkpoint 491958278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,975.71715
Policy Entropy: 3.72921
Value Function Loss: 0.05887

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.47073
Value Function Update Magnitude: 0.73126

Collected Steps per Second: 22,875.23189
Overall Steps per Second: 10,671.61837

Timestep Collection Time: 2.18664
Timestep Consumption Time: 2.50055
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.68720

Cumulative Model Updates: 58,994
Cumulative Timesteps: 492,008,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,413.75132
Policy Entropy: 3.74464
Value Function Loss: 0.05719

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.46632
Value Function Update Magnitude: 0.83408

Collected Steps per Second: 22,639.20196
Overall Steps per Second: 10,744.95958

Timestep Collection Time: 2.20874
Timestep Consumption Time: 2.44498
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.65372

Cumulative Model Updates: 59,000
Cumulative Timesteps: 492,058,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 492058302...
Checkpoint 492058302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,222.93526
Policy Entropy: 3.74535
Value Function Loss: 0.05708

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.44306
Value Function Update Magnitude: 0.89441

Collected Steps per Second: 22,363.12511
Overall Steps per Second: 10,690.96529

Timestep Collection Time: 2.23672
Timestep Consumption Time: 2.44200
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.67872

Cumulative Model Updates: 59,006
Cumulative Timesteps: 492,108,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,228.98067
Policy Entropy: 3.74170
Value Function Loss: 0.05601

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.45901
Value Function Update Magnitude: 0.90372

Collected Steps per Second: 22,716.07787
Overall Steps per Second: 10,767.79289

Timestep Collection Time: 2.20170
Timestep Consumption Time: 2.44308
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.64478

Cumulative Model Updates: 59,012
Cumulative Timesteps: 492,158,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 492158336...
Checkpoint 492158336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,259.65096
Policy Entropy: 3.72757
Value Function Loss: 0.05779

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.47520
Value Function Update Magnitude: 0.89950

Collected Steps per Second: 22,473.92830
Overall Steps per Second: 10,757.42545

Timestep Collection Time: 2.22694
Timestep Consumption Time: 2.42548
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.65241

Cumulative Model Updates: 59,018
Cumulative Timesteps: 492,208,384

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,701.04312
Policy Entropy: 3.73384
Value Function Loss: 0.05719

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.43461
Value Function Update Magnitude: 0.89541

Collected Steps per Second: 22,841.76734
Overall Steps per Second: 10,825.69536

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.43103
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62123

Cumulative Model Updates: 59,024
Cumulative Timesteps: 492,258,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 492258412...
Checkpoint 492258412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,630.81755
Policy Entropy: 3.73102
Value Function Loss: 0.05697

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.46174
Value Function Update Magnitude: 0.89203

Collected Steps per Second: 22,650.75494
Overall Steps per Second: 10,751.81725

Timestep Collection Time: 2.20884
Timestep Consumption Time: 2.44451
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.65335

Cumulative Model Updates: 59,030
Cumulative Timesteps: 492,308,444

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,745.95945
Policy Entropy: 3.74358
Value Function Loss: 0.05722

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.47030
Value Function Update Magnitude: 0.86733

Collected Steps per Second: 23,133.11489
Overall Steps per Second: 10,861.76597

Timestep Collection Time: 2.16218
Timestep Consumption Time: 2.44278
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60496

Cumulative Model Updates: 59,036
Cumulative Timesteps: 492,358,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 492358462...
Checkpoint 492358462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,489.24776
Policy Entropy: 3.73838
Value Function Loss: 0.05850

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.45871
Value Function Update Magnitude: 0.83989

Collected Steps per Second: 22,552.49296
Overall Steps per Second: 10,656.50235

Timestep Collection Time: 2.21705
Timestep Consumption Time: 2.47492
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.69197

Cumulative Model Updates: 59,042
Cumulative Timesteps: 492,408,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,627.99597
Policy Entropy: 3.73974
Value Function Loss: 0.06146

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.47295
Value Function Update Magnitude: 0.79557

Collected Steps per Second: 22,945.56392
Overall Steps per Second: 10,852.70715

Timestep Collection Time: 2.17916
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60733

Cumulative Model Updates: 59,048
Cumulative Timesteps: 492,458,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 492458464...
Checkpoint 492458464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,637.05222
Policy Entropy: 3.74664
Value Function Loss: 0.06345

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.17409
Policy Update Magnitude: 0.44526
Value Function Update Magnitude: 0.69399

Collected Steps per Second: 22,561.16309
Overall Steps per Second: 10,696.44374

Timestep Collection Time: 2.21620
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.67445

Cumulative Model Updates: 59,054
Cumulative Timesteps: 492,508,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,635.57116
Policy Entropy: 3.74393
Value Function Loss: 0.06279

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.44102
Value Function Update Magnitude: 0.70498

Collected Steps per Second: 22,939.89920
Overall Steps per Second: 10,831.15442

Timestep Collection Time: 2.17978
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61668

Cumulative Model Updates: 59,060
Cumulative Timesteps: 492,558,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 492558468...
Checkpoint 492558468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,404.97262
Policy Entropy: 3.73563
Value Function Loss: 0.06107

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.58764
Value Function Update Magnitude: 0.63001

Collected Steps per Second: 22,386.99674
Overall Steps per Second: 10,709.85512

Timestep Collection Time: 2.23398
Timestep Consumption Time: 2.43574
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.66972

Cumulative Model Updates: 59,066
Cumulative Timesteps: 492,608,480

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,036.10434
Policy Entropy: 3.72014
Value Function Loss: 0.06086

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06326
Policy Update Magnitude: 0.68185
Value Function Update Magnitude: 0.62128

Collected Steps per Second: 22,585.83933
Overall Steps per Second: 10,651.72240

Timestep Collection Time: 2.21502
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.69671

Cumulative Model Updates: 59,072
Cumulative Timesteps: 492,658,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 492658508...
Checkpoint 492658508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421.93680
Policy Entropy: 3.72246
Value Function Loss: 0.06512

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.70456
Value Function Update Magnitude: 0.65380

Collected Steps per Second: 22,629.66742
Overall Steps per Second: 10,676.87353

Timestep Collection Time: 2.21055
Timestep Consumption Time: 2.47472
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.68527

Cumulative Model Updates: 59,078
Cumulative Timesteps: 492,708,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,912.42072
Policy Entropy: 3.72445
Value Function Loss: 0.06463

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.60923
Value Function Update Magnitude: 0.65923

Collected Steps per Second: 22,811.67535
Overall Steps per Second: 10,706.42247

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.47923
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.67196

Cumulative Model Updates: 59,084
Cumulative Timesteps: 492,758,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 492758552...
Checkpoint 492758552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,466.23728
Policy Entropy: 3.71614
Value Function Loss: 0.06782

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.54199
Value Function Update Magnitude: 0.61693

Collected Steps per Second: 22,737.13813
Overall Steps per Second: 10,614.04606

Timestep Collection Time: 2.19984
Timestep Consumption Time: 2.51260
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.71243

Cumulative Model Updates: 59,090
Cumulative Timesteps: 492,808,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,805.67942
Policy Entropy: 3.71911
Value Function Loss: 0.06175

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12082
Policy Update Magnitude: 0.51300
Value Function Update Magnitude: 0.54818

Collected Steps per Second: 23,072.84696
Overall Steps per Second: 10,879.99806

Timestep Collection Time: 2.16722
Timestep Consumption Time: 2.42873
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.59596

Cumulative Model Updates: 59,096
Cumulative Timesteps: 492,858,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 492858574...
Checkpoint 492858574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,191.10565
Policy Entropy: 3.73245
Value Function Loss: 0.05788

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.48255
Value Function Update Magnitude: 0.66842

Collected Steps per Second: 22,423.02039
Overall Steps per Second: 10,651.55028

Timestep Collection Time: 2.23056
Timestep Consumption Time: 2.46509
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.69565

Cumulative Model Updates: 59,102
Cumulative Timesteps: 492,908,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,615.89930
Policy Entropy: 3.73042
Value Function Loss: 0.05624

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.55822
Value Function Update Magnitude: 0.75797

Collected Steps per Second: 22,886.99753
Overall Steps per Second: 10,838.99052

Timestep Collection Time: 2.18552
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61482

Cumulative Model Updates: 59,108
Cumulative Timesteps: 492,958,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 492958610...
Checkpoint 492958610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,678.95243
Policy Entropy: 3.73291
Value Function Loss: 0.05700

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.62167
Value Function Update Magnitude: 0.77247

Collected Steps per Second: 22,615.93925
Overall Steps per Second: 10,737.51255

Timestep Collection Time: 2.21101
Timestep Consumption Time: 2.44594
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.65694

Cumulative Model Updates: 59,114
Cumulative Timesteps: 493,008,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,886.92260
Policy Entropy: 3.73094
Value Function Loss: 0.05552

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07168
Policy Update Magnitude: 0.64889
Value Function Update Magnitude: 0.73097

Collected Steps per Second: 22,956.46922
Overall Steps per Second: 10,863.11110

Timestep Collection Time: 2.17891
Timestep Consumption Time: 2.42567
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.60457

Cumulative Model Updates: 59,120
Cumulative Timesteps: 493,058,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 493058634...
Checkpoint 493058634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,750.20981
Policy Entropy: 3.72023
Value Function Loss: 0.05596

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.68426
Value Function Update Magnitude: 0.71168

Collected Steps per Second: 22,613.72760
Overall Steps per Second: 10,701.20487

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.46260
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.67480

Cumulative Model Updates: 59,126
Cumulative Timesteps: 493,108,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,718.62177
Policy Entropy: 3.72038
Value Function Loss: 0.05684

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.68002
Value Function Update Magnitude: 0.66125

Collected Steps per Second: 22,269.20640
Overall Steps per Second: 10,863.48245

Timestep Collection Time: 2.24624
Timestep Consumption Time: 2.35836
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60460

Cumulative Model Updates: 59,132
Cumulative Timesteps: 493,158,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 493158682...
Checkpoint 493158682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,914.62596
Policy Entropy: 3.72114
Value Function Loss: 0.05943

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.59416
Value Function Update Magnitude: 0.61915

Collected Steps per Second: 22,085.67704
Overall Steps per Second: 10,662.55357

Timestep Collection Time: 2.26427
Timestep Consumption Time: 2.42579
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69006

Cumulative Model Updates: 59,138
Cumulative Timesteps: 493,208,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,160.31732
Policy Entropy: 3.72751
Value Function Loss: 0.05728

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.52829
Value Function Update Magnitude: 0.58664

Collected Steps per Second: 22,372.68389
Overall Steps per Second: 10,899.63633

Timestep Collection Time: 2.23505
Timestep Consumption Time: 2.35263
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.58768

Cumulative Model Updates: 59,144
Cumulative Timesteps: 493,258,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 493258694...
Checkpoint 493258694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,444.96722
Policy Entropy: 3.73003
Value Function Loss: 0.05769

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.16255
Policy Update Magnitude: 0.47983
Value Function Update Magnitude: 0.55917

Collected Steps per Second: 22,281.84318
Overall Steps per Second: 10,661.01943

Timestep Collection Time: 2.24515
Timestep Consumption Time: 2.44728
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.69242

Cumulative Model Updates: 59,150
Cumulative Timesteps: 493,308,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,880.82478
Policy Entropy: 3.73313
Value Function Loss: 0.06054

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.15794
Policy Update Magnitude: 0.38779
Value Function Update Magnitude: 0.57266

Collected Steps per Second: 22,213.14822
Overall Steps per Second: 10,847.64572

Timestep Collection Time: 2.25308
Timestep Consumption Time: 2.36064
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.61372

Cumulative Model Updates: 59,156
Cumulative Timesteps: 493,358,768

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 493358768...
Checkpoint 493358768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,128.64288
Policy Entropy: 3.73637
Value Function Loss: 0.06035

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.44880
Value Function Update Magnitude: 0.61114

Collected Steps per Second: 22,035.76253
Overall Steps per Second: 10,713.29027

Timestep Collection Time: 2.26949
Timestep Consumption Time: 2.39854
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.66803

Cumulative Model Updates: 59,162
Cumulative Timesteps: 493,408,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,678.05001
Policy Entropy: 3.73339
Value Function Loss: 0.06046

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.58680

Collected Steps per Second: 22,372.16610
Overall Steps per Second: 10,645.07082

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.46317
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.69908

Cumulative Model Updates: 59,168
Cumulative Timesteps: 493,458,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 493458800...
Checkpoint 493458800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,642.77238
Policy Entropy: 3.73637
Value Function Loss: 0.05874

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06938
Policy Update Magnitude: 0.62659
Value Function Update Magnitude: 0.64520

Collected Steps per Second: 22,992.94064
Overall Steps per Second: 10,962.81608

Timestep Collection Time: 2.17554
Timestep Consumption Time: 2.38734
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.56288

Cumulative Model Updates: 59,174
Cumulative Timesteps: 493,508,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,054.24541
Policy Entropy: 3.73603
Value Function Loss: 0.05821

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07101
Policy Update Magnitude: 0.68165
Value Function Update Magnitude: 0.66932

Collected Steps per Second: 22,989.33921
Overall Steps per Second: 10,829.90588

Timestep Collection Time: 2.17623
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.61962

Cumulative Model Updates: 59,180
Cumulative Timesteps: 493,558,852

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 493558852...
Checkpoint 493558852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,122.22334
Policy Entropy: 3.74490
Value Function Loss: 0.05748

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.63734
Value Function Update Magnitude: 0.65502

Collected Steps per Second: 22,888.89269
Overall Steps per Second: 10,737.40291

Timestep Collection Time: 2.18551
Timestep Consumption Time: 2.47334
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.65885

Cumulative Model Updates: 59,186
Cumulative Timesteps: 493,608,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,374.73031
Policy Entropy: 3.73952
Value Function Loss: 0.05716

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.51546
Value Function Update Magnitude: 0.63192

Collected Steps per Second: 23,182.72211
Overall Steps per Second: 10,810.15177

Timestep Collection Time: 2.15781
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.62750

Cumulative Model Updates: 59,192
Cumulative Timesteps: 493,658,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 493658900...
Checkpoint 493658900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,902.71261
Policy Entropy: 3.73829
Value Function Loss: 0.05949

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.47877
Value Function Update Magnitude: 0.61815

Collected Steps per Second: 22,911.02072
Overall Steps per Second: 10,647.53244

Timestep Collection Time: 2.18305
Timestep Consumption Time: 2.51437
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.69743

Cumulative Model Updates: 59,198
Cumulative Timesteps: 493,708,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,986.88888
Policy Entropy: 3.73784
Value Function Loss: 0.06311

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.45381
Value Function Update Magnitude: 0.65241

Collected Steps per Second: 23,073.03900
Overall Steps per Second: 10,843.15671

Timestep Collection Time: 2.16703
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61120

Cumulative Model Updates: 59,204
Cumulative Timesteps: 493,758,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 493758916...
Checkpoint 493758916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,840.55416
Policy Entropy: 3.74483
Value Function Loss: 0.06283

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.44139
Value Function Update Magnitude: 0.71687

Collected Steps per Second: 22,877.54724
Overall Steps per Second: 10,711.34587

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.48250
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.66813

Cumulative Model Updates: 59,210
Cumulative Timesteps: 493,808,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,808.01176
Policy Entropy: 3.74580
Value Function Loss: 0.06158

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.43649
Value Function Update Magnitude: 0.69307

Collected Steps per Second: 22,840.44956
Overall Steps per Second: 10,830.64763

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.42869
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61893

Cumulative Model Updates: 59,216
Cumulative Timesteps: 493,858,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 493858944...
Checkpoint 493858944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,615.93107
Policy Entropy: 3.74471
Value Function Loss: 0.06037

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.47817
Value Function Update Magnitude: 0.64833

Collected Steps per Second: 22,681.77291
Overall Steps per Second: 10,705.68419

Timestep Collection Time: 2.20485
Timestep Consumption Time: 2.46650
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.67135

Cumulative Model Updates: 59,222
Cumulative Timesteps: 493,908,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,898.67221
Policy Entropy: 3.73463
Value Function Loss: 0.06140

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.53088
Value Function Update Magnitude: 0.65072

Collected Steps per Second: 23,282.14801
Overall Steps per Second: 10,884.65867

Timestep Collection Time: 2.14851
Timestep Consumption Time: 2.44713
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.59564

Cumulative Model Updates: 59,228
Cumulative Timesteps: 493,958,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 493958976...
Checkpoint 493958976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,754.28994
Policy Entropy: 3.74192
Value Function Loss: 0.05873

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.51628
Value Function Update Magnitude: 0.74182

Collected Steps per Second: 22,540.54408
Overall Steps per Second: 10,650.69773

Timestep Collection Time: 2.21831
Timestep Consumption Time: 2.47640
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.69472

Cumulative Model Updates: 59,234
Cumulative Timesteps: 494,008,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,223.80564
Policy Entropy: 3.73996
Value Function Loss: 0.05905

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.52994
Value Function Update Magnitude: 0.75492

Collected Steps per Second: 23,018.65212
Overall Steps per Second: 10,872.99810

Timestep Collection Time: 2.17285
Timestep Consumption Time: 2.42717
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60002

Cumulative Model Updates: 59,240
Cumulative Timesteps: 494,058,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 494058994...
Checkpoint 494058994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,283.19229
Policy Entropy: 3.74061
Value Function Loss: 0.05653

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.53122
Value Function Update Magnitude: 0.69669

Collected Steps per Second: 22,791.81614
Overall Steps per Second: 10,644.33982

Timestep Collection Time: 2.19482
Timestep Consumption Time: 2.50476
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.69959

Cumulative Model Updates: 59,246
Cumulative Timesteps: 494,109,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,579.82119
Policy Entropy: 3.73836
Value Function Loss: 0.05738

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.51005
Value Function Update Magnitude: 0.70558

Collected Steps per Second: 22,804.21011
Overall Steps per Second: 10,840.85991

Timestep Collection Time: 2.19293
Timestep Consumption Time: 2.41999
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.61292

Cumulative Model Updates: 59,252
Cumulative Timesteps: 494,159,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 494159026...
Checkpoint 494159026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,858.05560
Policy Entropy: 3.73928
Value Function Loss: 0.05600

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.55661
Value Function Update Magnitude: 0.79608

Collected Steps per Second: 22,577.17139
Overall Steps per Second: 10,805.36655

Timestep Collection Time: 2.21587
Timestep Consumption Time: 2.41406
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.62992

Cumulative Model Updates: 59,258
Cumulative Timesteps: 494,209,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,695.33554
Policy Entropy: 3.74125
Value Function Loss: 0.05571

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.54558
Value Function Update Magnitude: 0.84767

Collected Steps per Second: 23,219.78837
Overall Steps per Second: 10,863.53340

Timestep Collection Time: 2.15402
Timestep Consumption Time: 2.45000
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.60403

Cumulative Model Updates: 59,264
Cumulative Timesteps: 494,259,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 494259070...
Checkpoint 494259070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,563.85520
Policy Entropy: 3.74186
Value Function Loss: 0.05448

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.55097
Value Function Update Magnitude: 0.84451

Collected Steps per Second: 22,702.63461
Overall Steps per Second: 10,662.82959

Timestep Collection Time: 2.20353
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.69163

Cumulative Model Updates: 59,270
Cumulative Timesteps: 494,309,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,174.24439
Policy Entropy: 3.74998
Value Function Loss: 0.05388

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.61827
Value Function Update Magnitude: 0.80437

Collected Steps per Second: 23,062.87530
Overall Steps per Second: 10,903.04753

Timestep Collection Time: 2.16799
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.58587

Cumulative Model Updates: 59,276
Cumulative Timesteps: 494,359,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 494359096...
Checkpoint 494359096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,161.70269
Policy Entropy: 3.75845
Value Function Loss: 0.05437

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.65325
Value Function Update Magnitude: 0.81137

Collected Steps per Second: 23,028.82079
Overall Steps per Second: 10,740.31309

Timestep Collection Time: 2.17197
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.65703

Cumulative Model Updates: 59,282
Cumulative Timesteps: 494,409,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,190.46297
Policy Entropy: 3.77107
Value Function Loss: 0.05678

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.65099
Value Function Update Magnitude: 0.85252

Collected Steps per Second: 23,031.89675
Overall Steps per Second: 10,798.52551

Timestep Collection Time: 2.17186
Timestep Consumption Time: 2.46044
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.63230

Cumulative Model Updates: 59,288
Cumulative Timesteps: 494,459,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 494459136...
Checkpoint 494459136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,464.59087
Policy Entropy: 3.77540
Value Function Loss: 0.05425

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.54925
Value Function Update Magnitude: 0.84107

Collected Steps per Second: 22,757.77024
Overall Steps per Second: 10,630.95534

Timestep Collection Time: 2.19802
Timestep Consumption Time: 2.50730
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.70532

Cumulative Model Updates: 59,294
Cumulative Timesteps: 494,509,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,974.68557
Policy Entropy: 3.76102
Value Function Loss: 0.05374

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.51181
Value Function Update Magnitude: 0.82588

Collected Steps per Second: 22,321.62787
Overall Steps per Second: 10,870.99806

Timestep Collection Time: 2.23998
Timestep Consumption Time: 2.35941
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.59939

Cumulative Model Updates: 59,300
Cumulative Timesteps: 494,559,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 494559158...
Checkpoint 494559158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.83265
Policy Entropy: 3.76788
Value Function Loss: 0.05360

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.53154
Value Function Update Magnitude: 0.75872

Collected Steps per Second: 22,157.21595
Overall Steps per Second: 10,680.42475

Timestep Collection Time: 2.25759
Timestep Consumption Time: 2.42593
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.68352

Cumulative Model Updates: 59,306
Cumulative Timesteps: 494,609,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,392.09379
Policy Entropy: 3.76516
Value Function Loss: 0.05562

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.53944
Value Function Update Magnitude: 0.68267

Collected Steps per Second: 22,214.50756
Overall Steps per Second: 10,904.35697

Timestep Collection Time: 2.25141
Timestep Consumption Time: 2.33520
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.58661

Cumulative Model Updates: 59,312
Cumulative Timesteps: 494,659,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 494659194...
Checkpoint 494659194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,385.34016
Policy Entropy: 3.78658
Value Function Loss: 0.05463

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.52464
Value Function Update Magnitude: 0.63828

Collected Steps per Second: 21,858.20050
Overall Steps per Second: 10,620.73120

Timestep Collection Time: 2.28839
Timestep Consumption Time: 2.42127
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.70966

Cumulative Model Updates: 59,318
Cumulative Timesteps: 494,709,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,705.81909
Policy Entropy: 3.79047
Value Function Loss: 0.05092

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.56362
Value Function Update Magnitude: 0.70600

Collected Steps per Second: 22,184.06940
Overall Steps per Second: 10,844.13224

Timestep Collection Time: 2.25450
Timestep Consumption Time: 2.35758
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.61208

Cumulative Model Updates: 59,324
Cumulative Timesteps: 494,759,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 494759228...
Checkpoint 494759228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,705.76236
Policy Entropy: 3.80279
Value Function Loss: 0.04948

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.59068
Value Function Update Magnitude: 0.75095

Collected Steps per Second: 21,840.93619
Overall Steps per Second: 10,644.55252

Timestep Collection Time: 2.28946
Timestep Consumption Time: 2.40815
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.69761

Cumulative Model Updates: 59,330
Cumulative Timesteps: 494,809,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,254.12193
Policy Entropy: 3.79904
Value Function Loss: 0.05027

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.61135
Value Function Update Magnitude: 0.77174

Collected Steps per Second: 22,364.14240
Overall Steps per Second: 10,889.27536

Timestep Collection Time: 2.23644
Timestep Consumption Time: 2.35671
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.59314

Cumulative Model Updates: 59,336
Cumulative Timesteps: 494,859,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 494859248...
Checkpoint 494859248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,164.88462
Policy Entropy: 3.80315
Value Function Loss: 0.05184

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.56966
Value Function Update Magnitude: 0.77491

Collected Steps per Second: 21,933.55096
Overall Steps per Second: 10,681.43557

Timestep Collection Time: 2.28043
Timestep Consumption Time: 2.40227
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.68270

Cumulative Model Updates: 59,342
Cumulative Timesteps: 494,909,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,950.48479
Policy Entropy: 3.81071
Value Function Loss: 0.05074

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.55484
Value Function Update Magnitude: 0.80369

Collected Steps per Second: 22,618.68717
Overall Steps per Second: 10,674.95403

Timestep Collection Time: 2.21118
Timestep Consumption Time: 2.47399
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.68517

Cumulative Model Updates: 59,348
Cumulative Timesteps: 494,959,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 494959280...
Checkpoint 494959280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,834.76699
Policy Entropy: 3.79918
Value Function Loss: 0.05003

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.58493
Value Function Update Magnitude: 0.83643

Collected Steps per Second: 22,866.36903
Overall Steps per Second: 10,917.13041

Timestep Collection Time: 2.18732
Timestep Consumption Time: 2.39411
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.58142

Cumulative Model Updates: 59,354
Cumulative Timesteps: 495,009,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,708.57679
Policy Entropy: 3.79514
Value Function Loss: 0.04831

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.83947

Collected Steps per Second: 22,634.37064
Overall Steps per Second: 10,822.98158

Timestep Collection Time: 2.20956
Timestep Consumption Time: 2.41135
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.62091

Cumulative Model Updates: 59,360
Cumulative Timesteps: 495,059,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 495059308...
Checkpoint 495059308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,834.87705
Policy Entropy: 3.79215
Value Function Loss: 0.04848

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.59886
Value Function Update Magnitude: 0.84266

Collected Steps per Second: 22,537.14044
Overall Steps per Second: 10,737.77971

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.43887
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.65832

Cumulative Model Updates: 59,366
Cumulative Timesteps: 495,109,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,482.70210
Policy Entropy: 3.79212
Value Function Loss: 0.04947

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.63825
Value Function Update Magnitude: 0.85122

Collected Steps per Second: 22,830.05387
Overall Steps per Second: 10,887.85953

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.40275
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.59337

Cumulative Model Updates: 59,372
Cumulative Timesteps: 495,159,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 495159340...
Checkpoint 495159340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,737.34283
Policy Entropy: 3.78690
Value Function Loss: 0.05242

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.66367
Value Function Update Magnitude: 0.87586

Collected Steps per Second: 22,868.81797
Overall Steps per Second: 10,651.68566

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.50911
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.69672

Cumulative Model Updates: 59,378
Cumulative Timesteps: 495,209,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,661.26283
Policy Entropy: 3.77888
Value Function Loss: 0.05226

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07187
Policy Update Magnitude: 0.66902
Value Function Update Magnitude: 0.87643

Collected Steps per Second: 22,836.84240
Overall Steps per Second: 10,821.97375

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.62060

Cumulative Model Updates: 59,384
Cumulative Timesteps: 495,259,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 495259372...
Checkpoint 495259372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,561.95016
Policy Entropy: 3.76937
Value Function Loss: 0.05160

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.61461
Value Function Update Magnitude: 0.88610

Collected Steps per Second: 22,310.18012
Overall Steps per Second: 10,694.31258

Timestep Collection Time: 2.24158
Timestep Consumption Time: 2.43474
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.67632

Cumulative Model Updates: 59,390
Cumulative Timesteps: 495,309,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,036.24968
Policy Entropy: 3.77918
Value Function Loss: 0.05089

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.53820
Value Function Update Magnitude: 0.88791

Collected Steps per Second: 22,893.15575
Overall Steps per Second: 10,821.24423

Timestep Collection Time: 2.18423
Timestep Consumption Time: 2.43668
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.62091

Cumulative Model Updates: 59,396
Cumulative Timesteps: 495,359,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 495359386...
Checkpoint 495359386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,125.49004
Policy Entropy: 3.77212
Value Function Loss: 0.05138

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.49986
Value Function Update Magnitude: 0.88149

Collected Steps per Second: 22,547.96718
Overall Steps per Second: 10,802.35340

Timestep Collection Time: 2.21785
Timestep Consumption Time: 2.41151
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.62936

Cumulative Model Updates: 59,402
Cumulative Timesteps: 495,409,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,713.28203
Policy Entropy: 3.78808
Value Function Loss: 0.04940

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.48378
Value Function Update Magnitude: 0.86523

Collected Steps per Second: 22,804.78003
Overall Steps per Second: 10,815.74495

Timestep Collection Time: 2.19322
Timestep Consumption Time: 2.43114
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.62437

Cumulative Model Updates: 59,408
Cumulative Timesteps: 495,459,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 495459410...
Checkpoint 495459410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,464.44809
Policy Entropy: 3.78792
Value Function Loss: 0.04779

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12274
Policy Update Magnitude: 0.46009
Value Function Update Magnitude: 0.86460

Collected Steps per Second: 22,733.86757
Overall Steps per Second: 10,658.11790

Timestep Collection Time: 2.20007
Timestep Consumption Time: 2.49270
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.69276

Cumulative Model Updates: 59,414
Cumulative Timesteps: 495,509,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,302.52188
Policy Entropy: 3.79939
Value Function Loss: 0.04565

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.48192
Value Function Update Magnitude: 0.84110

Collected Steps per Second: 23,059.28978
Overall Steps per Second: 10,867.05064

Timestep Collection Time: 2.16910
Timestep Consumption Time: 2.43362
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.60272

Cumulative Model Updates: 59,420
Cumulative Timesteps: 495,559,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 495559444...
Checkpoint 495559444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,689.35653
Policy Entropy: 3.78077
Value Function Loss: 0.04513

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.48372
Value Function Update Magnitude: 0.80427

Collected Steps per Second: 22,750.68150
Overall Steps per Second: 10,664.96168

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.49091
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.68900

Cumulative Model Updates: 59,426
Cumulative Timesteps: 495,609,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,011.10981
Policy Entropy: 3.76061
Value Function Loss: 0.04779

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.44750
Value Function Update Magnitude: 0.82412

Collected Steps per Second: 22,758.27571
Overall Steps per Second: 10,681.49292

Timestep Collection Time: 2.19700
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.68099

Cumulative Model Updates: 59,432
Cumulative Timesteps: 495,659,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 495659452...
Checkpoint 495659452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,912.13610
Policy Entropy: 3.75490
Value Function Loss: 0.04786

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.43426
Value Function Update Magnitude: 0.83382

Collected Steps per Second: 22,651.00770
Overall Steps per Second: 10,808.64911

Timestep Collection Time: 2.20767
Timestep Consumption Time: 2.41881
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.62648

Cumulative Model Updates: 59,438
Cumulative Timesteps: 495,709,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.80840
Policy Entropy: 3.75887
Value Function Loss: 0.04949

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.51130
Value Function Update Magnitude: 0.79622

Collected Steps per Second: 22,886.04527
Overall Steps per Second: 10,718.85336

Timestep Collection Time: 2.18509
Timestep Consumption Time: 2.48034
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.66542

Cumulative Model Updates: 59,444
Cumulative Timesteps: 495,759,466

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 495759466...
Checkpoint 495759466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,333.81917
Policy Entropy: 3.76759
Value Function Loss: 0.04754

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07614
Policy Update Magnitude: 0.58677
Value Function Update Magnitude: 0.69018

Collected Steps per Second: 22,704.72049
Overall Steps per Second: 10,785.41616

Timestep Collection Time: 2.20236
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.63626

Cumulative Model Updates: 59,450
Cumulative Timesteps: 495,809,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.84519
Policy Entropy: 3.76710
Value Function Loss: 0.04949

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.69875

Collected Steps per Second: 23,125.46452
Overall Steps per Second: 10,891.26765

Timestep Collection Time: 2.16229
Timestep Consumption Time: 2.42891
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59120

Cumulative Model Updates: 59,456
Cumulative Timesteps: 495,859,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 495859474...
Checkpoint 495859474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,845.84177
Policy Entropy: 3.76270
Value Function Loss: 0.05028

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07328
Policy Update Magnitude: 0.59588
Value Function Update Magnitude: 0.76416

Collected Steps per Second: 22,499.11542
Overall Steps per Second: 10,774.81064

Timestep Collection Time: 2.22338
Timestep Consumption Time: 2.41930
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.64268

Cumulative Model Updates: 59,462
Cumulative Timesteps: 495,909,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,413.39735
Policy Entropy: 3.76994
Value Function Loss: 0.05056

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06659
Policy Update Magnitude: 0.63909
Value Function Update Magnitude: 0.80897

Collected Steps per Second: 23,053.24457
Overall Steps per Second: 10,845.46513

Timestep Collection Time: 2.16967
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61188

Cumulative Model Updates: 59,468
Cumulative Timesteps: 495,959,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 495959516...
Checkpoint 495959516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,291.73444
Policy Entropy: 3.77154
Value Function Loss: 0.04823

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.64462
Value Function Update Magnitude: 0.85726

Collected Steps per Second: 22,303.42736
Overall Steps per Second: 10,717.22736

Timestep Collection Time: 2.24315
Timestep Consumption Time: 2.42503
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.66819

Cumulative Model Updates: 59,474
Cumulative Timesteps: 496,009,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,984.39411
Policy Entropy: 3.76986
Value Function Loss: 0.04756

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.59143
Value Function Update Magnitude: 0.86097

Collected Steps per Second: 23,004.49439
Overall Steps per Second: 10,851.09420

Timestep Collection Time: 2.17453
Timestep Consumption Time: 2.43551
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.61004

Cumulative Model Updates: 59,480
Cumulative Timesteps: 496,059,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 496059570...
Checkpoint 496059570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,970.60140
Policy Entropy: 3.75600
Value Function Loss: 0.04800

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.51293
Value Function Update Magnitude: 0.85125

Collected Steps per Second: 22,596.00593
Overall Steps per Second: 10,665.75840

Timestep Collection Time: 2.21402
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.69052

Cumulative Model Updates: 59,486
Cumulative Timesteps: 496,109,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,454.61087
Policy Entropy: 3.75327
Value Function Loss: 0.04850

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.49143
Value Function Update Magnitude: 0.86293

Collected Steps per Second: 23,057.46610
Overall Steps per Second: 10,852.07160

Timestep Collection Time: 2.16936
Timestep Consumption Time: 2.43990
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60926

Cumulative Model Updates: 59,492
Cumulative Timesteps: 496,159,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 496159618...
Checkpoint 496159618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,151.33475
Policy Entropy: 3.75465
Value Function Loss: 0.04698

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.49484
Value Function Update Magnitude: 0.86670

Collected Steps per Second: 22,815.62542
Overall Steps per Second: 10,728.30687

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.47146
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.66504

Cumulative Model Updates: 59,498
Cumulative Timesteps: 496,209,666

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,733.38708
Policy Entropy: 3.75439
Value Function Loss: 0.04841

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.49119
Value Function Update Magnitude: 0.86861

Collected Steps per Second: 22,943.49684
Overall Steps per Second: 10,837.45852

Timestep Collection Time: 2.17944
Timestep Consumption Time: 2.43456
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61400

Cumulative Model Updates: 59,504
Cumulative Timesteps: 496,259,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 496259670...
Checkpoint 496259670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,221.55451
Policy Entropy: 3.75708
Value Function Loss: 0.04915

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07164
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.89202

Collected Steps per Second: 22,547.47515
Overall Steps per Second: 10,679.39213

Timestep Collection Time: 2.21799
Timestep Consumption Time: 2.46486
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.68285

Cumulative Model Updates: 59,510
Cumulative Timesteps: 496,309,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,913.05648
Policy Entropy: 3.75732
Value Function Loss: 0.05074

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06385
Policy Update Magnitude: 0.64435
Value Function Update Magnitude: 0.85795

Collected Steps per Second: 22,862.21220
Overall Steps per Second: 10,830.83360

Timestep Collection Time: 2.18771
Timestep Consumption Time: 2.43021
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61793

Cumulative Model Updates: 59,516
Cumulative Timesteps: 496,359,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 496359696...
Checkpoint 496359696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,745.75092
Policy Entropy: 3.76742
Value Function Loss: 0.05171

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06989
Policy Update Magnitude: 0.66251
Value Function Update Magnitude: 0.75305

Collected Steps per Second: 22,738.37333
Overall Steps per Second: 10,655.05648

Timestep Collection Time: 2.19910
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.69298

Cumulative Model Updates: 59,522
Cumulative Timesteps: 496,409,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,549.24717
Policy Entropy: 3.76437
Value Function Loss: 0.05297

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07169
Policy Update Magnitude: 0.67888
Value Function Update Magnitude: 0.67873

Collected Steps per Second: 22,578.86768
Overall Steps per Second: 10,564.25237

Timestep Collection Time: 2.21499
Timestep Consumption Time: 2.51909
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.73408

Cumulative Model Updates: 59,528
Cumulative Timesteps: 496,459,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 496459712...
Checkpoint 496459712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,451.59544
Policy Entropy: 3.76730
Value Function Loss: 0.05203

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06901
Policy Update Magnitude: 0.67718
Value Function Update Magnitude: 0.74364

Collected Steps per Second: 22,529.86706
Overall Steps per Second: 10,564.03741

Timestep Collection Time: 2.21928
Timestep Consumption Time: 2.51376
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.73304

Cumulative Model Updates: 59,534
Cumulative Timesteps: 496,509,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,877.86423
Policy Entropy: 3.76510
Value Function Loss: 0.05288

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.65865
Value Function Update Magnitude: 0.80220

Collected Steps per Second: 23,007.96996
Overall Steps per Second: 10,831.45075

Timestep Collection Time: 2.17316
Timestep Consumption Time: 2.44303
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61619

Cumulative Model Updates: 59,540
Cumulative Timesteps: 496,559,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 496559712...
Checkpoint 496559712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,638.14718
Policy Entropy: 3.76151
Value Function Loss: 0.05524

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10762
Policy Update Magnitude: 0.58471
Value Function Update Magnitude: 0.82764

Collected Steps per Second: 22,834.83397
Overall Steps per Second: 10,709.29487

Timestep Collection Time: 2.19034
Timestep Consumption Time: 2.48000
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.67034

Cumulative Model Updates: 59,546
Cumulative Timesteps: 496,609,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,224.83296
Policy Entropy: 3.76594
Value Function Loss: 0.05526

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.50184
Value Function Update Magnitude: 0.82571

Collected Steps per Second: 22,624.49579
Overall Steps per Second: 10,657.95881

Timestep Collection Time: 2.21079
Timestep Consumption Time: 2.48223
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.69302

Cumulative Model Updates: 59,552
Cumulative Timesteps: 496,659,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 496659746...
Checkpoint 496659746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,787.53393
Policy Entropy: 3.75996
Value Function Loss: 0.05715

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.47443
Value Function Update Magnitude: 0.78131

Collected Steps per Second: 21,495.33963
Overall Steps per Second: 10,447.39073

Timestep Collection Time: 2.32823
Timestep Consumption Time: 2.46206
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.79029

Cumulative Model Updates: 59,558
Cumulative Timesteps: 496,709,792

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,405.48841
Policy Entropy: 3.76324
Value Function Loss: 0.05364

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.48942
Value Function Update Magnitude: 0.70721

Collected Steps per Second: 22,826.48670
Overall Steps per Second: 10,803.33190

Timestep Collection Time: 2.19079
Timestep Consumption Time: 2.43815
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.62894

Cumulative Model Updates: 59,564
Cumulative Timesteps: 496,759,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 496759800...
Checkpoint 496759800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,886.74013
Policy Entropy: 3.74920
Value Function Loss: 0.05369

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.51811
Value Function Update Magnitude: 0.72147

Collected Steps per Second: 22,445.12601
Overall Steps per Second: 10,715.40172

Timestep Collection Time: 2.22872
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.66842

Cumulative Model Updates: 59,570
Cumulative Timesteps: 496,809,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,556.14718
Policy Entropy: 3.75570
Value Function Loss: 0.05386

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.51448
Value Function Update Magnitude: 0.71511

Collected Steps per Second: 22,998.27120
Overall Steps per Second: 10,861.40704

Timestep Collection Time: 2.17469
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.60474

Cumulative Model Updates: 59,576
Cumulative Timesteps: 496,859,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 496859838...
Checkpoint 496859838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,115.13962
Policy Entropy: 3.75737
Value Function Loss: 0.05641

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06682
Policy Update Magnitude: 0.58695
Value Function Update Magnitude: 0.72846

Collected Steps per Second: 22,348.60881
Overall Steps per Second: 10,740.63400

Timestep Collection Time: 2.23853
Timestep Consumption Time: 2.41930
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.65783

Cumulative Model Updates: 59,582
Cumulative Timesteps: 496,909,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,705.42890
Policy Entropy: 3.75743
Value Function Loss: 0.05533

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06984
Policy Update Magnitude: 0.67624
Value Function Update Magnitude: 0.67585

Collected Steps per Second: 23,038.04364
Overall Steps per Second: 10,850.12453

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60861

Cumulative Model Updates: 59,588
Cumulative Timesteps: 496,959,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 496959870...
Checkpoint 496959870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,933.99210
Policy Entropy: 3.74985
Value Function Loss: 0.05315

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.60634
Value Function Update Magnitude: 0.64689

Collected Steps per Second: 22,520.48254
Overall Steps per Second: 10,662.85504

Timestep Collection Time: 2.22136
Timestep Consumption Time: 2.47026
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.69161

Cumulative Model Updates: 59,594
Cumulative Timesteps: 497,009,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,006.66931
Policy Entropy: 3.73626
Value Function Loss: 0.05418

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.54438
Value Function Update Magnitude: 0.62558

Collected Steps per Second: 23,014.31990
Overall Steps per Second: 10,844.13556

Timestep Collection Time: 2.17265
Timestep Consumption Time: 2.43832
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.61097

Cumulative Model Updates: 59,600
Cumulative Timesteps: 497,059,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 497059898...
Checkpoint 497059898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.32490
Policy Entropy: 3.74309
Value Function Loss: 0.05646

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.57370
Value Function Update Magnitude: 0.64434

Collected Steps per Second: 22,366.68922
Overall Steps per Second: 10,753.08436

Timestep Collection Time: 2.23645
Timestep Consumption Time: 2.41542
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.65187

Cumulative Model Updates: 59,606
Cumulative Timesteps: 497,109,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,636.29076
Policy Entropy: 3.74811
Value Function Loss: 0.05579

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.51991
Value Function Update Magnitude: 0.73150

Collected Steps per Second: 22,865.03568
Overall Steps per Second: 10,822.53611

Timestep Collection Time: 2.18788
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.62239

Cumulative Model Updates: 59,612
Cumulative Timesteps: 497,159,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 497159946...
Checkpoint 497159946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,916.60264
Policy Entropy: 3.74551
Value Function Loss: 0.05436

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.52106
Value Function Update Magnitude: 0.81648

Collected Steps per Second: 22,492.29891
Overall Steps per Second: 10,661.53058

Timestep Collection Time: 2.22352
Timestep Consumption Time: 2.46737
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.69088

Cumulative Model Updates: 59,618
Cumulative Timesteps: 497,209,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,978.43847
Policy Entropy: 3.76265
Value Function Loss: 0.05227

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.49429
Value Function Update Magnitude: 0.83891

Collected Steps per Second: 22,903.82067
Overall Steps per Second: 10,850.04117

Timestep Collection Time: 2.18348
Timestep Consumption Time: 2.42572
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60920

Cumulative Model Updates: 59,624
Cumulative Timesteps: 497,259,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 497259968...
Checkpoint 497259968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,049.99896
Policy Entropy: 3.76276
Value Function Loss: 0.05311

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.51021
Value Function Update Magnitude: 0.82228

Collected Steps per Second: 22,368.78693
Overall Steps per Second: 10,758.79621

Timestep Collection Time: 2.23651
Timestep Consumption Time: 2.41345
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.64996

Cumulative Model Updates: 59,630
Cumulative Timesteps: 497,309,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.46780
Policy Entropy: 3.77315
Value Function Loss: 0.05569

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.55891
Value Function Update Magnitude: 0.83526

Collected Steps per Second: 22,899.19382
Overall Steps per Second: 10,845.44290

Timestep Collection Time: 2.18374
Timestep Consumption Time: 2.42704
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.61078

Cumulative Model Updates: 59,636
Cumulative Timesteps: 497,360,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 497360002...
Checkpoint 497360002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,887.66898
Policy Entropy: 3.78388
Value Function Loss: 0.05640

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.62386
Value Function Update Magnitude: 0.79417

Collected Steps per Second: 22,541.26533
Overall Steps per Second: 10,688.99951

Timestep Collection Time: 2.21851
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.67845

Cumulative Model Updates: 59,642
Cumulative Timesteps: 497,410,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,458.25908
Policy Entropy: 3.78780
Value Function Loss: 0.05547

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.64128
Value Function Update Magnitude: 0.79132

Collected Steps per Second: 23,105.07863
Overall Steps per Second: 10,913.61800

Timestep Collection Time: 2.16446
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.58235

Cumulative Model Updates: 59,648
Cumulative Timesteps: 497,460,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 497460020...
Checkpoint 497460020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,851.94616
Policy Entropy: 3.79638
Value Function Loss: 0.05483

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.58595
Value Function Update Magnitude: 0.84930

Collected Steps per Second: 22,383.70826
Overall Steps per Second: 10,624.14200

Timestep Collection Time: 2.23395
Timestep Consumption Time: 2.47269
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.70664

Cumulative Model Updates: 59,654
Cumulative Timesteps: 497,510,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,204.17246
Policy Entropy: 3.78398
Value Function Loss: 0.05358

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.56005
Value Function Update Magnitude: 0.89924

Collected Steps per Second: 22,810.37278
Overall Steps per Second: 10,801.46587

Timestep Collection Time: 2.19207
Timestep Consumption Time: 2.43711
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.62919

Cumulative Model Updates: 59,660
Cumulative Timesteps: 497,560,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 497560026...
Checkpoint 497560026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.22975
Policy Entropy: 3.78247
Value Function Loss: 0.05352

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.57023
Value Function Update Magnitude: 0.89432

Collected Steps per Second: 22,453.76839
Overall Steps per Second: 10,737.48781

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.43085
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.65863

Cumulative Model Updates: 59,666
Cumulative Timesteps: 497,610,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,824.32907
Policy Entropy: 3.77478
Value Function Loss: 0.05335

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.57354
Value Function Update Magnitude: 0.91359

Collected Steps per Second: 22,667.11698
Overall Steps per Second: 10,682.34721

Timestep Collection Time: 2.20707
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.68324

Cumulative Model Updates: 59,672
Cumulative Timesteps: 497,660,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 497660076...
Checkpoint 497660076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,499.38636
Policy Entropy: 3.77858
Value Function Loss: 0.05443

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.57010
Value Function Update Magnitude: 0.91725

Collected Steps per Second: 22,540.71610
Overall Steps per Second: 10,783.67752

Timestep Collection Time: 2.21839
Timestep Consumption Time: 2.41862
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.63701

Cumulative Model Updates: 59,678
Cumulative Timesteps: 497,710,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,763.66208
Policy Entropy: 3.76888
Value Function Loss: 0.05628

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.88431

Collected Steps per Second: 22,843.57151
Overall Steps per Second: 10,707.73829

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.48112
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.67027

Cumulative Model Updates: 59,684
Cumulative Timesteps: 497,760,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 497760088...
Checkpoint 497760088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,464.81036
Policy Entropy: 3.76717
Value Function Loss: 0.05561

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.85463

Collected Steps per Second: 22,737.09250
Overall Steps per Second: 10,829.43295

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.41916
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.61926

Cumulative Model Updates: 59,690
Cumulative Timesteps: 497,810,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,183.17733
Policy Entropy: 3.76362
Value Function Loss: 0.05246

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.56836
Value Function Update Magnitude: 0.84883

Collected Steps per Second: 23,062.65131
Overall Steps per Second: 10,721.76875

Timestep Collection Time: 2.16905
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.66565

Cumulative Model Updates: 59,696
Cumulative Timesteps: 497,860,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 497860136...
Checkpoint 497860136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,386.44727
Policy Entropy: 3.76371
Value Function Loss: 0.05127

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09087
Policy Update Magnitude: 0.54363
Value Function Update Magnitude: 0.82175

Collected Steps per Second: 22,492.43864
Overall Steps per Second: 10,668.55230

Timestep Collection Time: 2.22404
Timestep Consumption Time: 2.46488
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.68892

Cumulative Model Updates: 59,702
Cumulative Timesteps: 497,910,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,752.79227
Policy Entropy: 3.76565
Value Function Loss: 0.05049

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.56359
Value Function Update Magnitude: 0.83843

Collected Steps per Second: 23,062.99693
Overall Steps per Second: 10,731.03531

Timestep Collection Time: 2.16858
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.66069

Cumulative Model Updates: 59,708
Cumulative Timesteps: 497,960,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 497960174...
Checkpoint 497960174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,657.60998
Policy Entropy: 3.76749
Value Function Loss: 0.05171

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.54541
Value Function Update Magnitude: 0.87136

Collected Steps per Second: 22,107.02127
Overall Steps per Second: 10,683.84923

Timestep Collection Time: 2.26254
Timestep Consumption Time: 2.41911
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.68165

Cumulative Model Updates: 59,714
Cumulative Timesteps: 498,010,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,887.95132
Policy Entropy: 3.76520
Value Function Loss: 0.04985

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10474
Policy Update Magnitude: 0.55161
Value Function Update Magnitude: 0.87846

Collected Steps per Second: 22,203.89162
Overall Steps per Second: 10,863.09289

Timestep Collection Time: 2.25258
Timestep Consumption Time: 2.35164
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.60421

Cumulative Model Updates: 59,720
Cumulative Timesteps: 498,060,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 498060208...
Checkpoint 498060208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,503.09506
Policy Entropy: 3.76457
Value Function Loss: 0.04984

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.55794
Value Function Update Magnitude: 0.87291

Collected Steps per Second: 22,009.58125
Overall Steps per Second: 10,658.85512

Timestep Collection Time: 2.27265
Timestep Consumption Time: 2.42017
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.69281

Cumulative Model Updates: 59,726
Cumulative Timesteps: 498,110,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,201.49441
Policy Entropy: 3.75689
Value Function Loss: 0.05123

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06238
Policy Update Magnitude: 0.64620
Value Function Update Magnitude: 0.85585

Collected Steps per Second: 22,302.93702
Overall Steps per Second: 10,842.52123

Timestep Collection Time: 2.24222
Timestep Consumption Time: 2.37000
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.61221

Cumulative Model Updates: 59,732
Cumulative Timesteps: 498,160,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 498160236...
Checkpoint 498160236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,223.72765
Policy Entropy: 3.75227
Value Function Loss: 0.05272

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06381
Policy Update Magnitude: 0.68049
Value Function Update Magnitude: 0.86787

Collected Steps per Second: 21,774.50596
Overall Steps per Second: 10,659.06430

Timestep Collection Time: 2.29636
Timestep Consumption Time: 2.39468
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.69103

Cumulative Model Updates: 59,738
Cumulative Timesteps: 498,210,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,415.33347
Policy Entropy: 3.74370
Value Function Loss: 0.05237

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06351
Policy Update Magnitude: 0.68450
Value Function Update Magnitude: 0.87317

Collected Steps per Second: 22,181.05452
Overall Steps per Second: 10,586.54843

Timestep Collection Time: 2.25436
Timestep Consumption Time: 2.46900
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.72335

Cumulative Model Updates: 59,744
Cumulative Timesteps: 498,260,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 498260242...
Checkpoint 498260242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,604.35307
Policy Entropy: 3.74983
Value Function Loss: 0.05121

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06644
Policy Update Magnitude: 0.67246
Value Function Update Magnitude: 0.84738

Collected Steps per Second: 22,637.95100
Overall Steps per Second: 10,877.81292

Timestep Collection Time: 2.20895
Timestep Consumption Time: 2.38812
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.59706

Cumulative Model Updates: 59,750
Cumulative Timesteps: 498,310,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,289.62492
Policy Entropy: 3.73966
Value Function Loss: 0.05154

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.58482
Value Function Update Magnitude: 0.86122

Collected Steps per Second: 22,910.89157
Overall Steps per Second: 10,890.28505

Timestep Collection Time: 2.18315
Timestep Consumption Time: 2.40975
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.59290

Cumulative Model Updates: 59,756
Cumulative Timesteps: 498,360,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 498360266...
Checkpoint 498360266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,531.71584
Policy Entropy: 3.74392
Value Function Loss: 0.05219

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.57634
Value Function Update Magnitude: 0.87114

Collected Steps per Second: 22,397.87556
Overall Steps per Second: 10,754.51202

Timestep Collection Time: 2.23352
Timestep Consumption Time: 2.41811
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.65163

Cumulative Model Updates: 59,762
Cumulative Timesteps: 498,410,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,609.60543
Policy Entropy: 3.74020
Value Function Loss: 0.05346

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.60929
Value Function Update Magnitude: 0.86529

Collected Steps per Second: 23,171.72303
Overall Steps per Second: 10,885.22818

Timestep Collection Time: 2.15910
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.59614

Cumulative Model Updates: 59,768
Cumulative Timesteps: 498,460,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 498460322...
Checkpoint 498460322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,288.28024
Policy Entropy: 3.74652
Value Function Loss: 0.05412

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.52474
Value Function Update Magnitude: 0.85827

Collected Steps per Second: 22,497.75774
Overall Steps per Second: 10,659.97986

Timestep Collection Time: 2.22253
Timestep Consumption Time: 2.46810
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.69063

Cumulative Model Updates: 59,774
Cumulative Timesteps: 498,510,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,200.73518
Policy Entropy: 3.75824
Value Function Loss: 0.05558

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.50345
Value Function Update Magnitude: 0.90220

Collected Steps per Second: 23,017.75921
Overall Steps per Second: 10,833.46996

Timestep Collection Time: 2.17284
Timestep Consumption Time: 2.44377
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.61662

Cumulative Model Updates: 59,780
Cumulative Timesteps: 498,560,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 498560338...
Checkpoint 498560338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,443.18236
Policy Entropy: 3.76303
Value Function Loss: 0.05377

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.50828
Value Function Update Magnitude: 0.92081

Collected Steps per Second: 22,709.68347
Overall Steps per Second: 10,717.85451

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.46390
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.66605

Cumulative Model Updates: 59,786
Cumulative Timesteps: 498,610,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,554.16421
Policy Entropy: 3.76860
Value Function Loss: 0.05187

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07173
Policy Update Magnitude: 0.58140
Value Function Update Magnitude: 0.87676

Collected Steps per Second: 22,965.15293
Overall Steps per Second: 10,839.39710

Timestep Collection Time: 2.17808
Timestep Consumption Time: 2.43657
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.61465

Cumulative Model Updates: 59,792
Cumulative Timesteps: 498,660,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 498660368...
Checkpoint 498660368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,063.78609
Policy Entropy: 3.76558
Value Function Loss: 0.05271

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07209
Policy Update Magnitude: 0.62425
Value Function Update Magnitude: 0.83902

Collected Steps per Second: 22,442.10004
Overall Steps per Second: 10,712.34136

Timestep Collection Time: 2.22849
Timestep Consumption Time: 2.44014
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.66863

Cumulative Model Updates: 59,798
Cumulative Timesteps: 498,710,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,911.94111
Policy Entropy: 3.75078
Value Function Loss: 0.05658

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.66342
Value Function Update Magnitude: 0.75248

Collected Steps per Second: 23,198.62780
Overall Steps per Second: 10,863.27104

Timestep Collection Time: 2.15608
Timestep Consumption Time: 2.44825
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.60432

Cumulative Model Updates: 59,804
Cumulative Timesteps: 498,760,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 498760398...
Checkpoint 498760398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.81347
Policy Entropy: 3.72535
Value Function Loss: 0.06010

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.65103
Value Function Update Magnitude: 0.64908

Collected Steps per Second: 22,572.51970
Overall Steps per Second: 10,636.18348

Timestep Collection Time: 2.21526
Timestep Consumption Time: 2.48605
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.70131

Cumulative Model Updates: 59,810
Cumulative Timesteps: 498,810,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,236.52658
Policy Entropy: 3.71694
Value Function Loss: 0.06046

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.62269
Value Function Update Magnitude: 0.68490

Collected Steps per Second: 22,925.51710
Overall Steps per Second: 10,861.25052

Timestep Collection Time: 2.18167
Timestep Consumption Time: 2.42332
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.60499

Cumulative Model Updates: 59,816
Cumulative Timesteps: 498,860,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 498860418...
Checkpoint 498860418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,507.68125
Policy Entropy: 3.73636
Value Function Loss: 0.05827

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.54653
Value Function Update Magnitude: 0.79377

Collected Steps per Second: 22,528.27079
Overall Steps per Second: 10,779.26789

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.42016
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.64057

Cumulative Model Updates: 59,822
Cumulative Timesteps: 498,910,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.50638
Policy Entropy: 3.75581
Value Function Loss: 0.05524

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.51101
Value Function Update Magnitude: 0.81029

Collected Steps per Second: 22,764.77729
Overall Steps per Second: 10,801.25704

Timestep Collection Time: 2.19743
Timestep Consumption Time: 2.43388
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.63131

Cumulative Model Updates: 59,828
Cumulative Timesteps: 498,960,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 498960464...
Checkpoint 498960464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,239.33282
Policy Entropy: 3.76944
Value Function Loss: 0.05432

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.53253
Value Function Update Magnitude: 0.77138

Collected Steps per Second: 22,316.27453
Overall Steps per Second: 10,738.81252

Timestep Collection Time: 2.24079
Timestep Consumption Time: 2.41578
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.65657

Cumulative Model Updates: 59,834
Cumulative Timesteps: 499,010,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,221.68170
Policy Entropy: 3.76849
Value Function Loss: 0.05509

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.58260
Value Function Update Magnitude: 0.73345

Collected Steps per Second: 22,931.73318
Overall Steps per Second: 10,867.46413

Timestep Collection Time: 2.18100
Timestep Consumption Time: 2.42118
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.60218

Cumulative Model Updates: 59,840
Cumulative Timesteps: 499,060,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 499060484...
Checkpoint 499060484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,795.87280
Policy Entropy: 3.76847
Value Function Loss: 0.05540

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.77795

Collected Steps per Second: 22,619.98733
Overall Steps per Second: 10,632.83802

Timestep Collection Time: 2.21052
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.70260

Cumulative Model Updates: 59,846
Cumulative Timesteps: 499,110,486

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,338.59275
Policy Entropy: 3.75818
Value Function Loss: 0.05770

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.53558
Value Function Update Magnitude: 0.81622

Collected Steps per Second: 22,904.53728
Overall Steps per Second: 10,834.02523

Timestep Collection Time: 2.18393
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61712

Cumulative Model Updates: 59,852
Cumulative Timesteps: 499,160,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 499160508...
Checkpoint 499160508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,084.99675
Policy Entropy: 3.73829
Value Function Loss: 0.05762

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.49774
Value Function Update Magnitude: 0.86396

Collected Steps per Second: 22,510.33175
Overall Steps per Second: 10,707.75174

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.67157

Cumulative Model Updates: 59,858
Cumulative Timesteps: 499,210,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,341.49232
Policy Entropy: 3.74188
Value Function Loss: 0.05805

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.47560
Value Function Update Magnitude: 0.88502

Collected Steps per Second: 23,040.31424
Overall Steps per Second: 10,853.63713

Timestep Collection Time: 2.17028
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.60712

Cumulative Model Updates: 59,864
Cumulative Timesteps: 499,260,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 499260534...
Checkpoint 499260534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,264.35791
Policy Entropy: 3.74138
Value Function Loss: 0.05815

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.49008
Value Function Update Magnitude: 0.89698

Collected Steps per Second: 22,466.83008
Overall Steps per Second: 10,703.29145

Timestep Collection Time: 2.22550
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.67146

Cumulative Model Updates: 59,870
Cumulative Timesteps: 499,310,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,155.57758
Policy Entropy: 3.75077
Value Function Loss: 0.05713

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.51729
Value Function Update Magnitude: 0.88345

Collected Steps per Second: 23,089.44106
Overall Steps per Second: 10,881.03262

Timestep Collection Time: 2.16679
Timestep Consumption Time: 2.43112
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.59791

Cumulative Model Updates: 59,876
Cumulative Timesteps: 499,360,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 499360564...
Checkpoint 499360564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,846.46298
Policy Entropy: 3.74570
Value Function Loss: 0.05513

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.52807
Value Function Update Magnitude: 0.88048

Collected Steps per Second: 22,557.39148
Overall Steps per Second: 10,648.58639

Timestep Collection Time: 2.21692
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.69621

Cumulative Model Updates: 59,882
Cumulative Timesteps: 499,410,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,000.85048
Policy Entropy: 3.74967
Value Function Loss: 0.05540

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.48776
Value Function Update Magnitude: 0.87266

Collected Steps per Second: 23,051.07685
Overall Steps per Second: 10,891.08284

Timestep Collection Time: 2.16996
Timestep Consumption Time: 2.42278
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.59275

Cumulative Model Updates: 59,888
Cumulative Timesteps: 499,460,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 499460592...
Checkpoint 499460592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,202.52878
Policy Entropy: 3.75151
Value Function Loss: 0.05645

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.48371
Value Function Update Magnitude: 0.87470

Collected Steps per Second: 22,647.05449
Overall Steps per Second: 10,690.28270

Timestep Collection Time: 2.20832
Timestep Consumption Time: 2.46994
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.67827

Cumulative Model Updates: 59,894
Cumulative Timesteps: 499,510,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,559.93931
Policy Entropy: 3.76096
Value Function Loss: 0.05833

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.53575
Value Function Update Magnitude: 0.87356

Collected Steps per Second: 22,031.48149
Overall Steps per Second: 10,801.33530

Timestep Collection Time: 2.26948
Timestep Consumption Time: 2.35958
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62906

Cumulative Model Updates: 59,900
Cumulative Timesteps: 499,560,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 499560604...
Checkpoint 499560604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,291.34320
Policy Entropy: 3.75643
Value Function Loss: 0.05767

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.51090
Value Function Update Magnitude: 0.84045

Collected Steps per Second: 21,910.07770
Overall Steps per Second: 10,714.54455

Timestep Collection Time: 2.28406
Timestep Consumption Time: 2.38660
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.67066

Cumulative Model Updates: 59,906
Cumulative Timesteps: 499,610,648

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,053.78463
Policy Entropy: 3.75780
Value Function Loss: 0.05691

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.49119
Value Function Update Magnitude: 0.86217

Collected Steps per Second: 22,332.86552
Overall Steps per Second: 10,886.20774

Timestep Collection Time: 2.23957
Timestep Consumption Time: 2.35487
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.59444

Cumulative Model Updates: 59,912
Cumulative Timesteps: 499,660,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 499660664...
Checkpoint 499660664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,674.09265
Policy Entropy: 3.74426
Value Function Loss: 0.05731

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.49759
Value Function Update Magnitude: 0.86221

Collected Steps per Second: 21,625.56406
Overall Steps per Second: 10,749.63321

Timestep Collection Time: 2.31384
Timestep Consumption Time: 2.34102
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.65486

Cumulative Model Updates: 59,918
Cumulative Timesteps: 499,710,702

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,513.38661
Policy Entropy: 3.73641
Value Function Loss: 0.05726

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07567
Policy Update Magnitude: 0.56177
Value Function Update Magnitude: 0.87186

Collected Steps per Second: 22,146.27995
Overall Steps per Second: 10,855.84836

Timestep Collection Time: 2.25853
Timestep Consumption Time: 2.34894
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.60747

Cumulative Model Updates: 59,924
Cumulative Timesteps: 499,760,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 499760720...
Checkpoint 499760720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,088.11582
Policy Entropy: 3.71650
Value Function Loss: 0.05753

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.65810
Value Function Update Magnitude: 0.88881

Collected Steps per Second: 21,694.51962
Overall Steps per Second: 10,599.76098

Timestep Collection Time: 2.30584
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.71935

Cumulative Model Updates: 59,930
Cumulative Timesteps: 499,810,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,056.63904
Policy Entropy: 3.72100
Value Function Loss: 0.05771

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.62950
Value Function Update Magnitude: 0.85136

Collected Steps per Second: 22,970.90633
Overall Steps per Second: 10,909.40975

Timestep Collection Time: 2.17797
Timestep Consumption Time: 2.40798
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.58595

Cumulative Model Updates: 59,936
Cumulative Timesteps: 499,860,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 499860774...
Checkpoint 499860774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,858.53020
Policy Entropy: 3.72290
Value Function Loss: 0.05652

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.62142
Value Function Update Magnitude: 0.85449

Collected Steps per Second: 22,380.18319
Overall Steps per Second: 10,671.45935

Timestep Collection Time: 2.23421
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.68558

Cumulative Model Updates: 59,942
Cumulative Timesteps: 499,910,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,331.11416
Policy Entropy: 3.73692
Value Function Loss: 0.05815

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.53347
Value Function Update Magnitude: 0.85528

Collected Steps per Second: 23,189.49439
Overall Steps per Second: 10,860.43769

Timestep Collection Time: 2.15675
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.60516

Cumulative Model Updates: 59,948
Cumulative Timesteps: 499,960,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 499960790...
Checkpoint 499960790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,236.45009
Policy Entropy: 3.72471
Value Function Loss: 0.05839

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.50578
Value Function Update Magnitude: 0.82813

Collected Steps per Second: 22,309.65838
Overall Steps per Second: 10,654.01593

Timestep Collection Time: 2.24235
Timestep Consumption Time: 2.45316
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.69551

Cumulative Model Updates: 59,954
Cumulative Timesteps: 500,010,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,637.44559
Policy Entropy: 3.73296
Value Function Loss: 0.05786

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.52967
Value Function Update Magnitude: 0.79595

Collected Steps per Second: 23,216.68552
Overall Steps per Second: 10,903.78340

Timestep Collection Time: 2.15397
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.58630

Cumulative Model Updates: 59,960
Cumulative Timesteps: 500,060,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 500060824...
Checkpoint 500060824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,809.64082
Policy Entropy: 3.74033
Value Function Loss: 0.05857

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.51862
Value Function Update Magnitude: 0.82163

Collected Steps per Second: 22,403.28119
Overall Steps per Second: 10,696.17605

Timestep Collection Time: 2.23226
Timestep Consumption Time: 2.44324
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.67550

Cumulative Model Updates: 59,966
Cumulative Timesteps: 500,110,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,759.52492
Policy Entropy: 3.75349
Value Function Loss: 0.05888

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.82217

Collected Steps per Second: 23,037.00793
Overall Steps per Second: 10,849.25682

Timestep Collection Time: 2.17120
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61027

Cumulative Model Updates: 59,972
Cumulative Timesteps: 500,160,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 500160852...
Checkpoint 500160852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,031.31743
Policy Entropy: 3.75556
Value Function Loss: 0.06115

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.55111
Value Function Update Magnitude: 0.70638

Collected Steps per Second: 22,635.34429
Overall Steps per Second: 10,691.02273

Timestep Collection Time: 2.20938
Timestep Consumption Time: 2.46838
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.67776

Cumulative Model Updates: 59,978
Cumulative Timesteps: 500,210,862

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,705.87668
Policy Entropy: 3.75217
Value Function Loss: 0.05953

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06963
Policy Update Magnitude: 0.59487
Value Function Update Magnitude: 0.62781

Collected Steps per Second: 22,999.55734
Overall Steps per Second: 10,856.08658

Timestep Collection Time: 2.17413
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.60608

Cumulative Model Updates: 59,984
Cumulative Timesteps: 500,260,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 500260866...
Checkpoint 500260866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,721.91434
Policy Entropy: 3.75461
Value Function Loss: 0.05796

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 0.68256
Value Function Update Magnitude: 0.61827

Collected Steps per Second: 22,263.12350
Overall Steps per Second: 10,728.73576

Timestep Collection Time: 2.24676
Timestep Consumption Time: 2.41548
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.66225

Cumulative Model Updates: 59,990
Cumulative Timesteps: 500,310,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,284.53654
Policy Entropy: 3.76233
Value Function Loss: 0.05433

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.63000
Value Function Update Magnitude: 0.67586

Collected Steps per Second: 22,952.37087
Overall Steps per Second: 10,863.16609

Timestep Collection Time: 2.17938
Timestep Consumption Time: 2.42535
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.60473

Cumulative Model Updates: 59,996
Cumulative Timesteps: 500,360,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 500360908...
Checkpoint 500360908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.95724
Policy Entropy: 3.76896
Value Function Loss: 0.05681

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.56272
Value Function Update Magnitude: 0.66252

Collected Steps per Second: 22,456.39032
Overall Steps per Second: 10,641.26643

Timestep Collection Time: 2.22680
Timestep Consumption Time: 2.47245
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.69925

Cumulative Model Updates: 60,002
Cumulative Timesteps: 500,410,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,938.13363
Policy Entropy: 3.75514
Value Function Loss: 0.05926

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.54541
Value Function Update Magnitude: 0.70716

Collected Steps per Second: 23,066.69394
Overall Steps per Second: 10,866.75179

Timestep Collection Time: 2.16771
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.60138

Cumulative Model Updates: 60,008
Cumulative Timesteps: 500,460,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 500460916...
Checkpoint 500460916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,128.28284
Policy Entropy: 3.73619
Value Function Loss: 0.06185

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.70414

Collected Steps per Second: 22,181.03292
Overall Steps per Second: 10,713.15720

Timestep Collection Time: 2.25517
Timestep Consumption Time: 2.41404
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.66921

Cumulative Model Updates: 60,014
Cumulative Timesteps: 500,510,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,015.34748
Policy Entropy: 3.73153
Value Function Loss: 0.05971

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.55463
Value Function Update Magnitude: 0.71693

Collected Steps per Second: 23,211.10606
Overall Steps per Second: 10,888.65626

Timestep Collection Time: 2.15466
Timestep Consumption Time: 2.43838
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.59304

Cumulative Model Updates: 60,020
Cumulative Timesteps: 500,560,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 500560950...
Checkpoint 500560950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,305.71588
Policy Entropy: 3.72939
Value Function Loss: 0.06339

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08756
Policy Update Magnitude: 0.62044
Value Function Update Magnitude: 0.62263

Collected Steps per Second: 22,405.18541
Overall Steps per Second: 10,629.07573

Timestep Collection Time: 2.23279
Timestep Consumption Time: 2.47374
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.70652

Cumulative Model Updates: 60,026
Cumulative Timesteps: 500,610,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,131.05694
Policy Entropy: 3.72307
Value Function Loss: 0.06075

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.67254
Value Function Update Magnitude: 0.63036

Collected Steps per Second: 23,090.46065
Overall Steps per Second: 10,902.24624

Timestep Collection Time: 2.16548
Timestep Consumption Time: 2.42091
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.58639

Cumulative Model Updates: 60,032
Cumulative Timesteps: 500,660,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 500660978...
Checkpoint 500660978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,265.14697
Policy Entropy: 3.72413
Value Function Loss: 0.05944

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.66238
Value Function Update Magnitude: 0.74766

Collected Steps per Second: 22,341.36665
Overall Steps per Second: 10,655.98603

Timestep Collection Time: 2.23908
Timestep Consumption Time: 2.45538
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.69445

Cumulative Model Updates: 60,038
Cumulative Timesteps: 500,711,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,245.61879
Policy Entropy: 3.72274
Value Function Loss: 0.05621

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.64180
Value Function Update Magnitude: 0.73069

Collected Steps per Second: 23,006.16954
Overall Steps per Second: 10,875.01615

Timestep Collection Time: 2.17420
Timestep Consumption Time: 2.42533
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.59953

Cumulative Model Updates: 60,044
Cumulative Timesteps: 500,761,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 500761022...
Checkpoint 500761022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,510.58771
Policy Entropy: 3.72528
Value Function Loss: 0.05633

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.63682
Value Function Update Magnitude: 0.71412

Collected Steps per Second: 22,538.91963
Overall Steps per Second: 10,655.23927

Timestep Collection Time: 2.21927
Timestep Consumption Time: 2.47513
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.69440

Cumulative Model Updates: 60,050
Cumulative Timesteps: 500,811,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,956.36330
Policy Entropy: 3.72525
Value Function Loss: 0.05774

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.55631
Value Function Update Magnitude: 0.78747

Collected Steps per Second: 23,119.62894
Overall Steps per Second: 10,918.72120

Timestep Collection Time: 2.16310
Timestep Consumption Time: 2.41711
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.58021

Cumulative Model Updates: 60,056
Cumulative Timesteps: 500,861,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 500861052...
Checkpoint 500861052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,576.09894
Policy Entropy: 3.73935
Value Function Loss: 0.05807

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.51528
Value Function Update Magnitude: 0.83462

Collected Steps per Second: 22,399.03899
Overall Steps per Second: 10,636.13027

Timestep Collection Time: 2.23331
Timestep Consumption Time: 2.46990
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.70321

Cumulative Model Updates: 60,062
Cumulative Timesteps: 500,911,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,303.75747
Policy Entropy: 3.73067
Value Function Loss: 0.05914

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06921
Policy Update Magnitude: 0.52016
Value Function Update Magnitude: 0.85959

Collected Steps per Second: 23,097.92145
Overall Steps per Second: 10,916.87666

Timestep Collection Time: 2.16574
Timestep Consumption Time: 2.41653
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.58226

Cumulative Model Updates: 60,068
Cumulative Timesteps: 500,961,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 500961100...
Checkpoint 500961100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,568.11366
Policy Entropy: 3.72830
Value Function Loss: 0.05790

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.59037
Value Function Update Magnitude: 0.85639

Collected Steps per Second: 21,956.43503
Overall Steps per Second: 10,635.82873

Timestep Collection Time: 2.27824
Timestep Consumption Time: 2.42492
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.70316

Cumulative Model Updates: 60,074
Cumulative Timesteps: 501,011,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,076.36474
Policy Entropy: 3.72681
Value Function Loss: 0.05797

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.54947
Value Function Update Magnitude: 0.80566

Collected Steps per Second: 22,229.74511
Overall Steps per Second: 10,874.12212

Timestep Collection Time: 2.25032
Timestep Consumption Time: 2.34996
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.60028

Cumulative Model Updates: 60,080
Cumulative Timesteps: 501,061,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 501061146...
Checkpoint 501061146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,950.79491
Policy Entropy: 3.72394
Value Function Loss: 0.05729

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.51486
Value Function Update Magnitude: 0.80400

Collected Steps per Second: 21,592.52353
Overall Steps per Second: 10,732.66319

Timestep Collection Time: 2.31589
Timestep Consumption Time: 2.34334
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.65923

Cumulative Model Updates: 60,086
Cumulative Timesteps: 501,111,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,809.72957
Policy Entropy: 3.72538
Value Function Loss: 0.05774

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.60367
Value Function Update Magnitude: 0.84197

Collected Steps per Second: 22,273.02112
Overall Steps per Second: 10,876.74819

Timestep Collection Time: 2.24559
Timestep Consumption Time: 2.35285
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.59843

Cumulative Model Updates: 60,092
Cumulative Timesteps: 501,161,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 501161168...
Checkpoint 501161168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,547.35912
Policy Entropy: 3.71423
Value Function Loss: 0.05828

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.63670
Value Function Update Magnitude: 0.86574

Collected Steps per Second: 21,785.04306
Overall Steps per Second: 10,655.53805

Timestep Collection Time: 2.29543
Timestep Consumption Time: 2.39753
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.69296

Cumulative Model Updates: 60,098
Cumulative Timesteps: 501,211,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,117.45020
Policy Entropy: 3.71805
Value Function Loss: 0.05684

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.55772
Value Function Update Magnitude: 0.87486

Collected Steps per Second: 22,777.82351
Overall Steps per Second: 10,844.69683

Timestep Collection Time: 2.19617
Timestep Consumption Time: 2.41659
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61276

Cumulative Model Updates: 60,104
Cumulative Timesteps: 501,261,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 501261198...
Checkpoint 501261198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,446.99513
Policy Entropy: 3.72344
Value Function Loss: 0.05678

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.51512
Value Function Update Magnitude: 0.86820

Collected Steps per Second: 22,612.21893
Overall Steps per Second: 10,663.36344

Timestep Collection Time: 2.21217
Timestep Consumption Time: 2.47885
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.69102

Cumulative Model Updates: 60,110
Cumulative Timesteps: 501,311,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,164.48092
Policy Entropy: 3.73157
Value Function Loss: 0.05765

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.47928
Value Function Update Magnitude: 0.84564

Collected Steps per Second: 23,014.45470
Overall Steps per Second: 10,918.65744

Timestep Collection Time: 2.17376
Timestep Consumption Time: 2.40812
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.58188

Cumulative Model Updates: 60,116
Cumulative Timesteps: 501,361,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 501361248...
Checkpoint 501361248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,710.74074
Policy Entropy: 3.72644
Value Function Loss: 0.05872

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.46910
Value Function Update Magnitude: 0.85028

Collected Steps per Second: 22,536.12240
Overall Steps per Second: 10,622.44455

Timestep Collection Time: 2.21981
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.70946

Cumulative Model Updates: 60,122
Cumulative Timesteps: 501,411,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,278.80853
Policy Entropy: 3.71114
Value Function Loss: 0.05731

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.55563
Value Function Update Magnitude: 0.80578

Collected Steps per Second: 23,036.86686
Overall Steps per Second: 10,854.03086

Timestep Collection Time: 2.17174
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60935

Cumulative Model Updates: 60,128
Cumulative Timesteps: 501,461,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 501461304...
Checkpoint 501461304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,289.03363
Policy Entropy: 3.71065
Value Function Loss: 0.05896

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.52169
Value Function Update Magnitude: 0.69785

Collected Steps per Second: 22,382.25639
Overall Steps per Second: 10,690.03546

Timestep Collection Time: 2.23534
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.68025

Cumulative Model Updates: 60,134
Cumulative Timesteps: 501,511,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,798.13420
Policy Entropy: 3.70699
Value Function Loss: 0.06176

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.50759
Value Function Update Magnitude: 0.62998

Collected Steps per Second: 22,929.07439
Overall Steps per Second: 10,834.30543

Timestep Collection Time: 2.18090
Timestep Consumption Time: 2.43463
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61552

Cumulative Model Updates: 60,140
Cumulative Timesteps: 501,561,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 501561342...
Checkpoint 501561342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,857.94276
Policy Entropy: 3.71456
Value Function Loss: 0.06674

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.62058
Value Function Update Magnitude: 0.67053

Collected Steps per Second: 22,634.14860
Overall Steps per Second: 10,713.24610

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.45885
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.66861

Cumulative Model Updates: 60,146
Cumulative Timesteps: 501,611,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,003.10329
Policy Entropy: 3.70914
Value Function Loss: 0.06742

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.68615
Value Function Update Magnitude: 0.65556

Collected Steps per Second: 22,791.42579
Overall Steps per Second: 10,826.98897

Timestep Collection Time: 2.19521
Timestep Consumption Time: 2.42583
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62104

Cumulative Model Updates: 60,152
Cumulative Timesteps: 501,661,390

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 501661390...
Checkpoint 501661390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,047.86739
Policy Entropy: 3.71043
Value Function Loss: 0.06480

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.62558
Value Function Update Magnitude: 0.77307

Collected Steps per Second: 22,585.34305
Overall Steps per Second: 10,774.02821

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.42764
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.64209

Cumulative Model Updates: 60,158
Cumulative Timesteps: 501,711,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,353.61262
Policy Entropy: 3.71180
Value Function Loss: 0.06055

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.62018
Value Function Update Magnitude: 0.83752

Collected Steps per Second: 23,015.56457
Overall Steps per Second: 10,880.60558

Timestep Collection Time: 2.17270
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59588

Cumulative Model Updates: 60,164
Cumulative Timesteps: 501,761,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 501761410...
Checkpoint 501761410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,973.19820
Policy Entropy: 3.71593
Value Function Loss: 0.05973

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.66233
Value Function Update Magnitude: 0.79937

Collected Steps per Second: 22,255.91454
Overall Steps per Second: 10,600.25637

Timestep Collection Time: 2.24713
Timestep Consumption Time: 2.47087
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.71800

Cumulative Model Updates: 60,170
Cumulative Timesteps: 501,811,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,149.81970
Policy Entropy: 3.72625
Value Function Loss: 0.06055

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.65473
Value Function Update Magnitude: 0.69546

Collected Steps per Second: 23,002.63792
Overall Steps per Second: 10,924.96549

Timestep Collection Time: 2.17471
Timestep Consumption Time: 2.40416
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.57887

Cumulative Model Updates: 60,176
Cumulative Timesteps: 501,861,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 501861446...
Checkpoint 501861446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,483.85992
Policy Entropy: 3.72707
Value Function Loss: 0.05908

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.76523

Collected Steps per Second: 22,252.81591
Overall Steps per Second: 10,671.44527

Timestep Collection Time: 2.24709
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.68578

Cumulative Model Updates: 60,182
Cumulative Timesteps: 501,911,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,508.67759
Policy Entropy: 3.72907
Value Function Loss: 0.05822

Mean KL Divergence: 0.01904
SB3 Clip Fraction: 0.15854
Policy Update Magnitude: 0.49920
Value Function Update Magnitude: 0.80209

Collected Steps per Second: 23,224.72104
Overall Steps per Second: 10,867.42223

Timestep Collection Time: 2.15408
Timestep Consumption Time: 2.44940
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60348

Cumulative Model Updates: 60,188
Cumulative Timesteps: 501,961,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 501961478...
Checkpoint 501961478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,999.92728
Policy Entropy: 3.73828
Value Function Loss: 0.05587

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.43188
Value Function Update Magnitude: 0.82200

Collected Steps per Second: 22,497.96930
Overall Steps per Second: 10,654.25095

Timestep Collection Time: 2.22251
Timestep Consumption Time: 2.47064
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.69315

Cumulative Model Updates: 60,194
Cumulative Timesteps: 502,011,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,951.81995
Policy Entropy: 3.73754
Value Function Loss: 0.05821

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10573
Policy Update Magnitude: 0.46837
Value Function Update Magnitude: 0.75683

Collected Steps per Second: 22,947.49918
Overall Steps per Second: 10,847.52198

Timestep Collection Time: 2.17941
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.61045

Cumulative Model Updates: 60,200
Cumulative Timesteps: 502,061,492

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 502061492...
Checkpoint 502061492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,637.82588
Policy Entropy: 3.75361
Value Function Loss: 0.05765

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.52453
Value Function Update Magnitude: 0.65769

Collected Steps per Second: 22,732.29306
Overall Steps per Second: 10,721.06977

Timestep Collection Time: 2.19969
Timestep Consumption Time: 2.46440
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.66409

Cumulative Model Updates: 60,206
Cumulative Timesteps: 502,111,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,246.25105
Policy Entropy: 3.74440
Value Function Loss: 0.05927

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.65320

Collected Steps per Second: 22,602.18438
Overall Steps per Second: 10,651.31480

Timestep Collection Time: 2.21262
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.69520

Cumulative Model Updates: 60,212
Cumulative Timesteps: 502,161,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 502161506...
Checkpoint 502161506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,124.31696
Policy Entropy: 3.75409
Value Function Loss: 0.05719

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.52145
Value Function Update Magnitude: 0.71149

Collected Steps per Second: 22,692.05348
Overall Steps per Second: 10,781.61145

Timestep Collection Time: 2.20482
Timestep Consumption Time: 2.43567
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.64049

Cumulative Model Updates: 60,218
Cumulative Timesteps: 502,211,538

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,061.57256
Policy Entropy: 3.74562
Value Function Loss: 0.05871

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.15240
Policy Update Magnitude: 0.50229
Value Function Update Magnitude: 0.68771

Collected Steps per Second: 22,750.60282
Overall Steps per Second: 10,651.49788

Timestep Collection Time: 2.19897
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.69680

Cumulative Model Updates: 60,224
Cumulative Timesteps: 502,261,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 502261566...
Checkpoint 502261566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,249.27212
Policy Entropy: 3.77684
Value Function Loss: 0.05861

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.41630
Value Function Update Magnitude: 0.60063

Collected Steps per Second: 22,412.20374
Overall Steps per Second: 10,544.92042

Timestep Collection Time: 2.23111
Timestep Consumption Time: 2.51089
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.74200

Cumulative Model Updates: 60,230
Cumulative Timesteps: 502,311,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,338.84443
Policy Entropy: 3.76695
Value Function Loss: 0.05562

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.48411
Value Function Update Magnitude: 0.66591

Collected Steps per Second: 22,770.36635
Overall Steps per Second: 10,800.86301

Timestep Collection Time: 2.19707
Timestep Consumption Time: 2.43479
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.63185

Cumulative Model Updates: 60,236
Cumulative Timesteps: 502,361,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 502361598...
Checkpoint 502361598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.21525
Policy Entropy: 3.77519
Value Function Loss: 0.05264

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.60700
Value Function Update Magnitude: 0.72772

Collected Steps per Second: 22,253.46124
Overall Steps per Second: 10,696.64859

Timestep Collection Time: 2.24783
Timestep Consumption Time: 2.42859
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.67642

Cumulative Model Updates: 60,242
Cumulative Timesteps: 502,411,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,890.51898
Policy Entropy: 3.75354
Value Function Loss: 0.05180

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.66208
Value Function Update Magnitude: 0.76718

Collected Steps per Second: 23,109.09318
Overall Steps per Second: 10,905.31130

Timestep Collection Time: 2.16486
Timestep Consumption Time: 2.42263
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.58749

Cumulative Model Updates: 60,248
Cumulative Timesteps: 502,461,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 502461648...
Checkpoint 502461648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,394.28555
Policy Entropy: 3.74662
Value Function Loss: 0.05191

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.63199
Value Function Update Magnitude: 0.77576

Collected Steps per Second: 22,004.52685
Overall Steps per Second: 10,655.68157

Timestep Collection Time: 2.27244
Timestep Consumption Time: 2.42027
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.69271

Cumulative Model Updates: 60,254
Cumulative Timesteps: 502,511,652

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,658.16462
Policy Entropy: 3.73987
Value Function Loss: 0.05371

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.53296
Value Function Update Magnitude: 0.70281

Collected Steps per Second: 22,836.79732
Overall Steps per Second: 10,836.78928

Timestep Collection Time: 2.18971
Timestep Consumption Time: 2.42475
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61447

Cumulative Model Updates: 60,260
Cumulative Timesteps: 502,561,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 502561658...
Checkpoint 502561658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,130.21154
Policy Entropy: 3.74967
Value Function Loss: 0.05387

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.50866
Value Function Update Magnitude: 0.68679

Collected Steps per Second: 22,559.03685
Overall Steps per Second: 10,770.43282

Timestep Collection Time: 2.21738
Timestep Consumption Time: 2.42700
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.64438

Cumulative Model Updates: 60,266
Cumulative Timesteps: 502,611,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,603.18646
Policy Entropy: 3.75351
Value Function Loss: 0.05294

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.50298
Value Function Update Magnitude: 0.70741

Collected Steps per Second: 22,998.10536
Overall Steps per Second: 10,857.88703

Timestep Collection Time: 2.17514
Timestep Consumption Time: 2.43202
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.60716

Cumulative Model Updates: 60,272
Cumulative Timesteps: 502,661,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 502661704...
Checkpoint 502661704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,904.93419
Policy Entropy: 3.74931
Value Function Loss: 0.05326

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.43446
Value Function Update Magnitude: 0.77772

Collected Steps per Second: 22,324.85621
Overall Steps per Second: 10,682.94893

Timestep Collection Time: 2.24019
Timestep Consumption Time: 2.44129
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.68148

Cumulative Model Updates: 60,278
Cumulative Timesteps: 502,711,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,682.66229
Policy Entropy: 3.76383
Value Function Loss: 0.05646

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.45487
Value Function Update Magnitude: 0.71378

Collected Steps per Second: 23,224.00997
Overall Steps per Second: 10,898.03304

Timestep Collection Time: 2.15389
Timestep Consumption Time: 2.43611
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.59000

Cumulative Model Updates: 60,284
Cumulative Timesteps: 502,761,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 502761738...
Checkpoint 502761738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,298.04606
Policy Entropy: 3.76439
Value Function Loss: 0.05588

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.71863

Collected Steps per Second: 22,715.06115
Overall Steps per Second: 10,607.10625

Timestep Collection Time: 2.20171
Timestep Consumption Time: 2.51324
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.71495

Cumulative Model Updates: 60,290
Cumulative Timesteps: 502,811,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,987.36654
Policy Entropy: 3.76815
Value Function Loss: 0.05564

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.53499
Value Function Update Magnitude: 0.71616

Collected Steps per Second: 22,800.80527
Overall Steps per Second: 10,854.07092

Timestep Collection Time: 2.19396
Timestep Consumption Time: 2.41482
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.60878

Cumulative Model Updates: 60,296
Cumulative Timesteps: 502,861,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 502861774...
Checkpoint 502861774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,324.05503
Policy Entropy: 3.75032
Value Function Loss: 0.05521

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06978
Policy Update Magnitude: 0.59319
Value Function Update Magnitude: 0.68890

Collected Steps per Second: 22,399.29351
Overall Steps per Second: 10,777.11003

Timestep Collection Time: 2.23346
Timestep Consumption Time: 2.40860
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.64206

Cumulative Model Updates: 60,302
Cumulative Timesteps: 502,911,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,189.23809
Policy Entropy: 3.74597
Value Function Loss: 0.05797

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.55999
Value Function Update Magnitude: 0.73936

Collected Steps per Second: 23,128.28049
Overall Steps per Second: 10,889.04377

Timestep Collection Time: 2.16281
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.59379

Cumulative Model Updates: 60,308
Cumulative Timesteps: 502,961,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 502961824...
Checkpoint 502961824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,560.07351
Policy Entropy: 3.73729
Value Function Loss: 0.05640

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.51885
Value Function Update Magnitude: 0.72898

Collected Steps per Second: 22,666.13584
Overall Steps per Second: 10,634.36801

Timestep Collection Time: 2.20638
Timestep Consumption Time: 2.49630
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.70268

Cumulative Model Updates: 60,314
Cumulative Timesteps: 503,011,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,323.34699
Policy Entropy: 3.75319
Value Function Loss: 0.05352

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.53468
Value Function Update Magnitude: 0.71441

Collected Steps per Second: 22,985.54823
Overall Steps per Second: 10,838.99254

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.43896
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.61537

Cumulative Model Updates: 60,320
Cumulative Timesteps: 503,061,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 503061860...
Checkpoint 503061860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,109.14592
Policy Entropy: 3.75540
Value Function Loss: 0.05187

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.50378
Value Function Update Magnitude: 0.67851

Collected Steps per Second: 22,446.84929
Overall Steps per Second: 10,678.73804

Timestep Collection Time: 2.22820
Timestep Consumption Time: 2.45550
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.68370

Cumulative Model Updates: 60,326
Cumulative Timesteps: 503,111,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,932.77445
Policy Entropy: 3.76513
Value Function Loss: 0.05478

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.51978
Value Function Update Magnitude: 0.62265

Collected Steps per Second: 22,394.75647
Overall Steps per Second: 10,905.08284

Timestep Collection Time: 2.23275
Timestep Consumption Time: 2.35245
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58520

Cumulative Model Updates: 60,332
Cumulative Timesteps: 503,161,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 503161878...
Checkpoint 503161878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,817.42597
Policy Entropy: 3.74742
Value Function Loss: 0.05733

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.55597
Value Function Update Magnitude: 0.56710

Collected Steps per Second: 22,088.64970
Overall Steps per Second: 10,642.70667

Timestep Collection Time: 2.26361
Timestep Consumption Time: 2.43445
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.69805

Cumulative Model Updates: 60,338
Cumulative Timesteps: 503,211,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,290.48694
Policy Entropy: 3.75810
Value Function Loss: 0.05847

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.56937
Value Function Update Magnitude: 0.57281

Collected Steps per Second: 22,116.99280
Overall Steps per Second: 10,832.12407

Timestep Collection Time: 2.26080
Timestep Consumption Time: 2.35529
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.61608

Cumulative Model Updates: 60,344
Cumulative Timesteps: 503,261,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 503261880...
Checkpoint 503261880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,867.02924
Policy Entropy: 3.75103
Value Function Loss: 0.05934

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.62749

Collected Steps per Second: 21,417.06131
Overall Steps per Second: 10,674.03930

Timestep Collection Time: 2.33589
Timestep Consumption Time: 2.35099
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.68689

Cumulative Model Updates: 60,350
Cumulative Timesteps: 503,311,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,093.67395
Policy Entropy: 3.75760
Value Function Loss: 0.05901

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.58019
Value Function Update Magnitude: 0.63228

Collected Steps per Second: 22,283.84155
Overall Steps per Second: 10,818.27902

Timestep Collection Time: 2.24414
Timestep Consumption Time: 2.37841
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.62255

Cumulative Model Updates: 60,356
Cumulative Timesteps: 503,361,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 503361916...
Checkpoint 503361916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,035.40834
Policy Entropy: 3.75452
Value Function Loss: 0.05829

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.69230

Collected Steps per Second: 21,740.23708
Overall Steps per Second: 10,740.12728

Timestep Collection Time: 2.30034
Timestep Consumption Time: 2.35603
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.65637

Cumulative Model Updates: 60,362
Cumulative Timesteps: 503,411,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,915.51376
Policy Entropy: 3.75889
Value Function Loss: 0.05338

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.54638
Value Function Update Magnitude: 0.76154

Collected Steps per Second: 22,215.06085
Overall Steps per Second: 10,558.23017

Timestep Collection Time: 2.25190
Timestep Consumption Time: 2.48621
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.73810

Cumulative Model Updates: 60,368
Cumulative Timesteps: 503,461,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 503461952...
Checkpoint 503461952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,321.60554
Policy Entropy: 3.75957
Value Function Loss: 0.05224

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.50698
Value Function Update Magnitude: 0.76679

Collected Steps per Second: 22,585.40790
Overall Steps per Second: 10,699.59592

Timestep Collection Time: 2.21470
Timestep Consumption Time: 2.46024
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.67494

Cumulative Model Updates: 60,374
Cumulative Timesteps: 503,511,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,438.73736
Policy Entropy: 3.75841
Value Function Loss: 0.05195

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.49293
Value Function Update Magnitude: 0.79111

Collected Steps per Second: 23,063.62636
Overall Steps per Second: 10,767.17105

Timestep Collection Time: 2.16896
Timestep Consumption Time: 2.47702
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.64597

Cumulative Model Updates: 60,380
Cumulative Timesteps: 503,561,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 503561996...
Checkpoint 503561996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,762.68845
Policy Entropy: 3.74977
Value Function Loss: 0.05374

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07879
Policy Update Magnitude: 0.51363
Value Function Update Magnitude: 0.78042

Collected Steps per Second: 22,636.22651
Overall Steps per Second: 10,651.77993

Timestep Collection Time: 2.20947
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.69537

Cumulative Model Updates: 60,386
Cumulative Timesteps: 503,612,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,552.25666
Policy Entropy: 3.74721
Value Function Loss: 0.05434

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06928
Policy Update Magnitude: 0.58874
Value Function Update Magnitude: 0.77242

Collected Steps per Second: 23,218.25559
Overall Steps per Second: 10,914.34931

Timestep Collection Time: 2.15417
Timestep Consumption Time: 2.42842
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.58259

Cumulative Model Updates: 60,392
Cumulative Timesteps: 503,662,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 503662026...
Checkpoint 503662026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,938.12930
Policy Entropy: 3.75101
Value Function Loss: 0.05491

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06381
Policy Update Magnitude: 0.64337
Value Function Update Magnitude: 0.76561

Collected Steps per Second: 22,465.50547
Overall Steps per Second: 10,640.70365

Timestep Collection Time: 2.22661
Timestep Consumption Time: 2.47439
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.70100

Cumulative Model Updates: 60,398
Cumulative Timesteps: 503,712,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,983.36464
Policy Entropy: 3.74092
Value Function Loss: 0.05726

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06648
Policy Update Magnitude: 0.67613
Value Function Update Magnitude: 0.71031

Collected Steps per Second: 22,951.39986
Overall Steps per Second: 10,828.95039

Timestep Collection Time: 2.17904
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.61836

Cumulative Model Updates: 60,404
Cumulative Timesteps: 503,762,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 503762060...
Checkpoint 503762060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,007.19440
Policy Entropy: 3.73258
Value Function Loss: 0.05694

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.64384
Value Function Update Magnitude: 0.67239

Collected Steps per Second: 22,525.64797
Overall Steps per Second: 10,680.41245

Timestep Collection Time: 2.22022
Timestep Consumption Time: 2.46237
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.68259

Cumulative Model Updates: 60,410
Cumulative Timesteps: 503,812,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,774.13471
Policy Entropy: 3.73199
Value Function Loss: 0.05796

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.55776
Value Function Update Magnitude: 0.72643

Collected Steps per Second: 22,998.09536
Overall Steps per Second: 10,855.88788

Timestep Collection Time: 2.17453
Timestep Consumption Time: 2.43219
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60672

Cumulative Model Updates: 60,416
Cumulative Timesteps: 503,862,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 503862082...
Checkpoint 503862082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,248.84192
Policy Entropy: 3.72989
Value Function Loss: 0.05872

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.49461
Value Function Update Magnitude: 0.70359

Collected Steps per Second: 22,327.09443
Overall Steps per Second: 10,725.53190

Timestep Collection Time: 2.24086
Timestep Consumption Time: 2.42389
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.66476

Cumulative Model Updates: 60,422
Cumulative Timesteps: 503,912,114

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,871.87044
Policy Entropy: 3.74041
Value Function Loss: 0.05795

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.49974
Value Function Update Magnitude: 0.69837

Collected Steps per Second: 23,094.35443
Overall Steps per Second: 10,876.41852

Timestep Collection Time: 2.16564
Timestep Consumption Time: 2.43275
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59839

Cumulative Model Updates: 60,428
Cumulative Timesteps: 503,962,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 503962128...
Checkpoint 503962128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,185.36938
Policy Entropy: 3.73889
Value Function Loss: 0.05840

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06035
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.72067

Collected Steps per Second: 22,629.94734
Overall Steps per Second: 10,670.67610

Timestep Collection Time: 2.21035
Timestep Consumption Time: 2.47727
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.68761

Cumulative Model Updates: 60,434
Cumulative Timesteps: 504,012,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.89661
Policy Entropy: 3.74543
Value Function Loss: 0.05582

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06222
Policy Update Magnitude: 0.66931
Value Function Update Magnitude: 0.71634

Collected Steps per Second: 23,222.90985
Overall Steps per Second: 10,886.72966

Timestep Collection Time: 2.15425
Timestep Consumption Time: 2.44107
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.59532

Cumulative Model Updates: 60,440
Cumulative Timesteps: 504,062,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 504062176...
Checkpoint 504062176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,348.78994
Policy Entropy: 3.73851
Value Function Loss: 0.05848

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.55081
Value Function Update Magnitude: 0.67300

Collected Steps per Second: 22,474.07057
Overall Steps per Second: 10,677.21545

Timestep Collection Time: 2.22488
Timestep Consumption Time: 2.45818
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.68306

Cumulative Model Updates: 60,446
Cumulative Timesteps: 504,112,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,359.07480
Policy Entropy: 3.73637
Value Function Loss: 0.06176

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.53700
Value Function Update Magnitude: 0.71033

Collected Steps per Second: 23,157.59213
Overall Steps per Second: 10,920.02856

Timestep Collection Time: 2.16016
Timestep Consumption Time: 2.42078
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.58094

Cumulative Model Updates: 60,452
Cumulative Timesteps: 504,162,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 504162202...
Checkpoint 504162202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,470.32720
Policy Entropy: 3.73960
Value Function Loss: 0.06195

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.56917
Value Function Update Magnitude: 0.75900

Collected Steps per Second: 22,592.14259
Overall Steps per Second: 10,591.73697

Timestep Collection Time: 2.21404
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.72255

Cumulative Model Updates: 60,458
Cumulative Timesteps: 504,212,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,733.87235
Policy Entropy: 3.73560
Value Function Loss: 0.06398

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.48550
Value Function Update Magnitude: 0.68874

Collected Steps per Second: 23,069.90360
Overall Steps per Second: 10,882.75916

Timestep Collection Time: 2.16880
Timestep Consumption Time: 2.42875
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.59755

Cumulative Model Updates: 60,464
Cumulative Timesteps: 504,262,256

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 504262256...
Checkpoint 504262256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,226.54085
Policy Entropy: 3.73284
Value Function Loss: 0.06241

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.45526
Value Function Update Magnitude: 0.71116

Collected Steps per Second: 22,006.85729
Overall Steps per Second: 10,636.38552

Timestep Collection Time: 2.27247
Timestep Consumption Time: 2.42931
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.70179

Cumulative Model Updates: 60,470
Cumulative Timesteps: 504,312,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,942.98219
Policy Entropy: 3.71988
Value Function Loss: 0.06374

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.46785
Value Function Update Magnitude: 0.70357

Collected Steps per Second: 22,714.07690
Overall Steps per Second: 10,632.74327

Timestep Collection Time: 2.20145
Timestep Consumption Time: 2.50138
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.70283

Cumulative Model Updates: 60,476
Cumulative Timesteps: 504,362,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 504362270...
Checkpoint 504362270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,892.62503
Policy Entropy: 3.72358
Value Function Loss: 0.06276

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.50305
Value Function Update Magnitude: 0.67758

Collected Steps per Second: 22,518.76072
Overall Steps per Second: 10,694.13618

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.45538
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.67602

Cumulative Model Updates: 60,482
Cumulative Timesteps: 504,412,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,611.70908
Policy Entropy: 3.71307
Value Function Loss: 0.06246

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.53986
Value Function Update Magnitude: 0.72935

Collected Steps per Second: 23,187.26611
Overall Steps per Second: 10,697.09655

Timestep Collection Time: 2.15670
Timestep Consumption Time: 2.51821
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.67491

Cumulative Model Updates: 60,488
Cumulative Timesteps: 504,462,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 504462284...
Checkpoint 504462284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,718.73901
Policy Entropy: 3.72608
Value Function Loss: 0.06092

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.78991

Collected Steps per Second: 22,507.42281
Overall Steps per Second: 10,662.66757

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.46935
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.69226

Cumulative Model Updates: 60,494
Cumulative Timesteps: 504,512,316

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,554.91413
Policy Entropy: 3.71571
Value Function Loss: 0.06027

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.16709
Policy Update Magnitude: 0.46235
Value Function Update Magnitude: 0.80653

Collected Steps per Second: 22,649.23012
Overall Steps per Second: 10,644.50784

Timestep Collection Time: 2.20882
Timestep Consumption Time: 2.49107
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.69989

Cumulative Model Updates: 60,500
Cumulative Timesteps: 504,562,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 504562344...
Checkpoint 504562344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,147.83440
Policy Entropy: 3.71601
Value Function Loss: 0.05929

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.44264
Value Function Update Magnitude: 0.80259

Collected Steps per Second: 22,876.80225
Overall Steps per Second: 10,846.79982

Timestep Collection Time: 2.18649
Timestep Consumption Time: 2.42500
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.61150

Cumulative Model Updates: 60,506
Cumulative Timesteps: 504,612,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,326.05395
Policy Entropy: 3.69133
Value Function Loss: 0.05962

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.55784
Value Function Update Magnitude: 0.78862

Collected Steps per Second: 22,984.99174
Overall Steps per Second: 10,736.87459

Timestep Collection Time: 2.17585
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.65797

Cumulative Model Updates: 60,512
Cumulative Timesteps: 504,662,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 504662376...
Checkpoint 504662376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,032.54323
Policy Entropy: 3.69018
Value Function Loss: 0.06326

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.52994
Value Function Update Magnitude: 0.78748

Collected Steps per Second: 22,471.70611
Overall Steps per Second: 10,764.62555

Timestep Collection Time: 2.22511
Timestep Consumption Time: 2.41992
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.64503

Cumulative Model Updates: 60,518
Cumulative Timesteps: 504,712,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,283.11053
Policy Entropy: 3.68114
Value Function Loss: 0.06374

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.61326
Value Function Update Magnitude: 0.84025

Collected Steps per Second: 23,016.88658
Overall Steps per Second: 10,707.89351

Timestep Collection Time: 2.17267
Timestep Consumption Time: 2.49753
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.67020

Cumulative Model Updates: 60,524
Cumulative Timesteps: 504,762,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 504762386...
Checkpoint 504762386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,338.83879
Policy Entropy: 3.69046
Value Function Loss: 0.06412

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07189
Policy Update Magnitude: 0.70084
Value Function Update Magnitude: 0.74083

Collected Steps per Second: 22,688.27109
Overall Steps per Second: 10,668.12840

Timestep Collection Time: 2.20387
Timestep Consumption Time: 2.48318
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.68705

Cumulative Model Updates: 60,530
Cumulative Timesteps: 504,812,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,529.15484
Policy Entropy: 3.69414
Value Function Loss: 0.06223

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07243
Policy Update Magnitude: 0.70980
Value Function Update Magnitude: 0.64475

Collected Steps per Second: 23,222.73964
Overall Steps per Second: 10,709.90918

Timestep Collection Time: 2.15392
Timestep Consumption Time: 2.51652
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.67044

Cumulative Model Updates: 60,536
Cumulative Timesteps: 504,862,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 504862408...
Checkpoint 504862408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,565.48070
Policy Entropy: 3.69446
Value Function Loss: 0.06318

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.64679
Value Function Update Magnitude: 0.59251

Collected Steps per Second: 22,518.21622
Overall Steps per Second: 10,637.79480

Timestep Collection Time: 2.22176
Timestep Consumption Time: 2.48129
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.70304

Cumulative Model Updates: 60,542
Cumulative Timesteps: 504,912,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,087.55148
Policy Entropy: 3.70452
Value Function Loss: 0.06455

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.57910

Collected Steps per Second: 22,728.21450
Overall Steps per Second: 10,666.22269

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.48888
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.68976

Cumulative Model Updates: 60,548
Cumulative Timesteps: 504,962,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 504962460...
Checkpoint 504962460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,747.58344
Policy Entropy: 3.70324
Value Function Loss: 0.06559

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.52063
Value Function Update Magnitude: 0.59854

Collected Steps per Second: 22,826.72999
Overall Steps per Second: 10,891.44569

Timestep Collection Time: 2.19103
Timestep Consumption Time: 2.40102
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.59204

Cumulative Model Updates: 60,554
Cumulative Timesteps: 505,012,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,873.87623
Policy Entropy: 3.70220
Value Function Loss: 0.06580

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07057
Policy Update Magnitude: 0.57722
Value Function Update Magnitude: 0.65525

Collected Steps per Second: 23,334.11736
Overall Steps per Second: 10,974.63035

Timestep Collection Time: 2.14321
Timestep Consumption Time: 2.41366
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.55687

Cumulative Model Updates: 60,560
Cumulative Timesteps: 505,062,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 505062484...
Checkpoint 505062484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,156.65948
Policy Entropy: 3.69446
Value Function Loss: 0.06476

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.55352
Value Function Update Magnitude: 0.65422

Collected Steps per Second: 22,205.66570
Overall Steps per Second: 10,570.54144

Timestep Collection Time: 2.25222
Timestep Consumption Time: 2.47904
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.73126

Cumulative Model Updates: 60,566
Cumulative Timesteps: 505,112,496

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,122.85075
Policy Entropy: 3.69385
Value Function Loss: 0.06374

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.56730
Value Function Update Magnitude: 0.65138

Collected Steps per Second: 23,056.53584
Overall Steps per Second: 10,841.73076

Timestep Collection Time: 2.16980
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.61439

Cumulative Model Updates: 60,572
Cumulative Timesteps: 505,162,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 505162524...
Checkpoint 505162524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,621.40426
Policy Entropy: 3.69912
Value Function Loss: 0.06050

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.50817
Value Function Update Magnitude: 0.74603

Collected Steps per Second: 22,352.06927
Overall Steps per Second: 10,734.41639

Timestep Collection Time: 2.23756
Timestep Consumption Time: 2.42166
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.65922

Cumulative Model Updates: 60,578
Cumulative Timesteps: 505,212,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,852.69463
Policy Entropy: 3.70836
Value Function Loss: 0.05753

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.48972
Value Function Update Magnitude: 0.82039

Collected Steps per Second: 23,018.93159
Overall Steps per Second: 10,857.09462

Timestep Collection Time: 2.17352
Timestep Consumption Time: 2.43472
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.60823

Cumulative Model Updates: 60,584
Cumulative Timesteps: 505,262,570

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 505262570...
Checkpoint 505262570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,349.08297
Policy Entropy: 3.71857
Value Function Loss: 0.05457

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.44549
Value Function Update Magnitude: 0.84708

Collected Steps per Second: 22,396.87579
Overall Steps per Second: 10,676.53548

Timestep Collection Time: 2.23370
Timestep Consumption Time: 2.45209
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.68579

Cumulative Model Updates: 60,590
Cumulative Timesteps: 505,312,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,042.70338
Policy Entropy: 3.72380
Value Function Loss: 0.05611

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.15506
Policy Update Magnitude: 0.43739
Value Function Update Magnitude: 0.84886

Collected Steps per Second: 22,871.35330
Overall Steps per Second: 10,817.44585

Timestep Collection Time: 2.18737
Timestep Consumption Time: 2.43739
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.62475

Cumulative Model Updates: 60,596
Cumulative Timesteps: 505,362,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 505362626...
Checkpoint 505362626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,127.57570
Policy Entropy: 3.73661
Value Function Loss: 0.05773

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.15587
Policy Update Magnitude: 0.42623
Value Function Update Magnitude: 0.80841

Collected Steps per Second: 22,455.04210
Overall Steps per Second: 10,695.40034

Timestep Collection Time: 2.22721
Timestep Consumption Time: 2.44882
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.67603

Cumulative Model Updates: 60,602
Cumulative Timesteps: 505,412,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,382.08326
Policy Entropy: 3.74694
Value Function Loss: 0.05782

Mean KL Divergence: 0.02069
SB3 Clip Fraction: 0.16799
Policy Update Magnitude: 0.45464
Value Function Update Magnitude: 0.70100

Collected Steps per Second: 22,977.21633
Overall Steps per Second: 10,868.24966

Timestep Collection Time: 2.17720
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.60295

Cumulative Model Updates: 60,608
Cumulative Timesteps: 505,462,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 505462664...
Checkpoint 505462664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,099.07505
Policy Entropy: 3.74146
Value Function Loss: 0.05631

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.42812
Value Function Update Magnitude: 0.65207

Collected Steps per Second: 22,562.00865
Overall Steps per Second: 10,675.88199

Timestep Collection Time: 2.21682
Timestep Consumption Time: 2.46813
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.68495

Cumulative Model Updates: 60,614
Cumulative Timesteps: 505,512,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,240.98550
Policy Entropy: 3.73251
Value Function Loss: 0.05644

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.47719
Value Function Update Magnitude: 0.66084

Collected Steps per Second: 22,959.58888
Overall Steps per Second: 10,856.16767

Timestep Collection Time: 2.17826
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60678

Cumulative Model Updates: 60,620
Cumulative Timesteps: 505,562,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 505562692...
Checkpoint 505562692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,079.48315
Policy Entropy: 3.74105
Value Function Loss: 0.05545

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.52011
Value Function Update Magnitude: 0.69013

Collected Steps per Second: 22,377.70450
Overall Steps per Second: 10,760.34537

Timestep Collection Time: 2.23437
Timestep Consumption Time: 2.41232
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.64669

Cumulative Model Updates: 60,626
Cumulative Timesteps: 505,612,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,304.00492
Policy Entropy: 3.73694
Value Function Loss: 0.05515

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.51404
Value Function Update Magnitude: 0.70989

Collected Steps per Second: 23,395.18396
Overall Steps per Second: 10,874.38824

Timestep Collection Time: 2.13719
Timestep Consumption Time: 2.46077
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.59796

Cumulative Model Updates: 60,632
Cumulative Timesteps: 505,662,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 505662692...
Checkpoint 505662692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,718.89574
Policy Entropy: 3.72996
Value Function Loss: 0.05529

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.50135
Value Function Update Magnitude: 0.67196

Collected Steps per Second: 22,504.95533
Overall Steps per Second: 10,616.63854

Timestep Collection Time: 2.22235
Timestep Consumption Time: 2.48855
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.71091

Cumulative Model Updates: 60,638
Cumulative Timesteps: 505,712,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,038.36858
Policy Entropy: 3.72399
Value Function Loss: 0.05530

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.50069
Value Function Update Magnitude: 0.67780

Collected Steps per Second: 22,190.70545
Overall Steps per Second: 10,829.13490

Timestep Collection Time: 2.25383
Timestep Consumption Time: 2.36464
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.61847

Cumulative Model Updates: 60,644
Cumulative Timesteps: 505,762,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 505762720...
Checkpoint 505762720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,841.46942
Policy Entropy: 3.72553
Value Function Loss: 0.05572

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.76848

Collected Steps per Second: 21,932.66686
Overall Steps per Second: 10,760.36399

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.36802
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.64873

Cumulative Model Updates: 60,650
Cumulative Timesteps: 505,812,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,495.96139
Policy Entropy: 3.72677
Value Function Loss: 0.05517

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.61096
Value Function Update Magnitude: 0.84623

Collected Steps per Second: 22,255.67876
Overall Steps per Second: 10,845.88092

Timestep Collection Time: 2.24743
Timestep Consumption Time: 2.36428
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.61170

Cumulative Model Updates: 60,656
Cumulative Timesteps: 505,862,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 505862760...
Checkpoint 505862760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,246.39757
Policy Entropy: 3.71880
Value Function Loss: 0.05788

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.64017
Value Function Update Magnitude: 0.85584

Collected Steps per Second: 21,904.03451
Overall Steps per Second: 10,646.92022

Timestep Collection Time: 2.28396
Timestep Consumption Time: 2.41486
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.69882

Cumulative Model Updates: 60,662
Cumulative Timesteps: 505,912,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,123.16982
Policy Entropy: 3.70949
Value Function Loss: 0.05806

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.54623
Value Function Update Magnitude: 0.80766

Collected Steps per Second: 21,735.33409
Overall Steps per Second: 10,553.88708

Timestep Collection Time: 2.30141
Timestep Consumption Time: 2.43826
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.73968

Cumulative Model Updates: 60,668
Cumulative Timesteps: 505,962,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 505962810...
Checkpoint 505962810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,888.18352
Policy Entropy: 3.70967
Value Function Loss: 0.05819

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.50787
Value Function Update Magnitude: 0.85457

Collected Steps per Second: 21,968.71349
Overall Steps per Second: 10,631.44329

Timestep Collection Time: 2.27678
Timestep Consumption Time: 2.42794
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.70472

Cumulative Model Updates: 60,674
Cumulative Timesteps: 506,012,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,214.85168
Policy Entropy: 3.72283
Value Function Loss: 0.05541

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.49337
Value Function Update Magnitude: 0.85904

Collected Steps per Second: 22,320.87854
Overall Steps per Second: 10,747.00081

Timestep Collection Time: 2.24014
Timestep Consumption Time: 2.41250
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.65265

Cumulative Model Updates: 60,680
Cumulative Timesteps: 506,062,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 506062830...
Checkpoint 506062830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,527.86676
Policy Entropy: 3.71471
Value Function Loss: 0.05378

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.52452
Value Function Update Magnitude: 0.85206

Collected Steps per Second: 22,386.46320
Overall Steps per Second: 10,728.22772

Timestep Collection Time: 2.23483
Timestep Consumption Time: 2.42857
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.66340

Cumulative Model Updates: 60,686
Cumulative Timesteps: 506,112,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,232.92879
Policy Entropy: 3.71103
Value Function Loss: 0.05385

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.59417
Value Function Update Magnitude: 0.86739

Collected Steps per Second: 22,962.86308
Overall Steps per Second: 10,890.77945

Timestep Collection Time: 2.17821
Timestep Consumption Time: 2.41448
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.59269

Cumulative Model Updates: 60,692
Cumulative Timesteps: 506,162,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 506162878...
Checkpoint 506162878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,638.03835
Policy Entropy: 3.70735
Value Function Loss: 0.05585

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.66340
Value Function Update Magnitude: 0.86846

Collected Steps per Second: 22,591.82208
Overall Steps per Second: 10,640.82548

Timestep Collection Time: 2.21372
Timestep Consumption Time: 2.48629
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.70001

Cumulative Model Updates: 60,698
Cumulative Timesteps: 506,212,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,404.57020
Policy Entropy: 3.71424
Value Function Loss: 0.05614

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.60638
Value Function Update Magnitude: 0.85072

Collected Steps per Second: 22,826.23961
Overall Steps per Second: 10,878.55604

Timestep Collection Time: 2.19169
Timestep Consumption Time: 2.40708
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59877

Cumulative Model Updates: 60,704
Cumulative Timesteps: 506,262,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 506262918...
Checkpoint 506262918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,551.21921
Policy Entropy: 3.70971
Value Function Loss: 0.05555

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11236
Policy Update Magnitude: 0.53053
Value Function Update Magnitude: 0.81700

Collected Steps per Second: 22,283.12372
Overall Steps per Second: 10,734.81265

Timestep Collection Time: 2.24439
Timestep Consumption Time: 2.41447
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.65886

Cumulative Model Updates: 60,710
Cumulative Timesteps: 506,312,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,062.24013
Policy Entropy: 3.71943
Value Function Loss: 0.05478

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.50192
Value Function Update Magnitude: 0.81123

Collected Steps per Second: 22,931.09505
Overall Steps per Second: 10,863.32654

Timestep Collection Time: 2.18158
Timestep Consumption Time: 2.42346
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.60504

Cumulative Model Updates: 60,716
Cumulative Timesteps: 506,362,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 506362956...
Checkpoint 506362956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,232.21575
Policy Entropy: 3.71726
Value Function Loss: 0.05437

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.53306
Value Function Update Magnitude: 0.82784

Collected Steps per Second: 22,772.65447
Overall Steps per Second: 10,609.44818

Timestep Collection Time: 2.19597
Timestep Consumption Time: 2.51757
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.71353

Cumulative Model Updates: 60,722
Cumulative Timesteps: 506,412,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,728.88480
Policy Entropy: 3.73246
Value Function Loss: 0.05383

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.57206
Value Function Update Magnitude: 0.83685

Collected Steps per Second: 23,266.69667
Overall Steps per Second: 10,920.12271

Timestep Collection Time: 2.15020
Timestep Consumption Time: 2.43107
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.58127

Cumulative Model Updates: 60,728
Cumulative Timesteps: 506,462,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 506462992...
Checkpoint 506462992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,236.50148
Policy Entropy: 3.73862
Value Function Loss: 0.05383

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.55439
Value Function Update Magnitude: 0.80460

Collected Steps per Second: 22,354.58124
Overall Steps per Second: 10,650.78848

Timestep Collection Time: 2.23721
Timestep Consumption Time: 2.45840
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.69561

Cumulative Model Updates: 60,734
Cumulative Timesteps: 506,513,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.44454
Policy Entropy: 3.73690
Value Function Loss: 0.05212

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.15468
Policy Update Magnitude: 0.48775
Value Function Update Magnitude: 0.79875

Collected Steps per Second: 23,159.31090
Overall Steps per Second: 10,970.82402

Timestep Collection Time: 2.15913
Timestep Consumption Time: 2.39878
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.55791

Cumulative Model Updates: 60,740
Cumulative Timesteps: 506,563,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 506563008...
Checkpoint 506563008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,990.33517
Policy Entropy: 3.72715
Value Function Loss: 0.05543

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.49407
Value Function Update Magnitude: 0.74963

Collected Steps per Second: 22,503.29318
Overall Steps per Second: 10,591.62880

Timestep Collection Time: 2.22270
Timestep Consumption Time: 2.49971
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.72241

Cumulative Model Updates: 60,746
Cumulative Timesteps: 506,613,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,373.21675
Policy Entropy: 3.71776
Value Function Loss: 0.05429

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.48616
Value Function Update Magnitude: 0.64934

Collected Steps per Second: 22,915.44427
Overall Steps per Second: 10,838.37189

Timestep Collection Time: 2.18220
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61379

Cumulative Model Updates: 60,752
Cumulative Timesteps: 506,663,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 506663032...
Checkpoint 506663032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,962.91689
Policy Entropy: 3.71639
Value Function Loss: 0.05509

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.51728
Value Function Update Magnitude: 0.69613

Collected Steps per Second: 22,289.65498
Overall Steps per Second: 10,719.07346

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.66533

Cumulative Model Updates: 60,758
Cumulative Timesteps: 506,713,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,038.28285
Policy Entropy: 3.71159
Value Function Loss: 0.05291

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.48379
Value Function Update Magnitude: 0.72347

Collected Steps per Second: 23,011.98867
Overall Steps per Second: 10,849.05425

Timestep Collection Time: 2.17287
Timestep Consumption Time: 2.43601
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60888

Cumulative Model Updates: 60,764
Cumulative Timesteps: 506,763,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 506763042...
Checkpoint 506763042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,842.29190
Policy Entropy: 3.71857
Value Function Loss: 0.05589

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.45648
Value Function Update Magnitude: 0.67252

Collected Steps per Second: 22,382.99737
Overall Steps per Second: 10,668.22079

Timestep Collection Time: 2.23527
Timestep Consumption Time: 2.45455
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.68982

Cumulative Model Updates: 60,770
Cumulative Timesteps: 506,813,074

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,847.65596
Policy Entropy: 3.72805
Value Function Loss: 0.05760

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.52431
Value Function Update Magnitude: 0.64351

Collected Steps per Second: 23,223.77660
Overall Steps per Second: 10,911.00882

Timestep Collection Time: 2.15417
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.58509

Cumulative Model Updates: 60,776
Cumulative Timesteps: 506,863,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 506863102...
Checkpoint 506863102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,149.17907
Policy Entropy: 3.72699
Value Function Loss: 0.05873

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08195
Policy Update Magnitude: 0.61356
Value Function Update Magnitude: 0.63384

Collected Steps per Second: 22,440.46720
Overall Steps per Second: 10,658.22122

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.46428
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.69347

Cumulative Model Updates: 60,782
Cumulative Timesteps: 506,913,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,162.85283
Policy Entropy: 3.72120
Value Function Loss: 0.05913

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.63279
Value Function Update Magnitude: 0.61058

Collected Steps per Second: 23,159.93960
Overall Steps per Second: 10,883.71746

Timestep Collection Time: 2.15925
Timestep Consumption Time: 2.43551
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.59475

Cumulative Model Updates: 60,788
Cumulative Timesteps: 506,963,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 506963134...
Checkpoint 506963134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,425.96714
Policy Entropy: 3.71225
Value Function Loss: 0.06025

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.61063
Value Function Update Magnitude: 0.62741

Collected Steps per Second: 22,485.20279
Overall Steps per Second: 10,654.75433

Timestep Collection Time: 2.22493
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.69537

Cumulative Model Updates: 60,794
Cumulative Timesteps: 507,013,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,582.54321
Policy Entropy: 3.71841
Value Function Loss: 0.05913

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.56048
Value Function Update Magnitude: 0.66144

Collected Steps per Second: 22,904.71071
Overall Steps per Second: 10,844.11129

Timestep Collection Time: 2.18409
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.61319

Cumulative Model Updates: 60,800
Cumulative Timesteps: 507,063,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 507063188...
Checkpoint 507063188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,894.80803
Policy Entropy: 3.72479
Value Function Loss: 0.05813

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07313
Policy Update Magnitude: 0.58547
Value Function Update Magnitude: 0.72971

Collected Steps per Second: 22,543.22956
Overall Steps per Second: 10,720.18678

Timestep Collection Time: 2.21929
Timestep Consumption Time: 2.44760
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.66690

Cumulative Model Updates: 60,806
Cumulative Timesteps: 507,113,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,967.46635
Policy Entropy: 3.72446
Value Function Loss: 0.05700

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.68868
Value Function Update Magnitude: 0.77224

Collected Steps per Second: 22,914.50836
Overall Steps per Second: 10,830.65682

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.43596
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61930

Cumulative Model Updates: 60,812
Cumulative Timesteps: 507,163,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 507163248...
Checkpoint 507163248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,718.39176
Policy Entropy: 3.71220
Value Function Loss: 0.05848

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07041
Policy Update Magnitude: 0.69563
Value Function Update Magnitude: 0.74855

Collected Steps per Second: 22,421.42514
Overall Steps per Second: 10,758.31306

Timestep Collection Time: 2.23037
Timestep Consumption Time: 2.41795
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.64831

Cumulative Model Updates: 60,818
Cumulative Timesteps: 507,213,256

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,237.78443
Policy Entropy: 3.71309
Value Function Loss: 0.05869

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.68845
Value Function Update Magnitude: 0.76810

Collected Steps per Second: 22,941.38048
Overall Steps per Second: 10,867.19820

Timestep Collection Time: 2.18069
Timestep Consumption Time: 2.42289
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.60358

Cumulative Model Updates: 60,824
Cumulative Timesteps: 507,263,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 507263284...
Checkpoint 507263284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,522.61129
Policy Entropy: 3.71253
Value Function Loss: 0.05824

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.66381
Value Function Update Magnitude: 0.77607

Collected Steps per Second: 22,313.64725
Overall Steps per Second: 10,654.70510

Timestep Collection Time: 2.24123
Timestep Consumption Time: 2.45247
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.69370

Cumulative Model Updates: 60,830
Cumulative Timesteps: 507,313,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,688.75615
Policy Entropy: 3.72499
Value Function Loss: 0.05727

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.58753
Value Function Update Magnitude: 0.78115

Collected Steps per Second: 22,951.18025
Overall Steps per Second: 10,825.59862

Timestep Collection Time: 2.17958
Timestep Consumption Time: 2.44132
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.62090

Cumulative Model Updates: 60,836
Cumulative Timesteps: 507,363,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 507363318...
Checkpoint 507363318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,409.79437
Policy Entropy: 3.72465
Value Function Loss: 0.05637

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.54548
Value Function Update Magnitude: 0.77406

Collected Steps per Second: 22,193.99261
Overall Steps per Second: 10,673.94334

Timestep Collection Time: 2.25358
Timestep Consumption Time: 2.43222
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.68580

Cumulative Model Updates: 60,842
Cumulative Timesteps: 507,413,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,823.42206
Policy Entropy: 3.72105
Value Function Loss: 0.05824

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.59532
Value Function Update Magnitude: 0.78242

Collected Steps per Second: 22,979.78467
Overall Steps per Second: 10,857.48612

Timestep Collection Time: 2.17652
Timestep Consumption Time: 2.43007
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.60659

Cumulative Model Updates: 60,848
Cumulative Timesteps: 507,463,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 507463350...
Checkpoint 507463350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,816.10601
Policy Entropy: 3.72811
Value Function Loss: 0.05735

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.67012
Value Function Update Magnitude: 0.76106

Collected Steps per Second: 21,944.48066
Overall Steps per Second: 10,687.63507

Timestep Collection Time: 2.27975
Timestep Consumption Time: 2.40117
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.68092

Cumulative Model Updates: 60,854
Cumulative Timesteps: 507,513,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,047.66173
Policy Entropy: 3.73606
Value Function Loss: 0.05749

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.63576
Value Function Update Magnitude: 0.74465

Collected Steps per Second: 23,057.46907
Overall Steps per Second: 10,859.98682

Timestep Collection Time: 2.16954
Timestep Consumption Time: 2.43673
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60627

Cumulative Model Updates: 60,860
Cumulative Timesteps: 507,563,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 507563402...
Checkpoint 507563402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,725.75618
Policy Entropy: 3.74124
Value Function Loss: 0.05816

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.53888
Value Function Update Magnitude: 0.74531

Collected Steps per Second: 22,421.31161
Overall Steps per Second: 10,740.52972

Timestep Collection Time: 2.23109
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.65750

Cumulative Model Updates: 60,866
Cumulative Timesteps: 507,613,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,750.32625
Policy Entropy: 3.73044
Value Function Loss: 0.05904

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08087
Policy Update Magnitude: 0.63733
Value Function Update Magnitude: 0.80800

Collected Steps per Second: 23,183.04195
Overall Steps per Second: 10,882.56738

Timestep Collection Time: 2.15701
Timestep Consumption Time: 2.43805
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.59506

Cumulative Model Updates: 60,872
Cumulative Timesteps: 507,663,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 507663432...
Checkpoint 507663432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,209.47429
Policy Entropy: 3.71732
Value Function Loss: 0.05948

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.64670
Value Function Update Magnitude: 0.82647

Collected Steps per Second: 22,547.97328
Overall Steps per Second: 10,652.91230

Timestep Collection Time: 2.21812
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.69487

Cumulative Model Updates: 60,878
Cumulative Timesteps: 507,713,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,641.67455
Policy Entropy: 3.72046
Value Function Loss: 0.05824

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.16984
Policy Update Magnitude: 0.49851
Value Function Update Magnitude: 0.83965

Collected Steps per Second: 22,955.79891
Overall Steps per Second: 10,831.10275

Timestep Collection Time: 2.17888
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61800

Cumulative Model Updates: 60,884
Cumulative Timesteps: 507,763,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 507763464...
Checkpoint 507763464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,196.31155
Policy Entropy: 3.72579
Value Function Loss: 0.05727

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.44690
Value Function Update Magnitude: 0.81987

Collected Steps per Second: 22,484.81081
Overall Steps per Second: 10,762.63529

Timestep Collection Time: 2.22390
Timestep Consumption Time: 2.42217
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.64607

Cumulative Model Updates: 60,890
Cumulative Timesteps: 507,813,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,030.72594
Policy Entropy: 3.73123
Value Function Loss: 0.05632

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.50596
Value Function Update Magnitude: 0.82892

Collected Steps per Second: 22,740.79396
Overall Steps per Second: 10,815.98451

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.42507
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.62464

Cumulative Model Updates: 60,896
Cumulative Timesteps: 507,863,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 507863488...
Checkpoint 507863488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,327.66429
Policy Entropy: 3.72482
Value Function Loss: 0.05486

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.55413
Value Function Update Magnitude: 0.80668

Collected Steps per Second: 22,363.72288
Overall Steps per Second: 10,657.71867

Timestep Collection Time: 2.23603
Timestep Consumption Time: 2.45597
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.69200

Cumulative Model Updates: 60,902
Cumulative Timesteps: 507,913,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,563.81955
Policy Entropy: 3.71285
Value Function Loss: 0.05515

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.53780
Value Function Update Magnitude: 0.77356

Collected Steps per Second: 23,287.43973
Overall Steps per Second: 10,908.40423

Timestep Collection Time: 2.14794
Timestep Consumption Time: 2.43752
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.58546

Cumulative Model Updates: 60,908
Cumulative Timesteps: 507,963,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 507963514...
Checkpoint 507963514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,987.85292
Policy Entropy: 3.73077
Value Function Loss: 0.05438

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.59188
Value Function Update Magnitude: 0.73004

Collected Steps per Second: 22,741.31945
Overall Steps per Second: 10,647.72141

Timestep Collection Time: 2.19899
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.69659

Cumulative Model Updates: 60,914
Cumulative Timesteps: 508,013,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,201.80668
Policy Entropy: 3.73587
Value Function Loss: 0.05532

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.67679
Value Function Update Magnitude: 0.66497

Collected Steps per Second: 22,911.22509
Overall Steps per Second: 10,929.30941

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.39367
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.57705

Cumulative Model Updates: 60,920
Cumulative Timesteps: 508,063,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 508063546...
Checkpoint 508063546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,830.03931
Policy Entropy: 3.73270
Value Function Loss: 0.05491

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07133
Policy Update Magnitude: 0.69561
Value Function Update Magnitude: 0.62478

Collected Steps per Second: 22,414.96109
Overall Steps per Second: 10,633.84937

Timestep Collection Time: 2.23137
Timestep Consumption Time: 2.47210
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.70347

Cumulative Model Updates: 60,926
Cumulative Timesteps: 508,113,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,700.51693
Policy Entropy: 3.73295
Value Function Loss: 0.05825

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.62647
Value Function Update Magnitude: 0.58200

Collected Steps per Second: 22,821.85798
Overall Steps per Second: 10,837.55797

Timestep Collection Time: 2.19115
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.61414

Cumulative Model Updates: 60,932
Cumulative Timesteps: 508,163,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 508163568...
Checkpoint 508163568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,211.14010
Policy Entropy: 3.72511
Value Function Loss: 0.05745

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.53241
Value Function Update Magnitude: 0.57157

Collected Steps per Second: 22,362.98581
Overall Steps per Second: 10,707.73093

Timestep Collection Time: 2.23718
Timestep Consumption Time: 2.43515
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.67233

Cumulative Model Updates: 60,938
Cumulative Timesteps: 508,213,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,657.15789
Policy Entropy: 3.71909
Value Function Loss: 0.05864

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.50733
Value Function Update Magnitude: 0.57258

Collected Steps per Second: 23,184.74267
Overall Steps per Second: 10,985.06295

Timestep Collection Time: 2.15702
Timestep Consumption Time: 2.39552
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.55255

Cumulative Model Updates: 60,944
Cumulative Timesteps: 508,263,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 508263608...
Checkpoint 508263608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,096.43059
Policy Entropy: 3.72194
Value Function Loss: 0.05514

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.55065

Collected Steps per Second: 22,265.29301
Overall Steps per Second: 10,583.32770

Timestep Collection Time: 2.24628
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.72573

Cumulative Model Updates: 60,950
Cumulative Timesteps: 508,313,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,168.06625
Policy Entropy: 3.71852
Value Function Loss: 0.05836

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.51818
Value Function Update Magnitude: 0.55006

Collected Steps per Second: 23,081.60522
Overall Steps per Second: 10,839.83819

Timestep Collection Time: 2.16666
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.61354

Cumulative Model Updates: 60,956
Cumulative Timesteps: 508,363,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 508363632...
Checkpoint 508363632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,101.39075
Policy Entropy: 3.72053
Value Function Loss: 0.05945

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.58629
Value Function Update Magnitude: 0.58210

Collected Steps per Second: 22,498.51946
Overall Steps per Second: 10,716.92459

Timestep Collection Time: 2.22335
Timestep Consumption Time: 2.44422
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.66757

Cumulative Model Updates: 60,962
Cumulative Timesteps: 508,413,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180.02279
Policy Entropy: 3.71269
Value Function Loss: 0.06212

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.67573
Value Function Update Magnitude: 0.57183

Collected Steps per Second: 22,972.61083
Overall Steps per Second: 10,863.31234

Timestep Collection Time: 2.17738
Timestep Consumption Time: 2.42711
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60449

Cumulative Model Updates: 60,968
Cumulative Timesteps: 508,463,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 508463674...
Checkpoint 508463674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,186.37703
Policy Entropy: 3.71927
Value Function Loss: 0.06095

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.71018
Value Function Update Magnitude: 0.56247

Collected Steps per Second: 22,595.68304
Overall Steps per Second: 10,686.37785

Timestep Collection Time: 2.21308
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.67942

Cumulative Model Updates: 60,974
Cumulative Timesteps: 508,513,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,593.65418
Policy Entropy: 3.73413
Value Function Loss: 0.05749

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.67489
Value Function Update Magnitude: 0.63182

Collected Steps per Second: 22,967.41690
Overall Steps per Second: 10,828.29366

Timestep Collection Time: 2.17743
Timestep Consumption Time: 2.44102
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61846

Cumulative Model Updates: 60,980
Cumulative Timesteps: 508,563,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 508563690...
Checkpoint 508563690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.42578
Policy Entropy: 3.72875
Value Function Loss: 0.05679

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.57503
Value Function Update Magnitude: 0.63825

Collected Steps per Second: 22,541.42716
Overall Steps per Second: 10,667.42125

Timestep Collection Time: 2.21894
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.68886

Cumulative Model Updates: 60,986
Cumulative Timesteps: 508,613,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,705.46830
Policy Entropy: 3.72020
Value Function Loss: 0.05507

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.55960
Value Function Update Magnitude: 0.68650

Collected Steps per Second: 23,114.98174
Overall Steps per Second: 10,886.57780

Timestep Collection Time: 2.16431
Timestep Consumption Time: 2.43107
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.59538

Cumulative Model Updates: 60,992
Cumulative Timesteps: 508,663,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 508663736...
Checkpoint 508663736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,967.93940
Policy Entropy: 3.71679
Value Function Loss: 0.05644

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.64974

Collected Steps per Second: 22,331.63247
Overall Steps per Second: 10,692.39466

Timestep Collection Time: 2.23960
Timestep Consumption Time: 2.43793
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.67753

Cumulative Model Updates: 60,998
Cumulative Timesteps: 508,713,750

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,648.46633
Policy Entropy: 3.69867
Value Function Loss: 0.05641

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.60405
Value Function Update Magnitude: 0.65624

Collected Steps per Second: 22,939.18484
Overall Steps per Second: 10,853.47156

Timestep Collection Time: 2.18107
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.60977

Cumulative Model Updates: 61,004
Cumulative Timesteps: 508,763,782

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 508763782...
Checkpoint 508763782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,016.03728
Policy Entropy: 3.69744
Value Function Loss: 0.06024

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.59906
Value Function Update Magnitude: 0.71705

Collected Steps per Second: 22,507.84275
Overall Steps per Second: 10,716.36844

Timestep Collection Time: 2.22145
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.66576

Cumulative Model Updates: 61,010
Cumulative Timesteps: 508,813,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.07409
Policy Entropy: 3.71513
Value Function Loss: 0.06089

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.57699
Value Function Update Magnitude: 0.76838

Collected Steps per Second: 22,993.99484
Overall Steps per Second: 10,878.42818

Timestep Collection Time: 2.17526
Timestep Consumption Time: 2.42264
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.59791

Cumulative Model Updates: 61,016
Cumulative Timesteps: 508,863,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 508863800...
Checkpoint 508863800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,387.29138
Policy Entropy: 3.72283
Value Function Loss: 0.06085

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.74229

Collected Steps per Second: 22,452.10008
Overall Steps per Second: 10,664.79640

Timestep Collection Time: 2.22768
Timestep Consumption Time: 2.46215
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.68982

Cumulative Model Updates: 61,022
Cumulative Timesteps: 508,913,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,006.85115
Policy Entropy: 3.72249
Value Function Loss: 0.05985

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.51553
Value Function Update Magnitude: 0.74179

Collected Steps per Second: 23,113.49321
Overall Steps per Second: 10,870.43245

Timestep Collection Time: 2.16333
Timestep Consumption Time: 2.43649
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.59982

Cumulative Model Updates: 61,028
Cumulative Timesteps: 508,963,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 508963818...
Checkpoint 508963818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,265.25080
Policy Entropy: 3.71183
Value Function Loss: 0.06024

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.49322
Value Function Update Magnitude: 0.71502

Collected Steps per Second: 22,487.32783
Overall Steps per Second: 10,637.83999

Timestep Collection Time: 2.22347
Timestep Consumption Time: 2.47673
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.70020

Cumulative Model Updates: 61,034
Cumulative Timesteps: 509,013,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,099.34493
Policy Entropy: 3.71598
Value Function Loss: 0.05824

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.48786
Value Function Update Magnitude: 0.70733

Collected Steps per Second: 23,008.89679
Overall Steps per Second: 10,922.81231

Timestep Collection Time: 2.17359
Timestep Consumption Time: 2.40508
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.57867

Cumulative Model Updates: 61,040
Cumulative Timesteps: 509,063,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 509063830...
Checkpoint 509063830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,807.10423
Policy Entropy: 3.70782
Value Function Loss: 0.05889

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.49147
Value Function Update Magnitude: 0.74928

Collected Steps per Second: 22,489.75166
Overall Steps per Second: 10,667.83378

Timestep Collection Time: 2.22395
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.68849

Cumulative Model Updates: 61,046
Cumulative Timesteps: 509,113,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.53304
Policy Entropy: 3.70934
Value Function Loss: 0.05941

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.50755
Value Function Update Magnitude: 0.72222

Collected Steps per Second: 23,024.92310
Overall Steps per Second: 10,846.77487

Timestep Collection Time: 2.17182
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61022

Cumulative Model Updates: 61,052
Cumulative Timesteps: 509,163,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 509163852...
Checkpoint 509163852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,997.75020
Policy Entropy: 3.70096
Value Function Loss: 0.05980

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.71210

Collected Steps per Second: 22,313.94902
Overall Steps per Second: 10,697.42672

Timestep Collection Time: 2.24183
Timestep Consumption Time: 2.43444
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.67626

Cumulative Model Updates: 61,058
Cumulative Timesteps: 509,213,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.53853
Policy Entropy: 3.70121
Value Function Loss: 0.06066

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.51764
Value Function Update Magnitude: 0.72070

Collected Steps per Second: 22,783.60519
Overall Steps per Second: 10,818.52998

Timestep Collection Time: 2.19456
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.62170

Cumulative Model Updates: 61,064
Cumulative Timesteps: 509,263,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 509263876...
Checkpoint 509263876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,514.22978
Policy Entropy: 3.69889
Value Function Loss: 0.06026

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.48466
Value Function Update Magnitude: 0.69146

Collected Steps per Second: 22,419.10487
Overall Steps per Second: 10,760.02698

Timestep Collection Time: 2.23122
Timestep Consumption Time: 2.41765
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.64887

Cumulative Model Updates: 61,070
Cumulative Timesteps: 509,313,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,852.64289
Policy Entropy: 3.69113
Value Function Loss: 0.06094

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.48411
Value Function Update Magnitude: 0.72242

Collected Steps per Second: 22,834.18541
Overall Steps per Second: 10,806.63313

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.43797
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62845

Cumulative Model Updates: 61,076
Cumulative Timesteps: 509,363,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 509363916...
Checkpoint 509363916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,366.44467
Policy Entropy: 3.68080
Value Function Loss: 0.06137

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.46262
Value Function Update Magnitude: 0.79067

Collected Steps per Second: 22,509.47124
Overall Steps per Second: 10,748.55683

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.65365

Cumulative Model Updates: 61,082
Cumulative Timesteps: 509,413,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,424.72874
Policy Entropy: 3.67765
Value Function Loss: 0.06287

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07134
Policy Update Magnitude: 0.53051
Value Function Update Magnitude: 0.77214

Collected Steps per Second: 23,181.86639
Overall Steps per Second: 10,897.32340

Timestep Collection Time: 2.15807
Timestep Consumption Time: 2.43279
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.59085

Cumulative Model Updates: 61,088
Cumulative Timesteps: 509,463,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 509463964...
Checkpoint 509463964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,732.23531
Policy Entropy: 3.68338
Value Function Loss: 0.06501

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.60300
Value Function Update Magnitude: 0.63609

Collected Steps per Second: 22,507.89446
Overall Steps per Second: 10,621.69945

Timestep Collection Time: 2.22206
Timestep Consumption Time: 2.48660
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.70866

Cumulative Model Updates: 61,094
Cumulative Timesteps: 509,513,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,701.03120
Policy Entropy: 3.68620
Value Function Loss: 0.06746

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.54801
Value Function Update Magnitude: 0.53815

Collected Steps per Second: 22,868.15087
Overall Steps per Second: 10,823.52615

Timestep Collection Time: 2.18750
Timestep Consumption Time: 2.43429
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62178

Cumulative Model Updates: 61,100
Cumulative Timesteps: 509,564,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 509564002...
Checkpoint 509564002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,660.74021
Policy Entropy: 3.68265
Value Function Loss: 0.06425

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06642
Policy Update Magnitude: 0.57569
Value Function Update Magnitude: 0.51489

Collected Steps per Second: 22,302.84449
Overall Steps per Second: 10,695.36347

Timestep Collection Time: 2.24294
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.67717

Cumulative Model Updates: 61,106
Cumulative Timesteps: 509,614,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,214.52866
Policy Entropy: 3.68173
Value Function Loss: 0.06314

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.65036
Value Function Update Magnitude: 0.58473

Collected Steps per Second: 23,122.33853
Overall Steps per Second: 10,888.16210

Timestep Collection Time: 2.16328
Timestep Consumption Time: 2.43070
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.59398

Cumulative Model Updates: 61,112
Cumulative Timesteps: 509,664,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 509664046...
Checkpoint 509664046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,081.04242
Policy Entropy: 3.69935
Value Function Loss: 0.06006

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07327
Policy Update Magnitude: 0.68252
Value Function Update Magnitude: 0.67536

Collected Steps per Second: 22,124.12870
Overall Steps per Second: 10,647.36966

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.43651
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.69693

Cumulative Model Updates: 61,118
Cumulative Timesteps: 509,714,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,715.63950
Policy Entropy: 3.70201
Value Function Loss: 0.06021

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.67480
Value Function Update Magnitude: 0.76435

Collected Steps per Second: 23,142.14192
Overall Steps per Second: 10,892.84384

Timestep Collection Time: 2.16134
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.59182

Cumulative Model Updates: 61,124
Cumulative Timesteps: 509,764,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 509764074...
Checkpoint 509764074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,143.35695
Policy Entropy: 3.71424
Value Function Loss: 0.05684

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09516
Policy Update Magnitude: 0.62127
Value Function Update Magnitude: 0.78881

Collected Steps per Second: 22,300.35696
Overall Steps per Second: 10,706.61932

Timestep Collection Time: 2.24256
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.67094

Cumulative Model Updates: 61,130
Cumulative Timesteps: 509,814,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.61575
Policy Entropy: 3.70595
Value Function Loss: 0.05783

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.60433
Value Function Update Magnitude: 0.82306

Collected Steps per Second: 23,162.68746
Overall Steps per Second: 10,894.19053

Timestep Collection Time: 2.15985
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59217

Cumulative Model Updates: 61,136
Cumulative Timesteps: 509,864,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 509864112...
Checkpoint 509864112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,982.40902
Policy Entropy: 3.70158
Value Function Loss: 0.06043

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.57657
Value Function Update Magnitude: 0.84650

Collected Steps per Second: 22,659.50606
Overall Steps per Second: 10,666.94601

Timestep Collection Time: 2.20737
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.68906

Cumulative Model Updates: 61,142
Cumulative Timesteps: 509,914,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,873.80890
Policy Entropy: 3.68379
Value Function Loss: 0.06256

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.83356

Collected Steps per Second: 22,963.64205
Overall Steps per Second: 10,849.89805

Timestep Collection Time: 2.17831
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.61037

Cumulative Model Updates: 61,148
Cumulative Timesteps: 509,964,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 509964152...
Checkpoint 509964152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.86923
Policy Entropy: 3.67767
Value Function Loss: 0.06463

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.51266
Value Function Update Magnitude: 0.75407

Collected Steps per Second: 22,612.50399
Overall Steps per Second: 10,698.00128

Timestep Collection Time: 2.21249
Timestep Consumption Time: 2.46408
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.67657

Cumulative Model Updates: 61,154
Cumulative Timesteps: 510,014,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,346.79113
Policy Entropy: 3.68347
Value Function Loss: 0.06326

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06374
Policy Update Magnitude: 0.55820
Value Function Update Magnitude: 0.73719

Collected Steps per Second: 22,754.52807
Overall Steps per Second: 10,825.73033

Timestep Collection Time: 2.19807
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.62010

Cumulative Model Updates: 61,160
Cumulative Timesteps: 510,064,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 510064198...
Checkpoint 510064198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,139.54472
Policy Entropy: 3.69032
Value Function Loss: 0.06115

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.60071
Value Function Update Magnitude: 0.73590

Collected Steps per Second: 22,245.83889
Overall Steps per Second: 10,746.77542

Timestep Collection Time: 2.24860
Timestep Consumption Time: 2.40601
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.65461

Cumulative Model Updates: 61,166
Cumulative Timesteps: 510,114,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,021.59946
Policy Entropy: 3.70763
Value Function Loss: 0.06114

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.60542
Value Function Update Magnitude: 0.74648

Collected Steps per Second: 23,007.09682
Overall Steps per Second: 10,846.99689

Timestep Collection Time: 2.17420
Timestep Consumption Time: 2.43740
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.61160

Cumulative Model Updates: 61,172
Cumulative Timesteps: 510,164,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 510164242...
Checkpoint 510164242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,109.98965
Policy Entropy: 3.71027
Value Function Loss: 0.06220

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.55618
Value Function Update Magnitude: 0.69497

Collected Steps per Second: 22,391.09569
Overall Steps per Second: 10,644.26841

Timestep Collection Time: 2.23464
Timestep Consumption Time: 2.46611
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.70075

Cumulative Model Updates: 61,178
Cumulative Timesteps: 510,214,278

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,519.72912
Policy Entropy: 3.71057
Value Function Loss: 0.06291

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.58109
Value Function Update Magnitude: 0.68440

Collected Steps per Second: 22,981.04358
Overall Steps per Second: 10,871.26549

Timestep Collection Time: 2.17588
Timestep Consumption Time: 2.42377
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59965

Cumulative Model Updates: 61,184
Cumulative Timesteps: 510,264,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 510264282...
Checkpoint 510264282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,287.58905
Policy Entropy: 3.70364
Value Function Loss: 0.06026

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.51596
Value Function Update Magnitude: 0.71143

Collected Steps per Second: 22,439.78909
Overall Steps per Second: 10,715.51334

Timestep Collection Time: 2.22872
Timestep Consumption Time: 2.43853
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.66725

Cumulative Model Updates: 61,190
Cumulative Timesteps: 510,314,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,646.05089
Policy Entropy: 3.70787
Value Function Loss: 0.05909

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.49047
Value Function Update Magnitude: 0.78274

Collected Steps per Second: 22,299.75648
Overall Steps per Second: 10,895.39383

Timestep Collection Time: 2.24254
Timestep Consumption Time: 2.34729
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.58983

Cumulative Model Updates: 61,196
Cumulative Timesteps: 510,364,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 510364302...
Checkpoint 510364302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,164.49517
Policy Entropy: 3.69342
Value Function Loss: 0.05952

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.11916
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.70328

Collected Steps per Second: 22,074.83500
Overall Steps per Second: 10,654.35383

Timestep Collection Time: 2.26575
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.69442

Cumulative Model Updates: 61,202
Cumulative Timesteps: 510,414,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,870.05212
Policy Entropy: 3.69474
Value Function Loss: 0.06220

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.51069
Value Function Update Magnitude: 0.61258

Collected Steps per Second: 22,301.19858
Overall Steps per Second: 10,908.85089

Timestep Collection Time: 2.24329
Timestep Consumption Time: 2.34271
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.58600

Cumulative Model Updates: 61,208
Cumulative Timesteps: 510,464,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 510464346...
Checkpoint 510464346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,761.18080
Policy Entropy: 3.69283
Value Function Loss: 0.06380

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.15349
Policy Update Magnitude: 0.48105
Value Function Update Magnitude: 0.65976

Collected Steps per Second: 21,883.50886
Overall Steps per Second: 10,608.71681

Timestep Collection Time: 2.28537
Timestep Consumption Time: 2.42886
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.71424

Cumulative Model Updates: 61,214
Cumulative Timesteps: 510,514,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,072.05978
Policy Entropy: 3.70253
Value Function Loss: 0.06391

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.15639
Policy Update Magnitude: 0.48237
Value Function Update Magnitude: 0.63113

Collected Steps per Second: 22,198.82436
Overall Steps per Second: 10,852.58947

Timestep Collection Time: 2.25291
Timestep Consumption Time: 2.35539
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.60830

Cumulative Model Updates: 61,220
Cumulative Timesteps: 510,564,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 510564370...
Checkpoint 510564370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,799.98801
Policy Entropy: 3.68833
Value Function Loss: 0.06761

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.52663
Value Function Update Magnitude: 0.64509

Collected Steps per Second: 21,891.59560
Overall Steps per Second: 10,687.92453

Timestep Collection Time: 2.28517
Timestep Consumption Time: 2.39544
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.68061

Cumulative Model Updates: 61,226
Cumulative Timesteps: 510,614,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,335.64187
Policy Entropy: 3.69673
Value Function Loss: 0.06402

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.68552

Collected Steps per Second: 22,316.71718
Overall Steps per Second: 10,906.17634

Timestep Collection Time: 2.24191
Timestep Consumption Time: 2.34559
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.58749

Cumulative Model Updates: 61,232
Cumulative Timesteps: 510,664,428

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 510664428...
Checkpoint 510664428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,656.50336
Policy Entropy: 3.69173
Value Function Loss: 0.06579

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.50300
Value Function Update Magnitude: 0.64063

Collected Steps per Second: 21,829.18099
Overall Steps per Second: 10,644.62997

Timestep Collection Time: 2.29161
Timestep Consumption Time: 2.40785
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.69946

Cumulative Model Updates: 61,238
Cumulative Timesteps: 510,714,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,353.80867
Policy Entropy: 3.69809
Value Function Loss: 0.06345

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.51167
Value Function Update Magnitude: 0.62494

Collected Steps per Second: 22,623.74666
Overall Steps per Second: 10,713.46277

Timestep Collection Time: 2.21069
Timestep Consumption Time: 2.45765
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.66833

Cumulative Model Updates: 61,244
Cumulative Timesteps: 510,764,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 510764466...
Checkpoint 510764466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.85997
Policy Entropy: 3.69201
Value Function Loss: 0.06473

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.55311
Value Function Update Magnitude: 0.67374

Collected Steps per Second: 22,399.30300
Overall Steps per Second: 10,795.38250

Timestep Collection Time: 2.23311
Timestep Consumption Time: 2.40036
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.63346

Cumulative Model Updates: 61,250
Cumulative Timesteps: 510,814,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,259.22972
Policy Entropy: 3.68130
Value Function Loss: 0.06343

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.48558
Value Function Update Magnitude: 0.68083

Collected Steps per Second: 23,153.75708
Overall Steps per Second: 10,943.89461

Timestep Collection Time: 2.16008
Timestep Consumption Time: 2.40996
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.57004

Cumulative Model Updates: 61,256
Cumulative Timesteps: 510,864,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 510864500...
Checkpoint 510864500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,352.15974
Policy Entropy: 3.69012
Value Function Loss: 0.06368

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10879
Policy Update Magnitude: 0.45180
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 22,561.62324
Overall Steps per Second: 10,669.16354

Timestep Collection Time: 2.21615
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.68640

Cumulative Model Updates: 61,262
Cumulative Timesteps: 510,914,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,113.48859
Policy Entropy: 3.68893
Value Function Loss: 0.06223

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.45804
Value Function Update Magnitude: 0.63455

Collected Steps per Second: 22,780.80277
Overall Steps per Second: 10,804.12684

Timestep Collection Time: 2.19571
Timestep Consumption Time: 2.43400
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62971

Cumulative Model Updates: 61,268
Cumulative Timesteps: 510,964,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 510964520...
Checkpoint 510964520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,141.03330
Policy Entropy: 3.68538
Value Function Loss: 0.06223

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.42819
Value Function Update Magnitude: 0.62097

Collected Steps per Second: 22,399.16168
Overall Steps per Second: 10,725.01836

Timestep Collection Time: 2.23303
Timestep Consumption Time: 2.43065
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.66367

Cumulative Model Updates: 61,274
Cumulative Timesteps: 511,014,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,030.64844
Policy Entropy: 3.68449
Value Function Loss: 0.06018

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.49167
Value Function Update Magnitude: 0.72986

Collected Steps per Second: 22,953.65926
Overall Steps per Second: 10,865.78265

Timestep Collection Time: 2.17961
Timestep Consumption Time: 2.42475
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.60436

Cumulative Model Updates: 61,280
Cumulative Timesteps: 511,064,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 511064568...
Checkpoint 511064568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,234.63600
Policy Entropy: 3.69017
Value Function Loss: 0.05809

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.46285
Value Function Update Magnitude: 0.83709

Collected Steps per Second: 22,165.15496
Overall Steps per Second: 10,737.96771

Timestep Collection Time: 2.25597
Timestep Consumption Time: 2.40077
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.65675

Cumulative Model Updates: 61,286
Cumulative Timesteps: 511,114,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,308.36755
Policy Entropy: 3.69534
Value Function Loss: 0.05866

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.48138
Value Function Update Magnitude: 0.87568

Collected Steps per Second: 23,035.27760
Overall Steps per Second: 10,836.63973

Timestep Collection Time: 2.17102
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.61490

Cumulative Model Updates: 61,292
Cumulative Timesteps: 511,164,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 511164582...
Checkpoint 511164582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,617.59626
Policy Entropy: 3.68816
Value Function Loss: 0.05983

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.46537
Value Function Update Magnitude: 0.86270

Collected Steps per Second: 22,421.91355
Overall Steps per Second: 10,681.08677

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.45268
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.68398

Cumulative Model Updates: 61,298
Cumulative Timesteps: 511,214,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,137.79642
Policy Entropy: 3.68754
Value Function Loss: 0.06004

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.49111
Value Function Update Magnitude: 0.85418

Collected Steps per Second: 22,947.10973
Overall Steps per Second: 10,855.81467

Timestep Collection Time: 2.18023
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.60859

Cumulative Model Updates: 61,304
Cumulative Timesteps: 511,264,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 511264642...
Checkpoint 511264642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,464.40972
Policy Entropy: 3.68816
Value Function Loss: 0.06016

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.52833
Value Function Update Magnitude: 0.70229

Collected Steps per Second: 22,433.59627
Overall Steps per Second: 10,699.21356

Timestep Collection Time: 2.22978
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.67530

Cumulative Model Updates: 61,310
Cumulative Timesteps: 511,314,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,069.93880
Policy Entropy: 3.69407
Value Function Loss: 0.05980

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.52852
Value Function Update Magnitude: 0.63012

Collected Steps per Second: 22,652.63702
Overall Steps per Second: 10,805.93222

Timestep Collection Time: 2.20760
Timestep Consumption Time: 2.42023
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.62783

Cumulative Model Updates: 61,316
Cumulative Timesteps: 511,364,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 511364672...
Checkpoint 511364672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,881.07355
Policy Entropy: 3.69233
Value Function Loss: 0.06263

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.50046
Value Function Update Magnitude: 0.62896

Collected Steps per Second: 22,174.24597
Overall Steps per Second: 10,673.79500

Timestep Collection Time: 2.25496
Timestep Consumption Time: 2.42960
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.68456

Cumulative Model Updates: 61,322
Cumulative Timesteps: 511,414,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,259.48314
Policy Entropy: 3.69511
Value Function Loss: 0.06108

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.49268
Value Function Update Magnitude: 0.63194

Collected Steps per Second: 23,054.88045
Overall Steps per Second: 10,881.43449

Timestep Collection Time: 2.16926
Timestep Consumption Time: 2.42683
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.59609

Cumulative Model Updates: 61,328
Cumulative Timesteps: 511,464,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 511464686...
Checkpoint 511464686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,679.59290
Policy Entropy: 3.69472
Value Function Loss: 0.06231

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.45627
Value Function Update Magnitude: 0.66051

Collected Steps per Second: 22,555.58014
Overall Steps per Second: 10,723.29492

Timestep Collection Time: 2.21808
Timestep Consumption Time: 2.44747
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.66554

Cumulative Model Updates: 61,334
Cumulative Timesteps: 511,514,716

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,307.00063
Policy Entropy: 3.69245
Value Function Loss: 0.06213

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.45938
Value Function Update Magnitude: 0.65500

Collected Steps per Second: 23,084.47092
Overall Steps per Second: 10,859.43634

Timestep Collection Time: 2.16700
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.60650

Cumulative Model Updates: 61,340
Cumulative Timesteps: 511,564,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 511564740...
Checkpoint 511564740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,588.91181
Policy Entropy: 3.68746
Value Function Loss: 0.06471

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.48891
Value Function Update Magnitude: 0.60018

Collected Steps per Second: 22,700.38774
Overall Steps per Second: 10,689.58143

Timestep Collection Time: 2.20366
Timestep Consumption Time: 2.47603
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.67970

Cumulative Model Updates: 61,346
Cumulative Timesteps: 511,614,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,775.61202
Policy Entropy: 3.68148
Value Function Loss: 0.06529

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.48118
Value Function Update Magnitude: 0.58415

Collected Steps per Second: 23,010.29050
Overall Steps per Second: 10,858.49260

Timestep Collection Time: 2.17372
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60635

Cumulative Model Updates: 61,352
Cumulative Timesteps: 511,664,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 511664782...
Checkpoint 511664782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,826.53128
Policy Entropy: 3.67122
Value Function Loss: 0.06583

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.46492
Value Function Update Magnitude: 0.59354

Collected Steps per Second: 22,412.21424
Overall Steps per Second: 10,748.07348

Timestep Collection Time: 2.23218
Timestep Consumption Time: 2.42243
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.65460

Cumulative Model Updates: 61,358
Cumulative Timesteps: 511,714,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,432.59600
Policy Entropy: 3.66727
Value Function Loss: 0.06654

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.54661
Value Function Update Magnitude: 0.57785

Collected Steps per Second: 22,846.07110
Overall Steps per Second: 10,813.68012

Timestep Collection Time: 2.18874
Timestep Consumption Time: 2.43541
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.62414

Cumulative Model Updates: 61,364
Cumulative Timesteps: 511,764,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 511764814...
Checkpoint 511764814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,687.58906
Policy Entropy: 3.65778
Value Function Loss: 0.06865

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.60517
Value Function Update Magnitude: 0.59710

Collected Steps per Second: 22,485.85340
Overall Steps per Second: 10,639.81927

Timestep Collection Time: 2.22442
Timestep Consumption Time: 2.47660
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.70102

Cumulative Model Updates: 61,370
Cumulative Timesteps: 511,814,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,293.07063
Policy Entropy: 3.66479
Value Function Loss: 0.06706

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.54638
Value Function Update Magnitude: 0.59808

Collected Steps per Second: 22,662.05271
Overall Steps per Second: 10,664.72061

Timestep Collection Time: 2.20721
Timestep Consumption Time: 2.48302
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.69023

Cumulative Model Updates: 61,376
Cumulative Timesteps: 511,864,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 511864852...
Checkpoint 511864852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,312.76825
Policy Entropy: 3.68069
Value Function Loss: 0.06416

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.47822
Value Function Update Magnitude: 0.60153

Collected Steps per Second: 22,520.55226
Overall Steps per Second: 10,811.36320

Timestep Collection Time: 2.22108
Timestep Consumption Time: 2.40553
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.62661

Cumulative Model Updates: 61,382
Cumulative Timesteps: 511,914,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,732.91051
Policy Entropy: 3.69319
Value Function Loss: 0.06210

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.45682
Value Function Update Magnitude: 0.60496

Collected Steps per Second: 22,759.54552
Overall Steps per Second: 10,692.41524

Timestep Collection Time: 2.19732
Timestep Consumption Time: 2.47983
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.67715

Cumulative Model Updates: 61,388
Cumulative Timesteps: 511,964,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 511964882...
Checkpoint 511964882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,670.17311
Policy Entropy: 3.68338
Value Function Loss: 0.06286

Mean KL Divergence: 0.02052
SB3 Clip Fraction: 0.17638
Policy Update Magnitude: 0.41263
Value Function Update Magnitude: 0.58859

Collected Steps per Second: 22,593.64103
Overall Steps per Second: 10,659.69882

Timestep Collection Time: 2.21363
Timestep Consumption Time: 2.47825
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.69188

Cumulative Model Updates: 61,394
Cumulative Timesteps: 512,014,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,538.55019
Policy Entropy: 3.67748
Value Function Loss: 0.06380

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.44934
Value Function Update Magnitude: 0.57629

Collected Steps per Second: 23,046.47697
Overall Steps per Second: 10,736.51967

Timestep Collection Time: 2.16996
Timestep Consumption Time: 2.48797
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.65793

Cumulative Model Updates: 61,400
Cumulative Timesteps: 512,064,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 512064906...
Checkpoint 512064906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,943.92723
Policy Entropy: 3.68511
Value Function Loss: 0.06326

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.52718
Value Function Update Magnitude: 0.61074

Collected Steps per Second: 22,415.44103
Overall Steps per Second: 10,634.71837

Timestep Collection Time: 2.23123
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.70290

Cumulative Model Updates: 61,406
Cumulative Timesteps: 512,114,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,692.02652
Policy Entropy: 3.69964
Value Function Loss: 0.06002

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.59660
Value Function Update Magnitude: 0.71304

Collected Steps per Second: 23,139.82890
Overall Steps per Second: 10,874.58812

Timestep Collection Time: 2.16199
Timestep Consumption Time: 2.43846
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60045

Cumulative Model Updates: 61,412
Cumulative Timesteps: 512,164,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 512164948...
Checkpoint 512164948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,864.79004
Policy Entropy: 3.69787
Value Function Loss: 0.05982

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.73636

Collected Steps per Second: 22,500.92330
Overall Steps per Second: 10,665.41879

Timestep Collection Time: 2.22355
Timestep Consumption Time: 2.46750
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.69105

Cumulative Model Updates: 61,418
Cumulative Timesteps: 512,214,980

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,254.07226
Policy Entropy: 3.70037
Value Function Loss: 0.06025

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.61079
Value Function Update Magnitude: 0.63638

Collected Steps per Second: 22,327.14967
Overall Steps per Second: 10,885.45593

Timestep Collection Time: 2.23952
Timestep Consumption Time: 2.35395
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.59347

Cumulative Model Updates: 61,424
Cumulative Timesteps: 512,264,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 512264982...
Checkpoint 512264982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,423.24798
Policy Entropy: 3.70297
Value Function Loss: 0.06244

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.57570
Value Function Update Magnitude: 0.63967

Collected Steps per Second: 22,072.75662
Overall Steps per Second: 10,644.75517

Timestep Collection Time: 2.26650
Timestep Consumption Time: 2.43327
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.69978

Cumulative Model Updates: 61,430
Cumulative Timesteps: 512,315,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,512.58298
Policy Entropy: 3.70708
Value Function Loss: 0.06128

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.54066
Value Function Update Magnitude: 0.68452

Collected Steps per Second: 22,161.22194
Overall Steps per Second: 10,838.06404

Timestep Collection Time: 2.25737
Timestep Consumption Time: 2.35840
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61577

Cumulative Model Updates: 61,436
Cumulative Timesteps: 512,365,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 512365036...
Checkpoint 512365036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,375.72039
Policy Entropy: 3.69571
Value Function Loss: 0.06148

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.67557

Collected Steps per Second: 21,954.15127
Overall Steps per Second: 10,715.31992

Timestep Collection Time: 2.27775
Timestep Consumption Time: 2.38903
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.66678

Cumulative Model Updates: 61,442
Cumulative Timesteps: 512,415,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,146.82320
Policy Entropy: 3.69940
Value Function Loss: 0.05942

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.55755
Value Function Update Magnitude: 0.62076

Collected Steps per Second: 22,240.99532
Overall Steps per Second: 10,587.26056

Timestep Collection Time: 2.24837
Timestep Consumption Time: 2.47485
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.72322

Cumulative Model Updates: 61,448
Cumulative Timesteps: 512,465,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 512465048...
Checkpoint 512465048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,790.72356
Policy Entropy: 3.70132
Value Function Loss: 0.05881

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.52694
Value Function Update Magnitude: 0.63761

Collected Steps per Second: 22,817.18931
Overall Steps per Second: 10,890.04473

Timestep Collection Time: 2.19203
Timestep Consumption Time: 2.40079
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.59282

Cumulative Model Updates: 61,454
Cumulative Timesteps: 512,515,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,419.62301
Policy Entropy: 3.71352
Value Function Loss: 0.05890

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.53825
Value Function Update Magnitude: 0.66104

Collected Steps per Second: 23,064.92435
Overall Steps per Second: 10,916.31433

Timestep Collection Time: 2.16779
Timestep Consumption Time: 2.41251
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.58030

Cumulative Model Updates: 61,460
Cumulative Timesteps: 512,565,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 512565064...
Checkpoint 512565064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,968.83853
Policy Entropy: 3.70924
Value Function Loss: 0.05778

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.61037
Value Function Update Magnitude: 0.67306

Collected Steps per Second: 22,700.24023
Overall Steps per Second: 10,707.43209

Timestep Collection Time: 2.20332
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.67115

Cumulative Model Updates: 61,466
Cumulative Timesteps: 512,615,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,427.60292
Policy Entropy: 3.71482
Value Function Loss: 0.05752

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.57517
Value Function Update Magnitude: 0.68088

Collected Steps per Second: 23,014.88348
Overall Steps per Second: 10,927.31848

Timestep Collection Time: 2.17346
Timestep Consumption Time: 2.40424
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.57770

Cumulative Model Updates: 61,472
Cumulative Timesteps: 512,665,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 512665102...
Checkpoint 512665102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,613.31742
Policy Entropy: 3.71278
Value Function Loss: 0.05836

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07181
Policy Update Magnitude: 0.60338
Value Function Update Magnitude: 0.65996

Collected Steps per Second: 22,303.15731
Overall Steps per Second: 10,647.57852

Timestep Collection Time: 2.24237
Timestep Consumption Time: 2.45466
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.69703

Cumulative Model Updates: 61,478
Cumulative Timesteps: 512,715,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,922.83516
Policy Entropy: 3.70546
Value Function Loss: 0.06136

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.63039
Value Function Update Magnitude: 0.72089

Collected Steps per Second: 23,056.42514
Overall Steps per Second: 10,852.38170

Timestep Collection Time: 2.16937
Timestep Consumption Time: 2.43957
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60894

Cumulative Model Updates: 61,484
Cumulative Timesteps: 512,765,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 512765132...
Checkpoint 512765132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,144.97320
Policy Entropy: 3.69714
Value Function Loss: 0.06270

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.72690

Collected Steps per Second: 22,553.36076
Overall Steps per Second: 10,684.34469

Timestep Collection Time: 2.21776
Timestep Consumption Time: 2.46367
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.68143

Cumulative Model Updates: 61,490
Cumulative Timesteps: 512,815,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,118.00361
Policy Entropy: 3.70084
Value Function Loss: 0.06334

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.52648
Value Function Update Magnitude: 0.75015

Collected Steps per Second: 23,034.43757
Overall Steps per Second: 10,862.52681

Timestep Collection Time: 2.17118
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.60409

Cumulative Model Updates: 61,496
Cumulative Timesteps: 512,865,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 512865162...
Checkpoint 512865162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.62641
Policy Entropy: 3.69141
Value Function Loss: 0.06236

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.52533
Value Function Update Magnitude: 0.78905

Collected Steps per Second: 22,207.97970
Overall Steps per Second: 10,712.34962

Timestep Collection Time: 2.25225
Timestep Consumption Time: 2.41694
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.66919

Cumulative Model Updates: 61,502
Cumulative Timesteps: 512,915,180

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,024.31934
Policy Entropy: 3.69284
Value Function Loss: 0.06080

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.51864
Value Function Update Magnitude: 0.84683

Collected Steps per Second: 22,781.38634
Overall Steps per Second: 10,802.35607

Timestep Collection Time: 2.19521
Timestep Consumption Time: 2.43433
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.62955

Cumulative Model Updates: 61,508
Cumulative Timesteps: 512,965,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 512965190...
Checkpoint 512965190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,621.00133
Policy Entropy: 3.68770
Value Function Loss: 0.05956

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.49666
Value Function Update Magnitude: 0.88716

Collected Steps per Second: 22,631.61875
Overall Steps per Second: 10,762.45436

Timestep Collection Time: 2.20974
Timestep Consumption Time: 2.43697
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.64671

Cumulative Model Updates: 61,514
Cumulative Timesteps: 513,015,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,679.08083
Policy Entropy: 3.70645
Value Function Loss: 0.05821

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.50669
Value Function Update Magnitude: 0.87181

Collected Steps per Second: 22,746.45993
Overall Steps per Second: 10,789.80129

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.43645
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.63512

Cumulative Model Updates: 61,520
Cumulative Timesteps: 513,065,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 513065212...
Checkpoint 513065212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.12849
Policy Entropy: 3.71068
Value Function Loss: 0.05798

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.51628
Value Function Update Magnitude: 0.88254

Collected Steps per Second: 22,634.25284
Overall Steps per Second: 10,721.02402

Timestep Collection Time: 2.20957
Timestep Consumption Time: 2.45528
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.66485

Cumulative Model Updates: 61,526
Cumulative Timesteps: 513,115,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,119.55455
Policy Entropy: 3.70999
Value Function Loss: 0.05847

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.59675
Value Function Update Magnitude: 0.89352

Collected Steps per Second: 22,853.66687
Overall Steps per Second: 10,827.98550

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.43119
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.62025

Cumulative Model Updates: 61,532
Cumulative Timesteps: 513,165,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 513165252...
Checkpoint 513165252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,771.68810
Policy Entropy: 3.70606
Value Function Loss: 0.05758

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.15300
Policy Update Magnitude: 0.53683
Value Function Update Magnitude: 0.89868

Collected Steps per Second: 22,706.36229
Overall Steps per Second: 10,714.43010

Timestep Collection Time: 2.20247
Timestep Consumption Time: 2.46507
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.66754

Cumulative Model Updates: 61,538
Cumulative Timesteps: 513,215,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,396.74161
Policy Entropy: 3.70061
Value Function Loss: 0.06033

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15120
Policy Update Magnitude: 0.39837
Value Function Update Magnitude: 0.83715

Collected Steps per Second: 23,059.78339
Overall Steps per Second: 10,872.78275

Timestep Collection Time: 2.16914
Timestep Consumption Time: 2.43133
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60048

Cumulative Model Updates: 61,544
Cumulative Timesteps: 513,265,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 513265282...
Checkpoint 513265282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,368.04748
Policy Entropy: 3.71837
Value Function Loss: 0.05922

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.42292
Value Function Update Magnitude: 0.75184

Collected Steps per Second: 22,806.96082
Overall Steps per Second: 10,679.05459

Timestep Collection Time: 2.19284
Timestep Consumption Time: 2.49035
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.68319

Cumulative Model Updates: 61,550
Cumulative Timesteps: 513,315,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,152.12348
Policy Entropy: 3.71028
Value Function Loss: 0.05667

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.49922
Value Function Update Magnitude: 0.78324

Collected Steps per Second: 22,731.24148
Overall Steps per Second: 10,796.74900

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.63214

Cumulative Model Updates: 61,556
Cumulative Timesteps: 513,365,306

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 513365306...
Checkpoint 513365306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,936.54893
Policy Entropy: 3.71400
Value Function Loss: 0.05407

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.44562
Value Function Update Magnitude: 0.83220

Collected Steps per Second: 22,326.25829
Overall Steps per Second: 10,703.71330

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.43293
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.67352

Cumulative Model Updates: 61,562
Cumulative Timesteps: 513,415,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,087.03215
Policy Entropy: 3.70038
Value Function Loss: 0.05419

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.44017
Value Function Update Magnitude: 0.80077

Collected Steps per Second: 22,621.00529
Overall Steps per Second: 10,647.23043

Timestep Collection Time: 2.21157
Timestep Consumption Time: 2.48711
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.69869

Cumulative Model Updates: 61,568
Cumulative Timesteps: 513,465,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 513465358...
Checkpoint 513465358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,611.63939
Policy Entropy: 3.70507
Value Function Loss: 0.05452

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.48947
Value Function Update Magnitude: 0.75935

Collected Steps per Second: 22,832.05614
Overall Steps per Second: 10,842.32070

Timestep Collection Time: 2.19025
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.61230

Cumulative Model Updates: 61,574
Cumulative Timesteps: 513,515,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,732.52005
Policy Entropy: 3.69787
Value Function Loss: 0.05742

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.41596
Value Function Update Magnitude: 0.73460

Collected Steps per Second: 22,542.62861
Overall Steps per Second: 10,678.94606

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.46527
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.68436

Cumulative Model Updates: 61,580
Cumulative Timesteps: 513,565,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 513565390...
Checkpoint 513565390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,569.28927
Policy Entropy: 3.71258
Value Function Loss: 0.05748

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.51322
Value Function Update Magnitude: 0.78424

Collected Steps per Second: 22,900.69274
Overall Steps per Second: 10,857.10176

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.60546

Cumulative Model Updates: 61,586
Cumulative Timesteps: 513,615,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,866.56262
Policy Entropy: 3.71114
Value Function Loss: 0.05833

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.56308
Value Function Update Magnitude: 0.82640

Collected Steps per Second: 22,880.82295
Overall Steps per Second: 10,647.38434

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.51196
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.69824

Cumulative Model Updates: 61,592
Cumulative Timesteps: 513,665,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 513665416...
Checkpoint 513665416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,600.64029
Policy Entropy: 3.71978
Value Function Loss: 0.05791

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.52615
Value Function Update Magnitude: 0.74439

Collected Steps per Second: 22,679.01820
Overall Steps per Second: 10,639.81312

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.49525
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.70046

Cumulative Model Updates: 61,598
Cumulative Timesteps: 513,715,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,892.82128
Policy Entropy: 3.73522
Value Function Loss: 0.05578

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.49370
Value Function Update Magnitude: 0.70955

Collected Steps per Second: 23,078.34773
Overall Steps per Second: 10,773.04725

Timestep Collection Time: 2.16679
Timestep Consumption Time: 2.47498
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.64177

Cumulative Model Updates: 61,604
Cumulative Timesteps: 513,765,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 513765434...
Checkpoint 513765434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,923.73826
Policy Entropy: 3.73636
Value Function Loss: 0.05308

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.50834
Value Function Update Magnitude: 0.76981

Collected Steps per Second: 22,957.39975
Overall Steps per Second: 10,655.59540

Timestep Collection Time: 2.17891
Timestep Consumption Time: 2.51553
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.69443

Cumulative Model Updates: 61,610
Cumulative Timesteps: 513,815,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,433.42457
Policy Entropy: 3.73342
Value Function Loss: 0.05220

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.52112
Value Function Update Magnitude: 0.73885

Collected Steps per Second: 22,812.25535
Overall Steps per Second: 10,858.13536

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.41313
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.60503

Cumulative Model Updates: 61,616
Cumulative Timesteps: 513,865,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 513865458...
Checkpoint 513865458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,708.45297
Policy Entropy: 3.73831
Value Function Loss: 0.05483

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.51776
Value Function Update Magnitude: 0.73801

Collected Steps per Second: 22,821.66908
Overall Steps per Second: 10,720.57536

Timestep Collection Time: 2.19108
Timestep Consumption Time: 2.47323
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.66430

Cumulative Model Updates: 61,622
Cumulative Timesteps: 513,915,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,237.33911
Policy Entropy: 3.72775
Value Function Loss: 0.05650

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.51691
Value Function Update Magnitude: 0.71239

Collected Steps per Second: 22,603.56222
Overall Steps per Second: 10,763.96535

Timestep Collection Time: 2.21213
Timestep Consumption Time: 2.43318
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.64531

Cumulative Model Updates: 61,628
Cumulative Timesteps: 513,965,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 513965464...
Checkpoint 513965464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.02297
Policy Entropy: 3.72821
Value Function Loss: 0.05695

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.51235
Value Function Update Magnitude: 0.70932

Collected Steps per Second: 22,451.22437
Overall Steps per Second: 10,734.03888

Timestep Collection Time: 2.22821
Timestep Consumption Time: 2.43229
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.66050

Cumulative Model Updates: 61,634
Cumulative Timesteps: 514,015,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.80124
Policy Entropy: 3.71218
Value Function Loss: 0.05751

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05467
Policy Update Magnitude: 0.60263
Value Function Update Magnitude: 0.70241

Collected Steps per Second: 22,750.85575
Overall Steps per Second: 10,669.90518

Timestep Collection Time: 2.19842
Timestep Consumption Time: 2.48915
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.68758

Cumulative Model Updates: 61,640
Cumulative Timesteps: 514,065,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 514065506...
Checkpoint 514065506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,753.91628
Policy Entropy: 3.72177
Value Function Loss: 0.05888

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06076
Policy Update Magnitude: 0.70702
Value Function Update Magnitude: 0.74574

Collected Steps per Second: 22,840.06372
Overall Steps per Second: 10,847.00857

Timestep Collection Time: 2.19027
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.61196

Cumulative Model Updates: 61,646
Cumulative Timesteps: 514,115,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,123.75286
Policy Entropy: 3.71917
Value Function Loss: 0.05945

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.70892
Value Function Update Magnitude: 0.77815

Collected Steps per Second: 22,717.27746
Overall Steps per Second: 10,661.53421

Timestep Collection Time: 2.20150
Timestep Consumption Time: 2.48939
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.69088

Cumulative Model Updates: 61,652
Cumulative Timesteps: 514,165,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 514165544...
Checkpoint 514165544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,615.02946
Policy Entropy: 3.72894
Value Function Loss: 0.05854

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.67820
Value Function Update Magnitude: 0.85175

Collected Steps per Second: 22,851.46861
Overall Steps per Second: 10,826.10837

Timestep Collection Time: 2.18813
Timestep Consumption Time: 2.43052
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.61865

Cumulative Model Updates: 61,658
Cumulative Timesteps: 514,215,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,964.24521
Policy Entropy: 3.72703
Value Function Loss: 0.05916

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08762
Policy Update Magnitude: 0.56125
Value Function Update Magnitude: 0.89198

Collected Steps per Second: 22,415.42292
Overall Steps per Second: 10,572.12747

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.49991
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.73150

Cumulative Model Updates: 61,664
Cumulative Timesteps: 514,265,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 514265568...
Checkpoint 514265568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,161.95516
Policy Entropy: 3.72170
Value Function Loss: 0.05934

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.49466
Value Function Update Magnitude: 0.93102

Collected Steps per Second: 22,628.66577
Overall Steps per Second: 10,644.90417

Timestep Collection Time: 2.21091
Timestep Consumption Time: 2.48899
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.69990

Cumulative Model Updates: 61,670
Cumulative Timesteps: 514,315,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,104.09956
Policy Entropy: 3.71733
Value Function Loss: 0.06235

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.50891
Value Function Update Magnitude: 0.90855

Collected Steps per Second: 22,637.67536
Overall Steps per Second: 10,628.76854

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.49561
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.70440

Cumulative Model Updates: 61,676
Cumulative Timesteps: 514,365,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 514365600...
Checkpoint 514365600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,026.69123
Policy Entropy: 3.71192
Value Function Loss: 0.06687

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.54548
Value Function Update Magnitude: 0.80574

Collected Steps per Second: 22,676.44014
Overall Steps per Second: 10,803.28112

Timestep Collection Time: 2.20573
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.62989

Cumulative Model Updates: 61,682
Cumulative Timesteps: 514,415,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,146.89602
Policy Entropy: 3.72049
Value Function Loss: 0.06669

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06614
Policy Update Magnitude: 0.65177
Value Function Update Magnitude: 0.78061

Collected Steps per Second: 22,808.71599
Overall Steps per Second: 10,693.86486

Timestep Collection Time: 2.19302
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.67745

Cumulative Model Updates: 61,688
Cumulative Timesteps: 514,465,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 514465638...
Checkpoint 514465638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,462.41963
Policy Entropy: 3.72155
Value Function Loss: 0.06470

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.66854
Value Function Update Magnitude: 0.80477

Collected Steps per Second: 22,750.08857
Overall Steps per Second: 10,728.67873

Timestep Collection Time: 2.19823
Timestep Consumption Time: 2.46310
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.66134

Cumulative Model Updates: 61,694
Cumulative Timesteps: 514,515,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,440.31568
Policy Entropy: 3.72526
Value Function Loss: 0.06331

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.63372
Value Function Update Magnitude: 0.81715

Collected Steps per Second: 22,765.41383
Overall Steps per Second: 10,673.94146

Timestep Collection Time: 2.19710
Timestep Consumption Time: 2.48889
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.68599

Cumulative Model Updates: 61,700
Cumulative Timesteps: 514,565,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 514565666...
Checkpoint 514565666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,307.77174
Policy Entropy: 3.71577
Value Function Loss: 0.06488

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.56639
Value Function Update Magnitude: 0.81663

Collected Steps per Second: 22,682.74827
Overall Steps per Second: 10,591.61980

Timestep Collection Time: 2.20538
Timestep Consumption Time: 2.51760
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.72298

Cumulative Model Updates: 61,706
Cumulative Timesteps: 514,615,690

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,726.66399
Policy Entropy: 3.72213
Value Function Loss: 0.06518

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.86517

Collected Steps per Second: 22,933.32441
Overall Steps per Second: 10,860.68143

Timestep Collection Time: 2.18111
Timestep Consumption Time: 2.42450
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.60560

Cumulative Model Updates: 61,712
Cumulative Timesteps: 514,665,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 514665710...
Checkpoint 514665710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,185.04851
Policy Entropy: 3.70728
Value Function Loss: 0.06256

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.48763
Value Function Update Magnitude: 0.94187

Collected Steps per Second: 22,673.05261
Overall Steps per Second: 10,726.44810

Timestep Collection Time: 2.20561
Timestep Consumption Time: 2.45651
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.66212

Cumulative Model Updates: 61,718
Cumulative Timesteps: 514,715,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,260.06505
Policy Entropy: 3.70974
Value Function Loss: 0.06276

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.47757
Value Function Update Magnitude: 0.91627

Collected Steps per Second: 23,044.39776
Overall Steps per Second: 10,857.13790

Timestep Collection Time: 2.17085
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.60766

Cumulative Model Updates: 61,724
Cumulative Timesteps: 514,765,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 514765744...
Checkpoint 514765744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,360.88143
Policy Entropy: 3.70528
Value Function Loss: 0.06407

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.47216
Value Function Update Magnitude: 0.86813

Collected Steps per Second: 22,717.07420
Overall Steps per Second: 10,700.04582

Timestep Collection Time: 2.20108
Timestep Consumption Time: 2.47199
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.67306

Cumulative Model Updates: 61,730
Cumulative Timesteps: 514,815,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,582.37095
Policy Entropy: 3.69982
Value Function Loss: 0.06566

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.48086
Value Function Update Magnitude: 0.86248

Collected Steps per Second: 22,949.02548
Overall Steps per Second: 10,858.17744

Timestep Collection Time: 2.17953
Timestep Consumption Time: 2.42696
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60648

Cumulative Model Updates: 61,736
Cumulative Timesteps: 514,865,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 514865764...
Checkpoint 514865764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,805.35391
Policy Entropy: 3.68653
Value Function Loss: 0.06378

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.51250
Value Function Update Magnitude: 0.87152

Collected Steps per Second: 22,425.00839
Overall Steps per Second: 10,690.74642

Timestep Collection Time: 2.23010
Timestep Consumption Time: 2.44778
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.67788

Cumulative Model Updates: 61,742
Cumulative Timesteps: 514,915,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,612.22382
Policy Entropy: 3.68191
Value Function Loss: 0.06422

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.59331
Value Function Update Magnitude: 0.75816

Collected Steps per Second: 22,201.92699
Overall Steps per Second: 10,848.73167

Timestep Collection Time: 2.25242
Timestep Consumption Time: 2.35715
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60957

Cumulative Model Updates: 61,748
Cumulative Timesteps: 514,965,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 514965782...
Checkpoint 514965782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,681.51532
Policy Entropy: 3.67958
Value Function Loss: 0.06577

Mean KL Divergence: 0.02337
SB3 Clip Fraction: 0.18291
Policy Update Magnitude: 0.45596
Value Function Update Magnitude: 0.65790

Collected Steps per Second: 21,982.08872
Overall Steps per Second: 10,675.75712

Timestep Collection Time: 2.27576
Timestep Consumption Time: 2.41018
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.68594

Cumulative Model Updates: 61,754
Cumulative Timesteps: 515,015,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,071.26026
Policy Entropy: 3.67318
Value Function Loss: 0.06842

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.40387
Value Function Update Magnitude: 0.65495

Collected Steps per Second: 22,236.77408
Overall Steps per Second: 10,864.87465

Timestep Collection Time: 2.24943
Timestep Consumption Time: 2.35440
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.60383

Cumulative Model Updates: 61,760
Cumulative Timesteps: 515,065,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 515065828...
Checkpoint 515065828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,075.81458
Policy Entropy: 3.66499
Value Function Loss: 0.06897

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.50334
Value Function Update Magnitude: 0.57550

Collected Steps per Second: 22,078.30504
Overall Steps per Second: 10,667.08786

Timestep Collection Time: 2.26603
Timestep Consumption Time: 2.42410
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.69013

Cumulative Model Updates: 61,766
Cumulative Timesteps: 515,115,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,657.46556
Policy Entropy: 3.66587
Value Function Loss: 0.07079

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.49561
Value Function Update Magnitude: 0.60730

Collected Steps per Second: 21,989.68339
Overall Steps per Second: 10,646.63253

Timestep Collection Time: 2.27443
Timestep Consumption Time: 2.42321
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69764

Cumulative Model Updates: 61,772
Cumulative Timesteps: 515,165,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 515165872...
Checkpoint 515165872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.30860
Policy Entropy: 3.66993
Value Function Loss: 0.06803

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.45942
Value Function Update Magnitude: 0.61002

Collected Steps per Second: 22,351.80637
Overall Steps per Second: 10,666.82903

Timestep Collection Time: 2.23848
Timestep Consumption Time: 2.45214
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.69062

Cumulative Model Updates: 61,778
Cumulative Timesteps: 515,215,906

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,632.91272
Policy Entropy: 3.67170
Value Function Loss: 0.07095

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.49744
Value Function Update Magnitude: 0.52927

Collected Steps per Second: 22,916.08959
Overall Steps per Second: 10,714.11889

Timestep Collection Time: 2.18196
Timestep Consumption Time: 2.48497
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.66693

Cumulative Model Updates: 61,784
Cumulative Timesteps: 515,265,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 515265908...
Checkpoint 515265908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,949.62627
Policy Entropy: 3.67393
Value Function Loss: 0.06731

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.53159
Value Function Update Magnitude: 0.51591

Collected Steps per Second: 22,726.49517
Overall Steps per Second: 10,712.67425

Timestep Collection Time: 2.20096
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.66924

Cumulative Model Updates: 61,790
Cumulative Timesteps: 515,315,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,973.56523
Policy Entropy: 3.67018
Value Function Loss: 0.06644

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.49430
Value Function Update Magnitude: 0.58846

Collected Steps per Second: 22,694.43800
Overall Steps per Second: 10,854.94761

Timestep Collection Time: 2.20318
Timestep Consumption Time: 2.40301
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.60619

Cumulative Model Updates: 61,796
Cumulative Timesteps: 515,365,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 515365928...
Checkpoint 515365928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,786.10388
Policy Entropy: 3.66873
Value Function Loss: 0.06175

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.55427
Value Function Update Magnitude: 0.67765

Collected Steps per Second: 22,469.17888
Overall Steps per Second: 10,601.28323

Timestep Collection Time: 2.22643
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.71886

Cumulative Model Updates: 61,802
Cumulative Timesteps: 515,415,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,157.85092
Policy Entropy: 3.66321
Value Function Loss: 0.06028

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.58057
Value Function Update Magnitude: 0.76841

Collected Steps per Second: 22,769.15526
Overall Steps per Second: 10,828.87612

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.42278
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.62005

Cumulative Model Updates: 61,808
Cumulative Timesteps: 515,465,984

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 515465984...
Checkpoint 515465984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,890.43448
Policy Entropy: 3.66156
Value Function Loss: 0.05835

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.81467

Collected Steps per Second: 22,398.42295
Overall Steps per Second: 10,737.62781

Timestep Collection Time: 2.23364
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.65932

Cumulative Model Updates: 61,814
Cumulative Timesteps: 515,516,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,754.06029
Policy Entropy: 3.66419
Value Function Loss: 0.05961

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.60995
Value Function Update Magnitude: 0.83133

Collected Steps per Second: 22,671.16354
Overall Steps per Second: 10,789.68429

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.63498

Cumulative Model Updates: 61,820
Cumulative Timesteps: 515,566,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 515566024...
Checkpoint 515566024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,475.56850
Policy Entropy: 3.67361
Value Function Loss: 0.06020

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.57726
Value Function Update Magnitude: 0.85273

Collected Steps per Second: 22,702.37235
Overall Steps per Second: 10,756.67624

Timestep Collection Time: 2.20241
Timestep Consumption Time: 2.44586
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.64828

Cumulative Model Updates: 61,826
Cumulative Timesteps: 515,616,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,352.09018
Policy Entropy: 3.68880
Value Function Loss: 0.05953

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.50023
Value Function Update Magnitude: 0.87508

Collected Steps per Second: 23,190.25399
Overall Steps per Second: 10,952.51120

Timestep Collection Time: 2.15737
Timestep Consumption Time: 2.41053
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.56790

Cumulative Model Updates: 61,832
Cumulative Timesteps: 515,666,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 515666054...
Checkpoint 515666054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,908.09956
Policy Entropy: 3.67367
Value Function Loss: 0.06087

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.47407
Value Function Update Magnitude: 0.89155

Collected Steps per Second: 22,648.55452
Overall Steps per Second: 10,632.99698

Timestep Collection Time: 2.20906
Timestep Consumption Time: 2.49629
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.70535

Cumulative Model Updates: 61,838
Cumulative Timesteps: 515,716,086

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,229.07677
Policy Entropy: 3.67868
Value Function Loss: 0.06316

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.46797
Value Function Update Magnitude: 0.86881

Collected Steps per Second: 22,751.17506
Overall Steps per Second: 10,790.35161

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.63414

Cumulative Model Updates: 61,844
Cumulative Timesteps: 515,766,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 515766090...
Checkpoint 515766090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,120.13337
Policy Entropy: 3.67044
Value Function Loss: 0.06398

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.49619
Value Function Update Magnitude: 0.86424

Collected Steps per Second: 22,590.50021
Overall Steps per Second: 10,722.88302

Timestep Collection Time: 2.21403
Timestep Consumption Time: 2.45039
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.66442

Cumulative Model Updates: 61,850
Cumulative Timesteps: 515,816,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,397.37181
Policy Entropy: 3.69217
Value Function Loss: 0.06333

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.48861
Value Function Update Magnitude: 0.88709

Collected Steps per Second: 23,091.44860
Overall Steps per Second: 10,933.32393

Timestep Collection Time: 2.16574
Timestep Consumption Time: 2.40835
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.57409

Cumulative Model Updates: 61,856
Cumulative Timesteps: 515,866,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 515866116...
Checkpoint 515866116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,502.61985
Policy Entropy: 3.68655
Value Function Loss: 0.05970

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.54890
Value Function Update Magnitude: 0.87447

Collected Steps per Second: 22,573.97785
Overall Steps per Second: 10,596.86026

Timestep Collection Time: 2.21538
Timestep Consumption Time: 2.50394
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.71932

Cumulative Model Updates: 61,862
Cumulative Timesteps: 515,916,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,111.66171
Policy Entropy: 3.69518
Value Function Loss: 0.05952

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07693
Policy Update Magnitude: 0.58339
Value Function Update Magnitude: 0.88881

Collected Steps per Second: 22,276.27100
Overall Steps per Second: 10,854.90762

Timestep Collection Time: 2.24571
Timestep Consumption Time: 2.36290
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60861

Cumulative Model Updates: 61,868
Cumulative Timesteps: 515,966,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 515966152...
Checkpoint 515966152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,148.70888
Policy Entropy: 3.69834
Value Function Loss: 0.06224

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07490
Policy Update Magnitude: 0.66051
Value Function Update Magnitude: 0.87652

Collected Steps per Second: 21,851.32457
Overall Steps per Second: 10,709.89650

Timestep Collection Time: 2.28883
Timestep Consumption Time: 2.38105
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.66989

Cumulative Model Updates: 61,874
Cumulative Timesteps: 516,016,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,848.67756
Policy Entropy: 3.70565
Value Function Loss: 0.06325

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.66486
Value Function Update Magnitude: 0.81329

Collected Steps per Second: 22,290.19672
Overall Steps per Second: 10,880.30944

Timestep Collection Time: 2.24395
Timestep Consumption Time: 2.35317
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.59711

Cumulative Model Updates: 61,880
Cumulative Timesteps: 516,066,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 516066184...
Checkpoint 516066184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,904.03011
Policy Entropy: 3.71184
Value Function Loss: 0.06337

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.55461
Value Function Update Magnitude: 0.75207

Collected Steps per Second: 21,973.39868
Overall Steps per Second: 10,685.44146

Timestep Collection Time: 2.27657
Timestep Consumption Time: 2.40494
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.68151

Cumulative Model Updates: 61,886
Cumulative Timesteps: 516,116,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,790.86120
Policy Entropy: 3.69563
Value Function Loss: 0.06167

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.53699
Value Function Update Magnitude: 0.86311

Collected Steps per Second: 21,878.93501
Overall Steps per Second: 10,773.70950

Timestep Collection Time: 2.28613
Timestep Consumption Time: 2.35647
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.64260

Cumulative Model Updates: 61,892
Cumulative Timesteps: 516,166,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 516166226...
Checkpoint 516166226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,540.37740
Policy Entropy: 3.70043
Value Function Loss: 0.06388

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.52849
Value Function Update Magnitude: 0.74030

Collected Steps per Second: 22,018.34927
Overall Steps per Second: 10,682.42041

Timestep Collection Time: 2.27092
Timestep Consumption Time: 2.40985
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.68077

Cumulative Model Updates: 61,898
Cumulative Timesteps: 516,216,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,105.68935
Policy Entropy: 3.69763
Value Function Loss: 0.06279

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.48191
Value Function Update Magnitude: 0.78608

Collected Steps per Second: 22,889.53236
Overall Steps per Second: 10,895.09265

Timestep Collection Time: 2.18554
Timestep Consumption Time: 2.40607
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.59161

Cumulative Model Updates: 61,904
Cumulative Timesteps: 516,266,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 516266254...
Checkpoint 516266254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,256.43451
Policy Entropy: 3.70586
Value Function Loss: 0.06010

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.90842

Collected Steps per Second: 22,830.74166
Overall Steps per Second: 10,716.31017

Timestep Collection Time: 2.19012
Timestep Consumption Time: 2.47585
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.66597

Cumulative Model Updates: 61,910
Cumulative Timesteps: 516,316,256

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,669.80833
Policy Entropy: 3.70261
Value Function Loss: 0.05965

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.57059
Value Function Update Magnitude: 0.92676

Collected Steps per Second: 22,670.58165
Overall Steps per Second: 10,837.48157

Timestep Collection Time: 2.20630
Timestep Consumption Time: 2.40898
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.61528

Cumulative Model Updates: 61,916
Cumulative Timesteps: 516,366,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 516366274...
Checkpoint 516366274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,749.83552
Policy Entropy: 3.69673
Value Function Loss: 0.06199

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.69115
Value Function Update Magnitude: 0.85910

Collected Steps per Second: 21,408.85101
Overall Steps per Second: 10,371.36091

Timestep Collection Time: 2.33623
Timestep Consumption Time: 2.48628
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.82251

Cumulative Model Updates: 61,922
Cumulative Timesteps: 516,416,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,115.97288
Policy Entropy: 3.69817
Value Function Loss: 0.06487

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.67616
Value Function Update Magnitude: 0.76104

Collected Steps per Second: 22,235.63433
Overall Steps per Second: 10,442.24298

Timestep Collection Time: 2.24954
Timestep Consumption Time: 2.54062
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.79016

Cumulative Model Updates: 61,928
Cumulative Timesteps: 516,466,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 516466310...
Checkpoint 516466310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,766.98818
Policy Entropy: 3.70068
Value Function Loss: 0.06478

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06785
Policy Update Magnitude: 0.71111
Value Function Update Magnitude: 0.72824

Collected Steps per Second: 22,249.47691
Overall Steps per Second: 10,546.19033

Timestep Collection Time: 2.24850
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.74370

Cumulative Model Updates: 61,934
Cumulative Timesteps: 516,516,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,766.43593
Policy Entropy: 3.71672
Value Function Loss: 0.06577

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.72404
Value Function Update Magnitude: 0.68393

Collected Steps per Second: 21,649.69648
Overall Steps per Second: 10,393.85713

Timestep Collection Time: 2.30950
Timestep Consumption Time: 2.50103
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.81053

Cumulative Model Updates: 61,940
Cumulative Timesteps: 516,566,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 516566338...
Checkpoint 516566338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,472.01750
Policy Entropy: 3.71320
Value Function Loss: 0.06387

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.69362
Value Function Update Magnitude: 0.73267

Collected Steps per Second: 21,044.55820
Overall Steps per Second: 10,230.06140

Timestep Collection Time: 2.37610
Timestep Consumption Time: 2.51185
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.88795

Cumulative Model Updates: 61,946
Cumulative Timesteps: 516,616,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912.41924
Policy Entropy: 3.72301
Value Function Loss: 0.06388

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.69943
Value Function Update Magnitude: 0.75586

Collected Steps per Second: 21,339.44044
Overall Steps per Second: 10,260.61873

Timestep Collection Time: 2.34411
Timestep Consumption Time: 2.53103
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.87514

Cumulative Model Updates: 61,952
Cumulative Timesteps: 516,666,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 516666364...
Checkpoint 516666364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,823.11970
Policy Entropy: 3.71435
Value Function Loss: 0.06059

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.62052
Value Function Update Magnitude: 0.72285

Collected Steps per Second: 22,029.56166
Overall Steps per Second: 10,480.43343

Timestep Collection Time: 2.27095
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.77347

Cumulative Model Updates: 61,958
Cumulative Timesteps: 516,716,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,330.62245
Policy Entropy: 3.71678
Value Function Loss: 0.05946

Mean KL Divergence: 0.02112
SB3 Clip Fraction: 0.16878
Policy Update Magnitude: 0.49339
Value Function Update Magnitude: 0.69731

Collected Steps per Second: 22,801.54108
Overall Steps per Second: 10,861.18676

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.41187
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60576

Cumulative Model Updates: 61,964
Cumulative Timesteps: 516,766,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 516766416...
Checkpoint 516766416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,067.58974
Policy Entropy: 3.72671
Value Function Loss: 0.05937

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.11889
Policy Update Magnitude: 0.51742
Value Function Update Magnitude: 0.67825

Collected Steps per Second: 21,852.54221
Overall Steps per Second: 10,584.57800

Timestep Collection Time: 2.28925
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.72631

Cumulative Model Updates: 61,970
Cumulative Timesteps: 516,816,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,325.89457
Policy Entropy: 3.72119
Value Function Loss: 0.06038

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10808
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.70831

Collected Steps per Second: 22,655.23133
Overall Steps per Second: 10,613.17070

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.71377

Cumulative Model Updates: 61,976
Cumulative Timesteps: 516,866,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 516866470...
Checkpoint 516866470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.66969
Policy Entropy: 3.72391
Value Function Loss: 0.06269

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.58656
Value Function Update Magnitude: 0.76101

Collected Steps per Second: 22,679.05795
Overall Steps per Second: 10,642.45619

Timestep Collection Time: 2.20477
Timestep Consumption Time: 2.49359
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.69835

Cumulative Model Updates: 61,982
Cumulative Timesteps: 516,916,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,028.98225
Policy Entropy: 3.73172
Value Function Loss: 0.06120

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.88369

Collected Steps per Second: 22,874.81526
Overall Steps per Second: 10,815.78056

Timestep Collection Time: 2.18607
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62343

Cumulative Model Updates: 61,988
Cumulative Timesteps: 516,966,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 516966478...
Checkpoint 516966478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,528.56607
Policy Entropy: 3.73563
Value Function Loss: 0.05814

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.57673
Value Function Update Magnitude: 0.92859

Collected Steps per Second: 22,541.27394
Overall Steps per Second: 10,647.48682

Timestep Collection Time: 2.21833
Timestep Consumption Time: 2.47799
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.69632

Cumulative Model Updates: 61,994
Cumulative Timesteps: 517,016,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,543.50660
Policy Entropy: 3.74192
Value Function Loss: 0.05461

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.55247
Value Function Update Magnitude: 0.90564

Collected Steps per Second: 22,754.55901
Overall Steps per Second: 10,694.23685

Timestep Collection Time: 2.19824
Timestep Consumption Time: 2.47904
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.67729

Cumulative Model Updates: 62,000
Cumulative Timesteps: 517,066,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 517066502...
Checkpoint 517066502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,821.39776
Policy Entropy: 3.73647
Value Function Loss: 0.05501

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.64025
Value Function Update Magnitude: 0.78801

Collected Steps per Second: 22,495.89448
Overall Steps per Second: 10,833.23823

Timestep Collection Time: 2.22298
Timestep Consumption Time: 2.39318
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.61616

Cumulative Model Updates: 62,006
Cumulative Timesteps: 517,116,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.71379
Policy Entropy: 3.73118
Value Function Loss: 0.05475

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.64268
Value Function Update Magnitude: 0.69357

Collected Steps per Second: 22,579.49416
Overall Steps per Second: 10,603.38100

Timestep Collection Time: 2.21546
Timestep Consumption Time: 2.50228
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.71774

Cumulative Model Updates: 62,012
Cumulative Timesteps: 517,166,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 517166534...
Checkpoint 517166534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,382.86904
Policy Entropy: 3.72764
Value Function Loss: 0.05597

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.66262

Collected Steps per Second: 22,774.06710
Overall Steps per Second: 10,708.52416

Timestep Collection Time: 2.19680
Timestep Consumption Time: 2.47518
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67198

Cumulative Model Updates: 62,018
Cumulative Timesteps: 517,216,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,424.57485
Policy Entropy: 3.72318
Value Function Loss: 0.05735

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.65046

Collected Steps per Second: 23,356.70498
Overall Steps per Second: 10,746.01906

Timestep Collection Time: 2.14157
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.65475

Cumulative Model Updates: 62,024
Cumulative Timesteps: 517,266,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 517266584...
Checkpoint 517266584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,519.09184
Policy Entropy: 3.73226
Value Function Loss: 0.05626

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.50828
Value Function Update Magnitude: 0.62318

Collected Steps per Second: 22,611.08171
Overall Steps per Second: 10,673.82045

Timestep Collection Time: 2.21184
Timestep Consumption Time: 2.47365
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.68548

Cumulative Model Updates: 62,030
Cumulative Timesteps: 517,316,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,519.09184
Policy Entropy: 3.73017
Value Function Loss: 0.05711

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.60595

Collected Steps per Second: 22,845.07207
Overall Steps per Second: 10,785.15762

Timestep Collection Time: 2.18918
Timestep Consumption Time: 2.44793
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.63711

Cumulative Model Updates: 62,036
Cumulative Timesteps: 517,366,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 517366608...
Checkpoint 517366608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,325.95688
Policy Entropy: 3.73164
Value Function Loss: 0.05649

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.65932
Value Function Update Magnitude: 0.63402

Collected Steps per Second: 22,697.71328
Overall Steps per Second: 10,669.82168

Timestep Collection Time: 2.20419
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.68893

Cumulative Model Updates: 62,042
Cumulative Timesteps: 517,416,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,687.95807
Policy Entropy: 3.73640
Value Function Loss: 0.05628

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.59244
Value Function Update Magnitude: 0.68256

Collected Steps per Second: 23,256.65637
Overall Steps per Second: 10,923.46407

Timestep Collection Time: 2.15052
Timestep Consumption Time: 2.42806
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.57858

Cumulative Model Updates: 62,048
Cumulative Timesteps: 517,466,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 517466652...
Checkpoint 517466652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,012.70621
Policy Entropy: 3.74771
Value Function Loss: 0.05472

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.60444
Value Function Update Magnitude: 0.68832

Collected Steps per Second: 22,362.60307
Overall Steps per Second: 10,667.29974

Timestep Collection Time: 2.23597
Timestep Consumption Time: 2.45144
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.68741

Cumulative Model Updates: 62,054
Cumulative Timesteps: 517,516,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,981.91212
Policy Entropy: 3.74553
Value Function Loss: 0.05150

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.61130
Value Function Update Magnitude: 0.69845

Collected Steps per Second: 22,843.83762
Overall Steps per Second: 10,908.46614

Timestep Collection Time: 2.18930
Timestep Consumption Time: 2.39540
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.58470

Cumulative Model Updates: 62,060
Cumulative Timesteps: 517,566,666

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 517566666...
Checkpoint 517566666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,137.24958
Policy Entropy: 3.74507
Value Function Loss: 0.05200

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.60567
Value Function Update Magnitude: 0.76481

Collected Steps per Second: 22,396.22399
Overall Steps per Second: 10,619.40806

Timestep Collection Time: 2.23288
Timestep Consumption Time: 2.47624
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.70911

Cumulative Model Updates: 62,066
Cumulative Timesteps: 517,616,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,250.45634
Policy Entropy: 3.73355
Value Function Loss: 0.05359

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.64828
Value Function Update Magnitude: 0.79291

Collected Steps per Second: 23,039.33457
Overall Steps per Second: 10,853.30108

Timestep Collection Time: 2.17055
Timestep Consumption Time: 2.43708
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.60763

Cumulative Model Updates: 62,072
Cumulative Timesteps: 517,666,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 517666682...
Checkpoint 517666682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,780.18222
Policy Entropy: 3.73272
Value Function Loss: 0.05700

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.67907
Value Function Update Magnitude: 0.81697

Collected Steps per Second: 22,233.56936
Overall Steps per Second: 10,747.08110

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.40502
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.65522

Cumulative Model Updates: 62,078
Cumulative Timesteps: 517,716,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,434.05630
Policy Entropy: 3.69809
Value Function Loss: 0.05834

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.56169
Value Function Update Magnitude: 0.76679

Collected Steps per Second: 22,736.65432
Overall Steps per Second: 10,786.53427

Timestep Collection Time: 2.19918
Timestep Consumption Time: 2.43641
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.63559

Cumulative Model Updates: 62,084
Cumulative Timesteps: 517,766,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 517766714...
Checkpoint 517766714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,827.03828
Policy Entropy: 3.68597
Value Function Loss: 0.05922

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.49053
Value Function Update Magnitude: 0.73505

Collected Steps per Second: 22,554.45179
Overall Steps per Second: 10,679.93333

Timestep Collection Time: 2.21703
Timestep Consumption Time: 2.46502
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.68205

Cumulative Model Updates: 62,090
Cumulative Timesteps: 517,816,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,090.21821
Policy Entropy: 3.68521
Value Function Loss: 0.06136

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.51316
Value Function Update Magnitude: 0.71846

Collected Steps per Second: 22,927.08856
Overall Steps per Second: 10,859.25011

Timestep Collection Time: 2.18083
Timestep Consumption Time: 2.42354
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.60437

Cumulative Model Updates: 62,096
Cumulative Timesteps: 517,866,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 517866718...
Checkpoint 517866718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,816.80545
Policy Entropy: 3.69485
Value Function Loss: 0.06141

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.57732
Value Function Update Magnitude: 0.77570

Collected Steps per Second: 22,590.02568
Overall Steps per Second: 10,712.30922

Timestep Collection Time: 2.21354
Timestep Consumption Time: 2.45436
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.66790

Cumulative Model Updates: 62,102
Cumulative Timesteps: 517,916,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,591.39570
Policy Entropy: 3.69403
Value Function Loss: 0.06094

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.52320
Value Function Update Magnitude: 0.84420

Collected Steps per Second: 22,803.83396
Overall Steps per Second: 10,814.63334

Timestep Collection Time: 2.19349
Timestep Consumption Time: 2.43172
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62521

Cumulative Model Updates: 62,108
Cumulative Timesteps: 517,966,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 517966742...
Checkpoint 517966742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,898.23661
Policy Entropy: 3.70250
Value Function Loss: 0.05992

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.50297
Value Function Update Magnitude: 0.85901

Collected Steps per Second: 22,783.22807
Overall Steps per Second: 10,718.19467

Timestep Collection Time: 2.19583
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.66758

Cumulative Model Updates: 62,114
Cumulative Timesteps: 518,016,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,350.13231
Policy Entropy: 3.71327
Value Function Loss: 0.05920

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.16060
Policy Update Magnitude: 0.48530
Value Function Update Magnitude: 0.86495

Collected Steps per Second: 23,233.82227
Overall Steps per Second: 10,909.89092

Timestep Collection Time: 2.15229
Timestep Consumption Time: 2.43125
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.58355

Cumulative Model Updates: 62,120
Cumulative Timesteps: 518,066,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 518066776...
Checkpoint 518066776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,891.60682
Policy Entropy: 3.71445
Value Function Loss: 0.05751

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.56857
Value Function Update Magnitude: 0.86785

Collected Steps per Second: 22,731.62443
Overall Steps per Second: 10,644.86479

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.49892
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.69973

Cumulative Model Updates: 62,126
Cumulative Timesteps: 518,116,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,806.36199
Policy Entropy: 3.72794
Value Function Loss: 0.05788

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.60188
Value Function Update Magnitude: 0.83952

Collected Steps per Second: 22,888.92868
Overall Steps per Second: 10,807.37899

Timestep Collection Time: 2.18455
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.62665

Cumulative Model Updates: 62,132
Cumulative Timesteps: 518,166,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 518166806...
Checkpoint 518166806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,058.44005
Policy Entropy: 3.74266
Value Function Loss: 0.05780

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.61677
Value Function Update Magnitude: 0.82105

Collected Steps per Second: 22,808.87859
Overall Steps per Second: 10,752.72563

Timestep Collection Time: 2.19222
Timestep Consumption Time: 2.45795
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.65017

Cumulative Model Updates: 62,138
Cumulative Timesteps: 518,216,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,205.55960
Policy Entropy: 3.73576
Value Function Loss: 0.05732

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.57811
Value Function Update Magnitude: 0.82530

Collected Steps per Second: 23,015.29330
Overall Steps per Second: 10,869.65096

Timestep Collection Time: 2.17334
Timestep Consumption Time: 2.42847
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60180

Cumulative Model Updates: 62,144
Cumulative Timesteps: 518,266,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 518266828...
Checkpoint 518266828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,552.09448
Policy Entropy: 3.73222
Value Function Loss: 0.05586

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.58052
Value Function Update Magnitude: 0.82800

Collected Steps per Second: 22,558.16989
Overall Steps per Second: 10,674.71552

Timestep Collection Time: 2.21729
Timestep Consumption Time: 2.46836
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.68565

Cumulative Model Updates: 62,150
Cumulative Timesteps: 518,316,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,022.80196
Policy Entropy: 3.73464
Value Function Loss: 0.05519

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.58944
Value Function Update Magnitude: 0.79619

Collected Steps per Second: 22,846.87400
Overall Steps per Second: 10,812.93907

Timestep Collection Time: 2.18892
Timestep Consumption Time: 2.43609
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.62501

Cumulative Model Updates: 62,156
Cumulative Timesteps: 518,366,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 518366856...
Checkpoint 518366856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,129.99788
Policy Entropy: 3.73338
Value Function Loss: 0.05737

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.52318
Value Function Update Magnitude: 0.75584

Collected Steps per Second: 22,273.30442
Overall Steps per Second: 10,715.58693

Timestep Collection Time: 2.24610
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.66871

Cumulative Model Updates: 62,162
Cumulative Timesteps: 518,416,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,321.99791
Policy Entropy: 3.74277
Value Function Loss: 0.05706

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.49316
Value Function Update Magnitude: 0.80246

Collected Steps per Second: 22,843.92638
Overall Steps per Second: 10,854.01641

Timestep Collection Time: 2.19017
Timestep Consumption Time: 2.41937
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.60954

Cumulative Model Updates: 62,168
Cumulative Timesteps: 518,466,916

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 518466916...
Checkpoint 518466916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,645.40467
Policy Entropy: 3.72201
Value Function Loss: 0.05807

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.51218
Value Function Update Magnitude: 0.86579

Collected Steps per Second: 22,561.06536
Overall Steps per Second: 10,740.94935

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.43887
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.65508

Cumulative Model Updates: 62,174
Cumulative Timesteps: 518,516,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,668.26595
Policy Entropy: 3.72737
Value Function Loss: 0.05653

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.52863
Value Function Update Magnitude: 0.88034

Collected Steps per Second: 23,001.54949
Overall Steps per Second: 10,890.87055

Timestep Collection Time: 2.17394
Timestep Consumption Time: 2.41743
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.59137

Cumulative Model Updates: 62,180
Cumulative Timesteps: 518,566,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 518566920...
Checkpoint 518566920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,451.20129
Policy Entropy: 3.71226
Value Function Loss: 0.05692

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.52535
Value Function Update Magnitude: 0.87179

Collected Steps per Second: 22,614.59456
Overall Steps per Second: 10,639.21187

Timestep Collection Time: 2.21167
Timestep Consumption Time: 2.48943
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.70110

Cumulative Model Updates: 62,186
Cumulative Timesteps: 518,616,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,871.03792
Policy Entropy: 3.71943
Value Function Loss: 0.05489

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.49997
Value Function Update Magnitude: 0.84791

Collected Steps per Second: 22,222.21136
Overall Steps per Second: 10,838.33947

Timestep Collection Time: 2.25027
Timestep Consumption Time: 2.36354
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61381

Cumulative Model Updates: 62,192
Cumulative Timesteps: 518,666,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 518666942...
Checkpoint 518666942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,644.23047
Policy Entropy: 3.71296
Value Function Loss: 0.05548

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.60980
Value Function Update Magnitude: 0.85535

Collected Steps per Second: 21,761.00320
Overall Steps per Second: 10,725.30594

Timestep Collection Time: 2.29907
Timestep Consumption Time: 2.36560
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.66467

Cumulative Model Updates: 62,198
Cumulative Timesteps: 518,716,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,051.44514
Policy Entropy: 3.71658
Value Function Loss: 0.05603

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.66555
Value Function Update Magnitude: 0.85814

Collected Steps per Second: 22,254.55257
Overall Steps per Second: 10,865.71439

Timestep Collection Time: 2.24763
Timestep Consumption Time: 2.35584
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.60347

Cumulative Model Updates: 62,204
Cumulative Timesteps: 518,766,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 518766992...
Checkpoint 518766992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,133.44431
Policy Entropy: 3.72294
Value Function Loss: 0.05819

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.69341
Value Function Update Magnitude: 0.85685

Collected Steps per Second: 21,548.52261
Overall Steps per Second: 10,720.87947

Timestep Collection Time: 2.32109
Timestep Consumption Time: 2.34420
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.66529

Cumulative Model Updates: 62,210
Cumulative Timesteps: 518,817,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,746.44933
Policy Entropy: 3.73509
Value Function Loss: 0.05813

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.59009
Value Function Update Magnitude: 0.86911

Collected Steps per Second: 22,209.55109
Overall Steps per Second: 10,890.90043

Timestep Collection Time: 2.25236
Timestep Consumption Time: 2.34083
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.59319

Cumulative Model Updates: 62,216
Cumulative Timesteps: 518,867,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 518867032...
Checkpoint 518867032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,645.26360
Policy Entropy: 3.73831
Value Function Loss: 0.05964

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.56646
Value Function Update Magnitude: 0.85545

Collected Steps per Second: 22,151.10493
Overall Steps per Second: 10,704.08353

Timestep Collection Time: 2.25758
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.67186

Cumulative Model Updates: 62,222
Cumulative Timesteps: 518,917,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,875.35766
Policy Entropy: 3.74625
Value Function Loss: 0.05901

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.51598
Value Function Update Magnitude: 0.82630

Collected Steps per Second: 22,470.86929
Overall Steps per Second: 10,785.37333

Timestep Collection Time: 2.22599
Timestep Consumption Time: 2.41177
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.63776

Cumulative Model Updates: 62,228
Cumulative Timesteps: 518,967,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 518967060...
Checkpoint 518967060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,927.66740
Policy Entropy: 3.74355
Value Function Loss: 0.05933

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.47346
Value Function Update Magnitude: 0.82822

Collected Steps per Second: 22,719.56232
Overall Steps per Second: 10,676.02311

Timestep Collection Time: 2.20127
Timestep Consumption Time: 2.48324
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.68452

Cumulative Model Updates: 62,234
Cumulative Timesteps: 519,017,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,129.72846
Policy Entropy: 3.75972
Value Function Loss: 0.05859

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.47135
Value Function Update Magnitude: 0.82102

Collected Steps per Second: 22,932.71292
Overall Steps per Second: 10,919.88276

Timestep Collection Time: 2.18073
Timestep Consumption Time: 2.39899
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.57972

Cumulative Model Updates: 62,240
Cumulative Timesteps: 519,067,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 519067082...
Checkpoint 519067082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,952.51680
Policy Entropy: 3.77172
Value Function Loss: 0.05744

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.48130
Value Function Update Magnitude: 0.82780

Collected Steps per Second: 22,550.21950
Overall Steps per Second: 10,616.23616

Timestep Collection Time: 2.21843
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.71222

Cumulative Model Updates: 62,246
Cumulative Timesteps: 519,117,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,177.75835
Policy Entropy: 3.76571
Value Function Loss: 0.05840

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.57441
Value Function Update Magnitude: 0.84144

Collected Steps per Second: 22,928.66073
Overall Steps per Second: 10,868.36143

Timestep Collection Time: 2.18111
Timestep Consumption Time: 2.42032
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.60143

Cumulative Model Updates: 62,252
Cumulative Timesteps: 519,167,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 519167118...
Checkpoint 519167118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,146.71041
Policy Entropy: 3.75055
Value Function Loss: 0.05979

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.56783
Value Function Update Magnitude: 0.85242

Collected Steps per Second: 22,430.71383
Overall Steps per Second: 10,659.09376

Timestep Collection Time: 2.23016
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.69308

Cumulative Model Updates: 62,258
Cumulative Timesteps: 519,217,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,057.25434
Policy Entropy: 3.74933
Value Function Loss: 0.06063

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06179
Policy Update Magnitude: 0.61545
Value Function Update Magnitude: 0.80852

Collected Steps per Second: 22,736.65668
Overall Steps per Second: 10,888.26268

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.39435
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.59467

Cumulative Model Updates: 62,264
Cumulative Timesteps: 519,267,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 519267170...
Checkpoint 519267170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,936.26853
Policy Entropy: 3.74285
Value Function Loss: 0.06041

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06637
Policy Update Magnitude: 0.67783
Value Function Update Magnitude: 0.78326

Collected Steps per Second: 22,526.18382
Overall Steps per Second: 10,673.31752

Timestep Collection Time: 2.22008
Timestep Consumption Time: 2.46543
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.68552

Cumulative Model Updates: 62,270
Cumulative Timesteps: 519,317,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,860.03203
Policy Entropy: 3.72955
Value Function Loss: 0.06276

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.62367
Value Function Update Magnitude: 0.79011

Collected Steps per Second: 22,626.22622
Overall Steps per Second: 10,823.28612

Timestep Collection Time: 2.21089
Timestep Consumption Time: 2.41100
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62189

Cumulative Model Updates: 62,276
Cumulative Timesteps: 519,367,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 519367204...
Checkpoint 519367204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,457.63409
Policy Entropy: 3.73223
Value Function Loss: 0.06378

Mean KL Divergence: 0.02209
SB3 Clip Fraction: 0.17219
Policy Update Magnitude: 0.49687
Value Function Update Magnitude: 0.75464

Collected Steps per Second: 22,519.31125
Overall Steps per Second: 10,754.91736

Timestep Collection Time: 2.22120
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.65090

Cumulative Model Updates: 62,282
Cumulative Timesteps: 519,417,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,264.32990
Policy Entropy: 3.72857
Value Function Loss: 0.06293

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.16001
Policy Update Magnitude: 0.47242
Value Function Update Magnitude: 0.77174

Collected Steps per Second: 22,681.38080
Overall Steps per Second: 10,796.35943

Timestep Collection Time: 2.20657
Timestep Consumption Time: 2.42907
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.63564

Cumulative Model Updates: 62,288
Cumulative Timesteps: 519,467,272

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 519467272...
Checkpoint 519467272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,060.61449
Policy Entropy: 3.73952
Value Function Loss: 0.06120

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.50321
Value Function Update Magnitude: 0.78999

Collected Steps per Second: 22,544.32247
Overall Steps per Second: 10,716.75286

Timestep Collection Time: 2.21847
Timestep Consumption Time: 2.44842
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.66690

Cumulative Model Updates: 62,294
Cumulative Timesteps: 519,517,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,273.23000
Policy Entropy: 3.74755
Value Function Loss: 0.05891

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.62096
Value Function Update Magnitude: 0.82017

Collected Steps per Second: 22,952.48919
Overall Steps per Second: 10,830.30083

Timestep Collection Time: 2.17850
Timestep Consumption Time: 2.43836
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.61686

Cumulative Model Updates: 62,300
Cumulative Timesteps: 519,567,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 519567288...
Checkpoint 519567288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,048.62258
Policy Entropy: 3.75418
Value Function Loss: 0.05743

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.68235
Value Function Update Magnitude: 0.80849

Collected Steps per Second: 22,605.30273
Overall Steps per Second: 10,703.70366

Timestep Collection Time: 2.21222
Timestep Consumption Time: 2.45980
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.67203

Cumulative Model Updates: 62,306
Cumulative Timesteps: 519,617,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,807.37178
Policy Entropy: 3.74964
Value Function Loss: 0.05727

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.63599
Value Function Update Magnitude: 0.78489

Collected Steps per Second: 22,684.74681
Overall Steps per Second: 10,856.73153

Timestep Collection Time: 2.20545
Timestep Consumption Time: 2.40275
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60820

Cumulative Model Updates: 62,312
Cumulative Timesteps: 519,667,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 519667326...
Checkpoint 519667326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,465.72957
Policy Entropy: 3.74529
Value Function Loss: 0.05808

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.58139
Value Function Update Magnitude: 0.79210

Collected Steps per Second: 22,521.10419
Overall Steps per Second: 10,670.79485

Timestep Collection Time: 2.22156
Timestep Consumption Time: 2.46712
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.68869

Cumulative Model Updates: 62,318
Cumulative Timesteps: 519,717,358

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,482.27904
Policy Entropy: 3.74208
Value Function Loss: 0.05873

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.51338
Value Function Update Magnitude: 0.83563

Collected Steps per Second: 22,660.73874
Overall Steps per Second: 10,828.25477

Timestep Collection Time: 2.20752
Timestep Consumption Time: 2.41225
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.61977

Cumulative Model Updates: 62,324
Cumulative Timesteps: 519,767,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 519767382...
Checkpoint 519767382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.02537
Policy Entropy: 3.74359
Value Function Loss: 0.05802

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.47246
Value Function Update Magnitude: 0.86414

Collected Steps per Second: 22,435.92992
Overall Steps per Second: 10,724.17874

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.66497

Cumulative Model Updates: 62,330
Cumulative Timesteps: 519,817,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,787.75400
Policy Entropy: 3.74069
Value Function Loss: 0.05664

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.52143
Value Function Update Magnitude: 0.86929

Collected Steps per Second: 22,358.74225
Overall Steps per Second: 10,640.53810

Timestep Collection Time: 2.23689
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.70033

Cumulative Model Updates: 62,336
Cumulative Timesteps: 519,867,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 519867424...
Checkpoint 519867424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,488.93569
Policy Entropy: 3.73633
Value Function Loss: 0.05512

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.51065
Value Function Update Magnitude: 0.91304

Collected Steps per Second: 22,998.77026
Overall Steps per Second: 10,871.35650

Timestep Collection Time: 2.17533
Timestep Consumption Time: 2.42667
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60200

Cumulative Model Updates: 62,342
Cumulative Timesteps: 519,917,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,742.14602
Policy Entropy: 3.73489
Value Function Loss: 0.05838

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.51909
Value Function Update Magnitude: 0.91274

Collected Steps per Second: 22,492.05230
Overall Steps per Second: 10,574.71641

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.50595
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.72958

Cumulative Model Updates: 62,348
Cumulative Timesteps: 519,967,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 519967468...
Checkpoint 519967468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,278.77637
Policy Entropy: 3.72971
Value Function Loss: 0.06052

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.51215
Value Function Update Magnitude: 0.91696

Collected Steps per Second: 22,811.98524
Overall Steps per Second: 10,678.29305

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.68296

Cumulative Model Updates: 62,354
Cumulative Timesteps: 520,017,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,364.79262
Policy Entropy: 3.73539
Value Function Loss: 0.06141

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.61484
Value Function Update Magnitude: 0.93347

Collected Steps per Second: 22,977.30840
Overall Steps per Second: 10,822.51808

Timestep Collection Time: 2.17806
Timestep Consumption Time: 2.44619
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.62425

Cumulative Model Updates: 62,360
Cumulative Timesteps: 520,067,520

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 520067520...
Checkpoint 520067520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,483.93855
Policy Entropy: 3.73685
Value Function Loss: 0.05780

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.62416
Value Function Update Magnitude: 0.93303

Collected Steps per Second: 22,902.36842
Overall Steps per Second: 10,665.66971

Timestep Collection Time: 2.18440
Timestep Consumption Time: 2.50616
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.69056

Cumulative Model Updates: 62,366
Cumulative Timesteps: 520,117,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,259.19663
Policy Entropy: 3.74170
Value Function Loss: 0.05851

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.54781
Value Function Update Magnitude: 0.91279

Collected Steps per Second: 23,117.84870
Overall Steps per Second: 10,890.07116

Timestep Collection Time: 2.16344
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.59262

Cumulative Model Updates: 62,372
Cumulative Timesteps: 520,167,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 520167562...
Checkpoint 520167562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,960.81154
Policy Entropy: 3.72822
Value Function Loss: 0.05890

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.54529
Value Function Update Magnitude: 0.88974

Collected Steps per Second: 22,547.29028
Overall Steps per Second: 10,608.31346

Timestep Collection Time: 2.21854
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.71536

Cumulative Model Updates: 62,378
Cumulative Timesteps: 520,217,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,847.36324
Policy Entropy: 3.72120
Value Function Loss: 0.06031

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.59366
Value Function Update Magnitude: 0.86929

Collected Steps per Second: 23,129.49516
Overall Steps per Second: 10,878.57703

Timestep Collection Time: 2.16217
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.59711

Cumulative Model Updates: 62,384
Cumulative Timesteps: 520,267,594

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 520267594...
Checkpoint 520267594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,034.15265
Policy Entropy: 3.71902
Value Function Loss: 0.06281

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.60369
Value Function Update Magnitude: 0.86846

Collected Steps per Second: 22,525.74408
Overall Steps per Second: 10,687.69594

Timestep Collection Time: 2.22110
Timestep Consumption Time: 2.46017
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.68127

Cumulative Model Updates: 62,390
Cumulative Timesteps: 520,317,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,454.52022
Policy Entropy: 3.72187
Value Function Loss: 0.06304

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.52564
Value Function Update Magnitude: 0.85052

Collected Steps per Second: 22,963.39372
Overall Steps per Second: 10,836.06397

Timestep Collection Time: 2.17755
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61459

Cumulative Model Updates: 62,396
Cumulative Timesteps: 520,367,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 520367630...
Checkpoint 520367630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,153.47458
Policy Entropy: 3.72358
Value Function Loss: 0.06368

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.46439
Value Function Update Magnitude: 0.85777

Collected Steps per Second: 22,478.41916
Overall Steps per Second: 10,753.09081

Timestep Collection Time: 2.22542
Timestep Consumption Time: 2.42663
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.65206

Cumulative Model Updates: 62,402
Cumulative Timesteps: 520,417,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,909.91275
Policy Entropy: 3.71942
Value Function Loss: 0.06133

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.48185
Value Function Update Magnitude: 0.88329

Collected Steps per Second: 22,752.95978
Overall Steps per Second: 10,790.84669

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.63356

Cumulative Model Updates: 62,408
Cumulative Timesteps: 520,467,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 520467654...
Checkpoint 520467654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,954.58921
Policy Entropy: 3.71705
Value Function Loss: 0.06359

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06484
Policy Update Magnitude: 0.60713
Value Function Update Magnitude: 0.88168

Collected Steps per Second: 22,624.08642
Overall Steps per Second: 10,723.52305

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.45330
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.66395

Cumulative Model Updates: 62,414
Cumulative Timesteps: 520,517,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,033.79032
Policy Entropy: 3.70608
Value Function Loss: 0.06503

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.68224
Value Function Update Magnitude: 0.89175

Collected Steps per Second: 22,831.42646
Overall Steps per Second: 10,804.13681

Timestep Collection Time: 2.19066
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.62934

Cumulative Model Updates: 62,420
Cumulative Timesteps: 520,567,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 520567684...
Checkpoint 520567684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,036.16981
Policy Entropy: 3.70496
Value Function Loss: 0.06296

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.66436
Value Function Update Magnitude: 0.88921

Collected Steps per Second: 22,329.40081
Overall Steps per Second: 10,686.51044

Timestep Collection Time: 2.23992
Timestep Consumption Time: 2.44038
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.68029

Cumulative Model Updates: 62,426
Cumulative Timesteps: 520,617,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,935.00941
Policy Entropy: 3.70700
Value Function Loss: 0.05817

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.61142
Value Function Update Magnitude: 0.86167

Collected Steps per Second: 22,596.49266
Overall Steps per Second: 10,618.47964

Timestep Collection Time: 2.21388
Timestep Consumption Time: 2.49734
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.71122

Cumulative Model Updates: 62,432
Cumulative Timesteps: 520,667,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 520667726...
Checkpoint 520667726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,611.11046
Policy Entropy: 3.71759
Value Function Loss: 0.05818

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.56700
Value Function Update Magnitude: 0.83778

Collected Steps per Second: 22,593.19229
Overall Steps per Second: 10,641.03671

Timestep Collection Time: 2.21341
Timestep Consumption Time: 2.48613
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.69954

Cumulative Model Updates: 62,438
Cumulative Timesteps: 520,717,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,367.77107
Policy Entropy: 3.72166
Value Function Loss: 0.05864

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.84565

Collected Steps per Second: 22,794.51160
Overall Steps per Second: 10,809.02398

Timestep Collection Time: 2.19421
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.62724

Cumulative Model Updates: 62,444
Cumulative Timesteps: 520,767,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 520767750...
Checkpoint 520767750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,444.52568
Policy Entropy: 3.70985
Value Function Loss: 0.06011

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.56228
Value Function Update Magnitude: 0.84678

Collected Steps per Second: 22,571.02481
Overall Steps per Second: 10,575.61038

Timestep Collection Time: 2.21523
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.72786

Cumulative Model Updates: 62,450
Cumulative Timesteps: 520,817,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,490.22212
Policy Entropy: 3.71427
Value Function Loss: 0.06353

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.59087
Value Function Update Magnitude: 0.72866

Collected Steps per Second: 22,958.51339
Overall Steps per Second: 10,854.68641

Timestep Collection Time: 2.17810
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.60686

Cumulative Model Updates: 62,456
Cumulative Timesteps: 520,867,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 520867756...
Checkpoint 520867756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,481.69451
Policy Entropy: 3.70610
Value Function Loss: 0.06581

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.63052
Value Function Update Magnitude: 0.67162

Collected Steps per Second: 22,409.05496
Overall Steps per Second: 10,700.74541

Timestep Collection Time: 2.23178
Timestep Consumption Time: 2.44192
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.67369

Cumulative Model Updates: 62,462
Cumulative Timesteps: 520,917,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,419.39624
Policy Entropy: 3.69950
Value Function Loss: 0.06478

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.67633
Value Function Update Magnitude: 0.67588

Collected Steps per Second: 22,768.86253
Overall Steps per Second: 10,826.44099

Timestep Collection Time: 2.19607
Timestep Consumption Time: 2.42244
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61851

Cumulative Model Updates: 62,468
Cumulative Timesteps: 520,967,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 520967770...
Checkpoint 520967770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,831.87937
Policy Entropy: 3.69241
Value Function Loss: 0.06178

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.56359
Value Function Update Magnitude: 0.70373

Collected Steps per Second: 22,586.50081
Overall Steps per Second: 10,719.59476

Timestep Collection Time: 2.21380
Timestep Consumption Time: 2.45074
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.66454

Cumulative Model Updates: 62,474
Cumulative Timesteps: 521,017,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,776.68924
Policy Entropy: 3.68860
Value Function Loss: 0.06175

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.47975
Value Function Update Magnitude: 0.70509

Collected Steps per Second: 22,748.23802
Overall Steps per Second: 10,830.12480

Timestep Collection Time: 2.19876
Timestep Consumption Time: 2.41965
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61841

Cumulative Model Updates: 62,480
Cumulative Timesteps: 521,067,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 521067790...
Checkpoint 521067790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,962.48735
Policy Entropy: 3.68916
Value Function Loss: 0.06111

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10410
Policy Update Magnitude: 0.50634
Value Function Update Magnitude: 0.74853

Collected Steps per Second: 22,428.16635
Overall Steps per Second: 10,722.89494

Timestep Collection Time: 2.22943
Timestep Consumption Time: 2.43368
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.66311

Cumulative Model Updates: 62,486
Cumulative Timesteps: 521,117,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,462.73515
Policy Entropy: 3.69523
Value Function Loss: 0.06152

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.52494
Value Function Update Magnitude: 0.75622

Collected Steps per Second: 21,962.22897
Overall Steps per Second: 10,790.12040

Timestep Collection Time: 2.27782
Timestep Consumption Time: 2.35846
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.63628

Cumulative Model Updates: 62,492
Cumulative Timesteps: 521,167,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 521167818...
Checkpoint 521167818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,079.96271
Policy Entropy: 3.68996
Value Function Loss: 0.06441

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.49444
Value Function Update Magnitude: 0.73241

Collected Steps per Second: 21,837.38691
Overall Steps per Second: 10,743.83279

Timestep Collection Time: 2.29057
Timestep Consumption Time: 2.36513
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.65569

Cumulative Model Updates: 62,498
Cumulative Timesteps: 521,217,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,598.67910
Policy Entropy: 3.69941
Value Function Loss: 0.06269

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.48001
Value Function Update Magnitude: 0.77568

Collected Steps per Second: 22,005.63260
Overall Steps per Second: 10,685.09213

Timestep Collection Time: 2.27305
Timestep Consumption Time: 2.40823
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.68129

Cumulative Model Updates: 62,504
Cumulative Timesteps: 521,267,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 521267858...
Checkpoint 521267858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,366.88409
Policy Entropy: 3.70012
Value Function Loss: 0.06064

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.49063
Value Function Update Magnitude: 0.83884

Collected Steps per Second: 21,976.80673
Overall Steps per Second: 10,816.59330

Timestep Collection Time: 2.27513
Timestep Consumption Time: 2.34740
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.62253

Cumulative Model Updates: 62,510
Cumulative Timesteps: 521,317,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.35176
Policy Entropy: 3.72184
Value Function Loss: 0.05989

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.55207
Value Function Update Magnitude: 0.83912

Collected Steps per Second: 22,377.04107
Overall Steps per Second: 10,871.13742

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.36717
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.60375

Cumulative Model Updates: 62,516
Cumulative Timesteps: 521,367,906

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 521367906...
Checkpoint 521367906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,543.54517
Policy Entropy: 3.72762
Value Function Loss: 0.05943

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.61870
Value Function Update Magnitude: 0.84341

Collected Steps per Second: 21,845.31188
Overall Steps per Second: 10,800.64515

Timestep Collection Time: 2.29019
Timestep Consumption Time: 2.34194
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.63213

Cumulative Model Updates: 62,522
Cumulative Timesteps: 521,417,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,579.42679
Policy Entropy: 3.72845
Value Function Loss: 0.06033

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.60346
Value Function Update Magnitude: 0.85019

Collected Steps per Second: 22,267.31667
Overall Steps per Second: 10,643.36741

Timestep Collection Time: 2.24679
Timestep Consumption Time: 2.45379
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.70058

Cumulative Model Updates: 62,528
Cumulative Timesteps: 521,467,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 521467966...
Checkpoint 521467966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,935.74474
Policy Entropy: 3.72145
Value Function Loss: 0.06004

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.67778
Value Function Update Magnitude: 0.80448

Collected Steps per Second: 22,845.11381
Overall Steps per Second: 10,916.09458

Timestep Collection Time: 2.18918
Timestep Consumption Time: 2.39231
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.58149

Cumulative Model Updates: 62,534
Cumulative Timesteps: 521,517,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,473.57099
Policy Entropy: 3.71077
Value Function Loss: 0.06219

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.64353
Value Function Update Magnitude: 0.74708

Collected Steps per Second: 22,772.85304
Overall Steps per Second: 10,857.72276

Timestep Collection Time: 2.19612
Timestep Consumption Time: 2.41000
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60612

Cumulative Model Updates: 62,540
Cumulative Timesteps: 521,567,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 521567990...
Checkpoint 521567990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,162.96129
Policy Entropy: 3.72012
Value Function Loss: 0.06172

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.58000
Value Function Update Magnitude: 0.65644

Collected Steps per Second: 22,803.47077
Overall Steps per Second: 10,733.07886

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.65924

Cumulative Model Updates: 62,546
Cumulative Timesteps: 521,617,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.25076
Policy Entropy: 3.71736
Value Function Loss: 0.06200

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.61657

Collected Steps per Second: 23,036.61014
Overall Steps per Second: 10,808.35227

Timestep Collection Time: 2.17081
Timestep Consumption Time: 2.45599
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.62679

Cumulative Model Updates: 62,552
Cumulative Timesteps: 521,668,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 521668006...
Checkpoint 521668006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,458.79144
Policy Entropy: 3.72342
Value Function Loss: 0.06056

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.49609
Value Function Update Magnitude: 0.57786

Collected Steps per Second: 22,617.16312
Overall Steps per Second: 10,625.38825

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.49500
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.70571

Cumulative Model Updates: 62,558
Cumulative Timesteps: 521,718,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,160.93369
Policy Entropy: 3.71962
Value Function Loss: 0.05786

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.47623
Value Function Update Magnitude: 0.59442

Collected Steps per Second: 22,669.64330
Overall Steps per Second: 10,820.74798

Timestep Collection Time: 2.20630
Timestep Consumption Time: 2.41593
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.62223

Cumulative Model Updates: 62,564
Cumulative Timesteps: 521,768,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 521768022...
Checkpoint 521768022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,000.41553
Policy Entropy: 3.71770
Value Function Loss: 0.05644

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.51913
Value Function Update Magnitude: 0.60813

Collected Steps per Second: 22,438.70170
Overall Steps per Second: 10,738.85389

Timestep Collection Time: 2.22910
Timestep Consumption Time: 2.42857
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.65767

Cumulative Model Updates: 62,570
Cumulative Timesteps: 521,818,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,329.11974
Policy Entropy: 3.72096
Value Function Loss: 0.05302

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.60945
Value Function Update Magnitude: 0.68447

Collected Steps per Second: 22,819.50386
Overall Steps per Second: 10,817.44248

Timestep Collection Time: 2.19128
Timestep Consumption Time: 2.43125
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62253

Cumulative Model Updates: 62,576
Cumulative Timesteps: 521,868,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 521868044...
Checkpoint 521868044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.53542
Policy Entropy: 3.72446
Value Function Loss: 0.05119

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.65499
Value Function Update Magnitude: 0.76178

Collected Steps per Second: 22,623.89598
Overall Steps per Second: 10,741.74630

Timestep Collection Time: 2.21032
Timestep Consumption Time: 2.44498
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.65530

Cumulative Model Updates: 62,582
Cumulative Timesteps: 521,918,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,838.83573
Policy Entropy: 3.74048
Value Function Loss: 0.05214

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.64940
Value Function Update Magnitude: 0.78540

Collected Steps per Second: 22,443.64359
Overall Steps per Second: 10,594.47088

Timestep Collection Time: 2.22807
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.72001

Cumulative Model Updates: 62,588
Cumulative Timesteps: 521,968,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 521968056...
Checkpoint 521968056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,850.48170
Policy Entropy: 3.73770
Value Function Loss: 0.05125

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.68057
Value Function Update Magnitude: 0.76594

Collected Steps per Second: 22,462.74531
Overall Steps per Second: 10,585.60923

Timestep Collection Time: 2.22689
Timestep Consumption Time: 2.49858
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.72547

Cumulative Model Updates: 62,594
Cumulative Timesteps: 522,018,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,888.12809
Policy Entropy: 3.73008
Value Function Loss: 0.05336

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.68699
Value Function Update Magnitude: 0.67188

Collected Steps per Second: 22,812.71861
Overall Steps per Second: 10,863.73657

Timestep Collection Time: 2.19211
Timestep Consumption Time: 2.41109
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.60320

Cumulative Model Updates: 62,600
Cumulative Timesteps: 522,068,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 522068086...
Checkpoint 522068086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,156.27610
Policy Entropy: 3.72882
Value Function Loss: 0.05199

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.60231
Value Function Update Magnitude: 0.65855

Collected Steps per Second: 22,707.31263
Overall Steps per Second: 10,640.30592

Timestep Collection Time: 2.20246
Timestep Consumption Time: 2.49778
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.70024

Cumulative Model Updates: 62,606
Cumulative Timesteps: 522,118,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,915.04913
Policy Entropy: 3.73003
Value Function Loss: 0.05138

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.49618
Value Function Update Magnitude: 0.72090

Collected Steps per Second: 22,923.76809
Overall Steps per Second: 10,809.08595

Timestep Collection Time: 2.18193
Timestep Consumption Time: 2.44548
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.62740

Cumulative Model Updates: 62,612
Cumulative Timesteps: 522,168,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 522168116...
Checkpoint 522168116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,120.62665
Policy Entropy: 3.71838
Value Function Loss: 0.05057

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09780
Policy Update Magnitude: 0.48315
Value Function Update Magnitude: 0.73654

Collected Steps per Second: 22,763.95649
Overall Steps per Second: 10,658.10518

Timestep Collection Time: 2.19716
Timestep Consumption Time: 2.49561
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.69277

Cumulative Model Updates: 62,618
Cumulative Timesteps: 522,218,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,738.00659
Policy Entropy: 3.71942
Value Function Loss: 0.05262

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.48265
Value Function Update Magnitude: 0.74770

Collected Steps per Second: 22,916.02344
Overall Steps per Second: 10,847.14728

Timestep Collection Time: 2.18266
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.61117

Cumulative Model Updates: 62,624
Cumulative Timesteps: 522,268,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 522268150...
Checkpoint 522268150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,267.35163
Policy Entropy: 3.72300
Value Function Loss: 0.05389

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.51133
Value Function Update Magnitude: 0.78150

Collected Steps per Second: 22,518.35696
Overall Steps per Second: 10,712.08272

Timestep Collection Time: 2.22059
Timestep Consumption Time: 2.44741
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.66800

Cumulative Model Updates: 62,630
Cumulative Timesteps: 522,318,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,089.95096
Policy Entropy: 3.71851
Value Function Loss: 0.05446

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.59937
Value Function Update Magnitude: 0.80266

Collected Steps per Second: 22,817.62225
Overall Steps per Second: 10,816.50837

Timestep Collection Time: 2.19146
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62293

Cumulative Model Updates: 62,636
Cumulative Timesteps: 522,368,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 522368158...
Checkpoint 522368158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,845.59448
Policy Entropy: 3.70689
Value Function Loss: 0.05474

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.56224
Value Function Update Magnitude: 0.82944

Collected Steps per Second: 22,351.85296
Overall Steps per Second: 10,685.02574

Timestep Collection Time: 2.23820
Timestep Consumption Time: 2.44386
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.68207

Cumulative Model Updates: 62,642
Cumulative Timesteps: 522,418,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,620.86732
Policy Entropy: 3.72425
Value Function Loss: 0.05487

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.54633
Value Function Update Magnitude: 0.84770

Collected Steps per Second: 22,888.17878
Overall Steps per Second: 10,851.62847

Timestep Collection Time: 2.18497
Timestep Consumption Time: 2.42355
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.60852

Cumulative Model Updates: 62,648
Cumulative Timesteps: 522,468,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 522468196...
Checkpoint 522468196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,120.67313
Policy Entropy: 3.73530
Value Function Loss: 0.05507

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.84986

Collected Steps per Second: 22,631.04925
Overall Steps per Second: 10,738.33513

Timestep Collection Time: 2.21050
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.65864

Cumulative Model Updates: 62,654
Cumulative Timesteps: 522,518,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,455.64802
Policy Entropy: 3.73474
Value Function Loss: 0.05338

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.50039
Value Function Update Magnitude: 0.82105

Collected Steps per Second: 23,059.51656
Overall Steps per Second: 10,899.83973

Timestep Collection Time: 2.16917
Timestep Consumption Time: 2.41989
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.58906

Cumulative Model Updates: 62,660
Cumulative Timesteps: 522,568,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 522568242...
Checkpoint 522568242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,007.04745
Policy Entropy: 3.73836
Value Function Loss: 0.05139

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.47051
Value Function Update Magnitude: 0.79995

Collected Steps per Second: 22,451.22510
Overall Steps per Second: 10,633.00160

Timestep Collection Time: 2.22785
Timestep Consumption Time: 2.47618
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.70403

Cumulative Model Updates: 62,666
Cumulative Timesteps: 522,618,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,630.49053
Policy Entropy: 3.73511
Value Function Loss: 0.05020

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.51761
Value Function Update Magnitude: 0.79493

Collected Steps per Second: 22,827.04800
Overall Steps per Second: 10,825.42197

Timestep Collection Time: 2.19056
Timestep Consumption Time: 2.42857
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61913

Cumulative Model Updates: 62,672
Cumulative Timesteps: 522,668,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 522668264...
Checkpoint 522668264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,933.55934
Policy Entropy: 3.74050
Value Function Loss: 0.04861

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.53258
Value Function Update Magnitude: 0.77684

Collected Steps per Second: 22,736.81619
Overall Steps per Second: 10,736.45639

Timestep Collection Time: 2.20022
Timestep Consumption Time: 2.45923
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.65945

Cumulative Model Updates: 62,678
Cumulative Timesteps: 522,718,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,323.53005
Policy Entropy: 3.73087
Value Function Loss: 0.04831

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.51863
Value Function Update Magnitude: 0.76624

Collected Steps per Second: 22,874.72278
Overall Steps per Second: 10,827.57810

Timestep Collection Time: 2.18678
Timestep Consumption Time: 2.43309
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61987

Cumulative Model Updates: 62,684
Cumulative Timesteps: 522,768,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 522768312...
Checkpoint 522768312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.44516
Policy Entropy: 3.74144
Value Function Loss: 0.04605

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.47092
Value Function Update Magnitude: 0.76176

Collected Steps per Second: 22,556.49170
Overall Steps per Second: 10,703.66758

Timestep Collection Time: 2.21710
Timestep Consumption Time: 2.45513
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.67223

Cumulative Model Updates: 62,690
Cumulative Timesteps: 522,818,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,123.21495
Policy Entropy: 3.74279
Value Function Loss: 0.04643

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.45728
Value Function Update Magnitude: 0.74644

Collected Steps per Second: 22,812.32515
Overall Steps per Second: 10,848.10263

Timestep Collection Time: 2.19311
Timestep Consumption Time: 2.41875
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.61187

Cumulative Model Updates: 62,696
Cumulative Timesteps: 522,868,352

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 522868352...
Checkpoint 522868352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,725.07777
Policy Entropy: 3.74780
Value Function Loss: 0.04675

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.48066
Value Function Update Magnitude: 0.73895

Collected Steps per Second: 22,248.19496
Overall Steps per Second: 10,675.03411

Timestep Collection Time: 2.24791
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.68495

Cumulative Model Updates: 62,702
Cumulative Timesteps: 522,918,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,725.51105
Policy Entropy: 3.75824
Value Function Loss: 0.04585

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.47692
Value Function Update Magnitude: 0.74529

Collected Steps per Second: 22,482.80405
Overall Steps per Second: 10,590.77097

Timestep Collection Time: 2.22410
Timestep Consumption Time: 2.49737
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.72147

Cumulative Model Updates: 62,708
Cumulative Timesteps: 522,968,368

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 522968368...
Checkpoint 522968368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.56123
Policy Entropy: 3.75601
Value Function Loss: 0.04357

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.46737
Value Function Update Magnitude: 0.73716

Collected Steps per Second: 22,530.55382
Overall Steps per Second: 10,605.79744

Timestep Collection Time: 2.21992
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.71591

Cumulative Model Updates: 62,714
Cumulative Timesteps: 523,018,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,421.20297
Policy Entropy: 3.76013
Value Function Loss: 0.04271

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.12005
Policy Update Magnitude: 0.47751
Value Function Update Magnitude: 0.71348

Collected Steps per Second: 22,812.60201
Overall Steps per Second: 10,815.40294

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.62507

Cumulative Model Updates: 62,720
Cumulative Timesteps: 523,068,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 523068406...
Checkpoint 523068406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,096.53708
Policy Entropy: 3.75109
Value Function Loss: 0.04227

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.50812
Value Function Update Magnitude: 0.70837

Collected Steps per Second: 22,404.95097
Overall Steps per Second: 10,699.14797

Timestep Collection Time: 2.23245
Timestep Consumption Time: 2.44250
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.67495

Cumulative Model Updates: 62,726
Cumulative Timesteps: 523,118,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,136.76143
Policy Entropy: 3.75136
Value Function Loss: 0.04133

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.55959
Value Function Update Magnitude: 0.68764

Collected Steps per Second: 22,494.96136
Overall Steps per Second: 10,645.18938

Timestep Collection Time: 2.22396
Timestep Consumption Time: 2.47562
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.69959

Cumulative Model Updates: 62,732
Cumulative Timesteps: 523,168,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 523168452...
Checkpoint 523168452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,305.12711
Policy Entropy: 3.75268
Value Function Loss: 0.04231

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06808
Policy Update Magnitude: 0.60885
Value Function Update Magnitude: 0.68076

Collected Steps per Second: 22,733.07491
Overall Steps per Second: 10,804.13907

Timestep Collection Time: 2.20058
Timestep Consumption Time: 2.42968
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.63026

Cumulative Model Updates: 62,738
Cumulative Timesteps: 523,218,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,014.61398
Policy Entropy: 3.76474
Value Function Loss: 0.04285

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05573
Policy Update Magnitude: 0.63314
Value Function Update Magnitude: 0.69060

Collected Steps per Second: 22,731.22495
Overall Steps per Second: 10,653.69534

Timestep Collection Time: 2.20015
Timestep Consumption Time: 2.49419
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.69433

Cumulative Model Updates: 62,744
Cumulative Timesteps: 523,268,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 523268490...
Checkpoint 523268490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,770.71147
Policy Entropy: 3.77612
Value Function Loss: 0.04469

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06343
Policy Update Magnitude: 0.63884
Value Function Update Magnitude: 0.69663

Collected Steps per Second: 21,173.81585
Overall Steps per Second: 10,476.22958

Timestep Collection Time: 2.36301
Timestep Consumption Time: 2.41294
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.77595

Cumulative Model Updates: 62,750
Cumulative Timesteps: 523,318,524

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,520.81322
Policy Entropy: 3.77744
Value Function Loss: 0.04423

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06212
Policy Update Magnitude: 0.66028
Value Function Update Magnitude: 0.71674

Collected Steps per Second: 22,570.73678
Overall Steps per Second: 10,592.52046

Timestep Collection Time: 2.21552
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.72088

Cumulative Model Updates: 62,756
Cumulative Timesteps: 523,368,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 523368530...
Checkpoint 523368530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,411.00714
Policy Entropy: 3.77435
Value Function Loss: 0.04386

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06864
Policy Update Magnitude: 0.65914
Value Function Update Magnitude: 0.72688

Collected Steps per Second: 22,166.07239
Overall Steps per Second: 10,535.65755

Timestep Collection Time: 2.25579
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.74598

Cumulative Model Updates: 62,762
Cumulative Timesteps: 523,418,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,839.47630
Policy Entropy: 3.77607
Value Function Loss: 0.04345

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.57300
Value Function Update Magnitude: 0.71960

Collected Steps per Second: 22,875.64150
Overall Steps per Second: 10,856.17609

Timestep Collection Time: 2.18617
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.60659

Cumulative Model Updates: 62,768
Cumulative Timesteps: 523,468,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 523468542...
Checkpoint 523468542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,121.44471
Policy Entropy: 3.78050
Value Function Loss: 0.04542

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.47546
Value Function Update Magnitude: 0.71858

Collected Steps per Second: 22,722.65136
Overall Steps per Second: 10,745.21797

Timestep Collection Time: 2.20124
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.65491

Cumulative Model Updates: 62,774
Cumulative Timesteps: 523,518,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,005.16902
Policy Entropy: 3.77004
Value Function Loss: 0.05000

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.45806
Value Function Update Magnitude: 0.72677

Collected Steps per Second: 23,182.16046
Overall Steps per Second: 10,915.10041

Timestep Collection Time: 2.15683
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.58081

Cumulative Model Updates: 62,780
Cumulative Timesteps: 523,568,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 523568560...
Checkpoint 523568560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,533.40787
Policy Entropy: 3.76392
Value Function Loss: 0.05163

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.49793
Value Function Update Magnitude: 0.76622

Collected Steps per Second: 21,898.89433
Overall Steps per Second: 10,591.90472

Timestep Collection Time: 2.28450
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.72323

Cumulative Model Updates: 62,786
Cumulative Timesteps: 523,618,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,826.52680
Policy Entropy: 3.75339
Value Function Loss: 0.05313

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.51492
Value Function Update Magnitude: 0.78162

Collected Steps per Second: 22,118.96519
Overall Steps per Second: 10,840.03085

Timestep Collection Time: 2.26059
Timestep Consumption Time: 2.35212
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.61272

Cumulative Model Updates: 62,792
Cumulative Timesteps: 523,668,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 523668590...
Checkpoint 523668590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,665.74187
Policy Entropy: 3.75219
Value Function Loss: 0.05339

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.52671
Value Function Update Magnitude: 0.78821

Collected Steps per Second: 22,047.58577
Overall Steps per Second: 10,741.56739

Timestep Collection Time: 2.26855
Timestep Consumption Time: 2.38776
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.65630

Cumulative Model Updates: 62,798
Cumulative Timesteps: 523,718,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,233.59574
Policy Entropy: 3.74465
Value Function Loss: 0.05445

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.49727
Value Function Update Magnitude: 0.79565

Collected Steps per Second: 22,227.12110
Overall Steps per Second: 10,855.49033

Timestep Collection Time: 2.25040
Timestep Consumption Time: 2.35740
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.60781

Cumulative Model Updates: 62,804
Cumulative Timesteps: 523,768,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 523768626...
Checkpoint 523768626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,402.46959
Policy Entropy: 3.73386
Value Function Loss: 0.05429

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.51148
Value Function Update Magnitude: 0.78546

Collected Steps per Second: 21,968.71950
Overall Steps per Second: 10,674.35392

Timestep Collection Time: 2.27660
Timestep Consumption Time: 2.40884
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.68544

Cumulative Model Updates: 62,810
Cumulative Timesteps: 523,818,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,761.26618
Policy Entropy: 3.73621
Value Function Loss: 0.05393

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.48004
Value Function Update Magnitude: 0.78547

Collected Steps per Second: 22,192.44103
Overall Steps per Second: 10,861.68350

Timestep Collection Time: 2.25392
Timestep Consumption Time: 2.35126
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60518

Cumulative Model Updates: 62,816
Cumulative Timesteps: 523,868,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 523868660...
Checkpoint 523868660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,678.93935
Policy Entropy: 3.72438
Value Function Loss: 0.05878

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.50101
Value Function Update Magnitude: 0.71550

Collected Steps per Second: 22,157.98283
Overall Steps per Second: 10,750.09988

Timestep Collection Time: 2.25697
Timestep Consumption Time: 2.39508
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.65205

Cumulative Model Updates: 62,822
Cumulative Timesteps: 523,918,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,172.18949
Policy Entropy: 3.72734
Value Function Loss: 0.06236

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.50178
Value Function Update Magnitude: 0.73149

Collected Steps per Second: 22,713.19036
Overall Steps per Second: 10,877.17664

Timestep Collection Time: 2.20198
Timestep Consumption Time: 2.39609
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.59807

Cumulative Model Updates: 62,828
Cumulative Timesteps: 523,968,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 523968684...
Checkpoint 523968684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,356.88903
Policy Entropy: 3.73147
Value Function Loss: 0.06278

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.53210
Value Function Update Magnitude: 0.66385

Collected Steps per Second: 22,461.56945
Overall Steps per Second: 10,605.98689

Timestep Collection Time: 2.22727
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.71696

Cumulative Model Updates: 62,834
Cumulative Timesteps: 524,018,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,926.23112
Policy Entropy: 3.73481
Value Function Loss: 0.06031

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.55831
Value Function Update Magnitude: 0.72946

Collected Steps per Second: 22,872.82645
Overall Steps per Second: 10,867.69538

Timestep Collection Time: 2.18696
Timestep Consumption Time: 2.41585
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60282

Cumulative Model Updates: 62,840
Cumulative Timesteps: 524,068,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 524068734...
Checkpoint 524068734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,453.23965
Policy Entropy: 3.75168
Value Function Loss: 0.05706

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.78399

Collected Steps per Second: 22,787.82030
Overall Steps per Second: 10,681.98095

Timestep Collection Time: 2.19433
Timestep Consumption Time: 2.48682
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.68115

Cumulative Model Updates: 62,846
Cumulative Timesteps: 524,118,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,674.61789
Policy Entropy: 3.75559
Value Function Loss: 0.05636

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.17331
Policy Update Magnitude: 0.46518
Value Function Update Magnitude: 0.81040

Collected Steps per Second: 22,605.94259
Overall Steps per Second: 10,847.80401

Timestep Collection Time: 2.21243
Timestep Consumption Time: 2.39809
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.61052

Cumulative Model Updates: 62,852
Cumulative Timesteps: 524,168,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 524168752...
Checkpoint 524168752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.14947
Policy Entropy: 3.77989
Value Function Loss: 0.05580

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11325
Policy Update Magnitude: 0.52414
Value Function Update Magnitude: 0.73292

Collected Steps per Second: 22,657.19562
Overall Steps per Second: 10,684.90972

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.47427
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.68249

Cumulative Model Updates: 62,858
Cumulative Timesteps: 524,218,784

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,231.44869
Policy Entropy: 3.76888
Value Function Loss: 0.05427

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.65743
Value Function Update Magnitude: 0.66517

Collected Steps per Second: 22,948.07816
Overall Steps per Second: 10,692.00543

Timestep Collection Time: 2.17901
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67677

Cumulative Model Updates: 62,864
Cumulative Timesteps: 524,268,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 524268788...
Checkpoint 524268788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.14876
Policy Entropy: 3.75751
Value Function Loss: 0.05331

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.68996
Value Function Update Magnitude: 0.74180

Collected Steps per Second: 22,452.77506
Overall Steps per Second: 10,636.75244

Timestep Collection Time: 2.22699
Timestep Consumption Time: 2.47389
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.70087

Cumulative Model Updates: 62,870
Cumulative Timesteps: 524,318,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,182.94297
Policy Entropy: 3.75798
Value Function Loss: 0.04950

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.60137
Value Function Update Magnitude: 0.76583

Collected Steps per Second: 22,795.06388
Overall Steps per Second: 10,713.41641

Timestep Collection Time: 2.19407
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.66835

Cumulative Model Updates: 62,876
Cumulative Timesteps: 524,368,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 524368804...
Checkpoint 524368804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,824.12457
Policy Entropy: 3.77014
Value Function Loss: 0.04863

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07346
Policy Update Magnitude: 0.61550
Value Function Update Magnitude: 0.78392

Collected Steps per Second: 22,803.30530
Overall Steps per Second: 10,664.41543

Timestep Collection Time: 2.19284
Timestep Consumption Time: 2.49602
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68886

Cumulative Model Updates: 62,882
Cumulative Timesteps: 524,418,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,961.49277
Policy Entropy: 3.76693
Value Function Loss: 0.05150

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.66093
Value Function Update Magnitude: 0.79290

Collected Steps per Second: 22,621.65152
Overall Steps per Second: 10,778.92864

Timestep Collection Time: 2.21133
Timestep Consumption Time: 2.42957
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.64091

Cumulative Model Updates: 62,888
Cumulative Timesteps: 524,468,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 524468832...
Checkpoint 524468832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,074.32559
Policy Entropy: 3.76156
Value Function Loss: 0.05422

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06190
Policy Update Magnitude: 0.69181
Value Function Update Magnitude: 0.77180

Collected Steps per Second: 22,485.68293
Overall Steps per Second: 10,770.12486

Timestep Collection Time: 2.22470
Timestep Consumption Time: 2.42000
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.64470

Cumulative Model Updates: 62,894
Cumulative Timesteps: 524,518,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,927.25154
Policy Entropy: 3.75461
Value Function Loss: 0.05585

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.65435
Value Function Update Magnitude: 0.74861

Collected Steps per Second: 22,823.10958
Overall Steps per Second: 10,818.53405

Timestep Collection Time: 2.19120
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.62262

Cumulative Model Updates: 62,900
Cumulative Timesteps: 524,568,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 524568866...
Checkpoint 524568866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,081.65718
Policy Entropy: 3.76091
Value Function Loss: 0.05805

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.59536
Value Function Update Magnitude: 0.72903

Collected Steps per Second: 22,646.80759
Overall Steps per Second: 10,649.11987

Timestep Collection Time: 2.20782
Timestep Consumption Time: 2.48741
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.69522

Cumulative Model Updates: 62,906
Cumulative Timesteps: 524,618,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,740.01810
Policy Entropy: 3.75465
Value Function Loss: 0.05967

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09516
Policy Update Magnitude: 0.58425
Value Function Update Magnitude: 0.64898

Collected Steps per Second: 22,790.98837
Overall Steps per Second: 10,807.65365

Timestep Collection Time: 2.19455
Timestep Consumption Time: 2.43328
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.62783

Cumulative Model Updates: 62,912
Cumulative Timesteps: 524,668,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 524668882...
Checkpoint 524668882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,737.38500
Policy Entropy: 3.74403
Value Function Loss: 0.06257

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.58906
Value Function Update Magnitude: 0.63959

Collected Steps per Second: 22,721.16122
Overall Steps per Second: 10,748.11077

Timestep Collection Time: 2.20077
Timestep Consumption Time: 2.45158
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.65235

Cumulative Model Updates: 62,918
Cumulative Timesteps: 524,718,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,966.37954
Policy Entropy: 3.73894
Value Function Loss: 0.06279

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.58137
Value Function Update Magnitude: 0.63464

Collected Steps per Second: 22,850.39589
Overall Steps per Second: 10,824.01400

Timestep Collection Time: 2.18850
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.62010

Cumulative Model Updates: 62,924
Cumulative Timesteps: 524,768,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 524768894...
Checkpoint 524768894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,794.59412
Policy Entropy: 3.74889
Value Function Loss: 0.06286

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.53664
Value Function Update Magnitude: 0.68212

Collected Steps per Second: 22,605.35049
Overall Steps per Second: 10,719.40474

Timestep Collection Time: 2.21231
Timestep Consumption Time: 2.45306
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.66537

Cumulative Model Updates: 62,930
Cumulative Timesteps: 524,818,904

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,391.27509
Policy Entropy: 3.75294
Value Function Loss: 0.05915

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.55210
Value Function Update Magnitude: 0.69858

Collected Steps per Second: 22,999.59812
Overall Steps per Second: 10,825.19887

Timestep Collection Time: 2.17526
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62162

Cumulative Model Updates: 62,936
Cumulative Timesteps: 524,868,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 524868934...
Checkpoint 524868934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,096.91967
Policy Entropy: 3.74910
Value Function Loss: 0.05789

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.56482
Value Function Update Magnitude: 0.69893

Collected Steps per Second: 22,476.24402
Overall Steps per Second: 10,769.00213

Timestep Collection Time: 2.22546
Timestep Consumption Time: 2.41935
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.64481

Cumulative Model Updates: 62,942
Cumulative Timesteps: 524,918,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,824.92327
Policy Entropy: 3.73407
Value Function Loss: 0.05630

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.60247
Value Function Update Magnitude: 0.68081

Collected Steps per Second: 23,043.74044
Overall Steps per Second: 10,845.29239

Timestep Collection Time: 2.17013
Timestep Consumption Time: 2.44090
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.61103

Cumulative Model Updates: 62,948
Cumulative Timesteps: 524,968,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 524968962...
Checkpoint 524968962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,717.49420
Policy Entropy: 3.71842
Value Function Loss: 0.05679

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.58280
Value Function Update Magnitude: 0.69789

Collected Steps per Second: 22,694.46814
Overall Steps per Second: 10,696.07475

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.67891

Cumulative Model Updates: 62,954
Cumulative Timesteps: 525,019,008

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,892.32798
Policy Entropy: 3.71434
Value Function Loss: 0.05848

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.72607

Collected Steps per Second: 22,942.11049
Overall Steps per Second: 10,832.39447

Timestep Collection Time: 2.17957
Timestep Consumption Time: 2.43658
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61615

Cumulative Model Updates: 62,960
Cumulative Timesteps: 525,069,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 525069012...
Checkpoint 525069012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,130.58655
Policy Entropy: 3.70922
Value Function Loss: 0.05911

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.57499
Value Function Update Magnitude: 0.73077

Collected Steps per Second: 22,464.32939
Overall Steps per Second: 10,679.68223

Timestep Collection Time: 2.22682
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.68403

Cumulative Model Updates: 62,966
Cumulative Timesteps: 525,119,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,974.12098
Policy Entropy: 3.70767
Value Function Loss: 0.06202

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.66427
Value Function Update Magnitude: 0.68615

Collected Steps per Second: 22,900.94271
Overall Steps per Second: 10,832.42451

Timestep Collection Time: 2.18349
Timestep Consumption Time: 2.43265
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.61614

Cumulative Model Updates: 62,972
Cumulative Timesteps: 525,169,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 525169040...
Checkpoint 525169040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,361.73652
Policy Entropy: 3.70821
Value Function Loss: 0.06301

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.59653
Value Function Update Magnitude: 0.62978

Collected Steps per Second: 22,725.39788
Overall Steps per Second: 10,722.75094

Timestep Collection Time: 2.20018
Timestep Consumption Time: 2.46280
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.66298

Cumulative Model Updates: 62,978
Cumulative Timesteps: 525,219,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,204.00395
Policy Entropy: 3.71941
Value Function Loss: 0.06144

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.50853
Value Function Update Magnitude: 0.65108

Collected Steps per Second: 22,958.93983
Overall Steps per Second: 10,928.77626

Timestep Collection Time: 2.17919
Timestep Consumption Time: 2.39881
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.57801

Cumulative Model Updates: 62,984
Cumulative Timesteps: 525,269,072

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 525269072...
Checkpoint 525269072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,261.19680
Policy Entropy: 3.71953
Value Function Loss: 0.06155

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.47475
Value Function Update Magnitude: 0.70944

Collected Steps per Second: 22,671.93283
Overall Steps per Second: 10,600.00993

Timestep Collection Time: 2.20669
Timestep Consumption Time: 2.51311
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.71981

Cumulative Model Updates: 62,990
Cumulative Timesteps: 525,319,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,655.30845
Policy Entropy: 3.73083
Value Function Loss: 0.05987

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.50526
Value Function Update Magnitude: 0.66850

Collected Steps per Second: 22,538.95553
Overall Steps per Second: 10,645.94985

Timestep Collection Time: 2.21936
Timestep Consumption Time: 2.47933
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.69869

Cumulative Model Updates: 62,996
Cumulative Timesteps: 525,369,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 525369124...
Checkpoint 525369124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,393.60185
Policy Entropy: 3.70884
Value Function Loss: 0.06264

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.58666
Value Function Update Magnitude: 0.64922

Collected Steps per Second: 22,567.16534
Overall Steps per Second: 10,651.23333

Timestep Collection Time: 2.21579
Timestep Consumption Time: 2.47888
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69467

Cumulative Model Updates: 63,002
Cumulative Timesteps: 525,419,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,455.81107
Policy Entropy: 3.70612
Value Function Loss: 0.06184

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.63611
Value Function Update Magnitude: 0.68780

Collected Steps per Second: 23,143.67156
Overall Steps per Second: 10,707.47087

Timestep Collection Time: 2.16042
Timestep Consumption Time: 2.50922
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.66964

Cumulative Model Updates: 63,008
Cumulative Timesteps: 525,469,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 525469128...
Checkpoint 525469128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,914.58450
Policy Entropy: 3.69477
Value Function Loss: 0.06111

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.74374

Collected Steps per Second: 22,719.70767
Overall Steps per Second: 10,632.13196

Timestep Collection Time: 2.20091
Timestep Consumption Time: 2.50219
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.70310

Cumulative Model Updates: 63,014
Cumulative Timesteps: 525,519,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,642.11623
Policy Entropy: 3.70566
Value Function Loss: 0.06125

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.64792
Value Function Update Magnitude: 0.67320

Collected Steps per Second: 22,708.31240
Overall Steps per Second: 10,694.43168

Timestep Collection Time: 2.20281
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.67739

Cumulative Model Updates: 63,020
Cumulative Timesteps: 525,569,154

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 525569154...
Checkpoint 525569154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,794.10183
Policy Entropy: 3.70731
Value Function Loss: 0.06218

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.60030
Value Function Update Magnitude: 0.58735

Collected Steps per Second: 22,429.91492
Overall Steps per Second: 10,656.36851

Timestep Collection Time: 2.22979
Timestep Consumption Time: 2.46355
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.69334

Cumulative Model Updates: 63,026
Cumulative Timesteps: 525,619,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.27372
Policy Entropy: 3.71821
Value Function Loss: 0.06096

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.52337
Value Function Update Magnitude: 0.58823

Collected Steps per Second: 23,019.67291
Overall Steps per Second: 10,686.74781

Timestep Collection Time: 2.17249
Timestep Consumption Time: 2.50714
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.67963

Cumulative Model Updates: 63,032
Cumulative Timesteps: 525,669,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 525669178...
Checkpoint 525669178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,527.79199
Policy Entropy: 3.73342
Value Function Loss: 0.05911

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.15034
Policy Update Magnitude: 0.42221
Value Function Update Magnitude: 0.53797

Collected Steps per Second: 22,690.64101
Overall Steps per Second: 10,616.02743

Timestep Collection Time: 2.20549
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.71400

Cumulative Model Updates: 63,038
Cumulative Timesteps: 525,719,222

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,491.60092
Policy Entropy: 3.74201
Value Function Loss: 0.05372

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.50790
Value Function Update Magnitude: 0.56597

Collected Steps per Second: 22,979.11756
Overall Steps per Second: 10,856.51332

Timestep Collection Time: 2.17711
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60811

Cumulative Model Updates: 63,044
Cumulative Timesteps: 525,769,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 525769250...
Checkpoint 525769250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,548.32612
Policy Entropy: 3.74503
Value Function Loss: 0.05140

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.57936
Value Function Update Magnitude: 0.57454

Collected Steps per Second: 22,698.78736
Overall Steps per Second: 10,711.57532

Timestep Collection Time: 2.20408
Timestep Consumption Time: 2.46657
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.67065

Cumulative Model Updates: 63,050
Cumulative Timesteps: 525,819,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,560.02247
Policy Entropy: 3.75104
Value Function Loss: 0.04971

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.64996
Value Function Update Magnitude: 0.64775

Collected Steps per Second: 23,015.57290
Overall Steps per Second: 10,955.63936

Timestep Collection Time: 2.17322
Timestep Consumption Time: 2.39228
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.56550

Cumulative Model Updates: 63,056
Cumulative Timesteps: 525,869,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 525869298...
Checkpoint 525869298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,412.11596
Policy Entropy: 3.74069
Value Function Loss: 0.05109

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.65446
Value Function Update Magnitude: 0.65067

Collected Steps per Second: 22,789.45250
Overall Steps per Second: 10,655.98523

Timestep Collection Time: 2.19470
Timestep Consumption Time: 2.49900
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.69370

Cumulative Model Updates: 63,062
Cumulative Timesteps: 525,919,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,802.36382
Policy Entropy: 3.74251
Value Function Loss: 0.05351

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.67140
Value Function Update Magnitude: 0.56053

Collected Steps per Second: 22,644.79261
Overall Steps per Second: 10,779.62506

Timestep Collection Time: 2.20863
Timestep Consumption Time: 2.43105
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.63968

Cumulative Model Updates: 63,068
Cumulative Timesteps: 525,969,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 525969328...
Checkpoint 525969328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,646.61934
Policy Entropy: 3.74891
Value Function Loss: 0.05492

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06111
Policy Update Magnitude: 0.68406
Value Function Update Magnitude: 0.51322

Collected Steps per Second: 22,690.26419
Overall Steps per Second: 10,685.02904

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.68001

Cumulative Model Updates: 63,074
Cumulative Timesteps: 526,019,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,927.00743
Policy Entropy: 3.75067
Value Function Loss: 0.05213

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.65740
Value Function Update Magnitude: 0.60980

Collected Steps per Second: 22,617.69315
Overall Steps per Second: 10,656.90903

Timestep Collection Time: 2.21269
Timestep Consumption Time: 2.48342
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.69611

Cumulative Model Updates: 63,080
Cumulative Timesteps: 526,069,380

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 526069380...
Checkpoint 526069380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,052.55356
Policy Entropy: 3.74231
Value Function Loss: 0.05332

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.63785
Value Function Update Magnitude: 0.63706

Collected Steps per Second: 22,660.89975
Overall Steps per Second: 10,813.77131

Timestep Collection Time: 2.20733
Timestep Consumption Time: 2.41826
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.62558

Cumulative Model Updates: 63,086
Cumulative Timesteps: 526,119,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,854.85321
Policy Entropy: 3.73707
Value Function Loss: 0.05276

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11843
Policy Update Magnitude: 0.53749
Value Function Update Magnitude: 0.58834

Collected Steps per Second: 22,551.22529
Overall Steps per Second: 10,594.32009

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.71989

Cumulative Model Updates: 63,092
Cumulative Timesteps: 526,169,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 526169404...
Checkpoint 526169404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.56466
Policy Entropy: 3.73814
Value Function Loss: 0.05432

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.53009
Value Function Update Magnitude: 0.60264

Collected Steps per Second: 22,379.24833
Overall Steps per Second: 10,572.98254

Timestep Collection Time: 2.23439
Timestep Consumption Time: 2.49502
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72941

Cumulative Model Updates: 63,098
Cumulative Timesteps: 526,219,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,519.73132
Policy Entropy: 3.74778
Value Function Loss: 0.05281

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.56220
Value Function Update Magnitude: 0.64620

Collected Steps per Second: 22,714.94389
Overall Steps per Second: 10,819.08422

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.62387

Cumulative Model Updates: 63,104
Cumulative Timesteps: 526,269,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 526269434...
Checkpoint 526269434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,801.53299
Policy Entropy: 3.74664
Value Function Loss: 0.05395

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07115
Policy Update Magnitude: 0.61737
Value Function Update Magnitude: 0.63206

Collected Steps per Second: 22,470.68134
Overall Steps per Second: 10,756.85065

Timestep Collection Time: 2.22566
Timestep Consumption Time: 2.42366
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.64932

Cumulative Model Updates: 63,110
Cumulative Timesteps: 526,319,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,938.36767
Policy Entropy: 3.75058
Value Function Loss: 0.05444

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.63915
Value Function Update Magnitude: 0.62712

Collected Steps per Second: 22,809.50044
Overall Steps per Second: 10,804.25756

Timestep Collection Time: 2.19233
Timestep Consumption Time: 2.43603
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.62836

Cumulative Model Updates: 63,116
Cumulative Timesteps: 526,369,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 526369452...
Checkpoint 526369452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,374.69444
Policy Entropy: 3.73539
Value Function Loss: 0.05399

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.59092

Collected Steps per Second: 22,441.08687
Overall Steps per Second: 10,778.46622

Timestep Collection Time: 2.22815
Timestep Consumption Time: 2.41092
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.63906

Cumulative Model Updates: 63,122
Cumulative Timesteps: 526,419,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,313.57713
Policy Entropy: 3.75165
Value Function Loss: 0.05412

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.52101
Value Function Update Magnitude: 0.61584

Collected Steps per Second: 23,106.22743
Overall Steps per Second: 10,834.07190

Timestep Collection Time: 2.16452
Timestep Consumption Time: 2.45184
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.61636

Cumulative Model Updates: 63,128
Cumulative Timesteps: 526,469,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 526469468...
Checkpoint 526469468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,840.87440
Policy Entropy: 3.73851
Value Function Loss: 0.05446

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.53429
Value Function Update Magnitude: 0.60817

Collected Steps per Second: 22,605.81115
Overall Steps per Second: 10,626.44581

Timestep Collection Time: 2.21200
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.70562

Cumulative Model Updates: 63,134
Cumulative Timesteps: 526,519,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.15183
Policy Entropy: 3.74836
Value Function Loss: 0.05375

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.56949
Value Function Update Magnitude: 0.64537

Collected Steps per Second: 22,756.99741
Overall Steps per Second: 10,840.10347

Timestep Collection Time: 2.19836
Timestep Consumption Time: 2.41673
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61509

Cumulative Model Updates: 63,140
Cumulative Timesteps: 526,569,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 526569500...
Checkpoint 526569500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.98513
Policy Entropy: 3.74584
Value Function Loss: 0.05333

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.73658

Collected Steps per Second: 22,658.87585
Overall Steps per Second: 10,726.81520

Timestep Collection Time: 2.20691
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.66178

Cumulative Model Updates: 63,146
Cumulative Timesteps: 526,619,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,880.95758
Policy Entropy: 3.75028
Value Function Loss: 0.05283

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.56339
Value Function Update Magnitude: 0.75520

Collected Steps per Second: 23,060.25165
Overall Steps per Second: 10,877.38633

Timestep Collection Time: 2.16953
Timestep Consumption Time: 2.42992
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.59945

Cumulative Model Updates: 63,152
Cumulative Timesteps: 526,669,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 526669536...
Checkpoint 526669536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,522.16259
Policy Entropy: 3.76129
Value Function Loss: 0.05175

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.57069
Value Function Update Magnitude: 0.72247

Collected Steps per Second: 22,751.48297
Overall Steps per Second: 10,654.67433

Timestep Collection Time: 2.19845
Timestep Consumption Time: 2.49602
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.69447

Cumulative Model Updates: 63,158
Cumulative Timesteps: 526,719,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,206.07159
Policy Entropy: 3.76597
Value Function Loss: 0.05111

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.76169

Collected Steps per Second: 22,550.07872
Overall Steps per Second: 10,660.69108

Timestep Collection Time: 2.21791
Timestep Consumption Time: 2.47353
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.69144

Cumulative Model Updates: 63,164
Cumulative Timesteps: 526,769,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 526769568...
Checkpoint 526769568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,285.61262
Policy Entropy: 3.76667
Value Function Loss: 0.05105

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.56069
Value Function Update Magnitude: 0.81001

Collected Steps per Second: 22,483.81461
Overall Steps per Second: 10,584.68389

Timestep Collection Time: 2.22444
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.72513

Cumulative Model Updates: 63,170
Cumulative Timesteps: 526,819,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,549.83873
Policy Entropy: 3.75602
Value Function Loss: 0.05244

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.56777
Value Function Update Magnitude: 0.82414

Collected Steps per Second: 23,035.45127
Overall Steps per Second: 10,764.71464

Timestep Collection Time: 2.17126
Timestep Consumption Time: 2.47503
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.64629

Cumulative Model Updates: 63,176
Cumulative Timesteps: 526,869,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 526869598...
Checkpoint 526869598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,075.15751
Policy Entropy: 3.74932
Value Function Loss: 0.05332

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.55842
Value Function Update Magnitude: 0.79968

Collected Steps per Second: 22,505.67534
Overall Steps per Second: 10,634.23454

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.48142
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.70424

Cumulative Model Updates: 63,182
Cumulative Timesteps: 526,919,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,390.46115
Policy Entropy: 3.74739
Value Function Loss: 0.05281

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.78461

Collected Steps per Second: 22,749.82299
Overall Steps per Second: 10,829.96822

Timestep Collection Time: 2.19852
Timestep Consumption Time: 2.41977
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.61830

Cumulative Model Updates: 63,188
Cumulative Timesteps: 526,969,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 526969640...
Checkpoint 526969640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,284.39884
Policy Entropy: 3.74882
Value Function Loss: 0.05333

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.52954
Value Function Update Magnitude: 0.77948

Collected Steps per Second: 22,438.50611
Overall Steps per Second: 10,707.39069

Timestep Collection Time: 2.22876
Timestep Consumption Time: 2.44185
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.67061

Cumulative Model Updates: 63,194
Cumulative Timesteps: 527,019,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,018.18019
Policy Entropy: 3.74870
Value Function Loss: 0.05280

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.58474
Value Function Update Magnitude: 0.79254

Collected Steps per Second: 22,830.84075
Overall Steps per Second: 10,837.36452

Timestep Collection Time: 2.19072
Timestep Consumption Time: 2.42442
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61514

Cumulative Model Updates: 63,200
Cumulative Timesteps: 527,069,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 527069666...
Checkpoint 527069666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,959.51926
Policy Entropy: 3.74606
Value Function Loss: 0.05463

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.59977
Value Function Update Magnitude: 0.82916

Collected Steps per Second: 21,873.67961
Overall Steps per Second: 10,710.74053

Timestep Collection Time: 2.28649
Timestep Consumption Time: 2.38303
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.66952

Cumulative Model Updates: 63,206
Cumulative Timesteps: 527,119,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,269.21636
Policy Entropy: 3.74059
Value Function Loss: 0.05495

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.57751
Value Function Update Magnitude: 0.86359

Collected Steps per Second: 21,987.50854
Overall Steps per Second: 10,817.57665

Timestep Collection Time: 2.27575
Timestep Consumption Time: 2.34987
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.62562

Cumulative Model Updates: 63,212
Cumulative Timesteps: 527,169,718

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 527169718...
Checkpoint 527169718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,701.49332
Policy Entropy: 3.73865
Value Function Loss: 0.05533

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.56853
Value Function Update Magnitude: 0.86170

Collected Steps per Second: 21,689.42508
Overall Steps per Second: 10,757.45670

Timestep Collection Time: 2.30546
Timestep Consumption Time: 2.34286
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.64831

Cumulative Model Updates: 63,218
Cumulative Timesteps: 527,219,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,796.43617
Policy Entropy: 3.73346
Value Function Loss: 0.05576

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.57502
Value Function Update Magnitude: 0.87748

Collected Steps per Second: 21,882.00751
Overall Steps per Second: 10,783.79405

Timestep Collection Time: 2.28590
Timestep Consumption Time: 2.35255
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.63844

Cumulative Model Updates: 63,224
Cumulative Timesteps: 527,269,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 527269742...
Checkpoint 527269742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,014.89236
Policy Entropy: 3.73433
Value Function Loss: 0.05492

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06944
Policy Update Magnitude: 0.60009
Value Function Update Magnitude: 0.86482

Collected Steps per Second: 22,043.68462
Overall Steps per Second: 10,730.45875

Timestep Collection Time: 2.26840
Timestep Consumption Time: 2.39160
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.66001

Cumulative Model Updates: 63,230
Cumulative Timesteps: 527,319,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,298.66195
Policy Entropy: 3.73155
Value Function Loss: 0.05640

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.63081
Value Function Update Magnitude: 0.84258

Collected Steps per Second: 22,144.61349
Overall Steps per Second: 10,592.72536

Timestep Collection Time: 2.25834
Timestep Consumption Time: 2.46283
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.72116

Cumulative Model Updates: 63,236
Cumulative Timesteps: 527,369,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 527369756...
Checkpoint 527369756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,429.44123
Policy Entropy: 3.73168
Value Function Loss: 0.05713

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.16337
Policy Update Magnitude: 0.50654
Value Function Update Magnitude: 0.82844

Collected Steps per Second: 22,894.28898
Overall Steps per Second: 10,909.67415

Timestep Collection Time: 2.18430
Timestep Consumption Time: 2.39952
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.58382

Cumulative Model Updates: 63,242
Cumulative Timesteps: 527,419,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,259.25719
Policy Entropy: 3.72553
Value Function Loss: 0.05963

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11468
Policy Update Magnitude: 0.46789
Value Function Update Magnitude: 0.80346

Collected Steps per Second: 22,714.71869
Overall Steps per Second: 10,861.97213

Timestep Collection Time: 2.20139
Timestep Consumption Time: 2.40219
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.60358

Cumulative Model Updates: 63,248
Cumulative Timesteps: 527,469,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 527469768...
Checkpoint 527469768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,449.87702
Policy Entropy: 3.71159
Value Function Loss: 0.06245

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.52521
Value Function Update Magnitude: 0.67488

Collected Steps per Second: 22,789.18072
Overall Steps per Second: 10,709.54629

Timestep Collection Time: 2.19534
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.67153

Cumulative Model Updates: 63,254
Cumulative Timesteps: 527,519,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,033.87855
Policy Entropy: 3.70351
Value Function Loss: 0.06424

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.52376
Value Function Update Magnitude: 0.62906

Collected Steps per Second: 22,835.20286
Overall Steps per Second: 10,842.46880

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.42277
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61316

Cumulative Model Updates: 63,260
Cumulative Timesteps: 527,569,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 527569816...
Checkpoint 527569816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,822.29426
Policy Entropy: 3.71903
Value Function Loss: 0.06219

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.15920
Policy Update Magnitude: 0.45690
Value Function Update Magnitude: 0.64061

Collected Steps per Second: 22,488.63763
Overall Steps per Second: 10,766.19454

Timestep Collection Time: 2.22361
Timestep Consumption Time: 2.42111
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.64472

Cumulative Model Updates: 63,266
Cumulative Timesteps: 527,619,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,286.16660
Policy Entropy: 3.73654
Value Function Loss: 0.05960

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.43288
Value Function Update Magnitude: 0.62393

Collected Steps per Second: 22,764.04586
Overall Steps per Second: 10,794.75749

Timestep Collection Time: 2.19689
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.63280

Cumulative Model Updates: 63,272
Cumulative Timesteps: 527,669,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 527669832...
Checkpoint 527669832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,529.27389
Policy Entropy: 3.73029
Value Function Loss: 0.05725

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.44095
Value Function Update Magnitude: 0.60322

Collected Steps per Second: 22,509.26450
Overall Steps per Second: 10,695.48840

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.45415
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.67599

Cumulative Model Updates: 63,278
Cumulative Timesteps: 527,719,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,727.07845
Policy Entropy: 3.74128
Value Function Loss: 0.05219

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.46337
Value Function Update Magnitude: 0.71314

Collected Steps per Second: 22,671.05498
Overall Steps per Second: 10,661.73601

Timestep Collection Time: 2.20607
Timestep Consumption Time: 2.48491
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.69098

Cumulative Model Updates: 63,284
Cumulative Timesteps: 527,769,858

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 527769858...
Checkpoint 527769858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,473.63813
Policy Entropy: 3.72804
Value Function Loss: 0.05087

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.47102
Value Function Update Magnitude: 0.80854

Collected Steps per Second: 22,734.13149
Overall Steps per Second: 10,820.20334

Timestep Collection Time: 2.20057
Timestep Consumption Time: 2.42301
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.62357

Cumulative Model Updates: 63,290
Cumulative Timesteps: 527,819,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,828.01482
Policy Entropy: 3.74305
Value Function Loss: 0.04899

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.45938
Value Function Update Magnitude: 0.82736

Collected Steps per Second: 22,759.05092
Overall Steps per Second: 10,674.15940

Timestep Collection Time: 2.19833
Timestep Consumption Time: 2.48887
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.68721

Cumulative Model Updates: 63,296
Cumulative Timesteps: 527,869,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 527869918...
Checkpoint 527869918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,060.75071
Policy Entropy: 3.73490
Value Function Loss: 0.04902

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.48568
Value Function Update Magnitude: 0.82008

Collected Steps per Second: 22,801.08307
Overall Steps per Second: 10,839.69549

Timestep Collection Time: 2.19411
Timestep Consumption Time: 2.42115
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.61526

Cumulative Model Updates: 63,302
Cumulative Timesteps: 527,919,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,478.57277
Policy Entropy: 3.73769
Value Function Loss: 0.04808

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.47587
Value Function Update Magnitude: 0.80298

Collected Steps per Second: 22,670.67084
Overall Steps per Second: 10,611.29355

Timestep Collection Time: 2.20620
Timestep Consumption Time: 2.50727
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.71347

Cumulative Model Updates: 63,308
Cumulative Timesteps: 527,969,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 527969962...
Checkpoint 527969962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,780.77955
Policy Entropy: 3.73853
Value Function Loss: 0.04814

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.52854
Value Function Update Magnitude: 0.78256

Collected Steps per Second: 22,792.38424
Overall Steps per Second: 10,676.83915

Timestep Collection Time: 2.19442
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.68453

Cumulative Model Updates: 63,314
Cumulative Timesteps: 528,019,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,217.02685
Policy Entropy: 3.74938
Value Function Loss: 0.05023

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.60596
Value Function Update Magnitude: 0.77100

Collected Steps per Second: 23,179.84981
Overall Steps per Second: 10,800.16290

Timestep Collection Time: 2.15705
Timestep Consumption Time: 2.47251
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.62956

Cumulative Model Updates: 63,320
Cumulative Timesteps: 528,069,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 528069978...
Checkpoint 528069978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,520.66016
Policy Entropy: 3.74089
Value Function Loss: 0.05084

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06245
Policy Update Magnitude: 0.66909
Value Function Update Magnitude: 0.77650

Collected Steps per Second: 22,580.40126
Overall Steps per Second: 10,622.17550

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.49402
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.70939

Cumulative Model Updates: 63,326
Cumulative Timesteps: 528,120,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,545.73362
Policy Entropy: 3.73695
Value Function Loss: 0.04917

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07290
Policy Update Magnitude: 0.66533
Value Function Update Magnitude: 0.77922

Collected Steps per Second: 22,629.70204
Overall Steps per Second: 10,665.89829

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.47915
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.68934

Cumulative Model Updates: 63,332
Cumulative Timesteps: 528,170,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 528170018...
Checkpoint 528170018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,311.20575
Policy Entropy: 3.73157
Value Function Loss: 0.04844

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.59771
Value Function Update Magnitude: 0.78484

Collected Steps per Second: 22,961.98392
Overall Steps per Second: 10,960.07784

Timestep Collection Time: 2.17838
Timestep Consumption Time: 2.38545
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.56384

Cumulative Model Updates: 63,338
Cumulative Timesteps: 528,220,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,851.52709
Policy Entropy: 3.73278
Value Function Loss: 0.04745

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.51926
Value Function Update Magnitude: 0.77949

Collected Steps per Second: 22,954.70208
Overall Steps per Second: 10,841.06152

Timestep Collection Time: 2.17864
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.61302

Cumulative Model Updates: 63,344
Cumulative Timesteps: 528,270,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 528270048...
Checkpoint 528270048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,972.24411
Policy Entropy: 3.73839
Value Function Loss: 0.05022

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.52567
Value Function Update Magnitude: 0.78703

Collected Steps per Second: 22,762.66383
Overall Steps per Second: 10,658.80151

Timestep Collection Time: 2.19746
Timestep Consumption Time: 2.49538
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.69284

Cumulative Model Updates: 63,350
Cumulative Timesteps: 528,320,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,263.83736
Policy Entropy: 3.73907
Value Function Loss: 0.05170

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.46556
Value Function Update Magnitude: 0.82061

Collected Steps per Second: 22,880.17193
Overall Steps per Second: 10,823.28523

Timestep Collection Time: 2.18556
Timestep Consumption Time: 2.43466
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.62022

Cumulative Model Updates: 63,356
Cumulative Timesteps: 528,370,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 528370074...
Checkpoint 528370074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,102.49431
Policy Entropy: 3.73708
Value Function Loss: 0.05425

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.49697
Value Function Update Magnitude: 0.82857

Collected Steps per Second: 22,490.63348
Overall Steps per Second: 10,775.22680

Timestep Collection Time: 2.22350
Timestep Consumption Time: 2.41751
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.64102

Cumulative Model Updates: 63,362
Cumulative Timesteps: 528,420,082

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,877.99922
Policy Entropy: 3.72389
Value Function Loss: 0.05525

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.52169
Value Function Update Magnitude: 0.78866

Collected Steps per Second: 22,773.13646
Overall Steps per Second: 10,791.82391

Timestep Collection Time: 2.19583
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.63369

Cumulative Model Updates: 63,368
Cumulative Timesteps: 528,470,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 528470088...
Checkpoint 528470088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,207.47796
Policy Entropy: 3.72659
Value Function Loss: 0.05534

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.52491
Value Function Update Magnitude: 0.79454

Collected Steps per Second: 22,628.19599
Overall Steps per Second: 10,703.58221

Timestep Collection Time: 2.21096
Timestep Consumption Time: 2.46318
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.67414

Cumulative Model Updates: 63,374
Cumulative Timesteps: 528,520,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,514.16885
Policy Entropy: 3.73804
Value Function Loss: 0.05700

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.81477

Collected Steps per Second: 23,047.15429
Overall Steps per Second: 10,880.17416

Timestep Collection Time: 2.17042
Timestep Consumption Time: 2.42712
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.59754

Cumulative Model Updates: 63,380
Cumulative Timesteps: 528,570,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 528570140...
Checkpoint 528570140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,181.53067
Policy Entropy: 3.74826
Value Function Loss: 0.05595

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.58271
Value Function Update Magnitude: 0.79206

Collected Steps per Second: 22,559.56395
Overall Steps per Second: 10,676.84281

Timestep Collection Time: 2.21751
Timestep Consumption Time: 2.46796
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.68547

Cumulative Model Updates: 63,386
Cumulative Timesteps: 528,620,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,695.39124
Policy Entropy: 3.73876
Value Function Loss: 0.05489

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.56764
Value Function Update Magnitude: 0.77059

Collected Steps per Second: 22,955.87732
Overall Steps per Second: 10,837.29157

Timestep Collection Time: 2.17940
Timestep Consumption Time: 2.43707
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.61647

Cumulative Model Updates: 63,392
Cumulative Timesteps: 528,670,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 528670196...
Checkpoint 528670196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,452.49832
Policy Entropy: 3.74056
Value Function Loss: 0.05535

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.53980
Value Function Update Magnitude: 0.74853

Collected Steps per Second: 22,432.73376
Overall Steps per Second: 10,706.30897

Timestep Collection Time: 2.22933
Timestep Consumption Time: 2.44175
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.67108

Cumulative Model Updates: 63,398
Cumulative Timesteps: 528,720,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,477.22224
Policy Entropy: 3.73743
Value Function Loss: 0.05627

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09266
Policy Update Magnitude: 0.56105
Value Function Update Magnitude: 0.78132

Collected Steps per Second: 22,668.81888
Overall Steps per Second: 10,657.65403

Timestep Collection Time: 2.20691
Timestep Consumption Time: 2.48718
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.69409

Cumulative Model Updates: 63,404
Cumulative Timesteps: 528,770,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 528770234...
Checkpoint 528770234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,573.41912
Policy Entropy: 3.75381
Value Function Loss: 0.05673

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.82848

Collected Steps per Second: 22,623.23371
Overall Steps per Second: 10,830.53228

Timestep Collection Time: 2.21029
Timestep Consumption Time: 2.40665
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.61695

Cumulative Model Updates: 63,410
Cumulative Timesteps: 528,820,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,097.95336
Policy Entropy: 3.75348
Value Function Loss: 0.05507

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.49221
Value Function Update Magnitude: 0.85185

Collected Steps per Second: 22,798.62543
Overall Steps per Second: 10,728.28795

Timestep Collection Time: 2.19320
Timestep Consumption Time: 2.46756
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.66076

Cumulative Model Updates: 63,416
Cumulative Timesteps: 528,870,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 528870240...
Checkpoint 528870240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,130.40246
Policy Entropy: 3.77362
Value Function Loss: 0.05550

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.50436
Value Function Update Magnitude: 0.86585

Collected Steps per Second: 22,580.23081
Overall Steps per Second: 10,787.47349

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.42300
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.63946

Cumulative Model Updates: 63,422
Cumulative Timesteps: 528,920,288

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,038.90440
Policy Entropy: 3.76530
Value Function Loss: 0.05693

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.51685
Value Function Update Magnitude: 0.84847

Collected Steps per Second: 22,795.33828
Overall Steps per Second: 10,698.97595

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.67521

Cumulative Model Updates: 63,428
Cumulative Timesteps: 528,970,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 528970308...
Checkpoint 528970308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,931.42056
Policy Entropy: 3.75455
Value Function Loss: 0.05881

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.54278
Value Function Update Magnitude: 0.84058

Collected Steps per Second: 22,929.24340
Overall Steps per Second: 10,886.25511

Timestep Collection Time: 2.18080
Timestep Consumption Time: 2.41252
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.59332

Cumulative Model Updates: 63,434
Cumulative Timesteps: 529,020,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.16651
Policy Entropy: 3.73744
Value Function Loss: 0.05970

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.52449
Value Function Update Magnitude: 0.81268

Collected Steps per Second: 22,089.31505
Overall Steps per Second: 10,713.95369

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.40462
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.66942

Cumulative Model Updates: 63,440
Cumulative Timesteps: 529,070,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 529070340...
Checkpoint 529070340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,997.20260
Policy Entropy: 3.71964
Value Function Loss: 0.05864

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.82287

Collected Steps per Second: 22,221.44025
Overall Steps per Second: 10,843.64814

Timestep Collection Time: 2.25071
Timestep Consumption Time: 2.36158
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.61229

Cumulative Model Updates: 63,446
Cumulative Timesteps: 529,120,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,867.48874
Policy Entropy: 3.71306
Value Function Loss: 0.05868

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.55031
Value Function Update Magnitude: 0.85082

Collected Steps per Second: 21,067.47843
Overall Steps per Second: 10,536.74588

Timestep Collection Time: 2.37428
Timestep Consumption Time: 2.37292
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.74720

Cumulative Model Updates: 63,452
Cumulative Timesteps: 529,170,374

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 529170374...
Checkpoint 529170374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,524.86118
Policy Entropy: 3.71426
Value Function Loss: 0.06090

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.58672
Value Function Update Magnitude: 0.87579

Collected Steps per Second: 20,968.26896
Overall Steps per Second: 10,520.55176

Timestep Collection Time: 2.38589
Timestep Consumption Time: 2.36937
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.75526

Cumulative Model Updates: 63,458
Cumulative Timesteps: 529,220,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,872.52895
Policy Entropy: 3.71982
Value Function Loss: 0.06211

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.60689
Value Function Update Magnitude: 0.91143

Collected Steps per Second: 22,145.64206
Overall Steps per Second: 10,716.11408

Timestep Collection Time: 2.25895
Timestep Consumption Time: 2.40934
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.66830

Cumulative Model Updates: 63,464
Cumulative Timesteps: 529,270,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 529270428...
Checkpoint 529270428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,768.32361
Policy Entropy: 3.71315
Value Function Loss: 0.06235

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.54013
Value Function Update Magnitude: 0.93085

Collected Steps per Second: 22,364.45129
Overall Steps per Second: 10,659.98293

Timestep Collection Time: 2.23605
Timestep Consumption Time: 2.45514
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.69119

Cumulative Model Updates: 63,470
Cumulative Timesteps: 529,320,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,364.03100
Policy Entropy: 3.69958
Value Function Loss: 0.06053

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.90818

Collected Steps per Second: 22,800.01094
Overall Steps per Second: 10,684.79288

Timestep Collection Time: 2.19342
Timestep Consumption Time: 2.48706
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.68048

Cumulative Model Updates: 63,476
Cumulative Timesteps: 529,370,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 529370446...
Checkpoint 529370446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,438.90683
Policy Entropy: 3.69410
Value Function Loss: 0.05894

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.61513
Value Function Update Magnitude: 0.87699

Collected Steps per Second: 22,481.96062
Overall Steps per Second: 10,642.24612

Timestep Collection Time: 2.22427
Timestep Consumption Time: 2.47455
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.69882

Cumulative Model Updates: 63,482
Cumulative Timesteps: 529,420,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,469.49163
Policy Entropy: 3.69059
Value Function Loss: 0.06017

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.67386
Value Function Update Magnitude: 0.90404

Collected Steps per Second: 23,068.65283
Overall Steps per Second: 10,971.76342

Timestep Collection Time: 2.16857
Timestep Consumption Time: 2.39095
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.55952

Cumulative Model Updates: 63,488
Cumulative Timesteps: 529,470,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 529470478...
Checkpoint 529470478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,281.16417
Policy Entropy: 3.70238
Value Function Loss: 0.06126

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.61833
Value Function Update Magnitude: 0.84637

Collected Steps per Second: 22,555.29994
Overall Steps per Second: 10,668.04869

Timestep Collection Time: 2.21766
Timestep Consumption Time: 2.47111
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.68877

Cumulative Model Updates: 63,494
Cumulative Timesteps: 529,520,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,207.28524
Policy Entropy: 3.70028
Value Function Loss: 0.06563

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.54473
Value Function Update Magnitude: 0.71414

Collected Steps per Second: 22,664.22479
Overall Steps per Second: 10,888.69452

Timestep Collection Time: 2.20727
Timestep Consumption Time: 2.38704
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.59431

Cumulative Model Updates: 63,500
Cumulative Timesteps: 529,570,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 529570524...
Checkpoint 529570524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,334.53662
Policy Entropy: 3.70119
Value Function Loss: 0.06815

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.59216
Value Function Update Magnitude: 0.65985

Collected Steps per Second: 22,644.40586
Overall Steps per Second: 10,647.10386

Timestep Collection Time: 2.20858
Timestep Consumption Time: 2.48866
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69724

Cumulative Model Updates: 63,506
Cumulative Timesteps: 529,620,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,113.25603
Policy Entropy: 3.69925
Value Function Loss: 0.06703

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.67382

Collected Steps per Second: 22,941.74348
Overall Steps per Second: 10,812.95100

Timestep Collection Time: 2.17987
Timestep Consumption Time: 2.44514
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62501

Cumulative Model Updates: 63,512
Cumulative Timesteps: 529,670,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 529670546...
Checkpoint 529670546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,264.65934
Policy Entropy: 3.70171
Value Function Loss: 0.06647

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.53604
Value Function Update Magnitude: 0.69885

Collected Steps per Second: 22,656.78660
Overall Steps per Second: 10,650.24524

Timestep Collection Time: 2.20746
Timestep Consumption Time: 2.48858
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.69604

Cumulative Model Updates: 63,518
Cumulative Timesteps: 529,720,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,792.64846
Policy Entropy: 3.71110
Value Function Loss: 0.06327

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.50160
Value Function Update Magnitude: 0.77849

Collected Steps per Second: 22,969.09169
Overall Steps per Second: 10,865.99575

Timestep Collection Time: 2.17771
Timestep Consumption Time: 2.42564
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60335

Cumulative Model Updates: 63,524
Cumulative Timesteps: 529,770,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 529770580...
Checkpoint 529770580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911.72417
Policy Entropy: 3.71639
Value Function Loss: 0.06285

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.51378
Value Function Update Magnitude: 0.71406

Collected Steps per Second: 22,796.91295
Overall Steps per Second: 10,691.53986

Timestep Collection Time: 2.19407
Timestep Consumption Time: 2.48421
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.67828

Cumulative Model Updates: 63,530
Cumulative Timesteps: 529,820,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,867.89708
Policy Entropy: 3.72363
Value Function Loss: 0.06295

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.48798
Value Function Update Magnitude: 0.66020

Collected Steps per Second: 23,305.24868
Overall Steps per Second: 10,938.02172

Timestep Collection Time: 2.14664
Timestep Consumption Time: 2.42713
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57377

Cumulative Model Updates: 63,536
Cumulative Timesteps: 529,870,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 529870626...
Checkpoint 529870626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,978.88786
Policy Entropy: 3.71145
Value Function Loss: 0.06302

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.48624
Value Function Update Magnitude: 0.64687

Collected Steps per Second: 22,566.72258
Overall Steps per Second: 10,574.50057

Timestep Collection Time: 2.21592
Timestep Consumption Time: 2.51301
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.72892

Cumulative Model Updates: 63,542
Cumulative Timesteps: 529,920,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,723.64333
Policy Entropy: 3.70175
Value Function Loss: 0.06391

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.50349
Value Function Update Magnitude: 0.65950

Collected Steps per Second: 22,785.71800
Overall Steps per Second: 10,869.93367

Timestep Collection Time: 2.19541
Timestep Consumption Time: 2.40664
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.60205

Cumulative Model Updates: 63,548
Cumulative Timesteps: 529,970,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 529970656...
Checkpoint 529970656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,590.38785
Policy Entropy: 3.69037
Value Function Loss: 0.06550

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.47783
Value Function Update Magnitude: 0.67831

Collected Steps per Second: 22,820.24445
Overall Steps per Second: 10,724.30706

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.47246
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.66454

Cumulative Model Updates: 63,554
Cumulative Timesteps: 530,020,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,498.10332
Policy Entropy: 3.69770
Value Function Loss: 0.06504

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.47731
Value Function Update Magnitude: 0.64837

Collected Steps per Second: 22,903.63117
Overall Steps per Second: 10,917.30981

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.39788
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.58190

Cumulative Model Updates: 63,560
Cumulative Timesteps: 530,070,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 530070702...
Checkpoint 530070702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,280.82382
Policy Entropy: 3.69191
Value Function Loss: 0.06674

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07097
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.61497

Collected Steps per Second: 22,620.32380
Overall Steps per Second: 10,604.69627

Timestep Collection Time: 2.21093
Timestep Consumption Time: 2.50509
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.71602

Cumulative Model Updates: 63,566
Cumulative Timesteps: 530,120,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,801.18067
Policy Entropy: 3.70256
Value Function Loss: 0.06300

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.63964
Value Function Update Magnitude: 0.65701

Collected Steps per Second: 23,059.13706
Overall Steps per Second: 10,945.81744

Timestep Collection Time: 2.16947
Timestep Consumption Time: 2.40086
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.57033

Cumulative Model Updates: 63,572
Cumulative Timesteps: 530,170,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 530170740...
Checkpoint 530170740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,163.80141
Policy Entropy: 3.70657
Value Function Loss: 0.06177

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.59077
Value Function Update Magnitude: 0.69390

Collected Steps per Second: 22,659.44680
Overall Steps per Second: 10,627.54098

Timestep Collection Time: 2.20756
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.70683

Cumulative Model Updates: 63,578
Cumulative Timesteps: 530,220,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,648.83405
Policy Entropy: 3.70637
Value Function Loss: 0.06210

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.59078
Value Function Update Magnitude: 0.66789

Collected Steps per Second: 22,850.26488
Overall Steps per Second: 10,888.43721

Timestep Collection Time: 2.18868
Timestep Consumption Time: 2.40445
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.59313

Cumulative Model Updates: 63,584
Cumulative Timesteps: 530,270,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 530270774...
Checkpoint 530270774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,272.04906
Policy Entropy: 3.70037
Value Function Loss: 0.06541

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.58337
Value Function Update Magnitude: 0.66669

Collected Steps per Second: 22,448.52084
Overall Steps per Second: 10,650.11077

Timestep Collection Time: 2.22785
Timestep Consumption Time: 2.46806
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.69591

Cumulative Model Updates: 63,590
Cumulative Timesteps: 530,320,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,560.78756
Policy Entropy: 3.69054
Value Function Loss: 0.06704

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.59560
Value Function Update Magnitude: 0.68284

Collected Steps per Second: 22,787.18352
Overall Steps per Second: 10,826.60916

Timestep Collection Time: 2.19501
Timestep Consumption Time: 2.42491
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61991

Cumulative Model Updates: 63,596
Cumulative Timesteps: 530,370,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 530370804...
Checkpoint 530370804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,945.05445
Policy Entropy: 3.68346
Value Function Loss: 0.06505

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.53950
Value Function Update Magnitude: 0.66230

Collected Steps per Second: 22,635.03457
Overall Steps per Second: 10,703.34998

Timestep Collection Time: 2.21011
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.67386

Cumulative Model Updates: 63,602
Cumulative Timesteps: 530,420,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,840.40901
Policy Entropy: 3.69351
Value Function Loss: 0.06399

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.52285
Value Function Update Magnitude: 0.64343

Collected Steps per Second: 22,858.70908
Overall Steps per Second: 10,670.53150

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.68636

Cumulative Model Updates: 63,608
Cumulative Timesteps: 530,470,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 530470836...
Checkpoint 530470836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,931.71687
Policy Entropy: 3.69078
Value Function Loss: 0.06272

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.69322

Collected Steps per Second: 22,755.32512
Overall Steps per Second: 10,802.22514

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.63034

Cumulative Model Updates: 63,614
Cumulative Timesteps: 530,520,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,418.52927
Policy Entropy: 3.68304
Value Function Loss: 0.06080

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.64554
Value Function Update Magnitude: 0.76132

Collected Steps per Second: 22,715.46520
Overall Steps per Second: 10,626.84667

Timestep Collection Time: 2.20141
Timestep Consumption Time: 2.50422
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.70563

Cumulative Model Updates: 63,620
Cumulative Timesteps: 530,570,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 530570860...
Checkpoint 530570860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,169.85109
Policy Entropy: 3.68878
Value Function Loss: 0.05993

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.60450
Value Function Update Magnitude: 0.79618

Collected Steps per Second: 22,684.75000
Overall Steps per Second: 10,623.35529

Timestep Collection Time: 2.20492
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.70831

Cumulative Model Updates: 63,626
Cumulative Timesteps: 530,620,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,870.30668
Policy Entropy: 3.69993
Value Function Loss: 0.05999

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.52479
Value Function Update Magnitude: 0.74346

Collected Steps per Second: 22,724.89283
Overall Steps per Second: 10,772.43567

Timestep Collection Time: 2.20120
Timestep Consumption Time: 2.44232
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.64352

Cumulative Model Updates: 63,632
Cumulative Timesteps: 530,670,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 530670900...
Checkpoint 530670900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,440.93162
Policy Entropy: 3.70836
Value Function Loss: 0.06092

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.50827
Value Function Update Magnitude: 0.65709

Collected Steps per Second: 22,535.90702
Overall Steps per Second: 10,717.65619

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.44652
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.66520

Cumulative Model Updates: 63,638
Cumulative Timesteps: 530,720,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.09093
Policy Entropy: 3.71007
Value Function Loss: 0.06389

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.61538

Collected Steps per Second: 23,014.90784
Overall Steps per Second: 10,950.61193

Timestep Collection Time: 2.17346
Timestep Consumption Time: 2.39450
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.56796

Cumulative Model Updates: 63,644
Cumulative Timesteps: 530,770,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 530770922...
Checkpoint 530770922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,524.32222
Policy Entropy: 3.69465
Value Function Loss: 0.06291

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.52024
Value Function Update Magnitude: 0.56663

Collected Steps per Second: 22,652.80369
Overall Steps per Second: 10,638.06836

Timestep Collection Time: 2.20723
Timestep Consumption Time: 2.49287
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.70010

Cumulative Model Updates: 63,650
Cumulative Timesteps: 530,820,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,122.60709
Policy Entropy: 3.69463
Value Function Loss: 0.06186

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.46561
Value Function Update Magnitude: 0.56395

Collected Steps per Second: 22,938.88108
Overall Steps per Second: 10,808.48515

Timestep Collection Time: 2.18023
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62711

Cumulative Model Updates: 63,656
Cumulative Timesteps: 530,870,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 530870934...
Checkpoint 530870934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,034.59868
Policy Entropy: 3.68835
Value Function Loss: 0.05723

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.47578
Value Function Update Magnitude: 0.63500

Collected Steps per Second: 22,632.81134
Overall Steps per Second: 10,684.36741

Timestep Collection Time: 2.21033
Timestep Consumption Time: 2.47184
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.68217

Cumulative Model Updates: 63,662
Cumulative Timesteps: 530,920,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,757.61225
Policy Entropy: 3.68763
Value Function Loss: 0.05704

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.50700
Value Function Update Magnitude: 0.64375

Collected Steps per Second: 22,683.22702
Overall Steps per Second: 10,810.65612

Timestep Collection Time: 2.20489
Timestep Consumption Time: 2.42147
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.62636

Cumulative Model Updates: 63,668
Cumulative Timesteps: 530,970,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 530970974...
Checkpoint 530970974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,985.61780
Policy Entropy: 3.69216
Value Function Loss: 0.05791

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.53353
Value Function Update Magnitude: 0.59568

Collected Steps per Second: 22,613.71771
Overall Steps per Second: 10,762.78929

Timestep Collection Time: 2.21184
Timestep Consumption Time: 2.43547
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.64731

Cumulative Model Updates: 63,674
Cumulative Timesteps: 531,020,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,067.94802
Policy Entropy: 3.70816
Value Function Loss: 0.05973

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.52651
Value Function Update Magnitude: 0.57827

Collected Steps per Second: 22,952.21434
Overall Steps per Second: 10,852.66749

Timestep Collection Time: 2.17879
Timestep Consumption Time: 2.42911
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.60790

Cumulative Model Updates: 63,680
Cumulative Timesteps: 531,071,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 531071000...
Checkpoint 531071000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,176.65644
Policy Entropy: 3.71869
Value Function Loss: 0.05838

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.54196
Value Function Update Magnitude: 0.60722

Collected Steps per Second: 22,677.70118
Overall Steps per Second: 10,644.97400

Timestep Collection Time: 2.20499
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.69743

Cumulative Model Updates: 63,686
Cumulative Timesteps: 531,121,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,138.77270
Policy Entropy: 3.71324
Value Function Loss: 0.05547

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06651
Policy Update Magnitude: 0.63538
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 22,639.13689
Overall Steps per Second: 10,660.57952

Timestep Collection Time: 2.21051
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.69430

Cumulative Model Updates: 63,692
Cumulative Timesteps: 531,171,048

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 531171048...
Checkpoint 531171048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,200.68061
Policy Entropy: 3.71094
Value Function Loss: 0.05494

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07078
Policy Update Magnitude: 0.63349
Value Function Update Magnitude: 0.63753

Collected Steps per Second: 22,536.11678
Overall Steps per Second: 10,650.23667

Timestep Collection Time: 2.21990
Timestep Consumption Time: 2.47746
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.69736

Cumulative Model Updates: 63,698
Cumulative Timesteps: 531,221,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,887.01391
Policy Entropy: 3.70224
Value Function Loss: 0.05613

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07711
Policy Update Magnitude: 0.65143
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 23,107.30796
Overall Steps per Second: 10,715.85079

Timestep Collection Time: 2.16494
Timestep Consumption Time: 2.50347
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.66841

Cumulative Model Updates: 63,704
Cumulative Timesteps: 531,271,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 531271102...
Checkpoint 531271102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,722.84146
Policy Entropy: 3.70196
Value Function Loss: 0.05867

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.62706
Value Function Update Magnitude: 0.65890

Collected Steps per Second: 22,705.65850
Overall Steps per Second: 10,624.88635

Timestep Collection Time: 2.20236
Timestep Consumption Time: 2.50414
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.70650

Cumulative Model Updates: 63,710
Cumulative Timesteps: 531,321,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,689.50087
Policy Entropy: 3.70809
Value Function Loss: 0.05613

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.55224
Value Function Update Magnitude: 0.74787

Collected Steps per Second: 22,691.73104
Overall Steps per Second: 10,683.57031

Timestep Collection Time: 2.20362
Timestep Consumption Time: 2.47684
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.68046

Cumulative Model Updates: 63,716
Cumulative Timesteps: 531,371,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 531371112...
Checkpoint 531371112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,001.39331
Policy Entropy: 3.71480
Value Function Loss: 0.05476

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.54375
Value Function Update Magnitude: 0.79710

Collected Steps per Second: 22,435.06696
Overall Steps per Second: 10,685.12499

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.45134
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.68053

Cumulative Model Updates: 63,722
Cumulative Timesteps: 531,421,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,275.78716
Policy Entropy: 3.72245
Value Function Loss: 0.05330

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.58232
Value Function Update Magnitude: 0.78719

Collected Steps per Second: 22,708.24729
Overall Steps per Second: 10,621.44750

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.50601
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.70821

Cumulative Model Updates: 63,728
Cumulative Timesteps: 531,471,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 531471132...
Checkpoint 531471132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,907.35653
Policy Entropy: 3.73263
Value Function Loss: 0.05444

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.60667
Value Function Update Magnitude: 0.75121

Collected Steps per Second: 22,671.69610
Overall Steps per Second: 10,630.11013

Timestep Collection Time: 2.20592
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.70475

Cumulative Model Updates: 63,734
Cumulative Timesteps: 531,521,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,114.15249
Policy Entropy: 3.74016
Value Function Loss: 0.05348

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07301
Policy Update Magnitude: 0.62377
Value Function Update Magnitude: 0.67993

Collected Steps per Second: 21,867.44233
Overall Steps per Second: 10,654.07498

Timestep Collection Time: 2.28778
Timestep Consumption Time: 2.40788
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.69567

Cumulative Model Updates: 63,740
Cumulative Timesteps: 531,571,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 531571172...
Checkpoint 531571172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,272.34625
Policy Entropy: 3.74902
Value Function Loss: 0.05196

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.66610

Collected Steps per Second: 22,166.58854
Overall Steps per Second: 10,862.95729

Timestep Collection Time: 2.25583
Timestep Consumption Time: 2.34734
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.60317

Cumulative Model Updates: 63,746
Cumulative Timesteps: 531,621,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,929.25674
Policy Entropy: 3.74619
Value Function Loss: 0.05322

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.48435
Value Function Update Magnitude: 0.69776

Collected Steps per Second: 22,062.35714
Overall Steps per Second: 10,702.61621

Timestep Collection Time: 2.26730
Timestep Consumption Time: 2.40651
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.67381

Cumulative Model Updates: 63,752
Cumulative Timesteps: 531,671,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 531671198...
Checkpoint 531671198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,522.33518
Policy Entropy: 3.73029
Value Function Loss: 0.05468

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.49475
Value Function Update Magnitude: 0.78029

Collected Steps per Second: 21,990.02711
Overall Steps per Second: 10,825.98832

Timestep Collection Time: 2.27449
Timestep Consumption Time: 2.34551
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61999

Cumulative Model Updates: 63,758
Cumulative Timesteps: 531,721,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,134.98496
Policy Entropy: 3.73427
Value Function Loss: 0.05597

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.55471
Value Function Update Magnitude: 0.82317

Collected Steps per Second: 22,066.54276
Overall Steps per Second: 10,722.93758

Timestep Collection Time: 2.26678
Timestep Consumption Time: 2.39799
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.66477

Cumulative Model Updates: 63,764
Cumulative Timesteps: 531,771,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 531771234...
Checkpoint 531771234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,086.19423
Policy Entropy: 3.73091
Value Function Loss: 0.05675

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.53383
Value Function Update Magnitude: 0.86119

Collected Steps per Second: 21,818.13868
Overall Steps per Second: 10,792.64146

Timestep Collection Time: 2.29277
Timestep Consumption Time: 2.34224
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.63501

Cumulative Model Updates: 63,770
Cumulative Timesteps: 531,821,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,903.86160
Policy Entropy: 3.73205
Value Function Loss: 0.05811

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.53685
Value Function Update Magnitude: 0.89124

Collected Steps per Second: 22,462.93035
Overall Steps per Second: 10,907.48333

Timestep Collection Time: 2.22598
Timestep Consumption Time: 2.35821
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.58419

Cumulative Model Updates: 63,776
Cumulative Timesteps: 531,871,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 531871260...
Checkpoint 531871260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,637.09576
Policy Entropy: 3.72337
Value Function Loss: 0.05794

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.52693
Value Function Update Magnitude: 0.89285

Collected Steps per Second: 21,854.47854
Overall Steps per Second: 10,702.64178

Timestep Collection Time: 2.28987
Timestep Consumption Time: 2.38598
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.67585

Cumulative Model Updates: 63,782
Cumulative Timesteps: 531,921,304

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,728.03874
Policy Entropy: 3.73807
Value Function Loss: 0.05799

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.50665
Value Function Update Magnitude: 0.88127

Collected Steps per Second: 22,139.53502
Overall Steps per Second: 10,551.85546

Timestep Collection Time: 2.25904
Timestep Consumption Time: 2.48079
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.73983

Cumulative Model Updates: 63,788
Cumulative Timesteps: 531,971,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 531971318...
Checkpoint 531971318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,821.69844
Policy Entropy: 3.73036
Value Function Loss: 0.05950

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.47677
Value Function Update Magnitude: 0.87093

Collected Steps per Second: 22,795.69706
Overall Steps per Second: 10,726.73467

Timestep Collection Time: 2.19436
Timestep Consumption Time: 2.46894
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.66330

Cumulative Model Updates: 63,794
Cumulative Timesteps: 532,021,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,325.60197
Policy Entropy: 3.73694
Value Function Loss: 0.05994

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09551
Policy Update Magnitude: 0.46458
Value Function Update Magnitude: 0.88040

Collected Steps per Second: 22,679.17953
Overall Steps per Second: 10,737.50313

Timestep Collection Time: 2.20528
Timestep Consumption Time: 2.45260
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.65788

Cumulative Model Updates: 63,800
Cumulative Timesteps: 532,071,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 532071354...
Checkpoint 532071354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,928.40309
Policy Entropy: 3.73947
Value Function Loss: 0.06054

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.48360
Value Function Update Magnitude: 0.83475

Collected Steps per Second: 22,506.45335
Overall Steps per Second: 10,657.08102

Timestep Collection Time: 2.22167
Timestep Consumption Time: 2.47023
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.69190

Cumulative Model Updates: 63,806
Cumulative Timesteps: 532,121,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,690.10136
Policy Entropy: 3.73164
Value Function Loss: 0.05983

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.50772
Value Function Update Magnitude: 0.71834

Collected Steps per Second: 22,835.41224
Overall Steps per Second: 10,873.14956

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.40987
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.60032

Cumulative Model Updates: 63,812
Cumulative Timesteps: 532,171,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 532171376...
Checkpoint 532171376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,480.27180
Policy Entropy: 3.72407
Value Function Loss: 0.06029

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.48839
Value Function Update Magnitude: 0.68099

Collected Steps per Second: 22,729.00006
Overall Steps per Second: 10,689.76823

Timestep Collection Time: 2.20124
Timestep Consumption Time: 2.47912
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.68036

Cumulative Model Updates: 63,818
Cumulative Timesteps: 532,221,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,999.42011
Policy Entropy: 3.72463
Value Function Loss: 0.05861

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.49409
Value Function Update Magnitude: 0.76751

Collected Steps per Second: 22,908.69013
Overall Steps per Second: 10,828.16125

Timestep Collection Time: 2.18354
Timestep Consumption Time: 2.43608
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.61962

Cumulative Model Updates: 63,824
Cumulative Timesteps: 532,271,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 532271430...
Checkpoint 532271430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,703.76662
Policy Entropy: 3.71983
Value Function Loss: 0.05745

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.48235
Value Function Update Magnitude: 0.82589

Collected Steps per Second: 22,557.84168
Overall Steps per Second: 10,671.08963

Timestep Collection Time: 2.21723
Timestep Consumption Time: 2.46982
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.68706

Cumulative Model Updates: 63,830
Cumulative Timesteps: 532,321,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,392.20184
Policy Entropy: 3.73706
Value Function Loss: 0.05584

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.47458
Value Function Update Magnitude: 0.85459

Collected Steps per Second: 22,591.84797
Overall Steps per Second: 10,645.42173

Timestep Collection Time: 2.21416
Timestep Consumption Time: 2.48476
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.69892

Cumulative Model Updates: 63,836
Cumulative Timesteps: 532,371,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 532371468...
Checkpoint 532371468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,063.13659
Policy Entropy: 3.73238
Value Function Loss: 0.05689

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.49330
Value Function Update Magnitude: 0.76410

Collected Steps per Second: 22,671.09674
Overall Steps per Second: 10,696.64619

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.46940
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.67530

Cumulative Model Updates: 63,842
Cumulative Timesteps: 532,421,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,435.39385
Policy Entropy: 3.73195
Value Function Loss: 0.06139

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.52003
Value Function Update Magnitude: 0.67943

Collected Steps per Second: 23,206.01194
Overall Steps per Second: 10,762.53010

Timestep Collection Time: 2.15504
Timestep Consumption Time: 2.49163
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.64668

Cumulative Model Updates: 63,848
Cumulative Timesteps: 532,471,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 532471488...
Checkpoint 532471488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.90969
Policy Entropy: 3.72115
Value Function Loss: 0.06171

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06687
Policy Update Magnitude: 0.62133
Value Function Update Magnitude: 0.75050

Collected Steps per Second: 22,871.43724
Overall Steps per Second: 10,910.36642

Timestep Collection Time: 2.18683
Timestep Consumption Time: 2.39743
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.58426

Cumulative Model Updates: 63,854
Cumulative Timesteps: 532,521,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,014.57094
Policy Entropy: 3.71895
Value Function Loss: 0.06280

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.72128
Value Function Update Magnitude: 0.84815

Collected Steps per Second: 22,391.77714
Overall Steps per Second: 10,544.54482

Timestep Collection Time: 2.23412
Timestep Consumption Time: 2.51013
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.74425

Cumulative Model Updates: 63,860
Cumulative Timesteps: 532,571,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 532571530...
Checkpoint 532571530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,946.36981
Policy Entropy: 3.71330
Value Function Loss: 0.05939

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.73266
Value Function Update Magnitude: 0.88305

Collected Steps per Second: 22,597.22490
Overall Steps per Second: 10,650.63303

Timestep Collection Time: 2.21434
Timestep Consumption Time: 2.48378
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.69812

Cumulative Model Updates: 63,866
Cumulative Timesteps: 532,621,568

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,369.21389
Policy Entropy: 3.71613
Value Function Loss: 0.06082

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07084
Policy Update Magnitude: 0.71151
Value Function Update Magnitude: 0.89814

Collected Steps per Second: 22,737.99225
Overall Steps per Second: 10,809.45805

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.42788
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.62798

Cumulative Model Updates: 63,872
Cumulative Timesteps: 532,671,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 532671594...
Checkpoint 532671594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,075.78622
Policy Entropy: 3.71779
Value Function Loss: 0.05876

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.65651
Value Function Update Magnitude: 0.90734

Collected Steps per Second: 22,708.27720
Overall Steps per Second: 10,743.44544

Timestep Collection Time: 2.20219
Timestep Consumption Time: 2.45255
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.65475

Cumulative Model Updates: 63,878
Cumulative Timesteps: 532,721,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,441.51047
Policy Entropy: 3.71792
Value Function Loss: 0.06091

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.62611
Value Function Update Magnitude: 0.89587

Collected Steps per Second: 22,839.96877
Overall Steps per Second: 10,817.63699

Timestep Collection Time: 2.19081
Timestep Consumption Time: 2.43479
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.62559

Cumulative Model Updates: 63,884
Cumulative Timesteps: 532,771,640

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 532771640...
Checkpoint 532771640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,979.12820
Policy Entropy: 3.71689
Value Function Loss: 0.06177

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.80457

Collected Steps per Second: 22,678.95393
Overall Steps per Second: 10,726.60477

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.45682
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.66168

Cumulative Model Updates: 63,890
Cumulative Timesteps: 532,821,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,008.35295
Policy Entropy: 3.70224
Value Function Loss: 0.06320

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.59105
Value Function Update Magnitude: 0.73374

Collected Steps per Second: 22,984.67589
Overall Steps per Second: 10,914.41150

Timestep Collection Time: 2.17588
Timestep Consumption Time: 2.40631
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.58220

Cumulative Model Updates: 63,896
Cumulative Timesteps: 532,871,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 532871656...
Checkpoint 532871656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,471.08652
Policy Entropy: 3.69079
Value Function Loss: 0.06604

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.55559
Value Function Update Magnitude: 0.68712

Collected Steps per Second: 22,729.63003
Overall Steps per Second: 10,698.32636

Timestep Collection Time: 2.20012
Timestep Consumption Time: 2.47425
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.67438

Cumulative Model Updates: 63,902
Cumulative Timesteps: 532,921,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,378.91742
Policy Entropy: 3.67306
Value Function Loss: 0.06503

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.17182
Policy Update Magnitude: 0.50078
Value Function Update Magnitude: 0.73572

Collected Steps per Second: 22,419.10883
Overall Steps per Second: 10,769.36007

Timestep Collection Time: 2.23024
Timestep Consumption Time: 2.41256
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.64280

Cumulative Model Updates: 63,908
Cumulative Timesteps: 532,971,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 532971664...
Checkpoint 532971664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,228.63083
Policy Entropy: 3.68999
Value Function Loss: 0.06475

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.45350
Value Function Update Magnitude: 0.76719

Collected Steps per Second: 22,724.49271
Overall Steps per Second: 10,705.42984

Timestep Collection Time: 2.20159
Timestep Consumption Time: 2.47174
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.67333

Cumulative Model Updates: 63,914
Cumulative Timesteps: 533,021,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,549.48020
Policy Entropy: 3.70535
Value Function Loss: 0.06078

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.47641
Value Function Update Magnitude: 0.72230

Collected Steps per Second: 22,983.74415
Overall Steps per Second: 10,840.46963

Timestep Collection Time: 2.17545
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.61235

Cumulative Model Updates: 63,920
Cumulative Timesteps: 533,071,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 533071694...
Checkpoint 533071694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,460.64362
Policy Entropy: 3.71248
Value Function Loss: 0.05594

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.46089
Value Function Update Magnitude: 0.77466

Collected Steps per Second: 22,697.22829
Overall Steps per Second: 10,669.45144

Timestep Collection Time: 2.20371
Timestep Consumption Time: 2.48426
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.68796

Cumulative Model Updates: 63,926
Cumulative Timesteps: 533,121,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,558.62537
Policy Entropy: 3.70681
Value Function Loss: 0.05185

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11250
Policy Update Magnitude: 0.49749
Value Function Update Magnitude: 0.85039

Collected Steps per Second: 22,951.56165
Overall Steps per Second: 10,839.84853

Timestep Collection Time: 2.17894
Timestep Consumption Time: 2.43460
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.61353

Cumulative Model Updates: 63,932
Cumulative Timesteps: 533,171,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 533171722...
Checkpoint 533171722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.15116
Policy Entropy: 3.71763
Value Function Loss: 0.05094

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.49940
Value Function Update Magnitude: 0.77311

Collected Steps per Second: 22,594.53992
Overall Steps per Second: 10,704.54462

Timestep Collection Time: 2.21337
Timestep Consumption Time: 2.45848
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.67185

Cumulative Model Updates: 63,938
Cumulative Timesteps: 533,221,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,510.07297
Policy Entropy: 3.71377
Value Function Loss: 0.04949

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.49982
Value Function Update Magnitude: 0.76095

Collected Steps per Second: 22,891.59065
Overall Steps per Second: 10,870.43391

Timestep Collection Time: 2.18421
Timestep Consumption Time: 2.41542
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.59963

Cumulative Model Updates: 63,944
Cumulative Timesteps: 533,271,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 533271732...
Checkpoint 533271732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,713.89222
Policy Entropy: 3.73107
Value Function Loss: 0.04621

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.49020
Value Function Update Magnitude: 0.80064

Collected Steps per Second: 22,459.21840
Overall Steps per Second: 10,679.10494

Timestep Collection Time: 2.22688
Timestep Consumption Time: 2.45647
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.68335

Cumulative Model Updates: 63,950
Cumulative Timesteps: 533,321,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,019.69729
Policy Entropy: 3.72183
Value Function Loss: 0.04474

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.50766
Value Function Update Magnitude: 0.76101

Collected Steps per Second: 22,626.58221
Overall Steps per Second: 10,639.14713

Timestep Collection Time: 2.20997
Timestep Consumption Time: 2.49003
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.70000

Cumulative Model Updates: 63,956
Cumulative Timesteps: 533,371,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 533371750...
Checkpoint 533371750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,535.63057
Policy Entropy: 3.73229
Value Function Loss: 0.04074

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.56098
Value Function Update Magnitude: 0.75455

Collected Steps per Second: 22,641.70446
Overall Steps per Second: 10,676.68182

Timestep Collection Time: 2.20964
Timestep Consumption Time: 2.47627
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.68591

Cumulative Model Updates: 63,962
Cumulative Timesteps: 533,421,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,760.19317
Policy Entropy: 3.74948
Value Function Loss: 0.03858

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.58958
Value Function Update Magnitude: 0.72094

Collected Steps per Second: 22,916.40804
Overall Steps per Second: 10,666.14294

Timestep Collection Time: 2.18219
Timestep Consumption Time: 2.50629
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.68848

Cumulative Model Updates: 63,968
Cumulative Timesteps: 533,471,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 533471788...
Checkpoint 533471788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,605.52655
Policy Entropy: 3.75757
Value Function Loss: 0.03772

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06135
Policy Update Magnitude: 0.62843
Value Function Update Magnitude: 0.67637

Collected Steps per Second: 22,840.61554
Overall Steps per Second: 10,618.28146

Timestep Collection Time: 2.19066
Timestep Consumption Time: 2.52159
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.71225

Cumulative Model Updates: 63,974
Cumulative Timesteps: 533,521,824

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.06378
Policy Entropy: 3.76461
Value Function Loss: 0.03792

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06155
Policy Update Magnitude: 0.64208
Value Function Update Magnitude: 0.65821

Collected Steps per Second: 22,572.96309
Overall Steps per Second: 10,638.40783

Timestep Collection Time: 2.21593
Timestep Consumption Time: 2.48591
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.70183

Cumulative Model Updates: 63,980
Cumulative Timesteps: 533,571,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 533571844...
Checkpoint 533571844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.52984
Policy Entropy: 3.76415
Value Function Loss: 0.03936

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06321
Policy Update Magnitude: 0.64507
Value Function Update Magnitude: 0.66531

Collected Steps per Second: 22,529.15476
Overall Steps per Second: 10,645.09085

Timestep Collection Time: 2.22059
Timestep Consumption Time: 2.47904
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.69963

Cumulative Model Updates: 63,986
Cumulative Timesteps: 533,621,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,282.15439
Policy Entropy: 3.76362
Value Function Loss: 0.03991

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05887
Policy Update Magnitude: 0.65463
Value Function Update Magnitude: 0.67776

Collected Steps per Second: 23,080.72734
Overall Steps per Second: 10,736.40435

Timestep Collection Time: 2.16640
Timestep Consumption Time: 2.49084
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.65724

Cumulative Model Updates: 63,992
Cumulative Timesteps: 533,671,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 533671874...
Checkpoint 533671874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,951.34379
Policy Entropy: 3.76978
Value Function Loss: 0.04048

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06475
Policy Update Magnitude: 0.64921
Value Function Update Magnitude: 0.68139

Collected Steps per Second: 22,794.19692
Overall Steps per Second: 10,647.31304

Timestep Collection Time: 2.19468
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.69846

Cumulative Model Updates: 63,998
Cumulative Timesteps: 533,721,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,489.78175
Policy Entropy: 3.76683
Value Function Loss: 0.04287

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05746
Policy Update Magnitude: 0.63676
Value Function Update Magnitude: 0.67588

Collected Steps per Second: 23,010.42071
Overall Steps per Second: 10,876.35482

Timestep Collection Time: 2.17371
Timestep Consumption Time: 2.42507
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.59878

Cumulative Model Updates: 64,004
Cumulative Timesteps: 533,771,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 533771918...
Checkpoint 533771918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,457.44964
Policy Entropy: 3.77318
Value Function Loss: 0.04273

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06191
Policy Update Magnitude: 0.64590
Value Function Update Magnitude: 0.68075

Collected Steps per Second: 22,558.53563
Overall Steps per Second: 10,658.66411

Timestep Collection Time: 2.21779
Timestep Consumption Time: 2.47605
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.69383

Cumulative Model Updates: 64,010
Cumulative Timesteps: 533,821,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,802.27503
Policy Entropy: 3.76718
Value Function Loss: 0.04233

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05174
Policy Update Magnitude: 0.65387
Value Function Update Magnitude: 0.69414

Collected Steps per Second: 22,867.97035
Overall Steps per Second: 10,831.04183

Timestep Collection Time: 2.18681
Timestep Consumption Time: 2.43029
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.61710

Cumulative Model Updates: 64,016
Cumulative Timesteps: 533,871,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 533871956...
Checkpoint 533871956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,036.63154
Policy Entropy: 3.76911
Value Function Loss: 0.04386

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05972
Policy Update Magnitude: 0.65530
Value Function Update Magnitude: 0.70147

Collected Steps per Second: 22,522.74059
Overall Steps per Second: 10,778.38801

Timestep Collection Time: 2.22060
Timestep Consumption Time: 2.41961
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.64021

Cumulative Model Updates: 64,022
Cumulative Timesteps: 533,921,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,748.20188
Policy Entropy: 3.75897
Value Function Loss: 0.04609

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05806
Policy Update Magnitude: 0.63333
Value Function Update Magnitude: 0.72377

Collected Steps per Second: 22,682.90353
Overall Steps per Second: 10,784.71701

Timestep Collection Time: 2.20474
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.63712

Cumulative Model Updates: 64,028
Cumulative Timesteps: 533,971,980

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 533971980...
Checkpoint 533971980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,719.72339
Policy Entropy: 3.75208
Value Function Loss: 0.04829

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05635
Policy Update Magnitude: 0.65180
Value Function Update Magnitude: 0.73302

Collected Steps per Second: 22,292.78972
Overall Steps per Second: 10,740.65133

Timestep Collection Time: 2.24431
Timestep Consumption Time: 2.41388
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.65819

Cumulative Model Updates: 64,034
Cumulative Timesteps: 534,022,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,448.39683
Policy Entropy: 3.75641
Value Function Loss: 0.04807

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.56370
Value Function Update Magnitude: 0.72231

Collected Steps per Second: 22,800.85856
Overall Steps per Second: 10,809.15746

Timestep Collection Time: 2.19465
Timestep Consumption Time: 2.43475
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62941

Cumulative Model Updates: 64,040
Cumulative Timesteps: 534,072,052

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 534072052...
Checkpoint 534072052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,123.16686
Policy Entropy: 3.76758
Value Function Loss: 0.04883

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.47474
Value Function Update Magnitude: 0.70756

Collected Steps per Second: 22,554.15143
Overall Steps per Second: 10,755.87963

Timestep Collection Time: 2.21715
Timestep Consumption Time: 2.43203
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.64918

Cumulative Model Updates: 64,046
Cumulative Timesteps: 534,122,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,453.13078
Policy Entropy: 3.77112
Value Function Loss: 0.05253

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.44212
Value Function Update Magnitude: 0.66856

Collected Steps per Second: 22,591.73778
Overall Steps per Second: 10,776.10675

Timestep Collection Time: 2.21417
Timestep Consumption Time: 2.42776
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.64194

Cumulative Model Updates: 64,052
Cumulative Timesteps: 534,172,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 534172080...
Checkpoint 534172080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,386.14619
Policy Entropy: 3.76980
Value Function Loss: 0.05453

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.43638
Value Function Update Magnitude: 0.63409

Collected Steps per Second: 22,481.17748
Overall Steps per Second: 10,692.63364

Timestep Collection Time: 2.22479
Timestep Consumption Time: 2.45282
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.67761

Cumulative Model Updates: 64,058
Cumulative Timesteps: 534,222,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,142.10258
Policy Entropy: 3.75263
Value Function Loss: 0.05717

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.47359
Value Function Update Magnitude: 0.63494

Collected Steps per Second: 22,732.64478
Overall Steps per Second: 10,678.53440

Timestep Collection Time: 2.20036
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.68416

Cumulative Model Updates: 64,064
Cumulative Timesteps: 534,272,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 534272116...
Checkpoint 534272116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,159.36929
Policy Entropy: 3.74904
Value Function Loss: 0.05659

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.46988
Value Function Update Magnitude: 0.60431

Collected Steps per Second: 22,697.70650
Overall Steps per Second: 10,792.31125

Timestep Collection Time: 2.20383
Timestep Consumption Time: 2.43113
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.63497

Cumulative Model Updates: 64,070
Cumulative Timesteps: 534,322,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,670.20567
Policy Entropy: 3.74611
Value Function Loss: 0.05801

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08888
Policy Update Magnitude: 0.47078
Value Function Update Magnitude: 0.58388

Collected Steps per Second: 22,503.95183
Overall Steps per Second: 10,593.34935

Timestep Collection Time: 2.22245
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.72126

Cumulative Model Updates: 64,076
Cumulative Timesteps: 534,372,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 534372152...
Checkpoint 534372152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,316.25529
Policy Entropy: 3.73378
Value Function Loss: 0.06140

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.55275

Collected Steps per Second: 22,692.95478
Overall Steps per Second: 10,642.37545

Timestep Collection Time: 2.20359
Timestep Consumption Time: 2.49517
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.69876

Cumulative Model Updates: 64,082
Cumulative Timesteps: 534,422,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,165.54646
Policy Entropy: 3.73247
Value Function Loss: 0.06592

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.61420
Value Function Update Magnitude: 0.57907

Collected Steps per Second: 23,003.63102
Overall Steps per Second: 10,885.39342

Timestep Collection Time: 2.17479
Timestep Consumption Time: 2.42110
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.59588

Cumulative Model Updates: 64,088
Cumulative Timesteps: 534,472,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 534472186...
Checkpoint 534472186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,229.52850
Policy Entropy: 3.71771
Value Function Loss: 0.06413

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.63087
Value Function Update Magnitude: 0.58682

Collected Steps per Second: 22,618.01206
Overall Steps per Second: 10,598.93004

Timestep Collection Time: 2.21125
Timestep Consumption Time: 2.50753
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.71878

Cumulative Model Updates: 64,094
Cumulative Timesteps: 534,522,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,445.89750
Policy Entropy: 3.73395
Value Function Loss: 0.06202

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.64444
Value Function Update Magnitude: 0.69332

Collected Steps per Second: 22,800.55151
Overall Steps per Second: 10,847.45651

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.41751
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61140

Cumulative Model Updates: 64,100
Cumulative Timesteps: 534,572,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 534572222...
Checkpoint 534572222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,447.28349
Policy Entropy: 3.72064
Value Function Loss: 0.06355

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.11766
Policy Update Magnitude: 0.61994
Value Function Update Magnitude: 0.70383

Collected Steps per Second: 22,716.67744
Overall Steps per Second: 10,741.99595

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.45527
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.65779

Cumulative Model Updates: 64,106
Cumulative Timesteps: 534,622,256

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,673.04058
Policy Entropy: 3.72321
Value Function Loss: 0.06593

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.54020
Value Function Update Magnitude: 0.65071

Collected Steps per Second: 22,165.84922
Overall Steps per Second: 10,835.97505

Timestep Collection Time: 2.25671
Timestep Consumption Time: 2.35957
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61629

Cumulative Model Updates: 64,112
Cumulative Timesteps: 534,672,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 534672278...
Checkpoint 534672278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,267.96798
Policy Entropy: 3.71365
Value Function Loss: 0.06519

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.46901
Value Function Update Magnitude: 0.73473

Collected Steps per Second: 21,987.46636
Overall Steps per Second: 10,699.19928

Timestep Collection Time: 2.27521
Timestep Consumption Time: 2.40047
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.67568

Cumulative Model Updates: 64,118
Cumulative Timesteps: 534,722,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,101.95394
Policy Entropy: 3.71421
Value Function Loss: 0.06209

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.58629
Value Function Update Magnitude: 0.66450

Collected Steps per Second: 22,140.25212
Overall Steps per Second: 10,847.39415

Timestep Collection Time: 2.25860
Timestep Consumption Time: 2.35135
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.60996

Cumulative Model Updates: 64,124
Cumulative Timesteps: 534,772,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 534772310...
Checkpoint 534772310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,705.22700
Policy Entropy: 3.72056
Value Function Loss: 0.06443

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.64393
Value Function Update Magnitude: 0.61677

Collected Steps per Second: 21,995.10803
Overall Steps per Second: 10,708.59072

Timestep Collection Time: 2.27369
Timestep Consumption Time: 2.39639
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.67008

Cumulative Model Updates: 64,130
Cumulative Timesteps: 534,822,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,606.27117
Policy Entropy: 3.72604
Value Function Loss: 0.06440

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.67031
Value Function Update Magnitude: 0.60276

Collected Steps per Second: 22,380.60813
Overall Steps per Second: 10,642.01008

Timestep Collection Time: 2.23533
Timestep Consumption Time: 2.46566
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.70099

Cumulative Model Updates: 64,136
Cumulative Timesteps: 534,872,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 534872348...
Checkpoint 534872348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,473.96256
Policy Entropy: 3.72401
Value Function Loss: 0.06704

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.65855
Value Function Update Magnitude: 0.61246

Collected Steps per Second: 22,706.86308
Overall Steps per Second: 10,871.95694

Timestep Collection Time: 2.20295
Timestep Consumption Time: 2.39807
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60101

Cumulative Model Updates: 64,142
Cumulative Timesteps: 534,922,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,669.41983
Policy Entropy: 3.71686
Value Function Loss: 0.06606

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.62963
Value Function Update Magnitude: 0.65610

Collected Steps per Second: 23,032.17964
Overall Steps per Second: 10,922.73989

Timestep Collection Time: 2.17227
Timestep Consumption Time: 2.40827
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.58054

Cumulative Model Updates: 64,148
Cumulative Timesteps: 534,972,402

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 534972402...
Checkpoint 534972402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,794.28440
Policy Entropy: 3.70481
Value Function Loss: 0.06761

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.64679

Collected Steps per Second: 22,643.46160
Overall Steps per Second: 10,693.12726

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.46835
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.67702

Cumulative Model Updates: 64,154
Cumulative Timesteps: 535,022,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,594.78357
Policy Entropy: 3.70478
Value Function Loss: 0.06845

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.48860
Value Function Update Magnitude: 0.64925

Collected Steps per Second: 22,880.11835
Overall Steps per Second: 10,880.63776

Timestep Collection Time: 2.18688
Timestep Consumption Time: 2.41175
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.59863

Cumulative Model Updates: 64,160
Cumulative Timesteps: 535,072,450

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 535072450...
Checkpoint 535072450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,235.28762
Policy Entropy: 3.70926
Value Function Loss: 0.06562

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.47300
Value Function Update Magnitude: 0.67684

Collected Steps per Second: 22,801.19915
Overall Steps per Second: 10,619.73174

Timestep Collection Time: 2.19392
Timestep Consumption Time: 2.51656
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.71048

Cumulative Model Updates: 64,166
Cumulative Timesteps: 535,122,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,445.32742
Policy Entropy: 3.71510
Value Function Loss: 0.06804

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.43645
Value Function Update Magnitude: 0.59362

Collected Steps per Second: 22,828.79146
Overall Steps per Second: 10,843.43246

Timestep Collection Time: 2.19136
Timestep Consumption Time: 2.42213
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.61348

Cumulative Model Updates: 64,172
Cumulative Timesteps: 535,172,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 535172500...
Checkpoint 535172500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,712.91575
Policy Entropy: 3.71675
Value Function Loss: 0.06839

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.43924
Value Function Update Magnitude: 0.55047

Collected Steps per Second: 22,282.50736
Overall Steps per Second: 10,725.27938

Timestep Collection Time: 2.24400
Timestep Consumption Time: 2.41807
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.66207

Cumulative Model Updates: 64,178
Cumulative Timesteps: 535,222,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,576.72519
Policy Entropy: 3.69909
Value Function Loss: 0.06916

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.44267
Value Function Update Magnitude: 0.58697

Collected Steps per Second: 23,021.49084
Overall Steps per Second: 10,869.34513

Timestep Collection Time: 2.17319
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.60285

Cumulative Model Updates: 64,184
Cumulative Timesteps: 535,272,532

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 535272532...
Checkpoint 535272532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,329.28653
Policy Entropy: 3.70983
Value Function Loss: 0.06523

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.47088
Value Function Update Magnitude: 0.70936

Collected Steps per Second: 22,599.81264
Overall Steps per Second: 10,636.68669

Timestep Collection Time: 2.21294
Timestep Consumption Time: 2.48890
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.70184

Cumulative Model Updates: 64,190
Cumulative Timesteps: 535,322,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,501.38025
Policy Entropy: 3.71510
Value Function Loss: 0.06383

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.55718
Value Function Update Magnitude: 0.72478

Collected Steps per Second: 22,842.40757
Overall Steps per Second: 10,689.61569

Timestep Collection Time: 2.18996
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.67968

Cumulative Model Updates: 64,196
Cumulative Timesteps: 535,372,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 535372568...
Checkpoint 535372568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,189.64529
Policy Entropy: 3.72877
Value Function Loss: 0.06286

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.60700
Value Function Update Magnitude: 0.68360

Collected Steps per Second: 22,809.42239
Overall Steps per Second: 10,835.81204

Timestep Collection Time: 2.19287
Timestep Consumption Time: 2.42312
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.61599

Cumulative Model Updates: 64,202
Cumulative Timesteps: 535,422,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,381.38932
Policy Entropy: 3.72052
Value Function Loss: 0.06367

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.62935
Value Function Update Magnitude: 0.67950

Collected Steps per Second: 22,960.38239
Overall Steps per Second: 10,726.34673

Timestep Collection Time: 2.17793
Timestep Consumption Time: 2.48405
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.66198

Cumulative Model Updates: 64,208
Cumulative Timesteps: 535,472,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 535472592...
Checkpoint 535472592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,080.94351
Policy Entropy: 3.71832
Value Function Loss: 0.06230

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.62589
Value Function Update Magnitude: 0.74524

Collected Steps per Second: 22,552.25674
Overall Steps per Second: 10,833.24704

Timestep Collection Time: 2.21823
Timestep Consumption Time: 2.39960
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.61782

Cumulative Model Updates: 64,214
Cumulative Timesteps: 535,522,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,916.67900
Policy Entropy: 3.69977
Value Function Loss: 0.06092

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.61510
Value Function Update Magnitude: 0.80791

Collected Steps per Second: 22,857.86029
Overall Steps per Second: 10,869.37016

Timestep Collection Time: 2.18874
Timestep Consumption Time: 2.41410
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.60284

Cumulative Model Updates: 64,220
Cumulative Timesteps: 535,572,648

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 535572648...
Checkpoint 535572648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,653.11040
Policy Entropy: 3.70229
Value Function Loss: 0.06000

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.59330
Value Function Update Magnitude: 0.81423

Collected Steps per Second: 22,622.24239
Overall Steps per Second: 10,734.66936

Timestep Collection Time: 2.21083
Timestep Consumption Time: 2.44828
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.65911

Cumulative Model Updates: 64,226
Cumulative Timesteps: 535,622,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,370.06807
Policy Entropy: 3.69755
Value Function Loss: 0.06092

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.78001

Collected Steps per Second: 22,680.65788
Overall Steps per Second: 10,796.16470

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.63313

Cumulative Model Updates: 64,232
Cumulative Timesteps: 535,672,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 535672682...
Checkpoint 535672682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,020.74690
Policy Entropy: 3.69830
Value Function Loss: 0.06020

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.50475
Value Function Update Magnitude: 0.78001

Collected Steps per Second: 22,788.00272
Overall Steps per Second: 10,731.95007

Timestep Collection Time: 2.19440
Timestep Consumption Time: 2.46514
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.65954

Cumulative Model Updates: 64,238
Cumulative Timesteps: 535,722,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,277.39043
Policy Entropy: 3.69137
Value Function Loss: 0.05747

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09928
Policy Update Magnitude: 0.52286
Value Function Update Magnitude: 0.78495

Collected Steps per Second: 22,621.40944
Overall Steps per Second: 10,662.98057

Timestep Collection Time: 2.21162
Timestep Consumption Time: 2.48031
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.69193

Cumulative Model Updates: 64,244
Cumulative Timesteps: 535,772,718

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 535772718...
Checkpoint 535772718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,179.62702
Policy Entropy: 3.69853
Value Function Loss: 0.05600

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.52573
Value Function Update Magnitude: 0.77021

Collected Steps per Second: 22,951.32111
Overall Steps per Second: 10,900.99474

Timestep Collection Time: 2.17931
Timestep Consumption Time: 2.40908
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.58839

Cumulative Model Updates: 64,250
Cumulative Timesteps: 535,822,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,193.01280
Policy Entropy: 3.70750
Value Function Loss: 0.05563

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.61109
Value Function Update Magnitude: 0.76061

Collected Steps per Second: 22,773.53635
Overall Steps per Second: 10,806.20533

Timestep Collection Time: 2.19562
Timestep Consumption Time: 2.43154
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.62716

Cumulative Model Updates: 64,256
Cumulative Timesteps: 535,872,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 535872738...
Checkpoint 535872738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,918.57730
Policy Entropy: 3.71419
Value Function Loss: 0.05777

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.60038
Value Function Update Magnitude: 0.71281

Collected Steps per Second: 22,686.95916
Overall Steps per Second: 10,703.77629

Timestep Collection Time: 2.20409
Timestep Consumption Time: 2.46754
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.67162

Cumulative Model Updates: 64,262
Cumulative Timesteps: 535,922,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,391.61915
Policy Entropy: 3.70859
Value Function Loss: 0.05991

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.57586
Value Function Update Magnitude: 0.63739

Collected Steps per Second: 22,872.61562
Overall Steps per Second: 10,664.97769

Timestep Collection Time: 2.18707
Timestep Consumption Time: 2.50342
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.69049

Cumulative Model Updates: 64,268
Cumulative Timesteps: 535,972,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 535972766...
Checkpoint 535972766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,092.61673
Policy Entropy: 3.71536
Value Function Loss: 0.05992

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.58834
Value Function Update Magnitude: 0.62384

Collected Steps per Second: 22,454.36657
Overall Steps per Second: 10,639.46090

Timestep Collection Time: 2.22816
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.70249

Cumulative Model Updates: 64,274
Cumulative Timesteps: 536,022,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.87699
Policy Entropy: 3.69374
Value Function Loss: 0.06043

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.60376
Value Function Update Magnitude: 0.68859

Collected Steps per Second: 22,926.48291
Overall Steps per Second: 10,707.91448

Timestep Collection Time: 2.18184
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.67150

Cumulative Model Updates: 64,280
Cumulative Timesteps: 536,072,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 536072820...
Checkpoint 536072820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,229.07778
Policy Entropy: 3.70081
Value Function Loss: 0.05936

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.59787
Value Function Update Magnitude: 0.74764

Collected Steps per Second: 22,868.99264
Overall Steps per Second: 10,675.85734

Timestep Collection Time: 2.18680
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.68440

Cumulative Model Updates: 64,286
Cumulative Timesteps: 536,122,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,743.25691
Policy Entropy: 3.69575
Value Function Loss: 0.05914

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.52670
Value Function Update Magnitude: 0.76769

Collected Steps per Second: 22,572.31120
Overall Steps per Second: 10,632.00514

Timestep Collection Time: 2.21608
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.70485

Cumulative Model Updates: 64,292
Cumulative Timesteps: 536,172,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 536172852...
Checkpoint 536172852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,767.65854
Policy Entropy: 3.69561
Value Function Loss: 0.05981

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.53245
Value Function Update Magnitude: 0.76586

Collected Steps per Second: 22,568.99382
Overall Steps per Second: 10,836.29143

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.39898
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.61468

Cumulative Model Updates: 64,298
Cumulative Timesteps: 536,222,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,148.71827
Policy Entropy: 3.69067
Value Function Loss: 0.05955

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.55870
Value Function Update Magnitude: 0.75346

Collected Steps per Second: 22,923.58554
Overall Steps per Second: 10,845.97993

Timestep Collection Time: 2.18256
Timestep Consumption Time: 2.43040
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61295

Cumulative Model Updates: 64,304
Cumulative Timesteps: 536,272,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 536272890...
Checkpoint 536272890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,461.65534
Policy Entropy: 3.68136
Value Function Loss: 0.06360

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.53778
Value Function Update Magnitude: 0.73918

Collected Steps per Second: 22,698.49964
Overall Steps per Second: 10,636.64939

Timestep Collection Time: 2.20305
Timestep Consumption Time: 2.49824
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.70129

Cumulative Model Updates: 64,310
Cumulative Timesteps: 536,322,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,419.86018
Policy Entropy: 3.69018
Value Function Loss: 0.06275

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.49246
Value Function Update Magnitude: 0.70045

Collected Steps per Second: 22,697.49592
Overall Steps per Second: 10,665.74430

Timestep Collection Time: 2.20359
Timestep Consumption Time: 2.48581
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.68941

Cumulative Model Updates: 64,316
Cumulative Timesteps: 536,372,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 536372912...
Checkpoint 536372912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,256.55104
Policy Entropy: 3.68856
Value Function Loss: 0.06652

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.46621
Value Function Update Magnitude: 0.66497

Collected Steps per Second: 22,674.25981
Overall Steps per Second: 10,710.16615

Timestep Collection Time: 2.20594
Timestep Consumption Time: 2.46420
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.67014

Cumulative Model Updates: 64,322
Cumulative Timesteps: 536,422,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,770.89996
Policy Entropy: 3.69028
Value Function Loss: 0.06187

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.52811
Value Function Update Magnitude: 0.73352

Collected Steps per Second: 23,101.20325
Overall Steps per Second: 10,691.61711

Timestep Collection Time: 2.16448
Timestep Consumption Time: 2.51227
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.67675

Cumulative Model Updates: 64,328
Cumulative Timesteps: 536,472,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 536472932...
Checkpoint 536472932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,450.30230
Policy Entropy: 3.70575
Value Function Loss: 0.05953

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.78763

Collected Steps per Second: 22,486.92559
Overall Steps per Second: 10,667.12020

Timestep Collection Time: 2.22467
Timestep Consumption Time: 2.46507
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.68974

Cumulative Model Updates: 64,334
Cumulative Timesteps: 536,522,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,961.63369
Policy Entropy: 3.70338
Value Function Loss: 0.05620

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.51527
Value Function Update Magnitude: 0.78907

Collected Steps per Second: 23,032.17285
Overall Steps per Second: 10,873.23152

Timestep Collection Time: 2.17192
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60066

Cumulative Model Updates: 64,340
Cumulative Timesteps: 536,572,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 536572982...
Checkpoint 536572982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,269.51142
Policy Entropy: 3.71522
Value Function Loss: 0.05579

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.50543
Value Function Update Magnitude: 0.81410

Collected Steps per Second: 22,598.68009
Overall Steps per Second: 10,673.86580

Timestep Collection Time: 2.21270
Timestep Consumption Time: 2.47202
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.68471

Cumulative Model Updates: 64,346
Cumulative Timesteps: 536,622,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,181.47811
Policy Entropy: 3.70203
Value Function Loss: 0.05779

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.49729
Value Function Update Magnitude: 0.77757

Collected Steps per Second: 23,005.62143
Overall Steps per Second: 10,851.49527

Timestep Collection Time: 2.17425
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60950

Cumulative Model Updates: 64,352
Cumulative Timesteps: 536,673,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 536673006...
Checkpoint 536673006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,871.30850
Policy Entropy: 3.69711
Value Function Loss: 0.05999

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.49729
Value Function Update Magnitude: 0.67597

Collected Steps per Second: 22,412.95285
Overall Steps per Second: 10,644.93619

Timestep Collection Time: 2.23148
Timestep Consumption Time: 2.46691
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.69838

Cumulative Model Updates: 64,358
Cumulative Timesteps: 536,723,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,335.55174
Policy Entropy: 3.68734
Value Function Loss: 0.06265

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.49861
Value Function Update Magnitude: 0.66509

Collected Steps per Second: 22,182.37754
Overall Steps per Second: 10,833.24513

Timestep Collection Time: 2.25621
Timestep Consumption Time: 2.36365
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.61985

Cumulative Model Updates: 64,364
Cumulative Timesteps: 536,773,068

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 536773068...
Checkpoint 536773068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,663.85228
Policy Entropy: 3.69025
Value Function Loss: 0.06480

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.47204
Value Function Update Magnitude: 0.67668

Collected Steps per Second: 21,704.61533
Overall Steps per Second: 10,752.97336

Timestep Collection Time: 2.30504
Timestep Consumption Time: 2.34763
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.65267

Cumulative Model Updates: 64,370
Cumulative Timesteps: 536,823,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,186.17208
Policy Entropy: 3.70733
Value Function Loss: 0.06474

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.56058
Value Function Update Magnitude: 0.76038

Collected Steps per Second: 22,277.00273
Overall Steps per Second: 10,865.68866

Timestep Collection Time: 2.24536
Timestep Consumption Time: 2.35812
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60348

Cumulative Model Updates: 64,376
Cumulative Timesteps: 536,873,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 536873118...
Checkpoint 536873118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,269.91076
Policy Entropy: 3.71220
Value Function Loss: 0.06311

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.61212
Value Function Update Magnitude: 0.83259

Collected Steps per Second: 21,993.69793
Overall Steps per Second: 10,662.70185

Timestep Collection Time: 2.27338
Timestep Consumption Time: 2.41586
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.68924

Cumulative Model Updates: 64,382
Cumulative Timesteps: 536,923,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,850.79341
Policy Entropy: 3.71081
Value Function Loss: 0.05878

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.59938
Value Function Update Magnitude: 0.84282

Collected Steps per Second: 22,191.39566
Overall Steps per Second: 10,851.02695

Timestep Collection Time: 2.25376
Timestep Consumption Time: 2.35539
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60915

Cumulative Model Updates: 64,388
Cumulative Timesteps: 536,973,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 536973132...
Checkpoint 536973132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,253.58486
Policy Entropy: 3.71034
Value Function Loss: 0.05835

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.66719
Value Function Update Magnitude: 0.82523

Collected Steps per Second: 22,202.51113
Overall Steps per Second: 10,767.86817

Timestep Collection Time: 2.25209
Timestep Consumption Time: 2.39154
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.64363

Cumulative Model Updates: 64,394
Cumulative Timesteps: 537,023,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,637.99924
Policy Entropy: 3.71887
Value Function Loss: 0.05731

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.61324
Value Function Update Magnitude: 0.81244

Collected Steps per Second: 22,944.61627
Overall Steps per Second: 10,921.03779

Timestep Collection Time: 2.18029
Timestep Consumption Time: 2.40041
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.58070

Cumulative Model Updates: 64,400
Cumulative Timesteps: 537,073,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 537073160...
Checkpoint 537073160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,378.80125
Policy Entropy: 3.69694
Value Function Loss: 0.06199

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.50016
Value Function Update Magnitude: 0.80539

Collected Steps per Second: 22,975.84683
Overall Steps per Second: 10,800.78948

Timestep Collection Time: 2.17629
Timestep Consumption Time: 2.45319
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.62948

Cumulative Model Updates: 64,406
Cumulative Timesteps: 537,123,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,771.59379
Policy Entropy: 3.69613
Value Function Loss: 0.06318

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.49226
Value Function Update Magnitude: 0.74481

Collected Steps per Second: 23,132.92567
Overall Steps per Second: 10,817.15377

Timestep Collection Time: 2.16237
Timestep Consumption Time: 2.46195
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.62432

Cumulative Model Updates: 64,412
Cumulative Timesteps: 537,173,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 537173184...
Checkpoint 537173184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,760.46735
Policy Entropy: 3.68086
Value Function Loss: 0.06436

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.45109
Value Function Update Magnitude: 0.68882

Collected Steps per Second: 22,541.84571
Overall Steps per Second: 10,715.35916

Timestep Collection Time: 2.21890
Timestep Consumption Time: 2.44898
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.66788

Cumulative Model Updates: 64,418
Cumulative Timesteps: 537,223,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.55053
Policy Entropy: 3.69517
Value Function Loss: 0.06014

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.42427
Value Function Update Magnitude: 0.66777

Collected Steps per Second: 22,919.78716
Overall Steps per Second: 10,704.31467

Timestep Collection Time: 2.18248
Timestep Consumption Time: 2.49059
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.67307

Cumulative Model Updates: 64,424
Cumulative Timesteps: 537,273,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 537273224...
Checkpoint 537273224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,401.59280
Policy Entropy: 3.68880
Value Function Loss: 0.06050

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.44524
Value Function Update Magnitude: 0.63329

Collected Steps per Second: 22,951.95189
Overall Steps per Second: 10,700.64224

Timestep Collection Time: 2.17968
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.67523

Cumulative Model Updates: 64,430
Cumulative Timesteps: 537,323,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,143.43132
Policy Entropy: 3.69655
Value Function Loss: 0.06160

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.46553
Value Function Update Magnitude: 0.62762

Collected Steps per Second: 22,579.29793
Overall Steps per Second: 10,772.92507

Timestep Collection Time: 2.21530
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.64312

Cumulative Model Updates: 64,436
Cumulative Timesteps: 537,373,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 537373272...
Checkpoint 537373272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,182.44093
Policy Entropy: 3.69135
Value Function Loss: 0.06279

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.46560
Value Function Update Magnitude: 0.59179

Collected Steps per Second: 22,762.52596
Overall Steps per Second: 10,716.96528

Timestep Collection Time: 2.19677
Timestep Consumption Time: 2.46910
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.66587

Cumulative Model Updates: 64,442
Cumulative Timesteps: 537,423,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,960.82673
Policy Entropy: 3.69160
Value Function Loss: 0.06253

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08801
Policy Update Magnitude: 0.46491
Value Function Update Magnitude: 0.60732

Collected Steps per Second: 22,819.46162
Overall Steps per Second: 10,801.96057

Timestep Collection Time: 2.19138
Timestep Consumption Time: 2.43797
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.62934

Cumulative Model Updates: 64,448
Cumulative Timesteps: 537,473,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 537473282...
Checkpoint 537473282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,557.64315
Policy Entropy: 3.68929
Value Function Loss: 0.06211

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.47107
Value Function Update Magnitude: 0.59598

Collected Steps per Second: 22,426.39936
Overall Steps per Second: 10,765.78931

Timestep Collection Time: 2.22987
Timestep Consumption Time: 2.41521
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.64508

Cumulative Model Updates: 64,454
Cumulative Timesteps: 537,523,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,101.94965
Policy Entropy: 3.68986
Value Function Loss: 0.06213

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.48266
Value Function Update Magnitude: 0.60667

Collected Steps per Second: 22,739.14544
Overall Steps per Second: 10,763.98905

Timestep Collection Time: 2.19947
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.64642

Cumulative Model Updates: 64,460
Cumulative Timesteps: 537,573,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 537573304...
Checkpoint 537573304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,666.74764
Policy Entropy: 3.68574
Value Function Loss: 0.06093

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.49777
Value Function Update Magnitude: 0.63749

Collected Steps per Second: 22,528.06166
Overall Steps per Second: 10,777.19677

Timestep Collection Time: 2.22008
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.64072

Cumulative Model Updates: 64,466
Cumulative Timesteps: 537,623,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,987.97554
Policy Entropy: 3.69525
Value Function Loss: 0.06182

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.51376
Value Function Update Magnitude: 0.64090

Collected Steps per Second: 23,093.09596
Overall Steps per Second: 10,872.74097

Timestep Collection Time: 2.16550
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.59939

Cumulative Model Updates: 64,472
Cumulative Timesteps: 537,673,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 537673326...
Checkpoint 537673326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,344.11792
Policy Entropy: 3.69631
Value Function Loss: 0.06218

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.52271
Value Function Update Magnitude: 0.62962

Collected Steps per Second: 22,647.86050
Overall Steps per Second: 10,710.91497

Timestep Collection Time: 2.20816
Timestep Consumption Time: 2.46091
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.66907

Cumulative Model Updates: 64,478
Cumulative Timesteps: 537,723,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,173.90730
Policy Entropy: 3.70563
Value Function Loss: 0.06364

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.51349
Value Function Update Magnitude: 0.64203

Collected Steps per Second: 23,004.26566
Overall Steps per Second: 10,873.20454

Timestep Collection Time: 2.17429
Timestep Consumption Time: 2.42582
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.60012

Cumulative Model Updates: 64,484
Cumulative Timesteps: 537,773,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 537773354...
Checkpoint 537773354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.29153
Policy Entropy: 3.71021
Value Function Loss: 0.06323

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.52757
Value Function Update Magnitude: 0.67707

Collected Steps per Second: 22,942.84451
Overall Steps per Second: 10,713.80719

Timestep Collection Time: 2.18037
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.66912

Cumulative Model Updates: 64,490
Cumulative Timesteps: 537,823,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,472.45225
Policy Entropy: 3.70385
Value Function Loss: 0.06327

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06633
Policy Update Magnitude: 0.62724
Value Function Update Magnitude: 0.71385

Collected Steps per Second: 22,908.15359
Overall Steps per Second: 10,767.05804

Timestep Collection Time: 2.18289
Timestep Consumption Time: 2.46146
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.64435

Cumulative Model Updates: 64,496
Cumulative Timesteps: 537,873,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 537873384...
Checkpoint 537873384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,241.04529
Policy Entropy: 3.70872
Value Function Loss: 0.06568

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.66729
Value Function Update Magnitude: 0.76584

Collected Steps per Second: 22,681.91570
Overall Steps per Second: 10,670.64082

Timestep Collection Time: 2.20528
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.68763

Cumulative Model Updates: 64,502
Cumulative Timesteps: 537,923,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,447.96485
Policy Entropy: 3.71425
Value Function Loss: 0.06503

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10077
Policy Update Magnitude: 0.66000
Value Function Update Magnitude: 0.74657

Collected Steps per Second: 22,953.85026
Overall Steps per Second: 10,853.04156

Timestep Collection Time: 2.17942
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.60940

Cumulative Model Updates: 64,508
Cumulative Timesteps: 537,973,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 537973430...
Checkpoint 537973430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,454.49152
Policy Entropy: 3.72295
Value Function Loss: 0.06315

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.60052
Value Function Update Magnitude: 0.80356

Collected Steps per Second: 22,550.01595
Overall Steps per Second: 10,704.16284

Timestep Collection Time: 2.21871
Timestep Consumption Time: 2.45536
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.67407

Cumulative Model Updates: 64,514
Cumulative Timesteps: 538,023,462

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,190.68594
Policy Entropy: 3.71457
Value Function Loss: 0.06333

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.86474

Collected Steps per Second: 22,932.26172
Overall Steps per Second: 10,833.86757

Timestep Collection Time: 2.18138
Timestep Consumption Time: 2.43599
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.61737

Cumulative Model Updates: 64,520
Cumulative Timesteps: 538,073,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 538073486...
Checkpoint 538073486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,865.26345
Policy Entropy: 3.71941
Value Function Loss: 0.06411

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.58224
Value Function Update Magnitude: 0.89464

Collected Steps per Second: 22,618.14657
Overall Steps per Second: 10,688.45559

Timestep Collection Time: 2.21106
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.67888

Cumulative Model Updates: 64,526
Cumulative Timesteps: 538,123,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,599.24793
Policy Entropy: 3.73214
Value Function Loss: 0.06340

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.65784
Value Function Update Magnitude: 0.90054

Collected Steps per Second: 22,894.10014
Overall Steps per Second: 10,847.11514

Timestep Collection Time: 2.18414
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60989

Cumulative Model Updates: 64,532
Cumulative Timesteps: 538,173,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 538173500...
Checkpoint 538173500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,345.45486
Policy Entropy: 3.74454
Value Function Loss: 0.06283

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.60649
Value Function Update Magnitude: 0.80717

Collected Steps per Second: 22,590.85147
Overall Steps per Second: 10,784.16328

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.42431
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.63865

Cumulative Model Updates: 64,538
Cumulative Timesteps: 538,223,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,536.59086
Policy Entropy: 3.73359
Value Function Loss: 0.06364

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.54438
Value Function Update Magnitude: 0.68374

Collected Steps per Second: 22,803.74876
Overall Steps per Second: 10,791.71240

Timestep Collection Time: 2.19359
Timestep Consumption Time: 2.44164
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.63522

Cumulative Model Updates: 64,544
Cumulative Timesteps: 538,273,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 538273546...
Checkpoint 538273546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,843.42539
Policy Entropy: 3.72655
Value Function Loss: 0.06459

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.49684
Value Function Update Magnitude: 0.69495

Collected Steps per Second: 22,834.48629
Overall Steps per Second: 10,667.38115

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.50021
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.69225

Cumulative Model Updates: 64,550
Cumulative Timesteps: 538,323,600

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,025.74376
Policy Entropy: 3.71295
Value Function Loss: 0.06520

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.49168
Value Function Update Magnitude: 0.77891

Collected Steps per Second: 22,834.84140
Overall Steps per Second: 10,727.76250

Timestep Collection Time: 2.19086
Timestep Consumption Time: 2.47255
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.66341

Cumulative Model Updates: 64,556
Cumulative Timesteps: 538,373,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 538373628...
Checkpoint 538373628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,230.46242
Policy Entropy: 3.69255
Value Function Loss: 0.06687

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.85807

Collected Steps per Second: 22,817.04790
Overall Steps per Second: 10,819.76507

Timestep Collection Time: 2.19354
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62579

Cumulative Model Updates: 64,562
Cumulative Timesteps: 538,423,678

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,613.66137
Policy Entropy: 3.68862
Value Function Loss: 0.06735

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.61066
Value Function Update Magnitude: 0.83330

Collected Steps per Second: 22,865.97385
Overall Steps per Second: 10,853.79664

Timestep Collection Time: 2.18788
Timestep Consumption Time: 2.42138
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.60926

Cumulative Model Updates: 64,568
Cumulative Timesteps: 538,473,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 538473706...
Checkpoint 538473706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,816.06553
Policy Entropy: 3.70374
Value Function Loss: 0.06650

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.65147
Value Function Update Magnitude: 0.79138

Collected Steps per Second: 22,717.25160
Overall Steps per Second: 10,817.25202

Timestep Collection Time: 2.20194
Timestep Consumption Time: 2.42234
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.62428

Cumulative Model Updates: 64,574
Cumulative Timesteps: 538,523,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,368.63375
Policy Entropy: 3.71566
Value Function Loss: 0.06156

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.56015
Value Function Update Magnitude: 0.82167

Collected Steps per Second: 22,819.44959
Overall Steps per Second: 10,800.23948

Timestep Collection Time: 2.19146
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.63027

Cumulative Model Updates: 64,580
Cumulative Timesteps: 538,573,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 538573736...
Checkpoint 538573736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.17164
Policy Entropy: 3.72387
Value Function Loss: 0.05867

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.51934
Value Function Update Magnitude: 0.86979

Collected Steps per Second: 22,377.94086
Overall Steps per Second: 10,750.43151

Timestep Collection Time: 2.23434
Timestep Consumption Time: 2.41663
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.65098

Cumulative Model Updates: 64,586
Cumulative Timesteps: 538,623,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,966.39161
Policy Entropy: 3.72667
Value Function Loss: 0.05852

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.49432
Value Function Update Magnitude: 0.87012

Collected Steps per Second: 22,825.60275
Overall Steps per Second: 10,812.17175

Timestep Collection Time: 2.19070
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62479

Cumulative Model Updates: 64,592
Cumulative Timesteps: 538,673,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 538673740...
Checkpoint 538673740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,045.87291
Policy Entropy: 3.72296
Value Function Loss: 0.05852

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.54151
Value Function Update Magnitude: 0.85708

Collected Steps per Second: 22,562.49718
Overall Steps per Second: 10,662.25101

Timestep Collection Time: 2.21678
Timestep Consumption Time: 2.47417
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.69094

Cumulative Model Updates: 64,598
Cumulative Timesteps: 538,723,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,123.74941
Policy Entropy: 3.72841
Value Function Loss: 0.05742

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.55713
Value Function Update Magnitude: 0.87038

Collected Steps per Second: 22,593.68697
Overall Steps per Second: 10,667.18481

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.47545
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.68952

Cumulative Model Updates: 64,604
Cumulative Timesteps: 538,773,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 538773780...
Checkpoint 538773780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,964.66319
Policy Entropy: 3.72722
Value Function Loss: 0.05726

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.56151
Value Function Update Magnitude: 0.88157

Collected Steps per Second: 22,514.48990
Overall Steps per Second: 10,785.19963

Timestep Collection Time: 2.22124
Timestep Consumption Time: 2.41567
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.63691

Cumulative Model Updates: 64,610
Cumulative Timesteps: 538,823,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,759.72291
Policy Entropy: 3.72047
Value Function Loss: 0.05634

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.56551
Value Function Update Magnitude: 0.85739

Collected Steps per Second: 22,779.71848
Overall Steps per Second: 10,695.15447

Timestep Collection Time: 2.19625
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.67782

Cumulative Model Updates: 64,616
Cumulative Timesteps: 538,873,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 538873820...
Checkpoint 538873820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,416.53073
Policy Entropy: 3.70820
Value Function Loss: 0.05793

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.52991
Value Function Update Magnitude: 0.84920

Collected Steps per Second: 22,685.77024
Overall Steps per Second: 10,681.16811

Timestep Collection Time: 2.20491
Timestep Consumption Time: 2.47810
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.68301

Cumulative Model Updates: 64,622
Cumulative Timesteps: 538,923,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,702.45004
Policy Entropy: 3.70341
Value Function Loss: 0.05807

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08072
Policy Update Magnitude: 0.53995
Value Function Update Magnitude: 0.81982

Collected Steps per Second: 22,763.12305
Overall Steps per Second: 10,710.16365

Timestep Collection Time: 2.19689
Timestep Consumption Time: 2.47232
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.66921

Cumulative Model Updates: 64,628
Cumulative Timesteps: 538,973,848

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 538973848...
Checkpoint 538973848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,970.07161
Policy Entropy: 3.71091
Value Function Loss: 0.05819

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.58698
Value Function Update Magnitude: 0.82938

Collected Steps per Second: 22,815.47278
Overall Steps per Second: 10,668.98610

Timestep Collection Time: 2.19158
Timestep Consumption Time: 2.49509
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.68667

Cumulative Model Updates: 64,634
Cumulative Timesteps: 539,023,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,293.48845
Policy Entropy: 3.71428
Value Function Loss: 0.05916

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.57863
Value Function Update Magnitude: 0.81073

Collected Steps per Second: 22,922.07000
Overall Steps per Second: 10,857.30451

Timestep Collection Time: 2.18253
Timestep Consumption Time: 2.42525
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60777

Cumulative Model Updates: 64,640
Cumulative Timesteps: 539,073,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 539073878...
Checkpoint 539073878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,413.52014
Policy Entropy: 3.71888
Value Function Loss: 0.06237

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.53889
Value Function Update Magnitude: 0.76716

Collected Steps per Second: 22,802.69705
Overall Steps per Second: 10,676.54756

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.49183
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.68578

Cumulative Model Updates: 64,646
Cumulative Timesteps: 539,123,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,015.44996
Policy Entropy: 3.71987
Value Function Loss: 0.06779

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.66854

Collected Steps per Second: 22,050.89457
Overall Steps per Second: 10,808.32164

Timestep Collection Time: 2.26803
Timestep Consumption Time: 2.35915
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62718

Cumulative Model Updates: 64,652
Cumulative Timesteps: 539,173,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 539173918...
Checkpoint 539173918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,358.78817
Policy Entropy: 3.71567
Value Function Loss: 0.06801

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.55127
Value Function Update Magnitude: 0.62615

Collected Steps per Second: 21,933.32564
Overall Steps per Second: 10,710.70088

Timestep Collection Time: 2.28000
Timestep Consumption Time: 2.38897
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.66898

Cumulative Model Updates: 64,658
Cumulative Timesteps: 539,223,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,076.40410
Policy Entropy: 3.72851
Value Function Loss: 0.06250

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11314
Policy Update Magnitude: 0.57599
Value Function Update Magnitude: 0.70998

Collected Steps per Second: 22,113.92279
Overall Steps per Second: 10,827.24889

Timestep Collection Time: 2.26120
Timestep Consumption Time: 2.35715
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.61835

Cumulative Model Updates: 64,664
Cumulative Timesteps: 539,273,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 539273930...
Checkpoint 539273930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,662.53968
Policy Entropy: 3.74301
Value Function Loss: 0.05898

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.54691
Value Function Update Magnitude: 0.81362

Collected Steps per Second: 21,771.83416
Overall Steps per Second: 10,698.64336

Timestep Collection Time: 2.29737
Timestep Consumption Time: 2.37780
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.67517

Cumulative Model Updates: 64,670
Cumulative Timesteps: 539,323,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,310.38916
Policy Entropy: 3.74190
Value Function Loss: 0.05814

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.62556
Value Function Update Magnitude: 0.84185

Collected Steps per Second: 22,214.33315
Overall Steps per Second: 10,870.51467

Timestep Collection Time: 2.25206
Timestep Consumption Time: 2.35011
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60217

Cumulative Model Updates: 64,676
Cumulative Timesteps: 539,373,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 539373976...
Checkpoint 539373976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,242.63769
Policy Entropy: 3.73953
Value Function Loss: 0.06133

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.70486
Value Function Update Magnitude: 0.81676

Collected Steps per Second: 21,748.11588
Overall Steps per Second: 10,692.27067

Timestep Collection Time: 2.30034
Timestep Consumption Time: 2.37856
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.67889

Cumulative Model Updates: 64,682
Cumulative Timesteps: 539,424,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,419.67390
Policy Entropy: 3.72777
Value Function Loss: 0.06359

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06671
Policy Update Magnitude: 0.73431
Value Function Update Magnitude: 0.74124

Collected Steps per Second: 22,137.70837
Overall Steps per Second: 10,860.56386

Timestep Collection Time: 2.25922
Timestep Consumption Time: 2.34588
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.60510

Cumulative Model Updates: 64,688
Cumulative Timesteps: 539,474,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 539474018...
Checkpoint 539474018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,770.88766
Policy Entropy: 3.71526
Value Function Loss: 0.06408

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.72038
Value Function Update Magnitude: 0.76220

Collected Steps per Second: 22,133.16321
Overall Steps per Second: 10,673.19911

Timestep Collection Time: 2.26122
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.68913

Cumulative Model Updates: 64,694
Cumulative Timesteps: 539,524,066

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,039.18285
Policy Entropy: 3.71065
Value Function Loss: 0.06434

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.66415
Value Function Update Magnitude: 0.74574

Collected Steps per Second: 22,149.69479
Overall Steps per Second: 10,575.18606

Timestep Collection Time: 2.25818
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.72975

Cumulative Model Updates: 64,700
Cumulative Timesteps: 539,574,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 539574084...
Checkpoint 539574084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,220.83773
Policy Entropy: 3.70302
Value Function Loss: 0.06399

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.62398
Value Function Update Magnitude: 0.75218

Collected Steps per Second: 22,525.18037
Overall Steps per Second: 10,711.64590

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.44857
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.66875

Cumulative Model Updates: 64,706
Cumulative Timesteps: 539,624,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,896.74281
Policy Entropy: 3.72436
Value Function Loss: 0.06349

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.68000
Value Function Update Magnitude: 0.84747

Collected Steps per Second: 22,987.40574
Overall Steps per Second: 10,722.24102

Timestep Collection Time: 2.17554
Timestep Consumption Time: 2.48860
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.66414

Cumulative Model Updates: 64,712
Cumulative Timesteps: 539,674,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 539674104...
Checkpoint 539674104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,131.91012
Policy Entropy: 3.72241
Value Function Loss: 0.06120

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07010
Policy Update Magnitude: 0.74305
Value Function Update Magnitude: 0.89142

Collected Steps per Second: 22,539.99768
Overall Steps per Second: 10,622.88985

Timestep Collection Time: 2.21872
Timestep Consumption Time: 2.48904
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.70776

Cumulative Model Updates: 64,718
Cumulative Timesteps: 539,724,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,597.91591
Policy Entropy: 3.71202
Value Function Loss: 0.06520

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.67469
Value Function Update Magnitude: 0.76463

Collected Steps per Second: 23,033.26100
Overall Steps per Second: 10,954.52388

Timestep Collection Time: 2.17156
Timestep Consumption Time: 2.39441
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.56597

Cumulative Model Updates: 64,724
Cumulative Timesteps: 539,774,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 539774132...
Checkpoint 539774132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,331.14287
Policy Entropy: 3.70089
Value Function Loss: 0.06444

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.75426

Collected Steps per Second: 22,730.60626
Overall Steps per Second: 10,765.25648

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.44763
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.64977

Cumulative Model Updates: 64,730
Cumulative Timesteps: 539,824,188

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,813.59659
Policy Entropy: 3.70753
Value Function Loss: 0.06727

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.52792
Value Function Update Magnitude: 0.78306

Collected Steps per Second: 23,295.04445
Overall Steps per Second: 10,737.43880

Timestep Collection Time: 2.14724
Timestep Consumption Time: 2.51123
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.65847

Cumulative Model Updates: 64,736
Cumulative Timesteps: 539,874,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 539874208...
Checkpoint 539874208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,882.03869
Policy Entropy: 3.71146
Value Function Loss: 0.06557

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.58375
Value Function Update Magnitude: 0.68022

Collected Steps per Second: 22,654.25772
Overall Steps per Second: 10,652.43297

Timestep Collection Time: 2.20727
Timestep Consumption Time: 2.48687
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.69414

Cumulative Model Updates: 64,742
Cumulative Timesteps: 539,924,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,490.66438
Policy Entropy: 3.70292
Value Function Loss: 0.06906

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07771
Policy Update Magnitude: 0.67332
Value Function Update Magnitude: 0.67505

Collected Steps per Second: 22,743.95548
Overall Steps per Second: 10,812.69538

Timestep Collection Time: 2.19865
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62475

Cumulative Model Updates: 64,748
Cumulative Timesteps: 539,974,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 539974218...
Checkpoint 539974218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,261.11906
Policy Entropy: 3.70490
Value Function Loss: 0.06868

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.73502
Value Function Update Magnitude: 0.70117

Collected Steps per Second: 22,279.06806
Overall Steps per Second: 10,717.57473

Timestep Collection Time: 2.24561
Timestep Consumption Time: 2.42243
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.66803

Cumulative Model Updates: 64,754
Cumulative Timesteps: 540,024,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,871.35069
Policy Entropy: 3.69984
Value Function Loss: 0.06863

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.73717
Value Function Update Magnitude: 0.73297

Collected Steps per Second: 22,521.04558
Overall Steps per Second: 10,591.32841

Timestep Collection Time: 2.22032
Timestep Consumption Time: 2.50090
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.72122

Cumulative Model Updates: 64,760
Cumulative Timesteps: 540,074,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 540074252...
Checkpoint 540074252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,659.55029
Policy Entropy: 3.70312
Value Function Loss: 0.06690

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.61375
Value Function Update Magnitude: 0.76340

Collected Steps per Second: 22,518.33041
Overall Steps per Second: 10,635.62474

Timestep Collection Time: 2.22157
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.70363

Cumulative Model Updates: 64,766
Cumulative Timesteps: 540,124,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,181.41062
Policy Entropy: 3.68551
Value Function Loss: 0.06563

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.49419
Value Function Update Magnitude: 0.78941

Collected Steps per Second: 22,884.75521
Overall Steps per Second: 10,796.16025

Timestep Collection Time: 2.18486
Timestep Consumption Time: 2.44642
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.63128

Cumulative Model Updates: 64,772
Cumulative Timesteps: 540,174,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 540174278...
Checkpoint 540174278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,904.56887
Policy Entropy: 3.68504
Value Function Loss: 0.06532

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.46007
Value Function Update Magnitude: 0.75452

Collected Steps per Second: 22,552.50758
Overall Steps per Second: 10,668.26081

Timestep Collection Time: 2.21785
Timestep Consumption Time: 2.47064
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.68849

Cumulative Model Updates: 64,778
Cumulative Timesteps: 540,224,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,024.10354
Policy Entropy: 3.68627
Value Function Loss: 0.06423

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.47422
Value Function Update Magnitude: 0.73034

Collected Steps per Second: 22,824.33770
Overall Steps per Second: 10,816.20504

Timestep Collection Time: 2.19143
Timestep Consumption Time: 2.43292
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.62436

Cumulative Model Updates: 64,784
Cumulative Timesteps: 540,274,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 540274314...
Checkpoint 540274314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,006.43348
Policy Entropy: 3.68752
Value Function Loss: 0.06452

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.45659
Value Function Update Magnitude: 0.72006

Collected Steps per Second: 22,704.72589
Overall Steps per Second: 10,702.59923

Timestep Collection Time: 2.20289
Timestep Consumption Time: 2.47037
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.67326

Cumulative Model Updates: 64,790
Cumulative Timesteps: 540,324,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,157.31436
Policy Entropy: 3.69456
Value Function Loss: 0.06721

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.46054
Value Function Update Magnitude: 0.77359

Collected Steps per Second: 22,491.99830
Overall Steps per Second: 10,604.28998

Timestep Collection Time: 2.22390
Timestep Consumption Time: 2.49306
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.71696

Cumulative Model Updates: 64,796
Cumulative Timesteps: 540,374,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 540374350...
Checkpoint 540374350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,489.77808
Policy Entropy: 3.69872
Value Function Loss: 0.06831

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.43992
Value Function Update Magnitude: 0.73783

Collected Steps per Second: 22,788.26933
Overall Steps per Second: 10,721.38851

Timestep Collection Time: 2.19543
Timestep Consumption Time: 2.47095
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.66637

Cumulative Model Updates: 64,802
Cumulative Timesteps: 540,424,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,765.08733
Policy Entropy: 3.70505
Value Function Loss: 0.06990

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.46677
Value Function Update Magnitude: 0.71810

Collected Steps per Second: 23,111.65304
Overall Steps per Second: 10,767.16920

Timestep Collection Time: 2.16410
Timestep Consumption Time: 2.48113
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.64523

Cumulative Model Updates: 64,808
Cumulative Timesteps: 540,474,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 540474396...
Checkpoint 540474396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,167.13746
Policy Entropy: 3.69893
Value Function Loss: 0.06984

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.49471
Value Function Update Magnitude: 0.71475

Collected Steps per Second: 22,831.43367
Overall Steps per Second: 10,732.44036

Timestep Collection Time: 2.19119
Timestep Consumption Time: 2.47019
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.66138

Cumulative Model Updates: 64,814
Cumulative Timesteps: 540,524,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,506.64146
Policy Entropy: 3.69736
Value Function Loss: 0.06680

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.47768
Value Function Update Magnitude: 0.81183

Collected Steps per Second: 22,168.27566
Overall Steps per Second: 10,727.60711

Timestep Collection Time: 2.25557
Timestep Consumption Time: 2.40549
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.66106

Cumulative Model Updates: 64,820
Cumulative Timesteps: 540,574,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 540574426...
Checkpoint 540574426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.27717
Policy Entropy: 3.69809
Value Function Loss: 0.06460

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.44781
Value Function Update Magnitude: 0.86888

Collected Steps per Second: 22,059.81772
Overall Steps per Second: 10,675.50572

Timestep Collection Time: 2.26684
Timestep Consumption Time: 2.41734
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.68418

Cumulative Model Updates: 64,826
Cumulative Timesteps: 540,624,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,396.10475
Policy Entropy: 3.70078
Value Function Loss: 0.06384

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.54274
Value Function Update Magnitude: 0.88983

Collected Steps per Second: 22,216.00669
Overall Steps per Second: 10,831.62288

Timestep Collection Time: 2.25135
Timestep Consumption Time: 2.36624
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61759

Cumulative Model Updates: 64,832
Cumulative Timesteps: 540,674,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 540674448...
Checkpoint 540674448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,105.61940
Policy Entropy: 3.68417
Value Function Loss: 0.06695

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.52769
Value Function Update Magnitude: 0.87566

Collected Steps per Second: 21,832.38774
Overall Steps per Second: 10,637.52552

Timestep Collection Time: 2.29118
Timestep Consumption Time: 2.41123
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.70241

Cumulative Model Updates: 64,838
Cumulative Timesteps: 540,724,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.02956
Policy Entropy: 3.69062
Value Function Loss: 0.06837

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.45815
Value Function Update Magnitude: 0.86516

Collected Steps per Second: 22,044.75314
Overall Steps per Second: 10,842.47506

Timestep Collection Time: 2.26811
Timestep Consumption Time: 2.34338
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.61149

Cumulative Model Updates: 64,844
Cumulative Timesteps: 540,774,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 540774470...
Checkpoint 540774470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,042.96124
Policy Entropy: 3.68346
Value Function Loss: 0.06903

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.47168
Value Function Update Magnitude: 0.84388

Collected Steps per Second: 21,969.91068
Overall Steps per Second: 10,690.31577

Timestep Collection Time: 2.27657
Timestep Consumption Time: 2.40206
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.67863

Cumulative Model Updates: 64,850
Cumulative Timesteps: 540,824,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,411.84965
Policy Entropy: 3.69743
Value Function Loss: 0.06798

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.46301
Value Function Update Magnitude: 0.75798

Collected Steps per Second: 22,949.25407
Overall Steps per Second: 10,900.48082

Timestep Collection Time: 2.17881
Timestep Consumption Time: 2.40833
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.58714

Cumulative Model Updates: 64,856
Cumulative Timesteps: 540,874,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 540874488...
Checkpoint 540874488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,976.76841
Policy Entropy: 3.69743
Value Function Loss: 0.06716

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.44629
Value Function Update Magnitude: 0.73333

Collected Steps per Second: 22,681.42706
Overall Steps per Second: 10,663.86456

Timestep Collection Time: 2.20656
Timestep Consumption Time: 2.48667
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.69323

Cumulative Model Updates: 64,862
Cumulative Timesteps: 540,924,536

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.14811
Policy Entropy: 3.71608
Value Function Loss: 0.06786

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07500
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.74793

Collected Steps per Second: 22,881.10317
Overall Steps per Second: 10,892.42469

Timestep Collection Time: 2.18600
Timestep Consumption Time: 2.40600
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.59200

Cumulative Model Updates: 64,868
Cumulative Timesteps: 540,974,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 540974554...
Checkpoint 540974554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,746.45873
Policy Entropy: 3.71690
Value Function Loss: 0.06958

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.58910
Value Function Update Magnitude: 0.75918

Collected Steps per Second: 22,523.42198
Overall Steps per Second: 10,688.23166

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.45941
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.68047

Cumulative Model Updates: 64,874
Cumulative Timesteps: 541,024,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,051.88825
Policy Entropy: 3.71280
Value Function Loss: 0.07006

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.54654
Value Function Update Magnitude: 0.74194

Collected Steps per Second: 23,061.45840
Overall Steps per Second: 10,835.28534

Timestep Collection Time: 2.16881
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.61603

Cumulative Model Updates: 64,880
Cumulative Timesteps: 541,074,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 541074596...
Checkpoint 541074596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,015.40245
Policy Entropy: 3.69512
Value Function Loss: 0.06984

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.49401
Value Function Update Magnitude: 0.64143

Collected Steps per Second: 22,514.55434
Overall Steps per Second: 10,682.08988

Timestep Collection Time: 2.22167
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.68260

Cumulative Model Updates: 64,886
Cumulative Timesteps: 541,124,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,087.44958
Policy Entropy: 3.68802
Value Function Loss: 0.06675

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.44344
Value Function Update Magnitude: 0.60858

Collected Steps per Second: 23,044.11549
Overall Steps per Second: 10,862.02238

Timestep Collection Time: 2.16992
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60356

Cumulative Model Updates: 64,892
Cumulative Timesteps: 541,174,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 541174620...
Checkpoint 541174620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,893.04176
Policy Entropy: 3.69344
Value Function Loss: 0.06460

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.48942
Value Function Update Magnitude: 0.65842

Collected Steps per Second: 22,574.84520
Overall Steps per Second: 10,728.60772

Timestep Collection Time: 2.21503
Timestep Consumption Time: 2.44578
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.66081

Cumulative Model Updates: 64,898
Cumulative Timesteps: 541,224,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.48803
Policy Entropy: 3.70400
Value Function Loss: 0.06340

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.46304
Value Function Update Magnitude: 0.73861

Collected Steps per Second: 22,971.55401
Overall Steps per Second: 10,850.14758

Timestep Collection Time: 2.17765
Timestep Consumption Time: 2.43279
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61044

Cumulative Model Updates: 64,904
Cumulative Timesteps: 541,274,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 541274648...
Checkpoint 541274648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,738.69260
Policy Entropy: 3.69973
Value Function Loss: 0.06492

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.46917
Value Function Update Magnitude: 0.75859

Collected Steps per Second: 22,702.66050
Overall Steps per Second: 10,666.88936

Timestep Collection Time: 2.20327
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.68928

Cumulative Model Updates: 64,910
Cumulative Timesteps: 541,324,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,815.56551
Policy Entropy: 3.71180
Value Function Loss: 0.06523

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.75932

Collected Steps per Second: 23,011.55115
Overall Steps per Second: 10,874.73876

Timestep Collection Time: 2.17282
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59781

Cumulative Model Updates: 64,916
Cumulative Timesteps: 541,374,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 541374668...
Checkpoint 541374668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,272.29127
Policy Entropy: 3.70886
Value Function Loss: 0.06214

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.52181
Value Function Update Magnitude: 0.80801

Collected Steps per Second: 22,228.91650
Overall Steps per Second: 10,695.72884

Timestep Collection Time: 2.24968
Timestep Consumption Time: 2.42583
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.67551

Cumulative Model Updates: 64,922
Cumulative Timesteps: 541,424,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,845.76319
Policy Entropy: 3.70865
Value Function Loss: 0.06213

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.51499
Value Function Update Magnitude: 0.83115

Collected Steps per Second: 23,012.87174
Overall Steps per Second: 10,851.04521

Timestep Collection Time: 2.17365
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60988

Cumulative Model Updates: 64,928
Cumulative Timesteps: 541,474,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 541474698...
Checkpoint 541474698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,594.91663
Policy Entropy: 3.69884
Value Function Loss: 0.06293

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.50941
Value Function Update Magnitude: 0.81898

Collected Steps per Second: 22,595.66199
Overall Steps per Second: 10,681.60274

Timestep Collection Time: 2.21335
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.68207

Cumulative Model Updates: 64,934
Cumulative Timesteps: 541,524,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,557.10636
Policy Entropy: 3.69184
Value Function Loss: 0.06481

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.57149
Value Function Update Magnitude: 0.80637

Collected Steps per Second: 22,873.80525
Overall Steps per Second: 10,880.32868

Timestep Collection Time: 2.18634
Timestep Consumption Time: 2.41002
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.59637

Cumulative Model Updates: 64,940
Cumulative Timesteps: 541,574,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 541574720...
Checkpoint 541574720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,565.57694
Policy Entropy: 3.69696
Value Function Loss: 0.06516

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.54795
Value Function Update Magnitude: 0.80140

Collected Steps per Second: 22,540.17445
Overall Steps per Second: 10,670.84493

Timestep Collection Time: 2.21871
Timestep Consumption Time: 2.46790
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.68660

Cumulative Model Updates: 64,946
Cumulative Timesteps: 541,624,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914.11287
Policy Entropy: 3.70829
Value Function Loss: 0.06432

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10768
Policy Update Magnitude: 0.50660
Value Function Update Magnitude: 0.81019

Collected Steps per Second: 22,886.56203
Overall Steps per Second: 10,904.40934

Timestep Collection Time: 2.18478
Timestep Consumption Time: 2.40071
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.58548

Cumulative Model Updates: 64,952
Cumulative Timesteps: 541,674,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 541674732...
Checkpoint 541674732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,542.75724
Policy Entropy: 3.71473
Value Function Loss: 0.06292

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.55352
Value Function Update Magnitude: 0.75803

Collected Steps per Second: 22,612.81181
Overall Steps per Second: 10,616.91135

Timestep Collection Time: 2.21114
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.70947

Cumulative Model Updates: 64,958
Cumulative Timesteps: 541,724,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,702.73553
Policy Entropy: 3.72028
Value Function Loss: 0.06467

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10030
Policy Update Magnitude: 0.60463
Value Function Update Magnitude: 0.76871

Collected Steps per Second: 22,934.56930
Overall Steps per Second: 10,838.02535

Timestep Collection Time: 2.18081
Timestep Consumption Time: 2.43405
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.61486

Cumulative Model Updates: 64,964
Cumulative Timesteps: 541,774,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 541774748...
Checkpoint 541774748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,136.56224
Policy Entropy: 3.69372
Value Function Loss: 0.06459

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.65877
Value Function Update Magnitude: 0.84187

Collected Steps per Second: 22,595.76816
Overall Steps per Second: 10,708.76216

Timestep Collection Time: 2.21333
Timestep Consumption Time: 2.45686
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.67019

Cumulative Model Updates: 64,970
Cumulative Timesteps: 541,824,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,084.98151
Policy Entropy: 3.70191
Value Function Loss: 0.06321

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.69110
Value Function Update Magnitude: 0.86146

Collected Steps per Second: 22,630.68292
Overall Steps per Second: 10,670.34273

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.68589

Cumulative Model Updates: 64,976
Cumulative Timesteps: 541,874,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 541874760...
Checkpoint 541874760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,536.47598
Policy Entropy: 3.69816
Value Function Loss: 0.06204

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06724
Policy Update Magnitude: 0.72688
Value Function Update Magnitude: 0.82581

Collected Steps per Second: 22,510.87886
Overall Steps per Second: 10,754.78680

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.65077

Cumulative Model Updates: 64,982
Cumulative Timesteps: 541,924,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,790.02564
Policy Entropy: 3.70410
Value Function Loss: 0.06750

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.64508
Value Function Update Magnitude: 0.74086

Collected Steps per Second: 22,760.93563
Overall Steps per Second: 10,649.72614

Timestep Collection Time: 2.19719
Timestep Consumption Time: 2.49871
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.69590

Cumulative Model Updates: 64,988
Cumulative Timesteps: 541,974,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 541974788...
Checkpoint 541974788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,813.70253
Policy Entropy: 3.69160
Value Function Loss: 0.07123

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.16098
Policy Update Magnitude: 0.56757
Value Function Update Magnitude: 0.74021

Collected Steps per Second: 22,765.83968
Overall Steps per Second: 10,672.39002

Timestep Collection Time: 2.19689
Timestep Consumption Time: 2.48941
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.68630

Cumulative Model Updates: 64,994
Cumulative Timesteps: 542,024,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,886.68620
Policy Entropy: 3.69011
Value Function Loss: 0.07180

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.52005
Value Function Update Magnitude: 0.78595

Collected Steps per Second: 22,846.71743
Overall Steps per Second: 10,850.68974

Timestep Collection Time: 2.18981
Timestep Consumption Time: 2.42096
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.61077

Cumulative Model Updates: 65,000
Cumulative Timesteps: 542,074,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 542074832...
Checkpoint 542074832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,847.57080
Policy Entropy: 3.69070
Value Function Loss: 0.06723

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.59358
Value Function Update Magnitude: 0.75803

Collected Steps per Second: 22,651.82362
Overall Steps per Second: 10,588.95985

Timestep Collection Time: 2.20733
Timestep Consumption Time: 2.51457
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.72190

Cumulative Model Updates: 65,006
Cumulative Timesteps: 542,124,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,426.86561
Policy Entropy: 3.70461
Value Function Loss: 0.06326

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.58382
Value Function Update Magnitude: 0.69350

Collected Steps per Second: 22,277.83518
Overall Steps per Second: 10,549.31628

Timestep Collection Time: 2.24600
Timestep Consumption Time: 2.49706
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.74306

Cumulative Model Updates: 65,012
Cumulative Timesteps: 542,174,868

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 542174868...
Checkpoint 542174868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,627.04923
Policy Entropy: 3.69739
Value Function Loss: 0.06507

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.61431
Value Function Update Magnitude: 0.68480

Collected Steps per Second: 22,829.49626
Overall Steps per Second: 10,716.71716

Timestep Collection Time: 2.19059
Timestep Consumption Time: 2.47595
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.66654

Cumulative Model Updates: 65,018
Cumulative Timesteps: 542,224,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,875.17196
Policy Entropy: 3.70244
Value Function Loss: 0.06573

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.59065
Value Function Update Magnitude: 0.70494

Collected Steps per Second: 23,219.06882
Overall Steps per Second: 10,701.20615

Timestep Collection Time: 2.15349
Timestep Consumption Time: 2.51907
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.67256

Cumulative Model Updates: 65,024
Cumulative Timesteps: 542,274,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 542274880...
Checkpoint 542274880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,969.11424
Policy Entropy: 3.70287
Value Function Loss: 0.06575

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.56602
Value Function Update Magnitude: 0.67944

Collected Steps per Second: 22,776.30838
Overall Steps per Second: 10,634.89308

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.50654
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.70207

Cumulative Model Updates: 65,030
Cumulative Timesteps: 542,324,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,301.25574
Policy Entropy: 3.69883
Value Function Loss: 0.06196

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06689
Policy Update Magnitude: 0.61618
Value Function Update Magnitude: 0.67144

Collected Steps per Second: 22,903.08584
Overall Steps per Second: 10,853.84059

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60943

Cumulative Model Updates: 65,036
Cumulative Timesteps: 542,374,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 542374916...
Checkpoint 542374916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,945.05940
Policy Entropy: 3.70344
Value Function Loss: 0.06234

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06767
Policy Update Magnitude: 0.65935
Value Function Update Magnitude: 0.64443

Collected Steps per Second: 22,566.69787
Overall Steps per Second: 10,712.27916

Timestep Collection Time: 2.21583
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.66791

Cumulative Model Updates: 65,042
Cumulative Timesteps: 542,424,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,947.52743
Policy Entropy: 3.71539
Value Function Loss: 0.06339

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.58904
Value Function Update Magnitude: 0.67045

Collected Steps per Second: 22,223.51462
Overall Steps per Second: 10,847.18864

Timestep Collection Time: 2.25077
Timestep Consumption Time: 2.36056
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61133

Cumulative Model Updates: 65,048
Cumulative Timesteps: 542,474,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 542474940...
Checkpoint 542474940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,750.10218
Policy Entropy: 3.71071
Value Function Loss: 0.06382

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.48645
Value Function Update Magnitude: 0.67172

Collected Steps per Second: 21,759.06556
Overall Steps per Second: 10,693.71986

Timestep Collection Time: 2.29909
Timestep Consumption Time: 2.37899
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.67807

Cumulative Model Updates: 65,054
Cumulative Timesteps: 542,524,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,745.89749
Policy Entropy: 3.70911
Value Function Loss: 0.06004

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.47612
Value Function Update Magnitude: 0.71957

Collected Steps per Second: 21,315.01780
Overall Steps per Second: 10,470.01458

Timestep Collection Time: 2.34689
Timestep Consumption Time: 2.43094
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.77783

Cumulative Model Updates: 65,060
Cumulative Timesteps: 542,574,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 542574990...
Checkpoint 542574990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,376.25941
Policy Entropy: 3.71201
Value Function Loss: 0.05812

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.52816
Value Function Update Magnitude: 0.73783

Collected Steps per Second: 21,896.10266
Overall Steps per Second: 10,655.73124

Timestep Collection Time: 2.28397
Timestep Consumption Time: 2.40928
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.69325

Cumulative Model Updates: 65,066
Cumulative Timesteps: 542,625,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,888.84658
Policy Entropy: 3.72556
Value Function Loss: 0.05620

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.59075
Value Function Update Magnitude: 0.83110

Collected Steps per Second: 22,188.51856
Overall Steps per Second: 10,840.26183

Timestep Collection Time: 2.25396
Timestep Consumption Time: 2.35958
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.61354

Cumulative Model Updates: 65,072
Cumulative Timesteps: 542,675,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 542675012...
Checkpoint 542675012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,167.29383
Policy Entropy: 3.73017
Value Function Loss: 0.05608

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.54574
Value Function Update Magnitude: 0.88607

Collected Steps per Second: 21,851.47707
Overall Steps per Second: 10,640.55268

Timestep Collection Time: 2.28872
Timestep Consumption Time: 2.41141
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.70013

Cumulative Model Updates: 65,078
Cumulative Timesteps: 542,725,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,799.54552
Policy Entropy: 3.72470
Value Function Loss: 0.05458

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.51564
Value Function Update Magnitude: 0.88311

Collected Steps per Second: 23,007.55486
Overall Steps per Second: 10,943.23785

Timestep Collection Time: 2.17442
Timestep Consumption Time: 2.39717
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.57159

Cumulative Model Updates: 65,084
Cumulative Timesteps: 542,775,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 542775052...
Checkpoint 542775052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,975.68128
Policy Entropy: 3.72406
Value Function Loss: 0.05431

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.48825
Value Function Update Magnitude: 0.85156

Collected Steps per Second: 22,619.21954
Overall Steps per Second: 10,656.87033

Timestep Collection Time: 2.21175
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.69444

Cumulative Model Updates: 65,090
Cumulative Timesteps: 542,825,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,421.68308
Policy Entropy: 3.72822
Value Function Loss: 0.05542

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.84899

Collected Steps per Second: 22,888.71718
Overall Steps per Second: 10,880.37078

Timestep Collection Time: 2.18536
Timestep Consumption Time: 2.41191
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.59727

Cumulative Model Updates: 65,096
Cumulative Timesteps: 542,875,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 542875100...
Checkpoint 542875100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,089.63882
Policy Entropy: 3.73080
Value Function Loss: 0.05549

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.50537
Value Function Update Magnitude: 0.83977

Collected Steps per Second: 22,497.76068
Overall Steps per Second: 10,669.21038

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.68732

Cumulative Model Updates: 65,102
Cumulative Timesteps: 542,925,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,165.78850
Policy Entropy: 3.72746
Value Function Loss: 0.05490

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.49664
Value Function Update Magnitude: 0.84630

Collected Steps per Second: 22,774.23546
Overall Steps per Second: 10,819.77320

Timestep Collection Time: 2.19555
Timestep Consumption Time: 2.42580
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.62135

Cumulative Model Updates: 65,108
Cumulative Timesteps: 542,975,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 542975112...
Checkpoint 542975112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,964.46997
Policy Entropy: 3.72626
Value Function Loss: 0.05516

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.81751

Collected Steps per Second: 22,677.22918
Overall Steps per Second: 10,735.46133

Timestep Collection Time: 2.20494
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.65765

Cumulative Model Updates: 65,114
Cumulative Timesteps: 543,025,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,090.79438
Policy Entropy: 3.72234
Value Function Loss: 0.05468

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.52059
Value Function Update Magnitude: 0.76948

Collected Steps per Second: 23,008.53662
Overall Steps per Second: 10,850.06589

Timestep Collection Time: 2.17354
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60919

Cumulative Model Updates: 65,120
Cumulative Timesteps: 543,075,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 543075124...
Checkpoint 543075124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,440.33361
Policy Entropy: 3.72565
Value Function Loss: 0.05572

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.55111
Value Function Update Magnitude: 0.79211

Collected Steps per Second: 22,667.36081
Overall Steps per Second: 10,651.16135

Timestep Collection Time: 2.20608
Timestep Consumption Time: 2.48881
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.69489

Cumulative Model Updates: 65,126
Cumulative Timesteps: 543,125,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,881.58633
Policy Entropy: 3.72100
Value Function Loss: 0.05493

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.82052

Collected Steps per Second: 22,891.07094
Overall Steps per Second: 10,842.89936

Timestep Collection Time: 2.18452
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.61187

Cumulative Model Updates: 65,132
Cumulative Timesteps: 543,175,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 543175136...
Checkpoint 543175136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,142.11856
Policy Entropy: 3.72008
Value Function Loss: 0.05690

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.54730
Value Function Update Magnitude: 0.81533

Collected Steps per Second: 22,532.36087
Overall Steps per Second: 10,777.95269

Timestep Collection Time: 2.21921
Timestep Consumption Time: 2.42026
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.63947

Cumulative Model Updates: 65,138
Cumulative Timesteps: 543,225,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,753.82902
Policy Entropy: 3.71604
Value Function Loss: 0.05479

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.55900
Value Function Update Magnitude: 0.79459

Collected Steps per Second: 22,916.11792
Overall Steps per Second: 10,816.58211

Timestep Collection Time: 2.18300
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62494

Cumulative Model Updates: 65,144
Cumulative Timesteps: 543,275,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 543275166...
Checkpoint 543275166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,467.80874
Policy Entropy: 3.71055
Value Function Loss: 0.05497

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07689
Policy Update Magnitude: 0.58157
Value Function Update Magnitude: 0.79961

Collected Steps per Second: 22,504.94115
Overall Steps per Second: 10,781.01669

Timestep Collection Time: 2.22236
Timestep Consumption Time: 2.41672
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.63908

Cumulative Model Updates: 65,150
Cumulative Timesteps: 543,325,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,520.63949
Policy Entropy: 3.69986
Value Function Loss: 0.05542

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.66879
Value Function Update Magnitude: 0.80253

Collected Steps per Second: 22,785.42997
Overall Steps per Second: 10,800.48522

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.63053

Cumulative Model Updates: 65,156
Cumulative Timesteps: 543,375,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 543375192...
Checkpoint 543375192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,682.73311
Policy Entropy: 3.71282
Value Function Loss: 0.05536

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07915
Policy Update Magnitude: 0.66226
Value Function Update Magnitude: 0.80993

Collected Steps per Second: 22,532.93103
Overall Steps per Second: 10,714.30385

Timestep Collection Time: 2.21968
Timestep Consumption Time: 2.44847
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.66815

Cumulative Model Updates: 65,162
Cumulative Timesteps: 543,425,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,307.70916
Policy Entropy: 3.72169
Value Function Loss: 0.05582

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.59634
Value Function Update Magnitude: 0.83485

Collected Steps per Second: 23,249.28760
Overall Steps per Second: 10,921.64522

Timestep Collection Time: 2.15121
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.57935

Cumulative Model Updates: 65,168
Cumulative Timesteps: 543,475,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 543475222...
Checkpoint 543475222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.75510
Policy Entropy: 3.72832
Value Function Loss: 0.05688

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.57744
Value Function Update Magnitude: 0.81665

Collected Steps per Second: 22,587.54413
Overall Steps per Second: 10,590.84077

Timestep Collection Time: 2.21361
Timestep Consumption Time: 2.50745
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.72106

Cumulative Model Updates: 65,174
Cumulative Timesteps: 543,525,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,419.20280
Policy Entropy: 3.70334
Value Function Loss: 0.05997

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.51818
Value Function Update Magnitude: 0.79059

Collected Steps per Second: 22,328.32615
Overall Steps per Second: 10,531.37442

Timestep Collection Time: 2.23940
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.74791

Cumulative Model Updates: 65,180
Cumulative Timesteps: 543,575,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 543575224...
Checkpoint 543575224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,823.43779
Policy Entropy: 3.69247
Value Function Loss: 0.06417

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.49331
Value Function Update Magnitude: 0.79724

Collected Steps per Second: 22,375.74342
Overall Steps per Second: 10,560.18793

Timestep Collection Time: 2.23572
Timestep Consumption Time: 2.50150
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.73723

Cumulative Model Updates: 65,186
Cumulative Timesteps: 543,625,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,667.96130
Policy Entropy: 3.67598
Value Function Loss: 0.06402

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.16525
Policy Update Magnitude: 0.43807
Value Function Update Magnitude: 0.82225

Collected Steps per Second: 23,081.20625
Overall Steps per Second: 10,875.17825

Timestep Collection Time: 2.16644
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.59799

Cumulative Model Updates: 65,192
Cumulative Timesteps: 543,675,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 543675254...
Checkpoint 543675254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,784.73674
Policy Entropy: 3.68726
Value Function Loss: 0.06316

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.40116
Value Function Update Magnitude: 0.81423

Collected Steps per Second: 22,523.84859
Overall Steps per Second: 10,689.97435

Timestep Collection Time: 2.21987
Timestep Consumption Time: 2.45741
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.67728

Cumulative Model Updates: 65,198
Cumulative Timesteps: 543,725,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,439.49456
Policy Entropy: 3.69582
Value Function Loss: 0.05919

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.42714
Value Function Update Magnitude: 0.79632

Collected Steps per Second: 22,442.53141
Overall Steps per Second: 10,615.73672

Timestep Collection Time: 2.22809
Timestep Consumption Time: 2.48227
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.71037

Cumulative Model Updates: 65,204
Cumulative Timesteps: 543,775,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 543775258...
Checkpoint 543775258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,359.87080
Policy Entropy: 3.71562
Value Function Loss: 0.05721

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.42006
Value Function Update Magnitude: 0.78345

Collected Steps per Second: 22,915.14132
Overall Steps per Second: 10,873.03658

Timestep Collection Time: 2.18284
Timestep Consumption Time: 2.41753
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60037

Cumulative Model Updates: 65,210
Cumulative Timesteps: 543,825,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,398.76577
Policy Entropy: 3.72155
Value Function Loss: 0.05666

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.44193
Value Function Update Magnitude: 0.75174

Collected Steps per Second: 22,940.06154
Overall Steps per Second: 10,720.21075

Timestep Collection Time: 2.18177
Timestep Consumption Time: 2.48698
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.66875

Cumulative Model Updates: 65,216
Cumulative Timesteps: 543,875,328

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 543875328...
Checkpoint 543875328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,387.89566
Policy Entropy: 3.72094
Value Function Loss: 0.05494

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.43508
Value Function Update Magnitude: 0.75072

Collected Steps per Second: 22,467.40523
Overall Steps per Second: 10,781.74159

Timestep Collection Time: 2.22580
Timestep Consumption Time: 2.41241
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.63821

Cumulative Model Updates: 65,222
Cumulative Timesteps: 543,925,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,703.42635
Policy Entropy: 3.71052
Value Function Loss: 0.05223

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.42590
Value Function Update Magnitude: 0.79787

Collected Steps per Second: 23,049.19300
Overall Steps per Second: 10,765.93526

Timestep Collection Time: 2.16971
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.64521

Cumulative Model Updates: 65,228
Cumulative Timesteps: 543,975,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 543975346...
Checkpoint 543975346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,132.27278
Policy Entropy: 3.72064
Value Function Loss: 0.04934

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.44975
Value Function Update Magnitude: 0.74515

Collected Steps per Second: 22,471.39920
Overall Steps per Second: 10,773.44095

Timestep Collection Time: 2.22558
Timestep Consumption Time: 2.41657
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.64216

Cumulative Model Updates: 65,234
Cumulative Timesteps: 544,025,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.80397
Policy Entropy: 3.73199
Value Function Loss: 0.04677

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.49749
Value Function Update Magnitude: 0.72731

Collected Steps per Second: 22,921.43939
Overall Steps per Second: 10,735.95961

Timestep Collection Time: 2.18171
Timestep Consumption Time: 2.47628
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.65799

Cumulative Model Updates: 65,240
Cumulative Timesteps: 544,075,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 544075366...
Checkpoint 544075366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,429.94904
Policy Entropy: 3.72878
Value Function Loss: 0.04732

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.59895
Value Function Update Magnitude: 0.74524

Collected Steps per Second: 22,819.71617
Overall Steps per Second: 10,844.28887

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.42002
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61146

Cumulative Model Updates: 65,246
Cumulative Timesteps: 544,125,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,992.02979
Policy Entropy: 3.73603
Value Function Loss: 0.04731

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.61025
Value Function Update Magnitude: 0.74103

Collected Steps per Second: 22,130.25169
Overall Steps per Second: 10,845.67358

Timestep Collection Time: 2.26080
Timestep Consumption Time: 2.35229
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.61308

Cumulative Model Updates: 65,252
Cumulative Timesteps: 544,175,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 544175406...
Checkpoint 544175406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,179.71195
Policy Entropy: 3.73742
Value Function Loss: 0.04833

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.56252
Value Function Update Magnitude: 0.73185

Collected Steps per Second: 21,959.94436
Overall Steps per Second: 10,754.72602

Timestep Collection Time: 2.27687
Timestep Consumption Time: 2.37225
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.64912

Cumulative Model Updates: 65,258
Cumulative Timesteps: 544,225,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,020.36118
Policy Entropy: 3.74866
Value Function Loss: 0.04860

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.54138
Value Function Update Magnitude: 0.74483

Collected Steps per Second: 22,290.09510
Overall Steps per Second: 10,835.85814

Timestep Collection Time: 2.24351
Timestep Consumption Time: 2.37154
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.61505

Cumulative Model Updates: 65,264
Cumulative Timesteps: 544,275,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 544275414...
Checkpoint 544275414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,488.59469
Policy Entropy: 3.74392
Value Function Loss: 0.04922

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06463
Policy Update Magnitude: 0.60269
Value Function Update Magnitude: 0.75788

Collected Steps per Second: 21,772.57171
Overall Steps per Second: 10,709.28132

Timestep Collection Time: 2.29702
Timestep Consumption Time: 2.37295
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.66997

Cumulative Model Updates: 65,270
Cumulative Timesteps: 544,325,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,385.90685
Policy Entropy: 3.73903
Value Function Loss: 0.04824

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05782
Policy Update Magnitude: 0.68039
Value Function Update Magnitude: 0.76620

Collected Steps per Second: 22,276.82791
Overall Steps per Second: 10,890.29216

Timestep Collection Time: 2.24547
Timestep Consumption Time: 2.34779
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.59327

Cumulative Model Updates: 65,276
Cumulative Timesteps: 544,375,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 544375448...
Checkpoint 544375448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,749.12361
Policy Entropy: 3.73018
Value Function Loss: 0.04962

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05672
Policy Update Magnitude: 0.68923
Value Function Update Magnitude: 0.74890

Collected Steps per Second: 21,645.07690
Overall Steps per Second: 10,615.27489

Timestep Collection Time: 2.31101
Timestep Consumption Time: 2.40126
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.71227

Cumulative Model Updates: 65,282
Cumulative Timesteps: 544,425,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,118.74754
Policy Entropy: 3.73062
Value Function Loss: 0.05170

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06479
Policy Update Magnitude: 0.67831
Value Function Update Magnitude: 0.74934

Collected Steps per Second: 22,898.01896
Overall Steps per Second: 10,879.96066

Timestep Collection Time: 2.18377
Timestep Consumption Time: 2.41220
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.59597

Cumulative Model Updates: 65,288
Cumulative Timesteps: 544,475,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 544475474...
Checkpoint 544475474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,012.19295
Policy Entropy: 3.73287
Value Function Loss: 0.05199

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06261
Policy Update Magnitude: 0.66238
Value Function Update Magnitude: 0.76600

Collected Steps per Second: 22,348.52304
Overall Steps per Second: 10,678.81016

Timestep Collection Time: 2.23845
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.68460

Cumulative Model Updates: 65,294
Cumulative Timesteps: 544,525,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,621.11147
Policy Entropy: 3.72618
Value Function Loss: 0.05225

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06151
Policy Update Magnitude: 0.63832
Value Function Update Magnitude: 0.78264

Collected Steps per Second: 22,849.58154
Overall Steps per Second: 10,890.17362

Timestep Collection Time: 2.18919
Timestep Consumption Time: 2.40413
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.59332

Cumulative Model Updates: 65,300
Cumulative Timesteps: 544,575,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 544575522...
Checkpoint 544575522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,632.82474
Policy Entropy: 3.72093
Value Function Loss: 0.05261

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06084
Policy Update Magnitude: 0.67429
Value Function Update Magnitude: 0.76935

Collected Steps per Second: 22,509.56094
Overall Steps per Second: 10,682.56030

Timestep Collection Time: 2.22261
Timestep Consumption Time: 2.46072
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.68333

Cumulative Model Updates: 65,306
Cumulative Timesteps: 544,625,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,710.68599
Policy Entropy: 3.72738
Value Function Loss: 0.05356

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.62656
Value Function Update Magnitude: 0.76958

Collected Steps per Second: 23,064.10413
Overall Steps per Second: 10,839.72602

Timestep Collection Time: 2.16908
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61525

Cumulative Model Updates: 65,312
Cumulative Timesteps: 544,675,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 544675580...
Checkpoint 544675580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,447.27093
Policy Entropy: 3.72664
Value Function Loss: 0.05544

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.56635
Value Function Update Magnitude: 0.76466

Collected Steps per Second: 22,735.67945
Overall Steps per Second: 10,682.70034

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.68121

Cumulative Model Updates: 65,318
Cumulative Timesteps: 544,725,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,306.09676
Policy Entropy: 3.72751
Value Function Loss: 0.05438

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.51720
Value Function Update Magnitude: 0.77601

Collected Steps per Second: 22,846.74916
Overall Steps per Second: 10,840.93489

Timestep Collection Time: 2.18946
Timestep Consumption Time: 2.42472
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61418

Cumulative Model Updates: 65,324
Cumulative Timesteps: 544,775,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 544775610...
Checkpoint 544775610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,983.55399
Policy Entropy: 3.69875
Value Function Loss: 0.05432

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.50588
Value Function Update Magnitude: 0.77008

Collected Steps per Second: 22,453.95372
Overall Steps per Second: 10,763.03926

Timestep Collection Time: 2.22687
Timestep Consumption Time: 2.41885
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.64571

Cumulative Model Updates: 65,330
Cumulative Timesteps: 544,825,612

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,897.00949
Policy Entropy: 3.69363
Value Function Loss: 0.05565

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.48370
Value Function Update Magnitude: 0.75413

Collected Steps per Second: 22,866.14215
Overall Steps per Second: 10,834.78132

Timestep Collection Time: 2.18760
Timestep Consumption Time: 2.42920
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.61680

Cumulative Model Updates: 65,336
Cumulative Timesteps: 544,875,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 544875634...
Checkpoint 544875634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,385.96729
Policy Entropy: 3.70396
Value Function Loss: 0.05897

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.45877
Value Function Update Magnitude: 0.72948

Collected Steps per Second: 22,572.22050
Overall Steps per Second: 10,697.29878

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.67595

Cumulative Model Updates: 65,342
Cumulative Timesteps: 544,925,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.26202
Policy Entropy: 3.71407
Value Function Loss: 0.06182

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.48862
Value Function Update Magnitude: 0.67708

Collected Steps per Second: 22,857.92437
Overall Steps per Second: 10,816.36707

Timestep Collection Time: 2.18769
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.62318

Cumulative Model Updates: 65,348
Cumulative Timesteps: 544,975,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 544975660...
Checkpoint 544975660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,286.83594
Policy Entropy: 3.71581
Value Function Loss: 0.06347

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.52075
Value Function Update Magnitude: 0.66504

Collected Steps per Second: 22,422.52662
Overall Steps per Second: 10,777.22570

Timestep Collection Time: 2.23106
Timestep Consumption Time: 2.41077
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.64183

Cumulative Model Updates: 65,354
Cumulative Timesteps: 545,025,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,698.76083
Policy Entropy: 3.71286
Value Function Loss: 0.06353

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.50159
Value Function Update Magnitude: 0.64123

Collected Steps per Second: 22,825.22061
Overall Steps per Second: 10,810.92856

Timestep Collection Time: 2.19161
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62717

Cumulative Model Updates: 65,360
Cumulative Timesteps: 545,075,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 545075710...
Checkpoint 545075710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,443.70322
Policy Entropy: 3.71688
Value Function Loss: 0.06337

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.59978
Value Function Update Magnitude: 0.72953

Collected Steps per Second: 22,458.06966
Overall Steps per Second: 10,676.49368

Timestep Collection Time: 2.22780
Timestep Consumption Time: 2.45839
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.68618

Cumulative Model Updates: 65,366
Cumulative Timesteps: 545,125,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,036.86732
Policy Entropy: 3.72600
Value Function Loss: 0.06295

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.60066
Value Function Update Magnitude: 0.75892

Collected Steps per Second: 22,983.90309
Overall Steps per Second: 10,861.95383

Timestep Collection Time: 2.17665
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60580

Cumulative Model Updates: 65,372
Cumulative Timesteps: 545,175,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 545175770...
Checkpoint 545175770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,235.85130
Policy Entropy: 3.72482
Value Function Loss: 0.06202

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.48588
Value Function Update Magnitude: 0.77828

Collected Steps per Second: 22,377.17809
Overall Steps per Second: 10,742.35369

Timestep Collection Time: 2.23504
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.65578

Cumulative Model Updates: 65,378
Cumulative Timesteps: 545,225,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,640.00179
Policy Entropy: 3.72462
Value Function Loss: 0.06069

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.49794
Value Function Update Magnitude: 0.81452

Collected Steps per Second: 23,354.19418
Overall Steps per Second: 10,864.46715

Timestep Collection Time: 2.14103
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.60234

Cumulative Model Updates: 65,384
Cumulative Timesteps: 545,275,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 545275786...
Checkpoint 545275786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,208.29283
Policy Entropy: 3.71954
Value Function Loss: 0.05960

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.52062
Value Function Update Magnitude: 0.82965

Collected Steps per Second: 21,985.52431
Overall Steps per Second: 10,645.85484

Timestep Collection Time: 2.27504
Timestep Consumption Time: 2.42331
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.69835

Cumulative Model Updates: 65,390
Cumulative Timesteps: 545,325,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,624.85453
Policy Entropy: 3.70601
Value Function Loss: 0.05882

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.52547
Value Function Update Magnitude: 0.84313

Collected Steps per Second: 22,265.58961
Overall Steps per Second: 10,861.66959

Timestep Collection Time: 2.24705
Timestep Consumption Time: 2.35924
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60629

Cumulative Model Updates: 65,396
Cumulative Timesteps: 545,375,836

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 545375836...
Checkpoint 545375836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,781.85480
Policy Entropy: 3.70882
Value Function Loss: 0.05836

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.60433
Value Function Update Magnitude: 0.84366

Collected Steps per Second: 21,966.84078
Overall Steps per Second: 10,663.78081

Timestep Collection Time: 2.27698
Timestep Consumption Time: 2.41348
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.69046

Cumulative Model Updates: 65,402
Cumulative Timesteps: 545,425,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,443.79645
Policy Entropy: 3.71514
Value Function Loss: 0.05911

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.55233
Value Function Update Magnitude: 0.83424

Collected Steps per Second: 22,100.94965
Overall Steps per Second: 10,838.97310

Timestep Collection Time: 2.26271
Timestep Consumption Time: 2.35101
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.61372

Cumulative Model Updates: 65,408
Cumulative Timesteps: 545,475,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 545475862...
Checkpoint 545475862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,928.61576
Policy Entropy: 3.73243
Value Function Loss: 0.05923

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.42439
Value Function Update Magnitude: 0.77553

Collected Steps per Second: 21,859.09099
Overall Steps per Second: 10,688.30619

Timestep Collection Time: 2.28784
Timestep Consumption Time: 2.39111
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.67895

Cumulative Model Updates: 65,414
Cumulative Timesteps: 545,525,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,902.83043
Policy Entropy: 3.75061
Value Function Loss: 0.06183

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.39065
Value Function Update Magnitude: 0.66340

Collected Steps per Second: 22,405.02721
Overall Steps per Second: 10,892.89987

Timestep Collection Time: 2.23271
Timestep Consumption Time: 2.35964
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.59235

Cumulative Model Updates: 65,420
Cumulative Timesteps: 545,575,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 545575896...
Checkpoint 545575896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.95439
Policy Entropy: 3.75153
Value Function Loss: 0.06279

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.38387
Value Function Update Magnitude: 0.60970

Collected Steps per Second: 22,106.03561
Overall Steps per Second: 10,690.01088

Timestep Collection Time: 2.26291
Timestep Consumption Time: 2.41660
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.67951

Cumulative Model Updates: 65,426
Cumulative Timesteps: 545,625,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,923.77149
Policy Entropy: 3.75354
Value Function Loss: 0.06282

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.37746
Value Function Update Magnitude: 0.62033

Collected Steps per Second: 22,660.55920
Overall Steps per Second: 10,817.99666

Timestep Collection Time: 2.20665
Timestep Consumption Time: 2.41564
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.62230

Cumulative Model Updates: 65,432
Cumulative Timesteps: 545,675,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 545675924...
Checkpoint 545675924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,830.01552
Policy Entropy: 3.74426
Value Function Loss: 0.06186

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.37295
Value Function Update Magnitude: 0.60400

Collected Steps per Second: 22,494.60196
Overall Steps per Second: 10,684.76405

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.67975

Cumulative Model Updates: 65,438
Cumulative Timesteps: 545,725,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.96567
Policy Entropy: 3.75348
Value Function Loss: 0.05890

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.38325
Value Function Update Magnitude: 0.64793

Collected Steps per Second: 22,780.47117
Overall Steps per Second: 10,887.90369

Timestep Collection Time: 2.19513
Timestep Consumption Time: 2.39768
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.59280

Cumulative Model Updates: 65,444
Cumulative Timesteps: 545,775,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 545775932...
Checkpoint 545775932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,815.48318
Policy Entropy: 3.76321
Value Function Loss: 0.05590

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.40830
Value Function Update Magnitude: 0.60843

Collected Steps per Second: 22,379.08398
Overall Steps per Second: 10,666.71989

Timestep Collection Time: 2.23530
Timestep Consumption Time: 2.45443
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.68973

Cumulative Model Updates: 65,450
Cumulative Timesteps: 545,825,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,137.79699
Policy Entropy: 3.76717
Value Function Loss: 0.05013

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.40201
Value Function Update Magnitude: 0.67831

Collected Steps per Second: 22,926.65241
Overall Steps per Second: 10,889.21863

Timestep Collection Time: 2.18165
Timestep Consumption Time: 2.41170
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.59335

Cumulative Model Updates: 65,456
Cumulative Timesteps: 545,875,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 545875974...
Checkpoint 545875974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,157.36690
Policy Entropy: 3.76208
Value Function Loss: 0.04837

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.44827
Value Function Update Magnitude: 0.73486

Collected Steps per Second: 22,396.08676
Overall Steps per Second: 10,641.83860

Timestep Collection Time: 2.23414
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.70182

Cumulative Model Updates: 65,462
Cumulative Timesteps: 545,926,010

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.57258
Policy Entropy: 3.75259
Value Function Loss: 0.04992

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06358
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.72571

Collected Steps per Second: 22,717.97100
Overall Steps per Second: 10,857.89152

Timestep Collection Time: 2.20169
Timestep Consumption Time: 2.40491
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.60660

Cumulative Model Updates: 65,468
Cumulative Timesteps: 545,976,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 545976028...
Checkpoint 545976028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,386.91206
Policy Entropy: 3.73917
Value Function Loss: 0.05134

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07340
Policy Update Magnitude: 0.62788
Value Function Update Magnitude: 0.73207

Collected Steps per Second: 22,603.24955
Overall Steps per Second: 10,712.35053

Timestep Collection Time: 2.21216
Timestep Consumption Time: 2.45554
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.66770

Cumulative Model Updates: 65,474
Cumulative Timesteps: 546,026,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,170.25229
Policy Entropy: 3.74122
Value Function Loss: 0.05234

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.58646
Value Function Update Magnitude: 0.74008

Collected Steps per Second: 23,157.99014
Overall Steps per Second: 10,895.08996

Timestep Collection Time: 2.16029
Timestep Consumption Time: 2.43150
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59179

Cumulative Model Updates: 65,480
Cumulative Timesteps: 546,076,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 546076058...
Checkpoint 546076058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,827.92505
Policy Entropy: 3.74419
Value Function Loss: 0.05190

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08200
Policy Update Magnitude: 0.60650
Value Function Update Magnitude: 0.73435

Collected Steps per Second: 22,637.43237
Overall Steps per Second: 10,646.61490

Timestep Collection Time: 2.20988
Timestep Consumption Time: 2.48889
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.69877

Cumulative Model Updates: 65,486
Cumulative Timesteps: 546,126,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,275.75512
Policy Entropy: 3.74007
Value Function Loss: 0.05098

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.57667
Value Function Update Magnitude: 0.72115

Collected Steps per Second: 22,681.00733
Overall Steps per Second: 10,679.04732

Timestep Collection Time: 2.20546
Timestep Consumption Time: 2.47867
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.68413

Cumulative Model Updates: 65,492
Cumulative Timesteps: 546,176,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 546176106...
Checkpoint 546176106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,191.34611
Policy Entropy: 3.74910
Value Function Loss: 0.05097

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.72498

Collected Steps per Second: 22,554.66754
Overall Steps per Second: 10,846.19016

Timestep Collection Time: 2.21799
Timestep Consumption Time: 2.39432
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.61231

Cumulative Model Updates: 65,498
Cumulative Timesteps: 546,226,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,818.80875
Policy Entropy: 3.75956
Value Function Loss: 0.05272

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.74673

Collected Steps per Second: 23,200.18994
Overall Steps per Second: 10,944.04094

Timestep Collection Time: 2.15559
Timestep Consumption Time: 2.41402
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.56961

Cumulative Model Updates: 65,504
Cumulative Timesteps: 546,276,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 546276142...
Checkpoint 546276142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,890.24150
Policy Entropy: 3.76203
Value Function Loss: 0.05564

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.50977
Value Function Update Magnitude: 0.77961

Collected Steps per Second: 22,673.34016
Overall Steps per Second: 10,683.01838

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.47519
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.68051

Cumulative Model Updates: 65,510
Cumulative Timesteps: 546,326,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,154.82668
Policy Entropy: 3.76286
Value Function Loss: 0.05672

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12484
Policy Update Magnitude: 0.46076
Value Function Update Magnitude: 0.80982

Collected Steps per Second: 23,089.85802
Overall Steps per Second: 10,899.63565

Timestep Collection Time: 2.16545
Timestep Consumption Time: 2.42186
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.58731

Cumulative Model Updates: 65,516
Cumulative Timesteps: 546,376,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 546376144...
Checkpoint 546376144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,269.39586
Policy Entropy: 3.76263
Value Function Loss: 0.05532

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.51747
Value Function Update Magnitude: 0.81076

Collected Steps per Second: 22,618.87436
Overall Steps per Second: 10,598.31845

Timestep Collection Time: 2.21116
Timestep Consumption Time: 2.50789
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.71905

Cumulative Model Updates: 65,522
Cumulative Timesteps: 546,426,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,067.75622
Policy Entropy: 3.76861
Value Function Loss: 0.05156

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07861
Policy Update Magnitude: 0.63434
Value Function Update Magnitude: 0.80327

Collected Steps per Second: 23,025.34551
Overall Steps per Second: 10,837.95739

Timestep Collection Time: 2.17213
Timestep Consumption Time: 2.44258
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.61471

Cumulative Model Updates: 65,528
Cumulative Timesteps: 546,476,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 546476172...
Checkpoint 546476172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,018.69675
Policy Entropy: 3.76630
Value Function Loss: 0.05174

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.61141
Value Function Update Magnitude: 0.75770

Collected Steps per Second: 22,891.68966
Overall Steps per Second: 10,748.28909

Timestep Collection Time: 2.18516
Timestep Consumption Time: 2.46879
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.65395

Cumulative Model Updates: 65,534
Cumulative Timesteps: 546,526,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,223.02275
Policy Entropy: 3.77107
Value Function Loss: 0.05314

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06122
Policy Update Magnitude: 0.63743
Value Function Update Magnitude: 0.76378

Collected Steps per Second: 22,937.16430
Overall Steps per Second: 10,935.78438

Timestep Collection Time: 2.18013
Timestep Consumption Time: 2.39256
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.57269

Cumulative Model Updates: 65,540
Cumulative Timesteps: 546,576,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 546576200...
Checkpoint 546576200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,252.48516
Policy Entropy: 3.76436
Value Function Loss: 0.05462

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06181
Policy Update Magnitude: 0.68088
Value Function Update Magnitude: 0.76348

Collected Steps per Second: 22,515.20841
Overall Steps per Second: 10,567.42610

Timestep Collection Time: 2.22081
Timestep Consumption Time: 2.51090
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.73171

Cumulative Model Updates: 65,546
Cumulative Timesteps: 546,626,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,889.18414
Policy Entropy: 3.76494
Value Function Loss: 0.05632

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06681
Policy Update Magnitude: 0.69306
Value Function Update Magnitude: 0.75850

Collected Steps per Second: 22,784.15983
Overall Steps per Second: 10,806.35973

Timestep Collection Time: 2.19530
Timestep Consumption Time: 2.43327
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.62857

Cumulative Model Updates: 65,552
Cumulative Timesteps: 546,676,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 546676220...
Checkpoint 546676220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.54706
Policy Entropy: 3.76907
Value Function Loss: 0.05571

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.56974
Value Function Update Magnitude: 0.75387

Collected Steps per Second: 22,225.18598
Overall Steps per Second: 10,691.57928

Timestep Collection Time: 2.25015
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.67751

Cumulative Model Updates: 65,558
Cumulative Timesteps: 546,726,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,844.33010
Policy Entropy: 3.76318
Value Function Loss: 0.05793

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.52054
Value Function Update Magnitude: 0.74431

Collected Steps per Second: 22,885.51451
Overall Steps per Second: 10,690.40789

Timestep Collection Time: 2.18592
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.67952

Cumulative Model Updates: 65,564
Cumulative Timesteps: 546,776,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 546776256...
Checkpoint 546776256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.82061
Policy Entropy: 3.77584
Value Function Loss: 0.05719

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.63459
Value Function Update Magnitude: 0.70118

Collected Steps per Second: 22,757.72091
Overall Steps per Second: 10,825.44178

Timestep Collection Time: 2.19785
Timestep Consumption Time: 2.42256
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.62041

Cumulative Model Updates: 65,570
Cumulative Timesteps: 546,826,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,987.93454
Policy Entropy: 3.78016
Value Function Loss: 0.05824

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.70816
Value Function Update Magnitude: 0.63125

Collected Steps per Second: 22,700.20247
Overall Steps per Second: 10,752.57470

Timestep Collection Time: 2.20395
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.65284

Cumulative Model Updates: 65,576
Cumulative Timesteps: 546,876,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 546876304...
Checkpoint 546876304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.44442
Policy Entropy: 3.78821
Value Function Loss: 0.05671

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07192
Policy Update Magnitude: 0.72105
Value Function Update Magnitude: 0.69205

Collected Steps per Second: 22,690.41011
Overall Steps per Second: 10,806.13396

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.42478
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62959

Cumulative Model Updates: 65,582
Cumulative Timesteps: 546,926,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,622.60398
Policy Entropy: 3.78322
Value Function Loss: 0.05794

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.70583
Value Function Update Magnitude: 0.69630

Collected Steps per Second: 22,764.91272
Overall Steps per Second: 10,680.51395

Timestep Collection Time: 2.19689
Timestep Consumption Time: 2.48566
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68255

Cumulative Model Updates: 65,588
Cumulative Timesteps: 546,976,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 546976344...
Checkpoint 546976344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,330.42381
Policy Entropy: 3.77601
Value Function Loss: 0.05698

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.60889
Value Function Update Magnitude: 0.69298

Collected Steps per Second: 22,707.16474
Overall Steps per Second: 10,712.49370

Timestep Collection Time: 2.20265
Timestep Consumption Time: 2.46629
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.66894

Cumulative Model Updates: 65,594
Cumulative Timesteps: 547,026,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,499.94677
Policy Entropy: 3.77752
Value Function Loss: 0.05603

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.56430
Value Function Update Magnitude: 0.76982

Collected Steps per Second: 23,145.42602
Overall Steps per Second: 10,799.74611

Timestep Collection Time: 2.16164
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.63270

Cumulative Model Updates: 65,600
Cumulative Timesteps: 547,076,392

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 547076392...
Checkpoint 547076392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,490.99673
Policy Entropy: 3.77571
Value Function Loss: 0.05489

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.55959
Value Function Update Magnitude: 0.79563

Collected Steps per Second: 22,785.42945
Overall Steps per Second: 10,896.35602

Timestep Collection Time: 2.19474
Timestep Consumption Time: 2.39469
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.58942

Cumulative Model Updates: 65,606
Cumulative Timesteps: 547,126,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,774.46731
Policy Entropy: 3.76423
Value Function Loss: 0.05910

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.57621
Value Function Update Magnitude: 0.80106

Collected Steps per Second: 23,080.91558
Overall Steps per Second: 10,762.60237

Timestep Collection Time: 2.16733
Timestep Consumption Time: 2.48061
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.64795

Cumulative Model Updates: 65,612
Cumulative Timesteps: 547,176,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 547176424...
Checkpoint 547176424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.56013
Policy Entropy: 3.75226
Value Function Loss: 0.06223

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.60310
Value Function Update Magnitude: 0.81935

Collected Steps per Second: 22,334.93730
Overall Steps per Second: 10,618.98335

Timestep Collection Time: 2.24062
Timestep Consumption Time: 2.47208
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.71269

Cumulative Model Updates: 65,618
Cumulative Timesteps: 547,226,468

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,884.18903
Policy Entropy: 3.73984
Value Function Loss: 0.06506

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.67295
Value Function Update Magnitude: 0.78473

Collected Steps per Second: 23,377.12104
Overall Steps per Second: 10,744.10948

Timestep Collection Time: 2.13987
Timestep Consumption Time: 2.51608
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.65595

Cumulative Model Updates: 65,624
Cumulative Timesteps: 547,276,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 547276492...
Checkpoint 547276492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,499.16361
Policy Entropy: 3.74301
Value Function Loss: 0.06248

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.66873
Value Function Update Magnitude: 0.75778

Collected Steps per Second: 22,728.93857
Overall Steps per Second: 10,624.28384

Timestep Collection Time: 2.20063
Timestep Consumption Time: 2.50726
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.70789

Cumulative Model Updates: 65,630
Cumulative Timesteps: 547,326,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,141.43231
Policy Entropy: 3.73230
Value Function Loss: 0.06032

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.78180

Collected Steps per Second: 23,038.32974
Overall Steps per Second: 10,859.36919

Timestep Collection Time: 2.17160
Timestep Consumption Time: 2.43548
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.60708

Cumulative Model Updates: 65,636
Cumulative Timesteps: 547,376,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 547376540...
Checkpoint 547376540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,535.41444
Policy Entropy: 3.73285
Value Function Loss: 0.05929

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.54880
Value Function Update Magnitude: 0.78724

Collected Steps per Second: 22,192.83624
Overall Steps per Second: 10,663.02081

Timestep Collection Time: 2.25406
Timestep Consumption Time: 2.43729
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.69135

Cumulative Model Updates: 65,642
Cumulative Timesteps: 547,426,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,696.85744
Policy Entropy: 3.73235
Value Function Loss: 0.05919

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.54803
Value Function Update Magnitude: 0.76943

Collected Steps per Second: 22,916.20089
Overall Steps per Second: 10,866.29276

Timestep Collection Time: 2.18230
Timestep Consumption Time: 2.42001
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.60231

Cumulative Model Updates: 65,648
Cumulative Timesteps: 547,476,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 547476574...
Checkpoint 547476574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,907.12833
Policy Entropy: 3.74168
Value Function Loss: 0.05996

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.55735
Value Function Update Magnitude: 0.77571

Collected Steps per Second: 22,389.96712
Overall Steps per Second: 10,746.92897

Timestep Collection Time: 2.23323
Timestep Consumption Time: 2.41945
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.65268

Cumulative Model Updates: 65,654
Cumulative Timesteps: 547,526,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,332.41706
Policy Entropy: 3.74145
Value Function Loss: 0.06310

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.79917

Collected Steps per Second: 23,207.48966
Overall Steps per Second: 10,920.14469

Timestep Collection Time: 2.15482
Timestep Consumption Time: 2.42460
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.57943

Cumulative Model Updates: 65,660
Cumulative Timesteps: 547,576,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 547576584...
Checkpoint 547576584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.58561
Policy Entropy: 3.72715
Value Function Loss: 0.06366

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.57053
Value Function Update Magnitude: 0.80893

Collected Steps per Second: 22,698.31174
Overall Steps per Second: 10,624.69058

Timestep Collection Time: 2.20281
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.70602

Cumulative Model Updates: 65,666
Cumulative Timesteps: 547,626,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,726.83387
Policy Entropy: 3.73223
Value Function Loss: 0.06276

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08255
Policy Update Magnitude: 0.66860
Value Function Update Magnitude: 0.81966

Collected Steps per Second: 23,235.88508
Overall Steps per Second: 10,824.77734

Timestep Collection Time: 2.15219
Timestep Consumption Time: 2.46758
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.61977

Cumulative Model Updates: 65,672
Cumulative Timesteps: 547,676,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 547676592...
Checkpoint 547676592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,108.83663
Policy Entropy: 3.73582
Value Function Loss: 0.06261

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.67541
Value Function Update Magnitude: 0.78855

Collected Steps per Second: 22,366.94201
Overall Steps per Second: 10,735.70193

Timestep Collection Time: 2.23580
Timestep Consumption Time: 2.42230
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.65810

Cumulative Model Updates: 65,678
Cumulative Timesteps: 547,726,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,559.33705
Policy Entropy: 3.72892
Value Function Loss: 0.06447

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.57038
Value Function Update Magnitude: 0.72998

Collected Steps per Second: 23,057.33683
Overall Steps per Second: 10,855.43390

Timestep Collection Time: 2.16859
Timestep Consumption Time: 2.43758
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.60617

Cumulative Model Updates: 65,684
Cumulative Timesteps: 547,776,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 547776602...
Checkpoint 547776602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,944.63467
Policy Entropy: 3.72538
Value Function Loss: 0.06581

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09275
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.61843

Collected Steps per Second: 22,494.51232
Overall Steps per Second: 10,603.81889

Timestep Collection Time: 2.22321
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.71623

Cumulative Model Updates: 65,690
Cumulative Timesteps: 547,826,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,724.12521
Policy Entropy: 3.70107
Value Function Loss: 0.06882

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.55337
Value Function Update Magnitude: 0.55927

Collected Steps per Second: 22,952.96510
Overall Steps per Second: 10,864.75932

Timestep Collection Time: 2.17863
Timestep Consumption Time: 2.42396
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60259

Cumulative Model Updates: 65,696
Cumulative Timesteps: 547,876,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 547876618...
Checkpoint 547876618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,788.89227
Policy Entropy: 3.70526
Value Function Loss: 0.06727

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.55844
Value Function Update Magnitude: 0.56824

Collected Steps per Second: 22,631.07929
Overall Steps per Second: 10,664.60301

Timestep Collection Time: 2.20970
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.68916

Cumulative Model Updates: 65,702
Cumulative Timesteps: 547,926,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,218.79932
Policy Entropy: 3.70533
Value Function Loss: 0.06806

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.59060
Value Function Update Magnitude: 0.56006

Collected Steps per Second: 22,977.10473
Overall Steps per Second: 10,870.72380

Timestep Collection Time: 2.17625
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.59988

Cumulative Model Updates: 65,708
Cumulative Timesteps: 547,976,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 547976630...
Checkpoint 547976630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,194.97188
Policy Entropy: 3.72014
Value Function Loss: 0.06363

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.56330
Value Function Update Magnitude: 0.63561

Collected Steps per Second: 22,279.10962
Overall Steps per Second: 10,737.13948

Timestep Collection Time: 2.24533
Timestep Consumption Time: 2.41364
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.65897

Cumulative Model Updates: 65,714
Cumulative Timesteps: 548,026,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,585.66556
Policy Entropy: 3.73819
Value Function Loss: 0.06505

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.49039
Value Function Update Magnitude: 0.68189

Collected Steps per Second: 22,990.97444
Overall Steps per Second: 10,848.10597

Timestep Collection Time: 2.17529
Timestep Consumption Time: 2.43492
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61021

Cumulative Model Updates: 65,720
Cumulative Timesteps: 548,076,666

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 548076666...
Checkpoint 548076666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,880.68048
Policy Entropy: 3.73705
Value Function Loss: 0.06626

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.39333
Value Function Update Magnitude: 0.59695

Collected Steps per Second: 22,615.18235
Overall Steps per Second: 10,641.02017

Timestep Collection Time: 2.21108
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.69917

Cumulative Model Updates: 65,726
Cumulative Timesteps: 548,126,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,023.78804
Policy Entropy: 3.73832
Value Function Loss: 0.06755

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.36541
Value Function Update Magnitude: 0.58000

Collected Steps per Second: 22,956.49646
Overall Steps per Second: 10,869.90034

Timestep Collection Time: 2.17925
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.60243

Cumulative Model Updates: 65,732
Cumulative Timesteps: 548,176,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 548176698...
Checkpoint 548176698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,025.03673
Policy Entropy: 3.73670
Value Function Loss: 0.06319

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.39340
Value Function Update Magnitude: 0.58887

Collected Steps per Second: 22,703.55432
Overall Steps per Second: 10,707.83477

Timestep Collection Time: 2.20274
Timestep Consumption Time: 2.46767
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.67041

Cumulative Model Updates: 65,738
Cumulative Timesteps: 548,226,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,378.74666
Policy Entropy: 3.73428
Value Function Loss: 0.06115

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06728
Policy Update Magnitude: 0.57260
Value Function Update Magnitude: 0.59325

Collected Steps per Second: 23,366.34648
Overall Steps per Second: 10,911.77526

Timestep Collection Time: 2.13992
Timestep Consumption Time: 2.44247
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.58239

Cumulative Model Updates: 65,744
Cumulative Timesteps: 548,276,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 548276710...
Checkpoint 548276710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,267.85953
Policy Entropy: 3.73043
Value Function Loss: 0.06064

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.67018
Value Function Update Magnitude: 0.60492

Collected Steps per Second: 22,741.32201
Overall Steps per Second: 10,649.69459

Timestep Collection Time: 2.20005
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.69798

Cumulative Model Updates: 65,750
Cumulative Timesteps: 548,326,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,987.29011
Policy Entropy: 3.73387
Value Function Loss: 0.06026

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.65300
Value Function Update Magnitude: 0.59393

Collected Steps per Second: 22,087.50401
Overall Steps per Second: 10,841.06893

Timestep Collection Time: 2.26499
Timestep Consumption Time: 2.34968
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.61467

Cumulative Model Updates: 65,756
Cumulative Timesteps: 548,376,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 548376770...
Checkpoint 548376770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,852.78038
Policy Entropy: 3.74510
Value Function Loss: 0.05936

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.62909
Value Function Update Magnitude: 0.65040

Collected Steps per Second: 21,923.15183
Overall Steps per Second: 10,698.96252

Timestep Collection Time: 2.28115
Timestep Consumption Time: 2.39313
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.67429

Cumulative Model Updates: 65,762
Cumulative Timesteps: 548,426,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,470.53051
Policy Entropy: 3.75193
Value Function Loss: 0.05603

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.58863
Value Function Update Magnitude: 0.65645

Collected Steps per Second: 22,364.79825
Overall Steps per Second: 10,877.85319

Timestep Collection Time: 2.23700
Timestep Consumption Time: 2.36226
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59925

Cumulative Model Updates: 65,768
Cumulative Timesteps: 548,476,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 548476810...
Checkpoint 548476810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,862.36411
Policy Entropy: 3.74742
Value Function Loss: 0.05633

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.54887
Value Function Update Magnitude: 0.64753

Collected Steps per Second: 21,886.57116
Overall Steps per Second: 10,653.50975

Timestep Collection Time: 2.28569
Timestep Consumption Time: 2.41004
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.69573

Cumulative Model Updates: 65,774
Cumulative Timesteps: 548,526,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,432.64918
Policy Entropy: 3.73962
Value Function Loss: 0.05653

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.55127
Value Function Update Magnitude: 0.68231

Collected Steps per Second: 22,419.94986
Overall Steps per Second: 10,948.20135

Timestep Collection Time: 2.23105
Timestep Consumption Time: 2.33774
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.56879

Cumulative Model Updates: 65,780
Cumulative Timesteps: 548,576,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 548576856...
Checkpoint 548576856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,257.11195
Policy Entropy: 3.73380
Value Function Loss: 0.05729

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.56346
Value Function Update Magnitude: 0.66379

Collected Steps per Second: 22,001.91857
Overall Steps per Second: 10,598.04360

Timestep Collection Time: 2.27326
Timestep Consumption Time: 2.44611
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.71936

Cumulative Model Updates: 65,786
Cumulative Timesteps: 548,626,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,765.73734
Policy Entropy: 3.73434
Value Function Loss: 0.06020

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.60257
Value Function Update Magnitude: 0.64017

Collected Steps per Second: 22,988.21510
Overall Steps per Second: 10,894.60689

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.41450
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.58961

Cumulative Model Updates: 65,792
Cumulative Timesteps: 548,676,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 548676874...
Checkpoint 548676874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,927.01542
Policy Entropy: 3.75235
Value Function Loss: 0.06217

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.56387
Value Function Update Magnitude: 0.67649

Collected Steps per Second: 22,466.41769
Overall Steps per Second: 10,629.60864

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.47988
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.70685

Cumulative Model Updates: 65,798
Cumulative Timesteps: 548,726,906

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,248.95356
Policy Entropy: 3.74271
Value Function Loss: 0.06218

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.56817
Value Function Update Magnitude: 0.72454

Collected Steps per Second: 23,311.47913
Overall Steps per Second: 10,908.52940

Timestep Collection Time: 2.14555
Timestep Consumption Time: 2.43948
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.58504

Cumulative Model Updates: 65,804
Cumulative Timesteps: 548,776,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 548776922...
Checkpoint 548776922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,880.77211
Policy Entropy: 3.73442
Value Function Loss: 0.06436

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.56476
Value Function Update Magnitude: 0.80975

Collected Steps per Second: 22,413.13599
Overall Steps per Second: 10,679.30381

Timestep Collection Time: 2.23182
Timestep Consumption Time: 2.45220
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68401

Cumulative Model Updates: 65,810
Cumulative Timesteps: 548,826,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,339.42755
Policy Entropy: 3.73114
Value Function Loss: 0.06181

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.47251
Value Function Update Magnitude: 0.84924

Collected Steps per Second: 23,336.99423
Overall Steps per Second: 10,911.54148

Timestep Collection Time: 2.14346
Timestep Consumption Time: 2.44086
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.58432

Cumulative Model Updates: 65,816
Cumulative Timesteps: 548,876,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 548876966...
Checkpoint 548876966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,773.50606
Policy Entropy: 3.73187
Value Function Loss: 0.06045

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.85733

Collected Steps per Second: 22,357.33722
Overall Steps per Second: 10,629.66902

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.46850
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.70588

Cumulative Model Updates: 65,822
Cumulative Timesteps: 548,926,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,077.02378
Policy Entropy: 3.72583
Value Function Loss: 0.05955

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.59922
Value Function Update Magnitude: 0.85071

Collected Steps per Second: 23,206.03439
Overall Steps per Second: 10,919.23153

Timestep Collection Time: 2.15513
Timestep Consumption Time: 2.42505
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.58018

Cumulative Model Updates: 65,828
Cumulative Timesteps: 548,977,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 548977000...
Checkpoint 548977000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,458.15269
Policy Entropy: 3.71718
Value Function Loss: 0.06214

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.61379
Value Function Update Magnitude: 0.74984

Collected Steps per Second: 22,407.54212
Overall Steps per Second: 10,637.26783

Timestep Collection Time: 2.23228
Timestep Consumption Time: 2.47005
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.70234

Cumulative Model Updates: 65,834
Cumulative Timesteps: 549,027,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,070.43541
Policy Entropy: 3.71087
Value Function Loss: 0.06397

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.79144

Collected Steps per Second: 22,738.25887
Overall Steps per Second: 10,775.80309

Timestep Collection Time: 2.19946
Timestep Consumption Time: 2.44167
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.64114

Cumulative Model Updates: 65,840
Cumulative Timesteps: 549,077,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 549077032...
Checkpoint 549077032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,105.81416
Policy Entropy: 3.72002
Value Function Loss: 0.06415

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.57099
Value Function Update Magnitude: 0.77543

Collected Steps per Second: 22,504.10335
Overall Steps per Second: 10,729.22902

Timestep Collection Time: 2.22191
Timestep Consumption Time: 2.43845
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.66035

Cumulative Model Updates: 65,846
Cumulative Timesteps: 549,127,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,455.62621
Policy Entropy: 3.71894
Value Function Loss: 0.06515

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.73219

Collected Steps per Second: 23,193.26698
Overall Steps per Second: 10,910.12198

Timestep Collection Time: 2.15752
Timestep Consumption Time: 2.42904
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.58657

Cumulative Model Updates: 65,852
Cumulative Timesteps: 549,177,074

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 549177074...
Checkpoint 549177074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,291.51011
Policy Entropy: 3.71730
Value Function Loss: 0.06372

Mean KL Divergence: 0.01916
SB3 Clip Fraction: 0.15446
Policy Update Magnitude: 0.49498
Value Function Update Magnitude: 0.81919

Collected Steps per Second: 22,496.00608
Overall Steps per Second: 10,687.24087

Timestep Collection Time: 2.22351
Timestep Consumption Time: 2.45684
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.68035

Cumulative Model Updates: 65,858
Cumulative Timesteps: 549,227,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,190.32292
Policy Entropy: 3.71683
Value Function Loss: 0.06493

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.51413
Value Function Update Magnitude: 0.73299

Collected Steps per Second: 23,095.24260
Overall Steps per Second: 10,867.26392

Timestep Collection Time: 2.16625
Timestep Consumption Time: 2.43749
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.60373

Cumulative Model Updates: 65,864
Cumulative Timesteps: 549,277,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 549277124...
Checkpoint 549277124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,507.49004
Policy Entropy: 3.71071
Value Function Loss: 0.06452

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06712
Policy Update Magnitude: 0.61219
Value Function Update Magnitude: 0.63545

Collected Steps per Second: 22,565.44005
Overall Steps per Second: 10,664.48692

Timestep Collection Time: 2.21649
Timestep Consumption Time: 2.47347
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.68996

Cumulative Model Updates: 65,870
Cumulative Timesteps: 549,327,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,672.16035
Policy Entropy: 3.70163
Value Function Loss: 0.06594

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.62140
Value Function Update Magnitude: 0.62333

Collected Steps per Second: 22,953.85165
Overall Steps per Second: 10,839.98955

Timestep Collection Time: 2.17950
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.61513

Cumulative Model Updates: 65,876
Cumulative Timesteps: 549,377,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 549377168...
Checkpoint 549377168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,979.26372
Policy Entropy: 3.69939
Value Function Loss: 0.06499

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.58746
Value Function Update Magnitude: 0.62944

Collected Steps per Second: 22,406.83957
Overall Steps per Second: 10,726.02262

Timestep Collection Time: 2.23191
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.66249

Cumulative Model Updates: 65,882
Cumulative Timesteps: 549,427,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,383.41852
Policy Entropy: 3.70233
Value Function Loss: 0.06241

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.55419
Value Function Update Magnitude: 0.64926

Collected Steps per Second: 23,293.51317
Overall Steps per Second: 10,936.93348

Timestep Collection Time: 2.14772
Timestep Consumption Time: 2.42650
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.57423

Cumulative Model Updates: 65,888
Cumulative Timesteps: 549,477,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 549477206...
Checkpoint 549477206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,944.99096
Policy Entropy: 3.70003
Value Function Loss: 0.06324

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.53103
Value Function Update Magnitude: 0.63515

Collected Steps per Second: 22,622.08332
Overall Steps per Second: 10,587.61406

Timestep Collection Time: 2.21138
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.72496

Cumulative Model Updates: 65,894
Cumulative Timesteps: 549,527,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,391.70921
Policy Entropy: 3.68873
Value Function Loss: 0.06354

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.58192
Value Function Update Magnitude: 0.70102

Collected Steps per Second: 22,956.05056
Overall Steps per Second: 10,841.37414

Timestep Collection Time: 2.17842
Timestep Consumption Time: 2.43428
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.61270

Cumulative Model Updates: 65,900
Cumulative Timesteps: 549,577,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 549577240...
Checkpoint 549577240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,458.24346
Policy Entropy: 3.67553
Value Function Loss: 0.06479

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.60564
Value Function Update Magnitude: 0.75109

Collected Steps per Second: 22,390.63987
Overall Steps per Second: 10,762.50596

Timestep Collection Time: 2.23317
Timestep Consumption Time: 2.41278
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.64594

Cumulative Model Updates: 65,906
Cumulative Timesteps: 549,627,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,446.69686
Policy Entropy: 3.69737
Value Function Loss: 0.06454

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.45568
Value Function Update Magnitude: 0.77955

Collected Steps per Second: 22,856.43788
Overall Steps per Second: 10,824.41082

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.62122

Cumulative Model Updates: 65,912
Cumulative Timesteps: 549,677,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 549677264...
Checkpoint 549677264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,220.30042
Policy Entropy: 3.69927
Value Function Loss: 0.06641

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.52220
Value Function Update Magnitude: 0.71506

Collected Steps per Second: 22,362.64651
Overall Steps per Second: 10,714.96031

Timestep Collection Time: 2.23659
Timestep Consumption Time: 2.43128
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.66787

Cumulative Model Updates: 65,918
Cumulative Timesteps: 549,727,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,153.06245
Policy Entropy: 3.70619
Value Function Loss: 0.06422

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.52178
Value Function Update Magnitude: 0.73216

Collected Steps per Second: 22,842.43991
Overall Steps per Second: 10,822.19638

Timestep Collection Time: 2.18996
Timestep Consumption Time: 2.43239
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.62235

Cumulative Model Updates: 65,924
Cumulative Timesteps: 549,777,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 549777304...
Checkpoint 549777304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,825.50084
Policy Entropy: 3.71102
Value Function Loss: 0.06077

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.56516
Value Function Update Magnitude: 0.70919

Collected Steps per Second: 22,370.35810
Overall Steps per Second: 10,740.62052

Timestep Collection Time: 2.23591
Timestep Consumption Time: 2.42100
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.65690

Cumulative Model Updates: 65,930
Cumulative Timesteps: 549,827,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,361.00533
Policy Entropy: 3.72441
Value Function Loss: 0.06186

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.63851
Value Function Update Magnitude: 0.70052

Collected Steps per Second: 23,002.38010
Overall Steps per Second: 10,835.25013

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.44108
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.61494

Cumulative Model Updates: 65,936
Cumulative Timesteps: 549,877,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 549877326...
Checkpoint 549877326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,424.97406
Policy Entropy: 3.71578
Value Function Loss: 0.06159

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.58753
Value Function Update Magnitude: 0.62977

Collected Steps per Second: 22,642.22749
Overall Steps per Second: 10,651.36574

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.69423

Cumulative Model Updates: 65,942
Cumulative Timesteps: 549,927,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,825.73138
Policy Entropy: 3.71124
Value Function Loss: 0.06267

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.52355
Value Function Update Magnitude: 0.63288

Collected Steps per Second: 22,809.40592
Overall Steps per Second: 10,693.87321

Timestep Collection Time: 2.19278
Timestep Consumption Time: 2.48429
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.67707

Cumulative Model Updates: 65,948
Cumulative Timesteps: 549,977,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 549977342...
Checkpoint 549977342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,343.11645
Policy Entropy: 3.71039
Value Function Loss: 0.06076

Mean KL Divergence: 0.02411
SB3 Clip Fraction: 0.17603
Policy Update Magnitude: 0.44623
Value Function Update Magnitude: 0.67691

Collected Steps per Second: 22,128.07806
Overall Steps per Second: 10,596.25832

Timestep Collection Time: 2.25984
Timestep Consumption Time: 2.45937
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.71921

Cumulative Model Updates: 65,954
Cumulative Timesteps: 550,027,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,212.35538
Policy Entropy: 3.72189
Value Function Loss: 0.06122

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.49363
Value Function Update Magnitude: 0.66849

Collected Steps per Second: 23,087.48033
Overall Steps per Second: 10,791.05623

Timestep Collection Time: 2.16628
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.63476

Cumulative Model Updates: 65,960
Cumulative Timesteps: 550,077,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 550077362...
Checkpoint 550077362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,907.02758
Policy Entropy: 3.72956
Value Function Loss: 0.06060

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.63410
Value Function Update Magnitude: 0.73546

Collected Steps per Second: 22,780.03795
Overall Steps per Second: 10,686.14628

Timestep Collection Time: 2.19622
Timestep Consumption Time: 2.48554
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.68176

Cumulative Model Updates: 65,966
Cumulative Timesteps: 550,127,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,320.87481
Policy Entropy: 3.73566
Value Function Loss: 0.05872

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.80151

Collected Steps per Second: 23,197.08997
Overall Steps per Second: 10,794.74875

Timestep Collection Time: 2.15605
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.63318

Cumulative Model Updates: 65,972
Cumulative Timesteps: 550,177,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 550177406...
Checkpoint 550177406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,439.84653
Policy Entropy: 3.74171
Value Function Loss: 0.05916

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.50945
Value Function Update Magnitude: 0.79631

Collected Steps per Second: 22,426.79324
Overall Steps per Second: 10,635.00409

Timestep Collection Time: 2.22957
Timestep Consumption Time: 2.47208
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.70164

Cumulative Model Updates: 65,978
Cumulative Timesteps: 550,227,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,064.90452
Policy Entropy: 3.73882
Value Function Loss: 0.05940

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.50964
Value Function Update Magnitude: 0.65953

Collected Steps per Second: 23,217.58781
Overall Steps per Second: 10,909.82363

Timestep Collection Time: 2.15432
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.58468

Cumulative Model Updates: 65,984
Cumulative Timesteps: 550,277,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 550277426...
Checkpoint 550277426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,936.86762
Policy Entropy: 3.72019
Value Function Loss: 0.06227

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.53458
Value Function Update Magnitude: 0.60805

Collected Steps per Second: 22,615.01832
Overall Steps per Second: 10,605.96474

Timestep Collection Time: 2.21101
Timestep Consumption Time: 2.50351
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.71452

Cumulative Model Updates: 65,990
Cumulative Timesteps: 550,327,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,755.77493
Policy Entropy: 3.71823
Value Function Loss: 0.06220

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07261
Policy Update Magnitude: 0.60316
Value Function Update Magnitude: 0.59265

Collected Steps per Second: 23,270.65497
Overall Steps per Second: 10,943.19539

Timestep Collection Time: 2.14992
Timestep Consumption Time: 2.42187
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.57179

Cumulative Model Updates: 65,996
Cumulative Timesteps: 550,377,458

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 550377458...
Checkpoint 550377458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,316.59804
Policy Entropy: 3.71330
Value Function Loss: 0.06137

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07366
Policy Update Magnitude: 0.68930
Value Function Update Magnitude: 0.63591

Collected Steps per Second: 22,396.56201
Overall Steps per Second: 10,655.36140

Timestep Collection Time: 2.23293
Timestep Consumption Time: 2.46048
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.69341

Cumulative Model Updates: 66,002
Cumulative Timesteps: 550,427,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.88563
Policy Entropy: 3.72250
Value Function Loss: 0.06406

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.65046
Value Function Update Magnitude: 0.61882

Collected Steps per Second: 23,038.08030
Overall Steps per Second: 10,880.16910

Timestep Collection Time: 2.17154
Timestep Consumption Time: 2.42656
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.59809

Cumulative Model Updates: 66,008
Cumulative Timesteps: 550,477,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 550477496...
Checkpoint 550477496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,304.46376
Policy Entropy: 3.71816
Value Function Loss: 0.06302

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.56810
Value Function Update Magnitude: 0.64245

Collected Steps per Second: 22,474.20648
Overall Steps per Second: 10,610.36523

Timestep Collection Time: 2.22531
Timestep Consumption Time: 2.48820
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.71350

Cumulative Model Updates: 66,014
Cumulative Timesteps: 550,527,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,050.90667
Policy Entropy: 3.70807
Value Function Loss: 0.06166

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.64371

Collected Steps per Second: 23,004.97112
Overall Steps per Second: 10,869.46932

Timestep Collection Time: 2.17440
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.60206

Cumulative Model Updates: 66,020
Cumulative Timesteps: 550,577,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 550577530...
Checkpoint 550577530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,282.74499
Policy Entropy: 3.70628
Value Function Loss: 0.06048

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.63065
Value Function Update Magnitude: 0.61775

Collected Steps per Second: 22,008.79841
Overall Steps per Second: 10,633.37202

Timestep Collection Time: 2.27218
Timestep Consumption Time: 2.43075
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.70293

Cumulative Model Updates: 66,026
Cumulative Timesteps: 550,627,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,595.57394
Policy Entropy: 3.71048
Value Function Loss: 0.05842

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06785
Policy Update Magnitude: 0.72718
Value Function Update Magnitude: 0.60159

Collected Steps per Second: 22,446.11293
Overall Steps per Second: 10,529.54021

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.52190
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.75025

Cumulative Model Updates: 66,032
Cumulative Timesteps: 550,677,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 550677556...
Checkpoint 550677556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,746.20254
Policy Entropy: 3.72988
Value Function Loss: 0.05807

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06528
Policy Update Magnitude: 0.73864
Value Function Update Magnitude: 0.62833

Collected Steps per Second: 22,332.38352
Overall Steps per Second: 10,641.48916

Timestep Collection Time: 2.23908
Timestep Consumption Time: 2.45989
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.69897

Cumulative Model Updates: 66,038
Cumulative Timesteps: 550,727,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,512.07642
Policy Entropy: 3.72571
Value Function Loss: 0.05926

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06754
Policy Update Magnitude: 0.73331
Value Function Update Magnitude: 0.66673

Collected Steps per Second: 23,050.66411
Overall Steps per Second: 10,954.32910

Timestep Collection Time: 2.16913
Timestep Consumption Time: 2.39527
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.56441

Cumulative Model Updates: 66,044
Cumulative Timesteps: 550,777,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 550777560...
Checkpoint 550777560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,732.57655
Policy Entropy: 3.71771
Value Function Loss: 0.05934

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.64044
Value Function Update Magnitude: 0.67647

Collected Steps per Second: 22,610.38949
Overall Steps per Second: 10,595.45679

Timestep Collection Time: 2.21252
Timestep Consumption Time: 2.50893
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.72146

Cumulative Model Updates: 66,050
Cumulative Timesteps: 550,827,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,424.06345
Policy Entropy: 3.70865
Value Function Loss: 0.05841

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09353
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.72742

Collected Steps per Second: 23,194.52822
Overall Steps per Second: 10,897.51894

Timestep Collection Time: 2.15620
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.58930

Cumulative Model Updates: 66,056
Cumulative Timesteps: 550,877,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 550877598...
Checkpoint 550877598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,127.68945
Policy Entropy: 3.70866
Value Function Loss: 0.05760

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.53937
Value Function Update Magnitude: 0.78634

Collected Steps per Second: 22,585.36327
Overall Steps per Second: 10,632.26894

Timestep Collection Time: 2.21391
Timestep Consumption Time: 2.48894
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.70285

Cumulative Model Updates: 66,062
Cumulative Timesteps: 550,927,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,327.58971
Policy Entropy: 3.71883
Value Function Loss: 0.05767

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.51964
Value Function Update Magnitude: 0.82843

Collected Steps per Second: 23,195.03061
Overall Steps per Second: 10,891.37144

Timestep Collection Time: 2.15650
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59263

Cumulative Model Updates: 66,068
Cumulative Timesteps: 550,977,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 550977620...
Checkpoint 550977620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,792.96054
Policy Entropy: 3.71972
Value Function Loss: 0.05921

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.51103
Value Function Update Magnitude: 0.82506

Collected Steps per Second: 22,602.83996
Overall Steps per Second: 10,690.73368

Timestep Collection Time: 2.21326
Timestep Consumption Time: 2.46612
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.67938

Cumulative Model Updates: 66,074
Cumulative Timesteps: 551,027,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,582.15997
Policy Entropy: 3.70646
Value Function Loss: 0.06004

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.52199
Value Function Update Magnitude: 0.83213

Collected Steps per Second: 23,123.98682
Overall Steps per Second: 10,917.28576

Timestep Collection Time: 2.16312
Timestep Consumption Time: 2.41860
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.58172

Cumulative Model Updates: 66,080
Cumulative Timesteps: 551,077,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 551077666...
Checkpoint 551077666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,524.75803
Policy Entropy: 3.70175
Value Function Loss: 0.06538

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.48610
Value Function Update Magnitude: 0.73415

Collected Steps per Second: 22,763.66040
Overall Steps per Second: 10,652.05213

Timestep Collection Time: 2.19692
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.69487

Cumulative Model Updates: 66,086
Cumulative Timesteps: 551,127,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,280.48680
Policy Entropy: 3.68588
Value Function Loss: 0.06580

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08060
Policy Update Magnitude: 0.58132
Value Function Update Magnitude: 0.62291

Collected Steps per Second: 23,156.08570
Overall Steps per Second: 10,927.06584

Timestep Collection Time: 2.16038
Timestep Consumption Time: 2.41779
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.57817

Cumulative Model Updates: 66,092
Cumulative Timesteps: 551,177,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 551177702...
Checkpoint 551177702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,752.84256
Policy Entropy: 3.68818
Value Function Loss: 0.06472

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.58261
Value Function Update Magnitude: 0.65688

Collected Steps per Second: 22,351.25016
Overall Steps per Second: 10,608.18335

Timestep Collection Time: 2.23764
Timestep Consumption Time: 2.47702
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.71466

Cumulative Model Updates: 66,098
Cumulative Timesteps: 551,227,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,165.77030
Policy Entropy: 3.71358
Value Function Loss: 0.06382

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.47530
Value Function Update Magnitude: 0.61781

Collected Steps per Second: 22,599.21411
Overall Steps per Second: 10,624.97287

Timestep Collection Time: 2.21353
Timestep Consumption Time: 2.49462
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.70815

Cumulative Model Updates: 66,104
Cumulative Timesteps: 551,277,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 551277740...
Checkpoint 551277740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,266.60952
Policy Entropy: 3.71698
Value Function Loss: 0.06477

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.47901
Value Function Update Magnitude: 0.65884

Collected Steps per Second: 22,599.58181
Overall Steps per Second: 10,794.73897

Timestep Collection Time: 2.21305
Timestep Consumption Time: 2.42013
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.63318

Cumulative Model Updates: 66,110
Cumulative Timesteps: 551,327,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,628.79205
Policy Entropy: 3.71414
Value Function Loss: 0.06338

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.47324
Value Function Update Magnitude: 0.70902

Collected Steps per Second: 22,757.48328
Overall Steps per Second: 10,688.50794

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.48144
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.67904

Cumulative Model Updates: 66,116
Cumulative Timesteps: 551,377,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 551377766...
Checkpoint 551377766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,730.20745
Policy Entropy: 3.71410
Value Function Loss: 0.06057

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.51615
Value Function Update Magnitude: 0.67534

Collected Steps per Second: 22,523.78335
Overall Steps per Second: 10,595.45966

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.49973
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.72013

Cumulative Model Updates: 66,122
Cumulative Timesteps: 551,427,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,893.19735
Policy Entropy: 3.70692
Value Function Loss: 0.05883

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.55688
Value Function Update Magnitude: 0.73375

Collected Steps per Second: 22,926.14456
Overall Steps per Second: 10,881.02949

Timestep Collection Time: 2.18188
Timestep Consumption Time: 2.41530
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.59718

Cumulative Model Updates: 66,128
Cumulative Timesteps: 551,477,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 551477800...
Checkpoint 551477800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,487.76948
Policy Entropy: 3.69458
Value Function Loss: 0.05713

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.76937

Collected Steps per Second: 22,000.76438
Overall Steps per Second: 10,646.71800

Timestep Collection Time: 2.27401
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.69910

Cumulative Model Updates: 66,134
Cumulative Timesteps: 551,527,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,766.05413
Policy Entropy: 3.69654
Value Function Loss: 0.05804

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.52088
Value Function Update Magnitude: 0.74678

Collected Steps per Second: 22,570.04652
Overall Steps per Second: 10,889.38392

Timestep Collection Time: 2.21657
Timestep Consumption Time: 2.37763
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.59420

Cumulative Model Updates: 66,140
Cumulative Timesteps: 551,577,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 551577858...
Checkpoint 551577858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,918.67775
Policy Entropy: 3.68783
Value Function Loss: 0.05694

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.52500
Value Function Update Magnitude: 0.79761

Collected Steps per Second: 21,988.78042
Overall Steps per Second: 10,644.86165

Timestep Collection Time: 2.27452
Timestep Consumption Time: 2.42389
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.69842

Cumulative Model Updates: 66,146
Cumulative Timesteps: 551,627,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,273.11541
Policy Entropy: 3.68983
Value Function Loss: 0.05886

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.51507
Value Function Update Magnitude: 0.82326

Collected Steps per Second: 22,507.58964
Overall Steps per Second: 10,848.68534

Timestep Collection Time: 2.22316
Timestep Consumption Time: 2.38919
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.61236

Cumulative Model Updates: 66,152
Cumulative Timesteps: 551,677,910

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 551677910...
Checkpoint 551677910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,488.16276
Policy Entropy: 3.69343
Value Function Loss: 0.06024

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.49762
Value Function Update Magnitude: 0.82393

Collected Steps per Second: 22,089.76371
Overall Steps per Second: 10,645.62702

Timestep Collection Time: 2.26476
Timestep Consumption Time: 2.43464
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.69939

Cumulative Model Updates: 66,158
Cumulative Timesteps: 551,727,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,716.28331
Policy Entropy: 3.69715
Value Function Loss: 0.06083

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.51307
Value Function Update Magnitude: 0.84141

Collected Steps per Second: 22,402.94023
Overall Steps per Second: 10,671.37452

Timestep Collection Time: 2.23221
Timestep Consumption Time: 2.45397
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.68618

Cumulative Model Updates: 66,164
Cumulative Timesteps: 551,777,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 551777946...
Checkpoint 551777946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,587.54561
Policy Entropy: 3.69007
Value Function Loss: 0.06049

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.64549
Value Function Update Magnitude: 0.80981

Collected Steps per Second: 22,802.93714
Overall Steps per Second: 10,882.25676

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.40328
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.59721

Cumulative Model Updates: 66,170
Cumulative Timesteps: 551,827,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,072.68691
Policy Entropy: 3.69918
Value Function Loss: 0.06155

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06572
Policy Update Magnitude: 0.74784
Value Function Update Magnitude: 0.73683

Collected Steps per Second: 23,132.63204
Overall Steps per Second: 10,960.64737

Timestep Collection Time: 2.16188
Timestep Consumption Time: 2.40081
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.56269

Cumulative Model Updates: 66,176
Cumulative Timesteps: 551,877,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 551877984...
Checkpoint 551877984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,326.31653
Policy Entropy: 3.71529
Value Function Loss: 0.06037

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.71805
Value Function Update Magnitude: 0.71636

Collected Steps per Second: 22,161.86002
Overall Steps per Second: 10,602.53583

Timestep Collection Time: 2.25649
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.71661

Cumulative Model Updates: 66,182
Cumulative Timesteps: 551,927,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,655.62364
Policy Entropy: 3.71573
Value Function Loss: 0.06107

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.62572
Value Function Update Magnitude: 0.75687

Collected Steps per Second: 22,851.46057
Overall Steps per Second: 10,891.28441

Timestep Collection Time: 2.18866
Timestep Consumption Time: 2.40346
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.59211

Cumulative Model Updates: 66,188
Cumulative Timesteps: 551,978,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 551978006...
Checkpoint 551978006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,538.76399
Policy Entropy: 3.71651
Value Function Loss: 0.06151

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.65135
Value Function Update Magnitude: 0.80726

Collected Steps per Second: 22,606.55270
Overall Steps per Second: 10,674.81863

Timestep Collection Time: 2.21263
Timestep Consumption Time: 2.47316
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.68579

Cumulative Model Updates: 66,194
Cumulative Timesteps: 552,028,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,408.44233
Policy Entropy: 3.71263
Value Function Loss: 0.06213

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 0.61034
Value Function Update Magnitude: 0.81362

Collected Steps per Second: 22,696.28654
Overall Steps per Second: 10,822.63094

Timestep Collection Time: 2.20406
Timestep Consumption Time: 2.41811
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62217

Cumulative Model Updates: 66,200
Cumulative Timesteps: 552,078,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 552078050...
Checkpoint 552078050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,085.13171
Policy Entropy: 3.70800
Value Function Loss: 0.06388

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.11872
Policy Update Magnitude: 0.55637
Value Function Update Magnitude: 0.76007

Collected Steps per Second: 22,481.32727
Overall Steps per Second: 10,757.65064

Timestep Collection Time: 2.22425
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.64823

Cumulative Model Updates: 66,206
Cumulative Timesteps: 552,128,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,758.02004
Policy Entropy: 3.70648
Value Function Loss: 0.06450

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.50272
Value Function Update Magnitude: 0.84745

Collected Steps per Second: 23,189.02869
Overall Steps per Second: 10,870.41220

Timestep Collection Time: 2.15731
Timestep Consumption Time: 2.44472
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.60203

Cumulative Model Updates: 66,212
Cumulative Timesteps: 552,178,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 552178080...
Checkpoint 552178080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,346.42326
Policy Entropy: 3.69936
Value Function Loss: 0.06524

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.42935
Value Function Update Magnitude: 0.88020

Collected Steps per Second: 22,426.41707
Overall Steps per Second: 10,637.53012

Timestep Collection Time: 2.23005
Timestep Consumption Time: 2.47142
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.70147

Cumulative Model Updates: 66,218
Cumulative Timesteps: 552,228,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,623.34971
Policy Entropy: 3.70117
Value Function Loss: 0.06519

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.46511
Value Function Update Magnitude: 0.90328

Collected Steps per Second: 23,021.15740
Overall Steps per Second: 10,844.29519

Timestep Collection Time: 2.17313
Timestep Consumption Time: 2.44017
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.61330

Cumulative Model Updates: 66,224
Cumulative Timesteps: 552,278,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 552278120...
Checkpoint 552278120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,136.30963
Policy Entropy: 3.69349
Value Function Loss: 0.06419

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.43873
Value Function Update Magnitude: 0.88366

Collected Steps per Second: 22,187.83103
Overall Steps per Second: 10,659.83982

Timestep Collection Time: 2.25439
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.69238

Cumulative Model Updates: 66,230
Cumulative Timesteps: 552,328,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,863.85858
Policy Entropy: 3.68599
Value Function Loss: 0.06419

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12894
Policy Update Magnitude: 0.44507
Value Function Update Magnitude: 0.75993

Collected Steps per Second: 22,786.99562
Overall Steps per Second: 10,707.03828

Timestep Collection Time: 2.19502
Timestep Consumption Time: 2.47648
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.67151

Cumulative Model Updates: 66,236
Cumulative Timesteps: 552,378,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 552378158...
Checkpoint 552378158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,517.42052
Policy Entropy: 3.68878
Value Function Loss: 0.06224

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.45292
Value Function Update Magnitude: 0.73824

Collected Steps per Second: 22,645.62800
Overall Steps per Second: 10,800.61041

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.42366
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.63363

Cumulative Model Updates: 66,242
Cumulative Timesteps: 552,428,204

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,830.37737
Policy Entropy: 3.69404
Value Function Loss: 0.06145

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.48410
Value Function Update Magnitude: 0.76189

Collected Steps per Second: 22,755.42054
Overall Steps per Second: 10,663.13011

Timestep Collection Time: 2.19789
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.69037

Cumulative Model Updates: 66,248
Cumulative Timesteps: 552,478,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 552478218...
Checkpoint 552478218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,659.33257
Policy Entropy: 3.69707
Value Function Loss: 0.05997

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.68687

Collected Steps per Second: 22,671.01911
Overall Steps per Second: 10,655.28989

Timestep Collection Time: 2.20661
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.69494

Cumulative Model Updates: 66,254
Cumulative Timesteps: 552,528,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,383.39847
Policy Entropy: 3.67865
Value Function Loss: 0.06054

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.65881
Value Function Update Magnitude: 0.65824

Collected Steps per Second: 23,029.13251
Overall Steps per Second: 10,784.95953

Timestep Collection Time: 2.17194
Timestep Consumption Time: 2.46581
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.63775

Cumulative Model Updates: 66,260
Cumulative Timesteps: 552,578,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 552578262...
Checkpoint 552578262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,403.74995
Policy Entropy: 3.68298
Value Function Loss: 0.05663

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10266
Policy Update Magnitude: 0.63427
Value Function Update Magnitude: 0.61427

Collected Steps per Second: 22,298.12453
Overall Steps per Second: 10,609.97109

Timestep Collection Time: 2.24306
Timestep Consumption Time: 2.47100
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.71406

Cumulative Model Updates: 66,266
Cumulative Timesteps: 552,628,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,695.62673
Policy Entropy: 3.67592
Value Function Loss: 0.05710

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.58354
Value Function Update Magnitude: 0.59850

Collected Steps per Second: 22,905.91078
Overall Steps per Second: 10,828.21073

Timestep Collection Time: 2.18415
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.62034

Cumulative Model Updates: 66,272
Cumulative Timesteps: 552,678,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 552678308...
Checkpoint 552678308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,205.47430
Policy Entropy: 3.67972
Value Function Loss: 0.05472

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.53125
Value Function Update Magnitude: 0.65531

Collected Steps per Second: 22,350.15944
Overall Steps per Second: 10,743.71148

Timestep Collection Time: 2.23775
Timestep Consumption Time: 2.41744
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.65519

Cumulative Model Updates: 66,278
Cumulative Timesteps: 552,728,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,069.07817
Policy Entropy: 3.70089
Value Function Loss: 0.05729

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.47791
Value Function Update Magnitude: 0.66942

Collected Steps per Second: 22,991.57238
Overall Steps per Second: 10,858.72048

Timestep Collection Time: 2.17619
Timestep Consumption Time: 2.43154
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60773

Cumulative Model Updates: 66,284
Cumulative Timesteps: 552,778,356

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 552778356...
Checkpoint 552778356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.33040
Policy Entropy: 3.71416
Value Function Loss: 0.05921

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.47848
Value Function Update Magnitude: 0.66914

Collected Steps per Second: 22,362.37255
Overall Steps per Second: 10,688.26727

Timestep Collection Time: 2.23661
Timestep Consumption Time: 2.44291
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.67952

Cumulative Model Updates: 66,290
Cumulative Timesteps: 552,828,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,927.52479
Policy Entropy: 3.70840
Value Function Loss: 0.05892

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.52012
Value Function Update Magnitude: 0.71790

Collected Steps per Second: 22,965.07161
Overall Steps per Second: 10,880.16064

Timestep Collection Time: 2.17896
Timestep Consumption Time: 2.42024
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.59920

Cumulative Model Updates: 66,296
Cumulative Timesteps: 552,878,412

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 552878412...
Checkpoint 552878412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,539.22200
Policy Entropy: 3.69788
Value Function Loss: 0.05745

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.49125
Value Function Update Magnitude: 0.77708

Collected Steps per Second: 21,999.31391
Overall Steps per Second: 10,658.34505

Timestep Collection Time: 2.27316
Timestep Consumption Time: 2.41875
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.69191

Cumulative Model Updates: 66,302
Cumulative Timesteps: 552,928,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,467.84079
Policy Entropy: 3.70894
Value Function Loss: 0.05567

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.50199
Value Function Update Magnitude: 0.78889

Collected Steps per Second: 22,385.60760
Overall Steps per Second: 10,890.25612

Timestep Collection Time: 2.23385
Timestep Consumption Time: 2.35797
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.59181

Cumulative Model Updates: 66,308
Cumulative Timesteps: 552,978,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 552978426...
Checkpoint 552978426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,910.41162
Policy Entropy: 3.72516
Value Function Loss: 0.05420

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.14778
Policy Update Magnitude: 0.44351
Value Function Update Magnitude: 0.75014

Collected Steps per Second: 21,680.81441
Overall Steps per Second: 10,679.73991

Timestep Collection Time: 2.30729
Timestep Consumption Time: 2.37672
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.68401

Cumulative Model Updates: 66,314
Cumulative Timesteps: 553,028,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,414.24988
Policy Entropy: 3.73585
Value Function Loss: 0.05466

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.49557
Value Function Update Magnitude: 0.77176

Collected Steps per Second: 22,447.17459
Overall Steps per Second: 10,919.63800

Timestep Collection Time: 2.22861
Timestep Consumption Time: 2.35268
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.58129

Cumulative Model Updates: 66,320
Cumulative Timesteps: 553,078,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 553078476...
Checkpoint 553078476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,595.09073
Policy Entropy: 3.73062
Value Function Loss: 0.05377

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07055
Policy Update Magnitude: 0.61020
Value Function Update Magnitude: 0.75294

Collected Steps per Second: 21,956.88160
Overall Steps per Second: 10,633.77083

Timestep Collection Time: 2.27719
Timestep Consumption Time: 2.42481
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.70200

Cumulative Model Updates: 66,326
Cumulative Timesteps: 553,128,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,587.28218
Policy Entropy: 3.73169
Value Function Loss: 0.05476

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.60344
Value Function Update Magnitude: 0.61714

Collected Steps per Second: 22,274.45136
Overall Steps per Second: 10,863.43926

Timestep Collection Time: 2.24553
Timestep Consumption Time: 2.35872
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.60425

Cumulative Model Updates: 66,332
Cumulative Timesteps: 553,178,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 553178494...
Checkpoint 553178494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,558.07160
Policy Entropy: 3.73822
Value Function Loss: 0.05525

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07063
Policy Update Magnitude: 0.59415
Value Function Update Magnitude: 0.60698

Collected Steps per Second: 21,691.92224
Overall Steps per Second: 10,675.80077

Timestep Collection Time: 2.30611
Timestep Consumption Time: 2.37963
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.68574

Cumulative Model Updates: 66,338
Cumulative Timesteps: 553,228,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,220.11788
Policy Entropy: 3.74635
Value Function Loss: 0.05335

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.66567
Value Function Update Magnitude: 0.59381

Collected Steps per Second: 22,421.61714
Overall Steps per Second: 10,922.17921

Timestep Collection Time: 2.23053
Timestep Consumption Time: 2.34841
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.57894

Cumulative Model Updates: 66,344
Cumulative Timesteps: 553,278,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 553278530...
Checkpoint 553278530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,519.37547
Policy Entropy: 3.74563
Value Function Loss: 0.05364

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06442
Policy Update Magnitude: 0.69077
Value Function Update Magnitude: 0.62437

Collected Steps per Second: 22,136.09415
Overall Steps per Second: 10,628.76364

Timestep Collection Time: 2.26020
Timestep Consumption Time: 2.44703
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.70723

Cumulative Model Updates: 66,350
Cumulative Timesteps: 553,328,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,796.82945
Policy Entropy: 3.74005
Value Function Loss: 0.05332

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.65202
Value Function Update Magnitude: 0.62035

Collected Steps per Second: 23,148.37320
Overall Steps per Second: 10,971.91963

Timestep Collection Time: 2.15998
Timestep Consumption Time: 2.39711
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.55709

Cumulative Model Updates: 66,356
Cumulative Timesteps: 553,378,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 553378562...
Checkpoint 553378562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,610.86895
Policy Entropy: 3.73143
Value Function Loss: 0.05606

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.57022
Value Function Update Magnitude: 0.57590

Collected Steps per Second: 22,651.47158
Overall Steps per Second: 10,682.86843

Timestep Collection Time: 2.20745
Timestep Consumption Time: 2.47313
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.68058

Cumulative Model Updates: 66,362
Cumulative Timesteps: 553,428,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,842.51944
Policy Entropy: 3.73706
Value Function Loss: 0.05482

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.56746
Value Function Update Magnitude: 0.62803

Collected Steps per Second: 23,300.79680
Overall Steps per Second: 10,783.69852

Timestep Collection Time: 2.14619
Timestep Consumption Time: 2.49118
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.63737

Cumulative Model Updates: 66,368
Cumulative Timesteps: 553,478,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 553478572...
Checkpoint 553478572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,511.74734
Policy Entropy: 3.73326
Value Function Loss: 0.05605

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.56482
Value Function Update Magnitude: 0.67609

Collected Steps per Second: 22,417.84020
Overall Steps per Second: 10,670.42639

Timestep Collection Time: 2.23153
Timestep Consumption Time: 2.45676
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.68829

Cumulative Model Updates: 66,374
Cumulative Timesteps: 553,528,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,973.99819
Policy Entropy: 3.73786
Value Function Loss: 0.05540

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.51054
Value Function Update Magnitude: 0.69015

Collected Steps per Second: 23,056.69736
Overall Steps per Second: 10,905.78010

Timestep Collection Time: 2.16978
Timestep Consumption Time: 2.41751
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.58729

Cumulative Model Updates: 66,380
Cumulative Timesteps: 553,578,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 553578626...
Checkpoint 553578626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,951.13363
Policy Entropy: 3.74252
Value Function Loss: 0.05873

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.51243
Value Function Update Magnitude: 0.68910

Collected Steps per Second: 22,370.68335
Overall Steps per Second: 10,611.10495

Timestep Collection Time: 2.23614
Timestep Consumption Time: 2.47817
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.71431

Cumulative Model Updates: 66,386
Cumulative Timesteps: 553,628,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,151.15743
Policy Entropy: 3.73623
Value Function Loss: 0.05944

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.58898
Value Function Update Magnitude: 0.68215

Collected Steps per Second: 23,026.60338
Overall Steps per Second: 10,864.56699

Timestep Collection Time: 2.17210
Timestep Consumption Time: 2.43149
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.60359

Cumulative Model Updates: 66,392
Cumulative Timesteps: 553,678,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 553678666...
Checkpoint 553678666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,228.61148
Policy Entropy: 3.74302
Value Function Loss: 0.06007

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.63507
Value Function Update Magnitude: 0.66148

Collected Steps per Second: 22,554.05325
Overall Steps per Second: 10,683.97276

Timestep Collection Time: 2.21699
Timestep Consumption Time: 2.46311
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.68009

Cumulative Model Updates: 66,398
Cumulative Timesteps: 553,728,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,669.06553
Policy Entropy: 3.72922
Value Function Loss: 0.05909

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.64405
Value Function Update Magnitude: 0.66848

Collected Steps per Second: 23,178.30248
Overall Steps per Second: 10,977.86346

Timestep Collection Time: 2.15788
Timestep Consumption Time: 2.39820
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.55608

Cumulative Model Updates: 66,404
Cumulative Timesteps: 553,778,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 553778684...
Checkpoint 553778684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,940.77934
Policy Entropy: 3.72695
Value Function Loss: 0.06138

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.59670
Value Function Update Magnitude: 0.64644

Collected Steps per Second: 22,408.54431
Overall Steps per Second: 10,573.49104

Timestep Collection Time: 2.23138
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.72900

Cumulative Model Updates: 66,410
Cumulative Timesteps: 553,828,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,958.05646
Policy Entropy: 3.72354
Value Function Loss: 0.06304

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.52076
Value Function Update Magnitude: 0.64608

Collected Steps per Second: 22,692.24365
Overall Steps per Second: 10,676.50543

Timestep Collection Time: 2.20401
Timestep Consumption Time: 2.48048
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.68449

Cumulative Model Updates: 66,416
Cumulative Timesteps: 553,878,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 553878700...
Checkpoint 553878700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,335.02685
Policy Entropy: 3.70723
Value Function Loss: 0.06432

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.52135
Value Function Update Magnitude: 0.60942

Collected Steps per Second: 22,935.84820
Overall Steps per Second: 10,904.55630

Timestep Collection Time: 2.18008
Timestep Consumption Time: 2.40534
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.58542

Cumulative Model Updates: 66,422
Cumulative Timesteps: 553,928,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,843.40806
Policy Entropy: 3.73031
Value Function Loss: 0.06212

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.53686
Value Function Update Magnitude: 0.66291

Collected Steps per Second: 23,063.93776
Overall Steps per Second: 10,888.08148

Timestep Collection Time: 2.16884
Timestep Consumption Time: 2.42536
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.59420

Cumulative Model Updates: 66,428
Cumulative Timesteps: 553,978,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 553978724...
Checkpoint 553978724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,456.57062
Policy Entropy: 3.74731
Value Function Loss: 0.05898

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.59935
Value Function Update Magnitude: 0.74835

Collected Steps per Second: 22,518.73283
Overall Steps per Second: 10,617.86189

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.71149

Cumulative Model Updates: 66,434
Cumulative Timesteps: 554,028,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,360.95913
Policy Entropy: 3.74321
Value Function Loss: 0.05720

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.66074
Value Function Update Magnitude: 0.79007

Collected Steps per Second: 22,972.91940
Overall Steps per Second: 10,919.15374

Timestep Collection Time: 2.17682
Timestep Consumption Time: 2.40302
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.57984

Cumulative Model Updates: 66,440
Cumulative Timesteps: 554,078,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 554078758...
Checkpoint 554078758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,030.14628
Policy Entropy: 3.74164
Value Function Loss: 0.05727

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.66558
Value Function Update Magnitude: 0.76938

Collected Steps per Second: 22,507.70757
Overall Steps per Second: 10,654.68503

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.47141
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.69296

Cumulative Model Updates: 66,446
Cumulative Timesteps: 554,128,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,341.54526
Policy Entropy: 3.74073
Value Function Loss: 0.05868

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.63938
Value Function Update Magnitude: 0.76550

Collected Steps per Second: 23,165.81069
Overall Steps per Second: 10,882.66154

Timestep Collection Time: 2.15878
Timestep Consumption Time: 2.43660
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.59538

Cumulative Model Updates: 66,452
Cumulative Timesteps: 554,178,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 554178770...
Checkpoint 554178770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,342.87571
Policy Entropy: 3.74928
Value Function Loss: 0.05887

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.67094
Value Function Update Magnitude: 0.75665

Collected Steps per Second: 22,523.46697
Overall Steps per Second: 10,668.85867

Timestep Collection Time: 2.22017
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.68710

Cumulative Model Updates: 66,458
Cumulative Timesteps: 554,228,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,334.39601
Policy Entropy: 3.75506
Value Function Loss: 0.05997

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.64691
Value Function Update Magnitude: 0.71123

Collected Steps per Second: 23,173.35460
Overall Steps per Second: 10,891.05596

Timestep Collection Time: 2.15774
Timestep Consumption Time: 2.43337
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.59111

Cumulative Model Updates: 66,464
Cumulative Timesteps: 554,278,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 554278778...
Checkpoint 554278778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,708.42724
Policy Entropy: 3.76015
Value Function Loss: 0.05997

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.56768
Value Function Update Magnitude: 0.72137

Collected Steps per Second: 22,698.54729
Overall Steps per Second: 10,613.47511

Timestep Collection Time: 2.20402
Timestep Consumption Time: 2.50961
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.71363

Cumulative Model Updates: 66,470
Cumulative Timesteps: 554,328,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,138.73197
Policy Entropy: 3.76057
Value Function Loss: 0.05886

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.54455
Value Function Update Magnitude: 0.80221

Collected Steps per Second: 22,680.71962
Overall Steps per Second: 10,864.30155

Timestep Collection Time: 2.20584
Timestep Consumption Time: 2.39915
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60499

Cumulative Model Updates: 66,476
Cumulative Timesteps: 554,378,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 554378836...
Checkpoint 554378836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,054.97881
Policy Entropy: 3.75674
Value Function Loss: 0.05691

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.53805
Value Function Update Magnitude: 0.84463

Collected Steps per Second: 22,371.01949
Overall Steps per Second: 10,755.83986

Timestep Collection Time: 2.23611
Timestep Consumption Time: 2.41476
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.65087

Cumulative Model Updates: 66,482
Cumulative Timesteps: 554,428,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,259.59221
Policy Entropy: 3.74294
Value Function Loss: 0.05638

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.52289
Value Function Update Magnitude: 0.83087

Collected Steps per Second: 23,146.57056
Overall Steps per Second: 10,904.06913

Timestep Collection Time: 2.16136
Timestep Consumption Time: 2.42666
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.58801

Cumulative Model Updates: 66,488
Cumulative Timesteps: 554,478,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 554478888...
Checkpoint 554478888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,356.58876
Policy Entropy: 3.75098
Value Function Loss: 0.05397

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.51108
Value Function Update Magnitude: 0.82628

Collected Steps per Second: 22,751.51460
Overall Steps per Second: 10,633.79652

Timestep Collection Time: 2.19783
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.70237

Cumulative Model Updates: 66,494
Cumulative Timesteps: 554,528,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,378.78515
Policy Entropy: 3.74602
Value Function Loss: 0.05138

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.50449
Value Function Update Magnitude: 0.82013

Collected Steps per Second: 23,007.41127
Overall Steps per Second: 10,845.35770

Timestep Collection Time: 2.17330
Timestep Consumption Time: 2.43715
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.61045

Cumulative Model Updates: 66,500
Cumulative Timesteps: 554,578,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 554578894...
Checkpoint 554578894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,871.45996
Policy Entropy: 3.75127
Value Function Loss: 0.05114

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.50311
Value Function Update Magnitude: 0.79103

Collected Steps per Second: 22,286.73628
Overall Steps per Second: 10,742.13774

Timestep Collection Time: 2.24358
Timestep Consumption Time: 2.41118
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.65475

Cumulative Model Updates: 66,506
Cumulative Timesteps: 554,628,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,948.01965
Policy Entropy: 3.73426
Value Function Loss: 0.05525

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06348
Policy Update Magnitude: 0.58135
Value Function Update Magnitude: 0.77836

Collected Steps per Second: 22,995.11935
Overall Steps per Second: 10,851.60803

Timestep Collection Time: 2.17524
Timestep Consumption Time: 2.43421
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.60946

Cumulative Model Updates: 66,512
Cumulative Timesteps: 554,678,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 554678916...
Checkpoint 554678916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,065.39778
Policy Entropy: 3.73994
Value Function Loss: 0.05980

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06423
Policy Update Magnitude: 0.68475
Value Function Update Magnitude: 0.76835

Collected Steps per Second: 22,629.57098
Overall Steps per Second: 10,626.55426

Timestep Collection Time: 2.21109
Timestep Consumption Time: 2.49749
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.70858

Cumulative Model Updates: 66,518
Cumulative Timesteps: 554,728,952

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,450.59183
Policy Entropy: 3.74234
Value Function Loss: 0.06353

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06937
Policy Update Magnitude: 0.69918
Value Function Update Magnitude: 0.70379

Collected Steps per Second: 22,998.07882
Overall Steps per Second: 10,855.14905

Timestep Collection Time: 2.17444
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.60685

Cumulative Model Updates: 66,524
Cumulative Timesteps: 554,778,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 554778960...
Checkpoint 554778960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,988.71000
Policy Entropy: 3.74325
Value Function Loss: 0.06252

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.69301
Value Function Update Magnitude: 0.74848

Collected Steps per Second: 22,336.51826
Overall Steps per Second: 10,746.70633

Timestep Collection Time: 2.23884
Timestep Consumption Time: 2.41449
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.65333

Cumulative Model Updates: 66,530
Cumulative Timesteps: 554,828,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,350.12573
Policy Entropy: 3.74335
Value Function Loss: 0.06247

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.61272
Value Function Update Magnitude: 0.78416

Collected Steps per Second: 22,897.75917
Overall Steps per Second: 10,812.53285

Timestep Collection Time: 2.18423
Timestep Consumption Time: 2.44133
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.62556

Cumulative Model Updates: 66,536
Cumulative Timesteps: 554,878,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 554878982...
Checkpoint 554878982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,640.94026
Policy Entropy: 3.76010
Value Function Loss: 0.05855

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.17192
Policy Update Magnitude: 0.48998
Value Function Update Magnitude: 0.80273

Collected Steps per Second: 22,737.78272
Overall Steps per Second: 10,685.79834

Timestep Collection Time: 2.19942
Timestep Consumption Time: 2.48062
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.68004

Cumulative Model Updates: 66,542
Cumulative Timesteps: 554,928,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,441.75170
Policy Entropy: 3.75292
Value Function Loss: 0.05793

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.49434
Value Function Update Magnitude: 0.79765

Collected Steps per Second: 22,903.74259
Overall Steps per Second: 10,844.30126

Timestep Collection Time: 2.18331
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61127

Cumulative Model Updates: 66,548
Cumulative Timesteps: 554,978,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 554978998...
Checkpoint 554978998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,050.92535
Policy Entropy: 3.74774
Value Function Loss: 0.05776

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.51986
Value Function Update Magnitude: 0.65649

Collected Steps per Second: 22,364.13366
Overall Steps per Second: 10,758.85401

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.41181
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.64771

Cumulative Model Updates: 66,554
Cumulative Timesteps: 555,029,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,567.75694
Policy Entropy: 3.74732
Value Function Loss: 0.05906

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.53302
Value Function Update Magnitude: 0.62233

Collected Steps per Second: 23,175.64307
Overall Steps per Second: 10,841.15487

Timestep Collection Time: 2.15873
Timestep Consumption Time: 2.45609
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.61482

Cumulative Model Updates: 66,560
Cumulative Timesteps: 555,079,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 555079032...
Checkpoint 555079032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,470.82465
Policy Entropy: 3.74209
Value Function Loss: 0.06034

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.50406
Value Function Update Magnitude: 0.62088

Collected Steps per Second: 22,499.36630
Overall Steps per Second: 10,663.13687

Timestep Collection Time: 2.22344
Timestep Consumption Time: 2.46805
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.69149

Cumulative Model Updates: 66,566
Cumulative Timesteps: 555,129,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,042.34396
Policy Entropy: 3.73406
Value Function Loss: 0.05944

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07570
Policy Update Magnitude: 0.54988
Value Function Update Magnitude: 0.66874

Collected Steps per Second: 23,082.69577
Overall Steps per Second: 10,865.98918

Timestep Collection Time: 2.16630
Timestep Consumption Time: 2.43558
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60188

Cumulative Model Updates: 66,572
Cumulative Timesteps: 555,179,062

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 555179062...
Checkpoint 555179062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,597.50091
Policy Entropy: 3.73131
Value Function Loss: 0.06027

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.56931
Value Function Update Magnitude: 0.76570

Collected Steps per Second: 22,428.59278
Overall Steps per Second: 10,681.58281

Timestep Collection Time: 2.22974
Timestep Consumption Time: 2.45215
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.68189

Cumulative Model Updates: 66,578
Cumulative Timesteps: 555,229,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,783.06033
Policy Entropy: 3.71243
Value Function Loss: 0.05790

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.52177
Value Function Update Magnitude: 0.82294

Collected Steps per Second: 22,089.11236
Overall Steps per Second: 10,808.78594

Timestep Collection Time: 2.26401
Timestep Consumption Time: 2.36278
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.62679

Cumulative Model Updates: 66,584
Cumulative Timesteps: 555,279,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 555279082...
Checkpoint 555279082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,402.72417
Policy Entropy: 3.71975
Value Function Loss: 0.05504

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.58982
Value Function Update Magnitude: 0.81583

Collected Steps per Second: 21,716.39889
Overall Steps per Second: 10,774.68192

Timestep Collection Time: 2.30278
Timestep Consumption Time: 2.33847
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.64125

Cumulative Model Updates: 66,590
Cumulative Timesteps: 555,329,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,824.99893
Policy Entropy: 3.71987
Value Function Loss: 0.05587

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.55830
Value Function Update Magnitude: 0.82878

Collected Steps per Second: 22,444.71542
Overall Steps per Second: 10,873.87099

Timestep Collection Time: 2.22796
Timestep Consumption Time: 2.37077
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.59873

Cumulative Model Updates: 66,596
Cumulative Timesteps: 555,379,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 555379096...
Checkpoint 555379096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,992.65372
Policy Entropy: 3.73855
Value Function Loss: 0.05765

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.51142
Value Function Update Magnitude: 0.83520

Collected Steps per Second: 21,846.91646
Overall Steps per Second: 10,667.22642

Timestep Collection Time: 2.28984
Timestep Consumption Time: 2.39985
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.68969

Cumulative Model Updates: 66,602
Cumulative Timesteps: 555,429,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,111.93120
Policy Entropy: 3.72241
Value Function Loss: 0.06082

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.41495
Value Function Update Magnitude: 0.85500

Collected Steps per Second: 22,985.94240
Overall Steps per Second: 10,852.10461

Timestep Collection Time: 2.17568
Timestep Consumption Time: 2.43265
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.60832

Cumulative Model Updates: 66,608
Cumulative Timesteps: 555,479,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 555479132...
Checkpoint 555479132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,302.86233
Policy Entropy: 3.73826
Value Function Loss: 0.06099

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.42999
Value Function Update Magnitude: 0.81830

Collected Steps per Second: 22,367.38572
Overall Steps per Second: 10,611.85689

Timestep Collection Time: 2.23549
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.71190

Cumulative Model Updates: 66,614
Cumulative Timesteps: 555,529,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,550.37516
Policy Entropy: 3.73372
Value Function Loss: 0.05976

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.51481
Value Function Update Magnitude: 0.75834

Collected Steps per Second: 22,744.30384
Overall Steps per Second: 10,872.57618

Timestep Collection Time: 2.19958
Timestep Consumption Time: 2.40172
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.60130

Cumulative Model Updates: 66,620
Cumulative Timesteps: 555,579,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 555579162...
Checkpoint 555579162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,893.76949
Policy Entropy: 3.73165
Value Function Loss: 0.05811

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.52760
Value Function Update Magnitude: 0.81434

Collected Steps per Second: 22,198.38004
Overall Steps per Second: 10,709.16824

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.41687
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.66964

Cumulative Model Updates: 66,626
Cumulative Timesteps: 555,629,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,645.87568
Policy Entropy: 3.73198
Value Function Loss: 0.05531

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.44886
Value Function Update Magnitude: 0.85740

Collected Steps per Second: 22,877.14685
Overall Steps per Second: 10,871.10778

Timestep Collection Time: 2.18585
Timestep Consumption Time: 2.41405
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.59990

Cumulative Model Updates: 66,632
Cumulative Timesteps: 555,679,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 555679176...
Checkpoint 555679176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,827.20513
Policy Entropy: 3.73823
Value Function Loss: 0.05537

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.48681
Value Function Update Magnitude: 0.86677

Collected Steps per Second: 22,735.44459
Overall Steps per Second: 10,657.61866

Timestep Collection Time: 2.20018
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.69354

Cumulative Model Updates: 66,638
Cumulative Timesteps: 555,729,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,084.04341
Policy Entropy: 3.74690
Value Function Loss: 0.05495

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.57632
Value Function Update Magnitude: 0.84590

Collected Steps per Second: 22,928.61763
Overall Steps per Second: 10,926.16067

Timestep Collection Time: 2.18112
Timestep Consumption Time: 2.39597
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.57709

Cumulative Model Updates: 66,644
Cumulative Timesteps: 555,779,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 555779208...
Checkpoint 555779208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,780.32862
Policy Entropy: 3.77517
Value Function Loss: 0.05659

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.57290
Value Function Update Magnitude: 0.86632

Collected Steps per Second: 22,420.35873
Overall Steps per Second: 10,617.53962

Timestep Collection Time: 2.23074
Timestep Consumption Time: 2.47977
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.71051

Cumulative Model Updates: 66,650
Cumulative Timesteps: 555,829,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,671.26929
Policy Entropy: 3.77163
Value Function Loss: 0.05446

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.59663
Value Function Update Magnitude: 0.85258

Collected Steps per Second: 23,185.26803
Overall Steps per Second: 10,883.74717

Timestep Collection Time: 2.15680
Timestep Consumption Time: 2.43776
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.59456

Cumulative Model Updates: 66,656
Cumulative Timesteps: 555,879,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 555879228...
Checkpoint 555879228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,287.66002
Policy Entropy: 3.77883
Value Function Loss: 0.05572

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.61011
Value Function Update Magnitude: 0.77870

Collected Steps per Second: 22,427.09523
Overall Steps per Second: 10,675.16444

Timestep Collection Time: 2.22945
Timestep Consumption Time: 2.45432
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.68377

Cumulative Model Updates: 66,662
Cumulative Timesteps: 555,929,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,738.97145
Policy Entropy: 3.76932
Value Function Loss: 0.05635

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.62568
Value Function Update Magnitude: 0.80632

Collected Steps per Second: 22,718.93791
Overall Steps per Second: 10,673.59743

Timestep Collection Time: 2.20134
Timestep Consumption Time: 2.48425
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.68558

Cumulative Model Updates: 66,668
Cumulative Timesteps: 555,979,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 555979240...
Checkpoint 555979240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,003.74308
Policy Entropy: 3.75364
Value Function Loss: 0.05675

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.62619
Value Function Update Magnitude: 0.79910

Collected Steps per Second: 22,474.72739
Overall Steps per Second: 10,677.05203

Timestep Collection Time: 2.22543
Timestep Consumption Time: 2.45901
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.68444

Cumulative Model Updates: 66,674
Cumulative Timesteps: 556,029,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,882.90390
Policy Entropy: 3.74333
Value Function Loss: 0.05806

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.57679
Value Function Update Magnitude: 0.80881

Collected Steps per Second: 22,991.57323
Overall Steps per Second: 10,695.07031

Timestep Collection Time: 2.17558
Timestep Consumption Time: 2.50134
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.67692

Cumulative Model Updates: 66,680
Cumulative Timesteps: 556,079,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 556079276...
Checkpoint 556079276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,746.98797
Policy Entropy: 3.72902
Value Function Loss: 0.05835

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.49971
Value Function Update Magnitude: 0.80897

Collected Steps per Second: 22,460.15546
Overall Steps per Second: 10,566.32926

Timestep Collection Time: 2.22661
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.73296

Cumulative Model Updates: 66,686
Cumulative Timesteps: 556,129,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,980.18037
Policy Entropy: 3.72656
Value Function Loss: 0.05939

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.46369
Value Function Update Magnitude: 0.84266

Collected Steps per Second: 22,856.36797
Overall Steps per Second: 10,836.78403

Timestep Collection Time: 2.18871
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.61631

Cumulative Model Updates: 66,692
Cumulative Timesteps: 556,179,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 556179312...
Checkpoint 556179312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,893.35157
Policy Entropy: 3.72084
Value Function Loss: 0.05743

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.48420
Value Function Update Magnitude: 0.85775

Collected Steps per Second: 22,648.71625
Overall Steps per Second: 10,722.55882

Timestep Collection Time: 2.20860
Timestep Consumption Time: 2.45652
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.66512

Cumulative Model Updates: 66,698
Cumulative Timesteps: 556,229,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,017.90578
Policy Entropy: 3.72462
Value Function Loss: 0.05800

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.46307
Value Function Update Magnitude: 0.85547

Collected Steps per Second: 22,664.39116
Overall Steps per Second: 10,843.85125

Timestep Collection Time: 2.20646
Timestep Consumption Time: 2.40519
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.61165

Cumulative Model Updates: 66,704
Cumulative Timesteps: 556,279,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 556279342...
Checkpoint 556279342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,369.91666
Policy Entropy: 3.71860
Value Function Loss: 0.05806

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.50697
Value Function Update Magnitude: 0.86606

Collected Steps per Second: 22,241.47993
Overall Steps per Second: 10,673.35867

Timestep Collection Time: 2.24868
Timestep Consumption Time: 2.43719
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.68587

Cumulative Model Updates: 66,710
Cumulative Timesteps: 556,329,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,915.64801
Policy Entropy: 3.71123
Value Function Loss: 0.06086

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.54200
Value Function Update Magnitude: 0.83644

Collected Steps per Second: 22,964.45533
Overall Steps per Second: 10,853.84413

Timestep Collection Time: 2.17780
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60777

Cumulative Model Updates: 66,716
Cumulative Timesteps: 556,379,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 556379368...
Checkpoint 556379368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,189.68459
Policy Entropy: 3.71097
Value Function Loss: 0.06111

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.51855
Value Function Update Magnitude: 0.85017

Collected Steps per Second: 22,362.03575
Overall Steps per Second: 10,739.14946

Timestep Collection Time: 2.23620
Timestep Consumption Time: 2.42022
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.65642

Cumulative Model Updates: 66,722
Cumulative Timesteps: 556,429,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,817.05371
Policy Entropy: 3.71640
Value Function Loss: 0.06085

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06831
Policy Update Magnitude: 0.58613
Value Function Update Magnitude: 0.86232

Collected Steps per Second: 23,006.03372
Overall Steps per Second: 10,844.52344

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61173

Cumulative Model Updates: 66,728
Cumulative Timesteps: 556,479,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 556479386...
Checkpoint 556479386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,111.63705
Policy Entropy: 3.70403
Value Function Loss: 0.06112

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.66984
Value Function Update Magnitude: 0.86650

Collected Steps per Second: 22,612.46215
Overall Steps per Second: 10,697.24935

Timestep Collection Time: 2.21232
Timestep Consumption Time: 2.46421
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.67653

Cumulative Model Updates: 66,734
Cumulative Timesteps: 556,529,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,649.02865
Policy Entropy: 3.70525
Value Function Loss: 0.06187

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.58169
Value Function Update Magnitude: 0.87486

Collected Steps per Second: 23,094.29462
Overall Steps per Second: 10,876.18784

Timestep Collection Time: 2.16512
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.59738

Cumulative Model Updates: 66,740
Cumulative Timesteps: 556,579,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 556579414...
Checkpoint 556579414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,724.49149
Policy Entropy: 3.69158
Value Function Loss: 0.06188

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.55086
Value Function Update Magnitude: 0.87195

Collected Steps per Second: 22,076.41226
Overall Steps per Second: 10,644.50743

Timestep Collection Time: 2.26595
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.69951

Cumulative Model Updates: 66,746
Cumulative Timesteps: 556,629,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,719.37000
Policy Entropy: 3.69348
Value Function Loss: 0.06289

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06695
Policy Update Magnitude: 0.57374
Value Function Update Magnitude: 0.85739

Collected Steps per Second: 23,095.48875
Overall Steps per Second: 10,893.57962

Timestep Collection Time: 2.16657
Timestep Consumption Time: 2.42678
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59335

Cumulative Model Updates: 66,752
Cumulative Timesteps: 556,679,476

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 556679476...
Checkpoint 556679476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,643.58828
Policy Entropy: 3.68030
Value Function Loss: 0.06450

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.67250
Value Function Update Magnitude: 0.83367

Collected Steps per Second: 22,448.26818
Overall Steps per Second: 10,657.44278

Timestep Collection Time: 2.22752
Timestep Consumption Time: 2.46441
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.69193

Cumulative Model Updates: 66,758
Cumulative Timesteps: 556,729,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,509.74313
Policy Entropy: 3.69595
Value Function Loss: 0.06523

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.62824
Value Function Update Magnitude: 0.84537

Collected Steps per Second: 23,121.49629
Overall Steps per Second: 10,883.78113

Timestep Collection Time: 2.16353
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.59620

Cumulative Model Updates: 66,764
Cumulative Timesteps: 556,779,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 556779504...
Checkpoint 556779504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,370.61868
Policy Entropy: 3.68897
Value Function Loss: 0.06781

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.58209
Value Function Update Magnitude: 0.79643

Collected Steps per Second: 22,308.11483
Overall Steps per Second: 10,719.53370

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.42421
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.66662

Cumulative Model Updates: 66,770
Cumulative Timesteps: 556,829,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,125.26254
Policy Entropy: 3.68453
Value Function Loss: 0.06677

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.51669
Value Function Update Magnitude: 0.74231

Collected Steps per Second: 22,901.15157
Overall Steps per Second: 10,819.02436

Timestep Collection Time: 2.18461
Timestep Consumption Time: 2.43966
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.62426

Cumulative Model Updates: 66,776
Cumulative Timesteps: 556,879,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 556879558...
Checkpoint 556879558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,154.09223
Policy Entropy: 3.68100
Value Function Loss: 0.06727

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.51151
Value Function Update Magnitude: 0.79950

Collected Steps per Second: 22,573.75153
Overall Steps per Second: 10,681.89681

Timestep Collection Time: 2.21603
Timestep Consumption Time: 2.46704
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.68306

Cumulative Model Updates: 66,782
Cumulative Timesteps: 556,929,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,501.95739
Policy Entropy: 3.67988
Value Function Loss: 0.06878

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09739
Policy Update Magnitude: 0.49703
Value Function Update Magnitude: 0.80706

Collected Steps per Second: 23,127.11166
Overall Steps per Second: 10,886.51674

Timestep Collection Time: 2.16335
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.59578

Cumulative Model Updates: 66,788
Cumulative Timesteps: 556,979,614

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 556979614...
Checkpoint 556979614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,388.80818
Policy Entropy: 3.68408
Value Function Loss: 0.06963

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.47340
Value Function Update Magnitude: 0.73373

Collected Steps per Second: 22,302.62445
Overall Steps per Second: 10,747.64980

Timestep Collection Time: 2.24234
Timestep Consumption Time: 2.41077
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.65311

Cumulative Model Updates: 66,794
Cumulative Timesteps: 557,029,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,004.91460
Policy Entropy: 3.68509
Value Function Loss: 0.06851

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.45618
Value Function Update Magnitude: 0.70243

Collected Steps per Second: 22,631.80440
Overall Steps per Second: 10,757.47280

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.43972
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.64998

Cumulative Model Updates: 66,800
Cumulative Timesteps: 557,079,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 557079646...
Checkpoint 557079646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,661.84150
Policy Entropy: 3.69135
Value Function Loss: 0.06674

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.45965
Value Function Update Magnitude: 0.75385

Collected Steps per Second: 21,564.84568
Overall Steps per Second: 10,382.21458

Timestep Collection Time: 2.31933
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.81747

Cumulative Model Updates: 66,806
Cumulative Timesteps: 557,129,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,898.46933
Policy Entropy: 3.68620
Value Function Loss: 0.06534

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.45684
Value Function Update Magnitude: 0.81730

Collected Steps per Second: 23,159.21619
Overall Steps per Second: 10,831.59330

Timestep Collection Time: 2.15983
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.61797

Cumulative Model Updates: 66,812
Cumulative Timesteps: 557,179,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 557179682...
Checkpoint 557179682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,994.15247
Policy Entropy: 3.68144
Value Function Loss: 0.06558

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.50808
Value Function Update Magnitude: 0.82144

Collected Steps per Second: 22,462.44585
Overall Steps per Second: 10,609.21191

Timestep Collection Time: 2.22647
Timestep Consumption Time: 2.48754
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.71402

Cumulative Model Updates: 66,818
Cumulative Timesteps: 557,229,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,765.71865
Policy Entropy: 3.67424
Value Function Loss: 0.06811

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.49277
Value Function Update Magnitude: 0.74229

Collected Steps per Second: 23,113.35805
Overall Steps per Second: 10,875.26391

Timestep Collection Time: 2.16377
Timestep Consumption Time: 2.43492
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.59869

Cumulative Model Updates: 66,824
Cumulative Timesteps: 557,279,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 557279706...
Checkpoint 557279706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,456.19767
Policy Entropy: 3.67266
Value Function Loss: 0.06919

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.48351
Value Function Update Magnitude: 0.73101

Collected Steps per Second: 22,552.83862
Overall Steps per Second: 10,671.43020

Timestep Collection Time: 2.21710
Timestep Consumption Time: 2.46849
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.68559

Cumulative Model Updates: 66,830
Cumulative Timesteps: 557,329,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,274.70263
Policy Entropy: 3.66618
Value Function Loss: 0.07135

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.55676
Value Function Update Magnitude: 0.77439

Collected Steps per Second: 23,072.02111
Overall Steps per Second: 10,910.57489

Timestep Collection Time: 2.16773
Timestep Consumption Time: 2.41626
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.58399

Cumulative Model Updates: 66,836
Cumulative Timesteps: 557,379,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 557379722...
Checkpoint 557379722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,088.09411
Policy Entropy: 3.68042
Value Function Loss: 0.07119

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.50348
Value Function Update Magnitude: 0.74252

Collected Steps per Second: 22,185.13017
Overall Steps per Second: 10,712.18713

Timestep Collection Time: 2.25385
Timestep Consumption Time: 2.41392
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.66777

Cumulative Model Updates: 66,842
Cumulative Timesteps: 557,429,724

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,333.24440
Policy Entropy: 3.68202
Value Function Loss: 0.07118

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.41479
Value Function Update Magnitude: 0.75416

Collected Steps per Second: 22,971.08007
Overall Steps per Second: 10,887.46559

Timestep Collection Time: 2.17726
Timestep Consumption Time: 2.41646
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.59372

Cumulative Model Updates: 66,848
Cumulative Timesteps: 557,479,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 557479738...
Checkpoint 557479738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,326.04856
Policy Entropy: 3.68321
Value Function Loss: 0.07074

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06979
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.76593

Collected Steps per Second: 22,359.40301
Overall Steps per Second: 10,568.54034

Timestep Collection Time: 2.23664
Timestep Consumption Time: 2.49533
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.73197

Cumulative Model Updates: 66,854
Cumulative Timesteps: 557,529,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.11274
Policy Entropy: 3.67710
Value Function Loss: 0.06970

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06690
Policy Update Magnitude: 0.75939
Value Function Update Magnitude: 0.85205

Collected Steps per Second: 23,024.92800
Overall Steps per Second: 10,870.26647

Timestep Collection Time: 2.17191
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60044

Cumulative Model Updates: 66,860
Cumulative Timesteps: 557,579,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 557579756...
Checkpoint 557579756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,114.10781
Policy Entropy: 3.67412
Value Function Loss: 0.06988

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.73118
Value Function Update Magnitude: 0.92640

Collected Steps per Second: 21,788.89835
Overall Steps per Second: 10,666.90280

Timestep Collection Time: 2.29548
Timestep Consumption Time: 2.39342
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.68890

Cumulative Model Updates: 66,866
Cumulative Timesteps: 557,629,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,024.06520
Policy Entropy: 3.66811
Value Function Loss: 0.07335

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.63391
Value Function Update Magnitude: 0.85540

Collected Steps per Second: 22,043.41156
Overall Steps per Second: 10,698.37478

Timestep Collection Time: 2.26934
Timestep Consumption Time: 2.40651
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.67585

Cumulative Model Updates: 66,872
Cumulative Timesteps: 557,679,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 557679796...
Checkpoint 557679796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,326.16946
Policy Entropy: 3.66184
Value Function Loss: 0.07291

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09616
Policy Update Magnitude: 0.72779
Value Function Update Magnitude: 0.70079

Collected Steps per Second: 22,257.46717
Overall Steps per Second: 10,890.00860

Timestep Collection Time: 2.24644
Timestep Consumption Time: 2.34493
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.59136

Cumulative Model Updates: 66,878
Cumulative Timesteps: 557,729,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,175.20868
Policy Entropy: 3.66849
Value Function Loss: 0.07145

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.73232
Value Function Update Magnitude: 0.63478

Collected Steps per Second: 22,199.15092
Overall Steps per Second: 10,863.58698

Timestep Collection Time: 2.25369
Timestep Consumption Time: 2.35160
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.60529

Cumulative Model Updates: 66,884
Cumulative Timesteps: 557,779,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 557779826...
Checkpoint 557779826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,097.15856
Policy Entropy: 3.67720
Value Function Loss: 0.06689

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.57081
Value Function Update Magnitude: 0.64875

Collected Steps per Second: 21,909.07833
Overall Steps per Second: 10,664.34101

Timestep Collection Time: 2.28408
Timestep Consumption Time: 2.40838
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.69246

Cumulative Model Updates: 66,890
Cumulative Timesteps: 557,829,868

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,392.47732
Policy Entropy: 3.68714
Value Function Loss: 0.06715

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.53981
Value Function Update Magnitude: 0.65978

Collected Steps per Second: 22,497.28904
Overall Steps per Second: 10,934.13015

Timestep Collection Time: 2.22338
Timestep Consumption Time: 2.35129
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.57467

Cumulative Model Updates: 66,896
Cumulative Timesteps: 557,879,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 557879888...
Checkpoint 557879888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,475.08176
Policy Entropy: 3.69404
Value Function Loss: 0.06705

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.57964
Value Function Update Magnitude: 0.65921

Collected Steps per Second: 21,900.55793
Overall Steps per Second: 10,676.69049

Timestep Collection Time: 2.28405
Timestep Consumption Time: 2.40111
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.68516

Cumulative Model Updates: 66,902
Cumulative Timesteps: 557,929,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,957.07898
Policy Entropy: 3.68019
Value Function Loss: 0.07034

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.54437
Value Function Update Magnitude: 0.71225

Collected Steps per Second: 23,031.29042
Overall Steps per Second: 10,875.02346

Timestep Collection Time: 2.17174
Timestep Consumption Time: 2.42761
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.59935

Cumulative Model Updates: 66,908
Cumulative Timesteps: 557,979,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 557979928...
Checkpoint 557979928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,011.14157
Policy Entropy: 3.66908
Value Function Loss: 0.06993

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.51003
Value Function Update Magnitude: 0.71681

Collected Steps per Second: 22,306.05005
Overall Steps per Second: 10,621.16823

Timestep Collection Time: 2.24208
Timestep Consumption Time: 2.46663
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.70871

Cumulative Model Updates: 66,914
Cumulative Timesteps: 558,029,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,484.39085
Policy Entropy: 3.67607
Value Function Loss: 0.06773

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.52244
Value Function Update Magnitude: 0.69045

Collected Steps per Second: 22,792.76727
Overall Steps per Second: 10,844.33293

Timestep Collection Time: 2.19508
Timestep Consumption Time: 2.41857
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61365

Cumulative Model Updates: 66,920
Cumulative Timesteps: 558,079,972

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 558079972...
Checkpoint 558079972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,624.03924
Policy Entropy: 3.69810
Value Function Loss: 0.06432

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.70622

Collected Steps per Second: 22,344.55827
Overall Steps per Second: 10,718.77197

Timestep Collection Time: 2.23902
Timestep Consumption Time: 2.42849
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.66751

Cumulative Model Updates: 66,926
Cumulative Timesteps: 558,130,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,976.01210
Policy Entropy: 3.69678
Value Function Loss: 0.06504

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.53478
Value Function Update Magnitude: 0.76262

Collected Steps per Second: 23,152.85981
Overall Steps per Second: 10,879.79945

Timestep Collection Time: 2.15973
Timestep Consumption Time: 2.43631
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59604

Cumulative Model Updates: 66,932
Cumulative Timesteps: 558,180,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 558180006...
Checkpoint 558180006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,673.67782
Policy Entropy: 3.68536
Value Function Loss: 0.06629

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.50380
Value Function Update Magnitude: 0.85760

Collected Steps per Second: 22,673.89889
Overall Steps per Second: 10,660.99445

Timestep Collection Time: 2.20580
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.69131

Cumulative Model Updates: 66,938
Cumulative Timesteps: 558,230,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,926.07601
Policy Entropy: 3.68079
Value Function Loss: 0.06744

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.48030
Value Function Update Magnitude: 0.88031

Collected Steps per Second: 22,967.63137
Overall Steps per Second: 10,759.53948

Timestep Collection Time: 2.17811
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.64946

Cumulative Model Updates: 66,944
Cumulative Timesteps: 558,280,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 558280046...
Checkpoint 558280046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,821.52346
Policy Entropy: 3.68831
Value Function Loss: 0.06589

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.52636
Value Function Update Magnitude: 0.85179

Collected Steps per Second: 22,325.99251
Overall Steps per Second: 10,710.14706

Timestep Collection Time: 2.24098
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.67146

Cumulative Model Updates: 66,950
Cumulative Timesteps: 558,330,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,070.58756
Policy Entropy: 3.68457
Value Function Loss: 0.06652

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.51226
Value Function Update Magnitude: 0.81644

Collected Steps per Second: 22,897.42605
Overall Steps per Second: 10,716.62767

Timestep Collection Time: 2.18487
Timestep Consumption Time: 2.48339
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.66826

Cumulative Model Updates: 66,956
Cumulative Timesteps: 558,380,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 558380106...
Checkpoint 558380106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,776.72169
Policy Entropy: 3.70292
Value Function Loss: 0.06509

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09280
Policy Update Magnitude: 0.52549
Value Function Update Magnitude: 0.70877

Collected Steps per Second: 22,505.14317
Overall Steps per Second: 10,644.67157

Timestep Collection Time: 2.22305
Timestep Consumption Time: 2.47696
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.70000

Cumulative Model Updates: 66,962
Cumulative Timesteps: 558,430,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,276.05324
Policy Entropy: 3.70072
Value Function Loss: 0.06815

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.69626
Value Function Update Magnitude: 0.65920

Collected Steps per Second: 22,868.13811
Overall Steps per Second: 10,722.12060

Timestep Collection Time: 2.18837
Timestep Consumption Time: 2.47899
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.66736

Cumulative Model Updates: 66,968
Cumulative Timesteps: 558,480,180

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 558480180...
Checkpoint 558480180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,767.02621
Policy Entropy: 3.70781
Value Function Loss: 0.07143

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.72831
Value Function Update Magnitude: 0.66094

Collected Steps per Second: 22,540.49489
Overall Steps per Second: 10,627.85918

Timestep Collection Time: 2.21850
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.70518

Cumulative Model Updates: 66,974
Cumulative Timesteps: 558,530,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,767.34042
Policy Entropy: 3.71447
Value Function Loss: 0.07337

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.65375
Value Function Update Magnitude: 0.68206

Collected Steps per Second: 23,032.38067
Overall Steps per Second: 10,877.25290

Timestep Collection Time: 2.17164
Timestep Consumption Time: 2.42677
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59840

Cumulative Model Updates: 66,980
Cumulative Timesteps: 558,580,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 558580204...
Checkpoint 558580204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,753.66361
Policy Entropy: 3.69969
Value Function Loss: 0.07148

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.52882
Value Function Update Magnitude: 0.68091

Collected Steps per Second: 22,545.85103
Overall Steps per Second: 10,677.26492

Timestep Collection Time: 2.21841
Timestep Consumption Time: 2.46593
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.68435

Cumulative Model Updates: 66,986
Cumulative Timesteps: 558,630,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,419.07346
Policy Entropy: 3.70392
Value Function Loss: 0.06890

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.52292
Value Function Update Magnitude: 0.65816

Collected Steps per Second: 23,123.13160
Overall Steps per Second: 10,879.14167

Timestep Collection Time: 2.16459
Timestep Consumption Time: 2.43614
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60073

Cumulative Model Updates: 66,992
Cumulative Timesteps: 558,680,272

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 558680272...
Checkpoint 558680272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,687.32863
Policy Entropy: 3.70864
Value Function Loss: 0.06978

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.49779
Value Function Update Magnitude: 0.69876

Collected Steps per Second: 22,224.08366
Overall Steps per Second: 10,738.17987

Timestep Collection Time: 2.25035
Timestep Consumption Time: 2.40705
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.65740

Cumulative Model Updates: 66,998
Cumulative Timesteps: 558,730,284

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,316.93144
Policy Entropy: 3.70587
Value Function Loss: 0.07059

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.53129
Value Function Update Magnitude: 0.80600

Collected Steps per Second: 23,289.91798
Overall Steps per Second: 10,850.09331

Timestep Collection Time: 2.14685
Timestep Consumption Time: 2.46140
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.60826

Cumulative Model Updates: 67,004
Cumulative Timesteps: 558,780,284

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 558780284...
Checkpoint 558780284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,151.48508
Policy Entropy: 3.69936
Value Function Loss: 0.07142

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.51723
Value Function Update Magnitude: 0.84415

Collected Steps per Second: 21,872.04026
Overall Steps per Second: 10,622.53266

Timestep Collection Time: 2.28694
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.70886

Cumulative Model Updates: 67,010
Cumulative Timesteps: 558,830,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,341.38408
Policy Entropy: 3.69626
Value Function Loss: 0.07152

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.45681
Value Function Update Magnitude: 0.73892

Collected Steps per Second: 22,351.93130
Overall Steps per Second: 10,869.92115

Timestep Collection Time: 2.23802
Timestep Consumption Time: 2.36404
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60206

Cumulative Model Updates: 67,016
Cumulative Timesteps: 558,880,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 558880328...
Checkpoint 558880328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,969.20763
Policy Entropy: 3.69548
Value Function Loss: 0.07162

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11108
Policy Update Magnitude: 0.47312
Value Function Update Magnitude: 0.73507

Collected Steps per Second: 21,927.23400
Overall Steps per Second: 10,671.05932

Timestep Collection Time: 2.28054
Timestep Consumption Time: 2.40559
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.68613

Cumulative Model Updates: 67,022
Cumulative Timesteps: 558,930,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,592.70920
Policy Entropy: 3.69985
Value Function Loss: 0.06876

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.52398
Value Function Update Magnitude: 0.74280

Collected Steps per Second: 21,988.74949
Overall Steps per Second: 10,677.40075

Timestep Collection Time: 2.27535
Timestep Consumption Time: 2.41044
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.68578

Cumulative Model Updates: 67,028
Cumulative Timesteps: 558,980,366

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 558980366...
Checkpoint 558980366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,494.94588
Policy Entropy: 3.70796
Value Function Loss: 0.06604

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.46620
Value Function Update Magnitude: 0.71395

Collected Steps per Second: 22,177.13132
Overall Steps per Second: 10,886.16059

Timestep Collection Time: 2.25530
Timestep Consumption Time: 2.33916
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.59446

Cumulative Model Updates: 67,034
Cumulative Timesteps: 559,030,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,464.77313
Policy Entropy: 3.71195
Value Function Loss: 0.06187

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.53032
Value Function Update Magnitude: 0.79479

Collected Steps per Second: 22,167.61112
Overall Steps per Second: 10,555.44985

Timestep Collection Time: 2.25681
Timestep Consumption Time: 2.48274
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.73954

Cumulative Model Updates: 67,040
Cumulative Timesteps: 559,080,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 559080410...
Checkpoint 559080410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,554.22258
Policy Entropy: 3.70062
Value Function Loss: 0.06091

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.56966
Value Function Update Magnitude: 0.85974

Collected Steps per Second: 22,615.59938
Overall Steps per Second: 10,703.62338

Timestep Collection Time: 2.21148
Timestep Consumption Time: 2.46114
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.67262

Cumulative Model Updates: 67,046
Cumulative Timesteps: 559,130,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,743.91572
Policy Entropy: 3.69483
Value Function Loss: 0.06288

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.57566
Value Function Update Magnitude: 0.77293

Collected Steps per Second: 22,897.64863
Overall Steps per Second: 10,756.60773

Timestep Collection Time: 2.18415
Timestep Consumption Time: 2.46527
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.64942

Cumulative Model Updates: 67,052
Cumulative Timesteps: 559,180,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 559180436...
Checkpoint 559180436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,210.39493
Policy Entropy: 3.67900
Value Function Loss: 0.06659

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.50659
Value Function Update Magnitude: 0.72420

Collected Steps per Second: 22,810.84345
Overall Steps per Second: 10,719.77965

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.47362
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.66670

Cumulative Model Updates: 67,058
Cumulative Timesteps: 559,230,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,760.78994
Policy Entropy: 3.68410
Value Function Loss: 0.06556

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.49048
Value Function Update Magnitude: 0.76215

Collected Steps per Second: 23,169.29737
Overall Steps per Second: 10,834.38847

Timestep Collection Time: 2.15915
Timestep Consumption Time: 2.45818
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.61733

Cumulative Model Updates: 67,064
Cumulative Timesteps: 559,280,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 559280488...
Checkpoint 559280488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,386.26987
Policy Entropy: 3.68127
Value Function Loss: 0.06236

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.60834
Value Function Update Magnitude: 0.78285

Collected Steps per Second: 22,593.54114
Overall Steps per Second: 10,626.34200

Timestep Collection Time: 2.21497
Timestep Consumption Time: 2.49446
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.70943

Cumulative Model Updates: 67,070
Cumulative Timesteps: 559,330,532

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,936.26866
Policy Entropy: 3.69009
Value Function Loss: 0.06071

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.64823
Value Function Update Magnitude: 0.75897

Collected Steps per Second: 22,884.74369
Overall Steps per Second: 10,823.03722

Timestep Collection Time: 2.18486
Timestep Consumption Time: 2.43491
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61978

Cumulative Model Updates: 67,076
Cumulative Timesteps: 559,380,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 559380532...
Checkpoint 559380532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,842.27120
Policy Entropy: 3.70125
Value Function Loss: 0.05929

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.77944

Collected Steps per Second: 22,315.95893
Overall Steps per Second: 10,725.17410

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.42215
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.66342

Cumulative Model Updates: 67,082
Cumulative Timesteps: 559,430,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,548.64726
Policy Entropy: 3.69958
Value Function Loss: 0.05899

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.44066
Value Function Update Magnitude: 0.87105

Collected Steps per Second: 23,013.24633
Overall Steps per Second: 10,861.33284

Timestep Collection Time: 2.17336
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.60496

Cumulative Model Updates: 67,088
Cumulative Timesteps: 559,480,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 559480564...
Checkpoint 559480564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,394.64131
Policy Entropy: 3.70614
Value Function Loss: 0.05919

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.45542
Value Function Update Magnitude: 0.88184

Collected Steps per Second: 22,445.88512
Overall Steps per Second: 10,657.87007

Timestep Collection Time: 2.22794
Timestep Consumption Time: 2.46418
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.69212

Cumulative Model Updates: 67,094
Cumulative Timesteps: 559,530,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,760.85312
Policy Entropy: 3.70532
Value Function Loss: 0.05990

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.48426
Value Function Update Magnitude: 0.83965

Collected Steps per Second: 22,844.62531
Overall Steps per Second: 10,731.65522

Timestep Collection Time: 2.18975
Timestep Consumption Time: 2.47160
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.66135

Cumulative Model Updates: 67,100
Cumulative Timesteps: 559,580,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 559580596...
Checkpoint 559580596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,840.31403
Policy Entropy: 3.71946
Value Function Loss: 0.05916

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.44676
Value Function Update Magnitude: 0.81142

Collected Steps per Second: 22,337.53343
Overall Steps per Second: 10,763.57056

Timestep Collection Time: 2.23937
Timestep Consumption Time: 2.40797
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.64734

Cumulative Model Updates: 67,106
Cumulative Timesteps: 559,630,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,016.48267
Policy Entropy: 3.72511
Value Function Loss: 0.06088

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.46754
Value Function Update Magnitude: 0.77405

Collected Steps per Second: 23,140.88680
Overall Steps per Second: 10,881.30570

Timestep Collection Time: 2.16137
Timestep Consumption Time: 2.43514
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59651

Cumulative Model Updates: 67,112
Cumulative Timesteps: 559,680,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 559680634...
Checkpoint 559680634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,717.26306
Policy Entropy: 3.71302
Value Function Loss: 0.06185

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07998
Policy Update Magnitude: 0.58576
Value Function Update Magnitude: 0.78132

Collected Steps per Second: 22,479.55690
Overall Steps per Second: 10,742.71425

Timestep Collection Time: 2.22433
Timestep Consumption Time: 2.43017
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.65450

Cumulative Model Updates: 67,118
Cumulative Timesteps: 559,730,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,525.79529
Policy Entropy: 3.71751
Value Function Loss: 0.06047

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.71345
Value Function Update Magnitude: 0.74829

Collected Steps per Second: 23,251.56849
Overall Steps per Second: 10,948.40714

Timestep Collection Time: 2.15168
Timestep Consumption Time: 2.41793
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.56961

Cumulative Model Updates: 67,124
Cumulative Timesteps: 559,780,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 559780666...
Checkpoint 559780666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,278.62142
Policy Entropy: 3.70745
Value Function Loss: 0.05995

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.72756
Value Function Update Magnitude: 0.70273

Collected Steps per Second: 22,189.18371
Overall Steps per Second: 10,611.03815

Timestep Collection Time: 2.25380
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.71302

Cumulative Model Updates: 67,130
Cumulative Timesteps: 559,830,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,881.21348
Policy Entropy: 3.70260
Value Function Loss: 0.05864

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.61894
Value Function Update Magnitude: 0.68004

Collected Steps per Second: 23,217.06545
Overall Steps per Second: 10,914.79554

Timestep Collection Time: 2.15462
Timestep Consumption Time: 2.42851
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58314

Cumulative Model Updates: 67,136
Cumulative Timesteps: 559,880,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 559880700...
Checkpoint 559880700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,007.90481
Policy Entropy: 3.70035
Value Function Loss: 0.06194

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.67874
Value Function Update Magnitude: 0.78521

Collected Steps per Second: 22,812.22691
Overall Steps per Second: 10,654.86687

Timestep Collection Time: 2.19295
Timestep Consumption Time: 2.50218
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.69513

Cumulative Model Updates: 67,142
Cumulative Timesteps: 559,930,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,664.59293
Policy Entropy: 3.68954
Value Function Loss: 0.06208

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.70198
Value Function Update Magnitude: 0.83538

Collected Steps per Second: 23,031.31563
Overall Steps per Second: 10,856.73348

Timestep Collection Time: 2.17191
Timestep Consumption Time: 2.43555
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.60746

Cumulative Model Updates: 67,148
Cumulative Timesteps: 559,980,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 559980748...
Checkpoint 559980748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.45889
Policy Entropy: 3.69758
Value Function Loss: 0.06275

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.86273

Collected Steps per Second: 22,005.60354
Overall Steps per Second: 10,627.65386

Timestep Collection Time: 2.27242
Timestep Consumption Time: 2.43285
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.70527

Cumulative Model Updates: 67,154
Cumulative Timesteps: 560,030,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,612.85945
Policy Entropy: 3.70088
Value Function Loss: 0.06265

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.53111
Value Function Update Magnitude: 0.88896

Collected Steps per Second: 22,873.92714
Overall Steps per Second: 10,820.62866

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.43608
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62302

Cumulative Model Updates: 67,160
Cumulative Timesteps: 560,080,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 560080778...
Checkpoint 560080778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,108.94884
Policy Entropy: 3.70752
Value Function Loss: 0.06285

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.53619
Value Function Update Magnitude: 0.90002

Collected Steps per Second: 22,474.82718
Overall Steps per Second: 10,716.53939

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.44107
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.66587

Cumulative Model Updates: 67,166
Cumulative Timesteps: 560,130,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,344.66302
Policy Entropy: 3.70445
Value Function Loss: 0.06280

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.52447
Value Function Update Magnitude: 0.89500

Collected Steps per Second: 22,903.53984
Overall Steps per Second: 10,860.88219

Timestep Collection Time: 2.18438
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.60644

Cumulative Model Updates: 67,172
Cumulative Timesteps: 560,180,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 560180810...
Checkpoint 560180810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,330.61060
Policy Entropy: 3.72384
Value Function Loss: 0.06213

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.53243
Value Function Update Magnitude: 0.87672

Collected Steps per Second: 21,996.26990
Overall Steps per Second: 10,597.21823

Timestep Collection Time: 2.27393
Timestep Consumption Time: 2.44599
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.71992

Cumulative Model Updates: 67,178
Cumulative Timesteps: 560,230,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,359.45014
Policy Entropy: 3.71733
Value Function Loss: 0.06523

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.58579
Value Function Update Magnitude: 0.80958

Collected Steps per Second: 23,025.38811
Overall Steps per Second: 10,732.01400

Timestep Collection Time: 2.17186
Timestep Consumption Time: 2.48784
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.65970

Cumulative Model Updates: 67,184
Cumulative Timesteps: 560,280,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 560280836...
Checkpoint 560280836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,047.68337
Policy Entropy: 3.72479
Value Function Loss: 0.06399

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.58657
Value Function Update Magnitude: 0.74742

Collected Steps per Second: 22,562.46258
Overall Steps per Second: 10,621.44906

Timestep Collection Time: 2.21678
Timestep Consumption Time: 2.49218
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.70896

Cumulative Model Updates: 67,190
Cumulative Timesteps: 560,330,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,121.83205
Policy Entropy: 3.70400
Value Function Loss: 0.06605

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.53822
Value Function Update Magnitude: 0.76526

Collected Steps per Second: 22,995.26868
Overall Steps per Second: 10,779.47166

Timestep Collection Time: 2.17514
Timestep Consumption Time: 2.46497
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.64012

Cumulative Model Updates: 67,196
Cumulative Timesteps: 560,380,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 560380870...
Checkpoint 560380870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.25335
Policy Entropy: 3.70404
Value Function Loss: 0.06358

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.51110
Value Function Update Magnitude: 0.78660

Collected Steps per Second: 22,381.45640
Overall Steps per Second: 10,619.02086

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.47563
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.71060

Cumulative Model Updates: 67,202
Cumulative Timesteps: 560,430,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,441.76098
Policy Entropy: 3.69481
Value Function Loss: 0.06423

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.50747
Value Function Update Magnitude: 0.77854

Collected Steps per Second: 23,069.69164
Overall Steps per Second: 10,869.96662

Timestep Collection Time: 2.16778
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60075

Cumulative Model Updates: 67,208
Cumulative Timesteps: 560,480,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 560480902...
Checkpoint 560480902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,640.70646
Policy Entropy: 3.69536
Value Function Loss: 0.06242

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.49072
Value Function Update Magnitude: 0.74215

Collected Steps per Second: 22,285.06924
Overall Steps per Second: 10,725.46682

Timestep Collection Time: 2.24446
Timestep Consumption Time: 2.41902
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.66348

Cumulative Model Updates: 67,214
Cumulative Timesteps: 560,530,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,432.61020
Policy Entropy: 3.69804
Value Function Loss: 0.06222

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.49474
Value Function Update Magnitude: 0.74064

Collected Steps per Second: 23,146.55620
Overall Steps per Second: 10,886.28708

Timestep Collection Time: 2.16075
Timestep Consumption Time: 2.43347
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.59422

Cumulative Model Updates: 67,220
Cumulative Timesteps: 560,580,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 560580934...
Checkpoint 560580934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,676.18100
Policy Entropy: 3.69995
Value Function Loss: 0.06275

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.52294
Value Function Update Magnitude: 0.73523

Collected Steps per Second: 22,533.81514
Overall Steps per Second: 10,608.76812

Timestep Collection Time: 2.21942
Timestep Consumption Time: 2.49479
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.71421

Cumulative Model Updates: 67,226
Cumulative Timesteps: 560,630,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,292.85395
Policy Entropy: 3.69642
Value Function Loss: 0.06470

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.51987
Value Function Update Magnitude: 0.76204

Collected Steps per Second: 22,836.14305
Overall Steps per Second: 10,831.26822

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.61811

Cumulative Model Updates: 67,232
Cumulative Timesteps: 560,680,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 560680966...
Checkpoint 560680966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,274.78676
Policy Entropy: 3.69130
Value Function Loss: 0.06498

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09310
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.85726

Collected Steps per Second: 22,319.77797
Overall Steps per Second: 10,741.93077

Timestep Collection Time: 2.24079
Timestep Consumption Time: 2.41517
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.65596

Cumulative Model Updates: 67,238
Cumulative Timesteps: 560,730,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,610.57700
Policy Entropy: 3.69627
Value Function Loss: 0.06512

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.62159
Value Function Update Magnitude: 0.82588

Collected Steps per Second: 22,815.27981
Overall Steps per Second: 10,851.26214

Timestep Collection Time: 2.19213
Timestep Consumption Time: 2.41692
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.60905

Cumulative Model Updates: 67,244
Cumulative Timesteps: 560,780,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 560780994...
Checkpoint 560780994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,644.20986
Policy Entropy: 3.68869
Value Function Loss: 0.06465

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.63001
Value Function Update Magnitude: 0.71462

Collected Steps per Second: 21,670.28358
Overall Steps per Second: 10,675.64403

Timestep Collection Time: 2.30777
Timestep Consumption Time: 2.37673
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.68449

Cumulative Model Updates: 67,250
Cumulative Timesteps: 560,831,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,714.09546
Policy Entropy: 3.69559
Value Function Loss: 0.06450

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.56049
Value Function Update Magnitude: 0.69081

Collected Steps per Second: 22,327.82165
Overall Steps per Second: 10,869.77292

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.36065
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60010

Cumulative Model Updates: 67,256
Cumulative Timesteps: 560,881,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 560881006...
Checkpoint 560881006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,150.26873
Policy Entropy: 3.70014
Value Function Loss: 0.06217

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.57437
Value Function Update Magnitude: 0.76870

Collected Steps per Second: 21,789.41675
Overall Steps per Second: 10,665.17680

Timestep Collection Time: 2.29533
Timestep Consumption Time: 2.39413
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.68947

Cumulative Model Updates: 67,262
Cumulative Timesteps: 560,931,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,669.06190
Policy Entropy: 3.70040
Value Function Loss: 0.06434

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.52581
Value Function Update Magnitude: 0.79806

Collected Steps per Second: 22,409.99738
Overall Steps per Second: 10,892.84615

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.35949
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59109

Cumulative Model Updates: 67,268
Cumulative Timesteps: 560,981,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 560981030...
Checkpoint 560981030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.04235
Policy Entropy: 3.70304
Value Function Loss: 0.06521

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.51404
Value Function Update Magnitude: 0.77474

Collected Steps per Second: 21,865.19918
Overall Steps per Second: 10,677.36747

Timestep Collection Time: 2.28893
Timestep Consumption Time: 2.39836
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.68730

Cumulative Model Updates: 67,274
Cumulative Timesteps: 561,031,078

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,381.96433
Policy Entropy: 3.69786
Value Function Loss: 0.06852

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.51314
Value Function Update Magnitude: 0.75425

Collected Steps per Second: 22,284.10667
Overall Steps per Second: 10,865.13390

Timestep Collection Time: 2.24375
Timestep Consumption Time: 2.35812
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.60188

Cumulative Model Updates: 67,280
Cumulative Timesteps: 561,081,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 561081078...
Checkpoint 561081078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,306.71196
Policy Entropy: 3.69630
Value Function Loss: 0.06882

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.50630
Value Function Update Magnitude: 0.81521

Collected Steps per Second: 21,910.18978
Overall Steps per Second: 10,646.08438

Timestep Collection Time: 2.28213
Timestep Consumption Time: 2.41462
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.69675

Cumulative Model Updates: 67,286
Cumulative Timesteps: 561,131,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,956.51612
Policy Entropy: 3.69307
Value Function Loss: 0.06900

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.49639
Value Function Update Magnitude: 0.83150

Collected Steps per Second: 23,102.01839
Overall Steps per Second: 10,963.16889

Timestep Collection Time: 2.16449
Timestep Consumption Time: 2.39660
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.56109

Cumulative Model Updates: 67,292
Cumulative Timesteps: 561,181,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 561181084...
Checkpoint 561181084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,520.04655
Policy Entropy: 3.67730
Value Function Loss: 0.06841

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.48545
Value Function Update Magnitude: 0.83573

Collected Steps per Second: 22,328.22808
Overall Steps per Second: 10,617.08213

Timestep Collection Time: 2.23986
Timestep Consumption Time: 2.47067
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.71052

Cumulative Model Updates: 67,298
Cumulative Timesteps: 561,231,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,211.42522
Policy Entropy: 3.68291
Value Function Loss: 0.06718

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.53536
Value Function Update Magnitude: 0.84002

Collected Steps per Second: 22,888.66503
Overall Steps per Second: 10,891.97829

Timestep Collection Time: 2.18527
Timestep Consumption Time: 2.40691
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.59219

Cumulative Model Updates: 67,304
Cumulative Timesteps: 561,281,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 561281114...
Checkpoint 561281114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,017.42856
Policy Entropy: 3.68002
Value Function Loss: 0.06648

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06224
Policy Update Magnitude: 0.68642
Value Function Update Magnitude: 0.88858

Collected Steps per Second: 22,826.53948
Overall Steps per Second: 10,724.96187

Timestep Collection Time: 2.19061
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.66239

Cumulative Model Updates: 67,310
Cumulative Timesteps: 561,331,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,013.58116
Policy Entropy: 3.68055
Value Function Loss: 0.07016

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.73926
Value Function Update Magnitude: 0.91774

Collected Steps per Second: 23,119.11983
Overall Steps per Second: 10,887.60905

Timestep Collection Time: 2.16280
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.59256

Cumulative Model Updates: 67,316
Cumulative Timesteps: 561,381,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 561381120...
Checkpoint 561381120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.55097
Policy Entropy: 3.67827
Value Function Loss: 0.06778

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.63328
Value Function Update Magnitude: 0.87703

Collected Steps per Second: 22,570.43692
Overall Steps per Second: 10,586.85679

Timestep Collection Time: 2.21529
Timestep Consumption Time: 2.50755
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.72284

Cumulative Model Updates: 67,322
Cumulative Timesteps: 561,431,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,361.08880
Policy Entropy: 3.67842
Value Function Loss: 0.06925

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.65657
Value Function Update Magnitude: 0.80963

Collected Steps per Second: 22,571.17986
Overall Steps per Second: 10,618.40960

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.70918

Cumulative Model Updates: 67,328
Cumulative Timesteps: 561,481,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 561481124...
Checkpoint 561481124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,428.66217
Policy Entropy: 3.69249
Value Function Loss: 0.06759

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.71880
Value Function Update Magnitude: 0.80882

Collected Steps per Second: 22,441.98334
Overall Steps per Second: 10,814.22109

Timestep Collection Time: 2.22904
Timestep Consumption Time: 2.39672
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.62576

Cumulative Model Updates: 67,334
Cumulative Timesteps: 561,531,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,397.26198
Policy Entropy: 3.67494
Value Function Loss: 0.06957

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.11853
Policy Update Magnitude: 0.64172
Value Function Update Magnitude: 0.76704

Collected Steps per Second: 23,085.04271
Overall Steps per Second: 10,766.47177

Timestep Collection Time: 2.16616
Timestep Consumption Time: 2.47844
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.64460

Cumulative Model Updates: 67,340
Cumulative Timesteps: 561,581,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 561581154...
Checkpoint 561581154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,595.88309
Policy Entropy: 3.66904
Value Function Loss: 0.07347

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.62168
Value Function Update Magnitude: 0.65872

Collected Steps per Second: 22,548.53658
Overall Steps per Second: 10,644.11702

Timestep Collection Time: 2.21762
Timestep Consumption Time: 2.48019
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.69781

Cumulative Model Updates: 67,346
Cumulative Timesteps: 561,631,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,162.47247
Policy Entropy: 3.67491
Value Function Loss: 0.07019

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.64134
Value Function Update Magnitude: 0.68580

Collected Steps per Second: 22,911.22300
Overall Steps per Second: 10,679.51237

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.50072
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.68411

Cumulative Model Updates: 67,352
Cumulative Timesteps: 561,681,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 561681182...
Checkpoint 561681182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,482.42658
Policy Entropy: 3.69732
Value Function Loss: 0.07170

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.75456

Collected Steps per Second: 22,514.23789
Overall Steps per Second: 10,645.52278

Timestep Collection Time: 2.22082
Timestep Consumption Time: 2.47599
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.69681

Cumulative Model Updates: 67,358
Cumulative Timesteps: 561,731,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,250.38327
Policy Entropy: 3.69823
Value Function Loss: 0.06951

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.50432
Value Function Update Magnitude: 0.71943

Collected Steps per Second: 23,117.93660
Overall Steps per Second: 10,878.74594

Timestep Collection Time: 2.16360
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.59777

Cumulative Model Updates: 67,364
Cumulative Timesteps: 561,781,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 561781200...
Checkpoint 561781200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,263.86681
Policy Entropy: 3.70069
Value Function Loss: 0.07206

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.51930
Value Function Update Magnitude: 0.74013

Collected Steps per Second: 22,365.20794
Overall Steps per Second: 10,687.37137

Timestep Collection Time: 2.23615
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.67954

Cumulative Model Updates: 67,370
Cumulative Timesteps: 561,831,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,430.06298
Policy Entropy: 3.70347
Value Function Loss: 0.06903

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.84087

Collected Steps per Second: 23,048.15038
Overall Steps per Second: 10,872.85670

Timestep Collection Time: 2.16963
Timestep Consumption Time: 2.42953
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.59916

Cumulative Model Updates: 67,376
Cumulative Timesteps: 561,881,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 561881218...
Checkpoint 561881218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,800.08541
Policy Entropy: 3.69721
Value Function Loss: 0.06639

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.66149
Value Function Update Magnitude: 0.84741

Collected Steps per Second: 22,320.38646
Overall Steps per Second: 10,642.80087

Timestep Collection Time: 2.24046
Timestep Consumption Time: 2.45830
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.69876

Cumulative Model Updates: 67,382
Cumulative Timesteps: 561,931,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,314.87301
Policy Entropy: 3.67942
Value Function Loss: 0.06623

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.70818
Value Function Update Magnitude: 0.77864

Collected Steps per Second: 23,024.75677
Overall Steps per Second: 10,869.06949

Timestep Collection Time: 2.17158
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60021

Cumulative Model Updates: 67,388
Cumulative Timesteps: 561,981,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 561981226...
Checkpoint 561981226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,917.67847
Policy Entropy: 3.67887
Value Function Loss: 0.06938

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.59932
Value Function Update Magnitude: 0.72641

Collected Steps per Second: 21,132.01898
Overall Steps per Second: 10,607.11114

Timestep Collection Time: 2.36750
Timestep Consumption Time: 2.34915
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.71665

Cumulative Model Updates: 67,394
Cumulative Timesteps: 562,031,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,833.00444
Policy Entropy: 3.68011
Value Function Loss: 0.07210

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.56210
Value Function Update Magnitude: 0.67018

Collected Steps per Second: 22,323.59091
Overall Steps per Second: 10,811.00270

Timestep Collection Time: 2.24005
Timestep Consumption Time: 2.38542
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.62547

Cumulative Model Updates: 67,400
Cumulative Timesteps: 562,081,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 562081262...
Checkpoint 562081262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,286.63857
Policy Entropy: 3.67529
Value Function Loss: 0.07427

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.50855
Value Function Update Magnitude: 0.65166

Collected Steps per Second: 21,874.07151
Overall Steps per Second: 10,790.10663

Timestep Collection Time: 2.28663
Timestep Consumption Time: 2.34891
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.63554

Cumulative Model Updates: 67,406
Cumulative Timesteps: 562,131,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,371.59312
Policy Entropy: 3.69784
Value Function Loss: 0.07385

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.47639
Value Function Update Magnitude: 0.72952

Collected Steps per Second: 22,171.67148
Overall Steps per Second: 10,864.77752

Timestep Collection Time: 2.25630
Timestep Consumption Time: 2.34812
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.60442

Cumulative Model Updates: 67,412
Cumulative Timesteps: 562,181,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 562181306...
Checkpoint 562181306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,230.78539
Policy Entropy: 3.69569
Value Function Loss: 0.07310

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.49874
Value Function Update Magnitude: 0.74818

Collected Steps per Second: 22,082.39941
Overall Steps per Second: 10,750.07371

Timestep Collection Time: 2.26425
Timestep Consumption Time: 2.38688
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.65113

Cumulative Model Updates: 67,418
Cumulative Timesteps: 562,231,306

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,875.48773
Policy Entropy: 3.70496
Value Function Loss: 0.07000

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.51922
Value Function Update Magnitude: 0.77243

Collected Steps per Second: 21,883.61544
Overall Steps per Second: 10,770.27984

Timestep Collection Time: 2.28500
Timestep Consumption Time: 2.35778
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.64278

Cumulative Model Updates: 67,424
Cumulative Timesteps: 562,281,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 562281310...
Checkpoint 562281310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,555.66826
Policy Entropy: 3.70242
Value Function Loss: 0.06935

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.56228
Value Function Update Magnitude: 0.77059

Collected Steps per Second: 22,094.93329
Overall Steps per Second: 10,736.46007

Timestep Collection Time: 2.26369
Timestep Consumption Time: 2.39483
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.65852

Cumulative Model Updates: 67,430
Cumulative Timesteps: 562,331,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,949.64831
Policy Entropy: 3.69667
Value Function Loss: 0.06796

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.55948
Value Function Update Magnitude: 0.76431

Collected Steps per Second: 22,494.63143
Overall Steps per Second: 10,835.80394

Timestep Collection Time: 2.22471
Timestep Consumption Time: 2.39368
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.61839

Cumulative Model Updates: 67,436
Cumulative Timesteps: 562,381,370

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 562381370...
Checkpoint 562381370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,142.22898
Policy Entropy: 3.69344
Value Function Loss: 0.06711

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.57059
Value Function Update Magnitude: 0.81371

Collected Steps per Second: 22,436.39318
Overall Steps per Second: 10,803.25960

Timestep Collection Time: 2.22986
Timestep Consumption Time: 2.40115
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.63101

Cumulative Model Updates: 67,442
Cumulative Timesteps: 562,431,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,983.33245
Policy Entropy: 3.70732
Value Function Loss: 0.06787

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.61639
Value Function Update Magnitude: 0.71022

Collected Steps per Second: 23,328.03578
Overall Steps per Second: 10,832.77446

Timestep Collection Time: 2.14394
Timestep Consumption Time: 2.47297
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.61692

Cumulative Model Updates: 67,448
Cumulative Timesteps: 562,481,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 562481414...
Checkpoint 562481414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,448.61990
Policy Entropy: 3.71662
Value Function Loss: 0.06700

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.61368
Value Function Update Magnitude: 0.71224

Collected Steps per Second: 22,803.46478
Overall Steps per Second: 10,745.92918

Timestep Collection Time: 2.19335
Timestep Consumption Time: 2.46106
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.65441

Cumulative Model Updates: 67,454
Cumulative Timesteps: 562,531,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.77186
Policy Entropy: 3.73763
Value Function Loss: 0.06374

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.72133

Collected Steps per Second: 23,103.59315
Overall Steps per Second: 10,797.76693

Timestep Collection Time: 2.16425
Timestep Consumption Time: 2.46652
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.63077

Cumulative Model Updates: 67,460
Cumulative Timesteps: 562,581,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 562581432...
Checkpoint 562581432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,513.89241
Policy Entropy: 3.73954
Value Function Loss: 0.06134

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.60170
Value Function Update Magnitude: 0.70708

Collected Steps per Second: 22,658.80603
Overall Steps per Second: 10,617.52548

Timestep Collection Time: 2.20691
Timestep Consumption Time: 2.50285
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.70976

Cumulative Model Updates: 67,466
Cumulative Timesteps: 562,631,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,168.58409
Policy Entropy: 3.74346
Value Function Loss: 0.05838

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.59127
Value Function Update Magnitude: 0.74886

Collected Steps per Second: 23,303.41274
Overall Steps per Second: 10,946.18041

Timestep Collection Time: 2.14638
Timestep Consumption Time: 2.42307
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.56945

Cumulative Model Updates: 67,472
Cumulative Timesteps: 562,681,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 562681456...
Checkpoint 562681456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.33381
Policy Entropy: 3.74096
Value Function Loss: 0.05788

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.53971
Value Function Update Magnitude: 0.79404

Collected Steps per Second: 22,274.11788
Overall Steps per Second: 10,588.96038

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.47823
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.72398

Cumulative Model Updates: 67,478
Cumulative Timesteps: 562,731,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,530.54261
Policy Entropy: 3.74223
Value Function Loss: 0.05820

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.82379

Collected Steps per Second: 23,027.63164
Overall Steps per Second: 10,870.47819

Timestep Collection Time: 2.17165
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.60035

Cumulative Model Updates: 67,484
Cumulative Timesteps: 562,781,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 562781486...
Checkpoint 562781486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,274.31046
Policy Entropy: 3.72848
Value Function Loss: 0.05873

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.58902
Value Function Update Magnitude: 0.80210

Collected Steps per Second: 22,437.33150
Overall Steps per Second: 10,692.28220

Timestep Collection Time: 2.22941
Timestep Consumption Time: 2.44892
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.67833

Cumulative Model Updates: 67,490
Cumulative Timesteps: 562,831,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,243.85898
Policy Entropy: 3.72839
Value Function Loss: 0.06280

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.59144
Value Function Update Magnitude: 0.73114

Collected Steps per Second: 23,049.86703
Overall Steps per Second: 10,855.72075

Timestep Collection Time: 2.17034
Timestep Consumption Time: 2.43792
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.60826

Cumulative Model Updates: 67,496
Cumulative Timesteps: 562,881,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 562881534...
Checkpoint 562881534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,961.39895
Policy Entropy: 3.72470
Value Function Loss: 0.06721

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.54316
Value Function Update Magnitude: 0.65988

Collected Steps per Second: 22,540.45185
Overall Steps per Second: 10,706.22130

Timestep Collection Time: 2.21930
Timestep Consumption Time: 2.45312
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.67242

Cumulative Model Updates: 67,502
Cumulative Timesteps: 562,931,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,546.10888
Policy Entropy: 3.70624
Value Function Loss: 0.06892

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.54943
Value Function Update Magnitude: 0.57943

Collected Steps per Second: 22,919.37169
Overall Steps per Second: 10,839.78586

Timestep Collection Time: 2.18243
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.61448

Cumulative Model Updates: 67,508
Cumulative Timesteps: 562,981,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 562981578...
Checkpoint 562981578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,674.87022
Policy Entropy: 3.70249
Value Function Loss: 0.06622

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.52935
Value Function Update Magnitude: 0.54704

Collected Steps per Second: 22,525.25243
Overall Steps per Second: 10,695.91957

Timestep Collection Time: 2.22097
Timestep Consumption Time: 2.45632
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.67730

Cumulative Model Updates: 67,514
Cumulative Timesteps: 563,031,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,713.44028
Policy Entropy: 3.69719
Value Function Loss: 0.06268

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.52776

Collected Steps per Second: 22,687.87455
Overall Steps per Second: 10,693.76301

Timestep Collection Time: 2.20488
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.67787

Cumulative Model Updates: 67,520
Cumulative Timesteps: 563,081,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 563081630...
Checkpoint 563081630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,495.59817
Policy Entropy: 3.71004
Value Function Loss: 0.06108

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.54080
Value Function Update Magnitude: 0.57734

Collected Steps per Second: 22,534.61262
Overall Steps per Second: 10,794.61406

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.41342
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.63250

Cumulative Model Updates: 67,526
Cumulative Timesteps: 563,131,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,669.19541
Policy Entropy: 3.70710
Value Function Loss: 0.05985

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06064
Policy Update Magnitude: 0.60369
Value Function Update Magnitude: 0.62653

Collected Steps per Second: 22,910.93162
Overall Steps per Second: 10,911.55395

Timestep Collection Time: 2.18289
Timestep Consumption Time: 2.40051
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.58340

Cumulative Model Updates: 67,532
Cumulative Timesteps: 563,181,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 563181648...
Checkpoint 563181648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,867.77532
Policy Entropy: 3.71940
Value Function Loss: 0.05878

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.69482
Value Function Update Magnitude: 0.67277

Collected Steps per Second: 22,409.93828
Overall Steps per Second: 10,720.93418

Timestep Collection Time: 2.23240
Timestep Consumption Time: 2.43398
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.66638

Cumulative Model Updates: 67,538
Cumulative Timesteps: 563,231,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,904.58475
Policy Entropy: 3.72483
Value Function Loss: 0.05930

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.70459
Value Function Update Magnitude: 0.67556

Collected Steps per Second: 23,004.99147
Overall Steps per Second: 10,859.33613

Timestep Collection Time: 2.17353
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.60452

Cumulative Model Updates: 67,544
Cumulative Timesteps: 563,281,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 563281678...
Checkpoint 563281678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,160.18323
Policy Entropy: 3.73763
Value Function Loss: 0.05955

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.59599
Value Function Update Magnitude: 0.69905

Collected Steps per Second: 22,726.38433
Overall Steps per Second: 10,638.71550

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.49973
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.69982

Cumulative Model Updates: 67,550
Cumulative Timesteps: 563,331,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,882.59376
Policy Entropy: 3.72247
Value Function Loss: 0.06227

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.57373
Value Function Update Magnitude: 0.74001

Collected Steps per Second: 23,255.36523
Overall Steps per Second: 10,928.14560

Timestep Collection Time: 2.15082
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.57699

Cumulative Model Updates: 67,556
Cumulative Timesteps: 563,381,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 563381696...
Checkpoint 563381696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,564.10785
Policy Entropy: 3.70585
Value Function Loss: 0.06252

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.54938
Value Function Update Magnitude: 0.78299

Collected Steps per Second: 22,272.01444
Overall Steps per Second: 10,717.75002

Timestep Collection Time: 2.24560
Timestep Consumption Time: 2.42087
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.66646

Cumulative Model Updates: 67,562
Cumulative Timesteps: 563,431,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,946.74802
Policy Entropy: 3.70797
Value Function Loss: 0.06633

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.51664
Value Function Update Magnitude: 0.80902

Collected Steps per Second: 23,082.21482
Overall Steps per Second: 10,880.39366

Timestep Collection Time: 2.16738
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.59800

Cumulative Model Updates: 67,568
Cumulative Timesteps: 563,481,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 563481738...
Checkpoint 563481738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,830.15283
Policy Entropy: 3.70774
Value Function Loss: 0.06594

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.48968
Value Function Update Magnitude: 0.83395

Collected Steps per Second: 22,823.78571
Overall Steps per Second: 10,755.02545

Timestep Collection Time: 2.19149
Timestep Consumption Time: 2.45918
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.65066

Cumulative Model Updates: 67,574
Cumulative Timesteps: 563,531,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,636.02053
Policy Entropy: 3.71098
Value Function Loss: 0.06473

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.48350
Value Function Update Magnitude: 0.84212

Collected Steps per Second: 22,757.68345
Overall Steps per Second: 10,729.94655

Timestep Collection Time: 2.19794
Timestep Consumption Time: 2.46378
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.66172

Cumulative Model Updates: 67,580
Cumulative Timesteps: 563,581,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 563581776...
Checkpoint 563581776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,559.03597
Policy Entropy: 3.70788
Value Function Loss: 0.06102

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.48663
Value Function Update Magnitude: 0.83237

Collected Steps per Second: 22,722.68828
Overall Steps per Second: 10,679.66691

Timestep Collection Time: 2.20062
Timestep Consumption Time: 2.48155
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.68217

Cumulative Model Updates: 67,586
Cumulative Timesteps: 563,631,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,959.72164
Policy Entropy: 3.69890
Value Function Loss: 0.06030

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.52719
Value Function Update Magnitude: 0.80725

Collected Steps per Second: 22,892.52271
Overall Steps per Second: 10,811.80308

Timestep Collection Time: 2.18429
Timestep Consumption Time: 2.44065
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.62495

Cumulative Model Updates: 67,592
Cumulative Timesteps: 563,681,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 563681784...
Checkpoint 563681784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,198.80502
Policy Entropy: 3.70086
Value Function Loss: 0.05991

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.80171

Collected Steps per Second: 22,614.43203
Overall Steps per Second: 10,705.76892

Timestep Collection Time: 2.21124
Timestep Consumption Time: 2.45970
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67094

Cumulative Model Updates: 67,598
Cumulative Timesteps: 563,731,790

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,998.16459
Policy Entropy: 3.68891
Value Function Loss: 0.06125

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.58191
Value Function Update Magnitude: 0.81710

Collected Steps per Second: 22,914.78775
Overall Steps per Second: 10,845.55208

Timestep Collection Time: 2.18366
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61369

Cumulative Model Updates: 67,604
Cumulative Timesteps: 563,781,828

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 563781828...
Checkpoint 563781828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,468.71444
Policy Entropy: 3.70051
Value Function Loss: 0.06110

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.53830
Value Function Update Magnitude: 0.81546

Collected Steps per Second: 22,507.98127
Overall Steps per Second: 10,760.28286

Timestep Collection Time: 2.22170
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.64728

Cumulative Model Updates: 67,610
Cumulative Timesteps: 563,831,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,467.79855
Policy Entropy: 3.70469
Value Function Loss: 0.06160

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.55765
Value Function Update Magnitude: 0.82787

Collected Steps per Second: 22,727.62597
Overall Steps per Second: 10,778.46487

Timestep Collection Time: 2.20041
Timestep Consumption Time: 2.43940
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.63981

Cumulative Model Updates: 67,616
Cumulative Timesteps: 563,881,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 563881844...
Checkpoint 563881844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,836.93499
Policy Entropy: 3.71805
Value Function Loss: 0.06339

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.52290
Value Function Update Magnitude: 0.75619

Collected Steps per Second: 22,670.08568
Overall Steps per Second: 10,732.09260

Timestep Collection Time: 2.20687
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.66172

Cumulative Model Updates: 67,622
Cumulative Timesteps: 563,931,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,156.00148
Policy Entropy: 3.71445
Value Function Loss: 0.06383

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.58937
Value Function Update Magnitude: 0.73284

Collected Steps per Second: 22,889.09889
Overall Steps per Second: 10,823.16984

Timestep Collection Time: 2.18514
Timestep Consumption Time: 2.43605
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62120

Cumulative Model Updates: 67,628
Cumulative Timesteps: 563,981,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 563981890...
Checkpoint 563981890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,646.86955
Policy Entropy: 3.71290
Value Function Loss: 0.06078

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.63759
Value Function Update Magnitude: 0.77493

Collected Steps per Second: 22,618.88918
Overall Steps per Second: 10,696.96320

Timestep Collection Time: 2.21054
Timestep Consumption Time: 2.46368
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.67422

Cumulative Model Updates: 67,634
Cumulative Timesteps: 564,031,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,056.01016
Policy Entropy: 3.71122
Value Function Loss: 0.06112

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.61351
Value Function Update Magnitude: 0.79970

Collected Steps per Second: 22,857.56810
Overall Steps per Second: 10,835.23840

Timestep Collection Time: 2.18763
Timestep Consumption Time: 2.42731
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.61494

Cumulative Model Updates: 67,640
Cumulative Timesteps: 564,081,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 564081894...
Checkpoint 564081894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,350.52253
Policy Entropy: 3.71505
Value Function Loss: 0.06145

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.58639
Value Function Update Magnitude: 0.82217

Collected Steps per Second: 22,711.32131
Overall Steps per Second: 10,719.15317

Timestep Collection Time: 2.20243
Timestep Consumption Time: 2.46399
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.66641

Cumulative Model Updates: 67,646
Cumulative Timesteps: 564,131,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,150.68160
Policy Entropy: 3.71699
Value Function Loss: 0.06170

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.58304
Value Function Update Magnitude: 0.82506

Collected Steps per Second: 23,030.60006
Overall Steps per Second: 10,852.30329

Timestep Collection Time: 2.17181
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.60898

Cumulative Model Updates: 67,652
Cumulative Timesteps: 564,181,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 564181932...
Checkpoint 564181932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,229.78065
Policy Entropy: 3.71829
Value Function Loss: 0.06204

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.57572
Value Function Update Magnitude: 0.82066

Collected Steps per Second: 22,536.06284
Overall Steps per Second: 10,718.95494

Timestep Collection Time: 2.21893
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.66519

Cumulative Model Updates: 67,658
Cumulative Timesteps: 564,231,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,826.00889
Policy Entropy: 3.71904
Value Function Loss: 0.06032

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.56549
Value Function Update Magnitude: 0.83446

Collected Steps per Second: 22,917.22583
Overall Steps per Second: 10,864.96370

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.42231
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.60600

Cumulative Model Updates: 67,664
Cumulative Timesteps: 564,281,982

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 564281982...
Checkpoint 564281982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,731.65184
Policy Entropy: 3.72229
Value Function Loss: 0.05965

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.54784
Value Function Update Magnitude: 0.85148

Collected Steps per Second: 22,640.47710
Overall Steps per Second: 10,684.36018

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.47229
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.68161

Cumulative Model Updates: 67,670
Cumulative Timesteps: 564,332,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,575.84577
Policy Entropy: 3.71978
Value Function Loss: 0.05899

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.56184
Value Function Update Magnitude: 0.86078

Collected Steps per Second: 22,996.49741
Overall Steps per Second: 10,860.61243

Timestep Collection Time: 2.17468
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60471

Cumulative Model Updates: 67,676
Cumulative Timesteps: 564,382,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 564382012...
Checkpoint 564382012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,876.00478
Policy Entropy: 3.71783
Value Function Loss: 0.05907

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.53979
Value Function Update Magnitude: 0.85063

Collected Steps per Second: 22,473.48383
Overall Steps per Second: 10,699.89870

Timestep Collection Time: 2.22618
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.67575

Cumulative Model Updates: 67,682
Cumulative Timesteps: 564,432,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,065.35149
Policy Entropy: 3.71157
Value Function Loss: 0.05869

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08714
Policy Update Magnitude: 0.53001
Value Function Update Magnitude: 0.83086

Collected Steps per Second: 22,951.31933
Overall Steps per Second: 10,933.36305

Timestep Collection Time: 2.17852
Timestep Consumption Time: 2.39463
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.57316

Cumulative Model Updates: 67,688
Cumulative Timesteps: 564,482,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 564482042...
Checkpoint 564482042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,994.27824
Policy Entropy: 3.69639
Value Function Loss: 0.06425

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.55140
Value Function Update Magnitude: 0.74434

Collected Steps per Second: 22,415.85853
Overall Steps per Second: 10,576.50090

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.73011

Cumulative Model Updates: 67,694
Cumulative Timesteps: 564,532,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,882.09561
Policy Entropy: 3.69288
Value Function Loss: 0.06363

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.78622

Collected Steps per Second: 22,924.32991
Overall Steps per Second: 10,920.12236

Timestep Collection Time: 2.18222
Timestep Consumption Time: 2.39886
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.58108

Cumulative Model Updates: 67,700
Cumulative Timesteps: 564,582,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 564582096...
Checkpoint 564582096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,692.08472
Policy Entropy: 3.69579
Value Function Loss: 0.06244

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.57523
Value Function Update Magnitude: 0.82633

Collected Steps per Second: 22,512.17992
Overall Steps per Second: 10,659.46202

Timestep Collection Time: 2.22120
Timestep Consumption Time: 2.46985
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.69104

Cumulative Model Updates: 67,706
Cumulative Timesteps: 564,632,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,309.06625
Policy Entropy: 3.70823
Value Function Loss: 0.05883

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.62338
Value Function Update Magnitude: 0.82712

Collected Steps per Second: 23,044.74751
Overall Steps per Second: 10,855.64035

Timestep Collection Time: 2.16978
Timestep Consumption Time: 2.43631
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.60608

Cumulative Model Updates: 67,712
Cumulative Timesteps: 564,682,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 564682102...
Checkpoint 564682102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,604.26270
Policy Entropy: 3.72312
Value Function Loss: 0.05669

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07118
Policy Update Magnitude: 0.66878
Value Function Update Magnitude: 0.83347

Collected Steps per Second: 22,710.24795
Overall Steps per Second: 10,649.83209

Timestep Collection Time: 2.20174
Timestep Consumption Time: 2.49336
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.69510

Cumulative Model Updates: 67,718
Cumulative Timesteps: 564,732,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.94075
Policy Entropy: 3.72357
Value Function Loss: 0.05621

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06514
Policy Update Magnitude: 0.72164
Value Function Update Magnitude: 0.84377

Collected Steps per Second: 23,021.42084
Overall Steps per Second: 10,864.37527

Timestep Collection Time: 2.17215
Timestep Consumption Time: 2.43060
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.60275

Cumulative Model Updates: 67,724
Cumulative Timesteps: 564,782,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 564782110...
Checkpoint 564782110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,751.34643
Policy Entropy: 3.72328
Value Function Loss: 0.05778

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.72886
Value Function Update Magnitude: 0.85310

Collected Steps per Second: 22,374.34959
Overall Steps per Second: 10,728.97764

Timestep Collection Time: 2.23569
Timestep Consumption Time: 2.42664
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.66233

Cumulative Model Updates: 67,730
Cumulative Timesteps: 564,832,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,663.17199
Policy Entropy: 3.71375
Value Function Loss: 0.05934

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.65600
Value Function Update Magnitude: 0.86683

Collected Steps per Second: 22,714.49425
Overall Steps per Second: 10,781.95405

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.43663
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.63831

Cumulative Model Updates: 67,736
Cumulative Timesteps: 564,882,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 564882142...
Checkpoint 564882142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,323.57320
Policy Entropy: 3.71715
Value Function Loss: 0.05898

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.59879
Value Function Update Magnitude: 0.88330

Collected Steps per Second: 22,825.18937
Overall Steps per Second: 10,716.43379

Timestep Collection Time: 2.19161
Timestep Consumption Time: 2.47636
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.66797

Cumulative Model Updates: 67,742
Cumulative Timesteps: 564,932,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,812.01662
Policy Entropy: 3.71981
Value Function Loss: 0.05587

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.56220
Value Function Update Magnitude: 0.90072

Collected Steps per Second: 22,914.49697
Overall Steps per Second: 10,841.97760

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61337

Cumulative Model Updates: 67,748
Cumulative Timesteps: 564,982,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 564982184...
Checkpoint 564982184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,330.33764
Policy Entropy: 3.72080
Value Function Loss: 0.05588

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.50397
Value Function Update Magnitude: 0.90213

Collected Steps per Second: 22,619.22668
Overall Steps per Second: 10,747.69218

Timestep Collection Time: 2.21130
Timestep Consumption Time: 2.44253
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.65384

Cumulative Model Updates: 67,754
Cumulative Timesteps: 565,032,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,087.21412
Policy Entropy: 3.73578
Value Function Loss: 0.05633

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.46922
Value Function Update Magnitude: 0.91177

Collected Steps per Second: 22,764.64089
Overall Steps per Second: 10,805.00835

Timestep Collection Time: 2.19639
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62748

Cumulative Model Updates: 67,760
Cumulative Timesteps: 565,082,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 565082202...
Checkpoint 565082202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,130.18728
Policy Entropy: 3.73573
Value Function Loss: 0.05994

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.45930
Value Function Update Magnitude: 0.92669

Collected Steps per Second: 22,503.88377
Overall Steps per Second: 10,741.89626

Timestep Collection Time: 2.22219
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.65542

Cumulative Model Updates: 67,766
Cumulative Timesteps: 565,132,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,916.86624
Policy Entropy: 3.73827
Value Function Loss: 0.05932

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.46066
Value Function Update Magnitude: 0.95145

Collected Steps per Second: 22,891.84539
Overall Steps per Second: 10,826.30241

Timestep Collection Time: 2.18497
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.62004

Cumulative Model Updates: 67,772
Cumulative Timesteps: 565,182,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 565182228...
Checkpoint 565182228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,351.49660
Policy Entropy: 3.73356
Value Function Loss: 0.05920

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.45027
Value Function Update Magnitude: 0.90882

Collected Steps per Second: 22,667.17244
Overall Steps per Second: 10,671.89650

Timestep Collection Time: 2.20627
Timestep Consumption Time: 2.47987
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.68614

Cumulative Model Updates: 67,778
Cumulative Timesteps: 565,232,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,767.10049
Policy Entropy: 3.71789
Value Function Loss: 0.06176

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.46835
Value Function Update Magnitude: 0.87462

Collected Steps per Second: 22,670.30135
Overall Steps per Second: 10,656.40266

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.69389

Cumulative Model Updates: 67,784
Cumulative Timesteps: 565,282,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 565282258...
Checkpoint 565282258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,624.08032
Policy Entropy: 3.71336
Value Function Loss: 0.06459

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.48419
Value Function Update Magnitude: 0.75024

Collected Steps per Second: 22,792.28764
Overall Steps per Second: 10,883.07199

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.40133
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.59576

Cumulative Model Updates: 67,790
Cumulative Timesteps: 565,332,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,154.90237
Policy Entropy: 3.70307
Value Function Loss: 0.06480

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.48058
Value Function Update Magnitude: 0.77817

Collected Steps per Second: 23,077.15553
Overall Steps per Second: 10,879.41708

Timestep Collection Time: 2.16751
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.59767

Cumulative Model Updates: 67,796
Cumulative Timesteps: 565,382,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 565382294...
Checkpoint 565382294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,874.08456
Policy Entropy: 3.70663
Value Function Loss: 0.06228

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.49177
Value Function Update Magnitude: 0.85060

Collected Steps per Second: 22,312.48751
Overall Steps per Second: 10,737.31817

Timestep Collection Time: 2.24161
Timestep Consumption Time: 2.41653
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.65815

Cumulative Model Updates: 67,802
Cumulative Timesteps: 565,432,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,980.66143
Policy Entropy: 3.70795
Value Function Loss: 0.05961

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.52803
Value Function Update Magnitude: 0.86999

Collected Steps per Second: 22,820.17098
Overall Steps per Second: 10,755.21861

Timestep Collection Time: 2.19218
Timestep Consumption Time: 2.45914
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.65132

Cumulative Model Updates: 67,808
Cumulative Timesteps: 565,482,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 565482336...
Checkpoint 565482336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,365.18953
Policy Entropy: 3.70760
Value Function Loss: 0.06101

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.52738
Value Function Update Magnitude: 0.88049

Collected Steps per Second: 22,305.19855
Overall Steps per Second: 10,691.70727

Timestep Collection Time: 2.24369
Timestep Consumption Time: 2.43713
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.68082

Cumulative Model Updates: 67,814
Cumulative Timesteps: 565,532,382

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,976.24113
Policy Entropy: 3.70415
Value Function Loss: 0.06058

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.60012
Value Function Update Magnitude: 0.85520

Collected Steps per Second: 22,769.91516
Overall Steps per Second: 10,702.49861

Timestep Collection Time: 2.19702
Timestep Consumption Time: 2.47721
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.67424

Cumulative Model Updates: 67,820
Cumulative Timesteps: 565,582,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 565582408...
Checkpoint 565582408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,551.99642
Policy Entropy: 3.70073
Value Function Loss: 0.06086

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.64296
Value Function Update Magnitude: 0.80684

Collected Steps per Second: 22,721.45003
Overall Steps per Second: 10,829.17260

Timestep Collection Time: 2.20259
Timestep Consumption Time: 2.41882
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.62141

Cumulative Model Updates: 67,826
Cumulative Timesteps: 565,632,454

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,631.67756
Policy Entropy: 3.70993
Value Function Loss: 0.06379

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.57698
Value Function Update Magnitude: 0.78068

Collected Steps per Second: 22,577.83955
Overall Steps per Second: 10,602.09121

Timestep Collection Time: 2.21492
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.71681

Cumulative Model Updates: 67,832
Cumulative Timesteps: 565,682,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 565682462...
Checkpoint 565682462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,412.05769
Policy Entropy: 3.70221
Value Function Loss: 0.06685

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.80678

Collected Steps per Second: 22,548.58006
Overall Steps per Second: 10,589.88958

Timestep Collection Time: 2.21841
Timestep Consumption Time: 2.50515
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.72356

Cumulative Model Updates: 67,838
Cumulative Timesteps: 565,732,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,272.06393
Policy Entropy: 3.69413
Value Function Loss: 0.07068

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.59695
Value Function Update Magnitude: 0.75464

Collected Steps per Second: 22,816.40716
Overall Steps per Second: 10,832.26174

Timestep Collection Time: 2.19219
Timestep Consumption Time: 2.42531
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61750

Cumulative Model Updates: 67,844
Cumulative Timesteps: 565,782,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 565782502...
Checkpoint 565782502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,685.22799
Policy Entropy: 3.68185
Value Function Loss: 0.07398

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.17674
Policy Update Magnitude: 0.51877
Value Function Update Magnitude: 0.69991

Collected Steps per Second: 22,518.05626
Overall Steps per Second: 10,708.30360

Timestep Collection Time: 2.22186
Timestep Consumption Time: 2.45040
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.67226

Cumulative Model Updates: 67,850
Cumulative Timesteps: 565,832,534

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,761.71336
Policy Entropy: 3.69219
Value Function Loss: 0.07040

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.44929
Value Function Update Magnitude: 0.70456

Collected Steps per Second: 22,971.14822
Overall Steps per Second: 10,865.03845

Timestep Collection Time: 2.17786
Timestep Consumption Time: 2.42663
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60449

Cumulative Model Updates: 67,856
Cumulative Timesteps: 565,882,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 565882562...
Checkpoint 565882562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,086.99386
Policy Entropy: 3.69788
Value Function Loss: 0.06772

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.47758
Value Function Update Magnitude: 0.69656

Collected Steps per Second: 21,761.05275
Overall Steps per Second: 10,668.68271

Timestep Collection Time: 2.29823
Timestep Consumption Time: 2.38950
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.68774

Cumulative Model Updates: 67,862
Cumulative Timesteps: 565,932,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,794.70832
Policy Entropy: 3.69658
Value Function Loss: 0.06816

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.70815

Collected Steps per Second: 22,285.99086
Overall Steps per Second: 10,878.83824

Timestep Collection Time: 2.24356
Timestep Consumption Time: 2.35252
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.59608

Cumulative Model Updates: 67,868
Cumulative Timesteps: 565,982,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 565982574...
Checkpoint 565982574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,763.14524
Policy Entropy: 3.67935
Value Function Loss: 0.06701

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.53525
Value Function Update Magnitude: 0.81131

Collected Steps per Second: 21,683.15972
Overall Steps per Second: 10,702.78008

Timestep Collection Time: 2.30621
Timestep Consumption Time: 2.36603
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.67224

Cumulative Model Updates: 67,874
Cumulative Timesteps: 566,032,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,540.11890
Policy Entropy: 3.68297
Value Function Loss: 0.06424

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07372
Policy Update Magnitude: 0.60308
Value Function Update Magnitude: 0.88048

Collected Steps per Second: 22,219.78456
Overall Steps per Second: 10,843.28904

Timestep Collection Time: 2.25079
Timestep Consumption Time: 2.36147
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.61225

Cumulative Model Updates: 67,880
Cumulative Timesteps: 566,082,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 566082592...
Checkpoint 566082592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,195.84088
Policy Entropy: 3.68736
Value Function Loss: 0.06553

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07333
Policy Update Magnitude: 0.72461
Value Function Update Magnitude: 0.79309

Collected Steps per Second: 21,957.68574
Overall Steps per Second: 10,677.23704

Timestep Collection Time: 2.27829
Timestep Consumption Time: 2.40700
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.68529

Cumulative Model Updates: 67,886
Cumulative Timesteps: 566,132,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,088.24951
Policy Entropy: 3.69163
Value Function Loss: 0.06519

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07634
Policy Update Magnitude: 0.71434
Value Function Update Magnitude: 0.73459

Collected Steps per Second: 22,420.42327
Overall Steps per Second: 10,682.89391

Timestep Collection Time: 2.23118
Timestep Consumption Time: 2.45145
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.68263

Cumulative Model Updates: 67,892
Cumulative Timesteps: 566,182,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 566182642...
Checkpoint 566182642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,504.03956
Policy Entropy: 3.69261
Value Function Loss: 0.06544

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.63327
Value Function Update Magnitude: 0.85004

Collected Steps per Second: 22,507.63498
Overall Steps per Second: 10,840.24140

Timestep Collection Time: 2.22191
Timestep Consumption Time: 2.39145
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.61337

Cumulative Model Updates: 67,898
Cumulative Timesteps: 566,232,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,685.39367
Policy Entropy: 3.69381
Value Function Loss: 0.06554

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.53363
Value Function Update Magnitude: 0.90792

Collected Steps per Second: 22,948.24567
Overall Steps per Second: 10,865.72055

Timestep Collection Time: 2.17916
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.60236

Cumulative Model Updates: 67,904
Cumulative Timesteps: 566,282,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 566282660...
Checkpoint 566282660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,798.87055
Policy Entropy: 3.69522
Value Function Loss: 0.06612

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.49018
Value Function Update Magnitude: 0.93715

Collected Steps per Second: 22,931.34204
Overall Steps per Second: 10,750.16118

Timestep Collection Time: 2.18051
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.65128

Cumulative Model Updates: 67,910
Cumulative Timesteps: 566,332,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,784.06649
Policy Entropy: 3.69707
Value Function Loss: 0.06663

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.46683
Value Function Update Magnitude: 0.89238

Collected Steps per Second: 23,078.62614
Overall Steps per Second: 10,894.33340

Timestep Collection Time: 2.16668
Timestep Consumption Time: 2.42323
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.58991

Cumulative Model Updates: 67,916
Cumulative Timesteps: 566,382,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 566382666...
Checkpoint 566382666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,089.26637
Policy Entropy: 3.68773
Value Function Loss: 0.06729

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.50204
Value Function Update Magnitude: 0.73777

Collected Steps per Second: 22,737.33267
Overall Steps per Second: 10,642.34086

Timestep Collection Time: 2.19999
Timestep Consumption Time: 2.50029
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.70028

Cumulative Model Updates: 67,922
Cumulative Timesteps: 566,432,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,631.77289
Policy Entropy: 3.67920
Value Function Loss: 0.06716

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.55840
Value Function Update Magnitude: 0.66807

Collected Steps per Second: 22,831.42639
Overall Steps per Second: 10,809.32259

Timestep Collection Time: 2.19110
Timestep Consumption Time: 2.43694
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.62804

Cumulative Model Updates: 67,928
Cumulative Timesteps: 566,482,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 566482714...
Checkpoint 566482714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,310.16038
Policy Entropy: 3.68819
Value Function Loss: 0.06533

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.52596
Value Function Update Magnitude: 0.61034

Collected Steps per Second: 22,573.08527
Overall Steps per Second: 10,682.72731

Timestep Collection Time: 2.21547
Timestep Consumption Time: 2.46592
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.68139

Cumulative Model Updates: 67,934
Cumulative Timesteps: 566,532,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,929.81360
Policy Entropy: 3.68800
Value Function Loss: 0.06471

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.53556
Value Function Update Magnitude: 0.70045

Collected Steps per Second: 23,137.41689
Overall Steps per Second: 10,884.75368

Timestep Collection Time: 2.16117
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.59395

Cumulative Model Updates: 67,940
Cumulative Timesteps: 566,582,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 566582728...
Checkpoint 566582728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,054.23405
Policy Entropy: 3.68719
Value Function Loss: 0.06549

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.63356
Value Function Update Magnitude: 0.79784

Collected Steps per Second: 22,254.03461
Overall Steps per Second: 10,685.73585

Timestep Collection Time: 2.24741
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.68045

Cumulative Model Updates: 67,946
Cumulative Timesteps: 566,632,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.04603
Policy Entropy: 3.67757
Value Function Loss: 0.06755

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.71937
Value Function Update Magnitude: 0.84721

Collected Steps per Second: 22,695.99188
Overall Steps per Second: 10,663.59411

Timestep Collection Time: 2.20444
Timestep Consumption Time: 2.48741
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.69185

Cumulative Model Updates: 67,952
Cumulative Timesteps: 566,682,774

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 566682774...
Checkpoint 566682774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,945.23234
Policy Entropy: 3.67928
Value Function Loss: 0.06816

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.68336
Value Function Update Magnitude: 0.79470

Collected Steps per Second: 22,647.08097
Overall Steps per Second: 10,789.60888

Timestep Collection Time: 2.20894
Timestep Consumption Time: 2.42756
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.63650

Cumulative Model Updates: 67,958
Cumulative Timesteps: 566,732,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,847.20803
Policy Entropy: 3.67724
Value Function Loss: 0.07009

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15517
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.74172

Collected Steps per Second: 22,590.78145
Overall Steps per Second: 10,603.11142

Timestep Collection Time: 2.21418
Timestep Consumption Time: 2.50331
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.71748

Cumulative Model Updates: 67,964
Cumulative Timesteps: 566,782,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 566782820...
Checkpoint 566782820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,135.99984
Policy Entropy: 3.67903
Value Function Loss: 0.07047

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.43815
Value Function Update Magnitude: 0.69199

Collected Steps per Second: 22,748.28354
Overall Steps per Second: 10,663.10289

Timestep Collection Time: 2.19876
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.69075

Cumulative Model Updates: 67,970
Cumulative Timesteps: 566,832,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,883.08484
Policy Entropy: 3.66262
Value Function Loss: 0.06835

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.48520
Value Function Update Magnitude: 0.66613

Collected Steps per Second: 22,776.31007
Overall Steps per Second: 10,799.68635

Timestep Collection Time: 2.19605
Timestep Consumption Time: 2.43538
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.63143

Cumulative Model Updates: 67,976
Cumulative Timesteps: 566,882,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 566882856...
Checkpoint 566882856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,516.41059
Policy Entropy: 3.65826
Value Function Loss: 0.06586

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.51230
Value Function Update Magnitude: 0.67216

Collected Steps per Second: 22,684.89169
Overall Steps per Second: 10,675.04494

Timestep Collection Time: 2.20473
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.68513

Cumulative Model Updates: 67,982
Cumulative Timesteps: 566,932,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,394.59705
Policy Entropy: 3.65822
Value Function Loss: 0.06500

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.51335
Value Function Update Magnitude: 0.79847

Collected Steps per Second: 22,915.32830
Overall Steps per Second: 10,847.69686

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.42781
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.61020

Cumulative Model Updates: 67,988
Cumulative Timesteps: 566,982,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 566982880...
Checkpoint 566982880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,417.71179
Policy Entropy: 3.65513
Value Function Loss: 0.06648

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.48343
Value Function Update Magnitude: 0.80081

Collected Steps per Second: 22,672.83401
Overall Steps per Second: 10,714.15519

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.46213
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.66803

Cumulative Model Updates: 67,994
Cumulative Timesteps: 567,032,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,331.00065
Policy Entropy: 3.66559
Value Function Loss: 0.06742

Mean KL Divergence: 0.02364
SB3 Clip Fraction: 0.17037
Policy Update Magnitude: 0.48820
Value Function Update Magnitude: 0.83037

Collected Steps per Second: 23,030.17045
Overall Steps per Second: 10,850.04604

Timestep Collection Time: 2.17141
Timestep Consumption Time: 2.43760
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60901

Cumulative Model Updates: 68,000
Cumulative Timesteps: 567,082,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 567082902...
Checkpoint 567082902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,233.76966
Policy Entropy: 3.68505
Value Function Loss: 0.06994

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.16465
Policy Update Magnitude: 0.45232
Value Function Update Magnitude: 0.81138

Collected Steps per Second: 22,714.40449
Overall Steps per Second: 10,689.95071

Timestep Collection Time: 2.20169
Timestep Consumption Time: 2.47654
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.67823

Cumulative Model Updates: 68,006
Cumulative Timesteps: 567,132,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,961.03554
Policy Entropy: 3.68033
Value Function Loss: 0.07250

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.54450
Value Function Update Magnitude: 0.67228

Collected Steps per Second: 22,710.46916
Overall Steps per Second: 10,824.98067

Timestep Collection Time: 2.20286
Timestep Consumption Time: 2.41867
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.62153

Cumulative Model Updates: 68,012
Cumulative Timesteps: 567,182,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 567182940...
Checkpoint 567182940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,765.77661
Policy Entropy: 3.66913
Value Function Loss: 0.07405

Mean KL Divergence: 0.02775
SB3 Clip Fraction: 0.19598
Policy Update Magnitude: 0.51248
Value Function Update Magnitude: 0.64882

Collected Steps per Second: 22,502.38748
Overall Steps per Second: 10,797.34359

Timestep Collection Time: 2.22305
Timestep Consumption Time: 2.40994
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.63299

Cumulative Model Updates: 68,018
Cumulative Timesteps: 567,232,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,345.99045
Policy Entropy: 3.66113
Value Function Loss: 0.07300

Mean KL Divergence: 0.02489
SB3 Clip Fraction: 0.18510
Policy Update Magnitude: 0.46225
Value Function Update Magnitude: 0.56997

Collected Steps per Second: 22,242.91867
Overall Steps per Second: 10,869.69611

Timestep Collection Time: 2.24827
Timestep Consumption Time: 2.35241
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.60068

Cumulative Model Updates: 68,024
Cumulative Timesteps: 567,282,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 567282972...
Checkpoint 567282972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,731.14977
Policy Entropy: 3.67872
Value Function Loss: 0.06908

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.62935

Collected Steps per Second: 22,088.07105
Overall Steps per Second: 10,683.85696

Timestep Collection Time: 2.26502
Timestep Consumption Time: 2.41774
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.68277

Cumulative Model Updates: 68,030
Cumulative Timesteps: 567,333,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,732.51573
Policy Entropy: 3.68679
Value Function Loss: 0.06516

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.68430
Value Function Update Magnitude: 0.67135

Collected Steps per Second: 22,403.08268
Overall Steps per Second: 10,842.80455

Timestep Collection Time: 2.23255
Timestep Consumption Time: 2.38028
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.61283

Cumulative Model Updates: 68,036
Cumulative Timesteps: 567,383,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 567383018...
Checkpoint 567383018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,037.80458
Policy Entropy: 3.70227
Value Function Loss: 0.06215

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.61061
Value Function Update Magnitude: 0.71168

Collected Steps per Second: 20,699.86793
Overall Steps per Second: 10,289.56751

Timestep Collection Time: 2.41625
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.86085

Cumulative Model Updates: 68,042
Cumulative Timesteps: 567,433,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,396.51560
Policy Entropy: 3.68853
Value Function Loss: 0.05991

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.60225
Value Function Update Magnitude: 0.66869

Collected Steps per Second: 22,051.40515
Overall Steps per Second: 10,778.23737

Timestep Collection Time: 2.26752
Timestep Consumption Time: 2.37164
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.63916

Cumulative Model Updates: 68,048
Cumulative Timesteps: 567,483,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 567483036...
Checkpoint 567483036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,874.81762
Policy Entropy: 3.67545
Value Function Loss: 0.06333

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.65259
Value Function Update Magnitude: 0.63989

Collected Steps per Second: 21,870.80622
Overall Steps per Second: 10,643.87733

Timestep Collection Time: 2.28679
Timestep Consumption Time: 2.41206
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.69885

Cumulative Model Updates: 68,054
Cumulative Timesteps: 567,533,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,059.90810
Policy Entropy: 3.66847
Value Function Loss: 0.06313

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.64476
Value Function Update Magnitude: 0.63850

Collected Steps per Second: 22,073.88140
Overall Steps per Second: 10,687.77010

Timestep Collection Time: 2.26621
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.68049

Cumulative Model Updates: 68,060
Cumulative Timesteps: 567,583,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 567583074...
Checkpoint 567583074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,826.02476
Policy Entropy: 3.67345
Value Function Loss: 0.06206

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.58049
Value Function Update Magnitude: 0.72706

Collected Steps per Second: 22,130.50146
Overall Steps per Second: 10,856.22907

Timestep Collection Time: 2.26005
Timestep Consumption Time: 2.34708
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.60712

Cumulative Model Updates: 68,066
Cumulative Timesteps: 567,633,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,074.60599
Policy Entropy: 3.67928
Value Function Loss: 0.05968

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.60071
Value Function Update Magnitude: 0.77623

Collected Steps per Second: 22,208.19974
Overall Steps per Second: 10,538.33378

Timestep Collection Time: 2.25178
Timestep Consumption Time: 2.49356
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.74534

Cumulative Model Updates: 68,072
Cumulative Timesteps: 567,683,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 567683098...
Checkpoint 567683098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,801.75729
Policy Entropy: 3.67870
Value Function Loss: 0.05882

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.57955
Value Function Update Magnitude: 0.79827

Collected Steps per Second: 22,492.34525
Overall Steps per Second: 10,644.02344

Timestep Collection Time: 2.22342
Timestep Consumption Time: 2.47499
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.69841

Cumulative Model Updates: 68,078
Cumulative Timesteps: 567,733,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,608.28413
Policy Entropy: 3.69081
Value Function Loss: 0.06116

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.58672
Value Function Update Magnitude: 0.82534

Collected Steps per Second: 22,909.33321
Overall Steps per Second: 10,856.14408

Timestep Collection Time: 2.18269
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.60606

Cumulative Model Updates: 68,084
Cumulative Timesteps: 567,783,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 567783112...
Checkpoint 567783112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,940.05084
Policy Entropy: 3.68679
Value Function Loss: 0.06094

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.58901
Value Function Update Magnitude: 0.84156

Collected Steps per Second: 22,385.79111
Overall Steps per Second: 10,608.37940

Timestep Collection Time: 2.23427
Timestep Consumption Time: 2.48049
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.71476

Cumulative Model Updates: 68,090
Cumulative Timesteps: 567,833,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,557.94445
Policy Entropy: 3.69587
Value Function Loss: 0.06060

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.83250

Collected Steps per Second: 22,631.05384
Overall Steps per Second: 10,838.94284

Timestep Collection Time: 2.21068
Timestep Consumption Time: 2.40508
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.61576

Cumulative Model Updates: 68,096
Cumulative Timesteps: 567,883,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 567883158...
Checkpoint 567883158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.57443
Policy Entropy: 3.69252
Value Function Loss: 0.05939

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.47818
Value Function Update Magnitude: 0.82725

Collected Steps per Second: 22,656.91716
Overall Steps per Second: 10,694.96786

Timestep Collection Time: 2.20771
Timestep Consumption Time: 2.46925
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.67697

Cumulative Model Updates: 68,102
Cumulative Timesteps: 567,933,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,853.66934
Policy Entropy: 3.69535
Value Function Loss: 0.05948

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.48457
Value Function Update Magnitude: 0.81692

Collected Steps per Second: 23,003.83138
Overall Steps per Second: 10,858.26571

Timestep Collection Time: 2.17486
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.60755

Cumulative Model Updates: 68,108
Cumulative Timesteps: 567,983,208

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 567983208...
Checkpoint 567983208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,339.10139
Policy Entropy: 3.69274
Value Function Loss: 0.06127

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.49289
Value Function Update Magnitude: 0.81951

Collected Steps per Second: 22,363.88301
Overall Steps per Second: 10,756.15026

Timestep Collection Time: 2.23575
Timestep Consumption Time: 2.41276
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.64850

Cumulative Model Updates: 68,114
Cumulative Timesteps: 568,033,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,455.61061
Policy Entropy: 3.69896
Value Function Loss: 0.06349

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.84332

Collected Steps per Second: 22,755.11090
Overall Steps per Second: 10,788.41656

Timestep Collection Time: 2.19801
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.63608

Cumulative Model Updates: 68,120
Cumulative Timesteps: 568,083,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 568083224...
Checkpoint 568083224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,532.01419
Policy Entropy: 3.69372
Value Function Loss: 0.06547

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.54806
Value Function Update Magnitude: 0.85528

Collected Steps per Second: 22,769.54393
Overall Steps per Second: 10,728.91540

Timestep Collection Time: 2.19653
Timestep Consumption Time: 2.46508
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.66161

Cumulative Model Updates: 68,126
Cumulative Timesteps: 568,133,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,999.91643
Policy Entropy: 3.69666
Value Function Loss: 0.06519

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.87546

Collected Steps per Second: 22,597.48899
Overall Steps per Second: 10,818.93452

Timestep Collection Time: 2.21396
Timestep Consumption Time: 2.41034
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.62430

Cumulative Model Updates: 68,132
Cumulative Timesteps: 568,183,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 568183268...
Checkpoint 568183268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,396.63909
Policy Entropy: 3.68931
Value Function Loss: 0.06527

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.56596
Value Function Update Magnitude: 0.86552

Collected Steps per Second: 22,854.92504
Overall Steps per Second: 10,732.52359

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.47251
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.66153

Cumulative Model Updates: 68,138
Cumulative Timesteps: 568,233,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,926.13407
Policy Entropy: 3.68515
Value Function Loss: 0.06754

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06574
Policy Update Magnitude: 0.63053
Value Function Update Magnitude: 0.87048

Collected Steps per Second: 22,555.97803
Overall Steps per Second: 10,619.91836

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.71021

Cumulative Model Updates: 68,144
Cumulative Timesteps: 568,283,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 568283320...
Checkpoint 568283320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,824.96435
Policy Entropy: 3.69108
Value Function Loss: 0.06761

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.69370
Value Function Update Magnitude: 0.88561

Collected Steps per Second: 22,743.60916
Overall Steps per Second: 10,797.04154

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.63257

Cumulative Model Updates: 68,150
Cumulative Timesteps: 568,333,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,789.98166
Policy Entropy: 3.69780
Value Function Loss: 0.06496

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.60481
Value Function Update Magnitude: 0.88061

Collected Steps per Second: 22,565.02535
Overall Steps per Second: 10,561.40274

Timestep Collection Time: 2.21670
Timestep Consumption Time: 2.51941
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.73611

Cumulative Model Updates: 68,156
Cumulative Timesteps: 568,383,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 568383358...
Checkpoint 568383358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,062.56007
Policy Entropy: 3.71325
Value Function Loss: 0.06433

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.85749

Collected Steps per Second: 22,690.26464
Overall Steps per Second: 10,692.25190

Timestep Collection Time: 2.20394
Timestep Consumption Time: 2.47309
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.67703

Cumulative Model Updates: 68,162
Cumulative Timesteps: 568,433,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,379.80901
Policy Entropy: 3.71496
Value Function Loss: 0.06390

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08188
Policy Update Magnitude: 0.60813
Value Function Update Magnitude: 0.78849

Collected Steps per Second: 22,883.55477
Overall Steps per Second: 10,809.36871

Timestep Collection Time: 2.18629
Timestep Consumption Time: 2.44211
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.62839

Cumulative Model Updates: 68,168
Cumulative Timesteps: 568,483,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 568483396...
Checkpoint 568483396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,441.98877
Policy Entropy: 3.69872
Value Function Loss: 0.06640

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.67871
Value Function Update Magnitude: 0.84454

Collected Steps per Second: 22,763.67552
Overall Steps per Second: 10,685.22567

Timestep Collection Time: 2.19701
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.68048

Cumulative Model Updates: 68,174
Cumulative Timesteps: 568,533,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,082.16875
Policy Entropy: 3.68579
Value Function Loss: 0.06633

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.58306
Value Function Update Magnitude: 0.82573

Collected Steps per Second: 22,774.76293
Overall Steps per Second: 10,815.24985

Timestep Collection Time: 2.19576
Timestep Consumption Time: 2.42808
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.62384

Cumulative Model Updates: 68,180
Cumulative Timesteps: 568,583,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 568583416...
Checkpoint 568583416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,074.33850
Policy Entropy: 3.67905
Value Function Loss: 0.06671

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11508
Policy Update Magnitude: 0.51274
Value Function Update Magnitude: 0.84522

Collected Steps per Second: 22,771.35370
Overall Steps per Second: 10,734.64767

Timestep Collection Time: 2.19627
Timestep Consumption Time: 2.46266
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.65893

Cumulative Model Updates: 68,186
Cumulative Timesteps: 568,633,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,215.42924
Policy Entropy: 3.68311
Value Function Loss: 0.06592

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.85283

Collected Steps per Second: 22,615.76918
Overall Steps per Second: 10,608.22677

Timestep Collection Time: 2.21200
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.71577

Cumulative Model Updates: 68,192
Cumulative Timesteps: 568,683,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 568683454...
Checkpoint 568683454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,887.95789
Policy Entropy: 3.67720
Value Function Loss: 0.06627

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08138
Policy Update Magnitude: 0.63197
Value Function Update Magnitude: 0.85065

Collected Steps per Second: 22,503.56251
Overall Steps per Second: 10,594.83195

Timestep Collection Time: 2.22196
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.71947

Cumulative Model Updates: 68,198
Cumulative Timesteps: 568,733,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,501.18858
Policy Entropy: 3.67781
Value Function Loss: 0.06819

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.60277
Value Function Update Magnitude: 0.84398

Collected Steps per Second: 22,924.97396
Overall Steps per Second: 10,756.62610

Timestep Collection Time: 2.18111
Timestep Consumption Time: 2.46737
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.64848

Cumulative Model Updates: 68,204
Cumulative Timesteps: 568,783,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 568783458...
Checkpoint 568783458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,266.46853
Policy Entropy: 3.66540
Value Function Loss: 0.06897

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.51363
Value Function Update Magnitude: 0.80068

Collected Steps per Second: 22,562.58589
Overall Steps per Second: 10,663.90165

Timestep Collection Time: 2.21659
Timestep Consumption Time: 2.47325
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.68984

Cumulative Model Updates: 68,210
Cumulative Timesteps: 568,833,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,211.16990
Policy Entropy: 3.65997
Value Function Loss: 0.07101

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.48191
Value Function Update Magnitude: 0.75558

Collected Steps per Second: 22,898.88363
Overall Steps per Second: 10,813.97889

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.62383

Cumulative Model Updates: 68,216
Cumulative Timesteps: 568,883,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 568883472...
Checkpoint 568883472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,610.47442
Policy Entropy: 3.65080
Value Function Loss: 0.06812

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.51111
Value Function Update Magnitude: 0.84631

Collected Steps per Second: 22,643.49086
Overall Steps per Second: 10,732.85184

Timestep Collection Time: 2.20920
Timestep Consumption Time: 2.45163
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.66083

Cumulative Model Updates: 68,222
Cumulative Timesteps: 568,933,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,385.08602
Policy Entropy: 3.65837
Value Function Loss: 0.06768

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.58039
Value Function Update Magnitude: 0.86723

Collected Steps per Second: 22,874.83009
Overall Steps per Second: 10,826.50445

Timestep Collection Time: 2.18747
Timestep Consumption Time: 2.43434
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.62181

Cumulative Model Updates: 68,228
Cumulative Timesteps: 568,983,534

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 568983534...
Checkpoint 568983534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,375.35934
Policy Entropy: 3.66469
Value Function Loss: 0.06535

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.64292
Value Function Update Magnitude: 0.88167

Collected Steps per Second: 22,469.81377
Overall Steps per Second: 10,742.79427

Timestep Collection Time: 2.22539
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.65465

Cumulative Model Updates: 68,234
Cumulative Timesteps: 569,033,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,148.47576
Policy Entropy: 3.66305
Value Function Loss: 0.06613

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11372
Policy Update Magnitude: 0.60237
Value Function Update Magnitude: 0.88579

Collected Steps per Second: 22,740.57891
Overall Steps per Second: 10,792.30375

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.43519
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.63478

Cumulative Model Updates: 68,240
Cumulative Timesteps: 569,083,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 569083558...
Checkpoint 569083558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,074.80721
Policy Entropy: 3.66258
Value Function Loss: 0.06683

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.51425
Value Function Update Magnitude: 0.87327

Collected Steps per Second: 22,288.17012
Overall Steps per Second: 10,699.10994

Timestep Collection Time: 2.24352
Timestep Consumption Time: 2.43014
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.67366

Cumulative Model Updates: 68,246
Cumulative Timesteps: 569,133,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,433.67738
Policy Entropy: 3.68154
Value Function Loss: 0.06585

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.49823
Value Function Update Magnitude: 0.88152

Collected Steps per Second: 22,613.23291
Overall Steps per Second: 10,646.90486

Timestep Collection Time: 2.21145
Timestep Consumption Time: 2.48550
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.69695

Cumulative Model Updates: 68,252
Cumulative Timesteps: 569,183,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 569183570...
Checkpoint 569183570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506.30777
Policy Entropy: 3.70379
Value Function Loss: 0.06463

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.55191
Value Function Update Magnitude: 0.80969

Collected Steps per Second: 22,695.92333
Overall Steps per Second: 10,836.43412

Timestep Collection Time: 2.20339
Timestep Consumption Time: 2.41141
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.61480

Cumulative Model Updates: 68,258
Cumulative Timesteps: 569,233,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,302.60858
Policy Entropy: 3.69359
Value Function Loss: 0.06139

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.62107
Value Function Update Magnitude: 0.81563

Collected Steps per Second: 22,625.74733
Overall Steps per Second: 10,608.66668

Timestep Collection Time: 2.21084
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.71520

Cumulative Model Updates: 68,264
Cumulative Timesteps: 569,283,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 569283600...
Checkpoint 569283600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,789.65885
Policy Entropy: 3.68978
Value Function Loss: 0.06266

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.60346
Value Function Update Magnitude: 0.84021

Collected Steps per Second: 22,631.06650
Overall Steps per Second: 10,607.84113

Timestep Collection Time: 2.20953
Timestep Consumption Time: 2.50434
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.71387

Cumulative Model Updates: 68,270
Cumulative Timesteps: 569,333,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,842.22972
Policy Entropy: 3.68108
Value Function Loss: 0.06380

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.16053
Policy Update Magnitude: 0.55596
Value Function Update Magnitude: 0.85627

Collected Steps per Second: 23,053.15115
Overall Steps per Second: 10,851.22175

Timestep Collection Time: 2.16907
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.60814

Cumulative Model Updates: 68,276
Cumulative Timesteps: 569,383,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 569383608...
Checkpoint 569383608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,854.16644
Policy Entropy: 3.69405
Value Function Loss: 0.06581

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.16360
Policy Update Magnitude: 0.46464
Value Function Update Magnitude: 0.89317

Collected Steps per Second: 22,395.71773
Overall Steps per Second: 10,639.93240

Timestep Collection Time: 2.23373
Timestep Consumption Time: 2.46799
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.70172

Cumulative Model Updates: 68,282
Cumulative Timesteps: 569,433,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,425.53574
Policy Entropy: 3.69832
Value Function Loss: 0.06327

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.46793
Value Function Update Magnitude: 0.89565

Collected Steps per Second: 23,055.09149
Overall Steps per Second: 10,810.10193

Timestep Collection Time: 2.16881
Timestep Consumption Time: 2.45668
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62549

Cumulative Model Updates: 68,288
Cumulative Timesteps: 569,483,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 569483636...
Checkpoint 569483636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,709.96631
Policy Entropy: 3.70098
Value Function Loss: 0.05903

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.51632
Value Function Update Magnitude: 0.91298

Collected Steps per Second: 22,618.57622
Overall Steps per Second: 10,790.57175

Timestep Collection Time: 2.21101
Timestep Consumption Time: 2.42359
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.63460

Cumulative Model Updates: 68,294
Cumulative Timesteps: 569,533,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,868.66840
Policy Entropy: 3.71250
Value Function Loss: 0.05713

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.58325
Value Function Update Magnitude: 0.90980

Collected Steps per Second: 22,894.73995
Overall Steps per Second: 10,881.77539

Timestep Collection Time: 2.18461
Timestep Consumption Time: 2.41170
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.59631

Cumulative Model Updates: 68,300
Cumulative Timesteps: 569,583,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 569583662...
Checkpoint 569583662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,350.89492
Policy Entropy: 3.70565
Value Function Loss: 0.05883

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.59517
Value Function Update Magnitude: 0.88324

Collected Steps per Second: 22,678.76491
Overall Steps per Second: 10,777.57765

Timestep Collection Time: 2.20471
Timestep Consumption Time: 2.43456
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.63926

Cumulative Model Updates: 68,306
Cumulative Timesteps: 569,633,662

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,376.52315
Policy Entropy: 3.69412
Value Function Loss: 0.05954

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.66963
Value Function Update Magnitude: 0.88647

Collected Steps per Second: 22,603.04813
Overall Steps per Second: 10,610.08745

Timestep Collection Time: 2.21333
Timestep Consumption Time: 2.50181
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.71514

Cumulative Model Updates: 68,312
Cumulative Timesteps: 569,683,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 569683690...
Checkpoint 569683690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,856.47094
Policy Entropy: 3.70261
Value Function Loss: 0.05816

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.59388
Value Function Update Magnitude: 0.87717

Collected Steps per Second: 22,704.82085
Overall Steps per Second: 10,624.06087

Timestep Collection Time: 2.20279
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.70762

Cumulative Model Updates: 68,318
Cumulative Timesteps: 569,733,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,640.51150
Policy Entropy: 3.69802
Value Function Loss: 0.05648

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.49900
Value Function Update Magnitude: 0.85358

Collected Steps per Second: 23,064.77020
Overall Steps per Second: 10,778.47179

Timestep Collection Time: 2.16789
Timestep Consumption Time: 2.47117
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.63906

Cumulative Model Updates: 68,324
Cumulative Timesteps: 569,783,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 569783706...
Checkpoint 569783706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,686.88264
Policy Entropy: 3.70259
Value Function Loss: 0.05873

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.48495
Value Function Update Magnitude: 0.87541

Collected Steps per Second: 22,494.79163
Overall Steps per Second: 10,687.12680

Timestep Collection Time: 2.22416
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.68152

Cumulative Model Updates: 68,330
Cumulative Timesteps: 569,833,738

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,528.89893
Policy Entropy: 3.69600
Value Function Loss: 0.05982

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.57606
Value Function Update Magnitude: 0.89220

Collected Steps per Second: 22,918.22427
Overall Steps per Second: 10,839.62482

Timestep Collection Time: 2.18298
Timestep Consumption Time: 2.43249
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61547

Cumulative Model Updates: 68,336
Cumulative Timesteps: 569,883,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 569883768...
Checkpoint 569883768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,458.32483
Policy Entropy: 3.69651
Value Function Loss: 0.06173

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.58851
Value Function Update Magnitude: 0.89045

Collected Steps per Second: 22,733.31359
Overall Steps per Second: 10,674.16306

Timestep Collection Time: 2.19942
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.68421

Cumulative Model Updates: 68,342
Cumulative Timesteps: 569,933,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,395.63063
Policy Entropy: 3.68511
Value Function Loss: 0.06217

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.52154
Value Function Update Magnitude: 0.81784

Collected Steps per Second: 22,897.27535
Overall Steps per Second: 10,847.42210

Timestep Collection Time: 2.18436
Timestep Consumption Time: 2.42650
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.61087

Cumulative Model Updates: 68,348
Cumulative Timesteps: 569,983,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 569983784...
Checkpoint 569983784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,765.37695
Policy Entropy: 3.70114
Value Function Loss: 0.06367

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.51415
Value Function Update Magnitude: 0.82050

Collected Steps per Second: 22,568.48371
Overall Steps per Second: 10,720.53149

Timestep Collection Time: 2.21583
Timestep Consumption Time: 2.44886
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.66469

Cumulative Model Updates: 68,354
Cumulative Timesteps: 570,033,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,533.57618
Policy Entropy: 3.70471
Value Function Loss: 0.06187

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.65194
Value Function Update Magnitude: 0.86756

Collected Steps per Second: 22,865.68148
Overall Steps per Second: 10,803.99487

Timestep Collection Time: 2.18677
Timestep Consumption Time: 2.44133
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62810

Cumulative Model Updates: 68,360
Cumulative Timesteps: 570,083,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 570083794...
Checkpoint 570083794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,684.76375
Policy Entropy: 3.71007
Value Function Loss: 0.06183

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.70851
Value Function Update Magnitude: 0.89782

Collected Steps per Second: 22,697.67942
Overall Steps per Second: 10,708.33043

Timestep Collection Time: 2.20366
Timestep Consumption Time: 2.46728
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.67094

Cumulative Model Updates: 68,366
Cumulative Timesteps: 570,133,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,642.09183
Policy Entropy: 3.69750
Value Function Loss: 0.06362

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.56138
Value Function Update Magnitude: 0.91514

Collected Steps per Second: 21,911.83042
Overall Steps per Second: 10,654.27669

Timestep Collection Time: 2.28315
Timestep Consumption Time: 2.41243
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.69558

Cumulative Model Updates: 68,372
Cumulative Timesteps: 570,183,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 570183840...
Checkpoint 570183840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.07729
Policy Entropy: 3.70273
Value Function Loss: 0.06511

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.48859
Value Function Update Magnitude: 0.92308

Collected Steps per Second: 22,144.07286
Overall Steps per Second: 10,843.22382

Timestep Collection Time: 2.25821
Timestep Consumption Time: 2.35352
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.61173

Cumulative Model Updates: 68,378
Cumulative Timesteps: 570,233,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,529.86439
Policy Entropy: 3.70128
Value Function Loss: 0.06538

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.48349
Value Function Update Magnitude: 0.94415

Collected Steps per Second: 22,135.56446
Overall Steps per Second: 10,700.67004

Timestep Collection Time: 2.25890
Timestep Consumption Time: 2.41389
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.67279

Cumulative Model Updates: 68,384
Cumulative Timesteps: 570,283,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 570283848...
Checkpoint 570283848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,544.26973
Policy Entropy: 3.70194
Value Function Loss: 0.06343

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07520
Policy Update Magnitude: 0.57264
Value Function Update Magnitude: 0.94908

Collected Steps per Second: 22,188.91731
Overall Steps per Second: 10,840.83697

Timestep Collection Time: 2.25419
Timestep Consumption Time: 2.35966
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61385

Cumulative Model Updates: 68,390
Cumulative Timesteps: 570,333,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,902.85240
Policy Entropy: 3.69632
Value Function Loss: 0.06300

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.69121
Value Function Update Magnitude: 0.92376

Collected Steps per Second: 22,348.99555
Overall Steps per Second: 10,903.58589

Timestep Collection Time: 2.23733
Timestep Consumption Time: 2.34850
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.58583

Cumulative Model Updates: 68,396
Cumulative Timesteps: 570,383,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 570383868...
Checkpoint 570383868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,219.53167
Policy Entropy: 3.69963
Value Function Loss: 0.06439

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.71586
Value Function Update Magnitude: 0.89170

Collected Steps per Second: 21,967.64387
Overall Steps per Second: 10,706.37312

Timestep Collection Time: 2.27635
Timestep Consumption Time: 2.39433
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.67068

Cumulative Model Updates: 68,402
Cumulative Timesteps: 570,433,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,923.74125
Policy Entropy: 3.69610
Value Function Loss: 0.06649

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.68416
Value Function Update Magnitude: 0.89522

Collected Steps per Second: 22,735.93751
Overall Steps per Second: 10,836.77703

Timestep Collection Time: 2.19987
Timestep Consumption Time: 2.41553
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.61539

Cumulative Model Updates: 68,408
Cumulative Timesteps: 570,483,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 570483890...
Checkpoint 570483890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,149.71251
Policy Entropy: 3.68672
Value Function Loss: 0.06659

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.86477

Collected Steps per Second: 22,536.31988
Overall Steps per Second: 10,688.83174

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.45924
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.67797

Cumulative Model Updates: 68,414
Cumulative Timesteps: 570,533,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,195.84905
Policy Entropy: 3.68967
Value Function Loss: 0.06779

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.52944
Value Function Update Magnitude: 0.78757

Collected Steps per Second: 22,810.12012
Overall Steps per Second: 10,878.01933

Timestep Collection Time: 2.19201
Timestep Consumption Time: 2.40442
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.59642

Cumulative Model Updates: 68,420
Cumulative Timesteps: 570,583,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 570583892...
Checkpoint 570583892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,573.44014
Policy Entropy: 3.69772
Value Function Loss: 0.06624

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.60805
Value Function Update Magnitude: 0.81913

Collected Steps per Second: 22,591.86660
Overall Steps per Second: 10,666.59135

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.47445
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.68772

Cumulative Model Updates: 68,426
Cumulative Timesteps: 570,633,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,656.31127
Policy Entropy: 3.69931
Value Function Loss: 0.06820

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07172
Policy Update Magnitude: 0.69727
Value Function Update Magnitude: 0.78821

Collected Steps per Second: 22,766.00760
Overall Steps per Second: 10,808.01428

Timestep Collection Time: 2.19828
Timestep Consumption Time: 2.43218
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.63045

Cumulative Model Updates: 68,432
Cumulative Timesteps: 570,683,940

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 570683940...
Checkpoint 570683940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,006.11420
Policy Entropy: 3.69336
Value Function Loss: 0.06881

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.70046
Value Function Update Magnitude: 0.73922

Collected Steps per Second: 22,809.77881
Overall Steps per Second: 10,726.98194

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.46910
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.66114

Cumulative Model Updates: 68,438
Cumulative Timesteps: 570,733,940

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,729.77224
Policy Entropy: 3.68777
Value Function Loss: 0.07094

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.64944
Value Function Update Magnitude: 0.70325

Collected Steps per Second: 23,024.37456
Overall Steps per Second: 10,889.47531

Timestep Collection Time: 2.17222
Timestep Consumption Time: 2.42066
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.59288

Cumulative Model Updates: 68,444
Cumulative Timesteps: 570,783,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 570783954...
Checkpoint 570783954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,123.66769
Policy Entropy: 3.68434
Value Function Loss: 0.07163

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.53439
Value Function Update Magnitude: 0.70953

Collected Steps per Second: 22,562.47799
Overall Steps per Second: 10,682.20871

Timestep Collection Time: 2.21660
Timestep Consumption Time: 2.46520
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.68180

Cumulative Model Updates: 68,450
Cumulative Timesteps: 570,833,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,245.69573
Policy Entropy: 3.68397
Value Function Loss: 0.07068

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.52471
Value Function Update Magnitude: 0.78750

Collected Steps per Second: 22,935.44541
Overall Steps per Second: 10,832.25424

Timestep Collection Time: 2.18108
Timestep Consumption Time: 2.43698
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.61806

Cumulative Model Updates: 68,456
Cumulative Timesteps: 570,883,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 570883990...
Checkpoint 570883990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,277.32503
Policy Entropy: 3.68056
Value Function Loss: 0.06980

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.84746

Collected Steps per Second: 22,520.46717
Overall Steps per Second: 10,670.96093

Timestep Collection Time: 2.22118
Timestep Consumption Time: 2.46650
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.68768

Cumulative Model Updates: 68,462
Cumulative Timesteps: 570,934,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,420.35963
Policy Entropy: 3.68260
Value Function Loss: 0.07298

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.54708
Value Function Update Magnitude: 0.78815

Collected Steps per Second: 22,870.58752
Overall Steps per Second: 10,852.78844

Timestep Collection Time: 2.18683
Timestep Consumption Time: 2.42157
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.60840

Cumulative Model Updates: 68,468
Cumulative Timesteps: 570,984,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 570984026...
Checkpoint 570984026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,257.04686
Policy Entropy: 3.67867
Value Function Loss: 0.07015

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.54079
Value Function Update Magnitude: 0.77700

Collected Steps per Second: 22,739.05156
Overall Steps per Second: 10,703.12259

Timestep Collection Time: 2.19886
Timestep Consumption Time: 2.47267
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.67153

Cumulative Model Updates: 68,474
Cumulative Timesteps: 571,034,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,856.50893
Policy Entropy: 3.67901
Value Function Loss: 0.06796

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.64743
Value Function Update Magnitude: 0.75105

Collected Steps per Second: 22,709.92279
Overall Steps per Second: 10,692.23332

Timestep Collection Time: 2.20318
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.67947

Cumulative Model Updates: 68,480
Cumulative Timesteps: 571,084,060

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 571084060...
Checkpoint 571084060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,103.81419
Policy Entropy: 3.67810
Value Function Loss: 0.06492

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.62717
Value Function Update Magnitude: 0.75818

Collected Steps per Second: 22,845.57634
Overall Steps per Second: 10,845.68480

Timestep Collection Time: 2.18957
Timestep Consumption Time: 2.42259
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61216

Cumulative Model Updates: 68,486
Cumulative Timesteps: 571,134,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,658.44859
Policy Entropy: 3.67226
Value Function Loss: 0.06735

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.52348
Value Function Update Magnitude: 0.79801

Collected Steps per Second: 23,051.68481
Overall Steps per Second: 10,884.85836

Timestep Collection Time: 2.16939
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.59427

Cumulative Model Updates: 68,492
Cumulative Timesteps: 571,184,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 571184090...
Checkpoint 571184090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,964.51635
Policy Entropy: 3.66704
Value Function Loss: 0.06987

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.50757
Value Function Update Magnitude: 0.84501

Collected Steps per Second: 21,945.79526
Overall Steps per Second: 10,694.18824

Timestep Collection Time: 2.27843
Timestep Consumption Time: 2.39719
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.67562

Cumulative Model Updates: 68,498
Cumulative Timesteps: 571,234,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,339.57981
Policy Entropy: 3.68466
Value Function Loss: 0.07046

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.48498
Value Function Update Magnitude: 0.83471

Collected Steps per Second: 22,137.35626
Overall Steps per Second: 10,801.52135

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.37073
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.62972

Cumulative Model Updates: 68,504
Cumulative Timesteps: 571,284,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 571284100...
Checkpoint 571284100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,231.10203
Policy Entropy: 3.67905
Value Function Loss: 0.06877

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.50131
Value Function Update Magnitude: 0.88473

Collected Steps per Second: 21,696.04930
Overall Steps per Second: 10,746.00169

Timestep Collection Time: 2.30475
Timestep Consumption Time: 2.34851
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.65327

Cumulative Model Updates: 68,510
Cumulative Timesteps: 571,334,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,737.19977
Policy Entropy: 3.68861
Value Function Loss: 0.06838

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.54286
Value Function Update Magnitude: 0.90218

Collected Steps per Second: 22,194.79768
Overall Steps per Second: 10,878.87496

Timestep Collection Time: 2.25386
Timestep Consumption Time: 2.34441
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.59827

Cumulative Model Updates: 68,516
Cumulative Timesteps: 571,384,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 571384128...
Checkpoint 571384128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,839.42506
Policy Entropy: 3.68723
Value Function Loss: 0.06824

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.54354
Value Function Update Magnitude: 0.89427

Collected Steps per Second: 22,037.98934
Overall Steps per Second: 10,670.85589

Timestep Collection Time: 2.26999
Timestep Consumption Time: 2.41811
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.68810

Cumulative Model Updates: 68,522
Cumulative Timesteps: 571,434,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,432.37788
Policy Entropy: 3.68358
Value Function Loss: 0.06839

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.52199
Value Function Update Magnitude: 0.87876

Collected Steps per Second: 21,920.69661
Overall Steps per Second: 10,664.15896

Timestep Collection Time: 2.28141
Timestep Consumption Time: 2.40813
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.68954

Cumulative Model Updates: 68,528
Cumulative Timesteps: 571,484,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 571484164...
Checkpoint 571484164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,541.74745
Policy Entropy: 3.69142
Value Function Loss: 0.06635

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.53966
Value Function Update Magnitude: 0.83196

Collected Steps per Second: 22,180.85556
Overall Steps per Second: 10,857.17817

Timestep Collection Time: 2.25528
Timestep Consumption Time: 2.35218
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60746

Cumulative Model Updates: 68,534
Cumulative Timesteps: 571,534,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,666.87664
Policy Entropy: 3.68634
Value Function Loss: 0.06601

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.52214
Value Function Update Magnitude: 0.82267

Collected Steps per Second: 22,271.85077
Overall Steps per Second: 10,577.25523

Timestep Collection Time: 2.24606
Timestep Consumption Time: 2.48333
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.72939

Cumulative Model Updates: 68,540
Cumulative Timesteps: 571,584,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 571584212...
Checkpoint 571584212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,027.93703
Policy Entropy: 3.69411
Value Function Loss: 0.06570

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.49846
Value Function Update Magnitude: 0.75938

Collected Steps per Second: 22,586.62458
Overall Steps per Second: 10,705.29556

Timestep Collection Time: 2.21459
Timestep Consumption Time: 2.45787
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.67245

Cumulative Model Updates: 68,546
Cumulative Timesteps: 571,634,232

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,170.32727
Policy Entropy: 3.69052
Value Function Loss: 0.06815

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.48170
Value Function Update Magnitude: 0.79543

Collected Steps per Second: 22,770.30135
Overall Steps per Second: 10,709.24159

Timestep Collection Time: 2.19584
Timestep Consumption Time: 2.47302
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.66886

Cumulative Model Updates: 68,552
Cumulative Timesteps: 571,684,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 571684232...
Checkpoint 571684232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,042.29795
Policy Entropy: 3.70095
Value Function Loss: 0.06903

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.48794
Value Function Update Magnitude: 0.76821

Collected Steps per Second: 22,781.33906
Overall Steps per Second: 10,695.51455

Timestep Collection Time: 2.19478
Timestep Consumption Time: 2.48008
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.67486

Cumulative Model Updates: 68,558
Cumulative Timesteps: 571,734,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,033.01026
Policy Entropy: 3.69961
Value Function Loss: 0.06750

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.47957
Value Function Update Magnitude: 0.74825

Collected Steps per Second: 23,096.72094
Overall Steps per Second: 10,867.52679

Timestep Collection Time: 2.16550
Timestep Consumption Time: 2.43683
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.60234

Cumulative Model Updates: 68,564
Cumulative Timesteps: 571,784,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 571784248...
Checkpoint 571784248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,029.81897
Policy Entropy: 3.69488
Value Function Loss: 0.06919

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.51475
Value Function Update Magnitude: 0.67698

Collected Steps per Second: 22,706.68186
Overall Steps per Second: 10,704.98705

Timestep Collection Time: 2.20332
Timestep Consumption Time: 2.47021
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.67352

Cumulative Model Updates: 68,570
Cumulative Timesteps: 571,834,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,245.56990
Policy Entropy: 3.68880
Value Function Loss: 0.07004

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.68442

Collected Steps per Second: 22,720.12575
Overall Steps per Second: 10,827.56680

Timestep Collection Time: 2.20087
Timestep Consumption Time: 2.41734
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.61821

Cumulative Model Updates: 68,576
Cumulative Timesteps: 571,884,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 571884282...
Checkpoint 571884282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.18398
Policy Entropy: 3.68607
Value Function Loss: 0.06999

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.52646
Value Function Update Magnitude: 0.70521

Collected Steps per Second: 22,329.37175
Overall Steps per Second: 10,622.54679

Timestep Collection Time: 2.24108
Timestep Consumption Time: 2.46984
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.71092

Cumulative Model Updates: 68,582
Cumulative Timesteps: 571,934,324

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,102.90432
Policy Entropy: 3.68626
Value Function Loss: 0.07111

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.49976
Value Function Update Magnitude: 0.66960

Collected Steps per Second: 22,947.78834
Overall Steps per Second: 10,926.11005

Timestep Collection Time: 2.17964
Timestep Consumption Time: 2.39820
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.57784

Cumulative Model Updates: 68,588
Cumulative Timesteps: 571,984,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 571984342...
Checkpoint 571984342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,219.42329
Policy Entropy: 3.67771
Value Function Loss: 0.06894

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07058
Policy Update Magnitude: 0.62153
Value Function Update Magnitude: 0.61188

Collected Steps per Second: 22,559.77718
Overall Steps per Second: 10,645.04407

Timestep Collection Time: 2.21642
Timestep Consumption Time: 2.48079
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.69721

Cumulative Model Updates: 68,594
Cumulative Timesteps: 572,034,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,744.27961
Policy Entropy: 3.67468
Value Function Loss: 0.06932

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.62298
Value Function Update Magnitude: 0.60350

Collected Steps per Second: 22,628.48806
Overall Steps per Second: 10,634.67710

Timestep Collection Time: 2.20960
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.70160

Cumulative Model Updates: 68,600
Cumulative Timesteps: 572,084,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 572084344...
Checkpoint 572084344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,851.20344
Policy Entropy: 3.68559
Value Function Loss: 0.06584

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.56990
Value Function Update Magnitude: 0.60488

Collected Steps per Second: 22,775.50527
Overall Steps per Second: 10,699.26881

Timestep Collection Time: 2.19613
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.67490

Cumulative Model Updates: 68,606
Cumulative Timesteps: 572,134,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,575.10468
Policy Entropy: 3.69408
Value Function Loss: 0.06728

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.53935
Value Function Update Magnitude: 0.57854

Collected Steps per Second: 22,776.78085
Overall Steps per Second: 10,692.75023

Timestep Collection Time: 2.19592
Timestep Consumption Time: 2.48164
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.67756

Cumulative Model Updates: 68,612
Cumulative Timesteps: 572,184,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 572184378...
Checkpoint 572184378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,496.82016
Policy Entropy: 3.69299
Value Function Loss: 0.06644

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.55916
Value Function Update Magnitude: 0.60213

Collected Steps per Second: 22,815.84488
Overall Steps per Second: 10,652.81817

Timestep Collection Time: 2.19251
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.69585

Cumulative Model Updates: 68,618
Cumulative Timesteps: 572,234,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,256.10289
Policy Entropy: 3.69742
Value Function Loss: 0.06828

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.64634

Collected Steps per Second: 22,918.84293
Overall Steps per Second: 10,820.84644

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.43939
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62127

Cumulative Model Updates: 68,624
Cumulative Timesteps: 572,284,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 572284408...
Checkpoint 572284408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,801.71774
Policy Entropy: 3.68080
Value Function Loss: 0.06830

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.49435
Value Function Update Magnitude: 0.73339

Collected Steps per Second: 22,640.50322
Overall Steps per Second: 10,725.85006

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.45458
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.66425

Cumulative Model Updates: 68,630
Cumulative Timesteps: 572,334,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,964.27734
Policy Entropy: 3.67797
Value Function Loss: 0.06976

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.50690
Value Function Update Magnitude: 0.65823

Collected Steps per Second: 22,900.77280
Overall Steps per Second: 10,875.44600

Timestep Collection Time: 2.18351
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.59788

Cumulative Model Updates: 68,636
Cumulative Timesteps: 572,384,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 572384440...
Checkpoint 572384440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,363.56169
Policy Entropy: 3.67130
Value Function Loss: 0.07020

Mean KL Divergence: 0.02264
SB3 Clip Fraction: 0.17664
Policy Update Magnitude: 0.47784
Value Function Update Magnitude: 0.58981

Collected Steps per Second: 22,516.62306
Overall Steps per Second: 10,672.38614

Timestep Collection Time: 2.22191
Timestep Consumption Time: 2.46588
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.68780

Cumulative Model Updates: 68,642
Cumulative Timesteps: 572,434,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,460.01082
Policy Entropy: 3.69202
Value Function Loss: 0.06586

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.61175
Value Function Update Magnitude: 0.61388

Collected Steps per Second: 22,857.80270
Overall Steps per Second: 10,827.82535

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.43234
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.62161

Cumulative Model Updates: 68,648
Cumulative Timesteps: 572,484,512

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 572484512...
Checkpoint 572484512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,521.33458
Policy Entropy: 3.68965
Value Function Loss: 0.06009

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.64708
Value Function Update Magnitude: 0.65691

Collected Steps per Second: 22,484.07097
Overall Steps per Second: 10,775.08456

Timestep Collection Time: 2.22504
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.64293

Cumulative Model Updates: 68,654
Cumulative Timesteps: 572,534,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,214.89421
Policy Entropy: 3.70570
Value Function Loss: 0.05708

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.61317
Value Function Update Magnitude: 0.74306

Collected Steps per Second: 22,594.99794
Overall Steps per Second: 10,791.04493

Timestep Collection Time: 2.21430
Timestep Consumption Time: 2.42214
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.63644

Cumulative Model Updates: 68,660
Cumulative Timesteps: 572,584,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 572584572...
Checkpoint 572584572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,357.22283
Policy Entropy: 3.69922
Value Function Loss: 0.05710

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.58895
Value Function Update Magnitude: 0.78726

Collected Steps per Second: 22,677.99197
Overall Steps per Second: 10,710.66746

Timestep Collection Time: 2.20522
Timestep Consumption Time: 2.46396
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.66918

Cumulative Model Updates: 68,666
Cumulative Timesteps: 572,634,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,510.86602
Policy Entropy: 3.70528
Value Function Loss: 0.05677

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.62901
Value Function Update Magnitude: 0.80317

Collected Steps per Second: 23,076.86203
Overall Steps per Second: 10,851.27490

Timestep Collection Time: 2.16745
Timestep Consumption Time: 2.44196
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.60941

Cumulative Model Updates: 68,672
Cumulative Timesteps: 572,684,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 572684600...
Checkpoint 572684600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,353.34438
Policy Entropy: 3.70536
Value Function Loss: 0.05836

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.70886
Value Function Update Magnitude: 0.81015

Collected Steps per Second: 22,320.44953
Overall Steps per Second: 10,641.97212

Timestep Collection Time: 2.24117
Timestep Consumption Time: 2.45946
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.70063

Cumulative Model Updates: 68,678
Cumulative Timesteps: 572,734,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,138.67314
Policy Entropy: 3.70431
Value Function Loss: 0.05949

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07710
Policy Update Magnitude: 0.71369
Value Function Update Magnitude: 0.81382

Collected Steps per Second: 22,790.20061
Overall Steps per Second: 10,681.38499

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.48712
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.68104

Cumulative Model Updates: 68,684
Cumulative Timesteps: 572,784,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 572784624...
Checkpoint 572784624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,270.09948
Policy Entropy: 3.71358
Value Function Loss: 0.06045

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06408
Policy Update Magnitude: 0.72678
Value Function Update Magnitude: 0.81707

Collected Steps per Second: 22,955.75285
Overall Steps per Second: 10,867.28222

Timestep Collection Time: 2.17863
Timestep Consumption Time: 2.42344
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.60207

Cumulative Model Updates: 68,690
Cumulative Timesteps: 572,834,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,085.67818
Policy Entropy: 3.69864
Value Function Loss: 0.06126

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06445
Policy Update Magnitude: 0.75334
Value Function Update Magnitude: 0.74063

Collected Steps per Second: 22,945.68657
Overall Steps per Second: 10,837.14321

Timestep Collection Time: 2.18019
Timestep Consumption Time: 2.43597
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61616

Cumulative Model Updates: 68,696
Cumulative Timesteps: 572,884,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 572884662...
Checkpoint 572884662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,500.14070
Policy Entropy: 3.70374
Value Function Loss: 0.06163

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.74996
Value Function Update Magnitude: 0.59184

Collected Steps per Second: 22,733.86449
Overall Steps per Second: 10,712.39413

Timestep Collection Time: 2.19971
Timestep Consumption Time: 2.46852
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.66824

Cumulative Model Updates: 68,702
Cumulative Timesteps: 572,934,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,155.26637
Policy Entropy: 3.69261
Value Function Loss: 0.06352

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06872
Policy Update Magnitude: 0.74373
Value Function Update Magnitude: 0.53280

Collected Steps per Second: 21,985.04475
Overall Steps per Second: 10,675.69603

Timestep Collection Time: 2.27455
Timestep Consumption Time: 2.40955
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.68410

Cumulative Model Updates: 68,708
Cumulative Timesteps: 572,984,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 572984676...
Checkpoint 572984676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,129.03331
Policy Entropy: 3.70778
Value Function Loss: 0.06159

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06689
Policy Update Magnitude: 0.73367
Value Function Update Magnitude: 0.53316

Collected Steps per Second: 22,160.65304
Overall Steps per Second: 10,869.54490

Timestep Collection Time: 2.25697
Timestep Consumption Time: 2.34451
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.60148

Cumulative Model Updates: 68,714
Cumulative Timesteps: 573,034,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,761.83957
Policy Entropy: 3.71183
Value Function Loss: 0.06440

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.70681
Value Function Update Magnitude: 0.56162

Collected Steps per Second: 21,936.53268
Overall Steps per Second: 10,681.19842

Timestep Collection Time: 2.27958
Timestep Consumption Time: 2.40211
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.68168

Cumulative Model Updates: 68,720
Cumulative Timesteps: 573,084,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 573084698...
Checkpoint 573084698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,946.28531
Policy Entropy: 3.70983
Value Function Loss: 0.06370

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.70662
Value Function Update Magnitude: 0.58833

Collected Steps per Second: 22,269.69973
Overall Steps per Second: 10,903.50965

Timestep Collection Time: 2.24574
Timestep Consumption Time: 2.34104
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.58678

Cumulative Model Updates: 68,726
Cumulative Timesteps: 573,134,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,792.65242
Policy Entropy: 3.71169
Value Function Loss: 0.06427

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.64097
Value Function Update Magnitude: 0.63704

Collected Steps per Second: 22,015.50190
Overall Steps per Second: 10,827.85474

Timestep Collection Time: 2.27140
Timestep Consumption Time: 2.34687
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.61827

Cumulative Model Updates: 68,732
Cumulative Timesteps: 573,184,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 573184716...
Checkpoint 573184716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,817.68566
Policy Entropy: 3.71106
Value Function Loss: 0.06542

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.70663
Value Function Update Magnitude: 0.60220

Collected Steps per Second: 21,863.78994
Overall Steps per Second: 10,714.87775

Timestep Collection Time: 2.28734
Timestep Consumption Time: 2.38000
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.66734

Cumulative Model Updates: 68,738
Cumulative Timesteps: 573,234,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,170.39310
Policy Entropy: 3.71890
Value Function Loss: 0.06571

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.64872
Value Function Update Magnitude: 0.57543

Collected Steps per Second: 22,165.34889
Overall Steps per Second: 10,844.29753

Timestep Collection Time: 2.25577
Timestep Consumption Time: 2.35495
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.61072

Cumulative Model Updates: 68,744
Cumulative Timesteps: 573,284,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 573284726...
Checkpoint 573284726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,901.75856
Policy Entropy: 3.70605
Value Function Loss: 0.06758

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.66352
Value Function Update Magnitude: 0.67937

Collected Steps per Second: 22,020.78631
Overall Steps per Second: 10,692.52328

Timestep Collection Time: 2.27076
Timestep Consumption Time: 2.40578
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.67654

Cumulative Model Updates: 68,750
Cumulative Timesteps: 573,334,730

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,500.29407
Policy Entropy: 3.70942
Value Function Loss: 0.06573

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.70663
Value Function Update Magnitude: 0.76255

Collected Steps per Second: 22,119.12781
Overall Steps per Second: 10,580.58831

Timestep Collection Time: 2.26067
Timestep Consumption Time: 2.46535
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.72601

Cumulative Model Updates: 68,756
Cumulative Timesteps: 573,384,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 573384734...
Checkpoint 573384734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,504.18175
Policy Entropy: 3.72010
Value Function Loss: 0.06691

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.58790
Value Function Update Magnitude: 0.81917

Collected Steps per Second: 22,837.64315
Overall Steps per Second: 10,902.15472

Timestep Collection Time: 2.18963
Timestep Consumption Time: 2.39717
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.58680

Cumulative Model Updates: 68,762
Cumulative Timesteps: 573,434,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,465.30681
Policy Entropy: 3.72590
Value Function Loss: 0.06635

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08916
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.87419

Collected Steps per Second: 22,951.15392
Overall Steps per Second: 10,894.01979

Timestep Collection Time: 2.17959
Timestep Consumption Time: 2.41229
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.59188

Cumulative Model Updates: 68,768
Cumulative Timesteps: 573,484,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 573484764...
Checkpoint 573484764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,755.89412
Policy Entropy: 3.72235
Value Function Loss: 0.06410

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.53177
Value Function Update Magnitude: 0.89021

Collected Steps per Second: 22,628.28022
Overall Steps per Second: 10,706.09622

Timestep Collection Time: 2.21077
Timestep Consumption Time: 2.46189
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67266

Cumulative Model Updates: 68,774
Cumulative Timesteps: 573,534,790

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.07798
Policy Entropy: 3.71557
Value Function Loss: 0.06522

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.49204
Value Function Update Magnitude: 0.87057

Collected Steps per Second: 22,993.46599
Overall Steps per Second: 10,864.17375

Timestep Collection Time: 2.17453
Timestep Consumption Time: 2.42775
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60228

Cumulative Model Updates: 68,780
Cumulative Timesteps: 573,584,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 573584790...
Checkpoint 573584790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,576.39700
Policy Entropy: 3.71120
Value Function Loss: 0.06292

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.59314
Value Function Update Magnitude: 0.86948

Collected Steps per Second: 22,681.90570
Overall Steps per Second: 10,697.62976

Timestep Collection Time: 2.20555
Timestep Consumption Time: 2.47082
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.67636

Cumulative Model Updates: 68,786
Cumulative Timesteps: 573,634,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,084.86362
Policy Entropy: 3.70497
Value Function Loss: 0.06401

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.68071
Value Function Update Magnitude: 0.84889

Collected Steps per Second: 22,852.29490
Overall Steps per Second: 10,823.90610

Timestep Collection Time: 2.18814
Timestep Consumption Time: 2.43163
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61977

Cumulative Model Updates: 68,792
Cumulative Timesteps: 573,684,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 573684820...
Checkpoint 573684820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,611.94281
Policy Entropy: 3.71651
Value Function Loss: 0.06518

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.70263
Value Function Update Magnitude: 0.81906

Collected Steps per Second: 22,995.77114
Overall Steps per Second: 10,698.43982

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.50007
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.67507

Cumulative Model Updates: 68,798
Cumulative Timesteps: 573,734,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,237.92244
Policy Entropy: 3.70549
Value Function Loss: 0.06686

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.70981
Value Function Update Magnitude: 0.83302

Collected Steps per Second: 22,943.59128
Overall Steps per Second: 10,840.68580

Timestep Collection Time: 2.17952
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.61281

Cumulative Model Updates: 68,804
Cumulative Timesteps: 573,784,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 573784842...
Checkpoint 573784842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,480.86800
Policy Entropy: 3.70959
Value Function Loss: 0.06782

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.59529
Value Function Update Magnitude: 0.82016

Collected Steps per Second: 22,727.80993
Overall Steps per Second: 10,747.05718

Timestep Collection Time: 2.19995
Timestep Consumption Time: 2.45249
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.65244

Cumulative Model Updates: 68,810
Cumulative Timesteps: 573,834,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,464.68911
Policy Entropy: 3.71585
Value Function Loss: 0.06781

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.51047
Value Function Update Magnitude: 0.78521

Collected Steps per Second: 22,863.39942
Overall Steps per Second: 10,810.95335

Timestep Collection Time: 2.18760
Timestep Consumption Time: 2.43882
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.62642

Cumulative Model Updates: 68,816
Cumulative Timesteps: 573,884,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 573884858...
Checkpoint 573884858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,957.04269
Policy Entropy: 3.71993
Value Function Loss: 0.06955

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.48718
Value Function Update Magnitude: 0.68285

Collected Steps per Second: 22,443.42085
Overall Steps per Second: 10,731.49896

Timestep Collection Time: 2.22800
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.65955

Cumulative Model Updates: 68,822
Cumulative Timesteps: 573,934,862

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,186.32875
Policy Entropy: 3.73166
Value Function Loss: 0.06787

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.46702
Value Function Update Magnitude: 0.66327

Collected Steps per Second: 22,972.09609
Overall Steps per Second: 10,924.92541

Timestep Collection Time: 2.17786
Timestep Consumption Time: 2.40158
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.57944

Cumulative Model Updates: 68,828
Cumulative Timesteps: 573,984,892

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 573984892...
Checkpoint 573984892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,922.89828
Policy Entropy: 3.72594
Value Function Loss: 0.06745

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.52315
Value Function Update Magnitude: 0.71716

Collected Steps per Second: 22,670.11197
Overall Steps per Second: 10,617.38700

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.50411
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.71001

Cumulative Model Updates: 68,834
Cumulative Timesteps: 574,034,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,579.99116
Policy Entropy: 3.71786
Value Function Loss: 0.06592

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.56401
Value Function Update Magnitude: 0.78649

Collected Steps per Second: 22,756.05223
Overall Steps per Second: 10,793.75494

Timestep Collection Time: 2.19775
Timestep Consumption Time: 2.43568
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.63342

Cumulative Model Updates: 68,840
Cumulative Timesteps: 574,084,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 574084912...
Checkpoint 574084912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,512.81721
Policy Entropy: 3.70986
Value Function Loss: 0.06693

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.83454

Collected Steps per Second: 22,805.90958
Overall Steps per Second: 10,712.31610

Timestep Collection Time: 2.19241
Timestep Consumption Time: 2.47511
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.66752

Cumulative Model Updates: 68,846
Cumulative Timesteps: 574,134,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,952.33512
Policy Entropy: 3.71316
Value Function Loss: 0.06530

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.56478
Value Function Update Magnitude: 0.82921

Collected Steps per Second: 22,917.78521
Overall Steps per Second: 10,839.38821

Timestep Collection Time: 2.18197
Timestep Consumption Time: 2.43139
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.61336

Cumulative Model Updates: 68,852
Cumulative Timesteps: 574,184,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 574184918...
Checkpoint 574184918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,315.75114
Policy Entropy: 3.72350
Value Function Loss: 0.06753

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.55029
Value Function Update Magnitude: 0.79140

Collected Steps per Second: 22,422.91126
Overall Steps per Second: 10,741.25047

Timestep Collection Time: 2.22986
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.65495

Cumulative Model Updates: 68,858
Cumulative Timesteps: 574,234,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,556.58441
Policy Entropy: 3.71684
Value Function Loss: 0.06798

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.58982
Value Function Update Magnitude: 0.75197

Collected Steps per Second: 22,812.25685
Overall Steps per Second: 10,809.17175

Timestep Collection Time: 2.19207
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.62626

Cumulative Model Updates: 68,864
Cumulative Timesteps: 574,284,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 574284924...
Checkpoint 574284924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,077.86106
Policy Entropy: 3.71822
Value Function Loss: 0.07053

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.57991
Value Function Update Magnitude: 0.82229

Collected Steps per Second: 22,717.08944
Overall Steps per Second: 10,711.94032

Timestep Collection Time: 2.20169
Timestep Consumption Time: 2.46749
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.66918

Cumulative Model Updates: 68,870
Cumulative Timesteps: 574,334,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,841.13479
Policy Entropy: 3.71611
Value Function Loss: 0.07199

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.66533
Value Function Update Magnitude: 0.72663

Collected Steps per Second: 22,918.66294
Overall Steps per Second: 10,833.24058

Timestep Collection Time: 2.18198
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.61616

Cumulative Model Updates: 68,876
Cumulative Timesteps: 574,384,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 574384948...
Checkpoint 574384948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,407.54750
Policy Entropy: 3.72806
Value Function Loss: 0.07317

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.63977
Value Function Update Magnitude: 0.70718

Collected Steps per Second: 21,955.28766
Overall Steps per Second: 10,630.19896

Timestep Collection Time: 2.27772
Timestep Consumption Time: 2.42661
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.70433

Cumulative Model Updates: 68,882
Cumulative Timesteps: 574,434,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.91627
Policy Entropy: 3.73813
Value Function Loss: 0.07239

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11227
Policy Update Magnitude: 0.64658
Value Function Update Magnitude: 0.82279

Collected Steps per Second: 22,598.22972
Overall Steps per Second: 10,594.08033

Timestep Collection Time: 2.21283
Timestep Consumption Time: 2.50735
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.72018

Cumulative Model Updates: 68,888
Cumulative Timesteps: 574,484,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 574484962...
Checkpoint 574484962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,701.22441
Policy Entropy: 3.74222
Value Function Loss: 0.06895

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.59910
Value Function Update Magnitude: 0.90182

Collected Steps per Second: 22,720.95729
Overall Steps per Second: 10,668.53645

Timestep Collection Time: 2.20132
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.68818

Cumulative Model Updates: 68,894
Cumulative Timesteps: 574,534,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,812.64196
Policy Entropy: 3.73514
Value Function Loss: 0.06829

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.60483
Value Function Update Magnitude: 0.88231

Collected Steps per Second: 22,987.80727
Overall Steps per Second: 10,828.25263

Timestep Collection Time: 2.17550
Timestep Consumption Time: 2.44297
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.61847

Cumulative Model Updates: 68,900
Cumulative Timesteps: 574,584,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 574584988...
Checkpoint 574584988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,165.91348
Policy Entropy: 3.73168
Value Function Loss: 0.06746

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.68890
Value Function Update Magnitude: 0.90679

Collected Steps per Second: 22,832.88633
Overall Steps per Second: 10,690.02571

Timestep Collection Time: 2.19096
Timestep Consumption Time: 2.48873
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.67969

Cumulative Model Updates: 68,906
Cumulative Timesteps: 574,635,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,042.30505
Policy Entropy: 3.72728
Value Function Loss: 0.06747

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.70317
Value Function Update Magnitude: 0.89710

Collected Steps per Second: 23,014.63881
Overall Steps per Second: 10,883.81392

Timestep Collection Time: 2.17305
Timestep Consumption Time: 2.42203
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.59508

Cumulative Model Updates: 68,912
Cumulative Timesteps: 574,685,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 574685026...
Checkpoint 574685026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,665.76126
Policy Entropy: 3.72961
Value Function Loss: 0.06668

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.61526
Value Function Update Magnitude: 0.89045

Collected Steps per Second: 22,558.31796
Overall Steps per Second: 10,573.03817

Timestep Collection Time: 2.21781
Timestep Consumption Time: 2.51404
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.73185

Cumulative Model Updates: 68,918
Cumulative Timesteps: 574,735,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,752.64582
Policy Entropy: 3.72846
Value Function Loss: 0.06540

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.53264
Value Function Update Magnitude: 0.88089

Collected Steps per Second: 22,878.36190
Overall Steps per Second: 10,871.04126

Timestep Collection Time: 2.18661
Timestep Consumption Time: 2.41516
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.60177

Cumulative Model Updates: 68,924
Cumulative Timesteps: 574,785,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 574785082...
Checkpoint 574785082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,229.85556
Policy Entropy: 3.72260
Value Function Loss: 0.06639

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11052
Policy Update Magnitude: 0.48470
Value Function Update Magnitude: 0.84252

Collected Steps per Second: 22,490.55533
Overall Steps per Second: 10,727.54421

Timestep Collection Time: 2.22342
Timestep Consumption Time: 2.43804
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.66146

Cumulative Model Updates: 68,930
Cumulative Timesteps: 574,835,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,467.08840
Policy Entropy: 3.70545
Value Function Loss: 0.06822

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.47282
Value Function Update Magnitude: 0.86079

Collected Steps per Second: 22,721.88110
Overall Steps per Second: 10,791.14712

Timestep Collection Time: 2.20123
Timestep Consumption Time: 2.43368
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.63491

Cumulative Model Updates: 68,936
Cumulative Timesteps: 574,885,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 574885104...
Checkpoint 574885104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,938.72911
Policy Entropy: 3.70514
Value Function Loss: 0.07045

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.49115
Value Function Update Magnitude: 0.78331

Collected Steps per Second: 22,064.32615
Overall Steps per Second: 10,744.70367

Timestep Collection Time: 2.26737
Timestep Consumption Time: 2.38869
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.65606

Cumulative Model Updates: 68,942
Cumulative Timesteps: 574,935,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,283.70538
Policy Entropy: 3.70359
Value Function Loss: 0.07257

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.55938
Value Function Update Magnitude: 0.71841

Collected Steps per Second: 22,389.33060
Overall Steps per Second: 10,881.52324

Timestep Collection Time: 2.23428
Timestep Consumption Time: 2.36287
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.59715

Cumulative Model Updates: 68,948
Cumulative Timesteps: 574,985,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 574985156...
Checkpoint 574985156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,764.64589
Policy Entropy: 3.70678
Value Function Loss: 0.07018

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.53403
Value Function Update Magnitude: 0.75739

Collected Steps per Second: 22,031.02626
Overall Steps per Second: 10,667.25299

Timestep Collection Time: 2.26998
Timestep Consumption Time: 2.41820
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.68818

Cumulative Model Updates: 68,954
Cumulative Timesteps: 575,035,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,988.76288
Policy Entropy: 3.69641
Value Function Loss: 0.06916

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.14774
Policy Update Magnitude: 0.52049
Value Function Update Magnitude: 0.78897

Collected Steps per Second: 22,254.74153
Overall Steps per Second: 10,844.99498

Timestep Collection Time: 2.24680
Timestep Consumption Time: 2.36380
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.61061

Cumulative Model Updates: 68,960
Cumulative Timesteps: 575,085,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 575085168...
Checkpoint 575085168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,668.14301
Policy Entropy: 3.68140
Value Function Loss: 0.06895

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.17160
Policy Update Magnitude: 0.41220
Value Function Update Magnitude: 0.72484

Collected Steps per Second: 22,032.24346
Overall Steps per Second: 10,668.07696

Timestep Collection Time: 2.27058
Timestep Consumption Time: 2.41874
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.68932

Cumulative Model Updates: 68,966
Cumulative Timesteps: 575,135,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,412.17831
Policy Entropy: 3.68259
Value Function Loss: 0.07014

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.42566
Value Function Update Magnitude: 0.64116

Collected Steps per Second: 22,862.61438
Overall Steps per Second: 10,855.92033

Timestep Collection Time: 2.18733
Timestep Consumption Time: 2.41919
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.60652

Cumulative Model Updates: 68,972
Cumulative Timesteps: 575,185,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 575185202...
Checkpoint 575185202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,654.93118
Policy Entropy: 3.67632
Value Function Loss: 0.06955

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14326
Policy Update Magnitude: 0.49559
Value Function Update Magnitude: 0.62213

Collected Steps per Second: 22,821.27954
Overall Steps per Second: 10,720.17705

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.47336
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.66448

Cumulative Model Updates: 68,978
Cumulative Timesteps: 575,235,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,749.46904
Policy Entropy: 3.68432
Value Function Loss: 0.06986

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.15043
Policy Update Magnitude: 0.42944
Value Function Update Magnitude: 0.67019

Collected Steps per Second: 23,032.41709
Overall Steps per Second: 10,886.29644

Timestep Collection Time: 2.17172
Timestep Consumption Time: 2.42305
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59477

Cumulative Model Updates: 68,984
Cumulative Timesteps: 575,285,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 575285226...
Checkpoint 575285226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,019.79355
Policy Entropy: 3.67961
Value Function Loss: 0.06978

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.15208
Policy Update Magnitude: 0.41657
Value Function Update Magnitude: 0.59160

Collected Steps per Second: 22,636.05998
Overall Steps per Second: 10,655.29012

Timestep Collection Time: 2.20940
Timestep Consumption Time: 2.48424
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.69363

Cumulative Model Updates: 68,990
Cumulative Timesteps: 575,335,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,257.00432
Policy Entropy: 3.69615
Value Function Loss: 0.06408

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.38170
Value Function Update Magnitude: 0.59319

Collected Steps per Second: 22,901.35910
Overall Steps per Second: 10,950.77035

Timestep Collection Time: 2.18345
Timestep Consumption Time: 2.38280
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.56625

Cumulative Model Updates: 68,996
Cumulative Timesteps: 575,385,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 575385242...
Checkpoint 575385242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,963.30958
Policy Entropy: 3.71459
Value Function Loss: 0.05954

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.44380
Value Function Update Magnitude: 0.64175

Collected Steps per Second: 22,693.28489
Overall Steps per Second: 10,604.29741

Timestep Collection Time: 2.20426
Timestep Consumption Time: 2.51288
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.71714

Cumulative Model Updates: 69,002
Cumulative Timesteps: 575,435,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.52178
Policy Entropy: 3.72793
Value Function Loss: 0.05619

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.47337
Value Function Update Magnitude: 0.68677

Collected Steps per Second: 22,473.28971
Overall Steps per Second: 10,573.90502

Timestep Collection Time: 2.22504
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.72900

Cumulative Model Updates: 69,008
Cumulative Timesteps: 575,485,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 575485268...
Checkpoint 575485268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.92584
Policy Entropy: 3.71725
Value Function Loss: 0.05782

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.49460
Value Function Update Magnitude: 0.69443

Collected Steps per Second: 22,481.43944
Overall Steps per Second: 10,567.65349

Timestep Collection Time: 2.22495
Timestep Consumption Time: 2.50837
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73331

Cumulative Model Updates: 69,014
Cumulative Timesteps: 575,535,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,982.10885
Policy Entropy: 3.72056
Value Function Loss: 0.05924

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.50254
Value Function Update Magnitude: 0.68577

Collected Steps per Second: 22,781.37416
Overall Steps per Second: 10,818.42942

Timestep Collection Time: 2.19495
Timestep Consumption Time: 2.42716
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.62211

Cumulative Model Updates: 69,020
Cumulative Timesteps: 575,585,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 575585292...
Checkpoint 575585292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,882.60151
Policy Entropy: 3.71188
Value Function Loss: 0.05795

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.53267
Value Function Update Magnitude: 0.67502

Collected Steps per Second: 22,629.86990
Overall Steps per Second: 10,692.48766

Timestep Collection Time: 2.21062
Timestep Consumption Time: 2.46799
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.67861

Cumulative Model Updates: 69,026
Cumulative Timesteps: 575,635,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,608.54769
Policy Entropy: 3.72084
Value Function Loss: 0.05792

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.54288
Value Function Update Magnitude: 0.74338

Collected Steps per Second: 22,824.34640
Overall Steps per Second: 10,816.33269

Timestep Collection Time: 2.19257
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.62671

Cumulative Model Updates: 69,032
Cumulative Timesteps: 575,685,362

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 575685362...
Checkpoint 575685362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,987.45227
Policy Entropy: 3.71496
Value Function Loss: 0.05758

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.49840
Value Function Update Magnitude: 0.77721

Collected Steps per Second: 22,650.21863
Overall Steps per Second: 10,794.57928

Timestep Collection Time: 2.20907
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.63529

Cumulative Model Updates: 69,038
Cumulative Timesteps: 575,735,398

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,605.55066
Policy Entropy: 3.72164
Value Function Loss: 0.05857

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.43556
Value Function Update Magnitude: 0.70720

Collected Steps per Second: 22,885.19019
Overall Steps per Second: 10,844.59092

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.61244

Cumulative Model Updates: 69,044
Cumulative Timesteps: 575,785,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 575785418...
Checkpoint 575785418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,678.16237
Policy Entropy: 3.71002
Value Function Loss: 0.05939

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.41675
Value Function Update Magnitude: 0.65078

Collected Steps per Second: 22,744.60789
Overall Steps per Second: 10,617.26521

Timestep Collection Time: 2.19876
Timestep Consumption Time: 2.51149
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.71025

Cumulative Model Updates: 69,050
Cumulative Timesteps: 575,835,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,531.78244
Policy Entropy: 3.69803
Value Function Loss: 0.05924

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.46081
Value Function Update Magnitude: 0.63736

Collected Steps per Second: 22,765.82887
Overall Steps per Second: 10,679.55352

Timestep Collection Time: 2.19750
Timestep Consumption Time: 2.48696
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.68447

Cumulative Model Updates: 69,056
Cumulative Timesteps: 575,885,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 575885456...
Checkpoint 575885456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,671.59410
Policy Entropy: 3.69836
Value Function Loss: 0.05930

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.49176
Value Function Update Magnitude: 0.64628

Collected Steps per Second: 22,783.51809
Overall Steps per Second: 10,826.45160

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.42482
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62035

Cumulative Model Updates: 69,062
Cumulative Timesteps: 575,935,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,455.82348
Policy Entropy: 3.69451
Value Function Loss: 0.06213

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.58708
Value Function Update Magnitude: 0.69191

Collected Steps per Second: 22,912.20022
Overall Steps per Second: 10,723.68947

Timestep Collection Time: 2.18224
Timestep Consumption Time: 2.48033
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.66257

Cumulative Model Updates: 69,068
Cumulative Timesteps: 575,985,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 575985478...
Checkpoint 575985478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,371.74157
Policy Entropy: 3.70529
Value Function Loss: 0.06353

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05792
Policy Update Magnitude: 0.66574
Value Function Update Magnitude: 0.69510

Collected Steps per Second: 22,864.44941
Overall Steps per Second: 10,849.56148

Timestep Collection Time: 2.18794
Timestep Consumption Time: 2.42294
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61088

Cumulative Model Updates: 69,074
Cumulative Timesteps: 576,035,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,419.54921
Policy Entropy: 3.71106
Value Function Loss: 0.06390

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.59866
Value Function Update Magnitude: 0.72476

Collected Steps per Second: 22,570.60511
Overall Steps per Second: 10,601.11232

Timestep Collection Time: 2.21616
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.71837

Cumulative Model Updates: 69,080
Cumulative Timesteps: 576,085,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 576085524...
Checkpoint 576085524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,306.35449
Policy Entropy: 3.71600
Value Function Loss: 0.06321

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.56209
Value Function Update Magnitude: 0.77944

Collected Steps per Second: 22,641.28052
Overall Steps per Second: 10,619.04438

Timestep Collection Time: 2.20897
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.70984

Cumulative Model Updates: 69,086
Cumulative Timesteps: 576,135,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,589.30457
Policy Entropy: 3.71848
Value Function Loss: 0.06240

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.55514
Value Function Update Magnitude: 0.80290

Collected Steps per Second: 22,682.23353
Overall Steps per Second: 10,783.45863

Timestep Collection Time: 2.20490
Timestep Consumption Time: 2.43295
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.63784

Cumulative Model Updates: 69,092
Cumulative Timesteps: 576,185,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 576185550...
Checkpoint 576185550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,837.13379
Policy Entropy: 3.72064
Value Function Loss: 0.06403

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.80230

Collected Steps per Second: 22,579.54401
Overall Steps per Second: 10,665.92307

Timestep Collection Time: 2.21439
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.68783

Cumulative Model Updates: 69,098
Cumulative Timesteps: 576,235,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,368.36052
Policy Entropy: 3.70451
Value Function Loss: 0.06522

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10734
Policy Update Magnitude: 0.51811
Value Function Update Magnitude: 0.75609

Collected Steps per Second: 22,487.80696
Overall Steps per Second: 10,642.31582

Timestep Collection Time: 2.22361
Timestep Consumption Time: 2.47500
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.69860

Cumulative Model Updates: 69,104
Cumulative Timesteps: 576,285,554

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 576285554...
Checkpoint 576285554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,987.39128
Policy Entropy: 3.69411
Value Function Loss: 0.06646

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.44092
Value Function Update Magnitude: 0.75405

Collected Steps per Second: 22,768.74931
Overall Steps per Second: 10,798.37444

Timestep Collection Time: 2.19626
Timestep Consumption Time: 2.43463
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.63088

Cumulative Model Updates: 69,110
Cumulative Timesteps: 576,335,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,038.29391
Policy Entropy: 3.69305
Value Function Loss: 0.06394

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.43077
Value Function Update Magnitude: 0.82860

Collected Steps per Second: 22,670.67945
Overall Steps per Second: 10,607.84365

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.50951
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.71632

Cumulative Model Updates: 69,116
Cumulative Timesteps: 576,385,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 576385590...
Checkpoint 576385590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,724.23199
Policy Entropy: 3.69754
Value Function Loss: 0.06356

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.48449
Value Function Update Magnitude: 0.85315

Collected Steps per Second: 22,741.81263
Overall Steps per Second: 10,657.65206

Timestep Collection Time: 2.19912
Timestep Consumption Time: 2.49347
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.69259

Cumulative Model Updates: 69,122
Cumulative Timesteps: 576,435,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,604.71145
Policy Entropy: 3.69646
Value Function Loss: 0.06415

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.48872
Value Function Update Magnitude: 0.86173

Collected Steps per Second: 22,827.81381
Overall Steps per Second: 10,810.45741

Timestep Collection Time: 2.19040
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.62534

Cumulative Model Updates: 69,128
Cumulative Timesteps: 576,485,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 576485604...
Checkpoint 576485604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.27348
Policy Entropy: 3.69331
Value Function Loss: 0.06484

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.50062
Value Function Update Magnitude: 0.80730

Collected Steps per Second: 22,543.42376
Overall Steps per Second: 10,640.30760

Timestep Collection Time: 2.21936
Timestep Consumption Time: 2.48276
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.70212

Cumulative Model Updates: 69,134
Cumulative Timesteps: 576,535,636

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,442.83547
Policy Entropy: 3.68683
Value Function Loss: 0.06462

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.51030
Value Function Update Magnitude: 0.79759

Collected Steps per Second: 22,831.50459
Overall Steps per Second: 10,852.37980

Timestep Collection Time: 2.19083
Timestep Consumption Time: 2.41829
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.60913

Cumulative Model Updates: 69,140
Cumulative Timesteps: 576,585,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 576585656...
Checkpoint 576585656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,140.87145
Policy Entropy: 3.68526
Value Function Loss: 0.06896

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.58150
Value Function Update Magnitude: 0.71665

Collected Steps per Second: 22,682.01805
Overall Steps per Second: 10,744.07717

Timestep Collection Time: 2.20545
Timestep Consumption Time: 2.45051
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.65596

Cumulative Model Updates: 69,146
Cumulative Timesteps: 576,635,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,247.32032
Policy Entropy: 3.67595
Value Function Loss: 0.07196

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.53880
Value Function Update Magnitude: 0.79657

Collected Steps per Second: 23,059.19198
Overall Steps per Second: 10,861.34016

Timestep Collection Time: 2.16859
Timestep Consumption Time: 2.43544
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60404

Cumulative Model Updates: 69,152
Cumulative Timesteps: 576,685,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 576685686...
Checkpoint 576685686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,673.50261
Policy Entropy: 3.68601
Value Function Loss: 0.07188

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.49719
Value Function Update Magnitude: 0.80336

Collected Steps per Second: 22,052.85217
Overall Steps per Second: 10,654.11945

Timestep Collection Time: 2.26855
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.69565

Cumulative Model Updates: 69,158
Cumulative Timesteps: 576,735,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,869.57878
Policy Entropy: 3.70107
Value Function Loss: 0.06802

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.51009
Value Function Update Magnitude: 0.76733

Collected Steps per Second: 22,044.14877
Overall Steps per Second: 10,726.55971

Timestep Collection Time: 2.26890
Timestep Consumption Time: 2.39392
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.66282

Cumulative Model Updates: 69,164
Cumulative Timesteps: 576,785,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 576785730...
Checkpoint 576785730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,020.08118
Policy Entropy: 3.71012
Value Function Loss: 0.06522

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.62190
Value Function Update Magnitude: 0.76541

Collected Steps per Second: 21,861.23690
Overall Steps per Second: 10,793.61600

Timestep Collection Time: 2.28843
Timestep Consumption Time: 2.34653
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.63496

Cumulative Model Updates: 69,170
Cumulative Timesteps: 576,835,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,426.75136
Policy Entropy: 3.70896
Value Function Loss: 0.06389

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.63423
Value Function Update Magnitude: 0.79391

Collected Steps per Second: 22,213.89614
Overall Steps per Second: 10,849.39927

Timestep Collection Time: 2.25129
Timestep Consumption Time: 2.35818
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.60947

Cumulative Model Updates: 69,176
Cumulative Timesteps: 576,885,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 576885768...
Checkpoint 576885768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,657.98930
Policy Entropy: 3.70590
Value Function Loss: 0.06379

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07492
Policy Update Magnitude: 0.66692
Value Function Update Magnitude: 0.82110

Collected Steps per Second: 21,779.10793
Overall Steps per Second: 10,780.20279

Timestep Collection Time: 2.29624
Timestep Consumption Time: 2.34282
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.63906

Cumulative Model Updates: 69,182
Cumulative Timesteps: 576,935,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,547.94448
Policy Entropy: 3.70267
Value Function Loss: 0.06484

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.65525
Value Function Update Magnitude: 0.84010

Collected Steps per Second: 22,322.24071
Overall Steps per Second: 10,606.39714

Timestep Collection Time: 2.24001
Timestep Consumption Time: 2.47432
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.71432

Cumulative Model Updates: 69,188
Cumulative Timesteps: 576,985,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 576985780...
Checkpoint 576985780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.04772
Policy Entropy: 3.70375
Value Function Loss: 0.06488

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.52619
Value Function Update Magnitude: 0.79725

Collected Steps per Second: 22,802.41529
Overall Steps per Second: 10,879.40943

Timestep Collection Time: 2.19301
Timestep Consumption Time: 2.40338
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.59639

Cumulative Model Updates: 69,194
Cumulative Timesteps: 577,035,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,264.79845
Policy Entropy: 3.70358
Value Function Loss: 0.06786

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.48115
Value Function Update Magnitude: 0.75714

Collected Steps per Second: 22,720.32928
Overall Steps per Second: 10,848.25762

Timestep Collection Time: 2.20155
Timestep Consumption Time: 2.40933
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.61088

Cumulative Model Updates: 69,200
Cumulative Timesteps: 577,085,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 577085806...
Checkpoint 577085806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,941.58315
Policy Entropy: 3.70722
Value Function Loss: 0.06909

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07333
Policy Update Magnitude: 0.55870
Value Function Update Magnitude: 0.69370

Collected Steps per Second: 22,346.91381
Overall Steps per Second: 10,722.18848

Timestep Collection Time: 2.23834
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.66509

Cumulative Model Updates: 69,206
Cumulative Timesteps: 577,135,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,143.55991
Policy Entropy: 3.70674
Value Function Loss: 0.06729

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.56648
Value Function Update Magnitude: 0.65579

Collected Steps per Second: 22,966.54953
Overall Steps per Second: 10,953.94482

Timestep Collection Time: 2.17821
Timestep Consumption Time: 2.38873
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.56694

Cumulative Model Updates: 69,212
Cumulative Timesteps: 577,185,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 577185852...
Checkpoint 577185852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,324.71293
Policy Entropy: 3.71067
Value Function Loss: 0.06568

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.60732
Value Function Update Magnitude: 0.67429

Collected Steps per Second: 22,770.73540
Overall Steps per Second: 10,639.91304

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.50429
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.70079

Cumulative Model Updates: 69,218
Cumulative Timesteps: 577,235,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,545.83238
Policy Entropy: 3.70240
Value Function Loss: 0.06761

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.56986
Value Function Update Magnitude: 0.69628

Collected Steps per Second: 22,851.35094
Overall Steps per Second: 10,824.40737

Timestep Collection Time: 2.18867
Timestep Consumption Time: 2.43182
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62048

Cumulative Model Updates: 69,224
Cumulative Timesteps: 577,285,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 577285882...
Checkpoint 577285882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.27287
Policy Entropy: 3.71741
Value Function Loss: 0.06828

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.55114
Value Function Update Magnitude: 0.83885

Collected Steps per Second: 22,764.82183
Overall Steps per Second: 10,682.86745

Timestep Collection Time: 2.19743
Timestep Consumption Time: 2.48521
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.68264

Cumulative Model Updates: 69,230
Cumulative Timesteps: 577,335,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,799.96654
Policy Entropy: 3.70747
Value Function Loss: 0.06563

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.58591
Value Function Update Magnitude: 0.89432

Collected Steps per Second: 23,135.89888
Overall Steps per Second: 10,976.50167

Timestep Collection Time: 2.16132
Timestep Consumption Time: 2.39423
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.55555

Cumulative Model Updates: 69,236
Cumulative Timesteps: 577,385,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 577385910...
Checkpoint 577385910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,793.44347
Policy Entropy: 3.70622
Value Function Loss: 0.06570

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.53449
Value Function Update Magnitude: 0.82812

Collected Steps per Second: 22,612.48490
Overall Steps per Second: 10,601.45144

Timestep Collection Time: 2.21161
Timestep Consumption Time: 2.50567
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.71728

Cumulative Model Updates: 69,242
Cumulative Timesteps: 577,435,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,106.46921
Policy Entropy: 3.70445
Value Function Loss: 0.06641

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.53703
Value Function Update Magnitude: 0.74565

Collected Steps per Second: 22,855.39606
Overall Steps per Second: 10,817.51667

Timestep Collection Time: 2.18784
Timestep Consumption Time: 2.43466
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.62250

Cumulative Model Updates: 69,248
Cumulative Timesteps: 577,485,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 577485924...
Checkpoint 577485924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,735.22530
Policy Entropy: 3.70335
Value Function Loss: 0.06826

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07331
Policy Update Magnitude: 0.62992
Value Function Update Magnitude: 0.75086

Collected Steps per Second: 22,641.15445
Overall Steps per Second: 10,693.64885

Timestep Collection Time: 2.20899
Timestep Consumption Time: 2.46800
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.67698

Cumulative Model Updates: 69,254
Cumulative Timesteps: 577,535,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,079.67988
Policy Entropy: 3.69212
Value Function Loss: 0.07060

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10306
Policy Update Magnitude: 0.60762
Value Function Update Magnitude: 0.74600

Collected Steps per Second: 22,667.53175
Overall Steps per Second: 10,666.88876

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.68759

Cumulative Model Updates: 69,260
Cumulative Timesteps: 577,585,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 577585940...
Checkpoint 577585940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,971.24390
Policy Entropy: 3.69212
Value Function Loss: 0.07156

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.51462
Value Function Update Magnitude: 0.75994

Collected Steps per Second: 22,877.32330
Overall Steps per Second: 10,855.57562

Timestep Collection Time: 2.18644
Timestep Consumption Time: 2.42133
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.60777

Cumulative Model Updates: 69,266
Cumulative Timesteps: 577,635,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,497.83255
Policy Entropy: 3.69127
Value Function Loss: 0.06890

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.45732
Value Function Update Magnitude: 0.73620

Collected Steps per Second: 22,575.96817
Overall Steps per Second: 10,596.73466

Timestep Collection Time: 2.21510
Timestep Consumption Time: 2.50409
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.71919

Cumulative Model Updates: 69,272
Cumulative Timesteps: 577,685,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 577685968...
Checkpoint 577685968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,379.27918
Policy Entropy: 3.70101
Value Function Loss: 0.06775

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06762
Policy Update Magnitude: 0.54480
Value Function Update Magnitude: 0.75667

Collected Steps per Second: 22,492.66051
Overall Steps per Second: 10,568.95719

Timestep Collection Time: 2.22321
Timestep Consumption Time: 2.50819
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.73140

Cumulative Model Updates: 69,278
Cumulative Timesteps: 577,735,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,352.27385
Policy Entropy: 3.69522
Value Function Loss: 0.06660

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.68003
Value Function Update Magnitude: 0.71639

Collected Steps per Second: 22,910.71608
Overall Steps per Second: 10,812.32439

Timestep Collection Time: 2.18361
Timestep Consumption Time: 2.44334
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.62694

Cumulative Model Updates: 69,284
Cumulative Timesteps: 577,786,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 577786002...
Checkpoint 577786002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,464.79140
Policy Entropy: 3.69294
Value Function Loss: 0.06891

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.57625
Value Function Update Magnitude: 0.68485

Collected Steps per Second: 22,717.52255
Overall Steps per Second: 10,685.20946

Timestep Collection Time: 2.20182
Timestep Consumption Time: 2.47941
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.68124

Cumulative Model Updates: 69,290
Cumulative Timesteps: 577,836,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,466.33736
Policy Entropy: 3.68252
Value Function Loss: 0.07332

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.53131
Value Function Update Magnitude: 0.75604

Collected Steps per Second: 22,744.93919
Overall Steps per Second: 10,788.44607

Timestep Collection Time: 2.19908
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.63626

Cumulative Model Updates: 69,296
Cumulative Timesteps: 577,886,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 577886040...
Checkpoint 577886040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,696.68455
Policy Entropy: 3.68506
Value Function Loss: 0.07615

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.52573
Value Function Update Magnitude: 0.77204

Collected Steps per Second: 22,981.07705
Overall Steps per Second: 10,734.36528

Timestep Collection Time: 2.17640
Timestep Consumption Time: 2.48303
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.65943

Cumulative Model Updates: 69,302
Cumulative Timesteps: 577,936,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,689.84725
Policy Entropy: 3.66407
Value Function Loss: 0.07449

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.63422
Value Function Update Magnitude: 0.72561

Collected Steps per Second: 22,863.50523
Overall Steps per Second: 10,828.65612

Timestep Collection Time: 2.18750
Timestep Consumption Time: 2.43117
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.61867

Cumulative Model Updates: 69,308
Cumulative Timesteps: 577,986,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 577986070...
Checkpoint 577986070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,598.57697
Policy Entropy: 3.66976
Value Function Loss: 0.07130

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.61839
Value Function Update Magnitude: 0.73424

Collected Steps per Second: 22,500.90336
Overall Steps per Second: 10,772.32381

Timestep Collection Time: 2.22338
Timestep Consumption Time: 2.42075
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.64412

Cumulative Model Updates: 69,314
Cumulative Timesteps: 578,036,098

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,367.98739
Policy Entropy: 3.64936
Value Function Loss: 0.06967

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.52698
Value Function Update Magnitude: 0.80906

Collected Steps per Second: 22,872.83482
Overall Steps per Second: 10,804.52065

Timestep Collection Time: 2.18740
Timestep Consumption Time: 2.44326
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.63065

Cumulative Model Updates: 69,320
Cumulative Timesteps: 578,086,130

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 578086130...
Checkpoint 578086130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,020.75241
Policy Entropy: 3.65989
Value Function Loss: 0.07172

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.49551
Value Function Update Magnitude: 0.84113

Collected Steps per Second: 22,709.39051
Overall Steps per Second: 10,702.21367

Timestep Collection Time: 2.20191
Timestep Consumption Time: 2.47040
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.67230

Cumulative Model Updates: 69,326
Cumulative Timesteps: 578,136,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,040.43915
Policy Entropy: 3.65212
Value Function Loss: 0.07257

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.54069
Value Function Update Magnitude: 0.82954

Collected Steps per Second: 22,967.60527
Overall Steps per Second: 10,860.62612

Timestep Collection Time: 2.17759
Timestep Consumption Time: 2.42749
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.60508

Cumulative Model Updates: 69,332
Cumulative Timesteps: 578,186,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 578186148...
Checkpoint 578186148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,720.05455
Policy Entropy: 3.67120
Value Function Loss: 0.07245

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.49172
Value Function Update Magnitude: 0.84940

Collected Steps per Second: 22,563.84180
Overall Steps per Second: 10,700.93340

Timestep Collection Time: 2.21593
Timestep Consumption Time: 2.45655
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.67249

Cumulative Model Updates: 69,338
Cumulative Timesteps: 578,236,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,742.45524
Policy Entropy: 3.66779
Value Function Loss: 0.07208

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.40249
Value Function Update Magnitude: 0.84579

Collected Steps per Second: 22,721.12175
Overall Steps per Second: 10,585.98719

Timestep Collection Time: 2.20253
Timestep Consumption Time: 2.52485
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.72738

Cumulative Model Updates: 69,344
Cumulative Timesteps: 578,286,192

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 578286192...
Checkpoint 578286192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,106.91453
Policy Entropy: 3.67150
Value Function Loss: 0.07334

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.41864
Value Function Update Magnitude: 0.88018

Collected Steps per Second: 22,673.07105
Overall Steps per Second: 10,672.33377

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.48104
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.68745

Cumulative Model Updates: 69,350
Cumulative Timesteps: 578,336,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,478.80830
Policy Entropy: 3.67223
Value Function Loss: 0.07204

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.41656
Value Function Update Magnitude: 0.83431

Collected Steps per Second: 22,728.87989
Overall Steps per Second: 10,726.18264

Timestep Collection Time: 2.20037
Timestep Consumption Time: 2.46224
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.66261

Cumulative Model Updates: 69,356
Cumulative Timesteps: 578,386,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 578386230...
Checkpoint 578386230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,497.80381
Policy Entropy: 3.67397
Value Function Loss: 0.06963

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.49723
Value Function Update Magnitude: 0.73870

Collected Steps per Second: 22,686.20573
Overall Steps per Second: 10,656.16184

Timestep Collection Time: 2.20416
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.69250

Cumulative Model Updates: 69,362
Cumulative Timesteps: 578,436,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,613.90104
Policy Entropy: 3.67500
Value Function Loss: 0.06970

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.58294
Value Function Update Magnitude: 0.77117

Collected Steps per Second: 22,662.08858
Overall Steps per Second: 10,775.93683

Timestep Collection Time: 2.20703
Timestep Consumption Time: 2.43442
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.64145

Cumulative Model Updates: 69,368
Cumulative Timesteps: 578,486,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 578486250...
Checkpoint 578486250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,329.57861
Policy Entropy: 3.66185
Value Function Loss: 0.07098

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.59590
Value Function Update Magnitude: 0.74498

Collected Steps per Second: 22,551.72010
Overall Steps per Second: 10,763.16786

Timestep Collection Time: 2.21819
Timestep Consumption Time: 2.42951
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.64770

Cumulative Model Updates: 69,374
Cumulative Timesteps: 578,536,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,075.27694
Policy Entropy: 3.66091
Value Function Loss: 0.07586

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.50566
Value Function Update Magnitude: 0.59324

Collected Steps per Second: 22,835.38461
Overall Steps per Second: 10,832.99473

Timestep Collection Time: 2.18967
Timestep Consumption Time: 2.42604
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.61571

Cumulative Model Updates: 69,380
Cumulative Timesteps: 578,586,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 578586276...
Checkpoint 578586276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,083.13307
Policy Entropy: 3.65901
Value Function Loss: 0.07176

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.44423
Value Function Update Magnitude: 0.58170

Collected Steps per Second: 22,470.98557
Overall Steps per Second: 10,771.79955

Timestep Collection Time: 2.22643
Timestep Consumption Time: 2.41811
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.64453

Cumulative Model Updates: 69,386
Cumulative Timesteps: 578,636,306

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,136.32541
Policy Entropy: 3.65732
Value Function Loss: 0.06796

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.43954
Value Function Update Magnitude: 0.68609

Collected Steps per Second: 22,815.73158
Overall Steps per Second: 10,782.88502

Timestep Collection Time: 2.19165
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.63735

Cumulative Model Updates: 69,392
Cumulative Timesteps: 578,686,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 578686310...
Checkpoint 578686310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,517.66541
Policy Entropy: 3.66350
Value Function Loss: 0.06593

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.45322
Value Function Update Magnitude: 0.72685

Collected Steps per Second: 22,623.33633
Overall Steps per Second: 10,681.96974

Timestep Collection Time: 2.21081
Timestep Consumption Time: 2.47147
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.68228

Cumulative Model Updates: 69,398
Cumulative Timesteps: 578,736,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,764.38936
Policy Entropy: 3.67859
Value Function Loss: 0.06579

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.48735
Value Function Update Magnitude: 0.65738

Collected Steps per Second: 23,096.74153
Overall Steps per Second: 10,983.50539

Timestep Collection Time: 2.16515
Timestep Consumption Time: 2.38786
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.55301

Cumulative Model Updates: 69,404
Cumulative Timesteps: 578,786,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 578786334...
Checkpoint 578786334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,282.67816
Policy Entropy: 3.67021
Value Function Loss: 0.07045

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.55177
Value Function Update Magnitude: 0.63101

Collected Steps per Second: 22,471.20265
Overall Steps per Second: 10,579.15369

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.50301
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.72968

Cumulative Model Updates: 69,410
Cumulative Timesteps: 578,836,370

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,681.66836
Policy Entropy: 3.66986
Value Function Loss: 0.07086

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.55322
Value Function Update Magnitude: 0.67443

Collected Steps per Second: 22,611.52386
Overall Steps per Second: 10,638.37164

Timestep Collection Time: 2.21188
Timestep Consumption Time: 2.48940
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.70128

Cumulative Model Updates: 69,416
Cumulative Timesteps: 578,886,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 578886384...
Checkpoint 578886384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,944.08660
Policy Entropy: 3.65519
Value Function Loss: 0.06930

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.63802
Value Function Update Magnitude: 0.61563

Collected Steps per Second: 22,804.72904
Overall Steps per Second: 10,808.48169

Timestep Collection Time: 2.19288
Timestep Consumption Time: 2.43386
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.62674

Cumulative Model Updates: 69,422
Cumulative Timesteps: 578,936,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,067.73704
Policy Entropy: 3.68260
Value Function Loss: 0.06498

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.55871
Value Function Update Magnitude: 0.58824

Collected Steps per Second: 22,883.77368
Overall Steps per Second: 10,706.03833

Timestep Collection Time: 2.18557
Timestep Consumption Time: 2.48600
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.67157

Cumulative Model Updates: 69,428
Cumulative Timesteps: 578,986,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 578986406...
Checkpoint 578986406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,433.53578
Policy Entropy: 3.68400
Value Function Loss: 0.06525

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.57791
Value Function Update Magnitude: 0.60189

Collected Steps per Second: 22,584.40056
Overall Steps per Second: 10,666.49717

Timestep Collection Time: 2.21436
Timestep Consumption Time: 2.47415
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.68851

Cumulative Model Updates: 69,434
Cumulative Timesteps: 579,036,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,439.76589
Policy Entropy: 3.70189
Value Function Loss: 0.06533

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.52346
Value Function Update Magnitude: 0.61084

Collected Steps per Second: 22,605.60191
Overall Steps per Second: 10,769.15088

Timestep Collection Time: 2.21193
Timestep Consumption Time: 2.43115
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.64308

Cumulative Model Updates: 69,440
Cumulative Timesteps: 579,086,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 579086418...
Checkpoint 579086418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,861.04490
Policy Entropy: 3.68573
Value Function Loss: 0.06580

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.57297
Value Function Update Magnitude: 0.65591

Collected Steps per Second: 22,520.41292
Overall Steps per Second: 10,556.17446

Timestep Collection Time: 2.22065
Timestep Consumption Time: 2.51686
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.73751

Cumulative Model Updates: 69,446
Cumulative Timesteps: 579,136,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,397.07585
Policy Entropy: 3.66747
Value Function Loss: 0.06701

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.65313
Value Function Update Magnitude: 0.65845

Collected Steps per Second: 22,942.54679
Overall Steps per Second: 10,858.97445

Timestep Collection Time: 2.17971
Timestep Consumption Time: 2.42552
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.60522

Cumulative Model Updates: 69,452
Cumulative Timesteps: 579,186,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 579186436...
Checkpoint 579186436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,451.03405
Policy Entropy: 3.67409
Value Function Loss: 0.06638

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.58837
Value Function Update Magnitude: 0.67456

Collected Steps per Second: 22,369.03169
Overall Steps per Second: 10,771.98864

Timestep Collection Time: 2.23622
Timestep Consumption Time: 2.40749
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.64371

Cumulative Model Updates: 69,458
Cumulative Timesteps: 579,236,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,263.69808
Policy Entropy: 3.68290
Value Function Loss: 0.06573

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.52075
Value Function Update Magnitude: 0.70147

Collected Steps per Second: 22,626.40682
Overall Steps per Second: 10,760.43313

Timestep Collection Time: 2.21034
Timestep Consumption Time: 2.43743
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.64777

Cumulative Model Updates: 69,464
Cumulative Timesteps: 579,286,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 579286470...
Checkpoint 579286470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,648.67631
Policy Entropy: 3.69140
Value Function Loss: 0.06474

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.73579

Collected Steps per Second: 22,479.83861
Overall Steps per Second: 10,750.78901

Timestep Collection Time: 2.22466
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.65175

Cumulative Model Updates: 69,470
Cumulative Timesteps: 579,336,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,769.15520
Policy Entropy: 3.68671
Value Function Loss: 0.06461

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.78861

Collected Steps per Second: 22,472.45626
Overall Steps per Second: 10,603.54485

Timestep Collection Time: 2.22601
Timestep Consumption Time: 2.49165
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.71767

Cumulative Model Updates: 69,476
Cumulative Timesteps: 579,386,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 579386504...
Checkpoint 579386504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,765.95893
Policy Entropy: 3.68386
Value Function Loss: 0.06548

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.48480
Value Function Update Magnitude: 0.78210

Collected Steps per Second: 22,572.59934
Overall Steps per Second: 10,684.19866

Timestep Collection Time: 2.21570
Timestep Consumption Time: 2.46542
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.68112

Cumulative Model Updates: 69,482
Cumulative Timesteps: 579,436,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,843.85813
Policy Entropy: 3.68657
Value Function Loss: 0.06490

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.51039
Value Function Update Magnitude: 0.77608

Collected Steps per Second: 22,895.74000
Overall Steps per Second: 10,667.34849

Timestep Collection Time: 2.18521
Timestep Consumption Time: 2.50499
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.69020

Cumulative Model Updates: 69,488
Cumulative Timesteps: 579,486,550

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 579486550...
Checkpoint 579486550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,516.62404
Policy Entropy: 3.69131
Value Function Loss: 0.06405

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.53133
Value Function Update Magnitude: 0.76187

Collected Steps per Second: 22,744.19285
Overall Steps per Second: 10,639.65836

Timestep Collection Time: 2.19951
Timestep Consumption Time: 2.50234
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.70184

Cumulative Model Updates: 69,494
Cumulative Timesteps: 579,536,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.44140
Policy Entropy: 3.69444
Value Function Loss: 0.06240

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.57944
Value Function Update Magnitude: 0.82188

Collected Steps per Second: 22,863.37513
Overall Steps per Second: 10,849.35166

Timestep Collection Time: 2.18769
Timestep Consumption Time: 2.42254
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.61023

Cumulative Model Updates: 69,500
Cumulative Timesteps: 579,586,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 579586594...
Checkpoint 579586594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,187.14370
Policy Entropy: 3.69177
Value Function Loss: 0.06129

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.59327
Value Function Update Magnitude: 0.87095

Collected Steps per Second: 22,743.89423
Overall Steps per Second: 10,716.31504

Timestep Collection Time: 2.19910
Timestep Consumption Time: 2.46818
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.66728

Cumulative Model Updates: 69,506
Cumulative Timesteps: 579,636,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,563.01241
Policy Entropy: 3.68417
Value Function Loss: 0.06132

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11464
Policy Update Magnitude: 0.56723
Value Function Update Magnitude: 0.84522

Collected Steps per Second: 22,871.01988
Overall Steps per Second: 10,838.59548

Timestep Collection Time: 2.18705
Timestep Consumption Time: 2.42794
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.61499

Cumulative Model Updates: 69,512
Cumulative Timesteps: 579,686,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 579686630...
Checkpoint 579686630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,652.07096
Policy Entropy: 3.68449
Value Function Loss: 0.06090

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.51899
Value Function Update Magnitude: 0.83287

Collected Steps per Second: 22,603.03350
Overall Steps per Second: 10,701.29959

Timestep Collection Time: 2.21351
Timestep Consumption Time: 2.46181
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.67532

Cumulative Model Updates: 69,518
Cumulative Timesteps: 579,736,662

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,106.62991
Policy Entropy: 3.68991
Value Function Loss: 0.06087

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.47789
Value Function Update Magnitude: 0.84903

Collected Steps per Second: 22,848.61683
Overall Steps per Second: 10,834.13973

Timestep Collection Time: 2.18893
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.61633

Cumulative Model Updates: 69,524
Cumulative Timesteps: 579,786,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 579786676...
Checkpoint 579786676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,930.92067
Policy Entropy: 3.69468
Value Function Loss: 0.06079

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.44961
Value Function Update Magnitude: 0.86163

Collected Steps per Second: 21,969.24394
Overall Steps per Second: 10,732.89596

Timestep Collection Time: 2.27691
Timestep Consumption Time: 2.38371
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.66062

Cumulative Model Updates: 69,530
Cumulative Timesteps: 579,836,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,120.70196
Policy Entropy: 3.68889
Value Function Loss: 0.05955

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.49343
Value Function Update Magnitude: 0.87753

Collected Steps per Second: 22,259.33991
Overall Steps per Second: 10,848.88562

Timestep Collection Time: 2.24769
Timestep Consumption Time: 2.36403
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.61172

Cumulative Model Updates: 69,536
Cumulative Timesteps: 579,886,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 579886730...
Checkpoint 579886730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,784.10698
Policy Entropy: 3.68391
Value Function Loss: 0.06044

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.46862
Value Function Update Magnitude: 0.88008

Collected Steps per Second: 21,892.17866
Overall Steps per Second: 10,656.37971

Timestep Collection Time: 2.28392
Timestep Consumption Time: 2.40810
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.69203

Cumulative Model Updates: 69,542
Cumulative Timesteps: 579,936,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,099.82010
Policy Entropy: 3.68575
Value Function Loss: 0.06285

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.44866
Value Function Update Magnitude: 0.88616

Collected Steps per Second: 22,072.41059
Overall Steps per Second: 10,731.29477

Timestep Collection Time: 2.26627
Timestep Consumption Time: 2.39505
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.66132

Cumulative Model Updates: 69,548
Cumulative Timesteps: 579,986,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 579986752...
Checkpoint 579986752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,961.20551
Policy Entropy: 3.68178
Value Function Loss: 0.06866

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.44190
Value Function Update Magnitude: 0.84142

Collected Steps per Second: 21,841.95796
Overall Steps per Second: 10,785.86811

Timestep Collection Time: 2.28990
Timestep Consumption Time: 2.34727
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.63718

Cumulative Model Updates: 69,554
Cumulative Timesteps: 580,036,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,147.87586
Policy Entropy: 3.68408
Value Function Loss: 0.07360

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.46838
Value Function Update Magnitude: 0.75407

Collected Steps per Second: 22,246.86881
Overall Steps per Second: 10,879.88385

Timestep Collection Time: 2.24823
Timestep Consumption Time: 2.34888
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.59711

Cumulative Model Updates: 69,560
Cumulative Timesteps: 580,086,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 580086784...
Checkpoint 580086784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.29721
Policy Entropy: 3.68788
Value Function Loss: 0.07324

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.51867
Value Function Update Magnitude: 0.73342

Collected Steps per Second: 22,024.88562
Overall Steps per Second: 10,696.69932

Timestep Collection Time: 2.27089
Timestep Consumption Time: 2.40495
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.67583

Cumulative Model Updates: 69,566
Cumulative Timesteps: 580,136,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,051.76509
Policy Entropy: 3.68527
Value Function Loss: 0.07123

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.56841
Value Function Update Magnitude: 0.72797

Collected Steps per Second: 22,370.28398
Overall Steps per Second: 10,650.11098

Timestep Collection Time: 2.23573
Timestep Consumption Time: 2.46037
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.69610

Cumulative Model Updates: 69,572
Cumulative Timesteps: 580,186,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 580186814...
Checkpoint 580186814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,072.81403
Policy Entropy: 3.68509
Value Function Loss: 0.06869

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07045
Policy Update Magnitude: 0.70910
Value Function Update Magnitude: 0.71141

Collected Steps per Second: 22,603.76423
Overall Steps per Second: 10,871.20332

Timestep Collection Time: 2.21317
Timestep Consumption Time: 2.38853
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.60170

Cumulative Model Updates: 69,578
Cumulative Timesteps: 580,236,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,148.11026
Policy Entropy: 3.67807
Value Function Loss: 0.06865

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07597
Policy Update Magnitude: 0.75872
Value Function Update Magnitude: 0.69924

Collected Steps per Second: 22,944.09115
Overall Steps per Second: 10,878.02463

Timestep Collection Time: 2.18034
Timestep Consumption Time: 2.41847
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.59881

Cumulative Model Updates: 69,584
Cumulative Timesteps: 580,286,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 580286866...
Checkpoint 580286866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,509.01623
Policy Entropy: 3.68040
Value Function Loss: 0.06845

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.67509
Value Function Update Magnitude: 0.69739

Collected Steps per Second: 22,600.04986
Overall Steps per Second: 10,771.60937

Timestep Collection Time: 2.21238
Timestep Consumption Time: 2.42945
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.64183

Cumulative Model Updates: 69,590
Cumulative Timesteps: 580,336,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,602.86320
Policy Entropy: 3.67850
Value Function Loss: 0.06524

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.58844
Value Function Update Magnitude: 0.68475

Collected Steps per Second: 23,045.95071
Overall Steps per Second: 10,885.41118

Timestep Collection Time: 2.17079
Timestep Consumption Time: 2.42508
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.59588

Cumulative Model Updates: 69,596
Cumulative Timesteps: 580,386,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 580386894...
Checkpoint 580386894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,583.37051
Policy Entropy: 3.68780
Value Function Loss: 0.06115

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.59514
Value Function Update Magnitude: 0.70805

Collected Steps per Second: 22,501.39605
Overall Steps per Second: 10,626.49124

Timestep Collection Time: 2.22342
Timestep Consumption Time: 2.48463
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.70805

Cumulative Model Updates: 69,602
Cumulative Timesteps: 580,436,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,058.64797
Policy Entropy: 3.70604
Value Function Loss: 0.05962

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06759
Policy Update Magnitude: 0.65045
Value Function Update Magnitude: 0.68204

Collected Steps per Second: 22,861.44361
Overall Steps per Second: 10,824.17840

Timestep Collection Time: 2.18753
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.62021

Cumulative Model Updates: 69,608
Cumulative Timesteps: 580,486,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 580486934...
Checkpoint 580486934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,268.48334
Policy Entropy: 3.70616
Value Function Loss: 0.06232

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.65344
Value Function Update Magnitude: 0.69973

Collected Steps per Second: 22,935.73038
Overall Steps per Second: 10,709.01636

Timestep Collection Time: 2.18062
Timestep Consumption Time: 2.48966
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.67027

Cumulative Model Updates: 69,614
Cumulative Timesteps: 580,536,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,426.07107
Policy Entropy: 3.68798
Value Function Loss: 0.06526

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.63022
Value Function Update Magnitude: 0.70963

Collected Steps per Second: 22,986.84660
Overall Steps per Second: 10,845.34996

Timestep Collection Time: 2.17533
Timestep Consumption Time: 2.43531
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.61064

Cumulative Model Updates: 69,620
Cumulative Timesteps: 580,586,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 580586952...
Checkpoint 580586952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,765.36254
Policy Entropy: 3.68404
Value Function Loss: 0.06606

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.60705
Value Function Update Magnitude: 0.73672

Collected Steps per Second: 22,471.33889
Overall Steps per Second: 10,780.50642

Timestep Collection Time: 2.22666
Timestep Consumption Time: 2.41468
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.64134

Cumulative Model Updates: 69,626
Cumulative Timesteps: 580,636,988

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,391.41228
Policy Entropy: 3.67639
Value Function Loss: 0.06617

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.62169
Value Function Update Magnitude: 0.70449

Collected Steps per Second: 22,822.53328
Overall Steps per Second: 10,814.77997

Timestep Collection Time: 2.19090
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.62349

Cumulative Model Updates: 69,632
Cumulative Timesteps: 580,686,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 580686990...
Checkpoint 580686990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,097.15527
Policy Entropy: 3.66936
Value Function Loss: 0.06747

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.62147
Value Function Update Magnitude: 0.68989

Collected Steps per Second: 22,696.12032
Overall Steps per Second: 10,652.17369

Timestep Collection Time: 2.20390
Timestep Consumption Time: 2.49185
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.69576

Cumulative Model Updates: 69,638
Cumulative Timesteps: 580,737,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,792.80628
Policy Entropy: 3.67656
Value Function Loss: 0.06688

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.55291
Value Function Update Magnitude: 0.67217

Collected Steps per Second: 22,713.56893
Overall Steps per Second: 10,698.64569

Timestep Collection Time: 2.20194
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.67480

Cumulative Model Updates: 69,644
Cumulative Timesteps: 580,787,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 580787024...
Checkpoint 580787024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,987.29209
Policy Entropy: 3.68526
Value Function Loss: 0.06607

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.48346
Value Function Update Magnitude: 0.77546

Collected Steps per Second: 22,519.11944
Overall Steps per Second: 10,783.33056

Timestep Collection Time: 2.22176
Timestep Consumption Time: 2.41800
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.63975

Cumulative Model Updates: 69,650
Cumulative Timesteps: 580,837,056

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,518.86337
Policy Entropy: 3.70536
Value Function Loss: 0.06248

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.46350
Value Function Update Magnitude: 0.85454

Collected Steps per Second: 22,558.30969
Overall Steps per Second: 10,587.72164

Timestep Collection Time: 2.21719
Timestep Consumption Time: 2.50678
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.72396

Cumulative Model Updates: 69,656
Cumulative Timesteps: 580,887,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 580887072...
Checkpoint 580887072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,457.79484
Policy Entropy: 3.69685
Value Function Loss: 0.06140

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.51902
Value Function Update Magnitude: 0.88005

Collected Steps per Second: 22,621.06967
Overall Steps per Second: 10,572.87356

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.51936
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.73022

Cumulative Model Updates: 69,662
Cumulative Timesteps: 580,937,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,518.06375
Policy Entropy: 3.69225
Value Function Loss: 0.06134

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.82579

Collected Steps per Second: 22,768.32097
Overall Steps per Second: 10,667.78409

Timestep Collection Time: 2.19647
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68795

Cumulative Model Updates: 69,668
Cumulative Timesteps: 580,987,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 580987094...
Checkpoint 580987094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,790.22524
Policy Entropy: 3.68328
Value Function Loss: 0.06377

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.53965
Value Function Update Magnitude: 0.74344

Collected Steps per Second: 22,705.78153
Overall Steps per Second: 10,824.11634

Timestep Collection Time: 2.20217
Timestep Consumption Time: 2.41733
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.61950

Cumulative Model Updates: 69,674
Cumulative Timesteps: 581,037,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,085.12691
Policy Entropy: 3.68030
Value Function Loss: 0.06568

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.50389
Value Function Update Magnitude: 0.79742

Collected Steps per Second: 22,717.43343
Overall Steps per Second: 10,619.06937

Timestep Collection Time: 2.20175
Timestep Consumption Time: 2.50846
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.71021

Cumulative Model Updates: 69,680
Cumulative Timesteps: 581,087,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 581087114...
Checkpoint 581087114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,523.75365
Policy Entropy: 3.68968
Value Function Loss: 0.06599

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.49376
Value Function Update Magnitude: 0.85011

Collected Steps per Second: 22,615.77696
Overall Steps per Second: 10,639.55545

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.48890
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.70001

Cumulative Model Updates: 69,686
Cumulative Timesteps: 581,137,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,238.46419
Policy Entropy: 3.68766
Value Function Loss: 0.06515

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.49477
Value Function Update Magnitude: 0.84670

Collected Steps per Second: 22,881.17706
Overall Steps per Second: 10,776.50089

Timestep Collection Time: 2.18555
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.64047

Cumulative Model Updates: 69,692
Cumulative Timesteps: 581,187,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 581187128...
Checkpoint 581187128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,228.41539
Policy Entropy: 3.68214
Value Function Loss: 0.06307

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.46266
Value Function Update Magnitude: 0.76360

Collected Steps per Second: 22,570.17839
Overall Steps per Second: 10,663.50585

Timestep Collection Time: 2.21620
Timestep Consumption Time: 2.47457
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.69077

Cumulative Model Updates: 69,698
Cumulative Timesteps: 581,237,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,531.39106
Policy Entropy: 3.68394
Value Function Loss: 0.06499

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11430
Policy Update Magnitude: 0.46076
Value Function Update Magnitude: 0.72840

Collected Steps per Second: 22,514.43489
Overall Steps per Second: 10,589.57157

Timestep Collection Time: 2.22089
Timestep Consumption Time: 2.50093
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.72182

Cumulative Model Updates: 69,704
Cumulative Timesteps: 581,287,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 581287150...
Checkpoint 581287150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,013.20487
Policy Entropy: 3.67944
Value Function Loss: 0.06492

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.52323
Value Function Update Magnitude: 0.72773

Collected Steps per Second: 22,411.67931
Overall Steps per Second: 10,605.58474

Timestep Collection Time: 2.23205
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.71676

Cumulative Model Updates: 69,710
Cumulative Timesteps: 581,337,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,964.90873
Policy Entropy: 3.68801
Value Function Loss: 0.06494

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.50145
Value Function Update Magnitude: 0.81028

Collected Steps per Second: 23,008.00072
Overall Steps per Second: 10,809.48958

Timestep Collection Time: 2.17350
Timestep Consumption Time: 2.45280
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.62631

Cumulative Model Updates: 69,716
Cumulative Timesteps: 581,387,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 581387182...
Checkpoint 581387182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,725.85818
Policy Entropy: 3.70978
Value Function Loss: 0.06298

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.41661
Value Function Update Magnitude: 0.78044

Collected Steps per Second: 22,748.52539
Overall Steps per Second: 10,667.79810

Timestep Collection Time: 2.19812
Timestep Consumption Time: 2.48926
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.68738

Cumulative Model Updates: 69,722
Cumulative Timesteps: 581,437,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,543.93525
Policy Entropy: 3.72316
Value Function Loss: 0.06026

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.42677
Value Function Update Magnitude: 0.77716

Collected Steps per Second: 22,799.68564
Overall Steps per Second: 10,827.50676

Timestep Collection Time: 2.19433
Timestep Consumption Time: 2.42631
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62064

Cumulative Model Updates: 69,728
Cumulative Timesteps: 581,487,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 581487216...
Checkpoint 581487216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,547.93210
Policy Entropy: 3.71563
Value Function Loss: 0.05622

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.47139
Value Function Update Magnitude: 0.72001

Collected Steps per Second: 22,846.29099
Overall Steps per Second: 10,642.17250

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.69942

Cumulative Model Updates: 69,734
Cumulative Timesteps: 581,537,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,637.87803
Policy Entropy: 3.71328
Value Function Loss: 0.05260

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.55932
Value Function Update Magnitude: 0.73160

Collected Steps per Second: 22,853.61458
Overall Steps per Second: 10,811.58789

Timestep Collection Time: 2.18836
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62578

Cumulative Model Updates: 69,740
Cumulative Timesteps: 581,587,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 581587240...
Checkpoint 581587240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.72989
Policy Entropy: 3.72306
Value Function Loss: 0.04902

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.62296
Value Function Update Magnitude: 0.76030

Collected Steps per Second: 21,946.53981
Overall Steps per Second: 10,761.61786

Timestep Collection Time: 2.27954
Timestep Consumption Time: 2.36920
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.64874

Cumulative Model Updates: 69,746
Cumulative Timesteps: 581,637,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,141.94783
Policy Entropy: 3.73600
Value Function Loss: 0.04773

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.75957

Collected Steps per Second: 22,109.79377
Overall Steps per Second: 10,819.70830

Timestep Collection Time: 2.26244
Timestep Consumption Time: 2.36079
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.62323

Cumulative Model Updates: 69,752
Cumulative Timesteps: 581,687,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 581687290...
Checkpoint 581687290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,997.17568
Policy Entropy: 3.74567
Value Function Loss: 0.04910

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.60862
Value Function Update Magnitude: 0.75885

Collected Steps per Second: 21,827.08509
Overall Steps per Second: 10,742.12042

Timestep Collection Time: 2.29137
Timestep Consumption Time: 2.36450
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.65588

Cumulative Model Updates: 69,758
Cumulative Timesteps: 581,737,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,775.75848
Policy Entropy: 3.74366
Value Function Loss: 0.04924

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.60379
Value Function Update Magnitude: 0.76355

Collected Steps per Second: 22,195.90492
Overall Steps per Second: 10,852.31496

Timestep Collection Time: 2.25285
Timestep Consumption Time: 2.35483
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.60768

Cumulative Model Updates: 69,764
Cumulative Timesteps: 581,787,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 581787308...
Checkpoint 581787308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.25661
Policy Entropy: 3.75282
Value Function Loss: 0.05046

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.59918
Value Function Update Magnitude: 0.78613

Collected Steps per Second: 22,160.31876
Overall Steps per Second: 10,666.11921

Timestep Collection Time: 2.25728
Timestep Consumption Time: 2.43253
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.68980

Cumulative Model Updates: 69,770
Cumulative Timesteps: 581,837,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,352.19712
Policy Entropy: 3.76024
Value Function Loss: 0.05170

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.64076
Value Function Update Magnitude: 0.79878

Collected Steps per Second: 22,099.88998
Overall Steps per Second: 10,817.79239

Timestep Collection Time: 2.26255
Timestep Consumption Time: 2.35965
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62220

Cumulative Model Updates: 69,776
Cumulative Timesteps: 581,887,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 581887332...
Checkpoint 581887332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,374.66074
Policy Entropy: 3.76232
Value Function Loss: 0.05303

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.63395
Value Function Update Magnitude: 0.79747

Collected Steps per Second: 22,034.53305
Overall Steps per Second: 10,743.55124

Timestep Collection Time: 2.26944
Timestep Consumption Time: 2.38508
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.65451

Cumulative Model Updates: 69,782
Cumulative Timesteps: 581,937,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,652.30634
Policy Entropy: 3.74669
Value Function Loss: 0.05460

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06471
Policy Update Magnitude: 0.65466
Value Function Update Magnitude: 0.78995

Collected Steps per Second: 22,284.78073
Overall Steps per Second: 10,869.64387

Timestep Collection Time: 2.24476
Timestep Consumption Time: 2.35741
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.60217

Cumulative Model Updates: 69,788
Cumulative Timesteps: 581,987,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 581987362...
Checkpoint 581987362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,453.93612
Policy Entropy: 3.74308
Value Function Loss: 0.05498

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07466
Policy Update Magnitude: 0.69480
Value Function Update Magnitude: 0.79367

Collected Steps per Second: 21,910.53986
Overall Steps per Second: 10,683.64820

Timestep Collection Time: 2.28319
Timestep Consumption Time: 2.39929
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.68248

Cumulative Model Updates: 69,794
Cumulative Timesteps: 582,037,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,057.70840
Policy Entropy: 3.72789
Value Function Loss: 0.05472

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.60925
Value Function Update Magnitude: 0.82426

Collected Steps per Second: 22,263.43729
Overall Steps per Second: 10,620.30053

Timestep Collection Time: 2.24583
Timestep Consumption Time: 2.46213
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.70796

Cumulative Model Updates: 69,800
Cumulative Timesteps: 582,087,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 582087388...
Checkpoint 582087388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,000.68670
Policy Entropy: 3.72947
Value Function Loss: 0.05716

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.60255
Value Function Update Magnitude: 0.82999

Collected Steps per Second: 22,623.34500
Overall Steps per Second: 10,846.47224

Timestep Collection Time: 2.21179
Timestep Consumption Time: 2.40151
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61330

Cumulative Model Updates: 69,806
Cumulative Timesteps: 582,137,426

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,270.74215
Policy Entropy: 3.72265
Value Function Loss: 0.05763

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.57361
Value Function Update Magnitude: 0.83790

Collected Steps per Second: 23,069.68200
Overall Steps per Second: 10,935.83832

Timestep Collection Time: 2.16787
Timestep Consumption Time: 2.40535
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.57322

Cumulative Model Updates: 69,812
Cumulative Timesteps: 582,187,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 582187438...
Checkpoint 582187438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,793.78730
Policy Entropy: 3.73392
Value Function Loss: 0.05922

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.83211

Collected Steps per Second: 22,557.74995
Overall Steps per Second: 10,685.79466

Timestep Collection Time: 2.21751
Timestep Consumption Time: 2.46366
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.68117

Cumulative Model Updates: 69,818
Cumulative Timesteps: 582,237,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,404.79180
Policy Entropy: 3.73420
Value Function Loss: 0.06046

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.56236
Value Function Update Magnitude: 0.83335

Collected Steps per Second: 22,901.67659
Overall Steps per Second: 10,792.39331

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.44974
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.63308

Cumulative Model Updates: 69,824
Cumulative Timesteps: 582,287,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 582287462...
Checkpoint 582287462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,177.80396
Policy Entropy: 3.73352
Value Function Loss: 0.05936

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07830
Policy Update Magnitude: 0.55644
Value Function Update Magnitude: 0.84811

Collected Steps per Second: 22,745.99985
Overall Steps per Second: 10,705.99960

Timestep Collection Time: 2.19880
Timestep Consumption Time: 2.47278
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.67159

Cumulative Model Updates: 69,830
Cumulative Timesteps: 582,337,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,466.66246
Policy Entropy: 3.72844
Value Function Loss: 0.05745

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.60324
Value Function Update Magnitude: 0.85213

Collected Steps per Second: 23,129.40787
Overall Steps per Second: 10,879.56831

Timestep Collection Time: 2.16236
Timestep Consumption Time: 2.43470
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.59706

Cumulative Model Updates: 69,836
Cumulative Timesteps: 582,387,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 582387490...
Checkpoint 582387490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,218.60174
Policy Entropy: 3.73450
Value Function Loss: 0.05596

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.60894
Value Function Update Magnitude: 0.85311

Collected Steps per Second: 22,752.20656
Overall Steps per Second: 10,694.31610

Timestep Collection Time: 2.19882
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.67800

Cumulative Model Updates: 69,842
Cumulative Timesteps: 582,437,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,974.03784
Policy Entropy: 3.73771
Value Function Loss: 0.05644

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.56862
Value Function Update Magnitude: 0.83971

Collected Steps per Second: 23,097.55111
Overall Steps per Second: 10,879.12913

Timestep Collection Time: 2.16516
Timestep Consumption Time: 2.43171
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.59688

Cumulative Model Updates: 69,848
Cumulative Timesteps: 582,487,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 582487528...
Checkpoint 582487528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,035.60509
Policy Entropy: 3.73060
Value Function Loss: 0.05893

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.53218
Value Function Update Magnitude: 0.79788

Collected Steps per Second: 22,514.89931
Overall Steps per Second: 10,751.28458

Timestep Collection Time: 2.22235
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.65396

Cumulative Model Updates: 69,854
Cumulative Timesteps: 582,537,564

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,288.56302
Policy Entropy: 3.72168
Value Function Loss: 0.05984

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.52838
Value Function Update Magnitude: 0.79854

Collected Steps per Second: 22,712.27657
Overall Steps per Second: 10,775.95584

Timestep Collection Time: 2.20269
Timestep Consumption Time: 2.43987
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.64256

Cumulative Model Updates: 69,860
Cumulative Timesteps: 582,587,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 582587592...
Checkpoint 582587592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,178.20195
Policy Entropy: 3.72062
Value Function Loss: 0.06143

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.56950
Value Function Update Magnitude: 0.82491

Collected Steps per Second: 22,813.16077
Overall Steps per Second: 10,695.62527

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.48448
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.67743

Cumulative Model Updates: 69,866
Cumulative Timesteps: 582,637,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,731.76503
Policy Entropy: 3.71073
Value Function Loss: 0.06056

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.57054
Value Function Update Magnitude: 0.84416

Collected Steps per Second: 22,904.43832
Overall Steps per Second: 10,825.34441

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.43620
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.61953

Cumulative Model Updates: 69,872
Cumulative Timesteps: 582,687,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 582687628...
Checkpoint 582687628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,172.54241
Policy Entropy: 3.70628
Value Function Loss: 0.06213

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.66110
Value Function Update Magnitude: 0.82611

Collected Steps per Second: 22,579.95774
Overall Steps per Second: 10,786.16477

Timestep Collection Time: 2.21444
Timestep Consumption Time: 2.42131
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.63575

Cumulative Model Updates: 69,878
Cumulative Timesteps: 582,737,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,155.64068
Policy Entropy: 3.71089
Value Function Loss: 0.06068

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.61976
Value Function Update Magnitude: 0.84104

Collected Steps per Second: 23,106.50535
Overall Steps per Second: 10,849.26665

Timestep Collection Time: 2.16502
Timestep Consumption Time: 2.44598
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.61100

Cumulative Model Updates: 69,884
Cumulative Timesteps: 582,787,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 582787656...
Checkpoint 582787656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,858.17947
Policy Entropy: 3.71814
Value Function Loss: 0.05936

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.79260

Collected Steps per Second: 22,840.70764
Overall Steps per Second: 10,769.65133

Timestep Collection Time: 2.18986
Timestep Consumption Time: 2.45449
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.64435

Cumulative Model Updates: 69,890
Cumulative Timesteps: 582,837,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,693.38183
Policy Entropy: 3.72653
Value Function Loss: 0.05830

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.50809
Value Function Update Magnitude: 0.75392

Collected Steps per Second: 22,705.11431
Overall Steps per Second: 10,805.66539

Timestep Collection Time: 2.20232
Timestep Consumption Time: 2.42525
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.62757

Cumulative Model Updates: 69,896
Cumulative Timesteps: 582,887,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 582887678...
Checkpoint 582887678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,810.63829
Policy Entropy: 3.70888
Value Function Loss: 0.05708

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.59415
Value Function Update Magnitude: 0.81915

Collected Steps per Second: 22,710.75379
Overall Steps per Second: 10,639.27263

Timestep Collection Time: 2.20257
Timestep Consumption Time: 2.49907
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.70164

Cumulative Model Updates: 69,902
Cumulative Timesteps: 582,937,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,957.97729
Policy Entropy: 3.71743
Value Function Loss: 0.05740

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10632
Policy Update Magnitude: 0.57681
Value Function Update Magnitude: 0.79077

Collected Steps per Second: 23,233.69911
Overall Steps per Second: 10,889.83076

Timestep Collection Time: 2.15282
Timestep Consumption Time: 2.44027
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.59309

Cumulative Model Updates: 69,908
Cumulative Timesteps: 582,987,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 582987718...
Checkpoint 582987718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,448.09993
Policy Entropy: 3.70563
Value Function Loss: 0.06227

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.69965

Collected Steps per Second: 22,588.36149
Overall Steps per Second: 10,649.48890

Timestep Collection Time: 2.21353
Timestep Consumption Time: 2.48153
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.69506

Cumulative Model Updates: 69,914
Cumulative Timesteps: 583,037,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,278.42786
Policy Entropy: 3.71663
Value Function Loss: 0.06233

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.51774
Value Function Update Magnitude: 0.69552

Collected Steps per Second: 22,915.64197
Overall Steps per Second: 10,890.99448

Timestep Collection Time: 2.18357
Timestep Consumption Time: 2.41086
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.59444

Cumulative Model Updates: 69,920
Cumulative Timesteps: 583,087,756

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 583087756...
Checkpoint 583087756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,972.50235
Policy Entropy: 3.70766
Value Function Loss: 0.06482

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.51427
Value Function Update Magnitude: 0.79089

Collected Steps per Second: 22,761.05786
Overall Steps per Second: 10,708.40293

Timestep Collection Time: 2.19717
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.67016

Cumulative Model Updates: 69,926
Cumulative Timesteps: 583,137,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,237.63255
Policy Entropy: 3.70961
Value Function Loss: 0.06362

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.74497

Collected Steps per Second: 22,717.48683
Overall Steps per Second: 10,804.29699

Timestep Collection Time: 2.20192
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62982

Cumulative Model Updates: 69,932
Cumulative Timesteps: 583,187,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 583187788...
Checkpoint 583187788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,610.46184
Policy Entropy: 3.70504
Value Function Loss: 0.06595

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.55016
Value Function Update Magnitude: 0.70362

Collected Steps per Second: 22,522.40085
Overall Steps per Second: 10,701.39737

Timestep Collection Time: 2.22126
Timestep Consumption Time: 2.45365
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.67490

Cumulative Model Updates: 69,938
Cumulative Timesteps: 583,237,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,946.40901
Policy Entropy: 3.70159
Value Function Loss: 0.06414

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.52250
Value Function Update Magnitude: 0.76041

Collected Steps per Second: 22,806.39953
Overall Steps per Second: 10,891.92207

Timestep Collection Time: 2.19237
Timestep Consumption Time: 2.39819
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.59056

Cumulative Model Updates: 69,944
Cumulative Timesteps: 583,287,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 583287816...
Checkpoint 583287816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,108.58127
Policy Entropy: 3.70746
Value Function Loss: 0.06278

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.53159
Value Function Update Magnitude: 0.80254

Collected Steps per Second: 22,691.50825
Overall Steps per Second: 10,608.75841

Timestep Collection Time: 2.20470
Timestep Consumption Time: 2.51102
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.71573

Cumulative Model Updates: 69,950
Cumulative Timesteps: 583,337,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,065.02110
Policy Entropy: 3.68861
Value Function Loss: 0.06298

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.51990
Value Function Update Magnitude: 0.79861

Collected Steps per Second: 22,816.88661
Overall Steps per Second: 10,897.95563

Timestep Collection Time: 2.19145
Timestep Consumption Time: 2.39675
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.58820

Cumulative Model Updates: 69,956
Cumulative Timesteps: 583,387,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 583387846...
Checkpoint 583387846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,249.35289
Policy Entropy: 3.70126
Value Function Loss: 0.06249

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.47050
Value Function Update Magnitude: 0.80678

Collected Steps per Second: 22,767.06901
Overall Steps per Second: 10,691.24517

Timestep Collection Time: 2.19624
Timestep Consumption Time: 2.48067
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.67691

Cumulative Model Updates: 69,962
Cumulative Timesteps: 583,437,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,810.76604
Policy Entropy: 3.70183
Value Function Loss: 0.06346

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.45567
Value Function Update Magnitude: 0.79845

Collected Steps per Second: 22,674.62382
Overall Steps per Second: 10,768.79380

Timestep Collection Time: 2.20617
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.64527

Cumulative Model Updates: 69,968
Cumulative Timesteps: 583,487,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 583487872...
Checkpoint 583487872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,816.14316
Policy Entropy: 3.70954
Value Function Loss: 0.06035

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.47881
Value Function Update Magnitude: 0.83119

Collected Steps per Second: 22,508.90556
Overall Steps per Second: 10,751.60077

Timestep Collection Time: 2.22232
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.65252

Cumulative Model Updates: 69,974
Cumulative Timesteps: 583,537,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,542.38805
Policy Entropy: 3.73005
Value Function Loss: 0.05708

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.48477
Value Function Update Magnitude: 0.80445

Collected Steps per Second: 22,860.73625
Overall Steps per Second: 10,878.27235

Timestep Collection Time: 2.18751
Timestep Consumption Time: 2.40955
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59705

Cumulative Model Updates: 69,980
Cumulative Timesteps: 583,587,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 583587902...
Checkpoint 583587902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015.63769
Policy Entropy: 3.73820
Value Function Loss: 0.05545

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.49231
Value Function Update Magnitude: 0.74325

Collected Steps per Second: 22,574.23867
Overall Steps per Second: 10,669.82372

Timestep Collection Time: 2.21545
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.68724

Cumulative Model Updates: 69,986
Cumulative Timesteps: 583,637,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,089.29335
Policy Entropy: 3.74217
Value Function Loss: 0.05337

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.52893
Value Function Update Magnitude: 0.70332

Collected Steps per Second: 22,733.20316
Overall Steps per Second: 10,806.85758

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.42804
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.62817

Cumulative Model Updates: 69,992
Cumulative Timesteps: 583,687,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 583687930...
Checkpoint 583687930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,628.20384
Policy Entropy: 3.74988
Value Function Loss: 0.05177

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.52104
Value Function Update Magnitude: 0.73693

Collected Steps per Second: 22,653.49338
Overall Steps per Second: 10,714.49789

Timestep Collection Time: 2.20849
Timestep Consumption Time: 2.46088
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.66937

Cumulative Model Updates: 69,998
Cumulative Timesteps: 583,737,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,021.15108
Policy Entropy: 3.75803
Value Function Loss: 0.04914

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.50276
Value Function Update Magnitude: 0.76962

Collected Steps per Second: 22,677.46861
Overall Steps per Second: 10,862.27779

Timestep Collection Time: 2.20518
Timestep Consumption Time: 2.39864
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.60382

Cumulative Model Updates: 70,004
Cumulative Timesteps: 583,787,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 583787968...
Checkpoint 583787968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,589.11851
Policy Entropy: 3.77093
Value Function Loss: 0.04760

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.52225
Value Function Update Magnitude: 0.79661

Collected Steps per Second: 22,505.60379
Overall Steps per Second: 10,687.50042

Timestep Collection Time: 2.22247
Timestep Consumption Time: 2.45758
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.68005

Cumulative Model Updates: 70,010
Cumulative Timesteps: 583,837,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,002.27280
Policy Entropy: 3.75768
Value Function Loss: 0.04657

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.78453

Collected Steps per Second: 22,852.83363
Overall Steps per Second: 10,829.65311

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.42972
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.61825

Cumulative Model Updates: 70,016
Cumulative Timesteps: 583,888,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 583888000...
Checkpoint 583888000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,935.83391
Policy Entropy: 3.75723
Value Function Loss: 0.04438

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.56038
Value Function Update Magnitude: 0.76572

Collected Steps per Second: 22,524.88919
Overall Steps per Second: 10,778.91672

Timestep Collection Time: 2.22021
Timestep Consumption Time: 2.41940
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.63961

Cumulative Model Updates: 70,022
Cumulative Timesteps: 583,938,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,688.85064
Policy Entropy: 3.75514
Value Function Loss: 0.04491

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.74583

Collected Steps per Second: 22,272.10660
Overall Steps per Second: 10,551.49111

Timestep Collection Time: 2.24604
Timestep Consumption Time: 2.49490
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.74094

Cumulative Model Updates: 70,028
Cumulative Timesteps: 583,988,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 583988034...
Checkpoint 583988034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,786.02931
Policy Entropy: 3.77285
Value Function Loss: 0.04351

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.52054
Value Function Update Magnitude: 0.73382

Collected Steps per Second: 22,726.91849
Overall Steps per Second: 10,699.64452

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.67436

Cumulative Model Updates: 70,034
Cumulative Timesteps: 584,038,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,335.24986
Policy Entropy: 3.77509
Value Function Loss: 0.04287

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.52055
Value Function Update Magnitude: 0.74641

Collected Steps per Second: 22,699.35861
Overall Steps per Second: 10,638.57232

Timestep Collection Time: 2.20367
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.70195

Cumulative Model Updates: 70,040
Cumulative Timesteps: 584,088,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 584088070...
Checkpoint 584088070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,205.99589
Policy Entropy: 3.78314
Value Function Loss: 0.04258

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.54926
Value Function Update Magnitude: 0.75302

Collected Steps per Second: 22,513.22291
Overall Steps per Second: 10,677.28878

Timestep Collection Time: 2.22207
Timestep Consumption Time: 2.46320
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.68527

Cumulative Model Updates: 70,046
Cumulative Timesteps: 584,138,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,524.13742
Policy Entropy: 3.77080
Value Function Loss: 0.04265

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.75061

Collected Steps per Second: 22,338.17089
Overall Steps per Second: 10,529.10478

Timestep Collection Time: 2.23850
Timestep Consumption Time: 2.51062
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.74912

Cumulative Model Updates: 70,052
Cumulative Timesteps: 584,188,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 584188100...
Checkpoint 584188100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.37665
Policy Entropy: 3.76455
Value Function Loss: 0.04418

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06233
Policy Update Magnitude: 0.62201
Value Function Update Magnitude: 0.73969

Collected Steps per Second: 22,608.00390
Overall Steps per Second: 10,633.47711

Timestep Collection Time: 2.21267
Timestep Consumption Time: 2.49172
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.70439

Cumulative Model Updates: 70,058
Cumulative Timesteps: 584,238,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,604.96164
Policy Entropy: 3.74093
Value Function Loss: 0.04727

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.67034
Value Function Update Magnitude: 0.73032

Collected Steps per Second: 22,668.74820
Overall Steps per Second: 10,758.54383

Timestep Collection Time: 2.20568
Timestep Consumption Time: 2.44179
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.64747

Cumulative Model Updates: 70,064
Cumulative Timesteps: 584,288,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 584288124...
Checkpoint 584288124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,814.60379
Policy Entropy: 3.75384
Value Function Loss: 0.04650

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.68225
Value Function Update Magnitude: 0.72014

Collected Steps per Second: 22,573.15350
Overall Steps per Second: 10,777.52771

Timestep Collection Time: 2.21502
Timestep Consumption Time: 2.42426
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.63928

Cumulative Model Updates: 70,070
Cumulative Timesteps: 584,338,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,784.91130
Policy Entropy: 3.76080
Value Function Loss: 0.04719

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06493
Policy Update Magnitude: 0.66933
Value Function Update Magnitude: 0.70976

Collected Steps per Second: 22,779.85154
Overall Steps per Second: 10,818.08069

Timestep Collection Time: 2.19545
Timestep Consumption Time: 2.42755
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.62300

Cumulative Model Updates: 70,076
Cumulative Timesteps: 584,388,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 584388136...
Checkpoint 584388136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.79016
Policy Entropy: 3.76929
Value Function Loss: 0.04917

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06126
Policy Update Magnitude: 0.69518
Value Function Update Magnitude: 0.70505

Collected Steps per Second: 22,638.35266
Overall Steps per Second: 10,673.61890

Timestep Collection Time: 2.20908
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.68538

Cumulative Model Updates: 70,082
Cumulative Timesteps: 584,438,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,405.98011
Policy Entropy: 3.75809
Value Function Loss: 0.05131

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.69211
Value Function Update Magnitude: 0.73646

Collected Steps per Second: 22,954.05807
Overall Steps per Second: 10,827.60398

Timestep Collection Time: 2.17948
Timestep Consumption Time: 2.44093
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.62041

Cumulative Model Updates: 70,088
Cumulative Timesteps: 584,488,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 584488174...
Checkpoint 584488174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,681.02043
Policy Entropy: 3.75308
Value Function Loss: 0.05452

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.59869
Value Function Update Magnitude: 0.71596

Collected Steps per Second: 22,748.88536
Overall Steps per Second: 10,694.14572

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.67676

Cumulative Model Updates: 70,094
Cumulative Timesteps: 584,538,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.03647
Policy Entropy: 3.75073
Value Function Loss: 0.05467

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.56880
Value Function Update Magnitude: 0.70833

Collected Steps per Second: 22,789.90145
Overall Steps per Second: 10,686.30165

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.48493
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.67889

Cumulative Model Updates: 70,100
Cumulative Timesteps: 584,588,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 584588188...
Checkpoint 584588188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,802.72441
Policy Entropy: 3.75702
Value Function Loss: 0.05498

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.59757
Value Function Update Magnitude: 0.74747

Collected Steps per Second: 22,440.46742
Overall Steps per Second: 10,842.19822

Timestep Collection Time: 2.22999
Timestep Consumption Time: 2.38550
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.61548

Cumulative Model Updates: 70,106
Cumulative Timesteps: 584,638,230

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,820.13005
Policy Entropy: 3.75487
Value Function Loss: 0.05476

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.53495
Value Function Update Magnitude: 0.77963

Collected Steps per Second: 22,768.10974
Overall Steps per Second: 10,689.99711

Timestep Collection Time: 2.19737
Timestep Consumption Time: 2.48270
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.68008

Cumulative Model Updates: 70,112
Cumulative Timesteps: 584,688,260

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 584688260...
Checkpoint 584688260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,006.97162
Policy Entropy: 3.74654
Value Function Loss: 0.05539

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.47419
Value Function Update Magnitude: 0.77116

Collected Steps per Second: 22,704.56676
Overall Steps per Second: 10,861.89481

Timestep Collection Time: 2.20246
Timestep Consumption Time: 2.40134
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60380

Cumulative Model Updates: 70,118
Cumulative Timesteps: 584,738,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,907.41692
Policy Entropy: 3.73028
Value Function Loss: 0.05921

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08782
Policy Update Magnitude: 0.50489
Value Function Update Magnitude: 0.76526

Collected Steps per Second: 22,952.09219
Overall Steps per Second: 10,857.66008

Timestep Collection Time: 2.17950
Timestep Consumption Time: 2.42776
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.60725

Cumulative Model Updates: 70,124
Cumulative Timesteps: 584,788,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 584788290...
Checkpoint 584788290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,363.23586
Policy Entropy: 3.72092
Value Function Loss: 0.06138

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.51962
Value Function Update Magnitude: 0.78677

Collected Steps per Second: 22,811.31855
Overall Steps per Second: 10,733.67551

Timestep Collection Time: 2.19312
Timestep Consumption Time: 2.46772
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.66085

Cumulative Model Updates: 70,130
Cumulative Timesteps: 584,838,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,353.48125
Policy Entropy: 3.72916
Value Function Loss: 0.06065

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.47782
Value Function Update Magnitude: 0.82993

Collected Steps per Second: 22,740.83113
Overall Steps per Second: 10,802.49350

Timestep Collection Time: 2.19974
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63078

Cumulative Model Updates: 70,136
Cumulative Timesteps: 584,888,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 584888342...
Checkpoint 584888342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,613.31203
Policy Entropy: 3.72815
Value Function Loss: 0.05971

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.57503
Value Function Update Magnitude: 0.87113

Collected Steps per Second: 22,560.90542
Overall Steps per Second: 10,787.23015

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.41985
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.63696

Cumulative Model Updates: 70,142
Cumulative Timesteps: 584,938,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,269.43368
Policy Entropy: 3.73952
Value Function Loss: 0.05955

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.60174
Value Function Update Magnitude: 0.88537

Collected Steps per Second: 22,892.57393
Overall Steps per Second: 10,820.99286

Timestep Collection Time: 2.18481
Timestep Consumption Time: 2.43731
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.62213

Cumulative Model Updates: 70,148
Cumulative Timesteps: 584,988,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 584988378...
Checkpoint 584988378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,439.78079
Policy Entropy: 3.72839
Value Function Loss: 0.06219

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.52488
Value Function Update Magnitude: 0.84431

Collected Steps per Second: 22,622.46624
Overall Steps per Second: 10,673.60938

Timestep Collection Time: 2.21055
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.68520

Cumulative Model Updates: 70,154
Cumulative Timesteps: 585,038,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,692.37788
Policy Entropy: 3.73023
Value Function Loss: 0.06464

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.50042
Value Function Update Magnitude: 0.68418

Collected Steps per Second: 22,771.38683
Overall Steps per Second: 10,816.50869

Timestep Collection Time: 2.19714
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.62552

Cumulative Model Updates: 70,160
Cumulative Timesteps: 585,088,418

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 585088418...
Checkpoint 585088418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,860.13261
Policy Entropy: 3.71706
Value Function Loss: 0.06706

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.57259
Value Function Update Magnitude: 0.72888

Collected Steps per Second: 22,623.94819
Overall Steps per Second: 10,774.18089

Timestep Collection Time: 2.21031
Timestep Consumption Time: 2.43097
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.64128

Cumulative Model Updates: 70,166
Cumulative Timesteps: 585,138,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.55812
Policy Entropy: 3.71278
Value Function Loss: 0.06638

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.57402
Value Function Update Magnitude: 0.82446

Collected Steps per Second: 22,824.96368
Overall Steps per Second: 10,816.20364

Timestep Collection Time: 2.19137
Timestep Consumption Time: 2.43299
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.62436

Cumulative Model Updates: 70,172
Cumulative Timesteps: 585,188,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 585188442...
Checkpoint 585188442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,136.22673
Policy Entropy: 3.70476
Value Function Loss: 0.06784

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.86336

Collected Steps per Second: 22,622.59526
Overall Steps per Second: 10,697.82414

Timestep Collection Time: 2.21062
Timestep Consumption Time: 2.46416
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.67478

Cumulative Model Updates: 70,178
Cumulative Timesteps: 585,238,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,033.69155
Policy Entropy: 3.71408
Value Function Loss: 0.06717

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11413
Policy Update Magnitude: 0.56872
Value Function Update Magnitude: 0.88872

Collected Steps per Second: 22,999.96399
Overall Steps per Second: 10,831.66299

Timestep Collection Time: 2.17461
Timestep Consumption Time: 2.44296
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.61757

Cumulative Model Updates: 70,184
Cumulative Timesteps: 585,288,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 585288468...
Checkpoint 585288468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,143.41541
Policy Entropy: 3.70785
Value Function Loss: 0.06636

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.88984

Collected Steps per Second: 22,516.04084
Overall Steps per Second: 10,696.87518

Timestep Collection Time: 2.22144
Timestep Consumption Time: 2.45451
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.67595

Cumulative Model Updates: 70,190
Cumulative Timesteps: 585,338,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,626.20015
Policy Entropy: 3.70466
Value Function Loss: 0.06358

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.54037
Value Function Update Magnitude: 0.88422

Collected Steps per Second: 22,956.65254
Overall Steps per Second: 10,860.35719

Timestep Collection Time: 2.17889
Timestep Consumption Time: 2.42685
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60574

Cumulative Model Updates: 70,196
Cumulative Timesteps: 585,388,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 585388506...
Checkpoint 585388506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,072.66702
Policy Entropy: 3.71096
Value Function Loss: 0.06359

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.54870
Value Function Update Magnitude: 0.87754

Collected Steps per Second: 23,191.62349
Overall Steps per Second: 10,725.82002

Timestep Collection Time: 2.15655
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.66295

Cumulative Model Updates: 70,202
Cumulative Timesteps: 585,438,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,563.37482
Policy Entropy: 3.71493
Value Function Loss: 0.06155

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.87199

Collected Steps per Second: 22,923.88346
Overall Steps per Second: 10,849.14219

Timestep Collection Time: 2.18227
Timestep Consumption Time: 2.42879
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61106

Cumulative Model Updates: 70,208
Cumulative Timesteps: 585,488,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 585488546...
Checkpoint 585488546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,231.09709
Policy Entropy: 3.70289
Value Function Loss: 0.06563

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.56988
Value Function Update Magnitude: 0.86674

Collected Steps per Second: 22,726.99389
Overall Steps per Second: 10,637.52045

Timestep Collection Time: 2.20073
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.70185

Cumulative Model Updates: 70,214
Cumulative Timesteps: 585,538,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,278.80169
Policy Entropy: 3.70755
Value Function Loss: 0.06648

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08230
Policy Update Magnitude: 0.60651
Value Function Update Magnitude: 0.85917

Collected Steps per Second: 22,989.33511
Overall Steps per Second: 10,879.22266

Timestep Collection Time: 2.17588
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.59794

Cumulative Model Updates: 70,220
Cumulative Timesteps: 585,588,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 585588584...
Checkpoint 585588584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,253.91294
Policy Entropy: 3.70372
Value Function Loss: 0.06371

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.61273
Value Function Update Magnitude: 0.87748

Collected Steps per Second: 22,077.52660
Overall Steps per Second: 10,683.72188

Timestep Collection Time: 2.26520
Timestep Consumption Time: 2.41575
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.68095

Cumulative Model Updates: 70,226
Cumulative Timesteps: 585,638,594

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,016.90924
Policy Entropy: 3.70878
Value Function Loss: 0.06609

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.61126
Value Function Update Magnitude: 0.79151

Collected Steps per Second: 22,117.46645
Overall Steps per Second: 10,826.43442

Timestep Collection Time: 2.26183
Timestep Consumption Time: 2.35889
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.62073

Cumulative Model Updates: 70,232
Cumulative Timesteps: 585,688,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 585688620...
Checkpoint 585688620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,919.67165
Policy Entropy: 3.68884
Value Function Loss: 0.06823

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.67116
Value Function Update Magnitude: 0.72761

Collected Steps per Second: 21,657.76983
Overall Steps per Second: 10,750.46675

Timestep Collection Time: 2.30947
Timestep Consumption Time: 2.34316
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.65264

Cumulative Model Updates: 70,238
Cumulative Timesteps: 585,738,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,864.79733
Policy Entropy: 3.66915
Value Function Loss: 0.07272

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.70913
Value Function Update Magnitude: 0.70047

Collected Steps per Second: 21,946.40190
Overall Steps per Second: 10,793.67544

Timestep Collection Time: 2.27919
Timestep Consumption Time: 2.35501
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.63420

Cumulative Model Updates: 70,244
Cumulative Timesteps: 585,788,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 585788658...
Checkpoint 585788658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,988.14018
Policy Entropy: 3.67864
Value Function Loss: 0.06983

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11804
Policy Update Magnitude: 0.62531
Value Function Update Magnitude: 0.67499

Collected Steps per Second: 22,007.36474
Overall Steps per Second: 10,699.65793

Timestep Collection Time: 2.27242
Timestep Consumption Time: 2.40156
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.67398

Cumulative Model Updates: 70,250
Cumulative Timesteps: 585,838,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,496.69506
Policy Entropy: 3.68714
Value Function Loss: 0.06939

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.51434
Value Function Update Magnitude: 0.71229

Collected Steps per Second: 22,641.06528
Overall Steps per Second: 10,702.71863

Timestep Collection Time: 2.20900
Timestep Consumption Time: 2.46402
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.67302

Cumulative Model Updates: 70,256
Cumulative Timesteps: 585,888,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 585888682...
Checkpoint 585888682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,535.80964
Policy Entropy: 3.68492
Value Function Loss: 0.06531

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.53250
Value Function Update Magnitude: 0.76226

Collected Steps per Second: 22,546.55268
Overall Steps per Second: 10,822.72738

Timestep Collection Time: 2.21896
Timestep Consumption Time: 2.40372
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.62268

Cumulative Model Updates: 70,262
Cumulative Timesteps: 585,938,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,873.94613
Policy Entropy: 3.68081
Value Function Loss: 0.06604

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.57908
Value Function Update Magnitude: 0.80864

Collected Steps per Second: 23,089.17462
Overall Steps per Second: 10,934.98446

Timestep Collection Time: 2.16638
Timestep Consumption Time: 2.40793
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.57431

Cumulative Model Updates: 70,268
Cumulative Timesteps: 585,988,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 585988732...
Checkpoint 585988732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,974.79840
Policy Entropy: 3.68541
Value Function Loss: 0.06442

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.51913
Value Function Update Magnitude: 0.80214

Collected Steps per Second: 22,788.36765
Overall Steps per Second: 10,743.31010

Timestep Collection Time: 2.19524
Timestep Consumption Time: 2.46124
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.65648

Cumulative Model Updates: 70,274
Cumulative Timesteps: 586,038,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,450.79982
Policy Entropy: 3.69846
Value Function Loss: 0.06292

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.51429
Value Function Update Magnitude: 0.82450

Collected Steps per Second: 22,687.56102
Overall Steps per Second: 10,760.76088

Timestep Collection Time: 2.20447
Timestep Consumption Time: 2.44334
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.64781

Cumulative Model Updates: 70,280
Cumulative Timesteps: 586,088,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 586088772...
Checkpoint 586088772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,316.02385
Policy Entropy: 3.69985
Value Function Loss: 0.05968

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08937
Policy Update Magnitude: 0.62192
Value Function Update Magnitude: 0.83013

Collected Steps per Second: 22,257.88568
Overall Steps per Second: 10,671.52958

Timestep Collection Time: 2.24855
Timestep Consumption Time: 2.44131
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.68986

Cumulative Model Updates: 70,286
Cumulative Timesteps: 586,138,820

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,073.82482
Policy Entropy: 3.68866
Value Function Loss: 0.06107

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.66837
Value Function Update Magnitude: 0.82348

Collected Steps per Second: 22,871.88770
Overall Steps per Second: 10,681.24174

Timestep Collection Time: 2.18653
Timestep Consumption Time: 2.49551
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.68204

Cumulative Model Updates: 70,292
Cumulative Timesteps: 586,188,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 586188830...
Checkpoint 586188830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,982.44191
Policy Entropy: 3.69040
Value Function Loss: 0.06022

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.63450
Value Function Update Magnitude: 0.82637

Collected Steps per Second: 22,821.34032
Overall Steps per Second: 10,856.92176

Timestep Collection Time: 2.19190
Timestep Consumption Time: 2.41549
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.60738

Cumulative Model Updates: 70,298
Cumulative Timesteps: 586,238,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,829.15229
Policy Entropy: 3.68478
Value Function Loss: 0.06093

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.53241
Value Function Update Magnitude: 0.82679

Collected Steps per Second: 22,842.83133
Overall Steps per Second: 10,700.72069

Timestep Collection Time: 2.18948
Timestep Consumption Time: 2.48441
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.67389

Cumulative Model Updates: 70,304
Cumulative Timesteps: 586,288,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 586288866...
Checkpoint 586288866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,955.35192
Policy Entropy: 3.69184
Value Function Loss: 0.05837

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.82174

Collected Steps per Second: 22,816.38946
Overall Steps per Second: 10,836.02002

Timestep Collection Time: 2.19220
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.61590

Cumulative Model Updates: 70,310
Cumulative Timesteps: 586,338,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.09312
Policy Entropy: 3.67922
Value Function Loss: 0.05907

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.83255

Collected Steps per Second: 22,871.49257
Overall Steps per Second: 10,737.98302

Timestep Collection Time: 2.18700
Timestep Consumption Time: 2.47123
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.65823

Cumulative Model Updates: 70,316
Cumulative Timesteps: 586,388,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 586388904...
Checkpoint 586388904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,680.21335
Policy Entropy: 3.69281
Value Function Loss: 0.06035

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11586
Policy Update Magnitude: 0.57565
Value Function Update Magnitude: 0.80477

Collected Steps per Second: 22,486.33356
Overall Steps per Second: 10,771.46980

Timestep Collection Time: 2.22375
Timestep Consumption Time: 2.41851
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.64226

Cumulative Model Updates: 70,322
Cumulative Timesteps: 586,438,908

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,350.34490
Policy Entropy: 3.68951
Value Function Loss: 0.06288

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.51359
Value Function Update Magnitude: 0.67560

Collected Steps per Second: 22,842.05294
Overall Steps per Second: 10,684.92063

Timestep Collection Time: 2.19000
Timestep Consumption Time: 2.49174
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.68174

Cumulative Model Updates: 70,328
Cumulative Timesteps: 586,488,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 586488932...
Checkpoint 586488932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,689.72371
Policy Entropy: 3.70629
Value Function Loss: 0.06391

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.50896
Value Function Update Magnitude: 0.66997

Collected Steps per Second: 22,708.23042
Overall Steps per Second: 10,712.05693

Timestep Collection Time: 2.20299
Timestep Consumption Time: 2.46708
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.67006

Cumulative Model Updates: 70,334
Cumulative Timesteps: 586,538,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,230.33633
Policy Entropy: 3.69511
Value Function Loss: 0.06402

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.53977
Value Function Update Magnitude: 0.74895

Collected Steps per Second: 22,872.23571
Overall Steps per Second: 10,688.57246

Timestep Collection Time: 2.18684
Timestep Consumption Time: 2.49273
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.67958

Cumulative Model Updates: 70,340
Cumulative Timesteps: 586,588,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 586588976...
Checkpoint 586588976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,031.89117
Policy Entropy: 3.67950
Value Function Loss: 0.06551

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.62356
Value Function Update Magnitude: 0.80792

Collected Steps per Second: 22,638.87492
Overall Steps per Second: 10,688.33479

Timestep Collection Time: 2.20956
Timestep Consumption Time: 2.47049
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.68006

Cumulative Model Updates: 70,346
Cumulative Timesteps: 586,638,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,159.14904
Policy Entropy: 3.67746
Value Function Loss: 0.06611

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.55383
Value Function Update Magnitude: 0.80761

Collected Steps per Second: 22,997.60632
Overall Steps per Second: 10,842.33081

Timestep Collection Time: 2.17518
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61377

Cumulative Model Updates: 70,352
Cumulative Timesteps: 586,689,022

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 586689022...
Checkpoint 586689022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,686.36214
Policy Entropy: 3.67914
Value Function Loss: 0.06501

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.48411
Value Function Update Magnitude: 0.80517

Collected Steps per Second: 22,544.41004
Overall Steps per Second: 10,643.56260

Timestep Collection Time: 2.21793
Timestep Consumption Time: 2.47993
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.69786

Cumulative Model Updates: 70,358
Cumulative Timesteps: 586,739,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,168.25279
Policy Entropy: 3.69485
Value Function Loss: 0.06724

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.48566
Value Function Update Magnitude: 0.80324

Collected Steps per Second: 23,029.75194
Overall Steps per Second: 10,872.54557

Timestep Collection Time: 2.17310
Timestep Consumption Time: 2.42987
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60297

Cumulative Model Updates: 70,364
Cumulative Timesteps: 586,789,070

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 586789070...
Checkpoint 586789070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,143.27001
Policy Entropy: 3.67905
Value Function Loss: 0.06889

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.79460

Collected Steps per Second: 22,723.58752
Overall Steps per Second: 10,707.18507

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.47089
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.67256

Cumulative Model Updates: 70,370
Cumulative Timesteps: 586,839,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,878.18683
Policy Entropy: 3.68752
Value Function Loss: 0.06847

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.54705
Value Function Update Magnitude: 0.80090

Collected Steps per Second: 22,745.43596
Overall Steps per Second: 10,803.28399

Timestep Collection Time: 2.19912
Timestep Consumption Time: 2.43095
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.63007

Cumulative Model Updates: 70,376
Cumulative Timesteps: 586,889,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 586889120...
Checkpoint 586889120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.47150
Policy Entropy: 3.67784
Value Function Loss: 0.06723

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.73753

Collected Steps per Second: 22,745.03299
Overall Steps per Second: 10,722.77153

Timestep Collection Time: 2.20039
Timestep Consumption Time: 2.46706
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.66745

Cumulative Model Updates: 70,382
Cumulative Timesteps: 586,939,168

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,689.68690
Policy Entropy: 3.66995
Value Function Loss: 0.06745

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07738
Policy Update Magnitude: 0.69067
Value Function Update Magnitude: 0.69153

Collected Steps per Second: 22,992.71586
Overall Steps per Second: 10,840.25124

Timestep Collection Time: 2.17538
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.61410

Cumulative Model Updates: 70,388
Cumulative Timesteps: 586,989,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 586989186...
Checkpoint 586989186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,630.61062
Policy Entropy: 3.66734
Value Function Loss: 0.07089

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.65876
Value Function Update Magnitude: 0.67888

Collected Steps per Second: 22,782.70024
Overall Steps per Second: 10,734.82784

Timestep Collection Time: 2.19509
Timestep Consumption Time: 2.46358
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.65867

Cumulative Model Updates: 70,394
Cumulative Timesteps: 587,039,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,402.58088
Policy Entropy: 3.67110
Value Function Loss: 0.07488

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.55139
Value Function Update Magnitude: 0.61548

Collected Steps per Second: 22,521.67691
Overall Steps per Second: 10,631.45685

Timestep Collection Time: 2.22133
Timestep Consumption Time: 2.48433
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.70566

Cumulative Model Updates: 70,400
Cumulative Timesteps: 587,089,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 587089224...
Checkpoint 587089224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,136.09240
Policy Entropy: 3.66724
Value Function Loss: 0.07466

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.50547
Value Function Update Magnitude: 0.62378

Collected Steps per Second: 22,492.00494
Overall Steps per Second: 10,634.05879

Timestep Collection Time: 2.22328
Timestep Consumption Time: 2.47916
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.70244

Cumulative Model Updates: 70,406
Cumulative Timesteps: 587,139,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,753.87687
Policy Entropy: 3.67700
Value Function Loss: 0.07288

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.56279
Value Function Update Magnitude: 0.65595

Collected Steps per Second: 22,824.25692
Overall Steps per Second: 10,732.46394

Timestep Collection Time: 2.19091
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.65932

Cumulative Model Updates: 70,412
Cumulative Timesteps: 587,189,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 587189236...
Checkpoint 587189236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,481.33993
Policy Entropy: 3.68456
Value Function Loss: 0.06964

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.64026
Value Function Update Magnitude: 0.74882

Collected Steps per Second: 22,715.99848
Overall Steps per Second: 10,622.72938

Timestep Collection Time: 2.20232
Timestep Consumption Time: 2.50720
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.70952

Cumulative Model Updates: 70,418
Cumulative Timesteps: 587,239,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,655.58478
Policy Entropy: 3.68900
Value Function Loss: 0.06776

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.62236
Value Function Update Magnitude: 0.79871

Collected Steps per Second: 22,935.29691
Overall Steps per Second: 10,840.32580

Timestep Collection Time: 2.18005
Timestep Consumption Time: 2.43236
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.61241

Cumulative Model Updates: 70,424
Cumulative Timesteps: 587,289,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 587289264...
Checkpoint 587289264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,174.18567
Policy Entropy: 3.69187
Value Function Loss: 0.06683

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.65572
Value Function Update Magnitude: 0.78011

Collected Steps per Second: 22,705.63961
Overall Steps per Second: 10,696.48353

Timestep Collection Time: 2.20254
Timestep Consumption Time: 2.47283
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.67537

Cumulative Model Updates: 70,430
Cumulative Timesteps: 587,339,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,790.92880
Policy Entropy: 3.68791
Value Function Loss: 0.07012

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.63147
Value Function Update Magnitude: 0.68545

Collected Steps per Second: 22,802.93448
Overall Steps per Second: 10,814.05763

Timestep Collection Time: 2.19331
Timestep Consumption Time: 2.43159
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.62491

Cumulative Model Updates: 70,436
Cumulative Timesteps: 587,389,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 587389288...
Checkpoint 587389288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,572.09190
Policy Entropy: 3.69327
Value Function Loss: 0.06911

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.63363
Value Function Update Magnitude: 0.66745

Collected Steps per Second: 22,671.02629
Overall Steps per Second: 10,743.44400

Timestep Collection Time: 2.20563
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.65437

Cumulative Model Updates: 70,442
Cumulative Timesteps: 587,439,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,294.69633
Policy Entropy: 3.71009
Value Function Loss: 0.06660

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06662
Policy Update Magnitude: 0.70956
Value Function Update Magnitude: 0.75057

Collected Steps per Second: 22,721.20161
Overall Steps per Second: 10,830.47264

Timestep Collection Time: 2.20156
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61863

Cumulative Model Updates: 70,448
Cumulative Timesteps: 587,489,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 587489314...
Checkpoint 587489314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,157.41740
Policy Entropy: 3.71147
Value Function Loss: 0.06337

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.67010
Value Function Update Magnitude: 0.81033

Collected Steps per Second: 22,678.84468
Overall Steps per Second: 10,677.32156

Timestep Collection Time: 2.20576
Timestep Consumption Time: 2.47931
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.68507

Cumulative Model Updates: 70,454
Cumulative Timesteps: 587,539,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,923.62126
Policy Entropy: 3.70353
Value Function Loss: 0.06635

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.60727
Value Function Update Magnitude: 0.82130

Collected Steps per Second: 23,126.19007
Overall Steps per Second: 10,886.22659

Timestep Collection Time: 2.16300
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.59498

Cumulative Model Updates: 70,460
Cumulative Timesteps: 587,589,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 587589360...
Checkpoint 587589360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,405.98292
Policy Entropy: 3.67826
Value Function Loss: 0.07054

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.59293
Value Function Update Magnitude: 0.78062

Collected Steps per Second: 22,576.62758
Overall Steps per Second: 10,713.82692

Timestep Collection Time: 2.21574
Timestep Consumption Time: 2.45336
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.66911

Cumulative Model Updates: 70,466
Cumulative Timesteps: 587,639,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,573.04861
Policy Entropy: 3.67325
Value Function Loss: 0.07294

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.52577
Value Function Update Magnitude: 0.77831

Collected Steps per Second: 22,785.06520
Overall Steps per Second: 10,807.60699

Timestep Collection Time: 2.19547
Timestep Consumption Time: 2.43312
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.62859

Cumulative Model Updates: 70,472
Cumulative Timesteps: 587,689,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 587689408...
Checkpoint 587689408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,425.23649
Policy Entropy: 3.67128
Value Function Loss: 0.07462

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.50020
Value Function Update Magnitude: 0.74553

Collected Steps per Second: 22,702.89492
Overall Steps per Second: 10,713.33081

Timestep Collection Time: 2.20245
Timestep Consumption Time: 2.46482
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.66727

Cumulative Model Updates: 70,478
Cumulative Timesteps: 587,739,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,647.47248
Policy Entropy: 3.67620
Value Function Loss: 0.07325

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.51647
Value Function Update Magnitude: 0.70453

Collected Steps per Second: 22,883.55170
Overall Steps per Second: 10,850.72001

Timestep Collection Time: 2.18567
Timestep Consumption Time: 2.42379
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60946

Cumulative Model Updates: 70,484
Cumulative Timesteps: 587,789,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 587789426...
Checkpoint 587789426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,699.89078
Policy Entropy: 3.68007
Value Function Loss: 0.07056

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.59916
Value Function Update Magnitude: 0.72405

Collected Steps per Second: 22,728.85084
Overall Steps per Second: 10,707.52218

Timestep Collection Time: 2.20055
Timestep Consumption Time: 2.47056
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.67111

Cumulative Model Updates: 70,490
Cumulative Timesteps: 587,839,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,653.63947
Policy Entropy: 3.66773
Value Function Loss: 0.07069

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.65828
Value Function Update Magnitude: 0.67636

Collected Steps per Second: 23,134.96012
Overall Steps per Second: 10,858.49369

Timestep Collection Time: 2.16158
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.60543

Cumulative Model Updates: 70,496
Cumulative Timesteps: 587,889,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 587889450...
Checkpoint 587889450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,906.52553
Policy Entropy: 3.66664
Value Function Loss: 0.06562

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.61354
Value Function Update Magnitude: 0.76191

Collected Steps per Second: 22,583.68313
Overall Steps per Second: 10,694.02198

Timestep Collection Time: 2.21540
Timestep Consumption Time: 2.46310
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.67850

Cumulative Model Updates: 70,502
Cumulative Timesteps: 587,939,482

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,428.71351
Policy Entropy: 3.66378
Value Function Loss: 0.06731

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.69895
Value Function Update Magnitude: 0.82809

Collected Steps per Second: 22,783.97652
Overall Steps per Second: 10,820.77881

Timestep Collection Time: 2.19514
Timestep Consumption Time: 2.42689
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.62203

Cumulative Model Updates: 70,508
Cumulative Timesteps: 587,989,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 587989496...
Checkpoint 587989496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,073.95519
Policy Entropy: 3.66906
Value Function Loss: 0.06620

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.73932
Value Function Update Magnitude: 0.80001

Collected Steps per Second: 22,452.83081
Overall Steps per Second: 10,701.37550

Timestep Collection Time: 2.22760
Timestep Consumption Time: 2.44619
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.67379

Cumulative Model Updates: 70,514
Cumulative Timesteps: 588,039,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,852.34834
Policy Entropy: 3.66842
Value Function Loss: 0.07170

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.72075
Value Function Update Magnitude: 0.73858

Collected Steps per Second: 22,849.93357
Overall Steps per Second: 10,816.07156

Timestep Collection Time: 2.18924
Timestep Consumption Time: 2.43573
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.62497

Cumulative Model Updates: 70,520
Cumulative Timesteps: 588,089,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 588089536...
Checkpoint 588089536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,353.46951
Policy Entropy: 3.67110
Value Function Loss: 0.07264

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.73561
Value Function Update Magnitude: 0.61945

Collected Steps per Second: 22,537.41401
Overall Steps per Second: 10,790.90341

Timestep Collection Time: 2.21951
Timestep Consumption Time: 2.41606
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.63557

Cumulative Model Updates: 70,526
Cumulative Timesteps: 588,139,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,906.72727
Policy Entropy: 3.67679
Value Function Loss: 0.06996

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.71259
Value Function Update Magnitude: 0.53106

Collected Steps per Second: 22,933.81474
Overall Steps per Second: 10,825.59904

Timestep Collection Time: 2.18027
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.61887

Cumulative Model Updates: 70,532
Cumulative Timesteps: 588,189,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 588189560...
Checkpoint 588189560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,419.50873
Policy Entropy: 3.67241
Value Function Loss: 0.06783

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.64449
Value Function Update Magnitude: 0.61438

Collected Steps per Second: 22,733.16277
Overall Steps per Second: 10,649.11904

Timestep Collection Time: 2.19978
Timestep Consumption Time: 2.49619
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.69598

Cumulative Model Updates: 70,538
Cumulative Timesteps: 588,239,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,284.60643
Policy Entropy: 3.67177
Value Function Loss: 0.06636

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12063
Policy Update Magnitude: 0.56607
Value Function Update Magnitude: 0.74972

Collected Steps per Second: 22,618.27797
Overall Steps per Second: 10,659.05030

Timestep Collection Time: 2.21157
Timestep Consumption Time: 2.48134
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.69291

Cumulative Model Updates: 70,544
Cumulative Timesteps: 588,289,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 588289590...
Checkpoint 588289590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,410.57894
Policy Entropy: 3.67252
Value Function Loss: 0.06680

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.18118
Policy Update Magnitude: 0.49970
Value Function Update Magnitude: 0.82364

Collected Steps per Second: 22,835.48346
Overall Steps per Second: 10,849.35734

Timestep Collection Time: 2.19080
Timestep Consumption Time: 2.42035
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61115

Cumulative Model Updates: 70,550
Cumulative Timesteps: 588,339,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.77871
Policy Entropy: 3.68775
Value Function Loss: 0.06432

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.46782
Value Function Update Magnitude: 0.87318

Collected Steps per Second: 22,968.55721
Overall Steps per Second: 10,865.27781

Timestep Collection Time: 2.17767
Timestep Consumption Time: 2.42580
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.60347

Cumulative Model Updates: 70,556
Cumulative Timesteps: 588,389,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 588389636...
Checkpoint 588389636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,683.11925
Policy Entropy: 3.69427
Value Function Loss: 0.06497

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.59754
Value Function Update Magnitude: 0.88468

Collected Steps per Second: 22,475.68628
Overall Steps per Second: 10,798.54985

Timestep Collection Time: 2.22507
Timestep Consumption Time: 2.40611
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.63118

Cumulative Model Updates: 70,562
Cumulative Timesteps: 588,439,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983.37189
Policy Entropy: 3.70921
Value Function Loss: 0.06370

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.71942
Value Function Update Magnitude: 0.85321

Collected Steps per Second: 23,150.20784
Overall Steps per Second: 10,848.98763

Timestep Collection Time: 2.16007
Timestep Consumption Time: 2.44921
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.60928

Cumulative Model Updates: 70,568
Cumulative Timesteps: 588,489,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 588489652...
Checkpoint 588489652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,759.74541
Policy Entropy: 3.70689
Value Function Loss: 0.06363

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.72028
Value Function Update Magnitude: 0.83562

Collected Steps per Second: 22,508.66008
Overall Steps per Second: 10,609.00543

Timestep Collection Time: 2.22261
Timestep Consumption Time: 2.49301
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.71562

Cumulative Model Updates: 70,574
Cumulative Timesteps: 588,539,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,821.37849
Policy Entropy: 3.70655
Value Function Loss: 0.06086

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.62132
Value Function Update Magnitude: 0.84531

Collected Steps per Second: 22,942.80417
Overall Steps per Second: 10,860.01554

Timestep Collection Time: 2.17951
Timestep Consumption Time: 2.42491
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.60441

Cumulative Model Updates: 70,580
Cumulative Timesteps: 588,589,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 588589684...
Checkpoint 588589684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,276.97368
Policy Entropy: 3.71150
Value Function Loss: 0.06025

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.55641
Value Function Update Magnitude: 0.85856

Collected Steps per Second: 22,851.78138
Overall Steps per Second: 10,722.46405

Timestep Collection Time: 2.18959
Timestep Consumption Time: 2.47688
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.66646

Cumulative Model Updates: 70,586
Cumulative Timesteps: 588,639,720

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,330.36892
Policy Entropy: 3.69655
Value Function Loss: 0.06177

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.60589
Value Function Update Magnitude: 0.86991

Collected Steps per Second: 22,682.70666
Overall Steps per Second: 10,791.49115

Timestep Collection Time: 2.20520
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.63513

Cumulative Model Updates: 70,592
Cumulative Timesteps: 588,689,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 588689740...
Checkpoint 588689740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,087.86171
Policy Entropy: 3.69311
Value Function Loss: 0.06527

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.57432
Value Function Update Magnitude: 0.88126

Collected Steps per Second: 22,305.81627
Overall Steps per Second: 10,712.82561

Timestep Collection Time: 2.24282
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.66992

Cumulative Model Updates: 70,598
Cumulative Timesteps: 588,739,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,922.22933
Policy Entropy: 3.68793
Value Function Loss: 0.06825

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.52520
Value Function Update Magnitude: 0.78638

Collected Steps per Second: 23,030.82912
Overall Steps per Second: 10,902.19166

Timestep Collection Time: 2.17222
Timestep Consumption Time: 2.41658
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.58880

Cumulative Model Updates: 70,604
Cumulative Timesteps: 588,789,796

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 588789796...
Checkpoint 588789796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,539.49402
Policy Entropy: 3.69312
Value Function Loss: 0.06793

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.49090
Value Function Update Magnitude: 0.69558

Collected Steps per Second: 22,701.25821
Overall Steps per Second: 10,664.47808

Timestep Collection Time: 2.20349
Timestep Consumption Time: 2.48703
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.69052

Cumulative Model Updates: 70,610
Cumulative Timesteps: 588,839,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,011.39164
Policy Entropy: 3.70484
Value Function Loss: 0.06480

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.50986
Value Function Update Magnitude: 0.68006

Collected Steps per Second: 22,639.02714
Overall Steps per Second: 10,668.41820

Timestep Collection Time: 2.20946
Timestep Consumption Time: 2.47915
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.68861

Cumulative Model Updates: 70,616
Cumulative Timesteps: 588,889,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 588889838...
Checkpoint 588889838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,866.75115
Policy Entropy: 3.68985
Value Function Loss: 0.06267

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.64203

Collected Steps per Second: 22,474.28847
Overall Steps per Second: 10,760.60278

Timestep Collection Time: 2.22512
Timestep Consumption Time: 2.42220
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.64732

Cumulative Model Updates: 70,622
Cumulative Timesteps: 588,939,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,839.17771
Policy Entropy: 3.68809
Value Function Loss: 0.06313

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.58430
Value Function Update Magnitude: 0.60688

Collected Steps per Second: 22,063.83383
Overall Steps per Second: 10,682.76479

Timestep Collection Time: 2.26724
Timestep Consumption Time: 2.41544
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.68268

Cumulative Model Updates: 70,628
Cumulative Timesteps: 588,989,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 588989870...
Checkpoint 588989870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,616.88796
Policy Entropy: 3.69321
Value Function Loss: 0.06627

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.59169
Value Function Update Magnitude: 0.62110

Collected Steps per Second: 22,389.70946
Overall Steps per Second: 10,920.58963

Timestep Collection Time: 2.23326
Timestep Consumption Time: 2.34543
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.57869

Cumulative Model Updates: 70,634
Cumulative Timesteps: 589,039,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,232.01871
Policy Entropy: 3.71295
Value Function Loss: 0.06672

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.53406
Value Function Update Magnitude: 0.65613

Collected Steps per Second: 22,438.74345
Overall Steps per Second: 10,916.57843

Timestep Collection Time: 2.22838
Timestep Consumption Time: 2.35200
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.58037

Cumulative Model Updates: 70,640
Cumulative Timesteps: 589,089,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 589089874...
Checkpoint 589089874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,603.94853
Policy Entropy: 3.71041
Value Function Loss: 0.06767

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.71151

Collected Steps per Second: 21,966.17183
Overall Steps per Second: 10,671.55771

Timestep Collection Time: 2.27623
Timestep Consumption Time: 2.40912
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.68535

Cumulative Model Updates: 70,646
Cumulative Timesteps: 589,139,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,164.89091
Policy Entropy: 3.70048
Value Function Loss: 0.06762

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.75972

Collected Steps per Second: 22,358.58837
Overall Steps per Second: 10,872.42766

Timestep Collection Time: 2.23726
Timestep Consumption Time: 2.36355
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60081

Cumulative Model Updates: 70,652
Cumulative Timesteps: 589,189,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 589189896...
Checkpoint 589189896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,619.30287
Policy Entropy: 3.68906
Value Function Loss: 0.06727

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.53569
Value Function Update Magnitude: 0.77139

Collected Steps per Second: 21,966.55416
Overall Steps per Second: 10,698.80594

Timestep Collection Time: 2.27737
Timestep Consumption Time: 2.39848
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67585

Cumulative Model Updates: 70,658
Cumulative Timesteps: 589,239,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,862.53650
Policy Entropy: 3.67369
Value Function Loss: 0.06902

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.49517
Value Function Update Magnitude: 0.72540

Collected Steps per Second: 22,199.44757
Overall Steps per Second: 10,611.20012

Timestep Collection Time: 2.25348
Timestep Consumption Time: 2.46097
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.71445

Cumulative Model Updates: 70,664
Cumulative Timesteps: 589,289,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 589289948...
Checkpoint 589289948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,529.46646
Policy Entropy: 3.68143
Value Function Loss: 0.06956

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.46798
Value Function Update Magnitude: 0.70995

Collected Steps per Second: 22,563.90275
Overall Steps per Second: 10,843.79914

Timestep Collection Time: 2.21637
Timestep Consumption Time: 2.39548
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.61185

Cumulative Model Updates: 70,670
Cumulative Timesteps: 589,339,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,833.84452
Policy Entropy: 3.68837
Value Function Loss: 0.07204

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.47986
Value Function Update Magnitude: 0.76207

Collected Steps per Second: 23,032.55602
Overall Steps per Second: 10,938.79076

Timestep Collection Time: 2.17145
Timestep Consumption Time: 2.40072
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.57217

Cumulative Model Updates: 70,676
Cumulative Timesteps: 589,389,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 589389972...
Checkpoint 589389972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,348.75787
Policy Entropy: 3.68976
Value Function Loss: 0.07232

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.56105
Value Function Update Magnitude: 0.78972

Collected Steps per Second: 22,476.11508
Overall Steps per Second: 10,687.32535

Timestep Collection Time: 2.22476
Timestep Consumption Time: 2.45405
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.67881

Cumulative Model Updates: 70,682
Cumulative Timesteps: 589,439,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,006.02106
Policy Entropy: 3.68315
Value Function Loss: 0.07100

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.63490
Value Function Update Magnitude: 0.71119

Collected Steps per Second: 22,907.48067
Overall Steps per Second: 10,821.34390

Timestep Collection Time: 2.18269
Timestep Consumption Time: 2.43781
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.62050

Cumulative Model Updates: 70,688
Cumulative Timesteps: 589,489,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 589489976...
Checkpoint 589489976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,328.17942
Policy Entropy: 3.68149
Value Function Loss: 0.06689

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.56413
Value Function Update Magnitude: 0.67260

Collected Steps per Second: 22,352.81051
Overall Steps per Second: 10,705.58023

Timestep Collection Time: 2.23748
Timestep Consumption Time: 2.43429
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.67177

Cumulative Model Updates: 70,694
Cumulative Timesteps: 589,539,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,025.94327
Policy Entropy: 3.69019
Value Function Loss: 0.06292

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.54088
Value Function Update Magnitude: 0.69648

Collected Steps per Second: 23,310.51985
Overall Steps per Second: 10,947.25880

Timestep Collection Time: 2.14538
Timestep Consumption Time: 2.42288
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.56827

Cumulative Model Updates: 70,700
Cumulative Timesteps: 589,590,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 589590000...
Checkpoint 589590000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,794.93633
Policy Entropy: 3.68956
Value Function Loss: 0.06245

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.54698
Value Function Update Magnitude: 0.71385

Collected Steps per Second: 22,704.65541
Overall Steps per Second: 10,639.88823

Timestep Collection Time: 2.20246
Timestep Consumption Time: 2.49741
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.69986

Cumulative Model Updates: 70,706
Cumulative Timesteps: 589,640,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,651.03027
Policy Entropy: 3.68449
Value Function Loss: 0.06352

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.56523
Value Function Update Magnitude: 0.72494

Collected Steps per Second: 22,723.41898
Overall Steps per Second: 10,777.64015

Timestep Collection Time: 2.20152
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.64165

Cumulative Model Updates: 70,712
Cumulative Timesteps: 589,690,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 589690032...
Checkpoint 589690032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,236.17640
Policy Entropy: 3.67145
Value Function Loss: 0.06875

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11720
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.73088

Collected Steps per Second: 22,526.13511
Overall Steps per Second: 10,764.71192

Timestep Collection Time: 2.22009
Timestep Consumption Time: 2.42565
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.64574

Cumulative Model Updates: 70,718
Cumulative Timesteps: 589,740,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,344.86793
Policy Entropy: 3.65470
Value Function Loss: 0.07288

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.51838
Value Function Update Magnitude: 0.67917

Collected Steps per Second: 23,002.48274
Overall Steps per Second: 10,857.46860

Timestep Collection Time: 2.17385
Timestep Consumption Time: 2.43164
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60549

Cumulative Model Updates: 70,724
Cumulative Timesteps: 589,790,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 589790046...
Checkpoint 589790046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,752.67235
Policy Entropy: 3.64346
Value Function Loss: 0.07602

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.52447
Value Function Update Magnitude: 0.68126

Collected Steps per Second: 22,584.28357
Overall Steps per Second: 10,670.51225

Timestep Collection Time: 2.21597
Timestep Consumption Time: 2.47416
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.69012

Cumulative Model Updates: 70,730
Cumulative Timesteps: 589,840,092

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,659.52977
Policy Entropy: 3.63808
Value Function Loss: 0.07401

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.51151
Value Function Update Magnitude: 0.70213

Collected Steps per Second: 22,953.31559
Overall Steps per Second: 10,837.77007

Timestep Collection Time: 2.17903
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61497

Cumulative Model Updates: 70,736
Cumulative Timesteps: 589,890,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 589890108...
Checkpoint 589890108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,388.29742
Policy Entropy: 3.63434
Value Function Loss: 0.07638

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.57202
Value Function Update Magnitude: 0.65754

Collected Steps per Second: 22,822.07290
Overall Steps per Second: 10,707.44368

Timestep Collection Time: 2.19121
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.67040

Cumulative Model Updates: 70,742
Cumulative Timesteps: 589,940,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,906.40043
Policy Entropy: 3.64154
Value Function Loss: 0.07456

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.57287
Value Function Update Magnitude: 0.59355

Collected Steps per Second: 22,673.99502
Overall Steps per Second: 10,643.15795

Timestep Collection Time: 2.20517
Timestep Consumption Time: 2.49268
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.69785

Cumulative Model Updates: 70,748
Cumulative Timesteps: 589,990,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 589990116...
Checkpoint 589990116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,384.68961
Policy Entropy: 3.65139
Value Function Loss: 0.07505

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.60894
Value Function Update Magnitude: 0.64649

Collected Steps per Second: 22,472.57127
Overall Steps per Second: 10,635.42057

Timestep Collection Time: 2.22627
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.70409

Cumulative Model Updates: 70,754
Cumulative Timesteps: 590,040,146

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,058.41842
Policy Entropy: 3.66405
Value Function Loss: 0.07143

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.58801
Value Function Update Magnitude: 0.72437

Collected Steps per Second: 22,947.43811
Overall Steps per Second: 10,715.78908

Timestep Collection Time: 2.17942
Timestep Consumption Time: 2.48772
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.66713

Cumulative Model Updates: 70,760
Cumulative Timesteps: 590,090,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 590090158...
Checkpoint 590090158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,070.38229
Policy Entropy: 3.66155
Value Function Loss: 0.06992

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.54957
Value Function Update Magnitude: 0.73752

Collected Steps per Second: 22,577.34594
Overall Steps per Second: 10,624.51567

Timestep Collection Time: 2.21567
Timestep Consumption Time: 2.49268
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.70836

Cumulative Model Updates: 70,766
Cumulative Timesteps: 590,140,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,167.67107
Policy Entropy: 3.66471
Value Function Loss: 0.06825

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.70122

Collected Steps per Second: 22,709.27219
Overall Steps per Second: 10,642.92709

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.70002

Cumulative Model Updates: 70,772
Cumulative Timesteps: 590,190,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 590190204...
Checkpoint 590190204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,832.62588
Policy Entropy: 3.66215
Value Function Loss: 0.06900

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.46706
Value Function Update Magnitude: 0.70573

Collected Steps per Second: 22,725.30984
Overall Steps per Second: 10,687.56010

Timestep Collection Time: 2.20107
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.68021

Cumulative Model Updates: 70,778
Cumulative Timesteps: 590,240,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.82206
Policy Entropy: 3.65704
Value Function Loss: 0.07183

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.41359
Value Function Update Magnitude: 0.63909

Collected Steps per Second: 22,739.64151
Overall Steps per Second: 10,705.37224

Timestep Collection Time: 2.20074
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.67466

Cumulative Model Updates: 70,784
Cumulative Timesteps: 590,290,268

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 590290268...
Checkpoint 590290268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,116.45421
Policy Entropy: 3.65007
Value Function Loss: 0.07321

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.48479
Value Function Update Magnitude: 0.63221

Collected Steps per Second: 22,547.38569
Overall Steps per Second: 10,635.65329

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.70211

Cumulative Model Updates: 70,790
Cumulative Timesteps: 590,340,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,761.35554
Policy Entropy: 3.65739
Value Function Loss: 0.06935

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.50920
Value Function Update Magnitude: 0.62763

Collected Steps per Second: 22,936.32033
Overall Steps per Second: 10,848.32463

Timestep Collection Time: 2.18108
Timestep Consumption Time: 2.43032
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.61140

Cumulative Model Updates: 70,796
Cumulative Timesteps: 590,390,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 590390304...
Checkpoint 590390304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.85456
Policy Entropy: 3.68011
Value Function Loss: 0.06823

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11272
Policy Update Magnitude: 0.49730
Value Function Update Magnitude: 0.69066

Collected Steps per Second: 22,531.29041
Overall Steps per Second: 10,707.25640

Timestep Collection Time: 2.21940
Timestep Consumption Time: 2.45089
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.67029

Cumulative Model Updates: 70,802
Cumulative Timesteps: 590,440,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,250.56311
Policy Entropy: 3.66909
Value Function Loss: 0.06498

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06569
Policy Update Magnitude: 0.60994
Value Function Update Magnitude: 0.77469

Collected Steps per Second: 22,772.01031
Overall Steps per Second: 10,822.87102

Timestep Collection Time: 2.19629
Timestep Consumption Time: 2.42485
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.62114

Cumulative Model Updates: 70,808
Cumulative Timesteps: 590,490,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 590490324...
Checkpoint 590490324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,116.80995
Policy Entropy: 3.68099
Value Function Loss: 0.06179

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.64861
Value Function Update Magnitude: 0.76644

Collected Steps per Second: 22,377.63990
Overall Steps per Second: 10,757.99340

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.41353
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.64808

Cumulative Model Updates: 70,814
Cumulative Timesteps: 590,540,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,292.65798
Policy Entropy: 3.66690
Value Function Loss: 0.06296

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09689
Policy Update Magnitude: 0.53215
Value Function Update Magnitude: 0.78009

Collected Steps per Second: 22,589.67218
Overall Steps per Second: 10,763.98725

Timestep Collection Time: 2.21446
Timestep Consumption Time: 2.43289
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.64735

Cumulative Model Updates: 70,820
Cumulative Timesteps: 590,590,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 590590352...
Checkpoint 590590352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,503.32876
Policy Entropy: 3.67818
Value Function Loss: 0.06396

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.54369
Value Function Update Magnitude: 0.75127

Collected Steps per Second: 22,534.67213
Overall Steps per Second: 10,800.44057

Timestep Collection Time: 2.21951
Timestep Consumption Time: 2.41141
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.63092

Cumulative Model Updates: 70,826
Cumulative Timesteps: 590,640,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,250.04430
Policy Entropy: 3.66428
Value Function Loss: 0.06637

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.50702
Value Function Update Magnitude: 0.67617

Collected Steps per Second: 23,033.52660
Overall Steps per Second: 10,871.85499

Timestep Collection Time: 2.17136
Timestep Consumption Time: 2.42896
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.60032

Cumulative Model Updates: 70,832
Cumulative Timesteps: 590,690,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 590690382...
Checkpoint 590690382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,124.67840
Policy Entropy: 3.67837
Value Function Loss: 0.06546

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.50967
Value Function Update Magnitude: 0.62417

Collected Steps per Second: 22,650.87630
Overall Steps per Second: 10,593.62313

Timestep Collection Time: 2.20786
Timestep Consumption Time: 2.51290
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.72076

Cumulative Model Updates: 70,838
Cumulative Timesteps: 590,740,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.62522
Policy Entropy: 3.67844
Value Function Loss: 0.06221

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.54899
Value Function Update Magnitude: 0.71725

Collected Steps per Second: 23,011.28513
Overall Steps per Second: 10,890.65086

Timestep Collection Time: 2.17398
Timestep Consumption Time: 2.41950
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.59348

Cumulative Model Updates: 70,844
Cumulative Timesteps: 590,790,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 590790418...
Checkpoint 590790418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,670.21656
Policy Entropy: 3.68179
Value Function Loss: 0.06264

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.16299
Policy Update Magnitude: 0.51078
Value Function Update Magnitude: 0.71332

Collected Steps per Second: 22,614.59928
Overall Steps per Second: 10,672.85505

Timestep Collection Time: 2.21273
Timestep Consumption Time: 2.47580
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.68853

Cumulative Model Updates: 70,850
Cumulative Timesteps: 590,840,458

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,690.14224
Policy Entropy: 3.69101
Value Function Loss: 0.06498

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.15934
Policy Update Magnitude: 0.45583
Value Function Update Magnitude: 0.62355

Collected Steps per Second: 22,778.07124
Overall Steps per Second: 10,831.71061

Timestep Collection Time: 2.19580
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.61755

Cumulative Model Updates: 70,856
Cumulative Timesteps: 590,890,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 590890474...
Checkpoint 590890474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,394.62353
Policy Entropy: 3.69957
Value Function Loss: 0.07103

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.52656
Value Function Update Magnitude: 0.50435

Collected Steps per Second: 22,533.56335
Overall Steps per Second: 10,710.12805

Timestep Collection Time: 2.21944
Timestep Consumption Time: 2.45015
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.66960

Cumulative Model Updates: 70,862
Cumulative Timesteps: 590,940,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.77419
Policy Entropy: 3.71020
Value Function Loss: 0.06817

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.60475
Value Function Update Magnitude: 0.41810

Collected Steps per Second: 22,894.81101
Overall Steps per Second: 10,850.30862

Timestep Collection Time: 2.18504
Timestep Consumption Time: 2.42552
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61056

Cumulative Model Updates: 70,868
Cumulative Timesteps: 590,990,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 590990512...
Checkpoint 590990512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,206.86093
Policy Entropy: 3.72504
Value Function Loss: 0.06558

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.54063
Value Function Update Magnitude: 0.42740

Collected Steps per Second: 21,707.27176
Overall Steps per Second: 10,771.73170

Timestep Collection Time: 2.30365
Timestep Consumption Time: 2.33868
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.64234

Cumulative Model Updates: 70,874
Cumulative Timesteps: 591,040,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,211.17407
Policy Entropy: 3.72799
Value Function Loss: 0.06411

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.56756
Value Function Update Magnitude: 0.44179

Collected Steps per Second: 22,062.07464
Overall Steps per Second: 10,805.87395

Timestep Collection Time: 2.26642
Timestep Consumption Time: 2.36087
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.62730

Cumulative Model Updates: 70,880
Cumulative Timesteps: 591,090,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 591090520...
Checkpoint 591090520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,658.24495
Policy Entropy: 3.72612
Value Function Loss: 0.06496

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.64206
Value Function Update Magnitude: 0.45374

Collected Steps per Second: 21,880.68346
Overall Steps per Second: 10,687.57570

Timestep Collection Time: 2.28558
Timestep Consumption Time: 2.39369
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.67927

Cumulative Model Updates: 70,886
Cumulative Timesteps: 591,140,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,825.90353
Policy Entropy: 3.72191
Value Function Loss: 0.06789

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.60695
Value Function Update Magnitude: 0.46311

Collected Steps per Second: 22,429.93572
Overall Steps per Second: 10,906.37969

Timestep Collection Time: 2.22961
Timestep Consumption Time: 2.35578
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.58539

Cumulative Model Updates: 70,892
Cumulative Timesteps: 591,190,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 591190540...
Checkpoint 591190540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,123.01385
Policy Entropy: 3.73101
Value Function Loss: 0.06828

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.48592
Value Function Update Magnitude: 0.46576

Collected Steps per Second: 22,035.64561
Overall Steps per Second: 10,657.71443

Timestep Collection Time: 2.27032
Timestep Consumption Time: 2.42374
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.69406

Cumulative Model Updates: 70,898
Cumulative Timesteps: 591,240,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.75088
Policy Entropy: 3.73959
Value Function Loss: 0.06558

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.59667
Value Function Update Magnitude: 0.51304

Collected Steps per Second: 22,297.84692
Overall Steps per Second: 10,854.12923

Timestep Collection Time: 2.24354
Timestep Consumption Time: 2.36540
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.60894

Cumulative Model Updates: 70,904
Cumulative Timesteps: 591,290,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 591290594...
Checkpoint 591290594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,749.55818
Policy Entropy: 3.74550
Value Function Loss: 0.06122

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.70224
Value Function Update Magnitude: 0.54988

Collected Steps per Second: 22,047.14012
Overall Steps per Second: 10,690.87909

Timestep Collection Time: 2.26887
Timestep Consumption Time: 2.41008
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.67894

Cumulative Model Updates: 70,910
Cumulative Timesteps: 591,340,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.10599
Policy Entropy: 3.73026
Value Function Loss: 0.05913

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07540
Policy Update Magnitude: 0.73103
Value Function Update Magnitude: 0.53532

Collected Steps per Second: 22,252.13023
Overall Steps per Second: 10,865.14405

Timestep Collection Time: 2.24734
Timestep Consumption Time: 2.35527
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.60261

Cumulative Model Updates: 70,916
Cumulative Timesteps: 591,390,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 591390624...
Checkpoint 591390624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,826.90818
Policy Entropy: 3.73212
Value Function Loss: 0.05915

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.73769
Value Function Update Magnitude: 0.50086

Collected Steps per Second: 21,951.44483
Overall Steps per Second: 10,673.19935

Timestep Collection Time: 2.27867
Timestep Consumption Time: 2.40784
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.68650

Cumulative Model Updates: 70,922
Cumulative Timesteps: 591,440,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,732.63228
Policy Entropy: 3.73744
Value Function Loss: 0.05883

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.67319
Value Function Update Magnitude: 0.47796

Collected Steps per Second: 21,999.72803
Overall Steps per Second: 10,797.34714

Timestep Collection Time: 2.27303
Timestep Consumption Time: 2.35829
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.63132

Cumulative Model Updates: 70,928
Cumulative Timesteps: 591,490,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 591490650...
Checkpoint 591490650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,849.37465
Policy Entropy: 3.74936
Value Function Loss: 0.05857

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07276
Policy Update Magnitude: 0.63045
Value Function Update Magnitude: 0.47671

Collected Steps per Second: 21,829.57052
Overall Steps per Second: 10,730.37795

Timestep Collection Time: 2.29056
Timestep Consumption Time: 2.36929
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.65985

Cumulative Model Updates: 70,934
Cumulative Timesteps: 591,540,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,685.39997
Policy Entropy: 3.76104
Value Function Loss: 0.05742

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.60446
Value Function Update Magnitude: 0.47899

Collected Steps per Second: 22,215.01193
Overall Steps per Second: 10,883.44615

Timestep Collection Time: 2.25172
Timestep Consumption Time: 2.34443
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.59615

Cumulative Model Updates: 70,940
Cumulative Timesteps: 591,590,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 591590674...
Checkpoint 591590674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,676.84278
Policy Entropy: 3.75637
Value Function Loss: 0.05662

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06802
Policy Update Magnitude: 0.64231
Value Function Update Magnitude: 0.53828

Collected Steps per Second: 22,081.14188
Overall Steps per Second: 10,693.67693

Timestep Collection Time: 2.26528
Timestep Consumption Time: 2.41225
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.67753

Cumulative Model Updates: 70,946
Cumulative Timesteps: 591,640,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,833.21651
Policy Entropy: 3.76197
Value Function Loss: 0.05529

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.70070
Value Function Update Magnitude: 0.59023

Collected Steps per Second: 22,274.93605
Overall Steps per Second: 10,854.03795

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.36304
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.60879

Cumulative Model Updates: 70,952
Cumulative Timesteps: 591,690,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 591690718...
Checkpoint 591690718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,754.39039
Policy Entropy: 3.75720
Value Function Loss: 0.05551

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06139
Policy Update Magnitude: 0.72301
Value Function Update Magnitude: 0.64067

Collected Steps per Second: 22,003.29372
Overall Steps per Second: 10,691.89659

Timestep Collection Time: 2.27366
Timestep Consumption Time: 2.40540
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.67906

Cumulative Model Updates: 70,958
Cumulative Timesteps: 591,740,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,979.32036
Policy Entropy: 3.74675
Value Function Loss: 0.05603

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.66783
Value Function Update Magnitude: 0.61799

Collected Steps per Second: 22,930.28247
Overall Steps per Second: 10,929.54196

Timestep Collection Time: 2.18078
Timestep Consumption Time: 2.39452
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.57531

Cumulative Model Updates: 70,964
Cumulative Timesteps: 591,790,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 591790752...
Checkpoint 591790752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,134.78390
Policy Entropy: 3.75348
Value Function Loss: 0.05758

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.64822

Collected Steps per Second: 22,626.48113
Overall Steps per Second: 10,688.81806

Timestep Collection Time: 2.21077
Timestep Consumption Time: 2.46907
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.67984

Cumulative Model Updates: 70,970
Cumulative Timesteps: 591,840,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,185.88134
Policy Entropy: 3.75425
Value Function Loss: 0.05798

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06391
Policy Update Magnitude: 0.62866
Value Function Update Magnitude: 0.61353

Collected Steps per Second: 22,955.04739
Overall Steps per Second: 10,823.98190

Timestep Collection Time: 2.17852
Timestep Consumption Time: 2.44159
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.62011

Cumulative Model Updates: 70,976
Cumulative Timesteps: 591,890,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 591890782...
Checkpoint 591890782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,063.68343
Policy Entropy: 3.75991
Value Function Loss: 0.05797

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07114
Policy Update Magnitude: 0.67529
Value Function Update Magnitude: 0.63317

Collected Steps per Second: 22,769.06200
Overall Steps per Second: 10,696.64660

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.67474

Cumulative Model Updates: 70,982
Cumulative Timesteps: 591,940,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,900.02180
Policy Entropy: 3.75200
Value Function Loss: 0.05895

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.60294
Value Function Update Magnitude: 0.65272

Collected Steps per Second: 23,061.08642
Overall Steps per Second: 10,917.22340

Timestep Collection Time: 2.16824
Timestep Consumption Time: 2.41186
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.58010

Cumulative Model Updates: 70,988
Cumulative Timesteps: 591,990,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 591990788...
Checkpoint 591990788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,135.96078
Policy Entropy: 3.76251
Value Function Loss: 0.05836

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.54495
Value Function Update Magnitude: 0.67771

Collected Steps per Second: 22,639.63185
Overall Steps per Second: 10,632.10779

Timestep Collection Time: 2.20878
Timestep Consumption Time: 2.49452
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.70330

Cumulative Model Updates: 70,994
Cumulative Timesteps: 592,040,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,176.92882
Policy Entropy: 3.76069
Value Function Loss: 0.05773

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.57090
Value Function Update Magnitude: 0.72874

Collected Steps per Second: 22,832.58626
Overall Steps per Second: 10,802.96427

Timestep Collection Time: 2.19090
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.63058

Cumulative Model Updates: 71,000
Cumulative Timesteps: 592,090,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 592090818...
Checkpoint 592090818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,069.32190
Policy Entropy: 3.76031
Value Function Loss: 0.05610

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.59445
Value Function Update Magnitude: 0.75708

Collected Steps per Second: 22,227.22855
Overall Steps per Second: 10,679.89480

Timestep Collection Time: 2.25048
Timestep Consumption Time: 2.43327
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.68375

Cumulative Model Updates: 71,006
Cumulative Timesteps: 592,140,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,779.90037
Policy Entropy: 3.76511
Value Function Loss: 0.05733

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.62697
Value Function Update Magnitude: 0.76218

Collected Steps per Second: 23,240.32434
Overall Steps per Second: 10,948.42127

Timestep Collection Time: 2.15238
Timestep Consumption Time: 2.41650
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.56888

Cumulative Model Updates: 71,012
Cumulative Timesteps: 592,190,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 592190862...
Checkpoint 592190862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,440.18049
Policy Entropy: 3.75962
Value Function Loss: 0.05639

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.62654
Value Function Update Magnitude: 0.71726

Collected Steps per Second: 22,333.70966
Overall Steps per Second: 10,606.28503

Timestep Collection Time: 2.23922
Timestep Consumption Time: 2.47591
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.71513

Cumulative Model Updates: 71,018
Cumulative Timesteps: 592,240,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,250.19089
Policy Entropy: 3.75480
Value Function Loss: 0.05779

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.58901
Value Function Update Magnitude: 0.64049

Collected Steps per Second: 23,100.99086
Overall Steps per Second: 10,866.26295

Timestep Collection Time: 2.16450
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.60158

Cumulative Model Updates: 71,024
Cumulative Timesteps: 592,290,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 592290874...
Checkpoint 592290874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,917.75074
Policy Entropy: 3.75751
Value Function Loss: 0.05755

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.55572
Value Function Update Magnitude: 0.62369

Collected Steps per Second: 22,683.76700
Overall Steps per Second: 10,651.67652

Timestep Collection Time: 2.20431
Timestep Consumption Time: 2.48998
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.69428

Cumulative Model Updates: 71,030
Cumulative Timesteps: 592,340,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,805.46399
Policy Entropy: 3.76021
Value Function Loss: 0.05655

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06217
Policy Update Magnitude: 0.62883
Value Function Update Magnitude: 0.63686

Collected Steps per Second: 23,174.52755
Overall Steps per Second: 10,892.01903

Timestep Collection Time: 2.15823
Timestep Consumption Time: 2.43375
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.59199

Cumulative Model Updates: 71,036
Cumulative Timesteps: 592,390,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 592390892...
Checkpoint 592390892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,821.09430
Policy Entropy: 3.75373
Value Function Loss: 0.05755

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07013
Policy Update Magnitude: 0.68521
Value Function Update Magnitude: 0.69477

Collected Steps per Second: 22,599.94072
Overall Steps per Second: 10,684.19455

Timestep Collection Time: 2.21417
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.68355

Cumulative Model Updates: 71,042
Cumulative Timesteps: 592,440,932

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,682.35003
Policy Entropy: 3.74549
Value Function Loss: 0.06022

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.61415
Value Function Update Magnitude: 0.68951

Collected Steps per Second: 22,778.16917
Overall Steps per Second: 10,816.93824

Timestep Collection Time: 2.19684
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.62608

Cumulative Model Updates: 71,048
Cumulative Timesteps: 592,490,972

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 592490972...
Checkpoint 592490972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,787.39739
Policy Entropy: 3.73036
Value Function Loss: 0.06250

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.54659
Value Function Update Magnitude: 0.70113

Collected Steps per Second: 22,521.57950
Overall Steps per Second: 10,774.39801

Timestep Collection Time: 2.22116
Timestep Consumption Time: 2.42170
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.64286

Cumulative Model Updates: 71,054
Cumulative Timesteps: 592,540,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,346.24475
Policy Entropy: 3.73060
Value Function Loss: 0.06083

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.50004
Value Function Update Magnitude: 0.74448

Collected Steps per Second: 22,942.61485
Overall Steps per Second: 10,837.47659

Timestep Collection Time: 2.18048
Timestep Consumption Time: 2.43554
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.61602

Cumulative Model Updates: 71,060
Cumulative Timesteps: 592,591,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 592591022...
Checkpoint 592591022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,171.06053
Policy Entropy: 3.73770
Value Function Loss: 0.05952

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.48826
Value Function Update Magnitude: 0.76125

Collected Steps per Second: 22,642.10385
Overall Steps per Second: 10,656.00807

Timestep Collection Time: 2.20925
Timestep Consumption Time: 2.48501
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.69425

Cumulative Model Updates: 71,066
Cumulative Timesteps: 592,641,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,640.68008
Policy Entropy: 3.74251
Value Function Loss: 0.05876

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.52965
Value Function Update Magnitude: 0.76556

Collected Steps per Second: 22,946.81059
Overall Steps per Second: 10,856.77382

Timestep Collection Time: 2.17948
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60652

Cumulative Model Updates: 71,072
Cumulative Timesteps: 592,691,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 592691056...
Checkpoint 592691056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,660.61385
Policy Entropy: 3.73256
Value Function Loss: 0.06091

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.54381
Value Function Update Magnitude: 0.76994

Collected Steps per Second: 22,301.90934
Overall Steps per Second: 10,732.43861

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.65971

Cumulative Model Updates: 71,078
Cumulative Timesteps: 592,741,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,830.24536
Policy Entropy: 3.72612
Value Function Loss: 0.06165

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.57769
Value Function Update Magnitude: 0.69705

Collected Steps per Second: 23,144.02756
Overall Steps per Second: 10,947.90238

Timestep Collection Time: 2.16056
Timestep Consumption Time: 2.40689
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.56745

Cumulative Model Updates: 71,084
Cumulative Timesteps: 592,791,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 592791070...
Checkpoint 592791070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,431.99526
Policy Entropy: 3.72048
Value Function Loss: 0.06272

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.53064
Value Function Update Magnitude: 0.72368

Collected Steps per Second: 22,515.45445
Overall Steps per Second: 10,615.87259

Timestep Collection Time: 2.22132
Timestep Consumption Time: 2.48993
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.71125

Cumulative Model Updates: 71,090
Cumulative Timesteps: 592,841,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,163.77534
Policy Entropy: 3.71786
Value Function Loss: 0.06154

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.53063
Value Function Update Magnitude: 0.79378

Collected Steps per Second: 22,720.25272
Overall Steps per Second: 10,808.98510

Timestep Collection Time: 2.20182
Timestep Consumption Time: 2.42636
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.62819

Cumulative Model Updates: 71,096
Cumulative Timesteps: 592,891,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 592891110...
Checkpoint 592891110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,102.29139
Policy Entropy: 3.72365
Value Function Loss: 0.06156

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.51144
Value Function Update Magnitude: 0.79242

Collected Steps per Second: 22,548.28537
Overall Steps per Second: 10,710.27713

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.45154
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.66953

Cumulative Model Updates: 71,102
Cumulative Timesteps: 592,941,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,716.85697
Policy Entropy: 3.70600
Value Function Loss: 0.06206

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07040
Policy Update Magnitude: 0.58491
Value Function Update Magnitude: 0.78682

Collected Steps per Second: 22,395.01102
Overall Steps per Second: 10,924.74983

Timestep Collection Time: 2.23398
Timestep Consumption Time: 2.34553
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.57951

Cumulative Model Updates: 71,108
Cumulative Timesteps: 592,991,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 592991152...
Checkpoint 592991152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,634.63472
Policy Entropy: 3.71372
Value Function Loss: 0.06251

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.79783

Collected Steps per Second: 21,970.89568
Overall Steps per Second: 10,641.92020

Timestep Collection Time: 2.27574
Timestep Consumption Time: 2.42266
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.69840

Cumulative Model Updates: 71,114
Cumulative Timesteps: 593,041,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,174.35744
Policy Entropy: 3.71272
Value Function Loss: 0.06433

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.58002
Value Function Update Magnitude: 0.81209

Collected Steps per Second: 22,470.36747
Overall Steps per Second: 10,904.58190

Timestep Collection Time: 2.22586
Timestep Consumption Time: 2.36083
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.58670

Cumulative Model Updates: 71,120
Cumulative Timesteps: 593,091,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 593091168...
Checkpoint 593091168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,667.96157
Policy Entropy: 3.71557
Value Function Loss: 0.06383

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.56872
Value Function Update Magnitude: 0.82461

Collected Steps per Second: 21,602.58205
Overall Steps per Second: 10,596.53913

Timestep Collection Time: 2.31472
Timestep Consumption Time: 2.40418
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.71890

Cumulative Model Updates: 71,126
Cumulative Timesteps: 593,141,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,194.38175
Policy Entropy: 3.72847
Value Function Loss: 0.06447

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06895
Policy Update Magnitude: 0.60598
Value Function Update Magnitude: 0.82609

Collected Steps per Second: 22,580.23893
Overall Steps per Second: 10,973.01149

Timestep Collection Time: 2.21548
Timestep Consumption Time: 2.34353
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.55900

Cumulative Model Updates: 71,132
Cumulative Timesteps: 593,191,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 593191198...
Checkpoint 593191198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,946.08696
Policy Entropy: 3.73065
Value Function Loss: 0.06534

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10538
Policy Update Magnitude: 0.65211
Value Function Update Magnitude: 0.81391

Collected Steps per Second: 22,080.42479
Overall Steps per Second: 10,695.44931

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.41082
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.67563

Cumulative Model Updates: 71,138
Cumulative Timesteps: 593,241,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,880.24652
Policy Entropy: 3.70889
Value Function Loss: 0.06963

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.16123
Policy Update Magnitude: 0.51338
Value Function Update Magnitude: 0.76777

Collected Steps per Second: 21,496.92251
Overall Steps per Second: 10,703.62090

Timestep Collection Time: 2.32712
Timestep Consumption Time: 2.34662
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.67375

Cumulative Model Updates: 71,144
Cumulative Timesteps: 593,291,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 593291232...
Checkpoint 593291232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,227.27044
Policy Entropy: 3.70415
Value Function Loss: 0.07044

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.41273
Value Function Update Magnitude: 0.65271

Collected Steps per Second: 21,873.43557
Overall Steps per Second: 10,633.78051

Timestep Collection Time: 2.28597
Timestep Consumption Time: 2.41622
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.70218

Cumulative Model Updates: 71,150
Cumulative Timesteps: 593,341,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,676.11796
Policy Entropy: 3.69693
Value Function Loss: 0.07003

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.44891
Value Function Update Magnitude: 0.62939

Collected Steps per Second: 22,453.75206
Overall Steps per Second: 10,633.50145

Timestep Collection Time: 2.22689
Timestep Consumption Time: 2.47542
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.70231

Cumulative Model Updates: 71,156
Cumulative Timesteps: 593,391,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 593391236...
Checkpoint 593391236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,080.12129
Policy Entropy: 3.69494
Value Function Loss: 0.06688

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.66514

Collected Steps per Second: 22,137.36424
Overall Steps per Second: 10,557.00517

Timestep Collection Time: 2.25962
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.73828

Cumulative Model Updates: 71,162
Cumulative Timesteps: 593,441,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,823.82944
Policy Entropy: 3.68280
Value Function Loss: 0.06831

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.63721
Value Function Update Magnitude: 0.69079

Collected Steps per Second: 22,597.17293
Overall Steps per Second: 10,823.78154

Timestep Collection Time: 2.21311
Timestep Consumption Time: 2.40727
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.62038

Cumulative Model Updates: 71,168
Cumulative Timesteps: 593,491,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 593491268...
Checkpoint 593491268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,824.40732
Policy Entropy: 3.68523
Value Function Loss: 0.06782

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.66775
Value Function Update Magnitude: 0.66635

Collected Steps per Second: 21,990.72029
Overall Steps per Second: 10,694.25902

Timestep Collection Time: 2.27460
Timestep Consumption Time: 2.40268
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.67728

Cumulative Model Updates: 71,174
Cumulative Timesteps: 593,541,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,075.23098
Policy Entropy: 3.68929
Value Function Loss: 0.06765

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11403
Policy Update Magnitude: 0.59340
Value Function Update Magnitude: 0.72205

Collected Steps per Second: 22,920.19148
Overall Steps per Second: 10,854.99573

Timestep Collection Time: 2.18244
Timestep Consumption Time: 2.42576
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.60820

Cumulative Model Updates: 71,180
Cumulative Timesteps: 593,591,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 593591310...
Checkpoint 593591310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,484.90155
Policy Entropy: 3.70853
Value Function Loss: 0.06465

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08192
Policy Update Magnitude: 0.58489
Value Function Update Magnitude: 0.73242

Collected Steps per Second: 22,349.65394
Overall Steps per Second: 10,722.88049

Timestep Collection Time: 2.23789
Timestep Consumption Time: 2.42653
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.66442

Cumulative Model Updates: 71,186
Cumulative Timesteps: 593,641,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,494.81479
Policy Entropy: 3.70915
Value Function Loss: 0.06273

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.78489

Collected Steps per Second: 23,162.11382
Overall Steps per Second: 10,847.27544

Timestep Collection Time: 2.15956
Timestep Consumption Time: 2.45174
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.61130

Cumulative Model Updates: 71,192
Cumulative Timesteps: 593,691,346

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 593691346...
Checkpoint 593691346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,316.44147
Policy Entropy: 3.71076
Value Function Loss: 0.06413

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.59728
Value Function Update Magnitude: 0.80990

Collected Steps per Second: 22,508.06782
Overall Steps per Second: 10,653.56298

Timestep Collection Time: 2.22160
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.69364

Cumulative Model Updates: 71,198
Cumulative Timesteps: 593,741,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,894.55507
Policy Entropy: 3.70004
Value Function Loss: 0.06628

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.57154
Value Function Update Magnitude: 0.78819

Collected Steps per Second: 22,864.27128
Overall Steps per Second: 10,711.61190

Timestep Collection Time: 2.18778
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.66989

Cumulative Model Updates: 71,204
Cumulative Timesteps: 593,791,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 593791372...
Checkpoint 593791372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,065.05409
Policy Entropy: 3.68278
Value Function Loss: 0.06873

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.76247

Collected Steps per Second: 22,341.75868
Overall Steps per Second: 10,804.35591

Timestep Collection Time: 2.23850
Timestep Consumption Time: 2.39037
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.62887

Cumulative Model Updates: 71,210
Cumulative Timesteps: 593,841,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.03194
Policy Entropy: 3.69068
Value Function Loss: 0.06983

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.57477
Value Function Update Magnitude: 0.76936

Collected Steps per Second: 23,072.86119
Overall Steps per Second: 10,913.69569

Timestep Collection Time: 2.16705
Timestep Consumption Time: 2.41435
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.58140

Cumulative Model Updates: 71,216
Cumulative Timesteps: 593,891,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 593891384...
Checkpoint 593891384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.87978
Policy Entropy: 3.69279
Value Function Loss: 0.06929

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.53200
Value Function Update Magnitude: 0.75131

Collected Steps per Second: 22,386.55285
Overall Steps per Second: 10,760.62897

Timestep Collection Time: 2.23357
Timestep Consumption Time: 2.41318
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.64675

Cumulative Model Updates: 71,222
Cumulative Timesteps: 593,941,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,587.03433
Policy Entropy: 3.70207
Value Function Loss: 0.06945

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.53308
Value Function Update Magnitude: 0.73244

Collected Steps per Second: 23,103.35729
Overall Steps per Second: 10,921.50642

Timestep Collection Time: 2.16479
Timestep Consumption Time: 2.41461
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.57940

Cumulative Model Updates: 71,228
Cumulative Timesteps: 593,991,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 593991400...
Checkpoint 593991400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,805.80422
Policy Entropy: 3.68212
Value Function Loss: 0.07005

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.53340
Value Function Update Magnitude: 0.65704

Collected Steps per Second: 22,379.11474
Overall Steps per Second: 10,573.77557

Timestep Collection Time: 2.23423
Timestep Consumption Time: 2.49445
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.72868

Cumulative Model Updates: 71,234
Cumulative Timesteps: 594,041,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,084.08019
Policy Entropy: 3.67312
Value Function Loss: 0.07027

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.59052

Collected Steps per Second: 22,776.05102
Overall Steps per Second: 10,793.24364

Timestep Collection Time: 2.19625
Timestep Consumption Time: 2.43831
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.63457

Cumulative Model Updates: 71,240
Cumulative Timesteps: 594,091,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 594091422...
Checkpoint 594091422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,404.58602
Policy Entropy: 3.67498
Value Function Loss: 0.06914

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.58089
Value Function Update Magnitude: 0.60023

Collected Steps per Second: 22,040.25634
Overall Steps per Second: 10,662.35829

Timestep Collection Time: 2.26930
Timestep Consumption Time: 2.42159
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.69089

Cumulative Model Updates: 71,246
Cumulative Timesteps: 594,141,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.77309
Policy Entropy: 3.67792
Value Function Loss: 0.06721

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14704
Policy Update Magnitude: 0.47495
Value Function Update Magnitude: 0.61647

Collected Steps per Second: 22,840.98121
Overall Steps per Second: 10,677.54017

Timestep Collection Time: 2.18931
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.68329

Cumulative Model Updates: 71,252
Cumulative Timesteps: 594,191,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 594191444...
Checkpoint 594191444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,301.55386
Policy Entropy: 3.69316
Value Function Loss: 0.06730

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.53423
Value Function Update Magnitude: 0.68668

Collected Steps per Second: 22,741.52229
Overall Steps per Second: 10,687.75747

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.48072
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.68031

Cumulative Model Updates: 71,258
Cumulative Timesteps: 594,241,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,659.60595
Policy Entropy: 3.68257
Value Function Loss: 0.06646

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.56723
Value Function Update Magnitude: 0.69783

Collected Steps per Second: 23,212.66819
Overall Steps per Second: 10,734.99991

Timestep Collection Time: 2.15408
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.65785

Cumulative Model Updates: 71,264
Cumulative Timesteps: 594,291,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 594291468...
Checkpoint 594291468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,143.78704
Policy Entropy: 3.67601
Value Function Loss: 0.06767

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.54283
Value Function Update Magnitude: 0.70611

Collected Steps per Second: 22,433.92469
Overall Steps per Second: 10,611.81552

Timestep Collection Time: 2.22877
Timestep Consumption Time: 2.48296
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.71173

Cumulative Model Updates: 71,270
Cumulative Timesteps: 594,341,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936.86975
Policy Entropy: 3.68962
Value Function Loss: 0.06858

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.48959
Value Function Update Magnitude: 0.67823

Collected Steps per Second: 23,260.09119
Overall Steps per Second: 10,964.88175

Timestep Collection Time: 2.15038
Timestep Consumption Time: 2.41128
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.56165

Cumulative Model Updates: 71,276
Cumulative Timesteps: 594,391,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 594391486...
Checkpoint 594391486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,223.09846
Policy Entropy: 3.69450
Value Function Loss: 0.06865

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.49608
Value Function Update Magnitude: 0.64141

Collected Steps per Second: 22,798.29155
Overall Steps per Second: 10,650.42052

Timestep Collection Time: 2.19385
Timestep Consumption Time: 2.50230
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.69615

Cumulative Model Updates: 71,282
Cumulative Timesteps: 594,441,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,106.19714
Policy Entropy: 3.70296
Value Function Loss: 0.06745

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.48870
Value Function Update Magnitude: 0.67911

Collected Steps per Second: 22,412.39679
Overall Steps per Second: 10,897.53309

Timestep Collection Time: 2.23260
Timestep Consumption Time: 2.35908
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.59168

Cumulative Model Updates: 71,288
Cumulative Timesteps: 594,491,540

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 594491540...
Checkpoint 594491540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,325.93339
Policy Entropy: 3.68824
Value Function Loss: 0.06655

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.45532
Value Function Update Magnitude: 0.67652

Collected Steps per Second: 21,845.59597
Overall Steps per Second: 10,576.20949

Timestep Collection Time: 2.28925
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.72854

Cumulative Model Updates: 71,294
Cumulative Timesteps: 594,541,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,764.93190
Policy Entropy: 3.68340
Value Function Loss: 0.06583

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.42047
Value Function Update Magnitude: 0.60766

Collected Steps per Second: 22,254.82212
Overall Steps per Second: 10,860.36806

Timestep Collection Time: 2.24697
Timestep Consumption Time: 2.35747
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.60445

Cumulative Model Updates: 71,300
Cumulative Timesteps: 594,591,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 594591556...
Checkpoint 594591556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,761.91938
Policy Entropy: 3.68862
Value Function Loss: 0.06583

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.47144
Value Function Update Magnitude: 0.61761

Collected Steps per Second: 21,919.50729
Overall Steps per Second: 10,725.32555

Timestep Collection Time: 2.28199
Timestep Consumption Time: 2.38174
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.66373

Cumulative Model Updates: 71,306
Cumulative Timesteps: 594,641,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,358.12255
Policy Entropy: 3.69060
Value Function Loss: 0.06708

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.53048
Value Function Update Magnitude: 0.60033

Collected Steps per Second: 22,521.85002
Overall Steps per Second: 10,850.15951

Timestep Collection Time: 2.22042
Timestep Consumption Time: 2.38854
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.60896

Cumulative Model Updates: 71,312
Cumulative Timesteps: 594,691,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 594691584...
Checkpoint 594691584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,476.87815
Policy Entropy: 3.68784
Value Function Loss: 0.06780

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.50700
Value Function Update Magnitude: 0.64182

Collected Steps per Second: 21,708.45846
Overall Steps per Second: 10,663.98171

Timestep Collection Time: 2.30362
Timestep Consumption Time: 2.38581
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.68943

Cumulative Model Updates: 71,318
Cumulative Timesteps: 594,741,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,125.14464
Policy Entropy: 3.69195
Value Function Loss: 0.06664

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.51550
Value Function Update Magnitude: 0.59183

Collected Steps per Second: 22,220.10219
Overall Steps per Second: 10,880.13069

Timestep Collection Time: 2.25048
Timestep Consumption Time: 2.34560
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.59608

Cumulative Model Updates: 71,324
Cumulative Timesteps: 594,791,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 594791598...
Checkpoint 594791598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,401.09705
Policy Entropy: 3.68963
Value Function Loss: 0.06711

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.53725
Value Function Update Magnitude: 0.59734

Collected Steps per Second: 21,820.17832
Overall Steps per Second: 10,651.74372

Timestep Collection Time: 2.29274
Timestep Consumption Time: 2.40396
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.69670

Cumulative Model Updates: 71,330
Cumulative Timesteps: 594,841,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,750.64707
Policy Entropy: 3.69660
Value Function Loss: 0.06741

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.51416
Value Function Update Magnitude: 0.62079

Collected Steps per Second: 22,834.39518
Overall Steps per Second: 10,861.58556

Timestep Collection Time: 2.19099
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60614

Cumulative Model Updates: 71,336
Cumulative Timesteps: 594,891,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 594891656...
Checkpoint 594891656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,041.65483
Policy Entropy: 3.69513
Value Function Loss: 0.06580

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.51954
Value Function Update Magnitude: 0.63869

Collected Steps per Second: 22,080.01981
Overall Steps per Second: 10,690.64285

Timestep Collection Time: 2.26503
Timestep Consumption Time: 2.41308
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.67811

Cumulative Model Updates: 71,342
Cumulative Timesteps: 594,941,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,668.71573
Policy Entropy: 3.69804
Value Function Loss: 0.06524

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.50958
Value Function Update Magnitude: 0.63764

Collected Steps per Second: 22,835.10206
Overall Steps per Second: 10,871.47972

Timestep Collection Time: 2.19022
Timestep Consumption Time: 2.41025
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60048

Cumulative Model Updates: 71,348
Cumulative Timesteps: 594,991,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 594991682...
Checkpoint 594991682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,067.07194
Policy Entropy: 3.70391
Value Function Loss: 0.06339

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08171
Policy Update Magnitude: 0.58647
Value Function Update Magnitude: 0.69095

Collected Steps per Second: 22,473.30077
Overall Steps per Second: 10,739.80173

Timestep Collection Time: 2.22513
Timestep Consumption Time: 2.43101
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.65614

Cumulative Model Updates: 71,354
Cumulative Timesteps: 595,041,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,560.40907
Policy Entropy: 3.71723
Value Function Loss: 0.06567

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.57103
Value Function Update Magnitude: 0.71407

Collected Steps per Second: 22,998.31323
Overall Steps per Second: 10,834.41504

Timestep Collection Time: 2.17451
Timestep Consumption Time: 2.44134
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61585

Cumulative Model Updates: 71,360
Cumulative Timesteps: 595,091,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 595091698...
Checkpoint 595091698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,601.35494
Policy Entropy: 3.72171
Value Function Loss: 0.06456

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.58607
Value Function Update Magnitude: 0.73624

Collected Steps per Second: 22,663.43780
Overall Steps per Second: 10,644.96567

Timestep Collection Time: 2.20726
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.69931

Cumulative Model Updates: 71,366
Cumulative Timesteps: 595,141,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,016.12392
Policy Entropy: 3.71944
Value Function Loss: 0.06629

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10573
Policy Update Magnitude: 0.55552
Value Function Update Magnitude: 0.79581

Collected Steps per Second: 23,061.82401
Overall Steps per Second: 10,877.60848

Timestep Collection Time: 2.16835
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.59715

Cumulative Model Updates: 71,372
Cumulative Timesteps: 595,191,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 595191728...
Checkpoint 595191728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.35121
Policy Entropy: 3.71470
Value Function Loss: 0.06188

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.51071
Value Function Update Magnitude: 0.81646

Collected Steps per Second: 22,483.95982
Overall Steps per Second: 10,669.44065

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.46385
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.68891

Cumulative Model Updates: 71,378
Cumulative Timesteps: 595,241,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,840.43351
Policy Entropy: 3.70625
Value Function Loss: 0.06145

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07085
Policy Update Magnitude: 0.58791
Value Function Update Magnitude: 0.78158

Collected Steps per Second: 23,017.04981
Overall Steps per Second: 10,851.68779

Timestep Collection Time: 2.17256
Timestep Consumption Time: 2.43557
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.60813

Cumulative Model Updates: 71,384
Cumulative Timesteps: 595,291,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 595291762...
Checkpoint 595291762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,461.36497
Policy Entropy: 3.70878
Value Function Loss: 0.05981

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.57089
Value Function Update Magnitude: 0.75055

Collected Steps per Second: 22,091.99910
Overall Steps per Second: 10,658.75072

Timestep Collection Time: 2.26471
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.69398

Cumulative Model Updates: 71,390
Cumulative Timesteps: 595,341,794

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,253.75213
Policy Entropy: 3.70052
Value Function Loss: 0.06076

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.50209
Value Function Update Magnitude: 0.83412

Collected Steps per Second: 23,021.95780
Overall Steps per Second: 10,749.94906

Timestep Collection Time: 2.17288
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.65342

Cumulative Model Updates: 71,396
Cumulative Timesteps: 595,391,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 595391818...
Checkpoint 595391818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,108.11428
Policy Entropy: 3.71859
Value Function Loss: 0.05770

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.50519
Value Function Update Magnitude: 0.89416

Collected Steps per Second: 22,643.02571
Overall Steps per Second: 10,774.40967

Timestep Collection Time: 2.20898
Timestep Consumption Time: 2.43332
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.64230

Cumulative Model Updates: 71,402
Cumulative Timesteps: 595,441,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,276.86942
Policy Entropy: 3.70614
Value Function Loss: 0.05854

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.51592
Value Function Update Magnitude: 0.85577

Collected Steps per Second: 22,816.07902
Overall Steps per Second: 10,701.36513

Timestep Collection Time: 2.19249
Timestep Consumption Time: 2.48205
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.67454

Cumulative Model Updates: 71,408
Cumulative Timesteps: 595,491,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 595491860...
Checkpoint 595491860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,434.13179
Policy Entropy: 3.70749
Value Function Loss: 0.05913

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.54682
Value Function Update Magnitude: 0.74965

Collected Steps per Second: 22,580.97276
Overall Steps per Second: 10,628.70131

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.70481

Cumulative Model Updates: 71,414
Cumulative Timesteps: 595,541,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,848.76692
Policy Entropy: 3.70498
Value Function Loss: 0.06172

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.46065
Value Function Update Magnitude: 0.74881

Collected Steps per Second: 23,216.10933
Overall Steps per Second: 10,834.97647

Timestep Collection Time: 2.15428
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.61598

Cumulative Model Updates: 71,420
Cumulative Timesteps: 595,591,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 595591880...
Checkpoint 595591880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,878.92563
Policy Entropy: 3.71286
Value Function Loss: 0.06199

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.41734
Value Function Update Magnitude: 0.73443

Collected Steps per Second: 22,576.05593
Overall Steps per Second: 10,626.04164

Timestep Collection Time: 2.21500
Timestep Consumption Time: 2.49098
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.70599

Cumulative Model Updates: 71,426
Cumulative Timesteps: 595,641,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,838.91723
Policy Entropy: 3.71588
Value Function Loss: 0.06144

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.39915
Value Function Update Magnitude: 0.74514

Collected Steps per Second: 22,813.61089
Overall Steps per Second: 10,805.74289

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.43725
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.63050

Cumulative Model Updates: 71,432
Cumulative Timesteps: 595,691,922

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 595691922...
Checkpoint 595691922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,597.49051
Policy Entropy: 3.71921
Value Function Loss: 0.05978

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07862
Policy Update Magnitude: 0.47651
Value Function Update Magnitude: 0.79642

Collected Steps per Second: 22,572.94178
Overall Steps per Second: 10,660.63506

Timestep Collection Time: 2.21637
Timestep Consumption Time: 2.47660
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.69297

Cumulative Model Updates: 71,438
Cumulative Timesteps: 595,741,952

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,802.66119
Policy Entropy: 3.71155
Value Function Loss: 0.06170

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.58714
Value Function Update Magnitude: 0.81993

Collected Steps per Second: 22,835.31877
Overall Steps per Second: 10,839.17881

Timestep Collection Time: 2.19082
Timestep Consumption Time: 2.42466
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.61548

Cumulative Model Updates: 71,444
Cumulative Timesteps: 595,791,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 595791980...
Checkpoint 595791980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,835.63738
Policy Entropy: 3.72032
Value Function Loss: 0.06180

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.59547
Value Function Update Magnitude: 0.84230

Collected Steps per Second: 22,374.76833
Overall Steps per Second: 10,760.98768

Timestep Collection Time: 2.23538
Timestep Consumption Time: 2.41253
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.64790

Cumulative Model Updates: 71,450
Cumulative Timesteps: 595,841,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,828.00312
Policy Entropy: 3.72007
Value Function Loss: 0.06128

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.84537

Collected Steps per Second: 23,270.15250
Overall Steps per Second: 10,894.95669

Timestep Collection Time: 2.14919
Timestep Consumption Time: 2.44119
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.59038

Cumulative Model Updates: 71,456
Cumulative Timesteps: 595,892,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 595892008...
Checkpoint 595892008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,145.05346
Policy Entropy: 3.73283
Value Function Loss: 0.06052

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.52714
Value Function Update Magnitude: 0.82774

Collected Steps per Second: 22,361.01304
Overall Steps per Second: 10,629.01622

Timestep Collection Time: 2.23657
Timestep Consumption Time: 2.46866
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.70523

Cumulative Model Updates: 71,462
Cumulative Timesteps: 595,942,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,109.59887
Policy Entropy: 3.72832
Value Function Loss: 0.06056

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.50289
Value Function Update Magnitude: 0.85344

Collected Steps per Second: 23,079.18163
Overall Steps per Second: 10,886.17599

Timestep Collection Time: 2.16715
Timestep Consumption Time: 2.42730
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.59445

Cumulative Model Updates: 71,468
Cumulative Timesteps: 595,992,036

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 595992036...
Checkpoint 595992036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,366.14549
Policy Entropy: 3.72811
Value Function Loss: 0.06020

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.58300
Value Function Update Magnitude: 0.87109

Collected Steps per Second: 22,795.57127
Overall Steps per Second: 10,672.09762

Timestep Collection Time: 2.19411
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.68661

Cumulative Model Updates: 71,474
Cumulative Timesteps: 596,042,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,967.64835
Policy Entropy: 3.72904
Value Function Loss: 0.05926

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.56406
Value Function Update Magnitude: 0.86888

Collected Steps per Second: 23,102.61239
Overall Steps per Second: 10,871.17134

Timestep Collection Time: 2.16486
Timestep Consumption Time: 2.43574
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.60061

Cumulative Model Updates: 71,480
Cumulative Timesteps: 596,092,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 596092066...
Checkpoint 596092066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,073.58131
Policy Entropy: 3.72505
Value Function Loss: 0.06077

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.49815
Value Function Update Magnitude: 0.85013

Collected Steps per Second: 22,513.32036
Overall Steps per Second: 10,672.70998

Timestep Collection Time: 2.22162
Timestep Consumption Time: 2.46473
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.68634

Cumulative Model Updates: 71,486
Cumulative Timesteps: 596,142,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,992.11853
Policy Entropy: 3.71693
Value Function Loss: 0.05837

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.49744
Value Function Update Magnitude: 0.83711

Collected Steps per Second: 22,960.91287
Overall Steps per Second: 10,875.43962

Timestep Collection Time: 2.17822
Timestep Consumption Time: 2.42058
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59880

Cumulative Model Updates: 71,492
Cumulative Timesteps: 596,192,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 596192096...
Checkpoint 596192096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,775.89235
Policy Entropy: 3.71422
Value Function Loss: 0.06054

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.52509
Value Function Update Magnitude: 0.86218

Collected Steps per Second: 22,528.25534
Overall Steps per Second: 10,688.60043

Timestep Collection Time: 2.22050
Timestep Consumption Time: 2.45963
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.68013

Cumulative Model Updates: 71,498
Cumulative Timesteps: 596,242,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,369.94200
Policy Entropy: 3.71215
Value Function Loss: 0.06281

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.50855
Value Function Update Magnitude: 0.86294

Collected Steps per Second: 23,092.58387
Overall Steps per Second: 10,909.46202

Timestep Collection Time: 2.16641
Timestep Consumption Time: 2.41933
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.58574

Cumulative Model Updates: 71,504
Cumulative Timesteps: 596,292,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 596292148...
Checkpoint 596292148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,141.53394
Policy Entropy: 3.71707
Value Function Loss: 0.06519

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.50015
Value Function Update Magnitude: 0.82223

Collected Steps per Second: 21,749.22207
Overall Steps per Second: 10,609.14777

Timestep Collection Time: 2.29893
Timestep Consumption Time: 2.41398
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.71291

Cumulative Model Updates: 71,510
Cumulative Timesteps: 596,342,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,621.59565
Policy Entropy: 3.73017
Value Function Loss: 0.06349

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06598
Policy Update Magnitude: 0.55604
Value Function Update Magnitude: 0.83778

Collected Steps per Second: 22,334.77360
Overall Steps per Second: 10,922.09336

Timestep Collection Time: 2.23866
Timestep Consumption Time: 2.33922
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.57788

Cumulative Model Updates: 71,516
Cumulative Timesteps: 596,392,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 596392148...
Checkpoint 596392148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,632.51819
Policy Entropy: 3.72821
Value Function Loss: 0.06455

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06269
Policy Update Magnitude: 0.69785
Value Function Update Magnitude: 0.87973

Collected Steps per Second: 22,010.67818
Overall Steps per Second: 10,650.39539

Timestep Collection Time: 2.27290
Timestep Consumption Time: 2.42439
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.69729

Cumulative Model Updates: 71,522
Cumulative Timesteps: 596,442,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,082.46131
Policy Entropy: 3.72529
Value Function Loss: 0.06567

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08200
Policy Update Magnitude: 0.70603
Value Function Update Magnitude: 0.85795

Collected Steps per Second: 22,168.97065
Overall Steps per Second: 10,820.66344

Timestep Collection Time: 2.25667
Timestep Consumption Time: 2.36671
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.62338

Cumulative Model Updates: 71,528
Cumulative Timesteps: 596,492,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 596492204...
Checkpoint 596492204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.99660
Policy Entropy: 3.72117
Value Function Loss: 0.06768

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.64479
Value Function Update Magnitude: 0.77522

Collected Steps per Second: 21,761.73623
Overall Steps per Second: 10,711.45467

Timestep Collection Time: 2.29779
Timestep Consumption Time: 2.37048
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.66827

Cumulative Model Updates: 71,534
Cumulative Timesteps: 596,542,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,836.12369
Policy Entropy: 3.73518
Value Function Loss: 0.06585

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.52605
Value Function Update Magnitude: 0.78558

Collected Steps per Second: 22,272.85562
Overall Steps per Second: 10,876.91370

Timestep Collection Time: 2.24533
Timestep Consumption Time: 2.35248
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.59781

Cumulative Model Updates: 71,540
Cumulative Timesteps: 596,592,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 596592218...
Checkpoint 596592218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,435.41425
Policy Entropy: 3.73918
Value Function Loss: 0.06106

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.44008
Value Function Update Magnitude: 0.86827

Collected Steps per Second: 21,566.30520
Overall Steps per Second: 10,659.98714

Timestep Collection Time: 2.31908
Timestep Consumption Time: 2.37267
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.69175

Cumulative Model Updates: 71,546
Cumulative Timesteps: 596,642,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,074.03970
Policy Entropy: 3.74239
Value Function Loss: 0.05895

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.39473
Value Function Update Magnitude: 0.88744

Collected Steps per Second: 22,097.73160
Overall Steps per Second: 10,816.83244

Timestep Collection Time: 2.26286
Timestep Consumption Time: 2.35994
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.62280

Cumulative Model Updates: 71,552
Cumulative Timesteps: 596,692,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 596692236...
Checkpoint 596692236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.53591
Policy Entropy: 3.73587
Value Function Loss: 0.05745

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.44323
Value Function Update Magnitude: 0.86274

Collected Steps per Second: 21,392.46545
Overall Steps per Second: 10,662.25182

Timestep Collection Time: 2.33736
Timestep Consumption Time: 2.35226
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.68963

Cumulative Model Updates: 71,558
Cumulative Timesteps: 596,742,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,125.20889
Policy Entropy: 3.73004
Value Function Loss: 0.05971

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.55933
Value Function Update Magnitude: 0.83374

Collected Steps per Second: 22,390.58666
Overall Steps per Second: 10,863.87723

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.36980
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.60333

Cumulative Model Updates: 71,564
Cumulative Timesteps: 596,792,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 596792248...
Checkpoint 596792248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,825.29825
Policy Entropy: 3.71905
Value Function Loss: 0.06109

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06972
Policy Update Magnitude: 0.64951
Value Function Update Magnitude: 0.84668

Collected Steps per Second: 21,850.48906
Overall Steps per Second: 10,739.94881

Timestep Collection Time: 2.28974
Timestep Consumption Time: 2.36875
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.65850

Cumulative Model Updates: 71,570
Cumulative Timesteps: 596,842,280

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,443.51152
Policy Entropy: 3.72750
Value Function Loss: 0.06190

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06910
Policy Update Magnitude: 0.67155
Value Function Update Magnitude: 0.84912

Collected Steps per Second: 22,473.98767
Overall Steps per Second: 10,934.06934

Timestep Collection Time: 2.22604
Timestep Consumption Time: 2.34938
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.57542

Cumulative Model Updates: 71,576
Cumulative Timesteps: 596,892,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 596892308...
Checkpoint 596892308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,254.61538
Policy Entropy: 3.71894
Value Function Loss: 0.06098

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.69622
Value Function Update Magnitude: 0.87759

Collected Steps per Second: 21,788.78341
Overall Steps per Second: 10,605.35843

Timestep Collection Time: 2.29558
Timestep Consumption Time: 2.42071
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.71630

Cumulative Model Updates: 71,582
Cumulative Timesteps: 596,942,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,844.95226
Policy Entropy: 3.72052
Value Function Loss: 0.06087

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 0.71046
Value Function Update Magnitude: 0.89988

Collected Steps per Second: 22,202.74099
Overall Steps per Second: 10,583.91217

Timestep Collection Time: 2.25242
Timestep Consumption Time: 2.47267
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.72510

Cumulative Model Updates: 71,588
Cumulative Timesteps: 596,992,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 596992336...
Checkpoint 596992336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561.86982
Policy Entropy: 3.71492
Value Function Loss: 0.06207

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.58028
Value Function Update Magnitude: 0.90166

Collected Steps per Second: 22,701.82496
Overall Steps per Second: 10,756.07267

Timestep Collection Time: 2.20282
Timestep Consumption Time: 2.44646
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.64928

Cumulative Model Updates: 71,594
Cumulative Timesteps: 597,042,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,528.87388
Policy Entropy: 3.72835
Value Function Loss: 0.06164

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.46240
Value Function Update Magnitude: 0.90661

Collected Steps per Second: 23,304.85263
Overall Steps per Second: 10,872.74902

Timestep Collection Time: 2.14676
Timestep Consumption Time: 2.45465
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.60141

Cumulative Model Updates: 71,600
Cumulative Timesteps: 597,092,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 597092374...
Checkpoint 597092374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,534.87185
Policy Entropy: 3.73575
Value Function Loss: 0.06156

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.42735
Value Function Update Magnitude: 0.84990

Collected Steps per Second: 22,669.75749
Overall Steps per Second: 10,848.39340

Timestep Collection Time: 2.20558
Timestep Consumption Time: 2.40340
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.60898

Cumulative Model Updates: 71,606
Cumulative Timesteps: 597,142,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,992.00971
Policy Entropy: 3.72922
Value Function Loss: 0.06188

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.50741
Value Function Update Magnitude: 0.71438

Collected Steps per Second: 22,949.43032
Overall Steps per Second: 10,914.74272

Timestep Collection Time: 2.17957
Timestep Consumption Time: 2.40322
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.58279

Cumulative Model Updates: 71,612
Cumulative Timesteps: 597,192,394

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 597192394...
Checkpoint 597192394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,263.73458
Policy Entropy: 3.72116
Value Function Loss: 0.06363

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.61366
Value Function Update Magnitude: 0.64120

Collected Steps per Second: 22,419.46559
Overall Steps per Second: 10,718.63151

Timestep Collection Time: 2.23119
Timestep Consumption Time: 2.43564
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.66683

Cumulative Model Updates: 71,618
Cumulative Timesteps: 597,242,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,208.16314
Policy Entropy: 3.71056
Value Function Loss: 0.06269

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.63739
Value Function Update Magnitude: 0.63817

Collected Steps per Second: 23,150.96361
Overall Steps per Second: 10,865.17526

Timestep Collection Time: 2.16069
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.60388

Cumulative Model Updates: 71,624
Cumulative Timesteps: 597,292,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 597292438...
Checkpoint 597292438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,519.15627
Policy Entropy: 3.72960
Value Function Loss: 0.06196

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.60028
Value Function Update Magnitude: 0.64867

Collected Steps per Second: 22,080.51254
Overall Steps per Second: 10,664.24391

Timestep Collection Time: 2.26480
Timestep Consumption Time: 2.42451
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.68932

Cumulative Model Updates: 71,630
Cumulative Timesteps: 597,342,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,999.26108
Policy Entropy: 3.72362
Value Function Loss: 0.06083

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.64378
Value Function Update Magnitude: 0.66281

Collected Steps per Second: 23,042.05218
Overall Steps per Second: 10,849.48189

Timestep Collection Time: 2.17038
Timestep Consumption Time: 2.43906
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.60944

Cumulative Model Updates: 71,636
Cumulative Timesteps: 597,392,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 597392456...
Checkpoint 597392456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,928.28771
Policy Entropy: 3.71962
Value Function Loss: 0.05910

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.64802
Value Function Update Magnitude: 0.68123

Collected Steps per Second: 22,501.97291
Overall Steps per Second: 10,779.13984

Timestep Collection Time: 2.22336
Timestep Consumption Time: 2.41801
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.64137

Cumulative Model Updates: 71,642
Cumulative Timesteps: 597,442,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,253.46005
Policy Entropy: 3.71470
Value Function Loss: 0.06024

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.59864
Value Function Update Magnitude: 0.66372

Collected Steps per Second: 23,184.67465
Overall Steps per Second: 10,807.01094

Timestep Collection Time: 2.15686
Timestep Consumption Time: 2.47033
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.62718

Cumulative Model Updates: 71,648
Cumulative Timesteps: 597,492,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 597492492...
Checkpoint 597492492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,140.62259
Policy Entropy: 3.70968
Value Function Loss: 0.06069

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.58133
Value Function Update Magnitude: 0.65562

Collected Steps per Second: 22,421.26238
Overall Steps per Second: 10,661.07646

Timestep Collection Time: 2.23119
Timestep Consumption Time: 2.46121
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.69240

Cumulative Model Updates: 71,654
Cumulative Timesteps: 597,542,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,995.46516
Policy Entropy: 3.69817
Value Function Loss: 0.06464

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.59937
Value Function Update Magnitude: 0.62239

Collected Steps per Second: 22,973.68110
Overall Steps per Second: 10,868.07535

Timestep Collection Time: 2.17780
Timestep Consumption Time: 2.42578
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.60358

Cumulative Model Updates: 71,660
Cumulative Timesteps: 597,592,550

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 597592550...
Checkpoint 597592550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,224.36047
Policy Entropy: 3.70316
Value Function Loss: 0.06455

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.54412
Value Function Update Magnitude: 0.61405

Collected Steps per Second: 22,505.68448
Overall Steps per Second: 10,747.55906

Timestep Collection Time: 2.22202
Timestep Consumption Time: 2.43095
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.65296

Cumulative Model Updates: 71,666
Cumulative Timesteps: 597,642,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,044.46645
Policy Entropy: 3.69330
Value Function Loss: 0.06558

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11626
Policy Update Magnitude: 0.50019
Value Function Update Magnitude: 0.60548

Collected Steps per Second: 22,930.02647
Overall Steps per Second: 10,873.64900

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.41869
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.60011

Cumulative Model Updates: 71,672
Cumulative Timesteps: 597,692,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 597692578...
Checkpoint 597692578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,194.90609
Policy Entropy: 3.68709
Value Function Loss: 0.06616

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.50583
Value Function Update Magnitude: 0.60768

Collected Steps per Second: 22,562.04551
Overall Steps per Second: 10,602.33532

Timestep Collection Time: 2.21647
Timestep Consumption Time: 2.50023
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.71670

Cumulative Model Updates: 71,678
Cumulative Timesteps: 597,742,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,049.91803
Policy Entropy: 3.68215
Value Function Loss: 0.06812

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.52523
Value Function Update Magnitude: 0.63174

Collected Steps per Second: 23,182.14876
Overall Steps per Second: 10,904.14763

Timestep Collection Time: 2.15873
Timestep Consumption Time: 2.43072
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.58945

Cumulative Model Updates: 71,684
Cumulative Timesteps: 597,792,630

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 597792630...
Checkpoint 597792630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,500.17590
Policy Entropy: 3.68581
Value Function Loss: 0.06906

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.52316
Value Function Update Magnitude: 0.68403

Collected Steps per Second: 22,329.26842
Overall Steps per Second: 10,678.25316

Timestep Collection Time: 2.23930
Timestep Consumption Time: 2.44330
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.68260

Cumulative Model Updates: 71,690
Cumulative Timesteps: 597,842,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,622.08567
Policy Entropy: 3.70446
Value Function Loss: 0.06782

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.51443
Value Function Update Magnitude: 0.78503

Collected Steps per Second: 22,844.22995
Overall Steps per Second: 10,818.15147

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.62334

Cumulative Model Updates: 71,696
Cumulative Timesteps: 597,892,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 597892648...
Checkpoint 597892648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,799.34152
Policy Entropy: 3.68970
Value Function Loss: 0.06646

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.51637
Value Function Update Magnitude: 0.80174

Collected Steps per Second: 22,139.85738
Overall Steps per Second: 10,673.87042

Timestep Collection Time: 2.25846
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.68452

Cumulative Model Updates: 71,702
Cumulative Timesteps: 597,942,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,708.36446
Policy Entropy: 3.69184
Value Function Loss: 0.06502

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.52439
Value Function Update Magnitude: 0.76373

Collected Steps per Second: 22,861.04873
Overall Steps per Second: 10,730.82479

Timestep Collection Time: 2.18748
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.66022

Cumulative Model Updates: 71,708
Cumulative Timesteps: 597,992,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 597992658...
Checkpoint 597992658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,105.99525
Policy Entropy: 3.69051
Value Function Loss: 0.06428

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.53061
Value Function Update Magnitude: 0.64420

Collected Steps per Second: 22,423.43295
Overall Steps per Second: 10,763.09625

Timestep Collection Time: 2.23124
Timestep Consumption Time: 2.41724
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.64848

Cumulative Model Updates: 71,714
Cumulative Timesteps: 598,042,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,703.59813
Policy Entropy: 3.70492
Value Function Loss: 0.06554

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.62199

Collected Steps per Second: 22,803.71721
Overall Steps per Second: 10,655.76986

Timestep Collection Time: 2.19298
Timestep Consumption Time: 2.50007
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.69304

Cumulative Model Updates: 71,720
Cumulative Timesteps: 598,092,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 598092698...
Checkpoint 598092698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,568.72556
Policy Entropy: 3.70006
Value Function Loss: 0.06956

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.57493
Value Function Update Magnitude: 0.61021

Collected Steps per Second: 22,540.57852
Overall Steps per Second: 10,628.18429

Timestep Collection Time: 2.21920
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.70654

Cumulative Model Updates: 71,726
Cumulative Timesteps: 598,142,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,334.28067
Policy Entropy: 3.70052
Value Function Loss: 0.07070

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.58992
Value Function Update Magnitude: 0.63241

Collected Steps per Second: 23,273.12700
Overall Steps per Second: 10,836.52160

Timestep Collection Time: 2.14840
Timestep Consumption Time: 2.46563
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.61403

Cumulative Model Updates: 71,732
Cumulative Timesteps: 598,192,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 598192720...
Checkpoint 598192720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,516.84564
Policy Entropy: 3.68653
Value Function Loss: 0.07317

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.56893
Value Function Update Magnitude: 0.74093

Collected Steps per Second: 22,782.36367
Overall Steps per Second: 10,684.24803

Timestep Collection Time: 2.19600
Timestep Consumption Time: 2.48660
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.68259

Cumulative Model Updates: 71,738
Cumulative Timesteps: 598,242,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,960.46656
Policy Entropy: 3.68976
Value Function Loss: 0.07279

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.60901
Value Function Update Magnitude: 0.83220

Collected Steps per Second: 23,061.15961
Overall Steps per Second: 10,859.95487

Timestep Collection Time: 2.16884
Timestep Consumption Time: 2.43670
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.60554

Cumulative Model Updates: 71,744
Cumulative Timesteps: 598,292,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 598292766...
Checkpoint 598292766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,662.73722
Policy Entropy: 3.66513
Value Function Loss: 0.07418

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.66135
Value Function Update Magnitude: 0.82615

Collected Steps per Second: 22,416.35767
Overall Steps per Second: 10,617.00064

Timestep Collection Time: 2.23087
Timestep Consumption Time: 2.47931
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.71018

Cumulative Model Updates: 71,750
Cumulative Timesteps: 598,342,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,324.36395
Policy Entropy: 3.67471
Value Function Loss: 0.07552

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.72494
Value Function Update Magnitude: 0.78831

Collected Steps per Second: 23,023.93331
Overall Steps per Second: 10,873.66828

Timestep Collection Time: 2.17183
Timestep Consumption Time: 2.42681
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.59863

Cumulative Model Updates: 71,756
Cumulative Timesteps: 598,392,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 598392778...
Checkpoint 598392778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,282.23441
Policy Entropy: 3.66994
Value Function Loss: 0.07717

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12116
Policy Update Magnitude: 0.60517
Value Function Update Magnitude: 0.67044

Collected Steps per Second: 21,914.82131
Overall Steps per Second: 10,632.01177

Timestep Collection Time: 2.28284
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.70541

Cumulative Model Updates: 71,762
Cumulative Timesteps: 598,442,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,443.09522
Policy Entropy: 3.68451
Value Function Loss: 0.07847

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.51222
Value Function Update Magnitude: 0.64940

Collected Steps per Second: 22,791.66557
Overall Steps per Second: 10,605.73584

Timestep Collection Time: 2.19484
Timestep Consumption Time: 2.52186
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.71669

Cumulative Model Updates: 71,768
Cumulative Timesteps: 598,492,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 598492830...
Checkpoint 598492830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,665.66699
Policy Entropy: 3.67126
Value Function Loss: 0.07505

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.47499
Value Function Update Magnitude: 0.66539

Collected Steps per Second: 22,596.36118
Overall Steps per Second: 10,666.25545

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.47741
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.69237

Cumulative Model Updates: 71,774
Cumulative Timesteps: 598,542,880

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,438.74335
Policy Entropy: 3.66896
Value Function Loss: 0.07468

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.44634
Value Function Update Magnitude: 0.64111

Collected Steps per Second: 23,352.51498
Overall Steps per Second: 10,774.19907

Timestep Collection Time: 2.14264
Timestep Consumption Time: 2.50142
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.64406

Cumulative Model Updates: 71,780
Cumulative Timesteps: 598,592,916

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 598592916...
Checkpoint 598592916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,907.30501
Policy Entropy: 3.67846
Value Function Loss: 0.07117

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.44362
Value Function Update Magnitude: 0.66236

Collected Steps per Second: 22,459.37726
Overall Steps per Second: 10,654.02251

Timestep Collection Time: 2.22660
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.69381

Cumulative Model Updates: 71,786
Cumulative Timesteps: 598,642,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,293.98845
Policy Entropy: 3.67551
Value Function Loss: 0.07043

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.49479
Value Function Update Magnitude: 0.67542

Collected Steps per Second: 23,181.38379
Overall Steps per Second: 10,912.94406

Timestep Collection Time: 2.15785
Timestep Consumption Time: 2.42588
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.58373

Cumulative Model Updates: 71,792
Cumulative Timesteps: 598,692,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 598692946...
Checkpoint 598692946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,980.65255
Policy Entropy: 3.67989
Value Function Loss: 0.07065

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.51084
Value Function Update Magnitude: 0.68350

Collected Steps per Second: 21,777.58528
Overall Steps per Second: 10,634.46202

Timestep Collection Time: 2.29677
Timestep Consumption Time: 2.40662
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.70339

Cumulative Model Updates: 71,798
Cumulative Timesteps: 598,742,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,470.05105
Policy Entropy: 3.68927
Value Function Loss: 0.06938

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.40370
Value Function Update Magnitude: 0.67239

Collected Steps per Second: 22,600.20352
Overall Steps per Second: 10,932.47676

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.36220
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.57554

Cumulative Model Updates: 71,804
Cumulative Timesteps: 598,792,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 598792986...
Checkpoint 598792986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,592.79761
Policy Entropy: 3.68500
Value Function Loss: 0.06829

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.42620
Value Function Update Magnitude: 0.67585

Collected Steps per Second: 21,884.53071
Overall Steps per Second: 10,592.98594

Timestep Collection Time: 2.28600
Timestep Consumption Time: 2.43675
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.72275

Cumulative Model Updates: 71,810
Cumulative Timesteps: 598,843,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,945.51894
Policy Entropy: 3.70255
Value Function Loss: 0.06314

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.39110
Value Function Update Magnitude: 0.59107

Collected Steps per Second: 22,502.00289
Overall Steps per Second: 10,918.31057

Timestep Collection Time: 2.22354
Timestep Consumption Time: 2.35904
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.58258

Cumulative Model Updates: 71,816
Cumulative Timesteps: 598,893,048

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 598893048...
Checkpoint 598893048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,789.26468
Policy Entropy: 3.71163
Value Function Loss: 0.06173

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.49950
Value Function Update Magnitude: 0.61010

Collected Steps per Second: 21,809.14102
Overall Steps per Second: 10,630.25434

Timestep Collection Time: 2.29344
Timestep Consumption Time: 2.41181
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.70525

Cumulative Model Updates: 71,822
Cumulative Timesteps: 598,943,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,344.63501
Policy Entropy: 3.72531
Value Function Loss: 0.06163

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.58828
Value Function Update Magnitude: 0.61512

Collected Steps per Second: 22,305.87595
Overall Steps per Second: 10,884.62394

Timestep Collection Time: 2.24282
Timestep Consumption Time: 2.35339
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.59621

Cumulative Model Updates: 71,828
Cumulative Timesteps: 598,993,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 598993094...
Checkpoint 598993094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,854.43645
Policy Entropy: 3.68835
Value Function Loss: 0.06388

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.58740
Value Function Update Magnitude: 0.59687

Collected Steps per Second: 21,945.29641
Overall Steps per Second: 10,670.51586

Timestep Collection Time: 2.27876
Timestep Consumption Time: 2.40780
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.68656

Cumulative Model Updates: 71,834
Cumulative Timesteps: 599,043,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,635.99768
Policy Entropy: 3.68071
Value Function Loss: 0.06817

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.55708
Value Function Update Magnitude: 0.60816

Collected Steps per Second: 22,225.82447
Overall Steps per Second: 10,857.33883

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.35639
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.60684

Cumulative Model Updates: 71,840
Cumulative Timesteps: 599,093,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 599093120...
Checkpoint 599093120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,044.65692
Policy Entropy: 3.67000
Value Function Loss: 0.06637

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.49361
Value Function Update Magnitude: 0.62413

Collected Steps per Second: 21,688.67810
Overall Steps per Second: 10,751.16529

Timestep Collection Time: 2.30618
Timestep Consumption Time: 2.34615
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.65233

Cumulative Model Updates: 71,846
Cumulative Timesteps: 599,143,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,089.70604
Policy Entropy: 3.69013
Value Function Loss: 0.06727

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.60529

Collected Steps per Second: 22,397.46446
Overall Steps per Second: 10,845.66930

Timestep Collection Time: 2.23347
Timestep Consumption Time: 2.37888
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.61235

Cumulative Model Updates: 71,852
Cumulative Timesteps: 599,193,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 599193162...
Checkpoint 599193162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,426.24698
Policy Entropy: 3.70384
Value Function Loss: 0.06660

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.60834

Collected Steps per Second: 21,772.65859
Overall Steps per Second: 10,626.37949

Timestep Collection Time: 2.29774
Timestep Consumption Time: 2.41016
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.70791

Cumulative Model Updates: 71,858
Cumulative Timesteps: 599,243,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,233.84786
Policy Entropy: 3.70443
Value Function Loss: 0.06655

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.58530
Value Function Update Magnitude: 0.67160

Collected Steps per Second: 23,016.39704
Overall Steps per Second: 10,909.77350

Timestep Collection Time: 2.17289
Timestep Consumption Time: 2.41126
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.58415

Cumulative Model Updates: 71,864
Cumulative Timesteps: 599,293,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 599293202...
Checkpoint 599293202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,518.76554
Policy Entropy: 3.71168
Value Function Loss: 0.06495

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.56614
Value Function Update Magnitude: 0.70961

Collected Steps per Second: 22,464.23320
Overall Steps per Second: 10,662.60787

Timestep Collection Time: 2.22585
Timestep Consumption Time: 2.46362
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.68947

Cumulative Model Updates: 71,870
Cumulative Timesteps: 599,343,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,552.18994
Policy Entropy: 3.71731
Value Function Loss: 0.06291

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.56404
Value Function Update Magnitude: 0.70147

Collected Steps per Second: 23,079.62387
Overall Steps per Second: 10,966.56224

Timestep Collection Time: 2.16745
Timestep Consumption Time: 2.39405
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.56150

Cumulative Model Updates: 71,876
Cumulative Timesteps: 599,393,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 599393228...
Checkpoint 599393228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,066.91972
Policy Entropy: 3.72052
Value Function Loss: 0.06319

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.58341
Value Function Update Magnitude: 0.64985

Collected Steps per Second: 22,660.84058
Overall Steps per Second: 10,732.99136

Timestep Collection Time: 2.20663
Timestep Consumption Time: 2.45228
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.65891

Cumulative Model Updates: 71,882
Cumulative Timesteps: 599,443,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,182.93662
Policy Entropy: 3.72012
Value Function Loss: 0.06207

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.60808
Value Function Update Magnitude: 0.66232

Collected Steps per Second: 23,149.69078
Overall Steps per Second: 10,742.23399

Timestep Collection Time: 2.16081
Timestep Consumption Time: 2.49577
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.65657

Cumulative Model Updates: 71,888
Cumulative Timesteps: 599,493,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 599493254...
Checkpoint 599493254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,842.37997
Policy Entropy: 3.72066
Value Function Loss: 0.06304

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.56331
Value Function Update Magnitude: 0.69102

Collected Steps per Second: 22,557.90410
Overall Steps per Second: 10,636.78961

Timestep Collection Time: 2.21670
Timestep Consumption Time: 2.48435
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.70104

Cumulative Model Updates: 71,894
Cumulative Timesteps: 599,543,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,492.77688
Policy Entropy: 3.70533
Value Function Loss: 0.06262

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.51611
Value Function Update Magnitude: 0.70580

Collected Steps per Second: 23,005.08883
Overall Steps per Second: 10,855.37386

Timestep Collection Time: 2.17421
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60767

Cumulative Model Updates: 71,900
Cumulative Timesteps: 599,593,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 599593276...
Checkpoint 599593276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,586.81443
Policy Entropy: 3.69874
Value Function Loss: 0.06340

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.51057
Value Function Update Magnitude: 0.67271

Collected Steps per Second: 22,338.22209
Overall Steps per Second: 10,725.40123

Timestep Collection Time: 2.23885
Timestep Consumption Time: 2.42410
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.66295

Cumulative Model Updates: 71,906
Cumulative Timesteps: 599,643,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,977.73886
Policy Entropy: 3.69087
Value Function Loss: 0.06469

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.48736
Value Function Update Magnitude: 0.66882

Collected Steps per Second: 22,950.48333
Overall Steps per Second: 10,832.14824

Timestep Collection Time: 2.17869
Timestep Consumption Time: 2.43738
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61607

Cumulative Model Updates: 71,912
Cumulative Timesteps: 599,693,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 599693290...
Checkpoint 599693290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.65916
Policy Entropy: 3.69569
Value Function Loss: 0.06470

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.66767

Collected Steps per Second: 22,410.29743
Overall Steps per Second: 10,724.29148

Timestep Collection Time: 2.23192
Timestep Consumption Time: 2.43207
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.66399

Cumulative Model Updates: 71,918
Cumulative Timesteps: 599,743,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,089.54446
Policy Entropy: 3.69020
Value Function Loss: 0.06604

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.60314
Value Function Update Magnitude: 0.68574

Collected Steps per Second: 22,946.27280
Overall Steps per Second: 10,810.08157

Timestep Collection Time: 2.17970
Timestep Consumption Time: 2.44709
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.62679

Cumulative Model Updates: 71,924
Cumulative Timesteps: 599,793,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 599793324...
Checkpoint 599793324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,777.12125
Policy Entropy: 3.70078
Value Function Loss: 0.06254

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.58194
Value Function Update Magnitude: 0.75960

Collected Steps per Second: 22,481.19679
Overall Steps per Second: 10,774.20040

Timestep Collection Time: 2.22622
Timestep Consumption Time: 2.41895
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.64517

Cumulative Model Updates: 71,930
Cumulative Timesteps: 599,843,372

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,502.69418
Policy Entropy: 3.70275
Value Function Loss: 0.06273

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.55521
Value Function Update Magnitude: 0.80907

Collected Steps per Second: 22,976.27572
Overall Steps per Second: 10,807.75033

Timestep Collection Time: 2.17685
Timestep Consumption Time: 2.45094
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62779

Cumulative Model Updates: 71,936
Cumulative Timesteps: 599,893,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 599893388...
Checkpoint 599893388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,597.34727
Policy Entropy: 3.71125
Value Function Loss: 0.06229

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11731
Policy Update Magnitude: 0.54278
Value Function Update Magnitude: 0.80867

Collected Steps per Second: 22,677.19580
Overall Steps per Second: 10,709.21061

Timestep Collection Time: 2.20565
Timestep Consumption Time: 2.46491
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.67056

Cumulative Model Updates: 71,942
Cumulative Timesteps: 599,943,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,652.37378
Policy Entropy: 3.70219
Value Function Loss: 0.06767

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.64129
Value Function Update Magnitude: 0.74060

Collected Steps per Second: 22,985.41640
Overall Steps per Second: 10,852.99573

Timestep Collection Time: 2.17581
Timestep Consumption Time: 2.43231
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.60813

Cumulative Model Updates: 71,948
Cumulative Timesteps: 599,993,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 599993418...
Checkpoint 599993418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,353.07588
Policy Entropy: 3.70545
Value Function Loss: 0.06798

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.61491
Value Function Update Magnitude: 0.68489

Collected Steps per Second: 22,569.51572
Overall Steps per Second: 10,699.93177

Timestep Collection Time: 2.21644
Timestep Consumption Time: 2.45873
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.67517

Cumulative Model Updates: 71,954
Cumulative Timesteps: 600,043,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,399.81798
Policy Entropy: 3.70729
Value Function Loss: 0.06833

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.59156
Value Function Update Magnitude: 0.65613

Collected Steps per Second: 23,211.88038
Overall Steps per Second: 10,926.78938

Timestep Collection Time: 2.15510
Timestep Consumption Time: 2.42300
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.57811

Cumulative Model Updates: 71,960
Cumulative Timesteps: 600,093,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 600093466...
Checkpoint 600093466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,902.57912
Policy Entropy: 3.71209
Value Function Loss: 0.06516

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.57904
Value Function Update Magnitude: 0.66865

Collected Steps per Second: 22,565.91482
Overall Steps per Second: 10,582.42107

Timestep Collection Time: 2.21715
Timestep Consumption Time: 2.51069
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.72784

Cumulative Model Updates: 71,966
Cumulative Timesteps: 600,143,498

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,445.38102
Policy Entropy: 3.70675
Value Function Loss: 0.06574

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.55656
Value Function Update Magnitude: 0.69938

Collected Steps per Second: 22,719.69333
Overall Steps per Second: 10,686.42510

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.47969
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.68183

Cumulative Model Updates: 71,972
Cumulative Timesteps: 600,193,530

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 600193530...
Checkpoint 600193530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,680.64214
Policy Entropy: 3.71450
Value Function Loss: 0.06658

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.50060
Value Function Update Magnitude: 0.78054

Collected Steps per Second: 22,752.79846
Overall Steps per Second: 10,823.61501

Timestep Collection Time: 2.19885
Timestep Consumption Time: 2.42345
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.62230

Cumulative Model Updates: 71,978
Cumulative Timesteps: 600,243,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,168.20157
Policy Entropy: 3.71275
Value Function Loss: 0.06989

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.48487
Value Function Update Magnitude: 0.86180

Collected Steps per Second: 22,897.03565
Overall Steps per Second: 10,725.03556

Timestep Collection Time: 2.18500
Timestep Consumption Time: 2.47979
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.66479

Cumulative Model Updates: 71,984
Cumulative Timesteps: 600,293,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 600293590...
Checkpoint 600293590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,962.72243
Policy Entropy: 3.71788
Value Function Loss: 0.07179

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.48908
Value Function Update Magnitude: 0.88319

Collected Steps per Second: 22,607.19710
Overall Steps per Second: 10,688.37466

Timestep Collection Time: 2.21292
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.68060

Cumulative Model Updates: 71,990
Cumulative Timesteps: 600,343,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,789.75284
Policy Entropy: 3.70730
Value Function Loss: 0.07277

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.49725
Value Function Update Magnitude: 0.82618

Collected Steps per Second: 23,031.26872
Overall Steps per Second: 10,687.28178

Timestep Collection Time: 2.17096
Timestep Consumption Time: 2.50750
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.67846

Cumulative Model Updates: 71,996
Cumulative Timesteps: 600,393,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 600393618...
Checkpoint 600393618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,528.47703
Policy Entropy: 3.70975
Value Function Loss: 0.06905

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.49499
Value Function Update Magnitude: 0.73311

Collected Steps per Second: 21,696.32042
Overall Steps per Second: 10,636.98239

Timestep Collection Time: 2.30472
Timestep Consumption Time: 2.39623
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.70096

Cumulative Model Updates: 72,002
Cumulative Timesteps: 600,443,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,280.79049
Policy Entropy: 3.69921
Value Function Loss: 0.06791

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.60089
Value Function Update Magnitude: 0.72843

Collected Steps per Second: 22,583.78919
Overall Steps per Second: 10,926.36970

Timestep Collection Time: 2.21495
Timestep Consumption Time: 2.36315
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.57810

Cumulative Model Updates: 72,008
Cumulative Timesteps: 600,493,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 600493644...
Checkpoint 600493644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,262.29635
Policy Entropy: 3.69124
Value Function Loss: 0.06507

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.66617
Value Function Update Magnitude: 0.78601

Collected Steps per Second: 21,573.73052
Overall Steps per Second: 10,611.43554

Timestep Collection Time: 2.31810
Timestep Consumption Time: 2.39474
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.71284

Cumulative Model Updates: 72,014
Cumulative Timesteps: 600,543,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,355.27042
Policy Entropy: 3.71448
Value Function Loss: 0.06507

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.56014
Value Function Update Magnitude: 0.86148

Collected Steps per Second: 22,391.24790
Overall Steps per Second: 10,892.83592

Timestep Collection Time: 2.23328
Timestep Consumption Time: 2.35744
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.59072

Cumulative Model Updates: 72,020
Cumulative Timesteps: 600,593,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 600593660...
Checkpoint 600593660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,138.12684
Policy Entropy: 3.72647
Value Function Loss: 0.06330

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.55246
Value Function Update Magnitude: 0.89980

Collected Steps per Second: 21,911.96217
Overall Steps per Second: 10,677.63648

Timestep Collection Time: 2.28268
Timestep Consumption Time: 2.40169
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.68437

Cumulative Model Updates: 72,026
Cumulative Timesteps: 600,643,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,042.46588
Policy Entropy: 3.73214
Value Function Loss: 0.06366

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10949
Policy Update Magnitude: 0.54594
Value Function Update Magnitude: 0.91562

Collected Steps per Second: 22,362.58187
Overall Steps per Second: 10,859.92177

Timestep Collection Time: 2.23668
Timestep Consumption Time: 2.36906
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.60574

Cumulative Model Updates: 72,032
Cumulative Timesteps: 600,693,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 600693696...
Checkpoint 600693696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,657.20723
Policy Entropy: 3.72515
Value Function Loss: 0.06468

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.56443
Value Function Update Magnitude: 0.90359

Collected Steps per Second: 21,594.98498
Overall Steps per Second: 10,555.00626

Timestep Collection Time: 2.31545
Timestep Consumption Time: 2.42183
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.73728

Cumulative Model Updates: 72,038
Cumulative Timesteps: 600,743,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,271.46984
Policy Entropy: 3.70603
Value Function Loss: 0.07033

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.56670
Value Function Update Magnitude: 0.92067

Collected Steps per Second: 22,161.31474
Overall Steps per Second: 10,541.44005

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.48819
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.74546

Cumulative Model Updates: 72,044
Cumulative Timesteps: 600,793,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 600793722...
Checkpoint 600793722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,596.61685
Policy Entropy: 3.70332
Value Function Loss: 0.07300

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.59130
Value Function Update Magnitude: 0.91123

Collected Steps per Second: 22,181.73604
Overall Steps per Second: 10,644.30193

Timestep Collection Time: 2.25564
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.70054

Cumulative Model Updates: 72,050
Cumulative Timesteps: 600,843,756

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,927.81925
Policy Entropy: 3.69958
Value Function Loss: 0.07555

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.76122

Collected Steps per Second: 22,939.46955
Overall Steps per Second: 10,880.71494

Timestep Collection Time: 2.18061
Timestep Consumption Time: 2.41670
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.59731

Cumulative Model Updates: 72,056
Cumulative Timesteps: 600,893,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 600893778...
Checkpoint 600893778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,637.54807
Policy Entropy: 3.70641
Value Function Loss: 0.07188

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.51662
Value Function Update Magnitude: 0.67065

Collected Steps per Second: 22,290.72145
Overall Steps per Second: 10,658.31548

Timestep Collection Time: 2.24398
Timestep Consumption Time: 2.44907
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.69305

Cumulative Model Updates: 72,062
Cumulative Timesteps: 600,943,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,488.18750
Policy Entropy: 3.70987
Value Function Loss: 0.06943

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.54873
Value Function Update Magnitude: 0.77378

Collected Steps per Second: 23,171.81388
Overall Steps per Second: 10,904.34761

Timestep Collection Time: 2.15883
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.58753

Cumulative Model Updates: 72,068
Cumulative Timesteps: 600,993,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 600993822...
Checkpoint 600993822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,385.22315
Policy Entropy: 3.71465
Value Function Loss: 0.06723

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.58809
Value Function Update Magnitude: 0.85362

Collected Steps per Second: 22,469.74797
Overall Steps per Second: 10,687.23129

Timestep Collection Time: 2.22521
Timestep Consumption Time: 2.45327
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.67848

Cumulative Model Updates: 72,074
Cumulative Timesteps: 601,043,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,662.05625
Policy Entropy: 3.71338
Value Function Loss: 0.06587

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.59630
Value Function Update Magnitude: 0.87009

Collected Steps per Second: 23,100.49616
Overall Steps per Second: 10,856.93273

Timestep Collection Time: 2.16515
Timestep Consumption Time: 2.44168
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60683

Cumulative Model Updates: 72,080
Cumulative Timesteps: 601,093,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 601093838...
Checkpoint 601093838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,238.51156
Policy Entropy: 3.70718
Value Function Loss: 0.06580

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.55225
Value Function Update Magnitude: 0.87490

Collected Steps per Second: 22,439.55089
Overall Steps per Second: 10,675.21446

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.45662
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.68581

Cumulative Model Updates: 72,086
Cumulative Timesteps: 601,143,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,292.34876
Policy Entropy: 3.70448
Value Function Loss: 0.06539

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.53384
Value Function Update Magnitude: 0.88644

Collected Steps per Second: 22,975.29416
Overall Steps per Second: 10,830.18760

Timestep Collection Time: 2.17625
Timestep Consumption Time: 2.44047
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61673

Cumulative Model Updates: 72,092
Cumulative Timesteps: 601,193,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 601193860...
Checkpoint 601193860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,868.70355
Policy Entropy: 3.70691
Value Function Loss: 0.06794

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.53573
Value Function Update Magnitude: 0.87244

Collected Steps per Second: 22,591.47102
Overall Steps per Second: 10,741.02206

Timestep Collection Time: 2.21376
Timestep Consumption Time: 2.44241
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.65617

Cumulative Model Updates: 72,098
Cumulative Timesteps: 601,243,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,470.30518
Policy Entropy: 3.70597
Value Function Loss: 0.06862

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.53400
Value Function Update Magnitude: 0.88590

Collected Steps per Second: 23,103.04759
Overall Steps per Second: 10,870.41807

Timestep Collection Time: 2.16543
Timestep Consumption Time: 2.43679
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60221

Cumulative Model Updates: 72,104
Cumulative Timesteps: 601,293,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 601293900...
Checkpoint 601293900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,844.91077
Policy Entropy: 3.69867
Value Function Loss: 0.07108

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.59463
Value Function Update Magnitude: 0.89779

Collected Steps per Second: 22,345.19798
Overall Steps per Second: 10,646.77600

Timestep Collection Time: 2.23896
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.69908

Cumulative Model Updates: 72,110
Cumulative Timesteps: 601,343,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,643.34112
Policy Entropy: 3.69552
Value Function Loss: 0.06816

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.62906
Value Function Update Magnitude: 0.88589

Collected Steps per Second: 22,851.77779
Overall Steps per Second: 10,804.24635

Timestep Collection Time: 2.18898
Timestep Consumption Time: 2.44087
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.62985

Cumulative Model Updates: 72,116
Cumulative Timesteps: 601,393,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 601393952...
Checkpoint 601393952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,724.05908
Policy Entropy: 3.67812
Value Function Loss: 0.07258

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.54424
Value Function Update Magnitude: 0.86186

Collected Steps per Second: 22,371.78902
Overall Steps per Second: 10,713.43815

Timestep Collection Time: 2.23523
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.66760

Cumulative Model Updates: 72,122
Cumulative Timesteps: 601,443,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,147.54587
Policy Entropy: 3.69125
Value Function Loss: 0.07012

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11518
Policy Update Magnitude: 0.48242
Value Function Update Magnitude: 0.80553

Collected Steps per Second: 23,054.53400
Overall Steps per Second: 10,878.39352

Timestep Collection Time: 2.16946
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.59774

Cumulative Model Updates: 72,128
Cumulative Timesteps: 601,493,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 601493974...
Checkpoint 601493974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,296.05693
Policy Entropy: 3.69478
Value Function Loss: 0.06889

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.49260
Value Function Update Magnitude: 0.79737

Collected Steps per Second: 22,357.95939
Overall Steps per Second: 10,744.67344

Timestep Collection Time: 2.23759
Timestep Consumption Time: 2.41848
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.65607

Cumulative Model Updates: 72,134
Cumulative Timesteps: 601,544,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,855.82361
Policy Entropy: 3.70824
Value Function Loss: 0.06813

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.50443
Value Function Update Magnitude: 0.79544

Collected Steps per Second: 23,095.81012
Overall Steps per Second: 10,929.28081

Timestep Collection Time: 2.16559
Timestep Consumption Time: 2.41074
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.57633

Cumulative Model Updates: 72,140
Cumulative Timesteps: 601,594,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 601594018...
Checkpoint 601594018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,892.34971
Policy Entropy: 3.70364
Value Function Loss: 0.06741

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.59284
Value Function Update Magnitude: 0.75367

Collected Steps per Second: 22,425.65197
Overall Steps per Second: 10,560.61492

Timestep Collection Time: 2.23004
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.73552

Cumulative Model Updates: 72,146
Cumulative Timesteps: 601,644,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,056.05546
Policy Entropy: 3.69695
Value Function Loss: 0.06843

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.64789
Value Function Update Magnitude: 0.78284

Collected Steps per Second: 22,930.81387
Overall Steps per Second: 10,834.16343

Timestep Collection Time: 2.18091
Timestep Consumption Time: 2.43505
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61595

Cumulative Model Updates: 72,152
Cumulative Timesteps: 601,694,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 601694038...
Checkpoint 601694038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,352.89697
Policy Entropy: 3.70236
Value Function Loss: 0.06531

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.50177
Value Function Update Magnitude: 0.74903

Collected Steps per Second: 22,408.08666
Overall Steps per Second: 10,712.99756

Timestep Collection Time: 2.23214
Timestep Consumption Time: 2.43677
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.66891

Cumulative Model Updates: 72,158
Cumulative Timesteps: 601,744,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,692.29647
Policy Entropy: 3.71002
Value Function Loss: 0.06713

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.67662

Collected Steps per Second: 23,140.23654
Overall Steps per Second: 10,892.93862

Timestep Collection Time: 2.16074
Timestep Consumption Time: 2.42939
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.59013

Cumulative Model Updates: 72,164
Cumulative Timesteps: 601,794,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 601794056...
Checkpoint 601794056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,905.12739
Policy Entropy: 3.71998
Value Function Loss: 0.06914

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.69486
Value Function Update Magnitude: 0.61669

Collected Steps per Second: 22,638.47229
Overall Steps per Second: 10,683.14138

Timestep Collection Time: 2.20863
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.68027

Cumulative Model Updates: 72,170
Cumulative Timesteps: 601,844,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.75899
Policy Entropy: 3.71499
Value Function Loss: 0.06887

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.72872
Value Function Update Magnitude: 0.58686

Collected Steps per Second: 22,907.80125
Overall Steps per Second: 10,833.40824

Timestep Collection Time: 2.18327
Timestep Consumption Time: 2.43337
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.61665

Cumulative Model Updates: 72,176
Cumulative Timesteps: 601,894,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 601894070...
Checkpoint 601894070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,284.44311
Policy Entropy: 3.72760
Value Function Loss: 0.06566

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.69410
Value Function Update Magnitude: 0.58356

Collected Steps per Second: 22,450.14721
Overall Steps per Second: 10,666.96839

Timestep Collection Time: 2.22903
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.69130

Cumulative Model Updates: 72,182
Cumulative Timesteps: 601,944,112

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,103.52579
Policy Entropy: 3.72025
Value Function Loss: 0.06086

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.61692
Value Function Update Magnitude: 0.66851

Collected Steps per Second: 23,384.90984
Overall Steps per Second: 10,936.68011

Timestep Collection Time: 2.13924
Timestep Consumption Time: 2.43491
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.57415

Cumulative Model Updates: 72,188
Cumulative Timesteps: 601,994,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 601994138...
Checkpoint 601994138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,708.50062
Policy Entropy: 3.72622
Value Function Loss: 0.05962

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.60406
Value Function Update Magnitude: 0.70392

Collected Steps per Second: 21,883.62679
Overall Steps per Second: 10,644.43941

Timestep Collection Time: 2.28518
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.69804

Cumulative Model Updates: 72,194
Cumulative Timesteps: 602,044,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,956.55362
Policy Entropy: 3.70557
Value Function Loss: 0.06016

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.58927
Value Function Update Magnitude: 0.62608

Collected Steps per Second: 22,270.67588
Overall Steps per Second: 10,841.44482

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.36815
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.61451

Cumulative Model Updates: 72,200
Cumulative Timesteps: 602,094,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 602094174...
Checkpoint 602094174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,672.83429
Policy Entropy: 3.71295
Value Function Loss: 0.05857

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.58971
Value Function Update Magnitude: 0.71014

Collected Steps per Second: 21,732.28412
Overall Steps per Second: 10,753.53246

Timestep Collection Time: 2.30146
Timestep Consumption Time: 2.34966
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.65112

Cumulative Model Updates: 72,206
Cumulative Timesteps: 602,144,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,253.79291
Policy Entropy: 3.73466
Value Function Loss: 0.05803

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.61328
Value Function Update Magnitude: 0.71285

Collected Steps per Second: 22,260.80338
Overall Steps per Second: 10,879.56567

Timestep Collection Time: 2.24727
Timestep Consumption Time: 2.35089
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.59816

Cumulative Model Updates: 72,212
Cumulative Timesteps: 602,194,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 602194216...
Checkpoint 602194216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,137.96611
Policy Entropy: 3.73971
Value Function Loss: 0.05844

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.66807

Collected Steps per Second: 21,963.31506
Overall Steps per Second: 10,639.43982

Timestep Collection Time: 2.27762
Timestep Consumption Time: 2.42414
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.70175

Cumulative Model Updates: 72,218
Cumulative Timesteps: 602,244,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,596.73937
Policy Entropy: 3.73911
Value Function Loss: 0.05966

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.59246
Value Function Update Magnitude: 0.61744

Collected Steps per Second: 22,505.51296
Overall Steps per Second: 10,793.69140

Timestep Collection Time: 2.22186
Timestep Consumption Time: 2.41085
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.63271

Cumulative Model Updates: 72,224
Cumulative Timesteps: 602,294,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 602294244...
Checkpoint 602294244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,637.30107
Policy Entropy: 3.71806
Value Function Loss: 0.06249

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.60220
Value Function Update Magnitude: 0.61858

Collected Steps per Second: 22,422.52373
Overall Steps per Second: 10,723.48125

Timestep Collection Time: 2.23079
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.66453

Cumulative Model Updates: 72,230
Cumulative Timesteps: 602,344,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,325.46074
Policy Entropy: 3.73194
Value Function Loss: 0.06253

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.56176
Value Function Update Magnitude: 0.63696

Collected Steps per Second: 23,118.73501
Overall Steps per Second: 10,955.88845

Timestep Collection Time: 2.16370
Timestep Consumption Time: 2.40206
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.56576

Cumulative Model Updates: 72,236
Cumulative Timesteps: 602,394,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 602394286...
Checkpoint 602394286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,393.96692
Policy Entropy: 3.72593
Value Function Loss: 0.06397

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07298
Policy Update Magnitude: 0.56342
Value Function Update Magnitude: 0.67447

Collected Steps per Second: 22,765.56967
Overall Steps per Second: 10,722.20417

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.46732
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.66397

Cumulative Model Updates: 72,242
Cumulative Timesteps: 602,444,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.40590
Policy Entropy: 3.73483
Value Function Loss: 0.06294

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.68116
Value Function Update Magnitude: 0.70144

Collected Steps per Second: 23,301.75715
Overall Steps per Second: 10,788.96106

Timestep Collection Time: 2.14653
Timestep Consumption Time: 2.48950
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.63603

Cumulative Model Updates: 72,248
Cumulative Timesteps: 602,494,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 602494312...
Checkpoint 602494312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,701.88382
Policy Entropy: 3.71972
Value Function Loss: 0.06393

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.68626
Value Function Update Magnitude: 0.69244

Collected Steps per Second: 22,472.29773
Overall Steps per Second: 10,628.89747

Timestep Collection Time: 2.22621
Timestep Consumption Time: 2.48058
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.70679

Cumulative Model Updates: 72,254
Cumulative Timesteps: 602,544,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,550.71566
Policy Entropy: 3.71729
Value Function Loss: 0.06439

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.59407
Value Function Update Magnitude: 0.69744

Collected Steps per Second: 22,673.25934
Overall Steps per Second: 10,849.38703

Timestep Collection Time: 2.20568
Timestep Consumption Time: 2.40379
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.60948

Cumulative Model Updates: 72,260
Cumulative Timesteps: 602,594,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 602594350...
Checkpoint 602594350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,936.14511
Policy Entropy: 3.71372
Value Function Loss: 0.06219

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.55538
Value Function Update Magnitude: 0.68759

Collected Steps per Second: 22,776.27355
Overall Steps per Second: 10,708.73135

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.47451
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.67039

Cumulative Model Updates: 72,266
Cumulative Timesteps: 602,644,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,453.87721
Policy Entropy: 3.72138
Value Function Loss: 0.06235

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06865
Policy Update Magnitude: 0.61428
Value Function Update Magnitude: 0.64699

Collected Steps per Second: 22,955.23101
Overall Steps per Second: 10,827.53595

Timestep Collection Time: 2.17859
Timestep Consumption Time: 2.44019
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.61878

Cumulative Model Updates: 72,272
Cumulative Timesteps: 602,694,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 602694374...
Checkpoint 602694374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,739.21971
Policy Entropy: 3.71170
Value Function Loss: 0.06314

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07303
Policy Update Magnitude: 0.66985
Value Function Update Magnitude: 0.65595

Collected Steps per Second: 22,327.67408
Overall Steps per Second: 10,684.37824

Timestep Collection Time: 2.24018
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.68141

Cumulative Model Updates: 72,278
Cumulative Timesteps: 602,744,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,721.32361
Policy Entropy: 3.69838
Value Function Loss: 0.06614

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.66401
Value Function Update Magnitude: 0.65427

Collected Steps per Second: 22,944.72228
Overall Steps per Second: 10,871.79068

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.42010
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.59943

Cumulative Model Updates: 72,284
Cumulative Timesteps: 602,794,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 602794396...
Checkpoint 602794396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,604.95572
Policy Entropy: 3.69276
Value Function Loss: 0.06733

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.61927

Collected Steps per Second: 22,414.77023
Overall Steps per Second: 10,736.15655

Timestep Collection Time: 2.23139
Timestep Consumption Time: 2.42726
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.65865

Cumulative Model Updates: 72,290
Cumulative Timesteps: 602,844,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,217.87074
Policy Entropy: 3.70307
Value Function Loss: 0.06490

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.50569
Value Function Update Magnitude: 0.63326

Collected Steps per Second: 23,076.76050
Overall Steps per Second: 10,836.11336

Timestep Collection Time: 2.16703
Timestep Consumption Time: 2.44791
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61494

Cumulative Model Updates: 72,296
Cumulative Timesteps: 602,894,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 602894420...
Checkpoint 602894420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,568.32743
Policy Entropy: 3.71082
Value Function Loss: 0.06435

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.50405
Value Function Update Magnitude: 0.66533

Collected Steps per Second: 22,513.75830
Overall Steps per Second: 10,663.49688

Timestep Collection Time: 2.22264
Timestep Consumption Time: 2.47000
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.69264

Cumulative Model Updates: 72,302
Cumulative Timesteps: 602,944,460

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,389.60797
Policy Entropy: 3.70505
Value Function Loss: 0.06345

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.47930
Value Function Update Magnitude: 0.70759

Collected Steps per Second: 22,947.96175
Overall Steps per Second: 10,855.25856

Timestep Collection Time: 2.17893
Timestep Consumption Time: 2.42732
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.60625

Cumulative Model Updates: 72,308
Cumulative Timesteps: 602,994,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 602994462...
Checkpoint 602994462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,284.27922
Policy Entropy: 3.69877
Value Function Loss: 0.06495

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.47979
Value Function Update Magnitude: 0.68604

Collected Steps per Second: 22,651.28785
Overall Steps per Second: 10,731.27833

Timestep Collection Time: 2.20756
Timestep Consumption Time: 2.45209
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.65965

Cumulative Model Updates: 72,314
Cumulative Timesteps: 603,044,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,212.31970
Policy Entropy: 3.68884
Value Function Loss: 0.06581

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.49608
Value Function Update Magnitude: 0.65058

Collected Steps per Second: 22,917.88651
Overall Steps per Second: 10,824.69214

Timestep Collection Time: 2.18266
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62110

Cumulative Model Updates: 72,320
Cumulative Timesteps: 603,094,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 603094488...
Checkpoint 603094488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,063.57636
Policy Entropy: 3.69456
Value Function Loss: 0.06492

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.52537
Value Function Update Magnitude: 0.66210

Collected Steps per Second: 22,522.25891
Overall Steps per Second: 10,718.19099

Timestep Collection Time: 2.22136
Timestep Consumption Time: 2.44641
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.66777

Cumulative Model Updates: 72,326
Cumulative Timesteps: 603,144,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,489.46520
Policy Entropy: 3.69638
Value Function Loss: 0.06464

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.64099
Value Function Update Magnitude: 0.69008

Collected Steps per Second: 22,855.89885
Overall Steps per Second: 10,830.47477

Timestep Collection Time: 2.18832
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.61808

Cumulative Model Updates: 72,332
Cumulative Timesteps: 603,194,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 603194534...
Checkpoint 603194534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,353.82269
Policy Entropy: 3.70886
Value Function Loss: 0.06451

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.63778
Value Function Update Magnitude: 0.65234

Collected Steps per Second: 22,600.82970
Overall Steps per Second: 10,668.45157

Timestep Collection Time: 2.21302
Timestep Consumption Time: 2.47520
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.68822

Cumulative Model Updates: 72,338
Cumulative Timesteps: 603,244,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,570.89625
Policy Entropy: 3.69960
Value Function Loss: 0.06557

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.52596
Value Function Update Magnitude: 0.68043

Collected Steps per Second: 22,896.36027
Overall Steps per Second: 10,711.86537

Timestep Collection Time: 2.18375
Timestep Consumption Time: 2.48397
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.66772

Cumulative Model Updates: 72,344
Cumulative Timesteps: 603,294,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 603294550...
Checkpoint 603294550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,609.22983
Policy Entropy: 3.70635
Value Function Loss: 0.06716

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.50966
Value Function Update Magnitude: 0.71491

Collected Steps per Second: 22,283.06949
Overall Steps per Second: 10,593.03207

Timestep Collection Time: 2.24413
Timestep Consumption Time: 2.47652
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.72065

Cumulative Model Updates: 72,350
Cumulative Timesteps: 603,344,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,502.09761
Policy Entropy: 3.69772
Value Function Loss: 0.06582

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.79578

Collected Steps per Second: 23,413.35612
Overall Steps per Second: 10,781.00045

Timestep Collection Time: 2.13622
Timestep Consumption Time: 2.50306
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.63927

Cumulative Model Updates: 72,356
Cumulative Timesteps: 603,394,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 603394572...
Checkpoint 603394572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,259.50013
Policy Entropy: 3.68902
Value Function Loss: 0.06620

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.80371

Collected Steps per Second: 22,383.69673
Overall Steps per Second: 10,590.96357

Timestep Collection Time: 2.23386
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.72119

Cumulative Model Updates: 72,362
Cumulative Timesteps: 603,444,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,398.81750
Policy Entropy: 3.69338
Value Function Loss: 0.06372

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.67564
Value Function Update Magnitude: 0.77257

Collected Steps per Second: 23,323.88157
Overall Steps per Second: 10,928.66666

Timestep Collection Time: 2.14493
Timestep Consumption Time: 2.43276
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.57769

Cumulative Model Updates: 72,368
Cumulative Timesteps: 603,494,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 603494602...
Checkpoint 603494602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,373.84432
Policy Entropy: 3.69360
Value Function Loss: 0.06521

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.71985
Value Function Update Magnitude: 0.77079

Collected Steps per Second: 22,310.54894
Overall Steps per Second: 10,614.73895

Timestep Collection Time: 2.24145
Timestep Consumption Time: 2.46973
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.71119

Cumulative Model Updates: 72,374
Cumulative Timesteps: 603,544,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,338.63945
Policy Entropy: 3.69240
Value Function Loss: 0.06419

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.70228
Value Function Update Magnitude: 0.81405

Collected Steps per Second: 22,887.07667
Overall Steps per Second: 10,828.93124

Timestep Collection Time: 2.18578
Timestep Consumption Time: 2.43389
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.61966

Cumulative Model Updates: 72,380
Cumulative Timesteps: 603,594,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 603594636...
Checkpoint 603594636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,231.82742
Policy Entropy: 3.68951
Value Function Loss: 0.06394

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.61837
Value Function Update Magnitude: 0.83445

Collected Steps per Second: 22,619.33244
Overall Steps per Second: 10,720.43293

Timestep Collection Time: 2.21191
Timestep Consumption Time: 2.45506
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.66698

Cumulative Model Updates: 72,386
Cumulative Timesteps: 603,644,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,380.57943
Policy Entropy: 3.68875
Value Function Loss: 0.06658

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08284
Policy Update Magnitude: 0.65109
Value Function Update Magnitude: 0.83354

Collected Steps per Second: 23,047.38472
Overall Steps per Second: 10,845.11286

Timestep Collection Time: 2.16962
Timestep Consumption Time: 2.44112
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.61074

Cumulative Model Updates: 72,392
Cumulative Timesteps: 603,694,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 603694672...
Checkpoint 603694672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,299.61256
Policy Entropy: 3.68497
Value Function Loss: 0.06865

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.59395
Value Function Update Magnitude: 0.77815

Collected Steps per Second: 22,305.29268
Overall Steps per Second: 10,676.43618

Timestep Collection Time: 2.24198
Timestep Consumption Time: 2.44198
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.68396

Cumulative Model Updates: 72,398
Cumulative Timesteps: 603,744,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,445.68756
Policy Entropy: 3.69703
Value Function Loss: 0.06764

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.45082
Value Function Update Magnitude: 0.73563

Collected Steps per Second: 23,006.47602
Overall Steps per Second: 10,947.22588

Timestep Collection Time: 2.17434
Timestep Consumption Time: 2.39522
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.56956

Cumulative Model Updates: 72,404
Cumulative Timesteps: 603,794,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 603794704...
Checkpoint 603794704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,875.09215
Policy Entropy: 3.70712
Value Function Loss: 0.06766

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.45069
Value Function Update Magnitude: 0.68729

Collected Steps per Second: 22,658.68076
Overall Steps per Second: 10,638.41870

Timestep Collection Time: 2.20745
Timestep Consumption Time: 2.49418
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.70164

Cumulative Model Updates: 72,410
Cumulative Timesteps: 603,844,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.68887
Policy Entropy: 3.71358
Value Function Loss: 0.06781

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.51463
Value Function Update Magnitude: 0.63999

Collected Steps per Second: 22,979.40914
Overall Steps per Second: 10,832.00014

Timestep Collection Time: 2.17638
Timestep Consumption Time: 2.44068
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.61706

Cumulative Model Updates: 72,416
Cumulative Timesteps: 603,894,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 603894734...
Checkpoint 603894734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,419.95604
Policy Entropy: 3.72163
Value Function Loss: 0.06660

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.65948
Value Function Update Magnitude: 0.64739

Collected Steps per Second: 22,548.43374
Overall Steps per Second: 10,683.10646

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.68197

Cumulative Model Updates: 72,422
Cumulative Timesteps: 603,944,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,548.60526
Policy Entropy: 3.71763
Value Function Loss: 0.06667

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.66228
Value Function Update Magnitude: 0.69831

Collected Steps per Second: 23,299.29823
Overall Steps per Second: 10,937.26997

Timestep Collection Time: 2.14624
Timestep Consumption Time: 2.42583
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.57207

Cumulative Model Updates: 72,428
Cumulative Timesteps: 603,994,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 603994758...
Checkpoint 603994758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,741.63838
Policy Entropy: 3.70901
Value Function Loss: 0.06438

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.76024

Collected Steps per Second: 22,623.09063
Overall Steps per Second: 10,681.48981

Timestep Collection Time: 2.21066
Timestep Consumption Time: 2.47146
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.68212

Cumulative Model Updates: 72,434
Cumulative Timesteps: 604,044,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,237.71417
Policy Entropy: 3.71516
Value Function Loss: 0.06564

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.50581
Value Function Update Magnitude: 0.83009

Collected Steps per Second: 23,090.41531
Overall Steps per Second: 10,892.41717

Timestep Collection Time: 2.16575
Timestep Consumption Time: 2.42534
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.59108

Cumulative Model Updates: 72,440
Cumulative Timesteps: 604,094,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 604094778...
Checkpoint 604094778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,643.38007
Policy Entropy: 3.70748
Value Function Loss: 0.06544

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.51558
Value Function Update Magnitude: 0.84106

Collected Steps per Second: 22,368.52666
Overall Steps per Second: 10,596.36833

Timestep Collection Time: 2.23636
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.72086

Cumulative Model Updates: 72,446
Cumulative Timesteps: 604,144,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,984.70405
Policy Entropy: 3.69293
Value Function Loss: 0.06869

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.52588
Value Function Update Magnitude: 0.81011

Collected Steps per Second: 23,028.15496
Overall Steps per Second: 10,851.34961

Timestep Collection Time: 2.17238
Timestep Consumption Time: 2.43773
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.61012

Cumulative Model Updates: 72,452
Cumulative Timesteps: 604,194,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 604194828...
Checkpoint 604194828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,082.87224
Policy Entropy: 3.69206
Value Function Loss: 0.06883

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.57255
Value Function Update Magnitude: 0.77360

Collected Steps per Second: 22,275.35235
Overall Steps per Second: 10,686.30205

Timestep Collection Time: 2.24589
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.68151

Cumulative Model Updates: 72,458
Cumulative Timesteps: 604,244,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,561.68878
Policy Entropy: 3.69815
Value Function Loss: 0.06886

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.57759
Value Function Update Magnitude: 0.77252

Collected Steps per Second: 22,780.11276
Overall Steps per Second: 10,683.34382

Timestep Collection Time: 2.19595
Timestep Consumption Time: 2.48648
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.68243

Cumulative Model Updates: 72,464
Cumulative Timesteps: 604,294,880

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 604294880...
Checkpoint 604294880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,728.72073
Policy Entropy: 3.70743
Value Function Loss: 0.06911

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.59161
Value Function Update Magnitude: 0.72731

Collected Steps per Second: 22,587.23348
Overall Steps per Second: 10,673.04677

Timestep Collection Time: 2.21453
Timestep Consumption Time: 2.47205
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.68657

Cumulative Model Updates: 72,470
Cumulative Timesteps: 604,344,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,005.61592
Policy Entropy: 3.69958
Value Function Loss: 0.06866

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.53137
Value Function Update Magnitude: 0.79224

Collected Steps per Second: 22,793.14388
Overall Steps per Second: 10,669.17902

Timestep Collection Time: 2.19364
Timestep Consumption Time: 2.49275
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68640

Cumulative Model Updates: 72,476
Cumulative Timesteps: 604,394,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 604394900...
Checkpoint 604394900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,280.30560
Policy Entropy: 3.68798
Value Function Loss: 0.06970

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.83989

Collected Steps per Second: 22,788.82662
Overall Steps per Second: 10,623.37845

Timestep Collection Time: 2.19494
Timestep Consumption Time: 2.51355
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.70848

Cumulative Model Updates: 72,482
Cumulative Timesteps: 604,444,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,921.44393
Policy Entropy: 3.67756
Value Function Loss: 0.06919

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.53658
Value Function Update Magnitude: 0.76082

Collected Steps per Second: 23,044.91686
Overall Steps per Second: 10,830.38126

Timestep Collection Time: 2.17080
Timestep Consumption Time: 2.44824
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61904

Cumulative Model Updates: 72,488
Cumulative Timesteps: 604,494,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 604494946...
Checkpoint 604494946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,338.92714
Policy Entropy: 3.68634
Value Function Loss: 0.06806

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.59029
Value Function Update Magnitude: 0.74358

Collected Steps per Second: 22,414.67096
Overall Steps per Second: 10,733.08079

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.42830
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.65943

Cumulative Model Updates: 72,494
Cumulative Timesteps: 604,544,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,315.84241
Policy Entropy: 3.68459
Value Function Loss: 0.06964

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.62641
Value Function Update Magnitude: 0.81814

Collected Steps per Second: 22,783.84725
Overall Steps per Second: 10,684.11508

Timestep Collection Time: 2.19542
Timestep Consumption Time: 2.48630
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.68172

Cumulative Model Updates: 72,500
Cumulative Timesteps: 604,594,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 604594976...
Checkpoint 604594976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,279.30366
Policy Entropy: 3.68420
Value Function Loss: 0.06883

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.61073
Value Function Update Magnitude: 0.80068

Collected Steps per Second: 22,647.31136
Overall Steps per Second: 10,815.47823

Timestep Collection Time: 2.20786
Timestep Consumption Time: 2.41533
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.62319

Cumulative Model Updates: 72,506
Cumulative Timesteps: 604,644,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,824.52462
Policy Entropy: 3.69634
Value Function Loss: 0.06798

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08259
Policy Update Magnitude: 0.56972
Value Function Update Magnitude: 0.80109

Collected Steps per Second: 23,015.91706
Overall Steps per Second: 10,716.06379

Timestep Collection Time: 2.17328
Timestep Consumption Time: 2.49448
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.66776

Cumulative Model Updates: 72,512
Cumulative Timesteps: 604,694,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 604694998...
Checkpoint 604694998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,445.33797
Policy Entropy: 3.69162
Value Function Loss: 0.06574

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.76488

Collected Steps per Second: 22,621.18784
Overall Steps per Second: 10,838.30557

Timestep Collection Time: 2.21049
Timestep Consumption Time: 2.40314
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61364

Cumulative Model Updates: 72,518
Cumulative Timesteps: 604,745,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,002.94849
Policy Entropy: 3.69258
Value Function Loss: 0.06586

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.51254
Value Function Update Magnitude: 0.72590

Collected Steps per Second: 22,707.00679
Overall Steps per Second: 10,718.30907

Timestep Collection Time: 2.20276
Timestep Consumption Time: 2.46384
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.66659

Cumulative Model Updates: 72,524
Cumulative Timesteps: 604,795,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 604795020...
Checkpoint 604795020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,449.85029
Policy Entropy: 3.69092
Value Function Loss: 0.06657

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.47708
Value Function Update Magnitude: 0.73313

Collected Steps per Second: 22,903.72534
Overall Steps per Second: 10,857.81941

Timestep Collection Time: 2.18314
Timestep Consumption Time: 2.42202
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.60516

Cumulative Model Updates: 72,530
Cumulative Timesteps: 604,845,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,743.95812
Policy Entropy: 3.68316
Value Function Loss: 0.06666

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.48079
Value Function Update Magnitude: 0.82790

Collected Steps per Second: 22,828.96647
Overall Steps per Second: 10,864.80513

Timestep Collection Time: 2.19134
Timestep Consumption Time: 2.41307
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.60441

Cumulative Model Updates: 72,536
Cumulative Timesteps: 604,895,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 604895048...
Checkpoint 604895048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,932.44058
Policy Entropy: 3.68766
Value Function Loss: 0.06777

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06944
Policy Update Magnitude: 0.56161
Value Function Update Magnitude: 0.80096

Collected Steps per Second: 22,691.32779
Overall Steps per Second: 10,734.11461

Timestep Collection Time: 2.20375
Timestep Consumption Time: 2.45486
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.65861

Cumulative Model Updates: 72,542
Cumulative Timesteps: 604,945,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,687.09628
Policy Entropy: 3.68477
Value Function Loss: 0.06662

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07730
Policy Update Magnitude: 0.67130
Value Function Update Magnitude: 0.78417

Collected Steps per Second: 22,878.52302
Overall Steps per Second: 10,834.66696

Timestep Collection Time: 2.18563
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.61519

Cumulative Model Updates: 72,548
Cumulative Timesteps: 604,995,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 604995058...
Checkpoint 604995058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,928.51026
Policy Entropy: 3.69074
Value Function Loss: 0.06608

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.61372
Value Function Update Magnitude: 0.83526

Collected Steps per Second: 22,152.81544
Overall Steps per Second: 10,671.84864

Timestep Collection Time: 2.25732
Timestep Consumption Time: 2.42847
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.68579

Cumulative Model Updates: 72,554
Cumulative Timesteps: 605,045,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.17036
Policy Entropy: 3.68422
Value Function Loss: 0.06422

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.86456

Collected Steps per Second: 23,059.58367
Overall Steps per Second: 10,862.83077

Timestep Collection Time: 2.16838
Timestep Consumption Time: 2.43465
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60304

Cumulative Model Updates: 72,560
Cumulative Timesteps: 605,095,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 605095066...
Checkpoint 605095066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,051.96662
Policy Entropy: 3.68610
Value Function Loss: 0.06697

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.61955
Value Function Update Magnitude: 0.85691

Collected Steps per Second: 22,351.18381
Overall Steps per Second: 10,712.66629

Timestep Collection Time: 2.23738
Timestep Consumption Time: 2.43074
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.66812

Cumulative Model Updates: 72,566
Cumulative Timesteps: 605,145,074

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,557.68574
Policy Entropy: 3.68821
Value Function Loss: 0.06906

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.61017
Value Function Update Magnitude: 0.75806

Collected Steps per Second: 22,918.72077
Overall Steps per Second: 10,845.92793

Timestep Collection Time: 2.18171
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.61021

Cumulative Model Updates: 72,572
Cumulative Timesteps: 605,195,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 605195076...
Checkpoint 605195076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,147.14548
Policy Entropy: 3.69835
Value Function Loss: 0.07017

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.53950
Value Function Update Magnitude: 0.66176

Collected Steps per Second: 22,699.97425
Overall Steps per Second: 10,649.20455

Timestep Collection Time: 2.20309
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.69613

Cumulative Model Updates: 72,578
Cumulative Timesteps: 605,245,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,455.50473
Policy Entropy: 3.70361
Value Function Loss: 0.06693

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.64691

Collected Steps per Second: 23,108.94438
Overall Steps per Second: 10,866.51897

Timestep Collection Time: 2.16462
Timestep Consumption Time: 2.43870
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.60331

Cumulative Model Updates: 72,584
Cumulative Timesteps: 605,295,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 605295108...
Checkpoint 605295108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,389.58942
Policy Entropy: 3.71277
Value Function Loss: 0.06728

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.53238
Value Function Update Magnitude: 0.63517

Collected Steps per Second: 22,470.22480
Overall Steps per Second: 10,769.72337

Timestep Collection Time: 2.22543
Timestep Consumption Time: 2.41777
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.64320

Cumulative Model Updates: 72,590
Cumulative Timesteps: 605,345,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,268.68566
Policy Entropy: 3.70643
Value Function Loss: 0.06820

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.52277
Value Function Update Magnitude: 0.61734

Collected Steps per Second: 23,225.74795
Overall Steps per Second: 10,932.43695

Timestep Collection Time: 2.15278
Timestep Consumption Time: 2.42076
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.57355

Cumulative Model Updates: 72,596
Cumulative Timesteps: 605,395,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 605395114...
Checkpoint 605395114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,418.17178
Policy Entropy: 3.69531
Value Function Loss: 0.07056

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.52095
Value Function Update Magnitude: 0.60223

Collected Steps per Second: 22,377.59335
Overall Steps per Second: 10,578.52716

Timestep Collection Time: 2.23581
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.72958

Cumulative Model Updates: 72,602
Cumulative Timesteps: 605,445,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,110.03717
Policy Entropy: 3.68993
Value Function Loss: 0.07300

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.50889
Value Function Update Magnitude: 0.59971

Collected Steps per Second: 23,190.36702
Overall Steps per Second: 10,880.98597

Timestep Collection Time: 2.15719
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.59756

Cumulative Model Updates: 72,608
Cumulative Timesteps: 605,495,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 605495172...
Checkpoint 605495172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,264.89955
Policy Entropy: 3.68856
Value Function Loss: 0.07480

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.49423
Value Function Update Magnitude: 0.62243

Collected Steps per Second: 22,584.81190
Overall Steps per Second: 10,655.60267

Timestep Collection Time: 2.21485
Timestep Consumption Time: 2.47958
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.69443

Cumulative Model Updates: 72,614
Cumulative Timesteps: 605,545,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,305.95088
Policy Entropy: 3.67926
Value Function Loss: 0.07666

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.49065
Value Function Update Magnitude: 0.63200

Collected Steps per Second: 22,957.95969
Overall Steps per Second: 10,850.52143

Timestep Collection Time: 2.17798
Timestep Consumption Time: 2.43028
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.60826

Cumulative Model Updates: 72,620
Cumulative Timesteps: 605,595,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 605595196...
Checkpoint 605595196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,532.47668
Policy Entropy: 3.68539
Value Function Loss: 0.07556

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14238
Policy Update Magnitude: 0.43444
Value Function Update Magnitude: 0.68626

Collected Steps per Second: 22,647.25766
Overall Steps per Second: 10,671.30884

Timestep Collection Time: 2.20839
Timestep Consumption Time: 2.47838
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.68677

Cumulative Model Updates: 72,626
Cumulative Timesteps: 605,645,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,833.38404
Policy Entropy: 3.68169
Value Function Loss: 0.07307

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.39637
Value Function Update Magnitude: 0.72772

Collected Steps per Second: 21,882.82432
Overall Steps per Second: 10,521.77155

Timestep Collection Time: 2.28526
Timestep Consumption Time: 2.46755
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.75281

Cumulative Model Updates: 72,632
Cumulative Timesteps: 605,695,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 605695218...
Checkpoint 605695218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,508.62702
Policy Entropy: 3.68299
Value Function Loss: 0.07045

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.43489
Value Function Update Magnitude: 0.74923

Collected Steps per Second: 22,593.99180
Overall Steps per Second: 10,596.66583

Timestep Collection Time: 2.21298
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.71847

Cumulative Model Updates: 72,638
Cumulative Timesteps: 605,745,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,600.06813
Policy Entropy: 3.70055
Value Function Loss: 0.06602

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.45031
Value Function Update Magnitude: 0.80650

Collected Steps per Second: 23,028.58689
Overall Steps per Second: 10,852.17959

Timestep Collection Time: 2.17260
Timestep Consumption Time: 2.43771
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.61032

Cumulative Model Updates: 72,644
Cumulative Timesteps: 605,795,250

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 605795250...
Checkpoint 605795250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,052.77049
Policy Entropy: 3.69969
Value Function Loss: 0.06363

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.50089
Value Function Update Magnitude: 0.78458

Collected Steps per Second: 22,657.87381
Overall Steps per Second: 10,705.19847

Timestep Collection Time: 2.20700
Timestep Consumption Time: 2.46419
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.67119

Cumulative Model Updates: 72,650
Cumulative Timesteps: 605,845,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,662.91502
Policy Entropy: 3.71010
Value Function Loss: 0.06268

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.48380
Value Function Update Magnitude: 0.76068

Collected Steps per Second: 22,752.32245
Overall Steps per Second: 10,791.06384

Timestep Collection Time: 2.19881
Timestep Consumption Time: 2.43725
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.63606

Cumulative Model Updates: 72,656
Cumulative Timesteps: 605,895,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 605895284...
Checkpoint 605895284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,317.03614
Policy Entropy: 3.70740
Value Function Loss: 0.06305

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.52432
Value Function Update Magnitude: 0.79427

Collected Steps per Second: 22,464.05791
Overall Steps per Second: 10,721.38952

Timestep Collection Time: 2.22596
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.66395

Cumulative Model Updates: 72,662
Cumulative Timesteps: 605,945,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,113.38280
Policy Entropy: 3.70545
Value Function Loss: 0.06532

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.52870
Value Function Update Magnitude: 0.81423

Collected Steps per Second: 22,837.99708
Overall Steps per Second: 10,852.37103

Timestep Collection Time: 2.19047
Timestep Consumption Time: 2.41921
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.60968

Cumulative Model Updates: 72,668
Cumulative Timesteps: 605,995,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 605995314...
Checkpoint 605995314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,730.41508
Policy Entropy: 3.70477
Value Function Loss: 0.06398

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.45596
Value Function Update Magnitude: 0.79417

Collected Steps per Second: 22,523.46772
Overall Steps per Second: 10,788.71643

Timestep Collection Time: 2.22079
Timestep Consumption Time: 2.41553
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.63633

Cumulative Model Updates: 72,674
Cumulative Timesteps: 606,045,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.85851
Policy Entropy: 3.70854
Value Function Loss: 0.06277

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.45354
Value Function Update Magnitude: 0.79106

Collected Steps per Second: 23,097.62093
Overall Steps per Second: 10,870.94409

Timestep Collection Time: 2.16559
Timestep Consumption Time: 2.43567
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.60126

Cumulative Model Updates: 72,680
Cumulative Timesteps: 606,095,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 606095354...
Checkpoint 606095354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,850.47066
Policy Entropy: 3.70287
Value Function Loss: 0.06366

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.46256
Value Function Update Magnitude: 0.80179

Collected Steps per Second: 22,625.18038
Overall Steps per Second: 10,593.18198

Timestep Collection Time: 2.21090
Timestep Consumption Time: 2.51119
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.72209

Cumulative Model Updates: 72,686
Cumulative Timesteps: 606,145,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,624.42387
Policy Entropy: 3.70194
Value Function Loss: 0.06893

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.45791
Value Function Update Magnitude: 0.67786

Collected Steps per Second: 23,072.55595
Overall Steps per Second: 10,873.93716

Timestep Collection Time: 2.16794
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59999

Cumulative Model Updates: 72,692
Cumulative Timesteps: 606,195,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 606195396...
Checkpoint 606195396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,473.97508
Policy Entropy: 3.70361
Value Function Loss: 0.07181

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.49388
Value Function Update Magnitude: 0.50728

Collected Steps per Second: 22,410.31573
Overall Steps per Second: 10,776.22324

Timestep Collection Time: 2.23236
Timestep Consumption Time: 2.41008
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.64244

Cumulative Model Updates: 72,698
Cumulative Timesteps: 606,245,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,080.28639
Policy Entropy: 3.69977
Value Function Loss: 0.07330

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.51511
Value Function Update Magnitude: 0.45684

Collected Steps per Second: 23,119.53680
Overall Steps per Second: 10,862.36263

Timestep Collection Time: 2.16285
Timestep Consumption Time: 2.44057
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.60342

Cumulative Model Updates: 72,704
Cumulative Timesteps: 606,295,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 606295428...
Checkpoint 606295428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,750.54047
Policy Entropy: 3.69960
Value Function Loss: 0.07159

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.58052
Value Function Update Magnitude: 0.48722

Collected Steps per Second: 22,644.44039
Overall Steps per Second: 10,611.45833

Timestep Collection Time: 2.20805
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.71189

Cumulative Model Updates: 72,710
Cumulative Timesteps: 606,345,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,679.07503
Policy Entropy: 3.69843
Value Function Loss: 0.07085

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.64771
Value Function Update Magnitude: 0.48328

Collected Steps per Second: 23,062.47817
Overall Steps per Second: 10,877.11223

Timestep Collection Time: 2.16872
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.59828

Cumulative Model Updates: 72,716
Cumulative Timesteps: 606,395,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 606395444...
Checkpoint 606395444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,165.38044
Policy Entropy: 3.70621
Value Function Loss: 0.06693

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.68677
Value Function Update Magnitude: 0.54629

Collected Steps per Second: 22,082.04636
Overall Steps per Second: 10,722.08120

Timestep Collection Time: 2.26555
Timestep Consumption Time: 2.40033
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.66589

Cumulative Model Updates: 72,722
Cumulative Timesteps: 606,445,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,059.41405
Policy Entropy: 3.70190
Value Function Loss: 0.06517

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.58027
Value Function Update Magnitude: 0.65926

Collected Steps per Second: 22,923.46174
Overall Steps per Second: 10,916.70179

Timestep Collection Time: 2.18222
Timestep Consumption Time: 2.40012
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.58234

Cumulative Model Updates: 72,728
Cumulative Timesteps: 606,495,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 606495496...
Checkpoint 606495496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,570.58194
Policy Entropy: 3.68626
Value Function Loss: 0.06611

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.48394
Value Function Update Magnitude: 0.71969

Collected Steps per Second: 22,438.16144
Overall Steps per Second: 10,576.68194

Timestep Collection Time: 2.22844
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.72757

Cumulative Model Updates: 72,734
Cumulative Timesteps: 606,545,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,700.54907
Policy Entropy: 3.68596
Value Function Loss: 0.06484

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09836
Policy Update Magnitude: 0.48757
Value Function Update Magnitude: 0.77136

Collected Steps per Second: 22,879.34016
Overall Steps per Second: 10,805.25719

Timestep Collection Time: 2.18590
Timestep Consumption Time: 2.44259
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.62849

Cumulative Model Updates: 72,740
Cumulative Timesteps: 606,595,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 606595510...
Checkpoint 606595510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,464.69617
Policy Entropy: 3.68135
Value Function Loss: 0.06692

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.52833
Value Function Update Magnitude: 0.79226

Collected Steps per Second: 22,453.11054
Overall Steps per Second: 10,739.51334

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.42904
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.65608

Cumulative Model Updates: 72,746
Cumulative Timesteps: 606,645,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,194.34218
Policy Entropy: 3.68720
Value Function Loss: 0.06513

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.51737
Value Function Update Magnitude: 0.80392

Collected Steps per Second: 23,097.95917
Overall Steps per Second: 10,870.96541

Timestep Collection Time: 2.16547
Timestep Consumption Time: 2.43559
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.60106

Cumulative Model Updates: 72,752
Cumulative Timesteps: 606,695,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 606695532...
Checkpoint 606695532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,162.45820
Policy Entropy: 3.67931
Value Function Loss: 0.06776

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.47915
Value Function Update Magnitude: 0.75700

Collected Steps per Second: 22,325.17795
Overall Steps per Second: 10,746.45443

Timestep Collection Time: 2.24025
Timestep Consumption Time: 2.41375
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.65400

Cumulative Model Updates: 72,758
Cumulative Timesteps: 606,745,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,973.37919
Policy Entropy: 3.67044
Value Function Loss: 0.06958

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.50701
Value Function Update Magnitude: 0.68836

Collected Steps per Second: 22,826.94757
Overall Steps per Second: 10,808.27305

Timestep Collection Time: 2.19092
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.62720

Cumulative Model Updates: 72,764
Cumulative Timesteps: 606,795,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 606795558...
Checkpoint 606795558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,958.29688
Policy Entropy: 3.66666
Value Function Loss: 0.07251

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.50378
Value Function Update Magnitude: 0.69443

Collected Steps per Second: 22,347.28839
Overall Steps per Second: 10,714.66746

Timestep Collection Time: 2.23786
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.66743

Cumulative Model Updates: 72,770
Cumulative Timesteps: 606,845,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,840.58204
Policy Entropy: 3.66699
Value Function Loss: 0.07155

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.46876
Value Function Update Magnitude: 0.71651

Collected Steps per Second: 23,089.20274
Overall Steps per Second: 10,903.43270

Timestep Collection Time: 2.16612
Timestep Consumption Time: 2.42088
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.58700

Cumulative Model Updates: 72,776
Cumulative Timesteps: 606,895,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 606895582...
Checkpoint 606895582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,376.49084
Policy Entropy: 3.66989
Value Function Loss: 0.07038

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.45154
Value Function Update Magnitude: 0.71339

Collected Steps per Second: 22,502.35228
Overall Steps per Second: 10,587.99736

Timestep Collection Time: 2.22252
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.72346

Cumulative Model Updates: 72,782
Cumulative Timesteps: 606,945,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,991.48473
Policy Entropy: 3.67549
Value Function Loss: 0.06865

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.44961
Value Function Update Magnitude: 0.74573

Collected Steps per Second: 22,763.99532
Overall Steps per Second: 10,796.96110

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.43585
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.63353

Cumulative Model Updates: 72,788
Cumulative Timesteps: 606,995,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 606995622...
Checkpoint 606995622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,027.58178
Policy Entropy: 3.67260
Value Function Loss: 0.06997

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.52176
Value Function Update Magnitude: 0.73168

Collected Steps per Second: 22,776.43930
Overall Steps per Second: 10,696.71239

Timestep Collection Time: 2.19657
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.67714

Cumulative Model Updates: 72,794
Cumulative Timesteps: 607,045,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,448.29686
Policy Entropy: 3.68162
Value Function Loss: 0.07144

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.55536
Value Function Update Magnitude: 0.81864

Collected Steps per Second: 23,063.67902
Overall Steps per Second: 10,896.24004

Timestep Collection Time: 2.16817
Timestep Consumption Time: 2.42112
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.58929

Cumulative Model Updates: 72,800
Cumulative Timesteps: 607,095,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 607095658...
Checkpoint 607095658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,635.22019
Policy Entropy: 3.68055
Value Function Loss: 0.07284

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.49342
Value Function Update Magnitude: 0.78773

Collected Steps per Second: 22,267.68139
Overall Steps per Second: 10,716.39703

Timestep Collection Time: 2.24675
Timestep Consumption Time: 2.42179
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.66855

Cumulative Model Updates: 72,806
Cumulative Timesteps: 607,145,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,640.95279
Policy Entropy: 3.67844
Value Function Loss: 0.07313

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.47651
Value Function Update Magnitude: 0.69372

Collected Steps per Second: 22,943.89890
Overall Steps per Second: 10,823.28682

Timestep Collection Time: 2.18027
Timestep Consumption Time: 2.44161
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.62189

Cumulative Model Updates: 72,812
Cumulative Timesteps: 607,195,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 607195712...
Checkpoint 607195712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,034.76381
Policy Entropy: 3.66389
Value Function Loss: 0.07190

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.48540
Value Function Update Magnitude: 0.68761

Collected Steps per Second: 22,723.86132
Overall Steps per Second: 10,712.51600

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.46730
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.66781

Cumulative Model Updates: 72,818
Cumulative Timesteps: 607,245,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,161.90871
Policy Entropy: 3.67258
Value Function Loss: 0.07295

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.53948
Value Function Update Magnitude: 0.77893

Collected Steps per Second: 23,115.78682
Overall Steps per Second: 10,882.24780

Timestep Collection Time: 2.16415
Timestep Consumption Time: 2.43288
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.59703

Cumulative Model Updates: 72,824
Cumulative Timesteps: 607,295,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 607295742...
Checkpoint 607295742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,045.71313
Policy Entropy: 3.65948
Value Function Loss: 0.07357

Mean KL Divergence: 0.02053
SB3 Clip Fraction: 0.17183
Policy Update Magnitude: 0.42822
Value Function Update Magnitude: 0.85869

Collected Steps per Second: 22,368.12532
Overall Steps per Second: 10,695.03487

Timestep Collection Time: 2.23622
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.67694

Cumulative Model Updates: 72,830
Cumulative Timesteps: 607,345,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,406.18361
Policy Entropy: 3.68618
Value Function Loss: 0.07166

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.40518
Value Function Update Magnitude: 0.86539

Collected Steps per Second: 22,891.49343
Overall Steps per Second: 10,834.37346

Timestep Collection Time: 2.18527
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.61716

Cumulative Model Updates: 72,836
Cumulative Timesteps: 607,395,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 607395786...
Checkpoint 607395786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,805.73265
Policy Entropy: 3.67570
Value Function Loss: 0.06630

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.49435
Value Function Update Magnitude: 0.87846

Collected Steps per Second: 22,612.38356
Overall Steps per Second: 10,691.52752

Timestep Collection Time: 2.21197
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.67828

Cumulative Model Updates: 72,842
Cumulative Timesteps: 607,445,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,798.78639
Policy Entropy: 3.68287
Value Function Loss: 0.06539

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.53125
Value Function Update Magnitude: 0.82404

Collected Steps per Second: 22,758.45278
Overall Steps per Second: 10,806.06715

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.43102
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.62888

Cumulative Model Updates: 72,848
Cumulative Timesteps: 607,495,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 607495824...
Checkpoint 607495824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,939.04494
Policy Entropy: 3.68933
Value Function Loss: 0.06387

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.53719
Value Function Update Magnitude: 0.83938

Collected Steps per Second: 22,221.30499
Overall Steps per Second: 10,694.48850

Timestep Collection Time: 2.25072
Timestep Consumption Time: 2.42589
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.67661

Cumulative Model Updates: 72,854
Cumulative Timesteps: 607,545,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,935.37063
Policy Entropy: 3.69613
Value Function Loss: 0.06659

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10661
Policy Update Magnitude: 0.52485
Value Function Update Magnitude: 0.83252

Collected Steps per Second: 22,818.81602
Overall Steps per Second: 10,672.72122

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.49397
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.68540

Cumulative Model Updates: 72,860
Cumulative Timesteps: 607,595,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 607595844...
Checkpoint 607595844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,316.89263
Policy Entropy: 3.68321
Value Function Loss: 0.06905

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.57940
Value Function Update Magnitude: 0.81062

Collected Steps per Second: 22,607.23592
Overall Steps per Second: 10,667.07583

Timestep Collection Time: 2.21292
Timestep Consumption Time: 2.47703
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.68995

Cumulative Model Updates: 72,866
Cumulative Timesteps: 607,645,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,089.73079
Policy Entropy: 3.67172
Value Function Loss: 0.06784

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.59517
Value Function Update Magnitude: 0.74576

Collected Steps per Second: 22,820.82577
Overall Steps per Second: 10,719.43005

Timestep Collection Time: 2.19212
Timestep Consumption Time: 2.47473
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.66685

Cumulative Model Updates: 72,872
Cumulative Timesteps: 607,695,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 607695898...
Checkpoint 607695898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,564.20665
Policy Entropy: 3.68612
Value Function Loss: 0.06725

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.52832
Value Function Update Magnitude: 0.67512

Collected Steps per Second: 22,483.66791
Overall Steps per Second: 10,600.09318

Timestep Collection Time: 2.22410
Timestep Consumption Time: 2.49340
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.71751

Cumulative Model Updates: 72,878
Cumulative Timesteps: 607,745,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,396.99919
Policy Entropy: 3.69375
Value Function Loss: 0.06570

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.50827
Value Function Update Magnitude: 0.69081

Collected Steps per Second: 22,701.62605
Overall Steps per Second: 10,690.33023

Timestep Collection Time: 2.20301
Timestep Consumption Time: 2.47523
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.67825

Cumulative Model Updates: 72,884
Cumulative Timesteps: 607,795,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 607795916...
Checkpoint 607795916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,607.99908
Policy Entropy: 3.68651
Value Function Loss: 0.06817

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.56579
Value Function Update Magnitude: 0.68800

Collected Steps per Second: 22,488.27896
Overall Steps per Second: 10,612.30730

Timestep Collection Time: 2.22374
Timestep Consumption Time: 2.48853
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.71226

Cumulative Model Updates: 72,890
Cumulative Timesteps: 607,845,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,185.95979
Policy Entropy: 3.67148
Value Function Loss: 0.06985

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.63791
Value Function Update Magnitude: 0.69938

Collected Steps per Second: 23,056.63755
Overall Steps per Second: 10,707.69856

Timestep Collection Time: 2.16953
Timestep Consumption Time: 2.50207
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.67159

Cumulative Model Updates: 72,896
Cumulative Timesteps: 607,895,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 607895946...
Checkpoint 607895946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,893.11745
Policy Entropy: 3.67351
Value Function Loss: 0.06994

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.60662
Value Function Update Magnitude: 0.69305

Collected Steps per Second: 22,510.34966
Overall Steps per Second: 10,658.69630

Timestep Collection Time: 2.22138
Timestep Consumption Time: 2.47000
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.69138

Cumulative Model Updates: 72,902
Cumulative Timesteps: 607,945,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,123.97572
Policy Entropy: 3.67531
Value Function Loss: 0.06818

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.48687
Value Function Update Magnitude: 0.74519

Collected Steps per Second: 22,558.90536
Overall Steps per Second: 10,632.12038

Timestep Collection Time: 2.21642
Timestep Consumption Time: 2.48631
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.70273

Cumulative Model Updates: 72,908
Cumulative Timesteps: 607,995,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 607995950...
Checkpoint 607995950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.49820
Policy Entropy: 3.67435
Value Function Loss: 0.06701

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.49901
Value Function Update Magnitude: 0.78503

Collected Steps per Second: 21,714.36977
Overall Steps per Second: 10,638.10553

Timestep Collection Time: 2.30327
Timestep Consumption Time: 2.39813
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.70140

Cumulative Model Updates: 72,914
Cumulative Timesteps: 608,045,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,281.11944
Policy Entropy: 3.67029
Value Function Loss: 0.06969

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.78499

Collected Steps per Second: 22,274.84208
Overall Steps per Second: 10,715.91272

Timestep Collection Time: 2.24486
Timestep Consumption Time: 2.42147
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.66633

Cumulative Model Updates: 72,920
Cumulative Timesteps: 608,095,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 608095968...
Checkpoint 608095968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,258.07924
Policy Entropy: 3.67225
Value Function Loss: 0.06864

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10208
Policy Update Magnitude: 0.52481
Value Function Update Magnitude: 0.81262

Collected Steps per Second: 21,843.29504
Overall Steps per Second: 10,632.03088

Timestep Collection Time: 2.28912
Timestep Consumption Time: 2.41383
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.70296

Cumulative Model Updates: 72,926
Cumulative Timesteps: 608,145,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,981.82038
Policy Entropy: 3.68092
Value Function Loss: 0.06769

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.49743
Value Function Update Magnitude: 0.85042

Collected Steps per Second: 22,445.16202
Overall Steps per Second: 10,881.17550

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.36820
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.59656

Cumulative Model Updates: 72,932
Cumulative Timesteps: 608,195,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 608195986...
Checkpoint 608195986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,054.30792
Policy Entropy: 3.67954
Value Function Loss: 0.06389

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.46378
Value Function Update Magnitude: 0.84041

Collected Steps per Second: 22,007.03161
Overall Steps per Second: 10,666.40719

Timestep Collection Time: 2.27336
Timestep Consumption Time: 2.41706
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.69043

Cumulative Model Updates: 72,938
Cumulative Timesteps: 608,246,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.20639
Policy Entropy: 3.68281
Value Function Loss: 0.06399

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.42385
Value Function Update Magnitude: 0.74330

Collected Steps per Second: 22,242.64019
Overall Steps per Second: 10,609.58284

Timestep Collection Time: 2.24856
Timestep Consumption Time: 2.46548
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.71404

Cumulative Model Updates: 72,944
Cumulative Timesteps: 608,296,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 608296030...
Checkpoint 608296030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,507.01143
Policy Entropy: 3.67506
Value Function Loss: 0.06301

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.42249
Value Function Update Magnitude: 0.72490

Collected Steps per Second: 22,693.87676
Overall Steps per Second: 10,870.28202

Timestep Collection Time: 2.20447
Timestep Consumption Time: 2.39780
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.60227

Cumulative Model Updates: 72,950
Cumulative Timesteps: 608,346,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,808.78785
Policy Entropy: 3.69938
Value Function Loss: 0.06041

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.44275
Value Function Update Magnitude: 0.71953

Collected Steps per Second: 22,915.91025
Overall Steps per Second: 10,889.45979

Timestep Collection Time: 2.18189
Timestep Consumption Time: 2.40971
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.59160

Cumulative Model Updates: 72,956
Cumulative Timesteps: 608,396,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 608396058...
Checkpoint 608396058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.54163
Policy Entropy: 3.70044
Value Function Loss: 0.05583

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.44642
Value Function Update Magnitude: 0.72239

Collected Steps per Second: 22,313.29044
Overall Steps per Second: 10,783.29194

Timestep Collection Time: 2.24198
Timestep Consumption Time: 2.39723
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.63921

Cumulative Model Updates: 72,962
Cumulative Timesteps: 608,446,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,970.61088
Policy Entropy: 3.70324
Value Function Loss: 0.05474

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.44558
Value Function Update Magnitude: 0.74765

Collected Steps per Second: 22,817.65988
Overall Steps per Second: 10,894.51233

Timestep Collection Time: 2.19234
Timestep Consumption Time: 2.39933
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.59167

Cumulative Model Updates: 72,968
Cumulative Timesteps: 608,496,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 608496108...
Checkpoint 608496108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,526.71712
Policy Entropy: 3.71424
Value Function Loss: 0.05390

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.45707
Value Function Update Magnitude: 0.73075

Collected Steps per Second: 22,446.13699
Overall Steps per Second: 10,621.02475

Timestep Collection Time: 2.22791
Timestep Consumption Time: 2.48049
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.70840

Cumulative Model Updates: 72,974
Cumulative Timesteps: 608,546,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.90032
Policy Entropy: 3.72666
Value Function Loss: 0.05387

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.44603
Value Function Update Magnitude: 0.73546

Collected Steps per Second: 22,865.29761
Overall Steps per Second: 10,818.56519

Timestep Collection Time: 2.18768
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62372

Cumulative Model Updates: 72,980
Cumulative Timesteps: 608,596,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 608596138...
Checkpoint 608596138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,435.41928
Policy Entropy: 3.74584
Value Function Loss: 0.05141

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.47464
Value Function Update Magnitude: 0.73597

Collected Steps per Second: 22,453.32455
Overall Steps per Second: 10,735.50489

Timestep Collection Time: 2.22693
Timestep Consumption Time: 2.43070
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.65763

Cumulative Model Updates: 72,986
Cumulative Timesteps: 608,646,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,399.18135
Policy Entropy: 3.74298
Value Function Loss: 0.04758

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.51382
Value Function Update Magnitude: 0.71544

Collected Steps per Second: 22,950.46949
Overall Steps per Second: 10,823.76877

Timestep Collection Time: 2.17965
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.62168

Cumulative Model Updates: 72,992
Cumulative Timesteps: 608,696,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 608696164...
Checkpoint 608696164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,329.39537
Policy Entropy: 3.75084
Value Function Loss: 0.04370

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.51647
Value Function Update Magnitude: 0.68899

Collected Steps per Second: 22,482.88660
Overall Steps per Second: 10,757.15962

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.65030

Cumulative Model Updates: 72,998
Cumulative Timesteps: 608,746,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,284.53816
Policy Entropy: 3.74033
Value Function Loss: 0.04198

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.52954
Value Function Update Magnitude: 0.65281

Collected Steps per Second: 23,217.94710
Overall Steps per Second: 10,807.80355

Timestep Collection Time: 2.15351
Timestep Consumption Time: 2.47278
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.62629

Cumulative Model Updates: 73,004
Cumulative Timesteps: 608,796,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 608796188...
Checkpoint 608796188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,406.33414
Policy Entropy: 3.75979
Value Function Loss: 0.04103

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.52427
Value Function Update Magnitude: 0.64074

Collected Steps per Second: 22,663.02767
Overall Steps per Second: 10,697.91543

Timestep Collection Time: 2.20632
Timestep Consumption Time: 2.46767
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.67399

Cumulative Model Updates: 73,010
Cumulative Timesteps: 608,846,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,344.73640
Policy Entropy: 3.74947
Value Function Loss: 0.04335

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.53353
Value Function Update Magnitude: 0.63797

Collected Steps per Second: 23,069.16766
Overall Steps per Second: 10,878.58774

Timestep Collection Time: 2.16861
Timestep Consumption Time: 2.43015
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.59876

Cumulative Model Updates: 73,016
Cumulative Timesteps: 608,896,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 608896218...
Checkpoint 608896218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,006.50482
Policy Entropy: 3.75595
Value Function Loss: 0.04481

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.64797

Collected Steps per Second: 22,484.58180
Overall Steps per Second: 10,683.84100

Timestep Collection Time: 2.22490
Timestep Consumption Time: 2.45750
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.68240

Cumulative Model Updates: 73,022
Cumulative Timesteps: 608,946,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,600.03856
Policy Entropy: 3.75883
Value Function Loss: 0.04636

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.54809
Value Function Update Magnitude: 0.67108

Collected Steps per Second: 22,817.49843
Overall Steps per Second: 10,822.02629

Timestep Collection Time: 2.19183
Timestep Consumption Time: 2.42949
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.62132

Cumulative Model Updates: 73,028
Cumulative Timesteps: 608,996,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 608996256...
Checkpoint 608996256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,240.59276
Policy Entropy: 3.75168
Value Function Loss: 0.04810

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.51543
Value Function Update Magnitude: 0.67334

Collected Steps per Second: 22,553.80016
Overall Steps per Second: 10,686.44871

Timestep Collection Time: 2.21807
Timestep Consumption Time: 2.46318
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.68126

Cumulative Model Updates: 73,034
Cumulative Timesteps: 609,046,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,111.72189
Policy Entropy: 3.74646
Value Function Loss: 0.05044

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.47565
Value Function Update Magnitude: 0.69125

Collected Steps per Second: 22,944.80112
Overall Steps per Second: 10,870.48397

Timestep Collection Time: 2.18036
Timestep Consumption Time: 2.42182
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.60219

Cumulative Model Updates: 73,040
Cumulative Timesteps: 609,096,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 609096310...
Checkpoint 609096310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,341.69150
Policy Entropy: 3.73486
Value Function Loss: 0.05163

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.47329
Value Function Update Magnitude: 0.69972

Collected Steps per Second: 22,548.46032
Overall Steps per Second: 10,721.10862

Timestep Collection Time: 2.21762
Timestep Consumption Time: 2.44645
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.66407

Cumulative Model Updates: 73,046
Cumulative Timesteps: 609,146,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,855.74095
Policy Entropy: 3.75070
Value Function Loss: 0.05190

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.48190
Value Function Update Magnitude: 0.71226

Collected Steps per Second: 22,901.23561
Overall Steps per Second: 10,795.42991

Timestep Collection Time: 2.18381
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.63270

Cumulative Model Updates: 73,052
Cumulative Timesteps: 609,196,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 609196326...
Checkpoint 609196326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,418.50404
Policy Entropy: 3.74993
Value Function Loss: 0.05197

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.49270
Value Function Update Magnitude: 0.72323

Collected Steps per Second: 22,567.78844
Overall Steps per Second: 10,724.07242

Timestep Collection Time: 2.21564
Timestep Consumption Time: 2.44696
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.66259

Cumulative Model Updates: 73,058
Cumulative Timesteps: 609,246,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,890.46250
Policy Entropy: 3.75739
Value Function Loss: 0.05288

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.48563
Value Function Update Magnitude: 0.71921

Collected Steps per Second: 23,126.43265
Overall Steps per Second: 10,888.09530

Timestep Collection Time: 2.16211
Timestep Consumption Time: 2.43024
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.59236

Cumulative Model Updates: 73,064
Cumulative Timesteps: 609,296,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 609296330...
Checkpoint 609296330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,790.72428
Policy Entropy: 3.74626
Value Function Loss: 0.05607

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.50714
Value Function Update Magnitude: 0.73679

Collected Steps per Second: 22,437.35897
Overall Steps per Second: 10,672.72056

Timestep Collection Time: 2.22852
Timestep Consumption Time: 2.45651
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.68503

Cumulative Model Updates: 73,070
Cumulative Timesteps: 609,346,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,745.84943
Policy Entropy: 3.74562
Value Function Loss: 0.05672

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06237
Policy Update Magnitude: 0.62352
Value Function Update Magnitude: 0.69680

Collected Steps per Second: 22,775.44066
Overall Steps per Second: 10,791.47864

Timestep Collection Time: 2.19658
Timestep Consumption Time: 2.43930
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.63588

Cumulative Model Updates: 73,076
Cumulative Timesteps: 609,396,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 609396360...
Checkpoint 609396360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,785.32740
Policy Entropy: 3.73822
Value Function Loss: 0.06112

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.60587
Value Function Update Magnitude: 0.61232

Collected Steps per Second: 22,540.34175
Overall Steps per Second: 10,768.87920

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.42612
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.64561

Cumulative Model Updates: 73,082
Cumulative Timesteps: 609,446,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,337.61714
Policy Entropy: 3.72784
Value Function Loss: 0.06379

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.51903
Value Function Update Magnitude: 0.63493

Collected Steps per Second: 22,644.53446
Overall Steps per Second: 10,800.14578

Timestep Collection Time: 2.20874
Timestep Consumption Time: 2.42230
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.63105

Cumulative Model Updates: 73,088
Cumulative Timesteps: 609,496,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 609496404...
Checkpoint 609496404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,620.17286
Policy Entropy: 3.71887
Value Function Loss: 0.06833

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.45583
Value Function Update Magnitude: 0.76231

Collected Steps per Second: 22,560.49334
Overall Steps per Second: 10,724.82354

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.44738
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.66507

Cumulative Model Updates: 73,094
Cumulative Timesteps: 609,546,436

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.43039
Policy Entropy: 3.71246
Value Function Loss: 0.06752

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.49405
Value Function Update Magnitude: 0.80248

Collected Steps per Second: 23,022.08339
Overall Steps per Second: 10,832.55036

Timestep Collection Time: 2.17270
Timestep Consumption Time: 2.44487
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.61756

Cumulative Model Updates: 73,100
Cumulative Timesteps: 609,596,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 609596456...
Checkpoint 609596456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,393.58718
Policy Entropy: 3.71307
Value Function Loss: 0.06617

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.52628
Value Function Update Magnitude: 0.81716

Collected Steps per Second: 22,572.23254
Overall Steps per Second: 10,708.12727

Timestep Collection Time: 2.21564
Timestep Consumption Time: 2.45483
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.67047

Cumulative Model Updates: 73,106
Cumulative Timesteps: 609,646,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.22330
Policy Entropy: 3.71584
Value Function Loss: 0.06508

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.53907
Value Function Update Magnitude: 0.80964

Collected Steps per Second: 22,648.14404
Overall Steps per Second: 10,650.87601

Timestep Collection Time: 2.20866
Timestep Consumption Time: 2.48786
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.69652

Cumulative Model Updates: 73,112
Cumulative Timesteps: 609,696,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 609696490...
Checkpoint 609696490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,063.98238
Policy Entropy: 3.71063
Value Function Loss: 0.06676

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.56134
Value Function Update Magnitude: 0.81366

Collected Steps per Second: 22,876.01477
Overall Steps per Second: 10,872.33840

Timestep Collection Time: 2.18605
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.59956

Cumulative Model Updates: 73,118
Cumulative Timesteps: 609,746,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,021.14926
Policy Entropy: 3.70283
Value Function Loss: 0.07094

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.58601
Value Function Update Magnitude: 0.82661

Collected Steps per Second: 22,634.93142
Overall Steps per Second: 10,623.06496

Timestep Collection Time: 2.20942
Timestep Consumption Time: 2.49826
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.70768

Cumulative Model Updates: 73,124
Cumulative Timesteps: 609,796,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 609796508...
Checkpoint 609796508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,637.27739
Policy Entropy: 3.70402
Value Function Loss: 0.06989

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.66931
Value Function Update Magnitude: 0.83176

Collected Steps per Second: 22,862.57109
Overall Steps per Second: 10,837.46693

Timestep Collection Time: 2.18751
Timestep Consumption Time: 2.42723
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.61473

Cumulative Model Updates: 73,130
Cumulative Timesteps: 609,846,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,540.84667
Policy Entropy: 3.69986
Value Function Loss: 0.06975

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.69227
Value Function Update Magnitude: 0.81099

Collected Steps per Second: 22,844.39014
Overall Steps per Second: 10,710.33462

Timestep Collection Time: 2.18916
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.66932

Cumulative Model Updates: 73,136
Cumulative Timesteps: 609,896,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 609896530...
Checkpoint 609896530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,739.38406
Policy Entropy: 3.70669
Value Function Loss: 0.06890

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07569
Policy Update Magnitude: 0.69531
Value Function Update Magnitude: 0.83417

Collected Steps per Second: 22,419.51511
Overall Steps per Second: 10,615.23146

Timestep Collection Time: 2.23038
Timestep Consumption Time: 2.48021
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.71059

Cumulative Model Updates: 73,142
Cumulative Timesteps: 609,946,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,295.03711
Policy Entropy: 3.70590
Value Function Loss: 0.06832

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.67887
Value Function Update Magnitude: 0.86635

Collected Steps per Second: 23,191.21742
Overall Steps per Second: 10,784.07788

Timestep Collection Time: 2.15668
Timestep Consumption Time: 2.48127
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.63795

Cumulative Model Updates: 73,148
Cumulative Timesteps: 609,996,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 609996550...
Checkpoint 609996550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,113.57972
Policy Entropy: 3.70138
Value Function Loss: 0.06653

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.56707
Value Function Update Magnitude: 0.87718

Collected Steps per Second: 22,712.05523
Overall Steps per Second: 10,625.49715

Timestep Collection Time: 2.20156
Timestep Consumption Time: 2.50429
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.70585

Cumulative Model Updates: 73,154
Cumulative Timesteps: 610,046,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,632.81490
Policy Entropy: 3.71824
Value Function Loss: 0.06538

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.45989
Value Function Update Magnitude: 0.88408

Collected Steps per Second: 23,148.34846
Overall Steps per Second: 10,904.56651

Timestep Collection Time: 2.16093
Timestep Consumption Time: 2.42632
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.58725

Cumulative Model Updates: 73,160
Cumulative Timesteps: 610,096,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 610096574...
Checkpoint 610096574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,881.38497
Policy Entropy: 3.70972
Value Function Loss: 0.06838

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.47064
Value Function Update Magnitude: 0.89654

Collected Steps per Second: 21,761.67899
Overall Steps per Second: 10,664.96668

Timestep Collection Time: 2.29890
Timestep Consumption Time: 2.39197
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.69087

Cumulative Model Updates: 73,166
Cumulative Timesteps: 610,146,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,670.02738
Policy Entropy: 3.71596
Value Function Loss: 0.07029

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.46599
Value Function Update Magnitude: 0.90996

Collected Steps per Second: 22,128.03595
Overall Steps per Second: 10,829.12681

Timestep Collection Time: 2.25985
Timestep Consumption Time: 2.35788
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.61773

Cumulative Model Updates: 73,172
Cumulative Timesteps: 610,196,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 610196608...
Checkpoint 610196608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,460.38917
Policy Entropy: 3.69724
Value Function Loss: 0.07209

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.54864
Value Function Update Magnitude: 0.82639

Collected Steps per Second: 21,847.25291
Overall Steps per Second: 10,704.49501

Timestep Collection Time: 2.28871
Timestep Consumption Time: 2.38241
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.67112

Cumulative Model Updates: 73,178
Cumulative Timesteps: 610,246,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,365.82064
Policy Entropy: 3.69412
Value Function Loss: 0.06855

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.51240
Value Function Update Magnitude: 0.84194

Collected Steps per Second: 22,269.83375
Overall Steps per Second: 10,853.53072

Timestep Collection Time: 2.24591
Timestep Consumption Time: 2.36236
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60827

Cumulative Model Updates: 73,184
Cumulative Timesteps: 610,296,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 610296626...
Checkpoint 610296626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,884.32093
Policy Entropy: 3.68564
Value Function Loss: 0.06671

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.45848
Value Function Update Magnitude: 0.85908

Collected Steps per Second: 21,732.49258
Overall Steps per Second: 10,709.23562

Timestep Collection Time: 2.30070
Timestep Consumption Time: 2.36816
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.66887

Cumulative Model Updates: 73,190
Cumulative Timesteps: 610,346,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,813.65159
Policy Entropy: 3.68914
Value Function Loss: 0.07072

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.46814
Value Function Update Magnitude: 0.72627

Collected Steps per Second: 22,177.64516
Overall Steps per Second: 10,586.65392

Timestep Collection Time: 2.25452
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.72293

Cumulative Model Updates: 73,196
Cumulative Timesteps: 610,396,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 610396626...
Checkpoint 610396626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,813.15024
Policy Entropy: 3.68646
Value Function Loss: 0.07318

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.49881
Value Function Update Magnitude: 0.67150

Collected Steps per Second: 22,869.93033
Overall Steps per Second: 10,895.89725

Timestep Collection Time: 2.18768
Timestep Consumption Time: 2.40414
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.59182

Cumulative Model Updates: 73,202
Cumulative Timesteps: 610,446,658

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,552.96552
Policy Entropy: 3.69637
Value Function Loss: 0.07460

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.51072
Value Function Update Magnitude: 0.64675

Collected Steps per Second: 22,877.24394
Overall Steps per Second: 10,899.76867

Timestep Collection Time: 2.18575
Timestep Consumption Time: 2.40187
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.58762

Cumulative Model Updates: 73,208
Cumulative Timesteps: 610,496,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 610496662...
Checkpoint 610496662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,768.09433
Policy Entropy: 3.69650
Value Function Loss: 0.07407

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.52543
Value Function Update Magnitude: 0.64619

Collected Steps per Second: 22,569.69551
Overall Steps per Second: 10,674.45185

Timestep Collection Time: 2.21554
Timestep Consumption Time: 2.46892
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.68446

Cumulative Model Updates: 73,214
Cumulative Timesteps: 610,546,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,078.99600
Policy Entropy: 3.70905
Value Function Loss: 0.07524

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.52351
Value Function Update Magnitude: 0.64722

Collected Steps per Second: 23,056.41457
Overall Steps per Second: 10,929.05945

Timestep Collection Time: 2.16859
Timestep Consumption Time: 2.40637
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57496

Cumulative Model Updates: 73,220
Cumulative Timesteps: 610,596,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 610596666...
Checkpoint 610596666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,355.90958
Policy Entropy: 3.70640
Value Function Loss: 0.07412

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.68204

Collected Steps per Second: 22,403.23667
Overall Steps per Second: 10,584.12880

Timestep Collection Time: 2.23271
Timestep Consumption Time: 2.49323
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.72594

Cumulative Model Updates: 73,226
Cumulative Timesteps: 610,646,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,983.70101
Policy Entropy: 3.70240
Value Function Loss: 0.07342

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.70075

Collected Steps per Second: 23,110.87971
Overall Steps per Second: 10,884.80205

Timestep Collection Time: 2.16348
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59356

Cumulative Model Updates: 73,232
Cumulative Timesteps: 610,696,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 610696686...
Checkpoint 610696686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,348.75894
Policy Entropy: 3.69803
Value Function Loss: 0.07128

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.49557
Value Function Update Magnitude: 0.71823

Collected Steps per Second: 22,452.62869
Overall Steps per Second: 10,709.28958

Timestep Collection Time: 2.22745
Timestep Consumption Time: 2.44252
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.66996

Cumulative Model Updates: 73,238
Cumulative Timesteps: 610,746,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,080.34334
Policy Entropy: 3.69253
Value Function Loss: 0.07322

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 0.41261
Value Function Update Magnitude: 0.72922

Collected Steps per Second: 22,772.23775
Overall Steps per Second: 10,808.20962

Timestep Collection Time: 2.19706
Timestep Consumption Time: 2.43201
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.62907

Cumulative Model Updates: 73,244
Cumulative Timesteps: 610,796,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 610796730...
Checkpoint 610796730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,658.52934
Policy Entropy: 3.69522
Value Function Loss: 0.07305

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06685
Policy Update Magnitude: 0.57388
Value Function Update Magnitude: 0.72638

Collected Steps per Second: 22,749.90577
Overall Steps per Second: 10,727.95404

Timestep Collection Time: 2.19922
Timestep Consumption Time: 2.46449
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.66370

Cumulative Model Updates: 73,250
Cumulative Timesteps: 610,846,762

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,139.56477
Policy Entropy: 3.69686
Value Function Loss: 0.07556

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.67351
Value Function Update Magnitude: 0.71096

Collected Steps per Second: 23,090.16227
Overall Steps per Second: 10,865.10498

Timestep Collection Time: 2.16560
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.60226

Cumulative Model Updates: 73,256
Cumulative Timesteps: 610,896,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 610896766...
Checkpoint 610896766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,649.31295
Policy Entropy: 3.70281
Value Function Loss: 0.07470

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.62893
Value Function Update Magnitude: 0.82132

Collected Steps per Second: 22,852.41832
Overall Steps per Second: 10,678.65239

Timestep Collection Time: 2.18918
Timestep Consumption Time: 2.49568
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.68486

Cumulative Model Updates: 73,262
Cumulative Timesteps: 610,946,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.83805
Policy Entropy: 3.70230
Value Function Loss: 0.07283

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.51622
Value Function Update Magnitude: 0.86091

Collected Steps per Second: 22,856.28339
Overall Steps per Second: 10,819.36898

Timestep Collection Time: 2.18872
Timestep Consumption Time: 2.43502
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.62374

Cumulative Model Updates: 73,268
Cumulative Timesteps: 610,996,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 610996820...
Checkpoint 610996820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,739.42895
Policy Entropy: 3.69220
Value Function Loss: 0.07522

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.51156
Value Function Update Magnitude: 0.88932

Collected Steps per Second: 22,466.95748
Overall Steps per Second: 10,788.35490

Timestep Collection Time: 2.22558
Timestep Consumption Time: 2.40923
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.63481

Cumulative Model Updates: 73,274
Cumulative Timesteps: 611,046,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,851.90899
Policy Entropy: 3.68769
Value Function Loss: 0.07385

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.52561
Value Function Update Magnitude: 0.90209

Collected Steps per Second: 22,929.80568
Overall Steps per Second: 10,879.52668

Timestep Collection Time: 2.18066
Timestep Consumption Time: 2.41532
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.59597

Cumulative Model Updates: 73,280
Cumulative Timesteps: 611,096,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 611096824...
Checkpoint 611096824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,754.44092
Policy Entropy: 3.68090
Value Function Loss: 0.07583

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.51155
Value Function Update Magnitude: 0.76514

Collected Steps per Second: 22,785.21509
Overall Steps per Second: 10,653.02067

Timestep Collection Time: 2.19493
Timestep Consumption Time: 2.49970
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.69463

Cumulative Model Updates: 73,286
Cumulative Timesteps: 611,146,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,779.26745
Policy Entropy: 3.68235
Value Function Loss: 0.07600

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.48488
Value Function Update Magnitude: 0.65879

Collected Steps per Second: 22,733.94794
Overall Steps per Second: 10,780.11495

Timestep Collection Time: 2.19979
Timestep Consumption Time: 2.43930
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.63910

Cumulative Model Updates: 73,292
Cumulative Timesteps: 611,196,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 611196846...
Checkpoint 611196846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,911.58176
Policy Entropy: 3.69063
Value Function Loss: 0.07645

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.54594
Value Function Update Magnitude: 0.66752

Collected Steps per Second: 22,380.56185
Overall Steps per Second: 10,751.78182

Timestep Collection Time: 2.23417
Timestep Consumption Time: 2.41641
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.65058

Cumulative Model Updates: 73,298
Cumulative Timesteps: 611,246,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,560.33035
Policy Entropy: 3.69521
Value Function Loss: 0.07526

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.48164
Value Function Update Magnitude: 0.78070

Collected Steps per Second: 23,191.03805
Overall Steps per Second: 10,910.70126

Timestep Collection Time: 2.15652
Timestep Consumption Time: 2.42723
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.58376

Cumulative Model Updates: 73,304
Cumulative Timesteps: 611,296,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 611296860...
Checkpoint 611296860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,911.01923
Policy Entropy: 3.69278
Value Function Loss: 0.07181

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07064
Policy Update Magnitude: 0.59298
Value Function Update Magnitude: 0.89521

Collected Steps per Second: 22,541.72457
Overall Steps per Second: 10,586.79271

Timestep Collection Time: 2.21882
Timestep Consumption Time: 2.50556
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.72438

Cumulative Model Updates: 73,310
Cumulative Timesteps: 611,346,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,705.55127
Policy Entropy: 3.68873
Value Function Loss: 0.07360

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.70896
Value Function Update Magnitude: 0.86294

Collected Steps per Second: 22,903.29714
Overall Steps per Second: 10,836.94859

Timestep Collection Time: 2.18423
Timestep Consumption Time: 2.43202
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61624

Cumulative Model Updates: 73,316
Cumulative Timesteps: 611,396,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 611396902...
Checkpoint 611396902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,731.15899
Policy Entropy: 3.68074
Value Function Loss: 0.07492

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.65785
Value Function Update Magnitude: 0.79197

Collected Steps per Second: 22,621.51307
Overall Steps per Second: 10,693.62634

Timestep Collection Time: 2.21108
Timestep Consumption Time: 2.46628
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.67737

Cumulative Model Updates: 73,322
Cumulative Timesteps: 611,446,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,910.43722
Policy Entropy: 3.69006
Value Function Loss: 0.07273

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.59309
Value Function Update Magnitude: 0.77537

Collected Steps per Second: 23,057.36026
Overall Steps per Second: 10,895.12147

Timestep Collection Time: 2.17033
Timestep Consumption Time: 2.42274
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.59306

Cumulative Model Updates: 73,328
Cumulative Timesteps: 611,496,962

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 611496962...
Checkpoint 611496962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,670.62743
Policy Entropy: 3.69562
Value Function Loss: 0.07329

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.15578
Policy Update Magnitude: 0.52487
Value Function Update Magnitude: 0.76093

Collected Steps per Second: 22,850.04136
Overall Steps per Second: 10,696.26881

Timestep Collection Time: 2.18932
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.67696

Cumulative Model Updates: 73,334
Cumulative Timesteps: 611,546,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,254.19652
Policy Entropy: 3.70246
Value Function Loss: 0.07344

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.16935
Policy Update Magnitude: 0.49782
Value Function Update Magnitude: 0.73416

Collected Steps per Second: 22,782.28236
Overall Steps per Second: 10,799.67671

Timestep Collection Time: 2.19486
Timestep Consumption Time: 2.43528
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.63014

Cumulative Model Updates: 73,340
Cumulative Timesteps: 611,596,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 611596992...
Checkpoint 611596992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,875.40448
Policy Entropy: 3.68039
Value Function Loss: 0.07676

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.15160
Policy Update Magnitude: 0.49405
Value Function Update Magnitude: 0.73105

Collected Steps per Second: 22,410.99594
Overall Steps per Second: 10,730.60294

Timestep Collection Time: 2.23114
Timestep Consumption Time: 2.42862
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.65976

Cumulative Model Updates: 73,346
Cumulative Timesteps: 611,646,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,611.25130
Policy Entropy: 3.67333
Value Function Loss: 0.07618

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.47397
Value Function Update Magnitude: 0.69174

Collected Steps per Second: 22,949.66989
Overall Steps per Second: 10,870.95620

Timestep Collection Time: 2.17946
Timestep Consumption Time: 2.42160
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.60107

Cumulative Model Updates: 73,352
Cumulative Timesteps: 611,697,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 611697012...
Checkpoint 611697012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,014.91242
Policy Entropy: 3.67771
Value Function Loss: 0.07498

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.49300
Value Function Update Magnitude: 0.67941

Collected Steps per Second: 22,558.22686
Overall Steps per Second: 10,696.74844

Timestep Collection Time: 2.21728
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.67600

Cumulative Model Updates: 73,358
Cumulative Timesteps: 611,747,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,081.27337
Policy Entropy: 3.69333
Value Function Loss: 0.07117

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.54863
Value Function Update Magnitude: 0.64902

Collected Steps per Second: 22,881.24029
Overall Steps per Second: 10,835.00199

Timestep Collection Time: 2.18598
Timestep Consumption Time: 2.43035
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61634

Cumulative Model Updates: 73,364
Cumulative Timesteps: 611,797,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 611797048...
Checkpoint 611797048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,000.84036
Policy Entropy: 3.69739
Value Function Loss: 0.06956

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.54078
Value Function Update Magnitude: 0.65287

Collected Steps per Second: 22,637.91406
Overall Steps per Second: 10,671.88147

Timestep Collection Time: 2.20913
Timestep Consumption Time: 2.47702
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.68615

Cumulative Model Updates: 73,370
Cumulative Timesteps: 611,847,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,492.77552
Policy Entropy: 3.69115
Value Function Loss: 0.07134

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.58148
Value Function Update Magnitude: 0.65407

Collected Steps per Second: 22,745.59865
Overall Steps per Second: 10,708.47999

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.47206
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.67125

Cumulative Model Updates: 73,376
Cumulative Timesteps: 611,897,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 611897080...
Checkpoint 611897080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,097.90398
Policy Entropy: 3.69656
Value Function Loss: 0.07172

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.57481
Value Function Update Magnitude: 0.64736

Collected Steps per Second: 22,770.86270
Overall Steps per Second: 10,874.05319

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.40241
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.59829

Cumulative Model Updates: 73,382
Cumulative Timesteps: 611,947,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,648.89823
Policy Entropy: 3.69837
Value Function Loss: 0.07206

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.56982
Value Function Update Magnitude: 0.67169

Collected Steps per Second: 22,564.34819
Overall Steps per Second: 10,667.86212

Timestep Collection Time: 2.21721
Timestep Consumption Time: 2.47257
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.68979

Cumulative Model Updates: 73,388
Cumulative Timesteps: 611,997,112

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 611997112...
Checkpoint 611997112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,211.72683
Policy Entropy: 3.69999
Value Function Loss: 0.07202

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.67110

Collected Steps per Second: 21,935.97066
Overall Steps per Second: 10,817.50606

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.34381
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.62417

Cumulative Model Updates: 73,394
Cumulative Timesteps: 612,047,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,433.02481
Policy Entropy: 3.69534
Value Function Loss: 0.07131

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.52572
Value Function Update Magnitude: 0.68749

Collected Steps per Second: 22,113.28775
Overall Steps per Second: 10,711.46708

Timestep Collection Time: 2.26244
Timestep Consumption Time: 2.40825
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.67070

Cumulative Model Updates: 73,400
Cumulative Timesteps: 612,097,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 612097164...
Checkpoint 612097164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,750.01741
Policy Entropy: 3.68326
Value Function Loss: 0.07135

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.52565
Value Function Update Magnitude: 0.68334

Collected Steps per Second: 22,156.07556
Overall Steps per Second: 10,871.44468

Timestep Collection Time: 2.25771
Timestep Consumption Time: 2.34352
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60123

Cumulative Model Updates: 73,406
Cumulative Timesteps: 612,147,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,737.58051
Policy Entropy: 3.68099
Value Function Loss: 0.06944

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.61373
Value Function Update Magnitude: 0.71609

Collected Steps per Second: 21,938.79580
Overall Steps per Second: 10,668.76502

Timestep Collection Time: 2.28044
Timestep Consumption Time: 2.40895
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.68939

Cumulative Model Updates: 73,412
Cumulative Timesteps: 612,197,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 612197216...
Checkpoint 612197216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,178.14059
Policy Entropy: 3.68411
Value Function Loss: 0.06790

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.60855
Value Function Update Magnitude: 0.76253

Collected Steps per Second: 22,081.86285
Overall Steps per Second: 10,820.52029

Timestep Collection Time: 2.26566
Timestep Consumption Time: 2.35796
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62362

Cumulative Model Updates: 73,418
Cumulative Timesteps: 612,247,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,107.68724
Policy Entropy: 3.68213
Value Function Loss: 0.06695

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.56582
Value Function Update Magnitude: 0.77174

Collected Steps per Second: 22,264.59309
Overall Steps per Second: 10,568.45104

Timestep Collection Time: 2.24599
Timestep Consumption Time: 2.48564
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.73163

Cumulative Model Updates: 73,424
Cumulative Timesteps: 612,297,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 612297252...
Checkpoint 612297252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,039.91231
Policy Entropy: 3.69244
Value Function Loss: 0.06852

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.76547

Collected Steps per Second: 22,707.09025
Overall Steps per Second: 10,692.39456

Timestep Collection Time: 2.20196
Timestep Consumption Time: 2.47427
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.67622

Cumulative Model Updates: 73,430
Cumulative Timesteps: 612,347,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,319.98229
Policy Entropy: 3.68395
Value Function Loss: 0.06916

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.56474
Value Function Update Magnitude: 0.80832

Collected Steps per Second: 22,784.15856
Overall Steps per Second: 10,784.54805

Timestep Collection Time: 2.19451
Timestep Consumption Time: 2.44176
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.63626

Cumulative Model Updates: 73,436
Cumulative Timesteps: 612,397,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 612397252...
Checkpoint 612397252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,686.23490
Policy Entropy: 3.68156
Value Function Loss: 0.06805

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06501
Policy Update Magnitude: 0.69440
Value Function Update Magnitude: 0.77230

Collected Steps per Second: 22,567.61144
Overall Steps per Second: 10,662.43115

Timestep Collection Time: 2.21574
Timestep Consumption Time: 2.47400
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.68974

Cumulative Model Updates: 73,442
Cumulative Timesteps: 612,447,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,991.95171
Policy Entropy: 3.67980
Value Function Loss: 0.06652

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.74559
Value Function Update Magnitude: 0.75227

Collected Steps per Second: 22,837.41739
Overall Steps per Second: 10,829.83708

Timestep Collection Time: 2.19018
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.61854

Cumulative Model Updates: 73,448
Cumulative Timesteps: 612,497,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 612497274...
Checkpoint 612497274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,084.47421
Policy Entropy: 3.69301
Value Function Loss: 0.06858

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.63771
Value Function Update Magnitude: 0.67584

Collected Steps per Second: 22,576.83178
Overall Steps per Second: 10,721.55131

Timestep Collection Time: 2.21546
Timestep Consumption Time: 2.44973
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.66518

Cumulative Model Updates: 73,454
Cumulative Timesteps: 612,547,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,890.26594
Policy Entropy: 3.68057
Value Function Loss: 0.07506

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.58901
Value Function Update Magnitude: 0.60192

Collected Steps per Second: 23,172.72849
Overall Steps per Second: 10,880.10028

Timestep Collection Time: 2.15780
Timestep Consumption Time: 2.43793
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.59573

Cumulative Model Updates: 73,460
Cumulative Timesteps: 612,597,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 612597294...
Checkpoint 612597294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,945.19972
Policy Entropy: 3.68759
Value Function Loss: 0.07550

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11668
Policy Update Magnitude: 0.55529
Value Function Update Magnitude: 0.59848

Collected Steps per Second: 22,652.73645
Overall Steps per Second: 10,682.76793

Timestep Collection Time: 2.20768
Timestep Consumption Time: 2.47369
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.68137

Cumulative Model Updates: 73,466
Cumulative Timesteps: 612,647,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,288.06275
Policy Entropy: 3.68737
Value Function Loss: 0.07736

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.52401
Value Function Update Magnitude: 0.60618

Collected Steps per Second: 22,693.26701
Overall Steps per Second: 10,864.82778

Timestep Collection Time: 2.20444
Timestep Consumption Time: 2.39996
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.60440

Cumulative Model Updates: 73,472
Cumulative Timesteps: 612,697,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 612697330...
Checkpoint 612697330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,537.82226
Policy Entropy: 3.68198
Value Function Loss: 0.07358

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.58833
Value Function Update Magnitude: 0.61648

Collected Steps per Second: 22,664.43053
Overall Steps per Second: 10,659.07362

Timestep Collection Time: 2.20672
Timestep Consumption Time: 2.48543
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.69215

Cumulative Model Updates: 73,478
Cumulative Timesteps: 612,747,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,870.22465
Policy Entropy: 3.69266
Value Function Loss: 0.07328

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.67423
Value Function Update Magnitude: 0.64920

Collected Steps per Second: 22,657.92168
Overall Steps per Second: 10,852.51744

Timestep Collection Time: 2.20797
Timestep Consumption Time: 2.40184
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.60981

Cumulative Model Updates: 73,484
Cumulative Timesteps: 612,797,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 612797372...
Checkpoint 612797372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,387.68387
Policy Entropy: 3.69724
Value Function Loss: 0.07099

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.68781
Value Function Update Magnitude: 0.68049

Collected Steps per Second: 22,893.98041
Overall Steps per Second: 10,673.27059

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.68554

Cumulative Model Updates: 73,490
Cumulative Timesteps: 612,847,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,337.57533
Policy Entropy: 3.68709
Value Function Loss: 0.07253

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.66621
Value Function Update Magnitude: 0.73958

Collected Steps per Second: 23,165.48706
Overall Steps per Second: 10,867.18285

Timestep Collection Time: 2.15916
Timestep Consumption Time: 2.44350
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60266

Cumulative Model Updates: 73,496
Cumulative Timesteps: 612,897,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 612897400...
Checkpoint 612897400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,269.95496
Policy Entropy: 3.68411
Value Function Loss: 0.07310

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.59853
Value Function Update Magnitude: 0.81046

Collected Steps per Second: 22,476.07049
Overall Steps per Second: 10,704.22939

Timestep Collection Time: 2.22592
Timestep Consumption Time: 2.44793
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.67385

Cumulative Model Updates: 73,502
Cumulative Timesteps: 612,947,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,016.33224
Policy Entropy: 3.66579
Value Function Loss: 0.07235

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.52874
Value Function Update Magnitude: 0.81735

Collected Steps per Second: 22,683.29449
Overall Steps per Second: 10,648.60207

Timestep Collection Time: 2.20471
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.69639

Cumulative Model Updates: 73,508
Cumulative Timesteps: 612,997,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 612997440...
Checkpoint 612997440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,542.65467
Policy Entropy: 3.65575
Value Function Loss: 0.07076

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.57883
Value Function Update Magnitude: 0.76793

Collected Steps per Second: 22,879.21394
Overall Steps per Second: 10,831.14500

Timestep Collection Time: 2.18670
Timestep Consumption Time: 2.43239
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.61909

Cumulative Model Updates: 73,514
Cumulative Timesteps: 613,047,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,879.29643
Policy Entropy: 3.64281
Value Function Loss: 0.07050

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.69574
Value Function Update Magnitude: 0.68468

Collected Steps per Second: 22,662.93882
Overall Steps per Second: 10,653.52326

Timestep Collection Time: 2.20642
Timestep Consumption Time: 2.48724
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.69366

Cumulative Model Updates: 73,520
Cumulative Timesteps: 613,097,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 613097474...
Checkpoint 613097474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,185.01691
Policy Entropy: 3.66042
Value Function Loss: 0.07122

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.14873
Policy Update Magnitude: 0.62953
Value Function Update Magnitude: 0.67866

Collected Steps per Second: 23,016.50297
Overall Steps per Second: 10,889.24707

Timestep Collection Time: 2.17288
Timestep Consumption Time: 2.41991
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.59279

Cumulative Model Updates: 73,526
Cumulative Timesteps: 613,147,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,376.95694
Policy Entropy: 3.67633
Value Function Loss: 0.07011

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.50597
Value Function Update Magnitude: 0.74287

Collected Steps per Second: 22,630.89310
Overall Steps per Second: 10,613.28212

Timestep Collection Time: 2.21140
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.71541

Cumulative Model Updates: 73,532
Cumulative Timesteps: 613,197,532

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 613197532...
Checkpoint 613197532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,360.60642
Policy Entropy: 3.66862
Value Function Loss: 0.06687

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.48358
Value Function Update Magnitude: 0.77317

Collected Steps per Second: 22,678.54205
Overall Steps per Second: 10,639.02002

Timestep Collection Time: 2.20526
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.70081

Cumulative Model Updates: 73,538
Cumulative Timesteps: 613,247,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,578.62189
Policy Entropy: 3.67306
Value Function Loss: 0.06752

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.48872
Value Function Update Magnitude: 0.71515

Collected Steps per Second: 22,993.37483
Overall Steps per Second: 10,827.60462

Timestep Collection Time: 2.17558
Timestep Consumption Time: 2.44446
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.62004

Cumulative Model Updates: 73,544
Cumulative Timesteps: 613,297,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 613297568...
Checkpoint 613297568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,768.13630
Policy Entropy: 3.65884
Value Function Loss: 0.06951

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.49139
Value Function Update Magnitude: 0.61779

Collected Steps per Second: 22,715.21667
Overall Steps per Second: 10,648.54215

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.49571
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.69811

Cumulative Model Updates: 73,550
Cumulative Timesteps: 613,347,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,573.67132
Policy Entropy: 3.65864
Value Function Loss: 0.07316

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.46490
Value Function Update Magnitude: 0.63551

Collected Steps per Second: 22,684.86517
Overall Steps per Second: 10,793.71943

Timestep Collection Time: 2.20517
Timestep Consumption Time: 2.42938
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.63455

Cumulative Model Updates: 73,556
Cumulative Timesteps: 613,397,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 613397620...
Checkpoint 613397620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,009.82620
Policy Entropy: 3.66364
Value Function Loss: 0.07030

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.47004
Value Function Update Magnitude: 0.66655

Collected Steps per Second: 22,628.51646
Overall Steps per Second: 10,734.19918

Timestep Collection Time: 2.21031
Timestep Consumption Time: 2.44919
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.65950

Cumulative Model Updates: 73,562
Cumulative Timesteps: 613,447,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,097.34349
Policy Entropy: 3.67629
Value Function Loss: 0.06543

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.71698

Collected Steps per Second: 22,614.42074
Overall Steps per Second: 10,662.72630

Timestep Collection Time: 2.21169
Timestep Consumption Time: 2.47905
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.69073

Cumulative Model Updates: 73,568
Cumulative Timesteps: 613,497,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 613497652...
Checkpoint 613497652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.82472
Policy Entropy: 3.69244
Value Function Loss: 0.05873

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.61357
Value Function Update Magnitude: 0.76743

Collected Steps per Second: 22,851.79048
Overall Steps per Second: 10,840.16668

Timestep Collection Time: 2.18819
Timestep Consumption Time: 2.42466
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.61284

Cumulative Model Updates: 73,574
Cumulative Timesteps: 613,547,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,045.10110
Policy Entropy: 3.69597
Value Function Loss: 0.05795

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.64223
Value Function Update Magnitude: 0.79327

Collected Steps per Second: 22,818.79985
Overall Steps per Second: 10,699.67734

Timestep Collection Time: 2.19153
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.67379

Cumulative Model Updates: 73,580
Cumulative Timesteps: 613,597,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 613597664...
Checkpoint 613597664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,427.01387
Policy Entropy: 3.69459
Value Function Loss: 0.05849

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.59775
Value Function Update Magnitude: 0.77096

Collected Steps per Second: 22,598.64638
Overall Steps per Second: 10,796.00372

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.41892
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.63153

Cumulative Model Updates: 73,586
Cumulative Timesteps: 613,647,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.35732
Policy Entropy: 3.69780
Value Function Loss: 0.05787

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.54480
Value Function Update Magnitude: 0.78181

Collected Steps per Second: 22,953.79666
Overall Steps per Second: 10,731.17922

Timestep Collection Time: 2.17890
Timestep Consumption Time: 2.48173
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.66062

Cumulative Model Updates: 73,592
Cumulative Timesteps: 613,697,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 613697680...
Checkpoint 613697680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,261.37211
Policy Entropy: 3.69566
Value Function Loss: 0.05941

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.53854
Value Function Update Magnitude: 0.71909

Collected Steps per Second: 22,868.39595
Overall Steps per Second: 10,864.08599

Timestep Collection Time: 2.18739
Timestep Consumption Time: 2.41696
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.60434

Cumulative Model Updates: 73,598
Cumulative Timesteps: 613,747,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,762.93196
Policy Entropy: 3.70534
Value Function Loss: 0.06026

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10412
Policy Update Magnitude: 0.53110
Value Function Update Magnitude: 0.66582

Collected Steps per Second: 22,609.73343
Overall Steps per Second: 10,624.43567

Timestep Collection Time: 2.21259
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.70858

Cumulative Model Updates: 73,604
Cumulative Timesteps: 613,797,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 613797728...
Checkpoint 613797728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,583.32006
Policy Entropy: 3.70766
Value Function Loss: 0.06041

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.63183
Value Function Update Magnitude: 0.68543

Collected Steps per Second: 22,765.43854
Overall Steps per Second: 10,862.13664

Timestep Collection Time: 2.19658
Timestep Consumption Time: 2.40712
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.60370

Cumulative Model Updates: 73,610
Cumulative Timesteps: 613,847,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.07907
Policy Entropy: 3.71288
Value Function Loss: 0.05974

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.71871
Value Function Update Magnitude: 0.72264

Collected Steps per Second: 22,987.46732
Overall Steps per Second: 10,763.40755

Timestep Collection Time: 2.17614
Timestep Consumption Time: 2.47146
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.64760

Cumulative Model Updates: 73,616
Cumulative Timesteps: 613,897,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 613897758...
Checkpoint 613897758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,682.00188
Policy Entropy: 3.70751
Value Function Loss: 0.05827

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06461
Policy Update Magnitude: 0.71770
Value Function Update Magnitude: 0.67017

Collected Steps per Second: 22,219.27457
Overall Steps per Second: 10,913.14614

Timestep Collection Time: 2.25264
Timestep Consumption Time: 2.33376
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.58640

Cumulative Model Updates: 73,622
Cumulative Timesteps: 613,947,810

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,623.56833
Policy Entropy: 3.70479
Value Function Loss: 0.05907

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.67001
Value Function Update Magnitude: 0.72600

Collected Steps per Second: 21,988.51028
Overall Steps per Second: 10,808.03152

Timestep Collection Time: 2.27464
Timestep Consumption Time: 2.35303
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.62767

Cumulative Model Updates: 73,628
Cumulative Timesteps: 613,997,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 613997826...
Checkpoint 613997826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,049.27894
Policy Entropy: 3.71468
Value Function Loss: 0.05967

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.52945
Value Function Update Magnitude: 0.75955

Collected Steps per Second: 22,181.30509
Overall Steps per Second: 10,683.62008

Timestep Collection Time: 2.25442
Timestep Consumption Time: 2.42620
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.68062

Cumulative Model Updates: 73,634
Cumulative Timesteps: 614,047,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,866.32357
Policy Entropy: 3.72298
Value Function Loss: 0.05995

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.51078
Value Function Update Magnitude: 0.79847

Collected Steps per Second: 22,350.47704
Overall Steps per Second: 10,910.24648

Timestep Collection Time: 2.23718
Timestep Consumption Time: 2.34585
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.58303

Cumulative Model Updates: 73,640
Cumulative Timesteps: 614,097,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 614097834...
Checkpoint 614097834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,483.89230
Policy Entropy: 3.73160
Value Function Loss: 0.06006

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.49578
Value Function Update Magnitude: 0.81239

Collected Steps per Second: 21,848.72951
Overall Steps per Second: 10,688.37440

Timestep Collection Time: 2.28874
Timestep Consumption Time: 2.38980
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.67854

Cumulative Model Updates: 73,646
Cumulative Timesteps: 614,147,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,734.96057
Policy Entropy: 3.73081
Value Function Loss: 0.06262

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.55052
Value Function Update Magnitude: 0.83986

Collected Steps per Second: 22,170.79597
Overall Steps per Second: 10,840.98533

Timestep Collection Time: 2.25639
Timestep Consumption Time: 2.35813
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61453

Cumulative Model Updates: 73,652
Cumulative Timesteps: 614,197,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 614197866...
Checkpoint 614197866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,627.74345
Policy Entropy: 3.72670
Value Function Loss: 0.06522

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.53705
Value Function Update Magnitude: 0.87618

Collected Steps per Second: 21,916.43612
Overall Steps per Second: 10,662.02960

Timestep Collection Time: 2.28267
Timestep Consumption Time: 2.40949
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.69216

Cumulative Model Updates: 73,658
Cumulative Timesteps: 614,247,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,177.58017
Policy Entropy: 3.70903
Value Function Loss: 0.06664

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07343
Policy Update Magnitude: 0.57447
Value Function Update Magnitude: 0.88196

Collected Steps per Second: 23,152.69435
Overall Steps per Second: 10,964.35333

Timestep Collection Time: 2.15992
Timestep Consumption Time: 2.40104
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.56096

Cumulative Model Updates: 73,664
Cumulative Timesteps: 614,297,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 614297902...
Checkpoint 614297902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,448.15113
Policy Entropy: 3.70286
Value Function Loss: 0.06613

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.56413
Value Function Update Magnitude: 0.86911

Collected Steps per Second: 22,260.07914
Overall Steps per Second: 10,610.68588

Timestep Collection Time: 2.24635
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.71261

Cumulative Model Updates: 73,670
Cumulative Timesteps: 614,347,906

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,097.78760
Policy Entropy: 3.68886
Value Function Loss: 0.06632

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.52090
Value Function Update Magnitude: 0.86663

Collected Steps per Second: 23,020.48817
Overall Steps per Second: 10,923.27392

Timestep Collection Time: 2.17267
Timestep Consumption Time: 2.40617
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.57885

Cumulative Model Updates: 73,676
Cumulative Timesteps: 614,397,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 614397922...
Checkpoint 614397922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,150.63233
Policy Entropy: 3.69085
Value Function Loss: 0.06553

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.52652
Value Function Update Magnitude: 0.82192

Collected Steps per Second: 22,560.22971
Overall Steps per Second: 10,583.59024

Timestep Collection Time: 2.21682
Timestep Consumption Time: 2.50861
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.72543

Cumulative Model Updates: 73,682
Cumulative Timesteps: 614,447,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,582.36405
Policy Entropy: 3.69031
Value Function Loss: 0.06818

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.57831
Value Function Update Magnitude: 0.70974

Collected Steps per Second: 23,069.92334
Overall Steps per Second: 10,886.33550

Timestep Collection Time: 2.16810
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.59457

Cumulative Model Updates: 73,688
Cumulative Timesteps: 614,497,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 614497952...
Checkpoint 614497952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,072.03948
Policy Entropy: 3.68909
Value Function Loss: 0.06968

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.60727
Value Function Update Magnitude: 0.61408

Collected Steps per Second: 22,680.96520
Overall Steps per Second: 10,709.45411

Timestep Collection Time: 2.20458
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.66896

Cumulative Model Updates: 73,694
Cumulative Timesteps: 614,547,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,727.38072
Policy Entropy: 3.69322
Value Function Loss: 0.07005

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.60055
Value Function Update Magnitude: 0.66096

Collected Steps per Second: 22,777.98307
Overall Steps per Second: 10,825.83367

Timestep Collection Time: 2.19580
Timestep Consumption Time: 2.42426
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.62006

Cumulative Model Updates: 73,700
Cumulative Timesteps: 614,597,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 614597970...
Checkpoint 614597970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,953.05940
Policy Entropy: 3.69358
Value Function Loss: 0.07194

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.57729
Value Function Update Magnitude: 0.65834

Collected Steps per Second: 22,585.88015
Overall Steps per Second: 10,698.55702

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.46153
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.67689

Cumulative Model Updates: 73,706
Cumulative Timesteps: 614,648,006

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,182.59540
Policy Entropy: 3.69032
Value Function Loss: 0.06982

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.58936
Value Function Update Magnitude: 0.69529

Collected Steps per Second: 22,822.65543
Overall Steps per Second: 10,842.89410

Timestep Collection Time: 2.19151
Timestep Consumption Time: 2.42128
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61279

Cumulative Model Updates: 73,712
Cumulative Timesteps: 614,698,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 614698022...
Checkpoint 614698022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,363.71826
Policy Entropy: 3.69147
Value Function Loss: 0.06907

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08126
Policy Update Magnitude: 0.56980
Value Function Update Magnitude: 0.78561

Collected Steps per Second: 22,604.90110
Overall Steps per Second: 10,727.58654

Timestep Collection Time: 2.21191
Timestep Consumption Time: 2.44897
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.66088

Cumulative Model Updates: 73,718
Cumulative Timesteps: 614,748,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,272.26810
Policy Entropy: 3.67685
Value Function Loss: 0.07074

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.56107
Value Function Update Magnitude: 0.79260

Collected Steps per Second: 22,834.57605
Overall Steps per Second: 10,813.00938

Timestep Collection Time: 2.19063
Timestep Consumption Time: 2.43547
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.62609

Cumulative Model Updates: 73,724
Cumulative Timesteps: 614,798,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 614798044...
Checkpoint 614798044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,415.41337
Policy Entropy: 3.68580
Value Function Loss: 0.07146

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.49384
Value Function Update Magnitude: 0.72848

Collected Steps per Second: 22,752.88841
Overall Steps per Second: 10,727.62093

Timestep Collection Time: 2.19814
Timestep Consumption Time: 2.46403
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.66217

Cumulative Model Updates: 73,730
Cumulative Timesteps: 614,848,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,619.47448
Policy Entropy: 3.67919
Value Function Loss: 0.07254

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.14090
Policy Update Magnitude: 0.42208
Value Function Update Magnitude: 0.75637

Collected Steps per Second: 23,181.52179
Overall Steps per Second: 10,936.23127

Timestep Collection Time: 2.15732
Timestep Consumption Time: 2.41555
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.57287

Cumulative Model Updates: 73,736
Cumulative Timesteps: 614,898,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 614898068...
Checkpoint 614898068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,644.64168
Policy Entropy: 3.68829
Value Function Loss: 0.07177

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.40585
Value Function Update Magnitude: 0.81752

Collected Steps per Second: 22,488.24922
Overall Steps per Second: 10,578.36491

Timestep Collection Time: 2.22338
Timestep Consumption Time: 2.50324
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.72663

Cumulative Model Updates: 73,742
Cumulative Timesteps: 614,948,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,594.13147
Policy Entropy: 3.69676
Value Function Loss: 0.06775

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.42358
Value Function Update Magnitude: 0.85152

Collected Steps per Second: 22,588.96794
Overall Steps per Second: 10,665.36987

Timestep Collection Time: 2.21444
Timestep Consumption Time: 2.47569
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.69013

Cumulative Model Updates: 73,748
Cumulative Timesteps: 614,998,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 614998090...
Checkpoint 614998090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,639.17435
Policy Entropy: 3.70915
Value Function Loss: 0.06555

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.45821
Value Function Update Magnitude: 0.78048

Collected Steps per Second: 22,364.25068
Overall Steps per Second: 10,940.76635

Timestep Collection Time: 2.23652
Timestep Consumption Time: 2.33519
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.57171

Cumulative Model Updates: 73,754
Cumulative Timesteps: 615,048,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,026.40851
Policy Entropy: 3.71256
Value Function Loss: 0.06324

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.43942
Value Function Update Magnitude: 0.76060

Collected Steps per Second: 22,256.77428
Overall Steps per Second: 10,857.36392

Timestep Collection Time: 2.24794
Timestep Consumption Time: 2.36017
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60812

Cumulative Model Updates: 73,760
Cumulative Timesteps: 615,098,140

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 615098140...
Checkpoint 615098140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,152.92720
Policy Entropy: 3.72022
Value Function Loss: 0.05903

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.45687
Value Function Update Magnitude: 0.75137

Collected Steps per Second: 22,213.10613
Overall Steps per Second: 10,707.97162

Timestep Collection Time: 2.25218
Timestep Consumption Time: 2.41985
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.67203

Cumulative Model Updates: 73,766
Cumulative Timesteps: 615,148,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,525.92798
Policy Entropy: 3.72431
Value Function Loss: 0.05553

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.51352
Value Function Update Magnitude: 0.65958

Collected Steps per Second: 21,934.98478
Overall Steps per Second: 10,777.44509

Timestep Collection Time: 2.28001
Timestep Consumption Time: 2.36042
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.64043

Cumulative Model Updates: 73,772
Cumulative Timesteps: 615,198,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 615198180...
Checkpoint 615198180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,915.03710
Policy Entropy: 3.73992
Value Function Loss: 0.05338

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.55994
Value Function Update Magnitude: 0.69967

Collected Steps per Second: 21,911.69606
Overall Steps per Second: 10,740.08130

Timestep Collection Time: 2.28316
Timestep Consumption Time: 2.37490
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.65807

Cumulative Model Updates: 73,778
Cumulative Timesteps: 615,248,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,617.30451
Policy Entropy: 3.72289
Value Function Loss: 0.05774

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.62091
Value Function Update Magnitude: 0.74082

Collected Steps per Second: 22,303.86749
Overall Steps per Second: 10,893.06444

Timestep Collection Time: 2.24230
Timestep Consumption Time: 2.34888
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.59118

Cumulative Model Updates: 73,784
Cumulative Timesteps: 615,298,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 615298220...
Checkpoint 615298220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,927.53077
Policy Entropy: 3.72981
Value Function Loss: 0.05806

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.66338
Value Function Update Magnitude: 0.77532

Collected Steps per Second: 22,079.24324
Overall Steps per Second: 10,659.93635

Timestep Collection Time: 2.26493
Timestep Consumption Time: 2.42628
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.69121

Cumulative Model Updates: 73,790
Cumulative Timesteps: 615,348,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,372.65460
Policy Entropy: 3.71976
Value Function Loss: 0.05952

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.57905
Value Function Update Magnitude: 0.78720

Collected Steps per Second: 22,160.78016
Overall Steps per Second: 10,574.21384

Timestep Collection Time: 2.25759
Timestep Consumption Time: 2.47373
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.73132

Cumulative Model Updates: 73,796
Cumulative Timesteps: 615,398,258

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 615398258...
Checkpoint 615398258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,585.02924
Policy Entropy: 3.70539
Value Function Loss: 0.06018

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.77191

Collected Steps per Second: 22,661.91615
Overall Steps per Second: 10,846.46771

Timestep Collection Time: 2.20723
Timestep Consumption Time: 2.40441
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.61164

Cumulative Model Updates: 73,802
Cumulative Timesteps: 615,448,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,195.61979
Policy Entropy: 3.69691
Value Function Loss: 0.06160

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.50917
Value Function Update Magnitude: 0.77177

Collected Steps per Second: 22,803.67474
Overall Steps per Second: 10,763.44560

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.45341
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.64665

Cumulative Model Updates: 73,808
Cumulative Timesteps: 615,498,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 615498292...
Checkpoint 615498292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,335.52828
Policy Entropy: 3.70059
Value Function Loss: 0.06228

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.48438
Value Function Update Magnitude: 0.77907

Collected Steps per Second: 22,745.62260
Overall Steps per Second: 10,928.13959

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.37855
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.57809

Cumulative Model Updates: 73,814
Cumulative Timesteps: 615,548,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,820.19409
Policy Entropy: 3.71255
Value Function Loss: 0.06138

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.50040
Value Function Update Magnitude: 0.78590

Collected Steps per Second: 22,844.83255
Overall Steps per Second: 10,832.94012

Timestep Collection Time: 2.18929
Timestep Consumption Time: 2.42755
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61684

Cumulative Model Updates: 73,820
Cumulative Timesteps: 615,598,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 615598336...
Checkpoint 615598336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,054.40293
Policy Entropy: 3.72058
Value Function Loss: 0.06266

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.77811

Collected Steps per Second: 22,644.67530
Overall Steps per Second: 10,680.79872

Timestep Collection Time: 2.20847
Timestep Consumption Time: 2.47377
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.68223

Cumulative Model Updates: 73,826
Cumulative Timesteps: 615,648,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,065.71054
Policy Entropy: 3.71207
Value Function Loss: 0.06396

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11259
Policy Update Magnitude: 0.50111
Value Function Update Magnitude: 0.77857

Collected Steps per Second: 23,208.40975
Overall Steps per Second: 10,891.25927

Timestep Collection Time: 2.15499
Timestep Consumption Time: 2.43713
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.59212

Cumulative Model Updates: 73,832
Cumulative Timesteps: 615,698,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 615698360...
Checkpoint 615698360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,292.01575
Policy Entropy: 3.70349
Value Function Loss: 0.06785

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.48690
Value Function Update Magnitude: 0.77262

Collected Steps per Second: 22,328.87177
Overall Steps per Second: 10,672.18460

Timestep Collection Time: 2.23988
Timestep Consumption Time: 2.44651
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.68639

Cumulative Model Updates: 73,838
Cumulative Timesteps: 615,748,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,961.47729
Policy Entropy: 3.69848
Value Function Loss: 0.06857

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.79899

Collected Steps per Second: 22,749.40747
Overall Steps per Second: 10,803.76822

Timestep Collection Time: 2.19883
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.63005

Cumulative Model Updates: 73,844
Cumulative Timesteps: 615,798,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 615798396...
Checkpoint 615798396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,860.60245
Policy Entropy: 3.70978
Value Function Loss: 0.06989

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.53673
Value Function Update Magnitude: 0.82028

Collected Steps per Second: 22,314.73748
Overall Steps per Second: 10,726.80208

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.42103
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.66215

Cumulative Model Updates: 73,850
Cumulative Timesteps: 615,848,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,301.03525
Policy Entropy: 3.72045
Value Function Loss: 0.06789

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.48903
Value Function Update Magnitude: 0.84276

Collected Steps per Second: 23,031.59477
Overall Steps per Second: 10,879.80987

Timestep Collection Time: 2.17241
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.59879

Cumulative Model Updates: 73,856
Cumulative Timesteps: 615,898,440

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 615898440...
Checkpoint 615898440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,319.56058
Policy Entropy: 3.72652
Value Function Loss: 0.06786

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.50408
Value Function Update Magnitude: 0.85651

Collected Steps per Second: 22,609.63582
Overall Steps per Second: 10,685.77157

Timestep Collection Time: 2.21145
Timestep Consumption Time: 2.46767
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.67912

Cumulative Model Updates: 73,862
Cumulative Timesteps: 615,948,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,027.68800
Policy Entropy: 3.71678
Value Function Loss: 0.06855

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.59455
Value Function Update Magnitude: 0.79007

Collected Steps per Second: 22,812.57617
Overall Steps per Second: 10,822.52300

Timestep Collection Time: 2.19239
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.62129

Cumulative Model Updates: 73,868
Cumulative Timesteps: 615,998,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 615998454...
Checkpoint 615998454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,416.83175
Policy Entropy: 3.70925
Value Function Loss: 0.07020

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.64848
Value Function Update Magnitude: 0.71946

Collected Steps per Second: 22,414.23010
Overall Steps per Second: 10,699.28552

Timestep Collection Time: 2.23153
Timestep Consumption Time: 2.44336
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.67489

Cumulative Model Updates: 73,874
Cumulative Timesteps: 616,048,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,374.68716
Policy Entropy: 3.70310
Value Function Loss: 0.06953

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.73113
Value Function Update Magnitude: 0.69649

Collected Steps per Second: 22,437.26747
Overall Steps per Second: 10,580.96967

Timestep Collection Time: 2.22879
Timestep Consumption Time: 2.49743
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.72622

Cumulative Model Updates: 73,880
Cumulative Timesteps: 616,098,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 616098480...
Checkpoint 616098480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,239.75935
Policy Entropy: 3.69214
Value Function Loss: 0.07037

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.71235
Value Function Update Magnitude: 0.75860

Collected Steps per Second: 22,632.41424
Overall Steps per Second: 10,647.32509

Timestep Collection Time: 2.20975
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.69714

Cumulative Model Updates: 73,886
Cumulative Timesteps: 616,148,492

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,485.58630
Policy Entropy: 3.67597
Value Function Loss: 0.07345

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11129
Policy Update Magnitude: 0.58412
Value Function Update Magnitude: 0.81385

Collected Steps per Second: 22,969.21019
Overall Steps per Second: 10,775.28371

Timestep Collection Time: 2.17726
Timestep Consumption Time: 2.46391
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.64118

Cumulative Model Updates: 73,892
Cumulative Timesteps: 616,198,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 616198502...
Checkpoint 616198502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,136.35934
Policy Entropy: 3.66052
Value Function Loss: 0.07612

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.53911
Value Function Update Magnitude: 0.83331

Collected Steps per Second: 22,758.87481
Overall Steps per Second: 10,618.98370

Timestep Collection Time: 2.19879
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.71250

Cumulative Model Updates: 73,898
Cumulative Timesteps: 616,248,544

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,996.08690
Policy Entropy: 3.66177
Value Function Loss: 0.07640

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.49566
Value Function Update Magnitude: 0.81225

Collected Steps per Second: 22,770.09271
Overall Steps per Second: 10,739.63014

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.46087
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.65770

Cumulative Model Updates: 73,904
Cumulative Timesteps: 616,298,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 616298566...
Checkpoint 616298566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,473.30388
Policy Entropy: 3.65874
Value Function Loss: 0.07813

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.43514
Value Function Update Magnitude: 0.71608

Collected Steps per Second: 22,649.53159
Overall Steps per Second: 10,810.56809

Timestep Collection Time: 2.20879
Timestep Consumption Time: 2.41891
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.62769

Cumulative Model Updates: 73,910
Cumulative Timesteps: 616,348,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,806.14725
Policy Entropy: 3.66925
Value Function Loss: 0.08119

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.42472
Value Function Update Magnitude: 0.62726

Collected Steps per Second: 22,154.68381
Overall Steps per Second: 10,830.47433

Timestep Collection Time: 2.25830
Timestep Consumption Time: 2.36125
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.61956

Cumulative Model Updates: 73,916
Cumulative Timesteps: 616,398,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 616398626...
Checkpoint 616398626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,760.46247
Policy Entropy: 3.68213
Value Function Loss: 0.07898

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.46230
Value Function Update Magnitude: 0.63058

Collected Steps per Second: 22,096.26132
Overall Steps per Second: 10,757.49620

Timestep Collection Time: 2.26391
Timestep Consumption Time: 2.38624
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.65015

Cumulative Model Updates: 73,922
Cumulative Timesteps: 616,448,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,186.75343
Policy Entropy: 3.67530
Value Function Loss: 0.07730

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08675
Policy Update Magnitude: 0.47740
Value Function Update Magnitude: 0.70396

Collected Steps per Second: 22,378.18397
Overall Steps per Second: 10,930.38324

Timestep Collection Time: 2.23441
Timestep Consumption Time: 2.34018
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.57459

Cumulative Model Updates: 73,928
Cumulative Timesteps: 616,498,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 616498652...
Checkpoint 616498652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,088.77783
Policy Entropy: 3.66824
Value Function Loss: 0.07315

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.56582
Value Function Update Magnitude: 0.76209

Collected Steps per Second: 22,064.27122
Overall Steps per Second: 10,673.22567

Timestep Collection Time: 2.26729
Timestep Consumption Time: 2.41977
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.68706

Cumulative Model Updates: 73,934
Cumulative Timesteps: 616,548,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,300.86228
Policy Entropy: 3.64842
Value Function Loss: 0.07362

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.55527
Value Function Update Magnitude: 0.70762

Collected Steps per Second: 22,178.40526
Overall Steps per Second: 10,574.84726

Timestep Collection Time: 2.25580
Timestep Consumption Time: 2.47524
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.73104

Cumulative Model Updates: 73,940
Cumulative Timesteps: 616,598,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 616598708...
Checkpoint 616598708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,468.60937
Policy Entropy: 3.65965
Value Function Loss: 0.07341

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.46382
Value Function Update Magnitude: 0.72568

Collected Steps per Second: 22,945.33036
Overall Steps per Second: 10,936.59139

Timestep Collection Time: 2.17962
Timestep Consumption Time: 2.39329
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.57291

Cumulative Model Updates: 73,946
Cumulative Timesteps: 616,648,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,326.82205
Policy Entropy: 3.67328
Value Function Loss: 0.07341

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.45123
Value Function Update Magnitude: 0.67318

Collected Steps per Second: 22,973.48839
Overall Steps per Second: 10,917.43904

Timestep Collection Time: 2.17694
Timestep Consumption Time: 2.40398
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.58093

Cumulative Model Updates: 73,952
Cumulative Timesteps: 616,698,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 616698732...
Checkpoint 616698732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,597.38867
Policy Entropy: 3.68843
Value Function Loss: 0.07429

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.54366
Value Function Update Magnitude: 0.69271

Collected Steps per Second: 22,693.03854
Overall Steps per Second: 10,700.16040

Timestep Collection Time: 2.20367
Timestep Consumption Time: 2.46990
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.67357

Cumulative Model Updates: 73,958
Cumulative Timesteps: 616,748,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,691.24790
Policy Entropy: 3.69030
Value Function Loss: 0.07341

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.60662
Value Function Update Magnitude: 0.67384

Collected Steps per Second: 23,048.95520
Overall Steps per Second: 10,802.31905

Timestep Collection Time: 2.16999
Timestep Consumption Time: 2.46013
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.63012

Cumulative Model Updates: 73,964
Cumulative Timesteps: 616,798,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 616798756...
Checkpoint 616798756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.17930
Policy Entropy: 3.68332
Value Function Loss: 0.07325

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.61305
Value Function Update Magnitude: 0.69357

Collected Steps per Second: 22,562.35747
Overall Steps per Second: 10,656.14016

Timestep Collection Time: 2.21714
Timestep Consumption Time: 2.47724
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.69438

Cumulative Model Updates: 73,970
Cumulative Timesteps: 616,848,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,484.88677
Policy Entropy: 3.65773
Value Function Loss: 0.07360

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.55936
Value Function Update Magnitude: 0.75370

Collected Steps per Second: 22,836.66569
Overall Steps per Second: 10,826.30411

Timestep Collection Time: 2.18981
Timestep Consumption Time: 2.42931
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61912

Cumulative Model Updates: 73,976
Cumulative Timesteps: 616,898,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 616898788...
Checkpoint 616898788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,953.21633
Policy Entropy: 3.62913
Value Function Loss: 0.07394

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.54085
Value Function Update Magnitude: 0.73294

Collected Steps per Second: 22,862.19737
Overall Steps per Second: 10,729.78981

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.47380
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.66160

Cumulative Model Updates: 73,982
Cumulative Timesteps: 616,948,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,052.88460
Policy Entropy: 3.62779
Value Function Loss: 0.07244

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.15528
Policy Update Magnitude: 0.50871
Value Function Update Magnitude: 0.74927

Collected Steps per Second: 22,611.95674
Overall Steps per Second: 10,639.42058

Timestep Collection Time: 2.21228
Timestep Consumption Time: 2.48948
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.70176

Cumulative Model Updates: 73,988
Cumulative Timesteps: 616,998,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 616998830...
Checkpoint 616998830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,994.09065
Policy Entropy: 3.65557
Value Function Loss: 0.06992

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.16816
Policy Update Magnitude: 0.44668
Value Function Update Magnitude: 0.77586

Collected Steps per Second: 22,829.64678
Overall Steps per Second: 10,829.00368

Timestep Collection Time: 2.19127
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61963

Cumulative Model Updates: 73,994
Cumulative Timesteps: 617,048,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,059.43547
Policy Entropy: 3.67170
Value Function Loss: 0.07028

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.14676
Policy Update Magnitude: 0.39639
Value Function Update Magnitude: 0.67135

Collected Steps per Second: 22,877.30175
Overall Steps per Second: 10,723.31880

Timestep Collection Time: 2.18583
Timestep Consumption Time: 2.47746
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.66330

Cumulative Model Updates: 74,000
Cumulative Timesteps: 617,098,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 617098862...
Checkpoint 617098862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,156.74419
Policy Entropy: 3.67928
Value Function Loss: 0.06953

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.43133
Value Function Update Magnitude: 0.65850

Collected Steps per Second: 22,754.00130
Overall Steps per Second: 10,820.13148

Timestep Collection Time: 2.19777
Timestep Consumption Time: 2.42399
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.62176

Cumulative Model Updates: 74,006
Cumulative Timesteps: 617,148,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,697.01557
Policy Entropy: 3.67665
Value Function Loss: 0.06996

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.42696
Value Function Update Magnitude: 0.70775

Collected Steps per Second: 22,670.61166
Overall Steps per Second: 10,586.76443

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.51738
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.72288

Cumulative Model Updates: 74,012
Cumulative Timesteps: 617,198,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 617198870...
Checkpoint 617198870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,681.33471
Policy Entropy: 3.67683
Value Function Loss: 0.06634

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.44920
Value Function Update Magnitude: 0.68850

Collected Steps per Second: 22,679.03260
Overall Steps per Second: 10,640.74715

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.49484
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.70005

Cumulative Model Updates: 74,018
Cumulative Timesteps: 617,248,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,975.37178
Policy Entropy: 3.68495
Value Function Loss: 0.06420

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.42740
Value Function Update Magnitude: 0.69336

Collected Steps per Second: 23,073.73521
Overall Steps per Second: 10,845.59566

Timestep Collection Time: 2.16783
Timestep Consumption Time: 2.44418
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.61201

Cumulative Model Updates: 74,024
Cumulative Timesteps: 617,298,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 617298902...
Checkpoint 617298902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,842.46966
Policy Entropy: 3.69009
Value Function Loss: 0.06129

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.45176
Value Function Update Magnitude: 0.65596

Collected Steps per Second: 22,600.49957
Overall Steps per Second: 10,610.22428

Timestep Collection Time: 2.21340
Timestep Consumption Time: 2.50130
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.71470

Cumulative Model Updates: 74,030
Cumulative Timesteps: 617,348,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,461.05332
Policy Entropy: 3.69732
Value Function Loss: 0.06093

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.62585

Collected Steps per Second: 22,883.44698
Overall Steps per Second: 10,812.59047

Timestep Collection Time: 2.18603
Timestep Consumption Time: 2.44042
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62646

Cumulative Model Updates: 74,036
Cumulative Timesteps: 617,398,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 617398950...
Checkpoint 617398950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,081.55288
Policy Entropy: 3.70220
Value Function Loss: 0.06047

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06342
Policy Update Magnitude: 0.68258
Value Function Update Magnitude: 0.62380

Collected Steps per Second: 22,710.85119
Overall Steps per Second: 10,743.00254

Timestep Collection Time: 2.20221
Timestep Consumption Time: 2.45329
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.65550

Cumulative Model Updates: 74,042
Cumulative Timesteps: 617,448,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,548.60573
Policy Entropy: 3.69188
Value Function Loss: 0.06067

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.66915
Value Function Update Magnitude: 0.65301

Collected Steps per Second: 22,721.13354
Overall Steps per Second: 10,823.21531

Timestep Collection Time: 2.20121
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.62099

Cumulative Model Updates: 74,048
Cumulative Timesteps: 617,498,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 617498978...
Checkpoint 617498978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,435.81484
Policy Entropy: 3.69964
Value Function Loss: 0.06482

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.55965
Value Function Update Magnitude: 0.61003

Collected Steps per Second: 22,595.96192
Overall Steps per Second: 10,728.68018

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.66283

Cumulative Model Updates: 74,054
Cumulative Timesteps: 617,549,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,360.19518
Policy Entropy: 3.68154
Value Function Loss: 0.06864

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.53650
Value Function Update Magnitude: 0.52431

Collected Steps per Second: 22,800.47565
Overall Steps per Second: 10,790.51537

Timestep Collection Time: 2.19390
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.63574

Cumulative Model Updates: 74,060
Cumulative Timesteps: 617,599,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 617599026...
Checkpoint 617599026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,572.60003
Policy Entropy: 3.68968
Value Function Loss: 0.06700

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.52456
Value Function Update Magnitude: 0.58210

Collected Steps per Second: 22,120.92913
Overall Steps per Second: 10,665.44147

Timestep Collection Time: 2.26039
Timestep Consumption Time: 2.42783
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.68823

Cumulative Model Updates: 74,066
Cumulative Timesteps: 617,649,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,513.40664
Policy Entropy: 3.68376
Value Function Loss: 0.06321

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.71163

Collected Steps per Second: 22,527.03467
Overall Steps per Second: 10,606.66838

Timestep Collection Time: 2.21973
Timestep Consumption Time: 2.49466
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.71439

Cumulative Model Updates: 74,072
Cumulative Timesteps: 617,699,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 617699032...
Checkpoint 617699032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,920.16361
Policy Entropy: 3.70083
Value Function Loss: 0.06186

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.53458
Value Function Update Magnitude: 0.65449

Collected Steps per Second: 22,725.34146
Overall Steps per Second: 10,656.67106

Timestep Collection Time: 2.20063
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.69284

Cumulative Model Updates: 74,078
Cumulative Timesteps: 617,749,042

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,865.29639
Policy Entropy: 3.70084
Value Function Loss: 0.06081

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.56471
Value Function Update Magnitude: 0.66778

Collected Steps per Second: 22,866.17607
Overall Steps per Second: 10,831.50366

Timestep Collection Time: 2.18672
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.61635

Cumulative Model Updates: 74,084
Cumulative Timesteps: 617,799,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 617799044...
Checkpoint 617799044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.01432
Policy Entropy: 3.68941
Value Function Loss: 0.06161

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.75150

Collected Steps per Second: 22,530.91005
Overall Steps per Second: 10,584.90356

Timestep Collection Time: 2.21935
Timestep Consumption Time: 2.50474
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.72409

Cumulative Model Updates: 74,090
Cumulative Timesteps: 617,849,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,537.04057
Policy Entropy: 3.68940
Value Function Loss: 0.06085

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.54271
Value Function Update Magnitude: 0.80011

Collected Steps per Second: 22,874.42258
Overall Steps per Second: 10,826.50549

Timestep Collection Time: 2.18707
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.62088

Cumulative Model Updates: 74,096
Cumulative Timesteps: 617,899,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 617899076...
Checkpoint 617899076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,000.40277
Policy Entropy: 3.68630
Value Function Loss: 0.06129

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.57164
Value Function Update Magnitude: 0.80143

Collected Steps per Second: 22,204.10309
Overall Steps per Second: 10,713.10526

Timestep Collection Time: 2.25238
Timestep Consumption Time: 2.41592
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.66830

Cumulative Model Updates: 74,102
Cumulative Timesteps: 617,949,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,750.71781
Policy Entropy: 3.70020
Value Function Loss: 0.06063

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.55414
Value Function Update Magnitude: 0.82357

Collected Steps per Second: 22,907.02084
Overall Steps per Second: 10,855.64173

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.60756

Cumulative Model Updates: 74,108
Cumulative Timesteps: 617,999,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 617999106...
Checkpoint 617999106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,627.05638
Policy Entropy: 3.68568
Value Function Loss: 0.06392

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.59861
Value Function Update Magnitude: 0.82865

Collected Steps per Second: 22,648.58742
Overall Steps per Second: 10,755.73309

Timestep Collection Time: 2.20764
Timestep Consumption Time: 2.44104
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.64868

Cumulative Model Updates: 74,114
Cumulative Timesteps: 618,049,106

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,680.15599
Policy Entropy: 3.67577
Value Function Loss: 0.06744

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06625
Policy Update Magnitude: 0.66729
Value Function Update Magnitude: 0.83646

Collected Steps per Second: 22,973.23690
Overall Steps per Second: 10,863.76278

Timestep Collection Time: 2.17662
Timestep Consumption Time: 2.42621
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.60283

Cumulative Model Updates: 74,120
Cumulative Timesteps: 618,099,110

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 618099110...
Checkpoint 618099110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,187.27758
Policy Entropy: 3.67882
Value Function Loss: 0.06924

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06727
Policy Update Magnitude: 0.71123
Value Function Update Magnitude: 0.85411

Collected Steps per Second: 22,049.86608
Overall Steps per Second: 10,640.53113

Timestep Collection Time: 2.26840
Timestep Consumption Time: 2.43230
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.70071

Cumulative Model Updates: 74,126
Cumulative Timesteps: 618,149,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.91643
Policy Entropy: 3.69097
Value Function Loss: 0.07017

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.69584
Value Function Update Magnitude: 0.82571

Collected Steps per Second: 21,952.31625
Overall Steps per Second: 10,668.53637

Timestep Collection Time: 2.27794
Timestep Consumption Time: 2.40930
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.68724

Cumulative Model Updates: 74,132
Cumulative Timesteps: 618,199,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 618199134...
Checkpoint 618199134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,285.35302
Policy Entropy: 3.69657
Value Function Loss: 0.06817

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.65410
Value Function Update Magnitude: 0.81006

Collected Steps per Second: 22,210.06638
Overall Steps per Second: 10,849.14368

Timestep Collection Time: 2.25150
Timestep Consumption Time: 2.35771
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.60921

Cumulative Model Updates: 74,138
Cumulative Timesteps: 618,249,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,936.70021
Policy Entropy: 3.69177
Value Function Loss: 0.06561

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.60372
Value Function Update Magnitude: 0.81789

Collected Steps per Second: 22,145.24000
Overall Steps per Second: 10,869.63725

Timestep Collection Time: 2.25891
Timestep Consumption Time: 2.34327
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.60218

Cumulative Model Updates: 74,144
Cumulative Timesteps: 618,299,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 618299164...
Checkpoint 618299164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,840.28770
Policy Entropy: 3.68494
Value Function Loss: 0.06328

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.55959
Value Function Update Magnitude: 0.82286

Collected Steps per Second: 22,104.91063
Overall Steps per Second: 10,736.30642

Timestep Collection Time: 2.26248
Timestep Consumption Time: 2.39573
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.65821

Cumulative Model Updates: 74,150
Cumulative Timesteps: 618,349,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,754.54864
Policy Entropy: 3.68216
Value Function Loss: 0.06205

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.57897
Value Function Update Magnitude: 0.81365

Collected Steps per Second: 22,140.38839
Overall Steps per Second: 10,818.96515

Timestep Collection Time: 2.25832
Timestep Consumption Time: 2.36320
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.62151

Cumulative Model Updates: 74,156
Cumulative Timesteps: 618,399,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 618399176...
Checkpoint 618399176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,379.01722
Policy Entropy: 3.68301
Value Function Loss: 0.06496

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10844
Policy Update Magnitude: 0.58434
Value Function Update Magnitude: 0.83779

Collected Steps per Second: 22,013.17145
Overall Steps per Second: 10,721.64130

Timestep Collection Time: 2.27137
Timestep Consumption Time: 2.39210
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.66347

Cumulative Model Updates: 74,162
Cumulative Timesteps: 618,449,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351.07059
Policy Entropy: 3.67246
Value Function Loss: 0.06661

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.84723

Collected Steps per Second: 22,439.01577
Overall Steps per Second: 10,796.94808

Timestep Collection Time: 2.22906
Timestep Consumption Time: 2.40354
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.63261

Cumulative Model Updates: 74,168
Cumulative Timesteps: 618,499,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 618499194...
Checkpoint 618499194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,436.95273
Policy Entropy: 3.66472
Value Function Loss: 0.07028

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.80250

Collected Steps per Second: 22,573.47449
Overall Steps per Second: 10,742.44257

Timestep Collection Time: 2.21552
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.65555

Cumulative Model Updates: 74,174
Cumulative Timesteps: 618,549,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,078.07144
Policy Entropy: 3.66944
Value Function Loss: 0.07200

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.48681
Value Function Update Magnitude: 0.70034

Collected Steps per Second: 22,999.63078
Overall Steps per Second: 10,948.04408

Timestep Collection Time: 2.17403
Timestep Consumption Time: 2.39317
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.56721

Cumulative Model Updates: 74,180
Cumulative Timesteps: 618,599,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 618599208...
Checkpoint 618599208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,900.10706
Policy Entropy: 3.66720
Value Function Loss: 0.07206

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.51733
Value Function Update Magnitude: 0.63045

Collected Steps per Second: 22,780.66952
Overall Steps per Second: 10,743.28644

Timestep Collection Time: 2.19493
Timestep Consumption Time: 2.45932
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.65426

Cumulative Model Updates: 74,186
Cumulative Timesteps: 618,649,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,811.08044
Policy Entropy: 3.66796
Value Function Loss: 0.07369

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.51294
Value Function Update Magnitude: 0.60323

Collected Steps per Second: 22,841.52560
Overall Steps per Second: 10,768.30206

Timestep Collection Time: 2.18996
Timestep Consumption Time: 2.45534
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.64530

Cumulative Model Updates: 74,192
Cumulative Timesteps: 618,699,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 618699232...
Checkpoint 618699232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,751.70213
Policy Entropy: 3.67411
Value Function Loss: 0.07189

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06432
Policy Update Magnitude: 0.59386
Value Function Update Magnitude: 0.68808

Collected Steps per Second: 22,906.54423
Overall Steps per Second: 10,709.22237

Timestep Collection Time: 2.18409
Timestep Consumption Time: 2.48758
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.67167

Cumulative Model Updates: 74,198
Cumulative Timesteps: 618,749,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,081.56395
Policy Entropy: 3.66874
Value Function Loss: 0.07234

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06647
Policy Update Magnitude: 0.71375
Value Function Update Magnitude: 0.77177

Collected Steps per Second: 23,001.34535
Overall Steps per Second: 10,814.74854

Timestep Collection Time: 2.17431
Timestep Consumption Time: 2.45012
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.62443

Cumulative Model Updates: 74,204
Cumulative Timesteps: 618,799,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 618799274...
Checkpoint 618799274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,257.42446
Policy Entropy: 3.65907
Value Function Loss: 0.07163

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07555
Policy Update Magnitude: 0.73810
Value Function Update Magnitude: 0.81158

Collected Steps per Second: 22,568.62699
Overall Steps per Second: 10,628.51771

Timestep Collection Time: 2.21662
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.70677

Cumulative Model Updates: 74,210
Cumulative Timesteps: 618,849,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,658.70681
Policy Entropy: 3.64865
Value Function Loss: 0.07315

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.66788
Value Function Update Magnitude: 0.80152

Collected Steps per Second: 22,927.05702
Overall Steps per Second: 10,849.54097

Timestep Collection Time: 2.18083
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60849

Cumulative Model Updates: 74,216
Cumulative Timesteps: 618,899,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 618899300...
Checkpoint 618899300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,342.92376
Policy Entropy: 3.64807
Value Function Loss: 0.07486

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.57107
Value Function Update Magnitude: 0.80841

Collected Steps per Second: 22,534.99345
Overall Steps per Second: 10,760.01439

Timestep Collection Time: 2.21922
Timestep Consumption Time: 2.42855
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.64776

Cumulative Model Updates: 74,222
Cumulative Timesteps: 618,949,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,784.49202
Policy Entropy: 3.64858
Value Function Loss: 0.07373

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.53291
Value Function Update Magnitude: 0.87594

Collected Steps per Second: 22,919.97241
Overall Steps per Second: 10,844.45902

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.43012
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61249

Cumulative Model Updates: 74,228
Cumulative Timesteps: 618,999,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 618999330...
Checkpoint 618999330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,769.60025
Policy Entropy: 3.64955
Value Function Loss: 0.07602

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10820
Policy Update Magnitude: 0.50681
Value Function Update Magnitude: 0.82676

Collected Steps per Second: 22,187.80856
Overall Steps per Second: 10,696.56220

Timestep Collection Time: 2.25511
Timestep Consumption Time: 2.42265
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.67776

Cumulative Model Updates: 74,234
Cumulative Timesteps: 619,049,366

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,378.80164
Policy Entropy: 3.65183
Value Function Loss: 0.07743

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.49581
Value Function Update Magnitude: 0.71653

Collected Steps per Second: 22,946.04084
Overall Steps per Second: 10,886.41316

Timestep Collection Time: 2.18025
Timestep Consumption Time: 2.41521
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.59545

Cumulative Model Updates: 74,240
Cumulative Timesteps: 619,099,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 619099394...
Checkpoint 619099394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,331.63036
Policy Entropy: 3.64479
Value Function Loss: 0.07713

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.48731
Value Function Update Magnitude: 0.64069

Collected Steps per Second: 22,886.53362
Overall Steps per Second: 10,693.94242

Timestep Collection Time: 2.18487
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.67592

Cumulative Model Updates: 74,246
Cumulative Timesteps: 619,149,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,065.23871
Policy Entropy: 3.65226
Value Function Loss: 0.07647

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.64200

Collected Steps per Second: 22,280.43563
Overall Steps per Second: 10,901.33501

Timestep Collection Time: 2.24538
Timestep Consumption Time: 2.34378
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.58916

Cumulative Model Updates: 74,252
Cumulative Timesteps: 619,199,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 619199426...
Checkpoint 619199426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,239.68373
Policy Entropy: 3.65596
Value Function Loss: 0.07246

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.53060
Value Function Update Magnitude: 0.69488

Collected Steps per Second: 22,090.26701
Overall Steps per Second: 10,667.01624

Timestep Collection Time: 2.26471
Timestep Consumption Time: 2.42526
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.68997

Cumulative Model Updates: 74,258
Cumulative Timesteps: 619,249,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,774.71141
Policy Entropy: 3.66190
Value Function Loss: 0.07167

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.73067

Collected Steps per Second: 22,313.13519
Overall Steps per Second: 10,856.00111

Timestep Collection Time: 2.24173
Timestep Consumption Time: 2.36586
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.60759

Cumulative Model Updates: 74,264
Cumulative Timesteps: 619,299,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 619299474...
Checkpoint 619299474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,571.38361
Policy Entropy: 3.66020
Value Function Loss: 0.07327

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.52925
Value Function Update Magnitude: 0.66830

Collected Steps per Second: 21,963.97699
Overall Steps per Second: 10,631.62464

Timestep Collection Time: 2.27855
Timestep Consumption Time: 2.42873
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.70728

Cumulative Model Updates: 74,270
Cumulative Timesteps: 619,349,520

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,031.10049
Policy Entropy: 3.66196
Value Function Loss: 0.07510

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.64707
Value Function Update Magnitude: 0.62825

Collected Steps per Second: 22,374.41149
Overall Steps per Second: 10,866.45767

Timestep Collection Time: 2.23505
Timestep Consumption Time: 2.36700
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.60205

Cumulative Model Updates: 74,276
Cumulative Timesteps: 619,399,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 619399528...
Checkpoint 619399528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,690.76610
Policy Entropy: 3.65526
Value Function Loss: 0.07679

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.66290
Value Function Update Magnitude: 0.63936

Collected Steps per Second: 22,275.95642
Overall Steps per Second: 10,676.31816

Timestep Collection Time: 2.24529
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.68476

Cumulative Model Updates: 74,282
Cumulative Timesteps: 619,449,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,644.06968
Policy Entropy: 3.65450
Value Function Loss: 0.07851

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.55108
Value Function Update Magnitude: 0.65369

Collected Steps per Second: 23,031.36506
Overall Steps per Second: 10,951.73152

Timestep Collection Time: 2.17182
Timestep Consumption Time: 2.39549
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.56731

Cumulative Model Updates: 74,288
Cumulative Timesteps: 619,499,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 619499564...
Checkpoint 619499564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,788.25737
Policy Entropy: 3.65713
Value Function Loss: 0.07831

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.55182
Value Function Update Magnitude: 0.66299

Collected Steps per Second: 22,833.66921
Overall Steps per Second: 10,768.30229

Timestep Collection Time: 2.19071
Timestep Consumption Time: 2.45459
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.64530

Cumulative Model Updates: 74,294
Cumulative Timesteps: 619,549,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,656.84524
Policy Entropy: 3.65900
Value Function Loss: 0.07586

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.61238
Value Function Update Magnitude: 0.72352

Collected Steps per Second: 22,732.14657
Overall Steps per Second: 10,727.22393

Timestep Collection Time: 2.20006
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.66216

Cumulative Model Updates: 74,300
Cumulative Timesteps: 619,599,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 619599598...
Checkpoint 619599598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,341.38412
Policy Entropy: 3.66506
Value Function Loss: 0.07046

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.58239
Value Function Update Magnitude: 0.80930

Collected Steps per Second: 22,618.82210
Overall Steps per Second: 10,651.42209

Timestep Collection Time: 2.21073
Timestep Consumption Time: 2.48386
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.69458

Cumulative Model Updates: 74,306
Cumulative Timesteps: 619,649,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,870.04134
Policy Entropy: 3.67129
Value Function Loss: 0.06799

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.52477
Value Function Update Magnitude: 0.85811

Collected Steps per Second: 22,757.06269
Overall Steps per Second: 10,823.81775

Timestep Collection Time: 2.19774
Timestep Consumption Time: 2.42300
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.62074

Cumulative Model Updates: 74,312
Cumulative Timesteps: 619,699,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 619699616...
Checkpoint 619699616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,781.76316
Policy Entropy: 3.67173
Value Function Loss: 0.06711

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.47244
Value Function Update Magnitude: 0.86157

Collected Steps per Second: 22,151.48097
Overall Steps per Second: 10,665.07460

Timestep Collection Time: 2.25737
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.68857

Cumulative Model Updates: 74,318
Cumulative Timesteps: 619,749,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,522.46456
Policy Entropy: 3.67496
Value Function Loss: 0.06703

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.49545
Value Function Update Magnitude: 0.82449

Collected Steps per Second: 22,833.76385
Overall Steps per Second: 10,708.75285

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.67151

Cumulative Model Updates: 74,324
Cumulative Timesteps: 619,799,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 619799646...
Checkpoint 619799646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,244.43788
Policy Entropy: 3.67013
Value Function Loss: 0.06597

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.52906
Value Function Update Magnitude: 0.79744

Collected Steps per Second: 22,709.21704
Overall Steps per Second: 10,788.22278

Timestep Collection Time: 2.20228
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.63580

Cumulative Model Updates: 74,330
Cumulative Timesteps: 619,849,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,620.84991
Policy Entropy: 3.68235
Value Function Loss: 0.06671

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.53174
Value Function Update Magnitude: 0.75562

Collected Steps per Second: 22,625.21220
Overall Steps per Second: 10,601.84506

Timestep Collection Time: 2.21063
Timestep Consumption Time: 2.50704
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.71767

Cumulative Model Updates: 74,336
Cumulative Timesteps: 619,899,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 619899674...
Checkpoint 619899674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,318.29067
Policy Entropy: 3.68377
Value Function Loss: 0.06894

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.61653
Value Function Update Magnitude: 0.74529

Collected Steps per Second: 22,549.81855
Overall Steps per Second: 10,587.41177

Timestep Collection Time: 2.21900
Timestep Consumption Time: 2.50718
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.72618

Cumulative Model Updates: 74,342
Cumulative Timesteps: 619,949,712

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,625.06227
Policy Entropy: 3.69594
Value Function Loss: 0.06835

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.62185
Value Function Update Magnitude: 0.77712

Collected Steps per Second: 23,191.17115
Overall Steps per Second: 10,874.04990

Timestep Collection Time: 2.15755
Timestep Consumption Time: 2.44387
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.60141

Cumulative Model Updates: 74,348
Cumulative Timesteps: 619,999,748

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 619999748...
Checkpoint 619999748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,281.62732
Policy Entropy: 3.69034
Value Function Loss: 0.06860

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.62350
Value Function Update Magnitude: 0.79790

Collected Steps per Second: 22,726.62019
Overall Steps per Second: 10,681.78284

Timestep Collection Time: 2.20121
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.68330

Cumulative Model Updates: 74,354
Cumulative Timesteps: 620,049,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,107.39050
Policy Entropy: 3.69921
Value Function Loss: 0.06647

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.65159
Value Function Update Magnitude: 0.83432

Collected Steps per Second: 22,582.44929
Overall Steps per Second: 10,653.55856

Timestep Collection Time: 2.21588
Timestep Consumption Time: 2.48114
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.69702

Cumulative Model Updates: 74,360
Cumulative Timesteps: 620,099,814

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 620099814...
Checkpoint 620099814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,499.73230
Policy Entropy: 3.69142
Value Function Loss: 0.06665

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.72866
Value Function Update Magnitude: 0.84454

Collected Steps per Second: 22,743.45313
Overall Steps per Second: 10,823.25919

Timestep Collection Time: 2.19949
Timestep Consumption Time: 2.42241
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.62190

Cumulative Model Updates: 74,366
Cumulative Timesteps: 620,149,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,955.92844
Policy Entropy: 3.70069
Value Function Loss: 0.06653

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.71869
Value Function Update Magnitude: 0.78108

Collected Steps per Second: 22,585.01436
Overall Steps per Second: 10,593.03281

Timestep Collection Time: 2.21492
Timestep Consumption Time: 2.50743
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.72235

Cumulative Model Updates: 74,372
Cumulative Timesteps: 620,199,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 620199862...
Checkpoint 620199862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,580.78436
Policy Entropy: 3.68173
Value Function Loss: 0.06812

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.68265
Value Function Update Magnitude: 0.82215

Collected Steps per Second: 22,867.11707
Overall Steps per Second: 10,645.93409

Timestep Collection Time: 2.18690
Timestep Consumption Time: 2.51048
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.69738

Cumulative Model Updates: 74,378
Cumulative Timesteps: 620,249,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,323.02263
Policy Entropy: 3.67387
Value Function Loss: 0.06932

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.65085
Value Function Update Magnitude: 0.75237

Collected Steps per Second: 22,769.04071
Overall Steps per Second: 10,803.04584

Timestep Collection Time: 2.19693
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.63036

Cumulative Model Updates: 74,384
Cumulative Timesteps: 620,299,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 620299892...
Checkpoint 620299892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,950.49093
Policy Entropy: 3.67209
Value Function Loss: 0.07114

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.66536
Value Function Update Magnitude: 0.76860

Collected Steps per Second: 22,591.44959
Overall Steps per Second: 10,667.15900

Timestep Collection Time: 2.21376
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.68841

Cumulative Model Updates: 74,390
Cumulative Timesteps: 620,349,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,557.60492
Policy Entropy: 3.67621
Value Function Loss: 0.07327

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.52551
Value Function Update Magnitude: 0.80540

Collected Steps per Second: 22,852.84946
Overall Steps per Second: 10,800.48232

Timestep Collection Time: 2.18861
Timestep Consumption Time: 2.44229
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.63090

Cumulative Model Updates: 74,396
Cumulative Timesteps: 620,399,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 620399920...
Checkpoint 620399920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,284.30531
Policy Entropy: 3.67459
Value Function Loss: 0.07548

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.45469
Value Function Update Magnitude: 0.78032

Collected Steps per Second: 22,322.85917
Overall Steps per Second: 10,704.03629

Timestep Collection Time: 2.24057
Timestep Consumption Time: 2.43206
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.67263

Cumulative Model Updates: 74,402
Cumulative Timesteps: 620,449,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,277.22398
Policy Entropy: 3.66484
Value Function Loss: 0.07792

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.43252
Value Function Update Magnitude: 0.66678

Collected Steps per Second: 22,976.59454
Overall Steps per Second: 10,857.91669

Timestep Collection Time: 2.17761
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60807

Cumulative Model Updates: 74,408
Cumulative Timesteps: 620,499,970

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 620499970...
Checkpoint 620499970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,216.43473
Policy Entropy: 3.66389
Value Function Loss: 0.07554

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06899
Policy Update Magnitude: 0.54331
Value Function Update Magnitude: 0.63648

Collected Steps per Second: 22,671.01314
Overall Steps per Second: 10,730.49793

Timestep Collection Time: 2.20669
Timestep Consumption Time: 2.45553
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.66223

Cumulative Model Updates: 74,414
Cumulative Timesteps: 620,549,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,219.45657
Policy Entropy: 3.67395
Value Function Loss: 0.07174

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.63937
Value Function Update Magnitude: 0.73522

Collected Steps per Second: 22,993.91705
Overall Steps per Second: 10,821.36061

Timestep Collection Time: 2.17510
Timestep Consumption Time: 2.44669
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62178

Cumulative Model Updates: 74,420
Cumulative Timesteps: 620,600,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 620600012...
Checkpoint 620600012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,520.87773
Policy Entropy: 3.67809
Value Function Loss: 0.06868

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09836
Policy Update Magnitude: 0.61860
Value Function Update Magnitude: 0.86010

Collected Steps per Second: 22,635.02390
Overall Steps per Second: 10,696.29233

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.67713

Cumulative Model Updates: 74,426
Cumulative Timesteps: 620,650,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,679.85518
Policy Entropy: 3.68673
Value Function Loss: 0.06710

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.61018
Value Function Update Magnitude: 0.87382

Collected Steps per Second: 23,044.92840
Overall Steps per Second: 10,869.92585

Timestep Collection Time: 2.17089
Timestep Consumption Time: 2.43153
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.60242

Cumulative Model Updates: 74,432
Cumulative Timesteps: 620,700,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 620700068...
Checkpoint 620700068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,561.39035
Policy Entropy: 3.68114
Value Function Loss: 0.07018

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.62552
Value Function Update Magnitude: 0.85496

Collected Steps per Second: 22,633.91112
Overall Steps per Second: 10,735.71448

Timestep Collection Time: 2.21022
Timestep Consumption Time: 2.44955
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.65977

Cumulative Model Updates: 74,438
Cumulative Timesteps: 620,750,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,349.09459
Policy Entropy: 3.67749
Value Function Loss: 0.07384

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.65555
Value Function Update Magnitude: 0.76471

Collected Steps per Second: 22,801.91700
Overall Steps per Second: 10,798.46323

Timestep Collection Time: 2.19289
Timestep Consumption Time: 2.43759
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.63047

Cumulative Model Updates: 74,444
Cumulative Timesteps: 620,800,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 620800096...
Checkpoint 620800096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,492.83895
Policy Entropy: 3.66772
Value Function Loss: 0.07621

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.61474
Value Function Update Magnitude: 0.74033

Collected Steps per Second: 22,686.36864
Overall Steps per Second: 10,734.71209

Timestep Collection Time: 2.20494
Timestep Consumption Time: 2.45490
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.65984

Cumulative Model Updates: 74,450
Cumulative Timesteps: 620,850,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,921.91048
Policy Entropy: 3.66697
Value Function Loss: 0.07664

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.56735
Value Function Update Magnitude: 0.73984

Collected Steps per Second: 23,171.66067
Overall Steps per Second: 10,921.49706

Timestep Collection Time: 2.15833
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.57923

Cumulative Model Updates: 74,456
Cumulative Timesteps: 620,900,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 620900130...
Checkpoint 620900130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,033.93421
Policy Entropy: 3.66517
Value Function Loss: 0.07554

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.49290
Value Function Update Magnitude: 0.74557

Collected Steps per Second: 22,548.96050
Overall Steps per Second: 10,598.30581

Timestep Collection Time: 2.21775
Timestep Consumption Time: 2.50074
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.71849

Cumulative Model Updates: 74,462
Cumulative Timesteps: 620,950,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,850.73621
Policy Entropy: 3.65080
Value Function Loss: 0.07619

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.55025
Value Function Update Magnitude: 0.71696

Collected Steps per Second: 22,943.92245
Overall Steps per Second: 10,838.94749

Timestep Collection Time: 2.18045
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61558

Cumulative Model Updates: 74,468
Cumulative Timesteps: 621,000,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 621000166...
Checkpoint 621000166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,754.17289
Policy Entropy: 3.64734
Value Function Loss: 0.07473

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.56534
Value Function Update Magnitude: 0.79030

Collected Steps per Second: 22,427.92967
Overall Steps per Second: 10,742.62463

Timestep Collection Time: 2.22990
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.65547

Cumulative Model Updates: 74,474
Cumulative Timesteps: 621,050,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,744.39613
Policy Entropy: 3.64686
Value Function Loss: 0.07145

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.58337
Value Function Update Magnitude: 0.88017

Collected Steps per Second: 22,811.56014
Overall Steps per Second: 10,839.07189

Timestep Collection Time: 2.19196
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.61313

Cumulative Model Updates: 74,480
Cumulative Timesteps: 621,100,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 621100180...
Checkpoint 621100180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,930.71060
Policy Entropy: 3.65703
Value Function Loss: 0.06870

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.53925
Value Function Update Magnitude: 0.83038

Collected Steps per Second: 22,542.28729
Overall Steps per Second: 10,697.93619

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.67604

Cumulative Model Updates: 74,486
Cumulative Timesteps: 621,150,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,408.48292
Policy Entropy: 3.65877
Value Function Loss: 0.07244

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 0.48691
Value Function Update Magnitude: 0.70029

Collected Steps per Second: 22,624.91125
Overall Steps per Second: 10,800.99755

Timestep Collection Time: 2.21093
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.63124

Cumulative Model Updates: 74,492
Cumulative Timesteps: 621,200,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 621200226...
Checkpoint 621200226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,981.54785
Policy Entropy: 3.65653
Value Function Loss: 0.07633

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.46410
Value Function Update Magnitude: 0.65868

Collected Steps per Second: 22,549.00816
Overall Steps per Second: 10,800.93673

Timestep Collection Time: 2.21801
Timestep Consumption Time: 2.41251
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.63052

Cumulative Model Updates: 74,498
Cumulative Timesteps: 621,250,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,117.20188
Policy Entropy: 3.65636
Value Function Loss: 0.08016

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.45404
Value Function Update Magnitude: 0.66986

Collected Steps per Second: 23,009.81222
Overall Steps per Second: 10,908.80388

Timestep Collection Time: 2.17429
Timestep Consumption Time: 2.41191
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.58620

Cumulative Model Updates: 74,504
Cumulative Timesteps: 621,300,270

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 621300270...
Checkpoint 621300270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,981.33609
Policy Entropy: 3.67764
Value Function Loss: 0.07845

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.47389
Value Function Update Magnitude: 0.72314

Collected Steps per Second: 22,721.11963
Overall Steps per Second: 10,668.70168

Timestep Collection Time: 2.20104
Timestep Consumption Time: 2.48651
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.68754

Cumulative Model Updates: 74,510
Cumulative Timesteps: 621,350,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,337.92020
Policy Entropy: 3.67245
Value Function Loss: 0.07678

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06457
Policy Update Magnitude: 0.62495
Value Function Update Magnitude: 0.71576

Collected Steps per Second: 22,884.93674
Overall Steps per Second: 10,860.58487

Timestep Collection Time: 2.18580
Timestep Consumption Time: 2.42002
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.60583

Cumulative Model Updates: 74,516
Cumulative Timesteps: 621,400,302

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 621400302...
Checkpoint 621400302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,997.93266
Policy Entropy: 3.66867
Value Function Loss: 0.07434

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06996
Policy Update Magnitude: 0.75005
Value Function Update Magnitude: 0.74300

Collected Steps per Second: 22,078.79730
Overall Steps per Second: 10,670.17779

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.42328
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.68971

Cumulative Model Updates: 74,522
Cumulative Timesteps: 621,450,342

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,789.54043
Policy Entropy: 3.65994
Value Function Loss: 0.07236

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.72671
Value Function Update Magnitude: 0.69546

Collected Steps per Second: 22,197.46868
Overall Steps per Second: 10,881.54754

Timestep Collection Time: 2.25476
Timestep Consumption Time: 2.34477
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.59953

Cumulative Model Updates: 74,528
Cumulative Timesteps: 621,500,392

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 621500392...
Checkpoint 621500392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,869.19140
Policy Entropy: 3.65780
Value Function Loss: 0.07341

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.66643
Value Function Update Magnitude: 0.65360

Collected Steps per Second: 21,838.10944
Overall Steps per Second: 10,609.73023

Timestep Collection Time: 2.29003
Timestep Consumption Time: 2.42356
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.71360

Cumulative Model Updates: 74,534
Cumulative Timesteps: 621,550,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,372.00135
Policy Entropy: 3.64600
Value Function Loss: 0.07172

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.65134

Collected Steps per Second: 22,338.58022
Overall Steps per Second: 10,862.52624

Timestep Collection Time: 2.23909
Timestep Consumption Time: 2.36555
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60464

Cumulative Model Updates: 74,540
Cumulative Timesteps: 621,600,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 621600420...
Checkpoint 621600420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,291.86568
Policy Entropy: 3.65104
Value Function Loss: 0.06830

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10060
Policy Update Magnitude: 0.49190
Value Function Update Magnitude: 0.73457

Collected Steps per Second: 21,909.05744
Overall Steps per Second: 10,707.49568

Timestep Collection Time: 2.28326
Timestep Consumption Time: 2.38861
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.67187

Cumulative Model Updates: 74,546
Cumulative Timesteps: 621,650,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,695.21448
Policy Entropy: 3.65427
Value Function Loss: 0.06599

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.50120
Value Function Update Magnitude: 0.81230

Collected Steps per Second: 22,289.90951
Overall Steps per Second: 10,882.37207

Timestep Collection Time: 2.24326
Timestep Consumption Time: 2.35151
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.59477

Cumulative Model Updates: 74,552
Cumulative Timesteps: 621,700,446

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 621700446...
Checkpoint 621700446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,945.96539
Policy Entropy: 3.65686
Value Function Loss: 0.06478

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.51553
Value Function Update Magnitude: 0.84035

Collected Steps per Second: 22,149.34761
Overall Steps per Second: 10,638.53275

Timestep Collection Time: 2.25813
Timestep Consumption Time: 2.44327
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.70140

Cumulative Model Updates: 74,558
Cumulative Timesteps: 621,750,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,396.19988
Policy Entropy: 3.65700
Value Function Loss: 0.06648

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.51330
Value Function Update Magnitude: 0.86843

Collected Steps per Second: 22,748.51071
Overall Steps per Second: 10,846.64764

Timestep Collection Time: 2.19803
Timestep Consumption Time: 2.41187
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.60990

Cumulative Model Updates: 74,564
Cumulative Timesteps: 621,800,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 621800464...
Checkpoint 621800464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,540.66397
Policy Entropy: 3.66218
Value Function Loss: 0.06759

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.48572
Value Function Update Magnitude: 0.84727

Collected Steps per Second: 22,586.80017
Overall Steps per Second: 10,717.75641

Timestep Collection Time: 2.21404
Timestep Consumption Time: 2.45187
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.66590

Cumulative Model Updates: 74,570
Cumulative Timesteps: 621,850,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,890.61023
Policy Entropy: 3.66612
Value Function Loss: 0.06958

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.53946
Value Function Update Magnitude: 0.76251

Collected Steps per Second: 22,759.27686
Overall Steps per Second: 10,867.00356

Timestep Collection Time: 2.19822
Timestep Consumption Time: 2.40562
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.60385

Cumulative Model Updates: 74,576
Cumulative Timesteps: 621,900,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 621900502...
Checkpoint 621900502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,518.12532
Policy Entropy: 3.67463
Value Function Loss: 0.07014

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.52389
Value Function Update Magnitude: 0.68948

Collected Steps per Second: 22,365.04143
Overall Steps per Second: 10,692.05950

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.67861

Cumulative Model Updates: 74,582
Cumulative Timesteps: 621,950,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,575.54859
Policy Entropy: 3.67072
Value Function Loss: 0.07213

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.49236
Value Function Update Magnitude: 0.74303

Collected Steps per Second: 22,846.94969
Overall Steps per Second: 10,780.23839

Timestep Collection Time: 2.18970
Timestep Consumption Time: 2.45101
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.64071

Cumulative Model Updates: 74,588
Cumulative Timesteps: 622,000,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 622000554...
Checkpoint 622000554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,422.84815
Policy Entropy: 3.67666
Value Function Loss: 0.06838

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.50890
Value Function Update Magnitude: 0.81686

Collected Steps per Second: 22,521.25808
Overall Steps per Second: 10,770.68580

Timestep Collection Time: 2.22119
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.64446

Cumulative Model Updates: 74,594
Cumulative Timesteps: 622,050,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,529.76850
Policy Entropy: 3.67272
Value Function Loss: 0.06846

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.52947
Value Function Update Magnitude: 0.86847

Collected Steps per Second: 23,080.45056
Overall Steps per Second: 10,842.70945

Timestep Collection Time: 2.16694
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.61268

Cumulative Model Updates: 74,600
Cumulative Timesteps: 622,100,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 622100592...
Checkpoint 622100592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,322.94680
Policy Entropy: 3.68321
Value Function Loss: 0.06544

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.53881
Value Function Update Magnitude: 0.82580

Collected Steps per Second: 22,518.42235
Overall Steps per Second: 10,732.55976

Timestep Collection Time: 2.22085
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.65965

Cumulative Model Updates: 74,606
Cumulative Timesteps: 622,150,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,518.77919
Policy Entropy: 3.67351
Value Function Loss: 0.07030

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.53953
Value Function Update Magnitude: 0.67784

Collected Steps per Second: 22,817.11451
Overall Steps per Second: 10,815.11655

Timestep Collection Time: 2.19239
Timestep Consumption Time: 2.43299
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.62538

Cumulative Model Updates: 74,612
Cumulative Timesteps: 622,200,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 622200626...
Checkpoint 622200626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,121.08709
Policy Entropy: 3.67520
Value Function Loss: 0.07004

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.62757
Value Function Update Magnitude: 0.62858

Collected Steps per Second: 22,161.80493
Overall Steps per Second: 10,660.28454

Timestep Collection Time: 2.25668
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.69143

Cumulative Model Updates: 74,618
Cumulative Timesteps: 622,250,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,394.10919
Policy Entropy: 3.67963
Value Function Loss: 0.07122

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.56397
Value Function Update Magnitude: 0.60749

Collected Steps per Second: 22,723.11912
Overall Steps per Second: 10,700.41981

Timestep Collection Time: 2.20181
Timestep Consumption Time: 2.47389
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.67570

Cumulative Model Updates: 74,624
Cumulative Timesteps: 622,300,670

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 622300670...
Checkpoint 622300670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,696.03852
Policy Entropy: 3.68598
Value Function Loss: 0.06858

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10410
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.59985

Collected Steps per Second: 22,591.47537
Overall Steps per Second: 10,670.04352

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.47279
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.68602

Cumulative Model Updates: 74,630
Cumulative Timesteps: 622,350,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,912.23976
Policy Entropy: 3.69063
Value Function Loss: 0.07177

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.51752
Value Function Update Magnitude: 0.63296

Collected Steps per Second: 22,764.64353
Overall Steps per Second: 10,672.56452

Timestep Collection Time: 2.19648
Timestep Consumption Time: 2.48862
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.68510

Cumulative Model Updates: 74,636
Cumulative Timesteps: 622,400,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 622400672...
Checkpoint 622400672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,088.54896
Policy Entropy: 3.68712
Value Function Loss: 0.07054

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.65520

Collected Steps per Second: 22,686.30908
Overall Steps per Second: 10,594.95228

Timestep Collection Time: 2.20406
Timestep Consumption Time: 2.51536
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.71942

Cumulative Model Updates: 74,642
Cumulative Timesteps: 622,450,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,965.62108
Policy Entropy: 3.67795
Value Function Loss: 0.07043

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.58874
Value Function Update Magnitude: 0.73162

Collected Steps per Second: 22,776.44749
Overall Steps per Second: 10,861.11976

Timestep Collection Time: 2.19648
Timestep Consumption Time: 2.40968
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.60615

Cumulative Model Updates: 74,648
Cumulative Timesteps: 622,500,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 622500702...
Checkpoint 622500702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,146.58209
Policy Entropy: 3.67467
Value Function Loss: 0.06967

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08840
Policy Update Magnitude: 0.58348
Value Function Update Magnitude: 0.73516

Collected Steps per Second: 22,597.09540
Overall Steps per Second: 10,723.83966

Timestep Collection Time: 2.21320
Timestep Consumption Time: 2.45042
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.66363

Cumulative Model Updates: 74,654
Cumulative Timesteps: 622,550,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,163.89794
Policy Entropy: 3.65792
Value Function Loss: 0.07079

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.59784
Value Function Update Magnitude: 0.67848

Collected Steps per Second: 22,964.83019
Overall Steps per Second: 10,832.07190

Timestep Collection Time: 2.17820
Timestep Consumption Time: 2.43975
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.61795

Cumulative Model Updates: 74,660
Cumulative Timesteps: 622,600,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 622600736...
Checkpoint 622600736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,657.13546
Policy Entropy: 3.66175
Value Function Loss: 0.07153

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.54492
Value Function Update Magnitude: 0.65980

Collected Steps per Second: 22,742.17653
Overall Steps per Second: 10,690.56948

Timestep Collection Time: 2.19865
Timestep Consumption Time: 2.47856
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.67721

Cumulative Model Updates: 74,666
Cumulative Timesteps: 622,650,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,623.90031
Policy Entropy: 3.66065
Value Function Loss: 0.07187

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.53082
Value Function Update Magnitude: 0.67809

Collected Steps per Second: 23,002.81196
Overall Steps per Second: 10,855.52670

Timestep Collection Time: 2.17460
Timestep Consumption Time: 2.43337
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60798

Cumulative Model Updates: 74,672
Cumulative Timesteps: 622,700,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 622700760...
Checkpoint 622700760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,540.08086
Policy Entropy: 3.66354
Value Function Loss: 0.07176

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.66383
Value Function Update Magnitude: 0.63731

Collected Steps per Second: 22,778.74552
Overall Steps per Second: 10,717.04607

Timestep Collection Time: 2.19556
Timestep Consumption Time: 2.47103
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.66658

Cumulative Model Updates: 74,678
Cumulative Timesteps: 622,750,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,692.16357
Policy Entropy: 3.65349
Value Function Loss: 0.07187

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.69662
Value Function Update Magnitude: 0.77400

Collected Steps per Second: 23,063.66998
Overall Steps per Second: 10,844.66140

Timestep Collection Time: 2.16791
Timestep Consumption Time: 2.44265
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61056

Cumulative Model Updates: 74,684
Cumulative Timesteps: 622,800,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 622800772...
Checkpoint 622800772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.43405
Policy Entropy: 3.65558
Value Function Loss: 0.07005

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.59139
Value Function Update Magnitude: 0.81069

Collected Steps per Second: 22,439.95045
Overall Steps per Second: 10,749.18053

Timestep Collection Time: 2.22879
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.65282

Cumulative Model Updates: 74,690
Cumulative Timesteps: 622,850,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,576.34929
Policy Entropy: 3.65582
Value Function Loss: 0.07166

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.53719
Value Function Update Magnitude: 0.82386

Collected Steps per Second: 22,876.12094
Overall Steps per Second: 10,916.88661

Timestep Collection Time: 2.18586
Timestep Consumption Time: 2.39457
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.58043

Cumulative Model Updates: 74,696
Cumulative Timesteps: 622,900,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 622900790...
Checkpoint 622900790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,221.76087
Policy Entropy: 3.63480
Value Function Loss: 0.07646

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.51604
Value Function Update Magnitude: 0.74557

Collected Steps per Second: 22,859.77911
Overall Steps per Second: 10,699.96362

Timestep Collection Time: 2.18839
Timestep Consumption Time: 2.48696
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.67534

Cumulative Model Updates: 74,702
Cumulative Timesteps: 622,950,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,736.92671
Policy Entropy: 3.62155
Value Function Loss: 0.08112

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.50308
Value Function Update Magnitude: 0.74579

Collected Steps per Second: 22,584.58924
Overall Steps per Second: 10,724.09515

Timestep Collection Time: 2.21434
Timestep Consumption Time: 2.44899
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.66333

Cumulative Model Updates: 74,708
Cumulative Timesteps: 623,000,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 623000826...
Checkpoint 623000826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,826.53464
Policy Entropy: 3.61627
Value Function Loss: 0.07983

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.53895
Value Function Update Magnitude: 0.70539

Collected Steps per Second: 22,500.74188
Overall Steps per Second: 10,669.11715

Timestep Collection Time: 2.22375
Timestep Consumption Time: 2.46605
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.68980

Cumulative Model Updates: 74,714
Cumulative Timesteps: 623,050,862

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,043.16090
Policy Entropy: 3.62733
Value Function Loss: 0.07631

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.15592
Policy Update Magnitude: 0.46664
Value Function Update Magnitude: 0.83533

Collected Steps per Second: 23,026.25111
Overall Steps per Second: 10,859.99602

Timestep Collection Time: 2.17178
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.60479

Cumulative Model Updates: 74,720
Cumulative Timesteps: 623,100,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 623100870...
Checkpoint 623100870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,615.33945
Policy Entropy: 3.64698
Value Function Loss: 0.07145

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.48449
Value Function Update Magnitude: 0.86437

Collected Steps per Second: 22,534.55420
Overall Steps per Second: 10,737.99769

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.43774
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.65673

Cumulative Model Updates: 74,726
Cumulative Timesteps: 623,150,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,937.00968
Policy Entropy: 3.66649
Value Function Loss: 0.07017

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.56676
Value Function Update Magnitude: 0.91544

Collected Steps per Second: 22,897.28178
Overall Steps per Second: 10,825.74819

Timestep Collection Time: 2.18401
Timestep Consumption Time: 2.43534
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61936

Cumulative Model Updates: 74,732
Cumulative Timesteps: 623,200,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 623200882...
Checkpoint 623200882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,765.29512
Policy Entropy: 3.65922
Value Function Loss: 0.06831

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.93088

Collected Steps per Second: 22,943.55498
Overall Steps per Second: 10,686.85409

Timestep Collection Time: 2.17996
Timestep Consumption Time: 2.50018
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.68014

Cumulative Model Updates: 74,738
Cumulative Timesteps: 623,250,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,330.33994
Policy Entropy: 3.65697
Value Function Loss: 0.06673

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.94992

Collected Steps per Second: 22,903.10190
Overall Steps per Second: 10,828.57878

Timestep Collection Time: 2.18346
Timestep Consumption Time: 2.43469
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.61815

Cumulative Model Updates: 74,744
Cumulative Timesteps: 623,300,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 623300906...
Checkpoint 623300906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,842.18270
Policy Entropy: 3.62431
Value Function Loss: 0.07095

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.52157
Value Function Update Magnitude: 0.94242

Collected Steps per Second: 22,513.62528
Overall Steps per Second: 10,669.39781

Timestep Collection Time: 2.22106
Timestep Consumption Time: 2.46562
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.68668

Cumulative Model Updates: 74,750
Cumulative Timesteps: 623,350,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,171.47627
Policy Entropy: 3.61324
Value Function Loss: 0.07320

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.55869
Value Function Update Magnitude: 0.91154

Collected Steps per Second: 22,194.97193
Overall Steps per Second: 10,480.36522

Timestep Collection Time: 2.25465
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.77483

Cumulative Model Updates: 74,756
Cumulative Timesteps: 623,400,952

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 623400952...
Checkpoint 623400952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,835.79646
Policy Entropy: 3.63352
Value Function Loss: 0.07696

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.16058
Policy Update Magnitude: 0.45717
Value Function Update Magnitude: 0.73357

Collected Steps per Second: 21,840.76218
Overall Steps per Second: 10,381.95028

Timestep Collection Time: 2.28994
Timestep Consumption Time: 2.52746
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.81740

Cumulative Model Updates: 74,762
Cumulative Timesteps: 623,450,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,239.37102
Policy Entropy: 3.65500
Value Function Loss: 0.07687

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.47936
Value Function Update Magnitude: 0.62178

Collected Steps per Second: 22,891.55937
Overall Steps per Second: 10,742.19163

Timestep Collection Time: 2.18500
Timestep Consumption Time: 2.47122
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.65622

Cumulative Model Updates: 74,768
Cumulative Timesteps: 623,500,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 623500984...
Checkpoint 623500984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.24740
Policy Entropy: 3.67037
Value Function Loss: 0.07716

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.52654
Value Function Update Magnitude: 0.52322

Collected Steps per Second: 22,508.13699
Overall Steps per Second: 10,658.24918

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.47038
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.69233

Cumulative Model Updates: 74,774
Cumulative Timesteps: 623,550,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,273.28772
Policy Entropy: 3.66372
Value Function Loss: 0.07538

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.58212
Value Function Update Magnitude: 0.57337

Collected Steps per Second: 22,661.12237
Overall Steps per Second: 10,652.57963

Timestep Collection Time: 2.20775
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.69651

Cumulative Model Updates: 74,780
Cumulative Timesteps: 623,601,026

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 623601026...
Checkpoint 623601026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,630.98896
Policy Entropy: 3.66492
Value Function Loss: 0.07165

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.61251
Value Function Update Magnitude: 0.56109

Collected Steps per Second: 22,630.65150
Overall Steps per Second: 10,813.05099

Timestep Collection Time: 2.21036
Timestep Consumption Time: 2.41571
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.62608

Cumulative Model Updates: 74,786
Cumulative Timesteps: 623,651,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,853.91164
Policy Entropy: 3.65374
Value Function Loss: 0.06886

Mean KL Divergence: 0.01923
SB3 Clip Fraction: 0.15821
Policy Update Magnitude: 0.59857
Value Function Update Magnitude: 0.57585

Collected Steps per Second: 23,146.34317
Overall Steps per Second: 10,911.75432

Timestep Collection Time: 2.16095
Timestep Consumption Time: 2.42292
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.58386

Cumulative Model Updates: 74,792
Cumulative Timesteps: 623,701,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 623701066...
Checkpoint 623701066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,616.71798
Policy Entropy: 3.65849
Value Function Loss: 0.06845

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.50814
Value Function Update Magnitude: 0.57312

Collected Steps per Second: 22,368.20334
Overall Steps per Second: 10,773.34689

Timestep Collection Time: 2.23621
Timestep Consumption Time: 2.40673
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.64294

Cumulative Model Updates: 74,798
Cumulative Timesteps: 623,751,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,503.21552
Policy Entropy: 3.65670
Value Function Loss: 0.06868

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.52940
Value Function Update Magnitude: 0.65790

Collected Steps per Second: 22,638.37278
Overall Steps per Second: 10,767.51119

Timestep Collection Time: 2.20882
Timestep Consumption Time: 2.43515
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.64397

Cumulative Model Updates: 74,804
Cumulative Timesteps: 623,801,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 623801090...
Checkpoint 623801090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.26140
Policy Entropy: 3.66773
Value Function Loss: 0.06948

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.66633
Value Function Update Magnitude: 0.63638

Collected Steps per Second: 22,553.69520
Overall Steps per Second: 10,694.71503

Timestep Collection Time: 2.21817
Timestep Consumption Time: 2.45965
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.67782

Cumulative Model Updates: 74,810
Cumulative Timesteps: 623,851,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,996.19240
Policy Entropy: 3.65584
Value Function Loss: 0.06822

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.64654
Value Function Update Magnitude: 0.62001

Collected Steps per Second: 23,130.06433
Overall Steps per Second: 10,971.72547

Timestep Collection Time: 2.16264
Timestep Consumption Time: 2.39653
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.55917

Cumulative Model Updates: 74,816
Cumulative Timesteps: 623,901,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 623901140...
Checkpoint 623901140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,954.30603
Policy Entropy: 3.65397
Value Function Loss: 0.06744

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.54990
Value Function Update Magnitude: 0.63655

Collected Steps per Second: 22,539.34108
Overall Steps per Second: 10,609.16953

Timestep Collection Time: 2.21870
Timestep Consumption Time: 2.49496
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.71366

Cumulative Model Updates: 74,822
Cumulative Timesteps: 623,951,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,730.26405
Policy Entropy: 3.66431
Value Function Loss: 0.06606

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.52895
Value Function Update Magnitude: 0.63690

Collected Steps per Second: 22,474.84447
Overall Steps per Second: 10,549.44617

Timestep Collection Time: 2.22471
Timestep Consumption Time: 2.51488
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.73959

Cumulative Model Updates: 74,828
Cumulative Timesteps: 624,001,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 624001148...
Checkpoint 624001148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,783.11833
Policy Entropy: 3.67274
Value Function Loss: 0.06623

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.55181
Value Function Update Magnitude: 0.68269

Collected Steps per Second: 22,971.03085
Overall Steps per Second: 10,750.80458

Timestep Collection Time: 2.17692
Timestep Consumption Time: 2.47446
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.65137

Cumulative Model Updates: 74,834
Cumulative Timesteps: 624,051,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,067.77807
Policy Entropy: 3.66888
Value Function Loss: 0.06653

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.58473
Value Function Update Magnitude: 0.67857

Collected Steps per Second: 22,878.33127
Overall Steps per Second: 10,682.27572

Timestep Collection Time: 2.18556
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.68084

Cumulative Model Updates: 74,840
Cumulative Timesteps: 624,101,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 624101156...
Checkpoint 624101156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,859.21891
Policy Entropy: 3.68887
Value Function Loss: 0.06744

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.62654

Collected Steps per Second: 22,880.28664
Overall Steps per Second: 10,673.02883

Timestep Collection Time: 2.18599
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.68620

Cumulative Model Updates: 74,846
Cumulative Timesteps: 624,151,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,861.52626
Policy Entropy: 3.68688
Value Function Loss: 0.07196

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.53554

Collected Steps per Second: 22,954.61851
Overall Steps per Second: 10,808.19702

Timestep Collection Time: 2.18039
Timestep Consumption Time: 2.45036
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.63074

Cumulative Model Updates: 74,852
Cumulative Timesteps: 624,201,222

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 624201222...
Checkpoint 624201222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.13999
Policy Entropy: 3.68447
Value Function Loss: 0.07132

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.55430
Value Function Update Magnitude: 0.53225

Collected Steps per Second: 22,669.57170
Overall Steps per Second: 10,695.16040

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.46951
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.67520

Cumulative Model Updates: 74,858
Cumulative Timesteps: 624,251,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,120.91521
Policy Entropy: 3.68116
Value Function Loss: 0.06786

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.63809
Value Function Update Magnitude: 0.71800

Collected Steps per Second: 22,915.80552
Overall Steps per Second: 10,843.73571

Timestep Collection Time: 2.18216
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61151

Cumulative Model Updates: 74,864
Cumulative Timesteps: 624,301,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 624301230...
Checkpoint 624301230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,549.81697
Policy Entropy: 3.68979
Value Function Loss: 0.06564

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.73884
Value Function Update Magnitude: 0.76094

Collected Steps per Second: 22,824.58792
Overall Steps per Second: 10,715.87705

Timestep Collection Time: 2.19185
Timestep Consumption Time: 2.47674
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.66859

Cumulative Model Updates: 74,870
Cumulative Timesteps: 624,351,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,226.17463
Policy Entropy: 3.69399
Value Function Loss: 0.06414

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.75490
Value Function Update Magnitude: 0.69707

Collected Steps per Second: 22,661.28108
Overall Steps per Second: 10,778.53530

Timestep Collection Time: 2.20720
Timestep Consumption Time: 2.43332
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.64052

Cumulative Model Updates: 74,876
Cumulative Timesteps: 624,401,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 624401276...
Checkpoint 624401276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,482.41823
Policy Entropy: 3.68372
Value Function Loss: 0.06237

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07173
Policy Update Magnitude: 0.76492
Value Function Update Magnitude: 0.73836

Collected Steps per Second: 22,165.35179
Overall Steps per Second: 10,642.56779

Timestep Collection Time: 2.25722
Timestep Consumption Time: 2.44390
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.70112

Cumulative Model Updates: 74,882
Cumulative Timesteps: 624,451,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,379.30423
Policy Entropy: 3.68513
Value Function Loss: 0.06184

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.77456
Value Function Update Magnitude: 0.80663

Collected Steps per Second: 22,784.86536
Overall Steps per Second: 10,653.58555

Timestep Collection Time: 2.19532
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.69513

Cumulative Model Updates: 74,888
Cumulative Timesteps: 624,501,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 624501328...
Checkpoint 624501328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,675.74718
Policy Entropy: 3.68611
Value Function Loss: 0.06277

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08786
Policy Update Magnitude: 0.76569
Value Function Update Magnitude: 0.81233

Collected Steps per Second: 22,648.62304
Overall Steps per Second: 10,624.84116

Timestep Collection Time: 2.20879
Timestep Consumption Time: 2.49961
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.70840

Cumulative Model Updates: 74,894
Cumulative Timesteps: 624,551,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,486.43377
Policy Entropy: 3.68645
Value Function Loss: 0.06345

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.61503
Value Function Update Magnitude: 0.80434

Collected Steps per Second: 23,008.47466
Overall Steps per Second: 10,883.40992

Timestep Collection Time: 2.17407
Timestep Consumption Time: 2.42210
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.59617

Cumulative Model Updates: 74,900
Cumulative Timesteps: 624,601,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 624601376...
Checkpoint 624601376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,688.57401
Policy Entropy: 3.67688
Value Function Loss: 0.06550

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.52742
Value Function Update Magnitude: 0.80974

Collected Steps per Second: 22,945.24417
Overall Steps per Second: 10,715.44050

Timestep Collection Time: 2.18032
Timestep Consumption Time: 2.48846
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.66878

Cumulative Model Updates: 74,906
Cumulative Timesteps: 624,651,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,320.52816
Policy Entropy: 3.67202
Value Function Loss: 0.06872

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.51385
Value Function Update Magnitude: 0.82945

Collected Steps per Second: 22,891.98543
Overall Steps per Second: 10,782.57851

Timestep Collection Time: 2.18504
Timestep Consumption Time: 2.45392
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.63896

Cumulative Model Updates: 74,912
Cumulative Timesteps: 624,701,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 624701424...
Checkpoint 624701424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,100.09693
Policy Entropy: 3.67209
Value Function Loss: 0.07031

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.56022
Value Function Update Magnitude: 0.74342

Collected Steps per Second: 22,416.05264
Overall Steps per Second: 10,652.45204

Timestep Collection Time: 2.23108
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.69488

Cumulative Model Updates: 74,918
Cumulative Timesteps: 624,751,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,138.32404
Policy Entropy: 3.67952
Value Function Loss: 0.06846

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.60363
Value Function Update Magnitude: 0.68519

Collected Steps per Second: 22,923.27431
Overall Steps per Second: 10,861.30298

Timestep Collection Time: 2.18197
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.60516

Cumulative Model Updates: 74,924
Cumulative Timesteps: 624,801,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 624801454...
Checkpoint 624801454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,743.02916
Policy Entropy: 3.67838
Value Function Loss: 0.06880

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.16266
Policy Update Magnitude: 0.52392
Value Function Update Magnitude: 0.69798

Collected Steps per Second: 22,567.69960
Overall Steps per Second: 10,671.10812

Timestep Collection Time: 2.21635
Timestep Consumption Time: 2.47088
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.68724

Cumulative Model Updates: 74,930
Cumulative Timesteps: 624,851,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,613.31499
Policy Entropy: 3.69366
Value Function Loss: 0.06500

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.80787

Collected Steps per Second: 22,911.91634
Overall Steps per Second: 10,866.11470

Timestep Collection Time: 2.18358
Timestep Consumption Time: 2.42064
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.60422

Cumulative Model Updates: 74,936
Cumulative Timesteps: 624,901,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 624901502...
Checkpoint 624901502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,238.37414
Policy Entropy: 3.69611
Value Function Loss: 0.06336

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.87334

Collected Steps per Second: 22,519.31834
Overall Steps per Second: 10,697.41548

Timestep Collection Time: 2.22049
Timestep Consumption Time: 2.45391
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.67440

Cumulative Model Updates: 74,942
Cumulative Timesteps: 624,951,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,657.91835
Policy Entropy: 3.69419
Value Function Loss: 0.06199

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.61745
Value Function Update Magnitude: 0.82396

Collected Steps per Second: 22,726.47126
Overall Steps per Second: 10,811.13122

Timestep Collection Time: 2.20052
Timestep Consumption Time: 2.42527
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.62579

Cumulative Model Updates: 74,948
Cumulative Timesteps: 625,001,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 625001516...
Checkpoint 625001516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,451.36750
Policy Entropy: 3.67978
Value Function Loss: 0.06366

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.56708
Value Function Update Magnitude: 0.80228

Collected Steps per Second: 22,492.65820
Overall Steps per Second: 10,742.09504

Timestep Collection Time: 2.22357
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.65589

Cumulative Model Updates: 74,954
Cumulative Timesteps: 625,051,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,580.08619
Policy Entropy: 3.67480
Value Function Loss: 0.06466

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.58238
Value Function Update Magnitude: 0.81510

Collected Steps per Second: 22,970.42174
Overall Steps per Second: 10,850.77058

Timestep Collection Time: 2.17732
Timestep Consumption Time: 2.43194
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.60926

Cumulative Model Updates: 74,960
Cumulative Timesteps: 625,101,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 625101544...
Checkpoint 625101544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,254.60672
Policy Entropy: 3.69395
Value Function Loss: 0.06379

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.59057
Value Function Update Magnitude: 0.85442

Collected Steps per Second: 21,981.46848
Overall Steps per Second: 10,647.56206

Timestep Collection Time: 2.27528
Timestep Consumption Time: 2.42195
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69723

Cumulative Model Updates: 74,966
Cumulative Timesteps: 625,151,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,257.05919
Policy Entropy: 3.70181
Value Function Loss: 0.06167

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.62850
Value Function Update Magnitude: 0.86651

Collected Steps per Second: 22,149.72830
Overall Steps per Second: 10,844.56506

Timestep Collection Time: 2.25791
Timestep Consumption Time: 2.35381
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.61171

Cumulative Model Updates: 74,972
Cumulative Timesteps: 625,201,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 625201570...
Checkpoint 625201570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,295.32237
Policy Entropy: 3.69289
Value Function Loss: 0.06208

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.61374
Value Function Update Magnitude: 0.86709

Collected Steps per Second: 21,973.84251
Overall Steps per Second: 10,741.63331

Timestep Collection Time: 2.27643
Timestep Consumption Time: 2.38040
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.65683

Cumulative Model Updates: 74,978
Cumulative Timesteps: 625,251,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,894.20729
Policy Entropy: 3.68930
Value Function Loss: 0.06209

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.57657
Value Function Update Magnitude: 0.89020

Collected Steps per Second: 22,235.34058
Overall Steps per Second: 10,839.95809

Timestep Collection Time: 2.25011
Timestep Consumption Time: 2.36540
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.61552

Cumulative Model Updates: 74,984
Cumulative Timesteps: 625,301,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 625301624...
Checkpoint 625301624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,680.04640
Policy Entropy: 3.68038
Value Function Loss: 0.06415

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.57017
Value Function Update Magnitude: 0.89613

Collected Steps per Second: 21,911.22219
Overall Steps per Second: 10,662.17485

Timestep Collection Time: 2.28312
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.69191

Cumulative Model Updates: 74,990
Cumulative Timesteps: 625,351,650

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,399.40338
Policy Entropy: 3.68388
Value Function Loss: 0.06409

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.55728
Value Function Update Magnitude: 0.88490

Collected Steps per Second: 21,983.12353
Overall Steps per Second: 10,471.66306

Timestep Collection Time: 2.27511
Timestep Consumption Time: 2.50102
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.77613

Cumulative Model Updates: 74,996
Cumulative Timesteps: 625,401,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 625401664...
Checkpoint 625401664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,078.91924
Policy Entropy: 3.69410
Value Function Loss: 0.06382

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.87702

Collected Steps per Second: 22,591.48198
Overall Steps per Second: 10,646.02929

Timestep Collection Time: 2.21429
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.69884

Cumulative Model Updates: 75,002
Cumulative Timesteps: 625,451,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,710.67643
Policy Entropy: 3.69497
Value Function Loss: 0.06567

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06433
Policy Update Magnitude: 0.64419
Value Function Update Magnitude: 0.85319

Collected Steps per Second: 22,715.03791
Overall Steps per Second: 10,825.14748

Timestep Collection Time: 2.20180
Timestep Consumption Time: 2.41837
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.62017

Cumulative Model Updates: 75,008
Cumulative Timesteps: 625,501,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 625501702...
Checkpoint 625501702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,160.47084
Policy Entropy: 3.68844
Value Function Loss: 0.06716

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07394
Policy Update Magnitude: 0.74079
Value Function Update Magnitude: 0.83029

Collected Steps per Second: 22,772.98553
Overall Steps per Second: 10,695.71441

Timestep Collection Time: 2.19602
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.67570

Cumulative Model Updates: 75,014
Cumulative Timesteps: 625,551,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,629.92712
Policy Entropy: 3.66772
Value Function Loss: 0.07036

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.73682
Value Function Update Magnitude: 0.82552

Collected Steps per Second: 22,918.30408
Overall Steps per Second: 10,854.82319

Timestep Collection Time: 2.18166
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.60625

Cumulative Model Updates: 75,020
Cumulative Timesteps: 625,601,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 625601712...
Checkpoint 625601712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,075.17591
Policy Entropy: 3.69048
Value Function Loss: 0.06694

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.67724
Value Function Update Magnitude: 0.87790

Collected Steps per Second: 22,880.92133
Overall Steps per Second: 10,709.87847

Timestep Collection Time: 2.18531
Timestep Consumption Time: 2.48346
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.66877

Cumulative Model Updates: 75,026
Cumulative Timesteps: 625,651,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,792.38197
Policy Entropy: 3.68989
Value Function Loss: 0.06576

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10705
Policy Update Magnitude: 0.62738
Value Function Update Magnitude: 0.84672

Collected Steps per Second: 22,848.55351
Overall Steps per Second: 10,810.21241

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.43771
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.62674

Cumulative Model Updates: 75,032
Cumulative Timesteps: 625,701,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 625701730...
Checkpoint 625701730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,732.48934
Policy Entropy: 3.71089
Value Function Loss: 0.06361

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.59405
Value Function Update Magnitude: 0.88132

Collected Steps per Second: 22,651.26582
Overall Steps per Second: 10,719.79971

Timestep Collection Time: 2.20844
Timestep Consumption Time: 2.45806
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.66651

Cumulative Model Updates: 75,038
Cumulative Timesteps: 625,751,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,440.52427
Policy Entropy: 3.69753
Value Function Loss: 0.06694

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.65267
Value Function Update Magnitude: 0.89709

Collected Steps per Second: 22,922.73222
Overall Steps per Second: 10,843.19086

Timestep Collection Time: 2.18220
Timestep Consumption Time: 2.43102
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.61322

Cumulative Model Updates: 75,044
Cumulative Timesteps: 625,801,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 625801776...
Checkpoint 625801776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,931.20958
Policy Entropy: 3.70119
Value Function Loss: 0.06643

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.61365
Value Function Update Magnitude: 0.89620

Collected Steps per Second: 22,579.26532
Overall Steps per Second: 10,703.83103

Timestep Collection Time: 2.21531
Timestep Consumption Time: 2.45779
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.67309

Cumulative Model Updates: 75,050
Cumulative Timesteps: 625,851,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,870.29112
Policy Entropy: 3.69667
Value Function Loss: 0.06409

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.89295

Collected Steps per Second: 22,955.06412
Overall Steps per Second: 10,848.65820

Timestep Collection Time: 2.17913
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61089

Cumulative Model Updates: 75,056
Cumulative Timesteps: 625,901,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 625901818...
Checkpoint 625901818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,612.48891
Policy Entropy: 3.69527
Value Function Loss: 0.06523

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.54994
Value Function Update Magnitude: 0.83979

Collected Steps per Second: 22,681.12825
Overall Steps per Second: 10,721.10202

Timestep Collection Time: 2.20562
Timestep Consumption Time: 2.46050
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.66612

Cumulative Model Updates: 75,062
Cumulative Timesteps: 625,951,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,915.77918
Policy Entropy: 3.69926
Value Function Loss: 0.06881

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.78314

Collected Steps per Second: 22,600.77815
Overall Steps per Second: 10,602.49356

Timestep Collection Time: 2.21240
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.71606

Cumulative Model Updates: 75,068
Cumulative Timesteps: 626,001,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 626001846...
Checkpoint 626001846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,160.03411
Policy Entropy: 3.69515
Value Function Loss: 0.07157

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.55760
Value Function Update Magnitude: 0.73993

Collected Steps per Second: 22,643.06457
Overall Steps per Second: 10,685.55119

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68221

Cumulative Model Updates: 75,074
Cumulative Timesteps: 626,051,878

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,467.43500
Policy Entropy: 3.69330
Value Function Loss: 0.07272

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.53663
Value Function Update Magnitude: 0.70973

Collected Steps per Second: 23,118.84252
Overall Steps per Second: 10,711.54089

Timestep Collection Time: 2.16334
Timestep Consumption Time: 2.50583
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.66917

Cumulative Model Updates: 75,080
Cumulative Timesteps: 626,101,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 626101892...
Checkpoint 626101892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,341.48917
Policy Entropy: 3.68417
Value Function Loss: 0.07571

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06225
Policy Update Magnitude: 0.57949
Value Function Update Magnitude: 0.70609

Collected Steps per Second: 22,883.98734
Overall Steps per Second: 10,672.68543

Timestep Collection Time: 2.18537
Timestep Consumption Time: 2.50042
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.68579

Cumulative Model Updates: 75,086
Cumulative Timesteps: 626,151,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,689.69741
Policy Entropy: 3.67816
Value Function Loss: 0.07666

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.66319
Value Function Update Magnitude: 0.69222

Collected Steps per Second: 22,720.30359
Overall Steps per Second: 10,844.03200

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.41045
PPO Batch Consumption Time: 0.27586
Total Iteration Time: 4.61138

Cumulative Model Updates: 75,092
Cumulative Timesteps: 626,201,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 626201908...
Checkpoint 626201908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,179.24673
Policy Entropy: 3.66113
Value Function Loss: 0.07956

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.17812
Policy Update Magnitude: 0.51366
Value Function Update Magnitude: 0.70588

Collected Steps per Second: 22,809.39136
Overall Steps per Second: 10,672.62025

Timestep Collection Time: 2.19278
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.68638

Cumulative Model Updates: 75,098
Cumulative Timesteps: 626,251,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.64874
Policy Entropy: 3.66375
Value Function Loss: 0.07991

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.44968
Value Function Update Magnitude: 0.69249

Collected Steps per Second: 22,963.78430
Overall Steps per Second: 10,837.73382

Timestep Collection Time: 2.17839
Timestep Consumption Time: 2.43734
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61573

Cumulative Model Updates: 75,104
Cumulative Timesteps: 626,301,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 626301948...
Checkpoint 626301948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,918.46045
Policy Entropy: 3.67598
Value Function Loss: 0.07669

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.50091
Value Function Update Magnitude: 0.73214

Collected Steps per Second: 22,638.89086
Overall Steps per Second: 10,718.61178

Timestep Collection Time: 2.20947
Timestep Consumption Time: 2.45718
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.66665

Cumulative Model Updates: 75,110
Cumulative Timesteps: 626,351,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,891.35186
Policy Entropy: 3.66928
Value Function Loss: 0.07450

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.51454
Value Function Update Magnitude: 0.73943

Collected Steps per Second: 22,879.21731
Overall Steps per Second: 10,871.31409

Timestep Collection Time: 2.18626
Timestep Consumption Time: 2.41484
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.60110

Cumulative Model Updates: 75,116
Cumulative Timesteps: 626,401,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 626401988...
Checkpoint 626401988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,180.99806
Policy Entropy: 3.68276
Value Function Loss: 0.07185

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.71584

Collected Steps per Second: 21,843.67557
Overall Steps per Second: 10,683.10989

Timestep Collection Time: 2.28982
Timestep Consumption Time: 2.39215
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.68197

Cumulative Model Updates: 75,122
Cumulative Timesteps: 626,452,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,026.39443
Policy Entropy: 3.68340
Value Function Loss: 0.07344

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.54596
Value Function Update Magnitude: 0.74623

Collected Steps per Second: 22,186.16144
Overall Steps per Second: 10,830.58991

Timestep Collection Time: 2.25582
Timestep Consumption Time: 2.36516
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.62099

Cumulative Model Updates: 75,128
Cumulative Timesteps: 626,502,054

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 626502054...
Checkpoint 626502054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,625.11155
Policy Entropy: 3.68929
Value Function Loss: 0.06999

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.53371
Value Function Update Magnitude: 0.76804

Collected Steps per Second: 21,941.02623
Overall Steps per Second: 10,690.59029

Timestep Collection Time: 2.27938
Timestep Consumption Time: 2.39875
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.67813

Cumulative Model Updates: 75,134
Cumulative Timesteps: 626,552,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,334.50521
Policy Entropy: 3.69704
Value Function Loss: 0.06963

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.53923
Value Function Update Magnitude: 0.76218

Collected Steps per Second: 22,421.10146
Overall Steps per Second: 10,907.00860

Timestep Collection Time: 2.23049
Timestep Consumption Time: 2.35464
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.58513

Cumulative Model Updates: 75,140
Cumulative Timesteps: 626,602,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 626602076...
Checkpoint 626602076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,768.74987
Policy Entropy: 3.69234
Value Function Loss: 0.06708

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.53363
Value Function Update Magnitude: 0.75385

Collected Steps per Second: 22,060.47384
Overall Steps per Second: 10,657.26764

Timestep Collection Time: 2.26695
Timestep Consumption Time: 2.42562
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.69257

Cumulative Model Updates: 75,146
Cumulative Timesteps: 626,652,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,477.04449
Policy Entropy: 3.69096
Value Function Loss: 0.06728

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.73081

Collected Steps per Second: 22,049.91082
Overall Steps per Second: 10,809.37987

Timestep Collection Time: 2.26849
Timestep Consumption Time: 2.35897
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.62746

Cumulative Model Updates: 75,152
Cumulative Timesteps: 626,702,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 626702106...
Checkpoint 626702106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,800.44067
Policy Entropy: 3.68198
Value Function Loss: 0.06692

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.56521
Value Function Update Magnitude: 0.69767

Collected Steps per Second: 21,999.89266
Overall Steps per Second: 10,692.99700

Timestep Collection Time: 2.27310
Timestep Consumption Time: 2.40360
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.67671

Cumulative Model Updates: 75,158
Cumulative Timesteps: 626,752,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,430.30218
Policy Entropy: 3.68563
Value Function Loss: 0.06749

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.53376
Value Function Update Magnitude: 0.69779

Collected Steps per Second: 22,647.98921
Overall Steps per Second: 10,867.66091

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.39416
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.60283

Cumulative Model Updates: 75,164
Cumulative Timesteps: 626,802,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 626802136...
Checkpoint 626802136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,016.85926
Policy Entropy: 3.68539
Value Function Loss: 0.06600

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.69747

Collected Steps per Second: 22,478.52984
Overall Steps per Second: 10,743.56549

Timestep Collection Time: 2.22488
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.65507

Cumulative Model Updates: 75,170
Cumulative Timesteps: 626,852,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,137.30149
Policy Entropy: 3.68415
Value Function Loss: 0.06586

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.58057
Value Function Update Magnitude: 0.71815

Collected Steps per Second: 23,013.19176
Overall Steps per Second: 10,945.87141

Timestep Collection Time: 2.17397
Timestep Consumption Time: 2.39670
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.57067

Cumulative Model Updates: 75,176
Cumulative Timesteps: 626,902,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 626902178...
Checkpoint 626902178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.77263
Policy Entropy: 3.68005
Value Function Loss: 0.06876

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.55418
Value Function Update Magnitude: 0.70453

Collected Steps per Second: 22,680.60685
Overall Steps per Second: 10,618.32442

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.50512
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.71035

Cumulative Model Updates: 75,182
Cumulative Timesteps: 626,952,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,816.15620
Policy Entropy: 3.69240
Value Function Loss: 0.07052

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11472
Policy Update Magnitude: 0.58804
Value Function Update Magnitude: 0.71570

Collected Steps per Second: 22,965.15236
Overall Steps per Second: 10,842.04011

Timestep Collection Time: 2.17773
Timestep Consumption Time: 2.43505
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.61279

Cumulative Model Updates: 75,188
Cumulative Timesteps: 627,002,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 627002206...
Checkpoint 627002206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,058.29200
Policy Entropy: 3.70925
Value Function Loss: 0.06904

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.60982
Value Function Update Magnitude: 0.75576

Collected Steps per Second: 22,735.71284
Overall Steps per Second: 10,694.81634

Timestep Collection Time: 2.19918
Timestep Consumption Time: 2.47598
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.67516

Cumulative Model Updates: 75,194
Cumulative Timesteps: 627,052,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,153.88077
Policy Entropy: 3.72616
Value Function Loss: 0.06512

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.64996
Value Function Update Magnitude: 0.83650

Collected Steps per Second: 22,737.17971
Overall Steps per Second: 10,794.40749

Timestep Collection Time: 2.20001
Timestep Consumption Time: 2.43406
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.63407

Cumulative Model Updates: 75,200
Cumulative Timesteps: 627,102,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 627102228...
Checkpoint 627102228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,279.81027
Policy Entropy: 3.73703
Value Function Loss: 0.05962

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.62561
Value Function Update Magnitude: 0.87177

Collected Steps per Second: 22,520.59312
Overall Steps per Second: 10,773.81132

Timestep Collection Time: 2.22143
Timestep Consumption Time: 2.42205
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.64348

Cumulative Model Updates: 75,206
Cumulative Timesteps: 627,152,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,919.93844
Policy Entropy: 3.73064
Value Function Loss: 0.05873

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.62302
Value Function Update Magnitude: 0.86829

Collected Steps per Second: 22,570.00622
Overall Steps per Second: 10,775.24602

Timestep Collection Time: 2.21551
Timestep Consumption Time: 2.42513
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.64064

Cumulative Model Updates: 75,212
Cumulative Timesteps: 627,202,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 627202260...
Checkpoint 627202260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,349.44920
Policy Entropy: 3.72479
Value Function Loss: 0.05912

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10060
Policy Update Magnitude: 0.56634
Value Function Update Magnitude: 0.85429

Collected Steps per Second: 22,409.31944
Overall Steps per Second: 10,758.82677

Timestep Collection Time: 2.23237
Timestep Consumption Time: 2.41739
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.64976

Cumulative Model Updates: 75,218
Cumulative Timesteps: 627,252,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,940.57611
Policy Entropy: 3.72177
Value Function Loss: 0.06330

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.55584
Value Function Update Magnitude: 0.80393

Collected Steps per Second: 22,708.39709
Overall Steps per Second: 10,781.54703

Timestep Collection Time: 2.20209
Timestep Consumption Time: 2.43602
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.63811

Cumulative Model Updates: 75,224
Cumulative Timesteps: 627,302,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 627302292...
Checkpoint 627302292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,475.82640
Policy Entropy: 3.73310
Value Function Loss: 0.06461

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.55908
Value Function Update Magnitude: 0.70630

Collected Steps per Second: 22,403.94159
Overall Steps per Second: 10,750.75489

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.65363

Cumulative Model Updates: 75,230
Cumulative Timesteps: 627,352,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,294.00176
Policy Entropy: 3.72963
Value Function Loss: 0.06772

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.69241

Collected Steps per Second: 22,585.61835
Overall Steps per Second: 10,798.47378

Timestep Collection Time: 2.21406
Timestep Consumption Time: 2.41678
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.63084

Cumulative Model Updates: 75,236
Cumulative Timesteps: 627,402,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 627402328...
Checkpoint 627402328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,205.07534
Policy Entropy: 3.72229
Value Function Loss: 0.06393

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.52881
Value Function Update Magnitude: 0.69639

Collected Steps per Second: 22,414.80445
Overall Steps per Second: 10,762.14460

Timestep Collection Time: 2.23174
Timestep Consumption Time: 2.41640
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.64814

Cumulative Model Updates: 75,242
Cumulative Timesteps: 627,452,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,343.74650
Policy Entropy: 3.71467
Value Function Loss: 0.06190

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.72781

Collected Steps per Second: 22,634.98632
Overall Steps per Second: 10,757.59199

Timestep Collection Time: 2.20950
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.64900

Cumulative Model Updates: 75,248
Cumulative Timesteps: 627,502,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 627502364...
Checkpoint 627502364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,793.78950
Policy Entropy: 3.71505
Value Function Loss: 0.05889

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.77818

Collected Steps per Second: 22,595.70461
Overall Steps per Second: 10,779.31368

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.63926

Cumulative Model Updates: 75,254
Cumulative Timesteps: 627,552,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,887.60134
Policy Entropy: 3.72409
Value Function Loss: 0.06349

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.82199

Collected Steps per Second: 22,333.06935
Overall Steps per Second: 10,525.83923

Timestep Collection Time: 2.23928
Timestep Consumption Time: 2.51188
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.75117

Cumulative Model Updates: 75,260
Cumulative Timesteps: 627,602,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 627602382...
Checkpoint 627602382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,296.14011
Policy Entropy: 3.72337
Value Function Loss: 0.06355

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.57737
Value Function Update Magnitude: 0.83448

Collected Steps per Second: 22,681.34376
Overall Steps per Second: 10,612.22100

Timestep Collection Time: 2.20578
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.71438

Cumulative Model Updates: 75,266
Cumulative Timesteps: 627,652,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,760.47137
Policy Entropy: 3.71682
Value Function Loss: 0.06577

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.56684
Value Function Update Magnitude: 0.84012

Collected Steps per Second: 22,503.13870
Overall Steps per Second: 10,718.81938

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.44307
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.66525

Cumulative Model Updates: 75,272
Cumulative Timesteps: 627,702,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 627702418...
Checkpoint 627702418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,633.87643
Policy Entropy: 3.69908
Value Function Loss: 0.06658

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.53709
Value Function Update Magnitude: 0.79452

Collected Steps per Second: 22,643.98012
Overall Steps per Second: 10,719.37004

Timestep Collection Time: 2.20853
Timestep Consumption Time: 2.45685
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.66539

Cumulative Model Updates: 75,278
Cumulative Timesteps: 627,752,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,138.13748
Policy Entropy: 3.69959
Value Function Loss: 0.06736

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.58425
Value Function Update Magnitude: 0.72398

Collected Steps per Second: 22,595.79740
Overall Steps per Second: 10,615.76286

Timestep Collection Time: 2.21307
Timestep Consumption Time: 2.49748
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.71054

Cumulative Model Updates: 75,284
Cumulative Timesteps: 627,802,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 627802434...
Checkpoint 627802434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,828.86729
Policy Entropy: 3.70418
Value Function Loss: 0.06862

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.59190
Value Function Update Magnitude: 0.68330

Collected Steps per Second: 22,611.61176
Overall Steps per Second: 10,668.26679

Timestep Collection Time: 2.21134
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.68698

Cumulative Model Updates: 75,290
Cumulative Timesteps: 627,852,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,813.87915
Policy Entropy: 3.71249
Value Function Loss: 0.06738

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.56587
Value Function Update Magnitude: 0.77725

Collected Steps per Second: 22,822.92535
Overall Steps per Second: 10,709.87505

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.47930
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.67139

Cumulative Model Updates: 75,296
Cumulative Timesteps: 627,902,466

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 627902466...
Checkpoint 627902466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,579.02197
Policy Entropy: 3.70835
Value Function Loss: 0.06873

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.55182
Value Function Update Magnitude: 0.88090

Collected Steps per Second: 21,474.80174
Overall Steps per Second: 10,272.27443

Timestep Collection Time: 2.32859
Timestep Consumption Time: 2.53947
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.86806

Cumulative Model Updates: 75,302
Cumulative Timesteps: 627,952,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,290.63835
Policy Entropy: 3.70887
Value Function Loss: 0.06927

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.59088
Value Function Update Magnitude: 0.86313

Collected Steps per Second: 21,799.35926
Overall Steps per Second: 10,408.39347

Timestep Collection Time: 2.29465
Timestep Consumption Time: 2.51127
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.80593

Cumulative Model Updates: 75,308
Cumulative Timesteps: 628,002,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 628002494...
Checkpoint 628002494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,088.27766
Policy Entropy: 3.69695
Value Function Loss: 0.06800

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.83050

Collected Steps per Second: 18,630.74807
Overall Steps per Second: 9,565.20680

Timestep Collection Time: 2.68395
Timestep Consumption Time: 2.54375
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 5.22770

Cumulative Model Updates: 75,314
Cumulative Timesteps: 628,052,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,533.19089
Policy Entropy: 3.70665
Value Function Loss: 0.06605

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.50658
Value Function Update Magnitude: 0.85205

Collected Steps per Second: 19,100.59532
Overall Steps per Second: 9,836.54905

Timestep Collection Time: 2.61824
Timestep Consumption Time: 2.46586
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 5.08410

Cumulative Model Updates: 75,320
Cumulative Timesteps: 628,102,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 628102508...
Checkpoint 628102508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,447.52846
Policy Entropy: 3.69510
Value Function Loss: 0.06625

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.82306

Collected Steps per Second: 21,491.28687
Overall Steps per Second: 10,240.38080

Timestep Collection Time: 2.32783
Timestep Consumption Time: 2.55754
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.88537

Cumulative Model Updates: 75,326
Cumulative Timesteps: 628,152,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,602.69685
Policy Entropy: 3.69416
Value Function Loss: 0.06697

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.62029
Value Function Update Magnitude: 0.81980

Collected Steps per Second: 20,682.65923
Overall Steps per Second: 10,112.37729

Timestep Collection Time: 2.41864
Timestep Consumption Time: 2.52816
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.94681

Cumulative Model Updates: 75,332
Cumulative Timesteps: 628,202,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 628202560...
Checkpoint 628202560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,588.33686
Policy Entropy: 3.69118
Value Function Loss: 0.06757

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.85430

Collected Steps per Second: 20,958.37145
Overall Steps per Second: 10,137.57812

Timestep Collection Time: 2.38692
Timestep Consumption Time: 2.54779
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.93471

Cumulative Model Updates: 75,338
Cumulative Timesteps: 628,252,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,892.82900
Policy Entropy: 3.69677
Value Function Loss: 0.06482

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09497
Policy Update Magnitude: 0.53612
Value Function Update Magnitude: 0.88041

Collected Steps per Second: 20,471.45064
Overall Steps per Second: 10,137.33776

Timestep Collection Time: 2.44370
Timestep Consumption Time: 2.49113
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.93483

Cumulative Model Updates: 75,344
Cumulative Timesteps: 628,302,612

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 628302612...
Checkpoint 628302612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,335.93502
Policy Entropy: 3.70035
Value Function Loss: 0.06584

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.88595

Collected Steps per Second: 22,186.40332
Overall Steps per Second: 10,604.87283

Timestep Collection Time: 2.25399
Timestep Consumption Time: 2.46158
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.71557

Cumulative Model Updates: 75,350
Cumulative Timesteps: 628,352,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,079.05233
Policy Entropy: 3.70220
Value Function Loss: 0.06530

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.56607
Value Function Update Magnitude: 0.88468

Collected Steps per Second: 20,150.18586
Overall Steps per Second: 10,007.47679

Timestep Collection Time: 2.48157
Timestep Consumption Time: 2.51510
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.99666

Cumulative Model Updates: 75,356
Cumulative Timesteps: 628,402,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 628402624...
Checkpoint 628402624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,227.82775
Policy Entropy: 3.69793
Value Function Loss: 0.06549

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.57064
Value Function Update Magnitude: 0.87925

Collected Steps per Second: 21,848.37955
Overall Steps per Second: 10,465.19232

Timestep Collection Time: 2.28887
Timestep Consumption Time: 2.48964
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.77851

Cumulative Model Updates: 75,362
Cumulative Timesteps: 628,452,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,385.52290
Policy Entropy: 3.69161
Value Function Loss: 0.06515

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.82852

Collected Steps per Second: 22,243.40472
Overall Steps per Second: 10,579.55897

Timestep Collection Time: 2.24903
Timestep Consumption Time: 2.47953
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.72855

Cumulative Model Updates: 75,368
Cumulative Timesteps: 628,502,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 628502658...
Checkpoint 628502658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.87250
Policy Entropy: 3.70082
Value Function Loss: 0.06728

Mean KL Divergence: 0.01809
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.49510
Value Function Update Magnitude: 0.74549

Collected Steps per Second: 22,376.79193
Overall Steps per Second: 10,680.85552

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.68146

Cumulative Model Updates: 75,374
Cumulative Timesteps: 628,552,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,713.17781
Policy Entropy: 3.70478
Value Function Loss: 0.06625

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.11627
Policy Update Magnitude: 0.50933
Value Function Update Magnitude: 0.74200

Collected Steps per Second: 22,453.61564
Overall Steps per Second: 10,514.06829

Timestep Collection Time: 2.22797
Timestep Consumption Time: 2.53004
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.75801

Cumulative Model Updates: 75,380
Cumulative Timesteps: 628,602,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 628602686...
Checkpoint 628602686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,551.05975
Policy Entropy: 3.71217
Value Function Loss: 0.06527

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.48290
Value Function Update Magnitude: 0.70741

Collected Steps per Second: 22,716.63011
Overall Steps per Second: 10,646.58485

Timestep Collection Time: 2.20191
Timestep Consumption Time: 2.49631
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.69822

Cumulative Model Updates: 75,386
Cumulative Timesteps: 628,652,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,828.64297
Policy Entropy: 3.71230
Value Function Loss: 0.06087

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.47119
Value Function Update Magnitude: 0.67112

Collected Steps per Second: 22,849.25881
Overall Steps per Second: 10,778.33761

Timestep Collection Time: 2.18887
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.64023

Cumulative Model Updates: 75,392
Cumulative Timesteps: 628,702,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 628702720...
Checkpoint 628702720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,986.06839
Policy Entropy: 3.72911
Value Function Loss: 0.05943

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.51840
Value Function Update Magnitude: 0.65962

Collected Steps per Second: 22,659.93635
Overall Steps per Second: 10,741.22991

Timestep Collection Time: 2.20707
Timestep Consumption Time: 2.44901
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.65608

Cumulative Model Updates: 75,398
Cumulative Timesteps: 628,752,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,281.92223
Policy Entropy: 3.73134
Value Function Loss: 0.05775

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.56345
Value Function Update Magnitude: 0.73710

Collected Steps per Second: 22,558.44469
Overall Steps per Second: 10,675.81434

Timestep Collection Time: 2.21788
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.68648

Cumulative Model Updates: 75,404
Cumulative Timesteps: 628,802,764

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 628802764...
Checkpoint 628802764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,845.75792
Policy Entropy: 3.72362
Value Function Loss: 0.05515

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.74556

Collected Steps per Second: 22,610.68649
Overall Steps per Second: 10,813.97863

Timestep Collection Time: 2.21161
Timestep Consumption Time: 2.41259
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.62420

Cumulative Model Updates: 75,410
Cumulative Timesteps: 628,852,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.58032
Policy Entropy: 3.71725
Value Function Loss: 0.05258

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.52499
Value Function Update Magnitude: 0.75567

Collected Steps per Second: 22,820.07444
Overall Steps per Second: 10,653.91581

Timestep Collection Time: 2.19246
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.69611

Cumulative Model Updates: 75,416
Cumulative Timesteps: 628,902,802

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 628902802...
Checkpoint 628902802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.72148
Policy Entropy: 3.72573
Value Function Loss: 0.04983

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.51491
Value Function Update Magnitude: 0.78296

Collected Steps per Second: 22,577.08274
Overall Steps per Second: 10,623.25563

Timestep Collection Time: 2.21588
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.70929

Cumulative Model Updates: 75,422
Cumulative Timesteps: 628,952,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,770.80922
Policy Entropy: 3.72881
Value Function Loss: 0.04923

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.51601
Value Function Update Magnitude: 0.78441

Collected Steps per Second: 23,003.52917
Overall Steps per Second: 10,870.30077

Timestep Collection Time: 2.17454
Timestep Consumption Time: 2.42718
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.60171

Cumulative Model Updates: 75,428
Cumulative Timesteps: 629,002,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 629002852...
Checkpoint 629002852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,992.84631
Policy Entropy: 3.74335
Value Function Loss: 0.05146

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.58044
Value Function Update Magnitude: 0.78658

Collected Steps per Second: 22,538.23673
Overall Steps per Second: 10,565.85207

Timestep Collection Time: 2.21854
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.73242

Cumulative Model Updates: 75,434
Cumulative Timesteps: 629,052,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,410.89178
Policy Entropy: 3.74903
Value Function Loss: 0.05142

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.63176
Value Function Update Magnitude: 0.79952

Collected Steps per Second: 22,974.32016
Overall Steps per Second: 10,817.92768

Timestep Collection Time: 2.17721
Timestep Consumption Time: 2.44659
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62381

Cumulative Model Updates: 75,440
Cumulative Timesteps: 629,102,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 629102874...
Checkpoint 629102874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.39680
Policy Entropy: 3.74894
Value Function Loss: 0.05157

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.60727
Value Function Update Magnitude: 0.81923

Collected Steps per Second: 22,410.92690
Overall Steps per Second: 10,725.95829

Timestep Collection Time: 2.23141
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.66233

Cumulative Model Updates: 75,446
Cumulative Timesteps: 629,152,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,734.62873
Policy Entropy: 3.72916
Value Function Loss: 0.05210

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.57863
Value Function Update Magnitude: 0.79902

Collected Steps per Second: 22,919.69136
Overall Steps per Second: 10,838.05173

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.43272
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.61504

Cumulative Model Updates: 75,452
Cumulative Timesteps: 629,202,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 629202900...
Checkpoint 629202900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.38542
Policy Entropy: 3.71784
Value Function Loss: 0.05396

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07824
Policy Update Magnitude: 0.61821
Value Function Update Magnitude: 0.78738

Collected Steps per Second: 22,531.50193
Overall Steps per Second: 10,702.34377

Timestep Collection Time: 2.21929
Timestep Consumption Time: 2.45295
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.67225

Cumulative Model Updates: 75,458
Cumulative Timesteps: 629,252,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,030.25968
Policy Entropy: 3.71771
Value Function Loss: 0.05741

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.57907
Value Function Update Magnitude: 0.74382

Collected Steps per Second: 22,965.57138
Overall Steps per Second: 10,846.72005

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.43359
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61172

Cumulative Model Updates: 75,464
Cumulative Timesteps: 629,302,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 629302926...
Checkpoint 629302926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,816.20529
Policy Entropy: 3.72707
Value Function Loss: 0.05851

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.53779
Value Function Update Magnitude: 0.72059

Collected Steps per Second: 22,702.24613
Overall Steps per Second: 10,671.33512

Timestep Collection Time: 2.20375
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.68826

Cumulative Model Updates: 75,470
Cumulative Timesteps: 629,352,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,463.20822
Policy Entropy: 3.72667
Value Function Loss: 0.05969

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.77370

Collected Steps per Second: 22,596.72418
Overall Steps per Second: 10,597.10835

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.50666
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.72034

Cumulative Model Updates: 75,476
Cumulative Timesteps: 629,402,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 629402978...
Checkpoint 629402978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,006.13407
Policy Entropy: 3.71440
Value Function Loss: 0.05955

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.53978
Value Function Update Magnitude: 0.79314

Collected Steps per Second: 22,768.33756
Overall Steps per Second: 10,700.31634

Timestep Collection Time: 2.19647
Timestep Consumption Time: 2.47722
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.67369

Cumulative Model Updates: 75,482
Cumulative Timesteps: 629,452,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,477.09969
Policy Entropy: 3.71188
Value Function Loss: 0.06070

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.53539
Value Function Update Magnitude: 0.75798

Collected Steps per Second: 22,907.20721
Overall Steps per Second: 10,708.80581

Timestep Collection Time: 2.18316
Timestep Consumption Time: 2.48683
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.66999

Cumulative Model Updates: 75,488
Cumulative Timesteps: 629,502,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 629502998...
Checkpoint 629502998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,642.59019
Policy Entropy: 3.71140
Value Function Loss: 0.06283

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.53258
Value Function Update Magnitude: 0.74486

Collected Steps per Second: 22,892.61540
Overall Steps per Second: 10,660.91288

Timestep Collection Time: 2.18516
Timestep Consumption Time: 2.50712
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.69228

Cumulative Model Updates: 75,494
Cumulative Timesteps: 629,553,022

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,829.10875
Policy Entropy: 3.71333
Value Function Loss: 0.06439

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.53363
Value Function Update Magnitude: 0.76862

Collected Steps per Second: 22,620.06822
Overall Steps per Second: 10,659.59124

Timestep Collection Time: 2.21158
Timestep Consumption Time: 2.48147
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.69305

Cumulative Model Updates: 75,500
Cumulative Timesteps: 629,603,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 629603048...
Checkpoint 629603048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,192.67898
Policy Entropy: 3.70939
Value Function Loss: 0.06527

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.82904

Collected Steps per Second: 22,506.36422
Overall Steps per Second: 10,611.26927

Timestep Collection Time: 2.22266
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.71423

Cumulative Model Updates: 75,506
Cumulative Timesteps: 629,653,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,364.96314
Policy Entropy: 3.71818
Value Function Loss: 0.06593

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.59576
Value Function Update Magnitude: 0.84049

Collected Steps per Second: 22,809.28146
Overall Steps per Second: 10,771.05106

Timestep Collection Time: 2.19314
Timestep Consumption Time: 2.45116
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.64430

Cumulative Model Updates: 75,512
Cumulative Timesteps: 629,703,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 629703096...
Checkpoint 629703096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,790.09720
Policy Entropy: 3.71709
Value Function Loss: 0.07069

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.63390
Value Function Update Magnitude: 0.75662

Collected Steps per Second: 22,440.22860
Overall Steps per Second: 10,638.20759

Timestep Collection Time: 2.22885
Timestep Consumption Time: 2.47269
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.70154

Cumulative Model Updates: 75,518
Cumulative Timesteps: 629,753,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,520.26740
Policy Entropy: 3.72923
Value Function Loss: 0.06930

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.67249
Value Function Update Magnitude: 0.73534

Collected Steps per Second: 22,598.80061
Overall Steps per Second: 10,670.11743

Timestep Collection Time: 2.21286
Timestep Consumption Time: 2.47387
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.68673

Cumulative Model Updates: 75,524
Cumulative Timesteps: 629,803,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 629803120...
Checkpoint 629803120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,671.80246
Policy Entropy: 3.71787
Value Function Loss: 0.07102

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.69649
Value Function Update Magnitude: 0.80124

Collected Steps per Second: 22,890.61948
Overall Steps per Second: 10,863.50531

Timestep Collection Time: 2.18483
Timestep Consumption Time: 2.41885
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.60367

Cumulative Model Updates: 75,530
Cumulative Timesteps: 629,853,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,206.96854
Policy Entropy: 3.72996
Value Function Loss: 0.07261

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.63860
Value Function Update Magnitude: 0.82109

Collected Steps per Second: 22,999.83647
Overall Steps per Second: 10,833.24305

Timestep Collection Time: 2.17454
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61672

Cumulative Model Updates: 75,536
Cumulative Timesteps: 629,903,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 629903146...
Checkpoint 629903146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,280.56698
Policy Entropy: 3.71688
Value Function Loss: 0.07068

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.59591
Value Function Update Magnitude: 0.80950

Collected Steps per Second: 22,643.13243
Overall Steps per Second: 10,739.21488

Timestep Collection Time: 2.20835
Timestep Consumption Time: 2.44785
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.65621

Cumulative Model Updates: 75,542
Cumulative Timesteps: 629,953,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,848.23743
Policy Entropy: 3.70698
Value Function Loss: 0.06949

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.60409
Value Function Update Magnitude: 0.85506

Collected Steps per Second: 22,851.30142
Overall Steps per Second: 10,852.84115

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.42038
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.60967

Cumulative Model Updates: 75,548
Cumulative Timesteps: 630,003,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 630003178...
Checkpoint 630003178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,448.89586
Policy Entropy: 3.71331
Value Function Loss: 0.06817

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.57777
Value Function Update Magnitude: 0.78809

Collected Steps per Second: 22,202.10055
Overall Steps per Second: 10,681.17782

Timestep Collection Time: 2.25285
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.68282

Cumulative Model Updates: 75,554
Cumulative Timesteps: 630,053,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,579.86728
Policy Entropy: 3.70927
Value Function Loss: 0.07274

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.62089
Value Function Update Magnitude: 0.67578

Collected Steps per Second: 22,326.89691
Overall Steps per Second: 10,875.07854

Timestep Collection Time: 2.24017
Timestep Consumption Time: 2.35897
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.59914

Cumulative Model Updates: 75,560
Cumulative Timesteps: 630,103,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 630103212...
Checkpoint 630103212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,827.46717
Policy Entropy: 3.70770
Value Function Loss: 0.07311

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.59505
Value Function Update Magnitude: 0.72473

Collected Steps per Second: 22,135.60911
Overall Steps per Second: 10,669.81282

Timestep Collection Time: 2.25917
Timestep Consumption Time: 2.42770
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.68687

Cumulative Model Updates: 75,566
Cumulative Timesteps: 630,153,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,250.48574
Policy Entropy: 3.70687
Value Function Loss: 0.07176

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.58723
Value Function Update Magnitude: 0.70449

Collected Steps per Second: 21,971.94857
Overall Steps per Second: 10,669.50004

Timestep Collection Time: 2.27690
Timestep Consumption Time: 2.41198
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68888

Cumulative Model Updates: 75,572
Cumulative Timesteps: 630,203,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 630203248...
Checkpoint 630203248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,709.69889
Policy Entropy: 3.68984
Value Function Loss: 0.07131

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.59586
Value Function Update Magnitude: 0.72402

Collected Steps per Second: 22,161.20619
Overall Steps per Second: 10,876.52249

Timestep Collection Time: 2.25755
Timestep Consumption Time: 2.34227
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.59982

Cumulative Model Updates: 75,578
Cumulative Timesteps: 630,253,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,343.38462
Policy Entropy: 3.70260
Value Function Loss: 0.06897

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.56924
Value Function Update Magnitude: 0.66856

Collected Steps per Second: 22,167.23038
Overall Steps per Second: 10,836.73674

Timestep Collection Time: 2.25621
Timestep Consumption Time: 2.35901
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61523

Cumulative Model Updates: 75,584
Cumulative Timesteps: 630,303,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 630303292...
Checkpoint 630303292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,036.24580
Policy Entropy: 3.71305
Value Function Loss: 0.06953

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.15416
Policy Update Magnitude: 0.47447
Value Function Update Magnitude: 0.63192

Collected Steps per Second: 21,729.92986
Overall Steps per Second: 10,630.93372

Timestep Collection Time: 2.30208
Timestep Consumption Time: 2.40344
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.70551

Cumulative Model Updates: 75,590
Cumulative Timesteps: 630,353,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,441.14143
Policy Entropy: 3.73459
Value Function Loss: 0.06847

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.46727
Value Function Update Magnitude: 0.60667

Collected Steps per Second: 22,866.13829
Overall Steps per Second: 10,767.20918

Timestep Collection Time: 2.18778
Timestep Consumption Time: 2.45837
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.64614

Cumulative Model Updates: 75,596
Cumulative Timesteps: 630,403,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 630403342...
Checkpoint 630403342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,040.33332
Policy Entropy: 3.73140
Value Function Loss: 0.06816

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.59560
Value Function Update Magnitude: 0.61357

Collected Steps per Second: 22,647.67188
Overall Steps per Second: 10,859.85695

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.39695
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.60522

Cumulative Model Updates: 75,602
Cumulative Timesteps: 630,453,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,704.97673
Policy Entropy: 3.73426
Value Function Loss: 0.06593

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.67012
Value Function Update Magnitude: 0.64608

Collected Steps per Second: 22,625.91667
Overall Steps per Second: 10,823.99672

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61992

Cumulative Model Updates: 75,608
Cumulative Timesteps: 630,503,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 630503360...
Checkpoint 630503360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,024.52611
Policy Entropy: 3.72394
Value Function Loss: 0.06529

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.61146
Value Function Update Magnitude: 0.73736

Collected Steps per Second: 22,531.02680
Overall Steps per Second: 10,706.60579

Timestep Collection Time: 2.21934
Timestep Consumption Time: 2.45105
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.67039

Cumulative Model Updates: 75,614
Cumulative Timesteps: 630,553,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,549.34762
Policy Entropy: 3.72415
Value Function Loss: 0.06619

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.59320
Value Function Update Magnitude: 0.82611

Collected Steps per Second: 22,870.38932
Overall Steps per Second: 10,899.28445

Timestep Collection Time: 2.18711
Timestep Consumption Time: 2.40218
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.58929

Cumulative Model Updates: 75,620
Cumulative Timesteps: 630,603,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 630603384...
Checkpoint 630603384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,446.13678
Policy Entropy: 3.71592
Value Function Loss: 0.06508

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.59936
Value Function Update Magnitude: 0.87193

Collected Steps per Second: 22,488.83179
Overall Steps per Second: 10,692.64906

Timestep Collection Time: 2.22413
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.67779

Cumulative Model Updates: 75,626
Cumulative Timesteps: 630,653,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,417.40689
Policy Entropy: 3.70166
Value Function Loss: 0.06460

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.58854
Value Function Update Magnitude: 0.89187

Collected Steps per Second: 22,882.63131
Overall Steps per Second: 10,806.79864

Timestep Collection Time: 2.18533
Timestep Consumption Time: 2.44195
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.62727

Cumulative Model Updates: 75,632
Cumulative Timesteps: 630,703,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 630703408...
Checkpoint 630703408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,509.92611
Policy Entropy: 3.69769
Value Function Loss: 0.06266

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.58154
Value Function Update Magnitude: 0.88859

Collected Steps per Second: 22,631.45749
Overall Steps per Second: 10,686.28787

Timestep Collection Time: 2.20958
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.67945

Cumulative Model Updates: 75,638
Cumulative Timesteps: 630,753,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,214.18684
Policy Entropy: 3.69689
Value Function Loss: 0.06764

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.52858
Value Function Update Magnitude: 0.87501

Collected Steps per Second: 22,893.22493
Overall Steps per Second: 10,730.93174

Timestep Collection Time: 2.18423
Timestep Consumption Time: 2.47557
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.65980

Cumulative Model Updates: 75,644
Cumulative Timesteps: 630,803,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 630803418...
Checkpoint 630803418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.51126
Policy Entropy: 3.70321
Value Function Loss: 0.06732

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06433
Policy Update Magnitude: 0.64596
Value Function Update Magnitude: 0.88454

Collected Steps per Second: 22,584.64014
Overall Steps per Second: 10,804.85290

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.41481
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.62977

Cumulative Model Updates: 75,650
Cumulative Timesteps: 630,853,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,618.16902
Policy Entropy: 3.69933
Value Function Loss: 0.06990

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.70868
Value Function Update Magnitude: 0.87400

Collected Steps per Second: 23,101.32200
Overall Steps per Second: 10,868.35539

Timestep Collection Time: 2.16542
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.60272

Cumulative Model Updates: 75,656
Cumulative Timesteps: 630,903,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 630903466...
Checkpoint 630903466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,415.69427
Policy Entropy: 3.69447
Value Function Loss: 0.07139

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.66404
Value Function Update Magnitude: 0.84872

Collected Steps per Second: 22,556.29230
Overall Steps per Second: 10,688.76796

Timestep Collection Time: 2.21739
Timestep Consumption Time: 2.46192
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.67930

Cumulative Model Updates: 75,662
Cumulative Timesteps: 630,953,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,582.62251
Policy Entropy: 3.69301
Value Function Loss: 0.07253

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.55538
Value Function Update Magnitude: 0.74930

Collected Steps per Second: 22,737.76492
Overall Steps per Second: 10,710.56812

Timestep Collection Time: 2.19969
Timestep Consumption Time: 2.47009
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.66978

Cumulative Model Updates: 75,668
Cumulative Timesteps: 631,003,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 631003498...
Checkpoint 631003498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,272.28116
Policy Entropy: 3.68373
Value Function Loss: 0.07439

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.55548
Value Function Update Magnitude: 0.71936

Collected Steps per Second: 22,474.93495
Overall Steps per Second: 10,796.55010

Timestep Collection Time: 2.22577
Timestep Consumption Time: 2.40756
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.63333

Cumulative Model Updates: 75,674
Cumulative Timesteps: 631,053,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,824.12989
Policy Entropy: 3.68652
Value Function Loss: 0.07240

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.52437
Value Function Update Magnitude: 0.77814

Collected Steps per Second: 23,041.16477
Overall Steps per Second: 10,864.87733

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.60438

Cumulative Model Updates: 75,680
Cumulative Timesteps: 631,103,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 631103548...
Checkpoint 631103548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,972.48132
Policy Entropy: 3.67511
Value Function Loss: 0.07077

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.63563
Value Function Update Magnitude: 0.77406

Collected Steps per Second: 22,673.42335
Overall Steps per Second: 10,722.32301

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.45794
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.66317

Cumulative Model Updates: 75,686
Cumulative Timesteps: 631,153,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,183.73801
Policy Entropy: 3.66807
Value Function Loss: 0.06998

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07531
Policy Update Magnitude: 0.70835
Value Function Update Magnitude: 0.72646

Collected Steps per Second: 22,647.82617
Overall Steps per Second: 10,681.45948

Timestep Collection Time: 2.20869
Timestep Consumption Time: 2.47438
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.68307

Cumulative Model Updates: 75,692
Cumulative Timesteps: 631,203,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 631203570...
Checkpoint 631203570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,845.64932
Policy Entropy: 3.65611
Value Function Loss: 0.07232

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.67569
Value Function Update Magnitude: 0.73474

Collected Steps per Second: 22,831.57456
Overall Steps per Second: 10,856.37277

Timestep Collection Time: 2.19021
Timestep Consumption Time: 2.41593
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.60614

Cumulative Model Updates: 75,698
Cumulative Timesteps: 631,253,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,705.51161
Policy Entropy: 3.64509
Value Function Loss: 0.07437

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.68738

Collected Steps per Second: 22,892.00709
Overall Steps per Second: 10,860.85308

Timestep Collection Time: 2.18539
Timestep Consumption Time: 2.42088
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.60627

Cumulative Model Updates: 75,704
Cumulative Timesteps: 631,303,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 631303604...
Checkpoint 631303604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,617.49698
Policy Entropy: 3.65494
Value Function Loss: 0.07253

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08436
Policy Update Magnitude: 0.54167
Value Function Update Magnitude: 0.69824

Collected Steps per Second: 21,922.38990
Overall Steps per Second: 10,699.55438

Timestep Collection Time: 2.28187
Timestep Consumption Time: 2.39347
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.67533

Cumulative Model Updates: 75,710
Cumulative Timesteps: 631,353,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,583.43219
Policy Entropy: 3.66308
Value Function Loss: 0.06976

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.72792

Collected Steps per Second: 21,936.90442
Overall Steps per Second: 10,670.87640

Timestep Collection Time: 2.27945
Timestep Consumption Time: 2.40658
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.68603

Cumulative Model Updates: 75,716
Cumulative Timesteps: 631,403,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 631403632...
Checkpoint 631403632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,477.01571
Policy Entropy: 3.67953
Value Function Loss: 0.07317

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.63311
Value Function Update Magnitude: 0.69501

Collected Steps per Second: 22,275.94519
Overall Steps per Second: 10,901.20374

Timestep Collection Time: 2.24493
Timestep Consumption Time: 2.34245
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.58738

Cumulative Model Updates: 75,722
Cumulative Timesteps: 631,453,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,684.39451
Policy Entropy: 3.67726
Value Function Loss: 0.07375

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.64036
Value Function Update Magnitude: 0.69944

Collected Steps per Second: 22,258.53752
Overall Steps per Second: 10,855.40038

Timestep Collection Time: 2.24705
Timestep Consumption Time: 2.36043
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.60748

Cumulative Model Updates: 75,728
Cumulative Timesteps: 631,503,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 631503656...
Checkpoint 631503656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,197.62239
Policy Entropy: 3.67950
Value Function Loss: 0.07461

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.62260
Value Function Update Magnitude: 0.69120

Collected Steps per Second: 22,111.40039
Overall Steps per Second: 10,673.96566

Timestep Collection Time: 2.26137
Timestep Consumption Time: 2.42311
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.68448

Cumulative Model Updates: 75,734
Cumulative Timesteps: 631,553,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,099.00217
Policy Entropy: 3.68063
Value Function Loss: 0.07233

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.55612
Value Function Update Magnitude: 0.73294

Collected Steps per Second: 22,037.81481
Overall Steps per Second: 10,534.99035

Timestep Collection Time: 2.26919
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.74685

Cumulative Model Updates: 75,740
Cumulative Timesteps: 631,603,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 631603666...
Checkpoint 631603666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,893.49349
Policy Entropy: 3.68957
Value Function Loss: 0.06986

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.54097
Value Function Update Magnitude: 0.73141

Collected Steps per Second: 22,740.04702
Overall Steps per Second: 10,771.30451

Timestep Collection Time: 2.19991
Timestep Consumption Time: 2.44447
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.64438

Cumulative Model Updates: 75,746
Cumulative Timesteps: 631,653,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,351.96683
Policy Entropy: 3.69436
Value Function Loss: 0.07010

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07648
Policy Update Magnitude: 0.59861
Value Function Update Magnitude: 0.72879

Collected Steps per Second: 23,191.34436
Overall Steps per Second: 10,810.02370

Timestep Collection Time: 2.15624
Timestep Consumption Time: 2.46966
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.62589

Cumulative Model Updates: 75,752
Cumulative Timesteps: 631,703,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 631703698...
Checkpoint 631703698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,758.50204
Policy Entropy: 3.69326
Value Function Loss: 0.06717

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.67560
Value Function Update Magnitude: 0.80270

Collected Steps per Second: 22,389.51724
Overall Steps per Second: 10,592.11230

Timestep Collection Time: 2.23337
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.72087

Cumulative Model Updates: 75,758
Cumulative Timesteps: 631,753,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,531.43194
Policy Entropy: 3.70149
Value Function Loss: 0.06717

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.66469
Value Function Update Magnitude: 0.89067

Collected Steps per Second: 22,774.46788
Overall Steps per Second: 10,879.74723

Timestep Collection Time: 2.19606
Timestep Consumption Time: 2.40093
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.59698

Cumulative Model Updates: 75,764
Cumulative Timesteps: 631,803,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 631803716...
Checkpoint 631803716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,213.83069
Policy Entropy: 3.70004
Value Function Loss: 0.06634

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.72024
Value Function Update Magnitude: 0.90528

Collected Steps per Second: 22,765.41732
Overall Steps per Second: 10,635.89816

Timestep Collection Time: 2.19667
Timestep Consumption Time: 2.50515
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.70181

Cumulative Model Updates: 75,770
Cumulative Timesteps: 631,853,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,738.82715
Policy Entropy: 3.69493
Value Function Loss: 0.06754

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.67378
Value Function Update Magnitude: 0.87098

Collected Steps per Second: 23,143.06525
Overall Steps per Second: 10,866.04462

Timestep Collection Time: 2.16047
Timestep Consumption Time: 2.44102
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.60149

Cumulative Model Updates: 75,776
Cumulative Timesteps: 631,903,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 631903724...
Checkpoint 631903724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,893.51902
Policy Entropy: 3.69518
Value Function Loss: 0.06697

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.62209
Value Function Update Magnitude: 0.80043

Collected Steps per Second: 22,688.43322
Overall Steps per Second: 10,641.94534

Timestep Collection Time: 2.20377
Timestep Consumption Time: 2.49462
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.69839

Cumulative Model Updates: 75,782
Cumulative Timesteps: 631,953,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,552.68915
Policy Entropy: 3.69945
Value Function Loss: 0.06560

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.65098
Value Function Update Magnitude: 0.78360

Collected Steps per Second: 22,708.20089
Overall Steps per Second: 10,856.64811

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.40401
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.60621

Cumulative Model Updates: 75,788
Cumulative Timesteps: 632,003,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 632003732...
Checkpoint 632003732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,213.39982
Policy Entropy: 3.68960
Value Function Loss: 0.06465

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.61983
Value Function Update Magnitude: 0.84650

Collected Steps per Second: 22,354.85231
Overall Steps per Second: 10,722.49922

Timestep Collection Time: 2.23790
Timestep Consumption Time: 2.42780
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.66570

Cumulative Model Updates: 75,794
Cumulative Timesteps: 632,053,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,899.87850
Policy Entropy: 3.70078
Value Function Loss: 0.06343

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.15890
Policy Update Magnitude: 0.50674
Value Function Update Magnitude: 0.87887

Collected Steps per Second: 23,114.15262
Overall Steps per Second: 10,875.17148

Timestep Collection Time: 2.16396
Timestep Consumption Time: 2.43533
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.59928

Cumulative Model Updates: 75,800
Cumulative Timesteps: 632,103,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 632103778...
Checkpoint 632103778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,626.15234
Policy Entropy: 3.69875
Value Function Loss: 0.06386

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.48914
Value Function Update Magnitude: 0.87289

Collected Steps per Second: 22,480.43112
Overall Steps per Second: 10,636.79226

Timestep Collection Time: 2.22425
Timestep Consumption Time: 2.47661
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.70085

Cumulative Model Updates: 75,806
Cumulative Timesteps: 632,153,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,554.75506
Policy Entropy: 3.69991
Value Function Loss: 0.05971

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.89142

Collected Steps per Second: 22,776.16233
Overall Steps per Second: 10,716.89833

Timestep Collection Time: 2.19651
Timestep Consumption Time: 2.47163
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.66814

Cumulative Model Updates: 75,812
Cumulative Timesteps: 632,203,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 632203808...
Checkpoint 632203808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.57950
Policy Entropy: 3.71394
Value Function Loss: 0.05901

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.54718
Value Function Update Magnitude: 0.84478

Collected Steps per Second: 22,515.12794
Overall Steps per Second: 10,792.35056

Timestep Collection Time: 2.22162
Timestep Consumption Time: 2.41315
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.63476

Cumulative Model Updates: 75,818
Cumulative Timesteps: 632,253,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,185.90282
Policy Entropy: 3.71835
Value Function Loss: 0.05747

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10577
Policy Update Magnitude: 0.57252
Value Function Update Magnitude: 0.77957

Collected Steps per Second: 22,889.56847
Overall Steps per Second: 10,664.65861

Timestep Collection Time: 2.18536
Timestep Consumption Time: 2.50508
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.69045

Cumulative Model Updates: 75,824
Cumulative Timesteps: 632,303,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 632303850...
Checkpoint 632303850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,515.70370
Policy Entropy: 3.72983
Value Function Loss: 0.05839

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.55255
Value Function Update Magnitude: 0.80603

Collected Steps per Second: 22,877.28660
Overall Steps per Second: 10,863.39850

Timestep Collection Time: 2.18680
Timestep Consumption Time: 2.41839
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.60519

Cumulative Model Updates: 75,830
Cumulative Timesteps: 632,353,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,187.93853
Policy Entropy: 3.71892
Value Function Loss: 0.06018

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.54168
Value Function Update Magnitude: 0.81623

Collected Steps per Second: 22,569.49656
Overall Steps per Second: 10,597.78300

Timestep Collection Time: 2.21538
Timestep Consumption Time: 2.50259
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.71797

Cumulative Model Updates: 75,836
Cumulative Timesteps: 632,403,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 632403878...
Checkpoint 632403878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,853.22571
Policy Entropy: 3.71202
Value Function Loss: 0.05970

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.63267
Value Function Update Magnitude: 0.81041

Collected Steps per Second: 22,283.00531
Overall Steps per Second: 10,593.33076

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.47609
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.71995

Cumulative Model Updates: 75,842
Cumulative Timesteps: 632,453,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.28374
Policy Entropy: 3.70139
Value Function Loss: 0.06059

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.62254
Value Function Update Magnitude: 0.81047

Collected Steps per Second: 22,933.80817
Overall Steps per Second: 10,822.91943

Timestep Collection Time: 2.18115
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.62186

Cumulative Model Updates: 75,848
Cumulative Timesteps: 632,503,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 632503900...
Checkpoint 632503900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,985.42940
Policy Entropy: 3.71584
Value Function Loss: 0.06312

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.63947
Value Function Update Magnitude: 0.80669

Collected Steps per Second: 22,803.96674
Overall Steps per Second: 10,723.11391

Timestep Collection Time: 2.19286
Timestep Consumption Time: 2.47052
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.66338

Cumulative Model Updates: 75,854
Cumulative Timesteps: 632,553,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,358.09205
Policy Entropy: 3.70934
Value Function Loss: 0.06800

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.59239
Value Function Update Magnitude: 0.80553

Collected Steps per Second: 22,787.94216
Overall Steps per Second: 10,810.92464

Timestep Collection Time: 2.19423
Timestep Consumption Time: 2.43091
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.62514

Cumulative Model Updates: 75,860
Cumulative Timesteps: 632,603,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 632603908...
Checkpoint 632603908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,287.45191
Policy Entropy: 3.70824
Value Function Loss: 0.06708

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.83146

Collected Steps per Second: 22,798.10533
Overall Steps per Second: 10,725.18314

Timestep Collection Time: 2.19413
Timestep Consumption Time: 2.46985
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.66398

Cumulative Model Updates: 75,866
Cumulative Timesteps: 632,653,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,552.12967
Policy Entropy: 3.69273
Value Function Loss: 0.06591

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07407
Policy Update Magnitude: 0.62991
Value Function Update Magnitude: 0.80985

Collected Steps per Second: 22,917.69811
Overall Steps per Second: 10,835.66528

Timestep Collection Time: 2.18364
Timestep Consumption Time: 2.43481
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.61845

Cumulative Model Updates: 75,872
Cumulative Timesteps: 632,703,974

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 632703974...
Checkpoint 632703974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,727.14722
Policy Entropy: 3.70772
Value Function Loss: 0.06433

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07334
Policy Update Magnitude: 0.68804
Value Function Update Magnitude: 0.81487

Collected Steps per Second: 22,817.50488
Overall Steps per Second: 10,720.63899

Timestep Collection Time: 2.19270
Timestep Consumption Time: 2.47418
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.66689

Cumulative Model Updates: 75,878
Cumulative Timesteps: 632,754,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,264.96837
Policy Entropy: 3.70645
Value Function Loss: 0.06685

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.65052
Value Function Update Magnitude: 0.84988

Collected Steps per Second: 22,392.82670
Overall Steps per Second: 10,540.76751

Timestep Collection Time: 2.23286
Timestep Consumption Time: 2.51063
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74349

Cumulative Model Updates: 75,884
Cumulative Timesteps: 632,804,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 632804006...
Checkpoint 632804006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,942.81101
Policy Entropy: 3.71376
Value Function Loss: 0.06905

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.63511
Value Function Update Magnitude: 0.87094

Collected Steps per Second: 22,571.82486
Overall Steps per Second: 10,608.90638

Timestep Collection Time: 2.21542
Timestep Consumption Time: 2.49817
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.71359

Cumulative Model Updates: 75,890
Cumulative Timesteps: 632,854,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,462.00676
Policy Entropy: 3.70437
Value Function Loss: 0.06892

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07152
Policy Update Magnitude: 0.65683
Value Function Update Magnitude: 0.87177

Collected Steps per Second: 22,893.64525
Overall Steps per Second: 10,801.49237

Timestep Collection Time: 2.18462
Timestep Consumption Time: 2.44566
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.63029

Cumulative Model Updates: 75,896
Cumulative Timesteps: 632,904,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 632904026...
Checkpoint 632904026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,481.01055
Policy Entropy: 3.69740
Value Function Loss: 0.06967

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07212
Policy Update Magnitude: 0.74291
Value Function Update Magnitude: 0.79117

Collected Steps per Second: 22,873.16451
Overall Steps per Second: 10,679.19104

Timestep Collection Time: 2.18675
Timestep Consumption Time: 2.49693
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.68369

Cumulative Model Updates: 75,902
Cumulative Timesteps: 632,954,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,582.23369
Policy Entropy: 3.69395
Value Function Loss: 0.06912

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07708
Policy Update Magnitude: 0.73626
Value Function Update Magnitude: 0.68034

Collected Steps per Second: 22,587.19694
Overall Steps per Second: 10,649.83431

Timestep Collection Time: 2.21417
Timestep Consumption Time: 2.48186
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69604

Cumulative Model Updates: 75,908
Cumulative Timesteps: 633,004,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 633004056...
Checkpoint 633004056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,696.07858
Policy Entropy: 3.67777
Value Function Loss: 0.07097

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.69269
Value Function Update Magnitude: 0.67015

Collected Steps per Second: 22,943.09541
Overall Steps per Second: 10,861.69419

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.42539
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.60591

Cumulative Model Updates: 75,914
Cumulative Timesteps: 633,054,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,292.16663
Policy Entropy: 3.68805
Value Function Loss: 0.06956

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.63826
Value Function Update Magnitude: 0.71262

Collected Steps per Second: 22,811.56090
Overall Steps per Second: 10,686.41006

Timestep Collection Time: 2.19345
Timestep Consumption Time: 2.48876
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.68221

Cumulative Model Updates: 75,920
Cumulative Timesteps: 633,104,120

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 633104120...
Checkpoint 633104120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,456.74649
Policy Entropy: 3.68934
Value Function Loss: 0.07077

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.54782
Value Function Update Magnitude: 0.74718

Collected Steps per Second: 22,872.58957
Overall Steps per Second: 10,858.71076

Timestep Collection Time: 2.18602
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60460

Cumulative Model Updates: 75,926
Cumulative Timesteps: 633,154,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,730.06709
Policy Entropy: 3.68779
Value Function Loss: 0.07009

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.53561
Value Function Update Magnitude: 0.81649

Collected Steps per Second: 22,787.48360
Overall Steps per Second: 10,697.12933

Timestep Collection Time: 2.19550
Timestep Consumption Time: 2.48145
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.67696

Cumulative Model Updates: 75,932
Cumulative Timesteps: 633,204,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 633204150...
Checkpoint 633204150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,375.14096
Policy Entropy: 3.69869
Value Function Loss: 0.06798

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.50298
Value Function Update Magnitude: 0.85468

Collected Steps per Second: 22,607.24138
Overall Steps per Second: 10,830.57233

Timestep Collection Time: 2.21310
Timestep Consumption Time: 2.40642
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.61952

Cumulative Model Updates: 75,938
Cumulative Timesteps: 633,254,182

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,675.61464
Policy Entropy: 3.68096
Value Function Loss: 0.06857

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.49676
Value Function Update Magnitude: 0.85620

Collected Steps per Second: 23,204.12791
Overall Steps per Second: 10,895.78427

Timestep Collection Time: 2.15600
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.59150

Cumulative Model Updates: 75,944
Cumulative Timesteps: 633,304,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 633304210...
Checkpoint 633304210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,747.06450
Policy Entropy: 3.68719
Value Function Loss: 0.06715

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.48220
Value Function Update Magnitude: 0.84324

Collected Steps per Second: 22,525.43737
Overall Steps per Second: 10,770.87067

Timestep Collection Time: 2.22069
Timestep Consumption Time: 2.42350
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.64419

Cumulative Model Updates: 75,950
Cumulative Timesteps: 633,354,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,529.60280
Policy Entropy: 3.67412
Value Function Loss: 0.06774

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.48521
Value Function Update Magnitude: 0.83197

Collected Steps per Second: 22,813.93549
Overall Steps per Second: 10,809.16393

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.43523
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.62792

Cumulative Model Updates: 75,956
Cumulative Timesteps: 633,404,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 633404256...
Checkpoint 633404256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,589.06200
Policy Entropy: 3.67230
Value Function Loss: 0.06766

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.46419
Value Function Update Magnitude: 0.83764

Collected Steps per Second: 22,676.16784
Overall Steps per Second: 10,679.97218

Timestep Collection Time: 2.20505
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.68185

Cumulative Model Updates: 75,962
Cumulative Timesteps: 633,454,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,325.16028
Policy Entropy: 3.66372
Value Function Loss: 0.07090

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.48106
Value Function Update Magnitude: 0.81988

Collected Steps per Second: 22,966.77690
Overall Steps per Second: 10,822.71099

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62269

Cumulative Model Updates: 75,968
Cumulative Timesteps: 633,504,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 633504288...
Checkpoint 633504288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,937.44982
Policy Entropy: 3.68343
Value Function Loss: 0.07186

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08057
Policy Update Magnitude: 0.53505
Value Function Update Magnitude: 0.72821

Collected Steps per Second: 22,572.43234
Overall Steps per Second: 10,714.56381

Timestep Collection Time: 2.21589
Timestep Consumption Time: 2.45234
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.66823

Cumulative Model Updates: 75,974
Cumulative Timesteps: 633,554,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,775.32761
Policy Entropy: 3.68281
Value Function Loss: 0.07280

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.56342
Value Function Update Magnitude: 0.70697

Collected Steps per Second: 22,742.11015
Overall Steps per Second: 10,683.09919

Timestep Collection Time: 2.19944
Timestep Consumption Time: 2.48272
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.68216

Cumulative Model Updates: 75,980
Cumulative Timesteps: 633,604,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 633604326...
Checkpoint 633604326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,765.73812
Policy Entropy: 3.68762
Value Function Loss: 0.07141

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.52215
Value Function Update Magnitude: 0.70601

Collected Steps per Second: 22,792.35614
Overall Steps per Second: 10,818.60489

Timestep Collection Time: 2.19477
Timestep Consumption Time: 2.42912
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.62389

Cumulative Model Updates: 75,986
Cumulative Timesteps: 633,654,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,602.47660
Policy Entropy: 3.67230
Value Function Loss: 0.07168

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.51337
Value Function Update Magnitude: 0.72459

Collected Steps per Second: 23,152.96236
Overall Steps per Second: 10,899.14861

Timestep Collection Time: 2.16085
Timestep Consumption Time: 2.42942
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59027

Cumulative Model Updates: 75,992
Cumulative Timesteps: 633,704,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 633704380...
Checkpoint 633704380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,492.22042
Policy Entropy: 3.67452
Value Function Loss: 0.07049

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05453
Policy Update Magnitude: 0.62945
Value Function Update Magnitude: 0.68181

Collected Steps per Second: 22,455.28036
Overall Steps per Second: 10,758.96986

Timestep Collection Time: 2.22736
Timestep Consumption Time: 2.42141
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.64877

Cumulative Model Updates: 75,998
Cumulative Timesteps: 633,754,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,154.60298
Policy Entropy: 3.66701
Value Function Loss: 0.07191

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06753
Policy Update Magnitude: 0.67100
Value Function Update Magnitude: 0.64829

Collected Steps per Second: 23,063.95600
Overall Steps per Second: 10,909.47022

Timestep Collection Time: 2.16893
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.58537

Cumulative Model Updates: 76,004
Cumulative Timesteps: 633,804,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 633804420...
Checkpoint 633804420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,283.35424
Policy Entropy: 3.67245
Value Function Loss: 0.07389

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.72540
Value Function Update Magnitude: 0.65302

Collected Steps per Second: 22,891.40335
Overall Steps per Second: 10,796.12742

Timestep Collection Time: 2.18527
Timestep Consumption Time: 2.44824
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.63351

Cumulative Model Updates: 76,010
Cumulative Timesteps: 633,854,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,868.19381
Policy Entropy: 3.66268
Value Function Loss: 0.07344

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.68532
Value Function Update Magnitude: 0.65789

Collected Steps per Second: 23,002.06844
Overall Steps per Second: 10,726.43833

Timestep Collection Time: 2.17415
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.66231

Cumulative Model Updates: 76,016
Cumulative Timesteps: 633,904,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 633904454...
Checkpoint 633904454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,750.17718
Policy Entropy: 3.67244
Value Function Loss: 0.07512

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.65091

Collected Steps per Second: 22,729.30238
Overall Steps per Second: 10,612.07023

Timestep Collection Time: 2.20033
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.71275

Cumulative Model Updates: 76,022
Cumulative Timesteps: 633,954,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,936.83025
Policy Entropy: 3.67049
Value Function Loss: 0.07579

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.59965
Value Function Update Magnitude: 0.66028

Collected Steps per Second: 22,749.56163
Overall Steps per Second: 10,666.51700

Timestep Collection Time: 2.19881
Timestep Consumption Time: 2.49082
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.68963

Cumulative Model Updates: 76,028
Cumulative Timesteps: 634,004,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 634004488...
Checkpoint 634004488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,536.72477
Policy Entropy: 3.68295
Value Function Loss: 0.07463

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.68487

Collected Steps per Second: 22,425.88038
Overall Steps per Second: 10,590.45850

Timestep Collection Time: 2.23046
Timestep Consumption Time: 2.49266
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.72312

Cumulative Model Updates: 76,034
Cumulative Timesteps: 634,054,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,838.80866
Policy Entropy: 3.67501
Value Function Loss: 0.07167

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.55531
Value Function Update Magnitude: 0.72326

Collected Steps per Second: 23,005.01410
Overall Steps per Second: 10,757.65992

Timestep Collection Time: 2.17431
Timestep Consumption Time: 2.47540
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.64971

Cumulative Model Updates: 76,040
Cumulative Timesteps: 634,104,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 634104528...
Checkpoint 634104528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,407.53280
Policy Entropy: 3.69068
Value Function Loss: 0.07106

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.57929
Value Function Update Magnitude: 0.75953

Collected Steps per Second: 22,759.42797
Overall Steps per Second: 10,611.39243

Timestep Collection Time: 2.19751
Timestep Consumption Time: 2.51573
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.71324

Cumulative Model Updates: 76,046
Cumulative Timesteps: 634,154,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,082.98322
Policy Entropy: 3.69426
Value Function Loss: 0.06886

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.64036
Value Function Update Magnitude: 0.82377

Collected Steps per Second: 21,912.10778
Overall Steps per Second: 10,481.80913

Timestep Collection Time: 2.28312
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.77284

Cumulative Model Updates: 76,052
Cumulative Timesteps: 634,204,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 634204570...
Checkpoint 634204570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,286.50447
Policy Entropy: 3.70137
Value Function Loss: 0.06979

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.74373
Value Function Update Magnitude: 0.87270

Collected Steps per Second: 22,777.58814
Overall Steps per Second: 10,650.30903

Timestep Collection Time: 2.19628
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.69714

Cumulative Model Updates: 76,058
Cumulative Timesteps: 634,254,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,444.95509
Policy Entropy: 3.69306
Value Function Loss: 0.06985

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.76355
Value Function Update Magnitude: 0.86261

Collected Steps per Second: 22,981.18329
Overall Steps per Second: 10,828.17736

Timestep Collection Time: 2.17595
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61814

Cumulative Model Updates: 76,064
Cumulative Timesteps: 634,304,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 634304602...
Checkpoint 634304602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,654.82562
Policy Entropy: 3.69795
Value Function Loss: 0.06797

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.72007
Value Function Update Magnitude: 0.86604

Collected Steps per Second: 22,707.83201
Overall Steps per Second: 10,721.80097

Timestep Collection Time: 2.20250
Timestep Consumption Time: 2.46220
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.66470

Cumulative Model Updates: 76,070
Cumulative Timesteps: 634,354,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,420.54205
Policy Entropy: 3.69316
Value Function Loss: 0.06611

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.61258
Value Function Update Magnitude: 0.88393

Collected Steps per Second: 22,698.02358
Overall Steps per Second: 10,882.81306

Timestep Collection Time: 2.20372
Timestep Consumption Time: 2.39252
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.59624

Cumulative Model Updates: 76,076
Cumulative Timesteps: 634,404,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 634404636...
Checkpoint 634404636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,985.02523
Policy Entropy: 3.69181
Value Function Loss: 0.06634

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.59394
Value Function Update Magnitude: 0.89433

Collected Steps per Second: 22,766.15054
Overall Steps per Second: 10,679.41599

Timestep Collection Time: 2.19756
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.68471

Cumulative Model Updates: 76,082
Cumulative Timesteps: 634,454,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,811.45526
Policy Entropy: 3.68532
Value Function Loss: 0.07245

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.84162

Collected Steps per Second: 22,760.72394
Overall Steps per Second: 10,791.27115

Timestep Collection Time: 2.19791
Timestep Consumption Time: 2.43787
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.63578

Cumulative Model Updates: 76,088
Cumulative Timesteps: 634,504,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 634504692...
Checkpoint 634504692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,842.00819
Policy Entropy: 3.68150
Value Function Loss: 0.07231

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10187
Policy Update Magnitude: 0.61995
Value Function Update Magnitude: 0.71862

Collected Steps per Second: 22,675.85108
Overall Steps per Second: 10,721.36188

Timestep Collection Time: 2.20552
Timestep Consumption Time: 2.45919
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.66471

Cumulative Model Updates: 76,094
Cumulative Timesteps: 634,554,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,865.75658
Policy Entropy: 3.70610
Value Function Loss: 0.07543

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.57722
Value Function Update Magnitude: 0.64518

Collected Steps per Second: 22,908.59990
Overall Steps per Second: 10,896.49519

Timestep Collection Time: 2.18355
Timestep Consumption Time: 2.40710
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.59065

Cumulative Model Updates: 76,100
Cumulative Timesteps: 634,604,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 634604726...
Checkpoint 634604726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,999.41227
Policy Entropy: 3.71663
Value Function Loss: 0.07250

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.52659
Value Function Update Magnitude: 0.67225

Collected Steps per Second: 22,668.63215
Overall Steps per Second: 10,675.03217

Timestep Collection Time: 2.20763
Timestep Consumption Time: 2.48032
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.68795

Cumulative Model Updates: 76,106
Cumulative Timesteps: 634,654,770

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.97017
Policy Entropy: 3.71181
Value Function Loss: 0.07187

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.58110
Value Function Update Magnitude: 0.77776

Collected Steps per Second: 22,866.66013
Overall Steps per Second: 10,805.85151

Timestep Collection Time: 2.18790
Timestep Consumption Time: 2.44200
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.62990

Cumulative Model Updates: 76,112
Cumulative Timesteps: 634,704,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 634704800...
Checkpoint 634704800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,423.67595
Policy Entropy: 3.69808
Value Function Loss: 0.06899

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.86226

Collected Steps per Second: 22,643.92442
Overall Steps per Second: 10,712.07504

Timestep Collection Time: 2.20916
Timestep Consumption Time: 2.46071
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.66987

Cumulative Model Updates: 76,118
Cumulative Timesteps: 634,754,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,985.88193
Policy Entropy: 3.70382
Value Function Loss: 0.06669

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.66643
Value Function Update Magnitude: 0.88240

Collected Steps per Second: 22,865.51802
Overall Steps per Second: 10,736.31280

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.47059
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.65746

Cumulative Model Updates: 76,124
Cumulative Timesteps: 634,804,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 634804828...
Checkpoint 634804828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,886.80359
Policy Entropy: 3.70882
Value Function Loss: 0.06333

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.88450

Collected Steps per Second: 22,590.40701
Overall Steps per Second: 10,787.90403

Timestep Collection Time: 2.21475
Timestep Consumption Time: 2.42304
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.63779

Cumulative Model Updates: 76,130
Cumulative Timesteps: 634,854,860

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,924.77969
Policy Entropy: 3.72833
Value Function Loss: 0.06238

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.58356
Value Function Update Magnitude: 0.86145

Collected Steps per Second: 22,758.24134
Overall Steps per Second: 10,666.64574

Timestep Collection Time: 2.19797
Timestep Consumption Time: 2.49160
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.68957

Cumulative Model Updates: 76,136
Cumulative Timesteps: 634,904,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 634904882...
Checkpoint 634904882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,053.77782
Policy Entropy: 3.73081
Value Function Loss: 0.06141

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.62430
Value Function Update Magnitude: 0.83389

Collected Steps per Second: 22,494.77573
Overall Steps per Second: 10,629.59658

Timestep Collection Time: 2.22443
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.70742

Cumulative Model Updates: 76,142
Cumulative Timesteps: 634,954,920

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,053.83150
Policy Entropy: 3.74212
Value Function Loss: 0.06162

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.57095
Value Function Update Magnitude: 0.81951

Collected Steps per Second: 22,900.14218
Overall Steps per Second: 10,833.70292

Timestep Collection Time: 2.18374
Timestep Consumption Time: 2.43222
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.61597

Cumulative Model Updates: 76,148
Cumulative Timesteps: 635,004,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 635004928...
Checkpoint 635004928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,000.71032
Policy Entropy: 3.74397
Value Function Loss: 0.06293

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.61674
Value Function Update Magnitude: 0.73078

Collected Steps per Second: 22,789.30439
Overall Steps per Second: 10,699.29697

Timestep Collection Time: 2.19419
Timestep Consumption Time: 2.47939
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.67358

Cumulative Model Updates: 76,154
Cumulative Timesteps: 635,054,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,846.11448
Policy Entropy: 3.74804
Value Function Loss: 0.06543

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.62829
Value Function Update Magnitude: 0.73276

Collected Steps per Second: 22,856.71054
Overall Steps per Second: 10,831.51973

Timestep Collection Time: 2.18885
Timestep Consumption Time: 2.43007
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.61893

Cumulative Model Updates: 76,160
Cumulative Timesteps: 635,104,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 635104962...
Checkpoint 635104962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,292.07816
Policy Entropy: 3.72143
Value Function Loss: 0.06850

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.70318
Value Function Update Magnitude: 0.73147

Collected Steps per Second: 22,653.20450
Overall Steps per Second: 10,642.58749

Timestep Collection Time: 2.20825
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.70036

Cumulative Model Updates: 76,166
Cumulative Timesteps: 635,154,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,207.74062
Policy Entropy: 3.72614
Value Function Loss: 0.06511

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.71194
Value Function Update Magnitude: 0.71096

Collected Steps per Second: 22,880.64943
Overall Steps per Second: 10,846.54241

Timestep Collection Time: 2.18648
Timestep Consumption Time: 2.42587
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.61235

Cumulative Model Updates: 76,172
Cumulative Timesteps: 635,205,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 635205014...
Checkpoint 635205014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,130.98748
Policy Entropy: 3.71445
Value Function Loss: 0.06532

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.59384
Value Function Update Magnitude: 0.67102

Collected Steps per Second: 22,459.16846
Overall Steps per Second: 10,674.80802

Timestep Collection Time: 2.22644
Timestep Consumption Time: 2.45786
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.68430

Cumulative Model Updates: 76,178
Cumulative Timesteps: 635,255,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,930.70123
Policy Entropy: 3.71794
Value Function Loss: 0.06324

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.61200

Collected Steps per Second: 22,661.84903
Overall Steps per Second: 10,793.19707

Timestep Collection Time: 2.20750
Timestep Consumption Time: 2.42746
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.63496

Cumulative Model Updates: 76,184
Cumulative Timesteps: 635,305,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 635305044...
Checkpoint 635305044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.27721
Policy Entropy: 3.71064
Value Function Loss: 0.06479

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.65031

Collected Steps per Second: 22,103.10969
Overall Steps per Second: 10,678.15029

Timestep Collection Time: 2.26294
Timestep Consumption Time: 2.42121
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.68414

Cumulative Model Updates: 76,190
Cumulative Timesteps: 635,355,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,505.71736
Policy Entropy: 3.71360
Value Function Loss: 0.06260

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.54143
Value Function Update Magnitude: 0.65609

Collected Steps per Second: 22,709.65338
Overall Steps per Second: 10,657.52339

Timestep Collection Time: 2.20303
Timestep Consumption Time: 2.49131
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.69434

Cumulative Model Updates: 76,196
Cumulative Timesteps: 635,405,092

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 635405092...
Checkpoint 635405092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,634.89669
Policy Entropy: 3.72372
Value Function Loss: 0.06014

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.57675
Value Function Update Magnitude: 0.74349

Collected Steps per Second: 22,537.49861
Overall Steps per Second: 10,677.94692

Timestep Collection Time: 2.21870
Timestep Consumption Time: 2.46422
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.68292

Cumulative Model Updates: 76,202
Cumulative Timesteps: 635,455,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,352.82879
Policy Entropy: 3.73414
Value Function Loss: 0.05917

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.77927

Collected Steps per Second: 23,303.53155
Overall Steps per Second: 10,780.10349

Timestep Collection Time: 2.14688
Timestep Consumption Time: 2.49407
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.64096

Cumulative Model Updates: 76,208
Cumulative Timesteps: 635,505,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 635505126...
Checkpoint 635505126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,550.36330
Policy Entropy: 3.73387
Value Function Loss: 0.05945

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.52492
Value Function Update Magnitude: 0.78166

Collected Steps per Second: 22,002.07152
Overall Steps per Second: 10,672.50089

Timestep Collection Time: 2.27379
Timestep Consumption Time: 2.41378
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.68756

Cumulative Model Updates: 76,214
Cumulative Timesteps: 635,555,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,167.01247
Policy Entropy: 3.72806
Value Function Loss: 0.06129

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.58169
Value Function Update Magnitude: 0.76618

Collected Steps per Second: 22,178.70854
Overall Steps per Second: 10,862.18560

Timestep Collection Time: 2.25559
Timestep Consumption Time: 2.34993
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.60552

Cumulative Model Updates: 76,220
Cumulative Timesteps: 635,605,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 635605180...
Checkpoint 635605180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,906.96247
Policy Entropy: 3.72093
Value Function Loss: 0.06200

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.59410
Value Function Update Magnitude: 0.76701

Collected Steps per Second: 22,054.94410
Overall Steps per Second: 10,659.56393

Timestep Collection Time: 2.26743
Timestep Consumption Time: 2.42395
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.69137

Cumulative Model Updates: 76,226
Cumulative Timesteps: 635,655,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,396.41285
Policy Entropy: 3.72366
Value Function Loss: 0.06791

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.57905
Value Function Update Magnitude: 0.70937

Collected Steps per Second: 22,452.35419
Overall Steps per Second: 10,830.73791

Timestep Collection Time: 2.22721
Timestep Consumption Time: 2.38984
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.61704

Cumulative Model Updates: 76,232
Cumulative Timesteps: 635,705,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 635705194...
Checkpoint 635705194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,877.57520
Policy Entropy: 3.71865
Value Function Loss: 0.07132

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06188
Policy Update Magnitude: 0.69485
Value Function Update Magnitude: 0.61298

Collected Steps per Second: 22,083.58335
Overall Steps per Second: 10,663.14339

Timestep Collection Time: 2.26467
Timestep Consumption Time: 2.42551
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.69017

Cumulative Model Updates: 76,238
Cumulative Timesteps: 635,755,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,863.30298
Policy Entropy: 3.71554
Value Function Loss: 0.07088

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.75768
Value Function Update Magnitude: 0.53828

Collected Steps per Second: 22,425.05881
Overall Steps per Second: 10,652.26688

Timestep Collection Time: 2.23001
Timestep Consumption Time: 2.46458
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.69459

Cumulative Model Updates: 76,244
Cumulative Timesteps: 635,805,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 635805214...
Checkpoint 635805214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,910.30496
Policy Entropy: 3.71800
Value Function Loss: 0.06812

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07173
Policy Update Magnitude: 0.74950
Value Function Update Magnitude: 0.56937

Collected Steps per Second: 22,597.60622
Overall Steps per Second: 10,879.47781

Timestep Collection Time: 2.21369
Timestep Consumption Time: 2.38433
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.59801

Cumulative Model Updates: 76,250
Cumulative Timesteps: 635,855,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,855.58586
Policy Entropy: 3.71613
Value Function Loss: 0.06786

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.65561
Value Function Update Magnitude: 0.71999

Collected Steps per Second: 22,991.33663
Overall Steps per Second: 10,928.86002

Timestep Collection Time: 2.17552
Timestep Consumption Time: 2.40117
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.57669

Cumulative Model Updates: 76,256
Cumulative Timesteps: 635,905,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 635905256...
Checkpoint 635905256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,604.28815
Policy Entropy: 3.71962
Value Function Loss: 0.06716

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.15038
Policy Update Magnitude: 0.56853
Value Function Update Magnitude: 0.79278

Collected Steps per Second: 22,819.31230
Overall Steps per Second: 10,757.56765

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.45785
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.64994

Cumulative Model Updates: 76,262
Cumulative Timesteps: 635,955,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,157.35114
Policy Entropy: 3.73521
Value Function Loss: 0.06219

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.83391

Collected Steps per Second: 22,501.98684
Overall Steps per Second: 10,752.59156

Timestep Collection Time: 2.22300
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.65209

Cumulative Model Updates: 76,268
Cumulative Timesteps: 636,005,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 636005300...
Checkpoint 636005300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,990.78958
Policy Entropy: 3.74388
Value Function Loss: 0.05875

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.61442
Value Function Update Magnitude: 0.85145

Collected Steps per Second: 22,733.40765
Overall Steps per Second: 10,721.06518

Timestep Collection Time: 2.19941
Timestep Consumption Time: 2.46431
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.66372

Cumulative Model Updates: 76,274
Cumulative Timesteps: 636,055,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.85910
Policy Entropy: 3.75243
Value Function Loss: 0.05407

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.71805
Value Function Update Magnitude: 0.82747

Collected Steps per Second: 22,742.92005
Overall Steps per Second: 10,789.30197

Timestep Collection Time: 2.19875
Timestep Consumption Time: 2.43603
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.63478

Cumulative Model Updates: 76,280
Cumulative Timesteps: 636,105,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 636105306...
Checkpoint 636105306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,651.84558
Policy Entropy: 3.76461
Value Function Loss: 0.05608

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.76977
Value Function Update Magnitude: 0.82211

Collected Steps per Second: 22,573.23402
Overall Steps per Second: 10,652.85563

Timestep Collection Time: 2.21528
Timestep Consumption Time: 2.47886
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.69414

Cumulative Model Updates: 76,286
Cumulative Timesteps: 636,155,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,985.90121
Policy Entropy: 3.77639
Value Function Loss: 0.05592

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.77649
Value Function Update Magnitude: 0.85074

Collected Steps per Second: 22,277.28450
Overall Steps per Second: 10,525.18595

Timestep Collection Time: 2.24534
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.75241

Cumulative Model Updates: 76,292
Cumulative Timesteps: 636,205,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 636205332...
Checkpoint 636205332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,745.02740
Policy Entropy: 3.77617
Value Function Loss: 0.05721

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.70186
Value Function Update Magnitude: 0.86628

Collected Steps per Second: 22,453.59724
Overall Steps per Second: 10,575.87865

Timestep Collection Time: 2.22708
Timestep Consumption Time: 2.50122
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.72831

Cumulative Model Updates: 76,298
Cumulative Timesteps: 636,255,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,241.95655
Policy Entropy: 3.77838
Value Function Loss: 0.05542

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.61007
Value Function Update Magnitude: 0.86009

Collected Steps per Second: 23,206.78678
Overall Steps per Second: 10,870.97133

Timestep Collection Time: 2.15566
Timestep Consumption Time: 2.44613
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.60180

Cumulative Model Updates: 76,304
Cumulative Timesteps: 636,305,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 636305364...
Checkpoint 636305364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,842.35404
Policy Entropy: 3.76532
Value Function Loss: 0.05513

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.59589
Value Function Update Magnitude: 0.85091

Collected Steps per Second: 22,726.25789
Overall Steps per Second: 10,688.25870

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.47942
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.68084

Cumulative Model Updates: 76,310
Cumulative Timesteps: 636,355,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,051.97588
Policy Entropy: 3.76594
Value Function Loss: 0.05417

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.63718
Value Function Update Magnitude: 0.83055

Collected Steps per Second: 22,875.92609
Overall Steps per Second: 10,832.40811

Timestep Collection Time: 2.18675
Timestep Consumption Time: 2.43124
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.61799

Cumulative Model Updates: 76,316
Cumulative Timesteps: 636,405,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 636405418...
Checkpoint 636405418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,897.11058
Policy Entropy: 3.75152
Value Function Loss: 0.05625

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.62286
Value Function Update Magnitude: 0.83234

Collected Steps per Second: 22,684.56511
Overall Steps per Second: 10,730.21461

Timestep Collection Time: 2.20538
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.66235

Cumulative Model Updates: 76,322
Cumulative Timesteps: 636,455,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,609.98281
Policy Entropy: 3.75331
Value Function Loss: 0.05677

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.56689
Value Function Update Magnitude: 0.83647

Collected Steps per Second: 22,735.64950
Overall Steps per Second: 10,617.02933

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.51093
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.71073

Cumulative Model Updates: 76,328
Cumulative Timesteps: 636,505,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 636505460...
Checkpoint 636505460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,430.32031
Policy Entropy: 3.74613
Value Function Loss: 0.05804

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.85184

Collected Steps per Second: 22,767.30808
Overall Steps per Second: 10,803.66288

Timestep Collection Time: 2.19692
Timestep Consumption Time: 2.43280
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62973

Cumulative Model Updates: 76,334
Cumulative Timesteps: 636,555,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.68160
Policy Entropy: 3.74461
Value Function Loss: 0.05561

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.57407
Value Function Update Magnitude: 0.86576

Collected Steps per Second: 22,389.14076
Overall Steps per Second: 10,580.14542

Timestep Collection Time: 2.23385
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.72716

Cumulative Model Updates: 76,340
Cumulative Timesteps: 636,605,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 636605492...
Checkpoint 636605492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,134.12675
Policy Entropy: 3.72957
Value Function Loss: 0.05652

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08660
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.86896

Collected Steps per Second: 22,564.26271
Overall Steps per Second: 10,656.05650

Timestep Collection Time: 2.21598
Timestep Consumption Time: 2.47637
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.69235

Cumulative Model Updates: 76,346
Cumulative Timesteps: 636,655,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,274.81250
Policy Entropy: 3.72168
Value Function Loss: 0.05713

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.55366
Value Function Update Magnitude: 0.86002

Collected Steps per Second: 22,502.80385
Overall Steps per Second: 10,611.20813

Timestep Collection Time: 2.22328
Timestep Consumption Time: 2.49155
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.71483

Cumulative Model Updates: 76,352
Cumulative Timesteps: 636,705,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 636705524...
Checkpoint 636705524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,834.09227
Policy Entropy: 3.71651
Value Function Loss: 0.05865

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.85592

Collected Steps per Second: 22,593.40584
Overall Steps per Second: 10,667.13217

Timestep Collection Time: 2.21348
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.68823

Cumulative Model Updates: 76,358
Cumulative Timesteps: 636,755,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,972.80030
Policy Entropy: 3.72388
Value Function Loss: 0.05931

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07094
Policy Update Magnitude: 0.62931
Value Function Update Magnitude: 0.87956

Collected Steps per Second: 22,772.76157
Overall Steps per Second: 10,701.21921

Timestep Collection Time: 2.19569
Timestep Consumption Time: 2.47686
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.67255

Cumulative Model Updates: 76,364
Cumulative Timesteps: 636,805,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 636805536...
Checkpoint 636805536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,367.24270
Policy Entropy: 3.73145
Value Function Loss: 0.05792

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.62352
Value Function Update Magnitude: 0.83919

Collected Steps per Second: 22,863.37035
Overall Steps per Second: 10,666.59818

Timestep Collection Time: 2.18717
Timestep Consumption Time: 2.50093
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.68809

Cumulative Model Updates: 76,370
Cumulative Timesteps: 636,855,542

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,309.55171
Policy Entropy: 3.73827
Value Function Loss: 0.05772

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.59385
Value Function Update Magnitude: 0.82249

Collected Steps per Second: 23,230.71907
Overall Steps per Second: 10,907.08480

Timestep Collection Time: 2.15267
Timestep Consumption Time: 2.43224
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.58491

Cumulative Model Updates: 76,376
Cumulative Timesteps: 636,905,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 636905550...
Checkpoint 636905550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.88120
Policy Entropy: 3.73873
Value Function Loss: 0.05699

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.58688
Value Function Update Magnitude: 0.83389

Collected Steps per Second: 22,377.79607
Overall Steps per Second: 10,574.35490

Timestep Collection Time: 2.23525
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.73031

Cumulative Model Updates: 76,382
Cumulative Timesteps: 636,955,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,654.06379
Policy Entropy: 3.72867
Value Function Loss: 0.05624

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.57622
Value Function Update Magnitude: 0.84082

Collected Steps per Second: 22,482.55421
Overall Steps per Second: 10,597.97977

Timestep Collection Time: 2.22395
Timestep Consumption Time: 2.49393
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.71788

Cumulative Model Updates: 76,388
Cumulative Timesteps: 637,005,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 637005570...
Checkpoint 637005570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,887.50699
Policy Entropy: 3.73399
Value Function Loss: 0.05617

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.82042

Collected Steps per Second: 22,812.48311
Overall Steps per Second: 10,906.79120

Timestep Collection Time: 2.19283
Timestep Consumption Time: 2.39367
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.58650

Cumulative Model Updates: 76,394
Cumulative Timesteps: 637,055,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.24960
Policy Entropy: 3.72494
Value Function Loss: 0.05534

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.52884
Value Function Update Magnitude: 0.80612

Collected Steps per Second: 22,899.93874
Overall Steps per Second: 10,669.54488

Timestep Collection Time: 2.18376
Timestep Consumption Time: 2.50322
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.68699

Cumulative Model Updates: 76,400
Cumulative Timesteps: 637,105,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 637105602...
Checkpoint 637105602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,725.51271
Policy Entropy: 3.72440
Value Function Loss: 0.05583

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07597
Policy Update Magnitude: 0.55581
Value Function Update Magnitude: 0.79246

Collected Steps per Second: 22,728.26919
Overall Steps per Second: 10,661.91879

Timestep Collection Time: 2.20096
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.69184

Cumulative Model Updates: 76,406
Cumulative Timesteps: 637,155,626

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,242.03768
Policy Entropy: 3.70531
Value Function Loss: 0.05961

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.51810
Value Function Update Magnitude: 0.78702

Collected Steps per Second: 22,954.65602
Overall Steps per Second: 10,701.06253

Timestep Collection Time: 2.17873
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.67355

Cumulative Model Updates: 76,412
Cumulative Timesteps: 637,205,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 637205638...
Checkpoint 637205638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.82447
Policy Entropy: 3.70375
Value Function Loss: 0.06256

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.46803
Value Function Update Magnitude: 0.77252

Collected Steps per Second: 22,431.37759
Overall Steps per Second: 10,647.64893

Timestep Collection Time: 2.22920
Timestep Consumption Time: 2.46705
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.69625

Cumulative Model Updates: 76,418
Cumulative Timesteps: 637,255,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,244.65879
Policy Entropy: 3.70485
Value Function Loss: 0.06367

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.51884
Value Function Update Magnitude: 0.75827

Collected Steps per Second: 22,941.24122
Overall Steps per Second: 10,836.21472

Timestep Collection Time: 2.18044
Timestep Consumption Time: 2.43575
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61619

Cumulative Model Updates: 76,424
Cumulative Timesteps: 637,305,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 637305664...
Checkpoint 637305664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,096.84728
Policy Entropy: 3.70836
Value Function Loss: 0.06386

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10060
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.67440

Collected Steps per Second: 22,666.96876
Overall Steps per Second: 10,713.62388

Timestep Collection Time: 2.20726
Timestep Consumption Time: 2.46268
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.66994

Cumulative Model Updates: 76,430
Cumulative Timesteps: 637,355,696

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,670.63689
Policy Entropy: 3.70620
Value Function Loss: 0.06402

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.57543
Value Function Update Magnitude: 0.65679

Collected Steps per Second: 22,975.03872
Overall Steps per Second: 10,851.65577

Timestep Collection Time: 2.17662
Timestep Consumption Time: 2.43171
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.60833

Cumulative Model Updates: 76,436
Cumulative Timesteps: 637,405,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 637405704...
Checkpoint 637405704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,846.56084
Policy Entropy: 3.70470
Value Function Loss: 0.06475

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.64641
Value Function Update Magnitude: 0.71166

Collected Steps per Second: 22,815.29501
Overall Steps per Second: 10,694.48739

Timestep Collection Time: 2.19221
Timestep Consumption Time: 2.48459
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.67680

Cumulative Model Updates: 76,442
Cumulative Timesteps: 637,455,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,666.42580
Policy Entropy: 3.69831
Value Function Loss: 0.06469

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09302
Policy Update Magnitude: 0.67599
Value Function Update Magnitude: 0.75505

Collected Steps per Second: 22,898.00436
Overall Steps per Second: 10,833.00897

Timestep Collection Time: 2.18438
Timestep Consumption Time: 2.43280
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.61718

Cumulative Model Updates: 76,448
Cumulative Timesteps: 637,505,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 637505738...
Checkpoint 637505738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,695.66670
Policy Entropy: 3.68957
Value Function Loss: 0.06629

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.61108
Value Function Update Magnitude: 0.76934

Collected Steps per Second: 22,642.64516
Overall Steps per Second: 10,705.90588

Timestep Collection Time: 2.20955
Timestep Consumption Time: 2.46357
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.67312

Cumulative Model Updates: 76,454
Cumulative Timesteps: 637,555,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,637.95991
Policy Entropy: 3.69274
Value Function Loss: 0.06618

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.49104
Value Function Update Magnitude: 0.81137

Collected Steps per Second: 22,737.97415
Overall Steps per Second: 10,828.07541

Timestep Collection Time: 2.19958
Timestep Consumption Time: 2.41934
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.61892

Cumulative Model Updates: 76,460
Cumulative Timesteps: 637,605,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 637605782...
Checkpoint 637605782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,520.24534
Policy Entropy: 3.67912
Value Function Loss: 0.06502

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.82821

Collected Steps per Second: 22,723.98849
Overall Steps per Second: 10,717.85250

Timestep Collection Time: 2.20129
Timestep Consumption Time: 2.46588
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.66717

Cumulative Model Updates: 76,466
Cumulative Timesteps: 637,655,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,883.51547
Policy Entropy: 3.68256
Value Function Loss: 0.06390

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.62728
Value Function Update Magnitude: 0.84168

Collected Steps per Second: 22,688.99879
Overall Steps per Second: 10,647.89443

Timestep Collection Time: 2.20468
Timestep Consumption Time: 2.49315
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.69783

Cumulative Model Updates: 76,472
Cumulative Timesteps: 637,705,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 637705826...
Checkpoint 637705826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,240.87248
Policy Entropy: 3.67120
Value Function Loss: 0.06590

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.62334
Value Function Update Magnitude: 0.88333

Collected Steps per Second: 22,969.58926
Overall Steps per Second: 10,847.85401

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.61253

Cumulative Model Updates: 76,478
Cumulative Timesteps: 637,755,862

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,766.75662
Policy Entropy: 3.68231
Value Function Loss: 0.06744

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.17042
Policy Update Magnitude: 0.53936
Value Function Update Magnitude: 0.91214

Collected Steps per Second: 22,603.50973
Overall Steps per Second: 10,635.73429

Timestep Collection Time: 2.21328
Timestep Consumption Time: 2.49048
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.70377

Cumulative Model Updates: 76,484
Cumulative Timesteps: 637,805,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 637805890...
Checkpoint 637805890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,317.00273
Policy Entropy: 3.68636
Value Function Loss: 0.07028

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.40384
Value Function Update Magnitude: 0.89925

Collected Steps per Second: 22,843.66502
Overall Steps per Second: 10,695.14029

Timestep Collection Time: 2.18975
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.67708

Cumulative Model Updates: 76,490
Cumulative Timesteps: 637,855,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,289.31636
Policy Entropy: 3.68489
Value Function Loss: 0.06838

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.37299
Value Function Update Magnitude: 0.88693

Collected Steps per Second: 22,878.20687
Overall Steps per Second: 10,718.92632

Timestep Collection Time: 2.18610
Timestep Consumption Time: 2.47985
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.66595

Cumulative Model Updates: 76,496
Cumulative Timesteps: 637,905,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 637905926...
Checkpoint 637905926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,250.25303
Policy Entropy: 3.68965
Value Function Loss: 0.06466

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.37905
Value Function Update Magnitude: 0.77613

Collected Steps per Second: 22,213.41041
Overall Steps per Second: 10,614.32119

Timestep Collection Time: 2.25152
Timestep Consumption Time: 2.46041
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.71194

Cumulative Model Updates: 76,502
Cumulative Timesteps: 637,955,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,856.03415
Policy Entropy: 3.70058
Value Function Loss: 0.06036

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.39952
Value Function Update Magnitude: 0.72130

Collected Steps per Second: 22,661.18269
Overall Steps per Second: 10,666.33928

Timestep Collection Time: 2.20677
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.68839

Cumulative Model Updates: 76,508
Cumulative Timesteps: 638,005,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 638005948...
Checkpoint 638005948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.39405
Policy Entropy: 3.70360
Value Function Loss: 0.05668

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.42300
Value Function Update Magnitude: 0.76401

Collected Steps per Second: 22,728.89984
Overall Steps per Second: 10,814.62185

Timestep Collection Time: 2.19993
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.62356

Cumulative Model Updates: 76,514
Cumulative Timesteps: 638,055,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,071.70977
Policy Entropy: 3.70249
Value Function Loss: 0.05448

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.39223
Value Function Update Magnitude: 0.75582

Collected Steps per Second: 22,438.27187
Overall Steps per Second: 10,456.05869

Timestep Collection Time: 2.22887
Timestep Consumption Time: 2.55419
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.78306

Cumulative Model Updates: 76,520
Cumulative Timesteps: 638,105,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 638105962...
Checkpoint 638105962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,963.06233
Policy Entropy: 3.69664
Value Function Loss: 0.05434

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.40208
Value Function Update Magnitude: 0.70921

Collected Steps per Second: 22,406.43660
Overall Steps per Second: 10,725.44116

Timestep Collection Time: 2.23248
Timestep Consumption Time: 2.43138
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.66386

Cumulative Model Updates: 76,526
Cumulative Timesteps: 638,155,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,202.92798
Policy Entropy: 3.70065
Value Function Loss: 0.05238

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.39970
Value Function Update Magnitude: 0.64209

Collected Steps per Second: 22,504.57626
Overall Steps per Second: 10,584.40604

Timestep Collection Time: 2.22310
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.72676

Cumulative Model Updates: 76,532
Cumulative Timesteps: 638,206,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 638206014...
Checkpoint 638206014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,203.25305
Policy Entropy: 3.72234
Value Function Loss: 0.04859

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.39882
Value Function Update Magnitude: 0.72304

Collected Steps per Second: 22,395.69739
Overall Steps per Second: 10,581.76382

Timestep Collection Time: 2.23284
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72568

Cumulative Model Updates: 76,538
Cumulative Timesteps: 638,256,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,022.81080
Policy Entropy: 3.72538
Value Function Loss: 0.04594

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.43446
Value Function Update Magnitude: 0.69388

Collected Steps per Second: 22,735.67459
Overall Steps per Second: 10,774.92251

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.44122
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.64040

Cumulative Model Updates: 76,544
Cumulative Timesteps: 638,306,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 638306020...
Checkpoint 638306020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,698.66433
Policy Entropy: 3.74261
Value Function Loss: 0.04414

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.44812
Value Function Update Magnitude: 0.65030

Collected Steps per Second: 22,525.83773
Overall Steps per Second: 10,652.60636

Timestep Collection Time: 2.22154
Timestep Consumption Time: 2.47609
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.69763

Cumulative Model Updates: 76,550
Cumulative Timesteps: 638,356,062

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,718.29004
Policy Entropy: 3.73917
Value Function Loss: 0.04299

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10808
Policy Update Magnitude: 0.42992
Value Function Update Magnitude: 0.67426

Collected Steps per Second: 22,527.92089
Overall Steps per Second: 10,697.63620

Timestep Collection Time: 2.21956
Timestep Consumption Time: 2.45456
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.67412

Cumulative Model Updates: 76,556
Cumulative Timesteps: 638,406,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 638406064...
Checkpoint 638406064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.68959
Policy Entropy: 3.75280
Value Function Loss: 0.04379

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.44323
Value Function Update Magnitude: 0.63413

Collected Steps per Second: 22,576.88301
Overall Steps per Second: 10,806.34139

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.41293
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.62821

Cumulative Model Updates: 76,562
Cumulative Timesteps: 638,456,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.29102
Policy Entropy: 3.76505
Value Function Loss: 0.04291

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.45060
Value Function Update Magnitude: 0.60717

Collected Steps per Second: 22,808.70469
Overall Steps per Second: 10,655.87481

Timestep Collection Time: 2.19232
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.69262

Cumulative Model Updates: 76,568
Cumulative Timesteps: 638,506,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 638506082...
Checkpoint 638506082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.32050
Policy Entropy: 3.76465
Value Function Loss: 0.04423

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.45404
Value Function Update Magnitude: 0.57717

Collected Steps per Second: 22,300.17241
Overall Steps per Second: 10,644.80471

Timestep Collection Time: 2.24294
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.69882

Cumulative Model Updates: 76,574
Cumulative Timesteps: 638,556,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.36955
Policy Entropy: 3.77292
Value Function Loss: 0.04082

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.47291
Value Function Update Magnitude: 0.61558

Collected Steps per Second: 23,074.87094
Overall Steps per Second: 10,789.64591

Timestep Collection Time: 2.16773
Timestep Consumption Time: 2.46820
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.63593

Cumulative Model Updates: 76,580
Cumulative Timesteps: 638,606,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 638606120...
Checkpoint 638606120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,091.74600
Policy Entropy: 3.78546
Value Function Loss: 0.03894

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.47646
Value Function Update Magnitude: 0.61273

Collected Steps per Second: 22,505.17844
Overall Steps per Second: 10,644.67295

Timestep Collection Time: 2.22224
Timestep Consumption Time: 2.47607
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.69831

Cumulative Model Updates: 76,586
Cumulative Timesteps: 638,656,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,238.05918
Policy Entropy: 3.79668
Value Function Loss: 0.03730

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.50069
Value Function Update Magnitude: 0.60302

Collected Steps per Second: 22,951.47110
Overall Steps per Second: 10,809.32971

Timestep Collection Time: 2.17982
Timestep Consumption Time: 2.44859
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62841

Cumulative Model Updates: 76,592
Cumulative Timesteps: 638,706,162

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 638706162...
Checkpoint 638706162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.66898
Policy Entropy: 3.80735
Value Function Loss: 0.03695

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06890
Policy Update Magnitude: 0.52973
Value Function Update Magnitude: 0.59416

Collected Steps per Second: 22,621.18097
Overall Steps per Second: 10,720.07061

Timestep Collection Time: 2.21209
Timestep Consumption Time: 2.45579
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.66788

Cumulative Model Updates: 76,598
Cumulative Timesteps: 638,756,202

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,497.39798
Policy Entropy: 3.80603
Value Function Loss: 0.03847

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06722
Policy Update Magnitude: 0.59588
Value Function Update Magnitude: 0.59858

Collected Steps per Second: 22,549.17997
Overall Steps per Second: 10,612.08456

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.49493
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.71293

Cumulative Model Updates: 76,604
Cumulative Timesteps: 638,806,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 638806216...
Checkpoint 638806216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.29790
Policy Entropy: 3.81016
Value Function Loss: 0.04122

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06055
Policy Update Magnitude: 0.64088
Value Function Update Magnitude: 0.60102

Collected Steps per Second: 22,771.10152
Overall Steps per Second: 10,877.46210

Timestep Collection Time: 2.19594
Timestep Consumption Time: 2.40109
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.59703

Cumulative Model Updates: 76,610
Cumulative Timesteps: 638,856,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,863.41973
Policy Entropy: 3.80863
Value Function Loss: 0.04131

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05460
Policy Update Magnitude: 0.68182
Value Function Update Magnitude: 0.59991

Collected Steps per Second: 22,392.05137
Overall Steps per Second: 10,622.83028

Timestep Collection Time: 2.23338
Timestep Consumption Time: 2.47440
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.70778

Cumulative Model Updates: 76,616
Cumulative Timesteps: 638,906,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 638906230...
Checkpoint 638906230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,612.33409
Policy Entropy: 3.80640
Value Function Loss: 0.04242

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06543
Policy Update Magnitude: 0.68716
Value Function Update Magnitude: 0.59124

Collected Steps per Second: 22,939.78449
Overall Steps per Second: 10,910.36244

Timestep Collection Time: 2.17979
Timestep Consumption Time: 2.40337
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.58317

Cumulative Model Updates: 76,622
Cumulative Timesteps: 638,956,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,747.02127
Policy Entropy: 3.80273
Value Function Loss: 0.04306

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.68778
Value Function Update Magnitude: 0.60695

Collected Steps per Second: 22,695.39814
Overall Steps per Second: 10,658.61487

Timestep Collection Time: 2.20424
Timestep Consumption Time: 2.48925
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.69348

Cumulative Model Updates: 76,628
Cumulative Timesteps: 639,006,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 639006260...
Checkpoint 639006260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,188.41182
Policy Entropy: 3.79649
Value Function Loss: 0.04441

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.06077
Policy Update Magnitude: 0.70183
Value Function Update Magnitude: 0.63029

Collected Steps per Second: 22,655.36021
Overall Steps per Second: 10,890.21155

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.38534
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.59330

Cumulative Model Updates: 76,634
Cumulative Timesteps: 639,056,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,749.92975
Policy Entropy: 3.78399
Value Function Loss: 0.04629

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05586
Policy Update Magnitude: 0.72145
Value Function Update Magnitude: 0.62516

Collected Steps per Second: 22,866.08436
Overall Steps per Second: 10,715.99527

Timestep Collection Time: 2.18717
Timestep Consumption Time: 2.47987
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.66704

Cumulative Model Updates: 76,640
Cumulative Timesteps: 639,106,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 639106294...
Checkpoint 639106294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,423.36626
Policy Entropy: 3.77350
Value Function Loss: 0.05018

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04978
Policy Update Magnitude: 0.73804
Value Function Update Magnitude: 0.63533

Collected Steps per Second: 22,641.12089
Overall Steps per Second: 10,814.94682

Timestep Collection Time: 2.20855
Timestep Consumption Time: 2.41505
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.62360

Cumulative Model Updates: 76,646
Cumulative Timesteps: 639,156,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,745.41207
Policy Entropy: 3.77326
Value Function Loss: 0.05203

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06720
Policy Update Magnitude: 0.73521
Value Function Update Magnitude: 0.65324

Collected Steps per Second: 22,368.86945
Overall Steps per Second: 10,594.34895

Timestep Collection Time: 2.23605
Timestep Consumption Time: 2.48514
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.72120

Cumulative Model Updates: 76,652
Cumulative Timesteps: 639,206,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 639206316...
Checkpoint 639206316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,075.06824
Policy Entropy: 3.76804
Value Function Loss: 0.05303

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.63854
Value Function Update Magnitude: 0.64861

Collected Steps per Second: 22,589.56785
Overall Steps per Second: 10,701.07186

Timestep Collection Time: 2.21465
Timestep Consumption Time: 2.46040
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.67505

Cumulative Model Updates: 76,658
Cumulative Timesteps: 639,256,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,853.41672
Policy Entropy: 3.75849
Value Function Loss: 0.05220

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.61644
Value Function Update Magnitude: 0.67242

Collected Steps per Second: 22,702.67680
Overall Steps per Second: 10,764.61447

Timestep Collection Time: 2.20362
Timestep Consumption Time: 2.44383
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.64745

Cumulative Model Updates: 76,664
Cumulative Timesteps: 639,306,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 639306372...
Checkpoint 639306372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.98364
Policy Entropy: 3.75049
Value Function Loss: 0.05417

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.55557
Value Function Update Magnitude: 0.69157

Collected Steps per Second: 22,604.72210
Overall Steps per Second: 10,672.20327

Timestep Collection Time: 2.21237
Timestep Consumption Time: 2.47364
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.68601

Cumulative Model Updates: 76,670
Cumulative Timesteps: 639,356,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,872.57123
Policy Entropy: 3.74599
Value Function Loss: 0.05719

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06659
Policy Update Magnitude: 0.62547
Value Function Update Magnitude: 0.67443

Collected Steps per Second: 22,606.11569
Overall Steps per Second: 10,660.40851

Timestep Collection Time: 2.21197
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.69063

Cumulative Model Updates: 76,676
Cumulative Timesteps: 639,406,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 639406386...
Checkpoint 639406386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,524.19533
Policy Entropy: 3.74223
Value Function Loss: 0.06204

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06091
Policy Update Magnitude: 0.70747
Value Function Update Magnitude: 0.66443

Collected Steps per Second: 22,892.33995
Overall Steps per Second: 10,846.23397

Timestep Collection Time: 2.18466
Timestep Consumption Time: 2.42634
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61100

Cumulative Model Updates: 76,682
Cumulative Timesteps: 639,456,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,414.53050
Policy Entropy: 3.73465
Value Function Loss: 0.06309

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.70985
Value Function Update Magnitude: 0.73754

Collected Steps per Second: 22,881.63137
Overall Steps per Second: 10,908.57577

Timestep Collection Time: 2.18542
Timestep Consumption Time: 2.39868
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.58410

Cumulative Model Updates: 76,688
Cumulative Timesteps: 639,506,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 639506404...
Checkpoint 639506404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,279.41163
Policy Entropy: 3.73415
Value Function Loss: 0.06517

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.64051
Value Function Update Magnitude: 0.79362

Collected Steps per Second: 22,683.51158
Overall Steps per Second: 10,655.45108

Timestep Collection Time: 2.20469
Timestep Consumption Time: 2.48869
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.69337

Cumulative Model Updates: 76,694
Cumulative Timesteps: 639,556,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,081.34995
Policy Entropy: 3.73095
Value Function Loss: 0.06383

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.59360
Value Function Update Magnitude: 0.82511

Collected Steps per Second: 22,976.98930
Overall Steps per Second: 10,911.16374

Timestep Collection Time: 2.17740
Timestep Consumption Time: 2.40782
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.58521

Cumulative Model Updates: 76,700
Cumulative Timesteps: 639,606,444

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 639606444...
Checkpoint 639606444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,999.86564
Policy Entropy: 3.71706
Value Function Loss: 0.06521

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.57348
Value Function Update Magnitude: 0.80831

Collected Steps per Second: 22,778.10729
Overall Steps per Second: 10,743.86469

Timestep Collection Time: 2.19518
Timestep Consumption Time: 2.45883
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.65401

Cumulative Model Updates: 76,706
Cumulative Timesteps: 639,656,446

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,933.80061
Policy Entropy: 3.71092
Value Function Loss: 0.06703

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.81366

Collected Steps per Second: 22,754.28823
Overall Steps per Second: 10,809.17957

Timestep Collection Time: 2.19748
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62588

Cumulative Model Updates: 76,712
Cumulative Timesteps: 639,706,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 639706448...
Checkpoint 639706448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,462.61125
Policy Entropy: 3.70900
Value Function Loss: 0.06590

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.49959
Value Function Update Magnitude: 0.82892

Collected Steps per Second: 22,672.00988
Overall Steps per Second: 10,615.03802

Timestep Collection Time: 2.20669
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.71312

Cumulative Model Updates: 76,718
Cumulative Timesteps: 639,756,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,922.82388
Policy Entropy: 3.72111
Value Function Loss: 0.06312

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.49824
Value Function Update Magnitude: 0.79562

Collected Steps per Second: 22,485.37446
Overall Steps per Second: 10,694.08447

Timestep Collection Time: 2.22527
Timestep Consumption Time: 2.45358
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.67885

Cumulative Model Updates: 76,724
Cumulative Timesteps: 639,806,514

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 639806514...
Checkpoint 639806514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,352.15726
Policy Entropy: 3.72180
Value Function Loss: 0.06267

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.64789
Value Function Update Magnitude: 0.68696

Collected Steps per Second: 22,518.53025
Overall Steps per Second: 10,650.91962

Timestep Collection Time: 2.22164
Timestep Consumption Time: 2.47542
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.69706

Cumulative Model Updates: 76,730
Cumulative Timesteps: 639,856,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,258.81685
Policy Entropy: 3.73055
Value Function Loss: 0.06410

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.63182
Value Function Update Magnitude: 0.71582

Collected Steps per Second: 21,788.65855
Overall Steps per Second: 10,447.56519

Timestep Collection Time: 2.29514
Timestep Consumption Time: 2.49143
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.78657

Cumulative Model Updates: 76,736
Cumulative Timesteps: 639,906,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 639906550...
Checkpoint 639906550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,038.74595
Policy Entropy: 3.71512
Value Function Loss: 0.06346

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.60826
Value Function Update Magnitude: 0.76189

Collected Steps per Second: 22,839.73211
Overall Steps per Second: 10,837.58281

Timestep Collection Time: 2.18978
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.61487

Cumulative Model Updates: 76,742
Cumulative Timesteps: 639,956,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.71759
Policy Entropy: 3.71686
Value Function Loss: 0.06293

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.60800
Value Function Update Magnitude: 0.80533

Collected Steps per Second: 22,887.14282
Overall Steps per Second: 10,695.83062

Timestep Collection Time: 2.18507
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.67565

Cumulative Model Updates: 76,748
Cumulative Timesteps: 640,006,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 640006574...
Checkpoint 640006574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,126.52232
Policy Entropy: 3.70982
Value Function Loss: 0.06022

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.58274
Value Function Update Magnitude: 0.80934

Collected Steps per Second: 22,745.26621
Overall Steps per Second: 10,864.70526

Timestep Collection Time: 2.19852
Timestep Consumption Time: 2.40409
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60261

Cumulative Model Updates: 76,754
Cumulative Timesteps: 640,056,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,821.24262
Policy Entropy: 3.69512
Value Function Loss: 0.06131

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08286
Policy Update Magnitude: 0.60637
Value Function Update Magnitude: 0.78383

Collected Steps per Second: 23,024.82145
Overall Steps per Second: 10,836.00916

Timestep Collection Time: 2.17157
Timestep Consumption Time: 2.44268
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.61424

Cumulative Model Updates: 76,760
Cumulative Timesteps: 640,106,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 640106580...
Checkpoint 640106580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,408.15190
Policy Entropy: 3.68877
Value Function Loss: 0.06084

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.59754
Value Function Update Magnitude: 0.80629

Collected Steps per Second: 22,530.61947
Overall Steps per Second: 10,763.29928

Timestep Collection Time: 2.22000
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.64709

Cumulative Model Updates: 76,766
Cumulative Timesteps: 640,156,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.49390
Policy Entropy: 3.69397
Value Function Loss: 0.06383

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.59576
Value Function Update Magnitude: 0.81336

Collected Steps per Second: 22,758.93258
Overall Steps per Second: 10,812.67403

Timestep Collection Time: 2.19729
Timestep Consumption Time: 2.42765
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.62494

Cumulative Model Updates: 76,772
Cumulative Timesteps: 640,206,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 640206606...
Checkpoint 640206606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,159.17562
Policy Entropy: 3.71386
Value Function Loss: 0.06417

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.54331
Value Function Update Magnitude: 0.81329

Collected Steps per Second: 22,607.63380
Overall Steps per Second: 10,715.39043

Timestep Collection Time: 2.21173
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.66637

Cumulative Model Updates: 76,778
Cumulative Timesteps: 640,256,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,170.43586
Policy Entropy: 3.71587
Value Function Loss: 0.06393

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.61083
Value Function Update Magnitude: 0.78302

Collected Steps per Second: 22,787.47836
Overall Steps per Second: 10,796.53464

Timestep Collection Time: 2.19498
Timestep Consumption Time: 2.43781
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.63278

Cumulative Model Updates: 76,784
Cumulative Timesteps: 640,306,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 640306626...
Checkpoint 640306626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.17576
Policy Entropy: 3.69917
Value Function Loss: 0.06688

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.59840
Value Function Update Magnitude: 0.73236

Collected Steps per Second: 22,806.23067
Overall Steps per Second: 10,804.95721

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.62880

Cumulative Model Updates: 76,790
Cumulative Timesteps: 640,356,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,280.89815
Policy Entropy: 3.69435
Value Function Loss: 0.06661

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.60633
Value Function Update Magnitude: 0.67115

Collected Steps per Second: 22,715.38748
Overall Steps per Second: 10,799.45152

Timestep Collection Time: 2.20212
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.63190

Cumulative Model Updates: 76,796
Cumulative Timesteps: 640,406,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 640406662...
Checkpoint 640406662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,301.04284
Policy Entropy: 3.69400
Value Function Loss: 0.06885

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10048
Policy Update Magnitude: 0.61067
Value Function Update Magnitude: 0.66380

Collected Steps per Second: 22,740.66706
Overall Steps per Second: 10,705.99222

Timestep Collection Time: 2.20073
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.67458

Cumulative Model Updates: 76,802
Cumulative Timesteps: 640,456,708

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,562.73448
Policy Entropy: 3.69326
Value Function Loss: 0.06731

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.65142
Value Function Update Magnitude: 0.64206

Collected Steps per Second: 22,768.14660
Overall Steps per Second: 10,809.77716

Timestep Collection Time: 2.19728
Timestep Consumption Time: 2.43075
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62803

Cumulative Model Updates: 76,808
Cumulative Timesteps: 640,506,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 640506736...
Checkpoint 640506736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,808.06351
Policy Entropy: 3.67890
Value Function Loss: 0.06908

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.69389
Value Function Update Magnitude: 0.62439

Collected Steps per Second: 22,497.96611
Overall Steps per Second: 10,691.50971

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.45477
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.67773

Cumulative Model Updates: 76,814
Cumulative Timesteps: 640,556,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,501.90704
Policy Entropy: 3.68079
Value Function Loss: 0.06943

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.57964
Value Function Update Magnitude: 0.61967

Collected Steps per Second: 22,639.06007
Overall Steps per Second: 10,671.14848

Timestep Collection Time: 2.20866
Timestep Consumption Time: 2.47706
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.68572

Cumulative Model Updates: 76,820
Cumulative Timesteps: 640,606,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 640606750...
Checkpoint 640606750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,531.73190
Policy Entropy: 3.69121
Value Function Loss: 0.06920

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.49112
Value Function Update Magnitude: 0.59684

Collected Steps per Second: 22,866.66223
Overall Steps per Second: 10,853.91590

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.60737

Cumulative Model Updates: 76,826
Cumulative Timesteps: 640,656,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,733.16158
Policy Entropy: 3.69412
Value Function Loss: 0.06883

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.49249
Value Function Update Magnitude: 0.60358

Collected Steps per Second: 22,964.62575
Overall Steps per Second: 10,858.88223

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.42823
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.60637

Cumulative Model Updates: 76,832
Cumulative Timesteps: 640,706,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 640706778...
Checkpoint 640706778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,565.85635
Policy Entropy: 3.68645
Value Function Loss: 0.06778

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.52663
Value Function Update Magnitude: 0.63586

Collected Steps per Second: 22,472.84224
Overall Steps per Second: 10,721.78984

Timestep Collection Time: 2.22517
Timestep Consumption Time: 2.43879
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.66396

Cumulative Model Updates: 76,838
Cumulative Timesteps: 640,756,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,266.27749
Policy Entropy: 3.68108
Value Function Loss: 0.06742

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.51169
Value Function Update Magnitude: 0.68873

Collected Steps per Second: 22,714.54013
Overall Steps per Second: 10,643.22530

Timestep Collection Time: 2.20211
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.69970

Cumulative Model Updates: 76,844
Cumulative Timesteps: 640,806,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 640806804...
Checkpoint 640806804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,209.60201
Policy Entropy: 3.67360
Value Function Loss: 0.06790

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.15167
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.70079

Collected Steps per Second: 22,665.02179
Overall Steps per Second: 10,691.08062

Timestep Collection Time: 2.20701
Timestep Consumption Time: 2.47184
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.67885

Cumulative Model Updates: 76,850
Cumulative Timesteps: 640,856,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,813.95479
Policy Entropy: 3.69426
Value Function Loss: 0.06850

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.15887
Policy Update Magnitude: 0.42902
Value Function Update Magnitude: 0.75767

Collected Steps per Second: 22,899.71288
Overall Steps per Second: 10,664.78594

Timestep Collection Time: 2.18439
Timestep Consumption Time: 2.50600
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.69039

Cumulative Model Updates: 76,856
Cumulative Timesteps: 640,906,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 640906848...
Checkpoint 640906848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.62452
Policy Entropy: 3.69880
Value Function Loss: 0.06885

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.39397
Value Function Update Magnitude: 0.69976

Collected Steps per Second: 22,544.51887
Overall Steps per Second: 10,652.14770

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.47695
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.69558

Cumulative Model Updates: 76,862
Cumulative Timesteps: 640,956,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,770.49656
Policy Entropy: 3.69849
Value Function Loss: 0.06557

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.50812
Value Function Update Magnitude: 0.66744

Collected Steps per Second: 22,613.46562
Overall Steps per Second: 10,668.52635

Timestep Collection Time: 2.21134
Timestep Consumption Time: 2.47591
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.68725

Cumulative Model Updates: 76,868
Cumulative Timesteps: 641,006,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 641006872...
Checkpoint 641006872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.44335
Policy Entropy: 3.70077
Value Function Loss: 0.06540

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.66582

Collected Steps per Second: 22,720.69614
Overall Steps per Second: 10,821.75974

Timestep Collection Time: 2.20099
Timestep Consumption Time: 2.42007
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.62106

Cumulative Model Updates: 76,874
Cumulative Timesteps: 641,056,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.51368
Policy Entropy: 3.69363
Value Function Loss: 0.06801

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.53668
Value Function Update Magnitude: 0.64196

Collected Steps per Second: 22,791.37739
Overall Steps per Second: 10,710.29796

Timestep Collection Time: 2.19478
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.67046

Cumulative Model Updates: 76,880
Cumulative Timesteps: 641,106,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 641106902...
Checkpoint 641106902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,658.52941
Policy Entropy: 3.69140
Value Function Loss: 0.06954

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.53123
Value Function Update Magnitude: 0.67421

Collected Steps per Second: 22,646.90299
Overall Steps per Second: 10,817.08425

Timestep Collection Time: 2.20781
Timestep Consumption Time: 2.41451
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.62232

Cumulative Model Updates: 76,886
Cumulative Timesteps: 641,156,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,111.33057
Policy Entropy: 3.68791
Value Function Loss: 0.06578

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.56388
Value Function Update Magnitude: 0.73068

Collected Steps per Second: 22,762.59122
Overall Steps per Second: 10,726.12702

Timestep Collection Time: 2.19773
Timestep Consumption Time: 2.46621
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.66394

Cumulative Model Updates: 76,892
Cumulative Timesteps: 641,206,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 641206928...
Checkpoint 641206928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.44362
Policy Entropy: 3.69847
Value Function Loss: 0.06410

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.57557
Value Function Update Magnitude: 0.81640

Collected Steps per Second: 23,094.52823
Overall Steps per Second: 10,945.62408

Timestep Collection Time: 2.16519
Timestep Consumption Time: 2.40321
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.56840

Cumulative Model Updates: 76,898
Cumulative Timesteps: 641,256,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,133.80861
Policy Entropy: 3.70388
Value Function Loss: 0.06134

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.61497
Value Function Update Magnitude: 0.84472

Collected Steps per Second: 21,845.16141
Overall Steps per Second: 10,735.17167

Timestep Collection Time: 2.28957
Timestep Consumption Time: 2.36951
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.65908

Cumulative Model Updates: 76,904
Cumulative Timesteps: 641,306,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 641306948...
Checkpoint 641306948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,260.93654
Policy Entropy: 3.70553
Value Function Loss: 0.06582

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.60006
Value Function Update Magnitude: 0.86155

Collected Steps per Second: 22,039.87963
Overall Steps per Second: 10,735.59075

Timestep Collection Time: 2.26998
Timestep Consumption Time: 2.39022
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.66020

Cumulative Model Updates: 76,910
Cumulative Timesteps: 641,356,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,203.98249
Policy Entropy: 3.69058
Value Function Loss: 0.06818

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09388
Policy Update Magnitude: 0.64497
Value Function Update Magnitude: 0.88534

Collected Steps per Second: 22,301.52446
Overall Steps per Second: 10,883.45227

Timestep Collection Time: 2.24200
Timestep Consumption Time: 2.35213
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.59413

Cumulative Model Updates: 76,916
Cumulative Timesteps: 641,406,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 641406978...
Checkpoint 641406978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,719.04134
Policy Entropy: 3.68713
Value Function Loss: 0.07098

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.59282
Value Function Update Magnitude: 0.89396

Collected Steps per Second: 21,854.65166
Overall Steps per Second: 10,701.88609

Timestep Collection Time: 2.28812
Timestep Consumption Time: 2.38452
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.67263

Cumulative Model Updates: 76,922
Cumulative Timesteps: 641,456,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,628.56116
Policy Entropy: 3.68180
Value Function Loss: 0.06953

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.55940
Value Function Update Magnitude: 0.87063

Collected Steps per Second: 22,240.33113
Overall Steps per Second: 10,579.96038

Timestep Collection Time: 2.24862
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.72686

Cumulative Model Updates: 76,928
Cumulative Timesteps: 641,506,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 641506994...
Checkpoint 641506994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.55388
Policy Entropy: 3.69975
Value Function Loss: 0.06701

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.54389
Value Function Update Magnitude: 0.85117

Collected Steps per Second: 22,762.79629
Overall Steps per Second: 10,853.37427

Timestep Collection Time: 2.19771
Timestep Consumption Time: 2.41155
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60926

Cumulative Model Updates: 76,934
Cumulative Timesteps: 641,557,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,982.18382
Policy Entropy: 3.70525
Value Function Loss: 0.06366

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.52560
Value Function Update Magnitude: 0.83629

Collected Steps per Second: 22,586.84854
Overall Steps per Second: 10,667.05160

Timestep Collection Time: 2.21430
Timestep Consumption Time: 2.47435
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.68864

Cumulative Model Updates: 76,940
Cumulative Timesteps: 641,607,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 641607034...
Checkpoint 641607034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,651.80635
Policy Entropy: 3.70265
Value Function Loss: 0.06683

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.55943
Value Function Update Magnitude: 0.83789

Collected Steps per Second: 22,887.19399
Overall Steps per Second: 10,920.95402

Timestep Collection Time: 2.18515
Timestep Consumption Time: 2.39430
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.57945

Cumulative Model Updates: 76,946
Cumulative Timesteps: 641,657,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.98339
Policy Entropy: 3.70501
Value Function Loss: 0.06698

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.63370
Value Function Update Magnitude: 0.84443

Collected Steps per Second: 22,814.56207
Overall Steps per Second: 10,639.88419

Timestep Collection Time: 2.19211
Timestep Consumption Time: 2.50832
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.70043

Cumulative Model Updates: 76,952
Cumulative Timesteps: 641,707,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 641707058...
Checkpoint 641707058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,321.12198
Policy Entropy: 3.70996
Value Function Loss: 0.06751

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.71362
Value Function Update Magnitude: 0.86335

Collected Steps per Second: 22,816.09328
Overall Steps per Second: 10,678.83995

Timestep Collection Time: 2.19214
Timestep Consumption Time: 2.49152
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.68365

Cumulative Model Updates: 76,958
Cumulative Timesteps: 641,757,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,638.57197
Policy Entropy: 3.72425
Value Function Loss: 0.06259

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.74353
Value Function Update Magnitude: 0.86931

Collected Steps per Second: 22,752.91319
Overall Steps per Second: 10,813.40486

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.42637
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.62389

Cumulative Model Updates: 76,964
Cumulative Timesteps: 641,807,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 641807074...
Checkpoint 641807074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.77016
Policy Entropy: 3.74056
Value Function Loss: 0.06085

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07353
Policy Update Magnitude: 0.72372
Value Function Update Magnitude: 0.86355

Collected Steps per Second: 22,627.81102
Overall Steps per Second: 10,612.39878

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.50190
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.71166

Cumulative Model Updates: 76,970
Cumulative Timesteps: 641,857,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,865.09225
Policy Entropy: 3.73327
Value Function Loss: 0.05899

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.76248
Value Function Update Magnitude: 0.84365

Collected Steps per Second: 22,868.35055
Overall Steps per Second: 10,799.25407

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.63088

Cumulative Model Updates: 76,976
Cumulative Timesteps: 641,907,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 641907086...
Checkpoint 641907086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,141.76154
Policy Entropy: 3.72176
Value Function Loss: 0.06254

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.76084
Value Function Update Magnitude: 0.81690

Collected Steps per Second: 22,472.80560
Overall Steps per Second: 10,742.00654

Timestep Collection Time: 2.22589
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.65667

Cumulative Model Updates: 76,982
Cumulative Timesteps: 641,957,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,911.89560
Policy Entropy: 3.72082
Value Function Loss: 0.06338

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.71900
Value Function Update Magnitude: 0.82254

Collected Steps per Second: 22,763.86263
Overall Steps per Second: 10,811.96182

Timestep Collection Time: 2.19708
Timestep Consumption Time: 2.42872
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62580

Cumulative Model Updates: 76,988
Cumulative Timesteps: 642,007,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 642007122...
Checkpoint 642007122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,170.80270
Policy Entropy: 3.72003
Value Function Loss: 0.06252

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.62353
Value Function Update Magnitude: 0.83061

Collected Steps per Second: 22,420.13979
Overall Steps per Second: 10,686.20703

Timestep Collection Time: 2.23103
Timestep Consumption Time: 2.44977
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.68080

Cumulative Model Updates: 76,994
Cumulative Timesteps: 642,057,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,172.76795
Policy Entropy: 3.72792
Value Function Loss: 0.06027

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.61094
Value Function Update Magnitude: 0.83109

Collected Steps per Second: 22,872.33221
Overall Steps per Second: 10,840.77510

Timestep Collection Time: 2.18710
Timestep Consumption Time: 2.42733
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.61443

Cumulative Model Updates: 77,000
Cumulative Timesteps: 642,107,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 642107166...
Checkpoint 642107166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,963.43847
Policy Entropy: 3.72494
Value Function Loss: 0.06499

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.62323
Value Function Update Magnitude: 0.70831

Collected Steps per Second: 22,521.50050
Overall Steps per Second: 10,701.08834

Timestep Collection Time: 2.22134
Timestep Consumption Time: 2.45369
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.67504

Cumulative Model Updates: 77,006
Cumulative Timesteps: 642,157,194

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,181.62021
Policy Entropy: 3.71186
Value Function Loss: 0.06795

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.67209
Value Function Update Magnitude: 0.57031

Collected Steps per Second: 22,676.49454
Overall Steps per Second: 10,664.35927

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.48478
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.69076

Cumulative Model Updates: 77,012
Cumulative Timesteps: 642,207,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 642207218...
Checkpoint 642207218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,438.42393
Policy Entropy: 3.70255
Value Function Loss: 0.06825

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.70172
Value Function Update Magnitude: 0.60790

Collected Steps per Second: 22,794.10132
Overall Steps per Second: 10,827.09598

Timestep Collection Time: 2.19364
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61823

Cumulative Model Updates: 77,018
Cumulative Timesteps: 642,257,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,466.09600
Policy Entropy: 3.69885
Value Function Loss: 0.06449

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.63100
Value Function Update Magnitude: 0.71073

Collected Steps per Second: 23,005.99423
Overall Steps per Second: 10,921.64933

Timestep Collection Time: 2.17404
Timestep Consumption Time: 2.40549
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.57953

Cumulative Model Updates: 77,024
Cumulative Timesteps: 642,307,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 642307236...
Checkpoint 642307236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,100.41876
Policy Entropy: 3.71440
Value Function Loss: 0.05963

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.56608
Value Function Update Magnitude: 0.76938

Collected Steps per Second: 22,558.40579
Overall Steps per Second: 10,704.94335

Timestep Collection Time: 2.21815
Timestep Consumption Time: 2.45614
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.67429

Cumulative Model Updates: 77,030
Cumulative Timesteps: 642,357,274

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,715.86837
Policy Entropy: 3.70192
Value Function Loss: 0.06007

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.55151
Value Function Update Magnitude: 0.78105

Collected Steps per Second: 22,689.57765
Overall Steps per Second: 10,854.28359

Timestep Collection Time: 2.20471
Timestep Consumption Time: 2.40397
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.60869

Cumulative Model Updates: 77,036
Cumulative Timesteps: 642,407,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 642407298...
Checkpoint 642407298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,130.06002
Policy Entropy: 3.71969
Value Function Loss: 0.05991

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.53565
Value Function Update Magnitude: 0.81334

Collected Steps per Second: 22,354.37473
Overall Steps per Second: 10,699.21430

Timestep Collection Time: 2.23715
Timestep Consumption Time: 2.43703
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.67418

Cumulative Model Updates: 77,042
Cumulative Timesteps: 642,457,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393.22116
Policy Entropy: 3.71168
Value Function Loss: 0.06244

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.56314
Value Function Update Magnitude: 0.83732

Collected Steps per Second: 22,910.45952
Overall Steps per Second: 10,820.03800

Timestep Collection Time: 2.18250
Timestep Consumption Time: 2.43874
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62124

Cumulative Model Updates: 77,048
Cumulative Timesteps: 642,507,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 642507310...
Checkpoint 642507310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.27926
Policy Entropy: 3.71535
Value Function Loss: 0.06299

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.64784
Value Function Update Magnitude: 0.85516

Collected Steps per Second: 22,894.85976
Overall Steps per Second: 10,722.55552

Timestep Collection Time: 2.18433
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.66400

Cumulative Model Updates: 77,054
Cumulative Timesteps: 642,557,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,480.37995
Policy Entropy: 3.69058
Value Function Loss: 0.06495

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.68161
Value Function Update Magnitude: 0.83560

Collected Steps per Second: 23,045.30769
Overall Steps per Second: 10,873.93212

Timestep Collection Time: 2.17007
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.59907

Cumulative Model Updates: 77,060
Cumulative Timesteps: 642,607,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 642607330...
Checkpoint 642607330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,806.04755
Policy Entropy: 3.68634
Value Function Loss: 0.06470

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.63027
Value Function Update Magnitude: 0.78185

Collected Steps per Second: 22,564.19465
Overall Steps per Second: 10,702.59129

Timestep Collection Time: 2.21652
Timestep Consumption Time: 2.45655
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.67307

Cumulative Model Updates: 77,066
Cumulative Timesteps: 642,657,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,111.78649
Policy Entropy: 3.69708
Value Function Loss: 0.06637

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.66921
Value Function Update Magnitude: 0.71125

Collected Steps per Second: 22,935.78297
Overall Steps per Second: 10,915.73114

Timestep Collection Time: 2.18035
Timestep Consumption Time: 2.40093
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.58128

Cumulative Model Updates: 77,072
Cumulative Timesteps: 642,707,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 642707352...
Checkpoint 642707352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,597.18902
Policy Entropy: 3.69859
Value Function Loss: 0.06662

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.67327
Value Function Update Magnitude: 0.77386

Collected Steps per Second: 22,803.67589
Overall Steps per Second: 10,633.02692

Timestep Collection Time: 2.19342
Timestep Consumption Time: 2.51060
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.70402

Cumulative Model Updates: 77,078
Cumulative Timesteps: 642,757,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,922.27135
Policy Entropy: 3.69969
Value Function Loss: 0.06425

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.53856
Value Function Update Magnitude: 0.79262

Collected Steps per Second: 23,077.85645
Overall Steps per Second: 10,833.96388

Timestep Collection Time: 2.16667
Timestep Consumption Time: 2.44863
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.61530

Cumulative Model Updates: 77,084
Cumulative Timesteps: 642,807,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 642807372...
Checkpoint 642807372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,629.98441
Policy Entropy: 3.70618
Value Function Loss: 0.05974

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09859
Policy Update Magnitude: 0.49186
Value Function Update Magnitude: 0.76709

Collected Steps per Second: 22,658.61541
Overall Steps per Second: 10,665.13188

Timestep Collection Time: 2.20711
Timestep Consumption Time: 2.48200
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.68911

Cumulative Model Updates: 77,090
Cumulative Timesteps: 642,857,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,800.01156
Policy Entropy: 3.70674
Value Function Loss: 0.05622

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06331
Policy Update Magnitude: 0.59648
Value Function Update Magnitude: 0.73761

Collected Steps per Second: 22,974.71697
Overall Steps per Second: 10,861.51267

Timestep Collection Time: 2.17735
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.60562

Cumulative Model Updates: 77,096
Cumulative Timesteps: 642,907,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 642907406...
Checkpoint 642907406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,708.65970
Policy Entropy: 3.69773
Value Function Loss: 0.05572

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.60994
Value Function Update Magnitude: 0.75126

Collected Steps per Second: 22,750.10994
Overall Steps per Second: 10,691.74779

Timestep Collection Time: 2.19797
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.67688

Cumulative Model Updates: 77,102
Cumulative Timesteps: 642,957,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,486.81671
Policy Entropy: 3.70561
Value Function Loss: 0.05633

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.64393
Value Function Update Magnitude: 0.77648

Collected Steps per Second: 22,698.52864
Overall Steps per Second: 10,672.99249

Timestep Collection Time: 2.20393
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.68716

Cumulative Model Updates: 77,108
Cumulative Timesteps: 643,007,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 643007436...
Checkpoint 643007436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,354.78799
Policy Entropy: 3.70639
Value Function Loss: 0.05725

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.62059
Value Function Update Magnitude: 0.77677

Collected Steps per Second: 22,586.54355
Overall Steps per Second: 10,783.47437

Timestep Collection Time: 2.21433
Timestep Consumption Time: 2.42370
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.63802

Cumulative Model Updates: 77,114
Cumulative Timesteps: 643,057,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,919.66680
Policy Entropy: 3.70100
Value Function Loss: 0.06214

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.59646
Value Function Update Magnitude: 0.75375

Collected Steps per Second: 22,788.00583
Overall Steps per Second: 10,657.08724

Timestep Collection Time: 2.19440
Timestep Consumption Time: 2.49788
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69228

Cumulative Model Updates: 77,120
Cumulative Timesteps: 643,107,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 643107456...
Checkpoint 643107456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,774.43577
Policy Entropy: 3.70530
Value Function Loss: 0.06205

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.53680
Value Function Update Magnitude: 0.78002

Collected Steps per Second: 22,872.29225
Overall Steps per Second: 10,732.67530

Timestep Collection Time: 2.18623
Timestep Consumption Time: 2.47282
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.65904

Cumulative Model Updates: 77,126
Cumulative Timesteps: 643,157,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,448.15229
Policy Entropy: 3.69294
Value Function Loss: 0.06350

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.51298
Value Function Update Magnitude: 0.73783

Collected Steps per Second: 23,072.08836
Overall Steps per Second: 10,703.42861

Timestep Collection Time: 2.16877
Timestep Consumption Time: 2.50618
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.67495

Cumulative Model Updates: 77,132
Cumulative Timesteps: 643,207,498

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 643207498...
Checkpoint 643207498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,716.54879
Policy Entropy: 3.70112
Value Function Loss: 0.06375

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.51464
Value Function Update Magnitude: 0.64045

Collected Steps per Second: 22,529.24595
Overall Steps per Second: 10,650.87863

Timestep Collection Time: 2.22129
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.69858

Cumulative Model Updates: 77,138
Cumulative Timesteps: 643,257,542

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,989.96258
Policy Entropy: 3.69105
Value Function Loss: 0.06590

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.59505
Value Function Update Magnitude: 0.61996

Collected Steps per Second: 23,169.18806
Overall Steps per Second: 10,856.62830

Timestep Collection Time: 2.15882
Timestep Consumption Time: 2.44832
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.60714

Cumulative Model Updates: 77,144
Cumulative Timesteps: 643,307,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 643307560...
Checkpoint 643307560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,963.96138
Policy Entropy: 3.70119
Value Function Loss: 0.06423

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11566
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.62932

Collected Steps per Second: 22,687.16514
Overall Steps per Second: 10,674.97482

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.48125
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.68629

Cumulative Model Updates: 77,150
Cumulative Timesteps: 643,357,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,105.63482
Policy Entropy: 3.70314
Value Function Loss: 0.06304

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.54613
Value Function Update Magnitude: 0.66784

Collected Steps per Second: 22,501.20206
Overall Steps per Second: 10,616.95128

Timestep Collection Time: 2.22326
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.71190

Cumulative Model Updates: 77,156
Cumulative Timesteps: 643,407,612

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 643407612...
Checkpoint 643407612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.29990
Policy Entropy: 3.71405
Value Function Loss: 0.06313

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.52087
Value Function Update Magnitude: 0.61120

Collected Steps per Second: 22,352.43762
Overall Steps per Second: 10,570.27040

Timestep Collection Time: 2.23725
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.73100

Cumulative Model Updates: 77,162
Cumulative Timesteps: 643,457,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,957.59252
Policy Entropy: 3.70762
Value Function Loss: 0.06509

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.46474
Value Function Update Magnitude: 0.64708

Collected Steps per Second: 22,922.21741
Overall Steps per Second: 10,838.81482

Timestep Collection Time: 2.18173
Timestep Consumption Time: 2.43225
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.61397

Cumulative Model Updates: 77,168
Cumulative Timesteps: 643,507,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 643507630...
Checkpoint 643507630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,156.29227
Policy Entropy: 3.70043
Value Function Loss: 0.06525

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.46160
Value Function Update Magnitude: 0.67101

Collected Steps per Second: 22,777.03969
Overall Steps per Second: 10,642.77466

Timestep Collection Time: 2.19651
Timestep Consumption Time: 2.50433
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.70084

Cumulative Model Updates: 77,174
Cumulative Timesteps: 643,557,660

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,447.41162
Policy Entropy: 3.71175
Value Function Loss: 0.06292

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.46319
Value Function Update Magnitude: 0.76015

Collected Steps per Second: 22,642.97680
Overall Steps per Second: 10,795.51251

Timestep Collection Time: 2.20907
Timestep Consumption Time: 2.42433
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.63341

Cumulative Model Updates: 77,180
Cumulative Timesteps: 643,607,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 643607680...
Checkpoint 643607680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,550.62514
Policy Entropy: 3.71595
Value Function Loss: 0.06101

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.49700
Value Function Update Magnitude: 0.76931

Collected Steps per Second: 22,748.51415
Overall Steps per Second: 10,728.84565

Timestep Collection Time: 2.19918
Timestep Consumption Time: 2.46377
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.66294

Cumulative Model Updates: 77,186
Cumulative Timesteps: 643,657,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,657.77748
Policy Entropy: 3.72574
Value Function Loss: 0.06146

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06366
Policy Update Magnitude: 0.59720
Value Function Update Magnitude: 0.69288

Collected Steps per Second: 22,859.07105
Overall Steps per Second: 10,869.54798

Timestep Collection Time: 2.18828
Timestep Consumption Time: 2.41375
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.60203

Cumulative Model Updates: 77,192
Cumulative Timesteps: 643,707,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 643707730...
Checkpoint 643707730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,558.83009
Policy Entropy: 3.71502
Value Function Loss: 0.06374

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06489
Policy Update Magnitude: 0.67368
Value Function Update Magnitude: 0.67539

Collected Steps per Second: 22,894.20644
Overall Steps per Second: 10,647.16774

Timestep Collection Time: 2.18405
Timestep Consumption Time: 2.51223
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.69627

Cumulative Model Updates: 77,198
Cumulative Timesteps: 643,757,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,055.28854
Policy Entropy: 3.71336
Value Function Loss: 0.06486

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.61196
Value Function Update Magnitude: 0.70025

Collected Steps per Second: 22,583.38751
Overall Steps per Second: 10,659.76560

Timestep Collection Time: 2.21543
Timestep Consumption Time: 2.47810
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.69354

Cumulative Model Updates: 77,204
Cumulative Timesteps: 643,807,764

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 643807764...
Checkpoint 643807764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,655.82114
Policy Entropy: 3.70991
Value Function Loss: 0.06485

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.59914
Value Function Update Magnitude: 0.69119

Collected Steps per Second: 20,810.46229
Overall Steps per Second: 10,168.20552

Timestep Collection Time: 2.40369
Timestep Consumption Time: 2.51576
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.91945

Cumulative Model Updates: 77,210
Cumulative Timesteps: 643,857,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,650.41108
Policy Entropy: 3.70633
Value Function Loss: 0.06979

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.60260
Value Function Update Magnitude: 0.69219

Collected Steps per Second: 21,881.19457
Overall Steps per Second: 10,437.15633

Timestep Collection Time: 2.28507
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.79058

Cumulative Model Updates: 77,216
Cumulative Timesteps: 643,907,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 643907786...
Checkpoint 643907786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,576.08971
Policy Entropy: 3.70227
Value Function Loss: 0.07116

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.61761
Value Function Update Magnitude: 0.72477

Collected Steps per Second: 22,618.62305
Overall Steps per Second: 10,627.45327

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.49463
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.70555

Cumulative Model Updates: 77,222
Cumulative Timesteps: 643,957,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,503.82706
Policy Entropy: 3.70549
Value Function Loss: 0.07420

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.74481

Collected Steps per Second: 23,081.76557
Overall Steps per Second: 10,790.51226

Timestep Collection Time: 2.16656
Timestep Consumption Time: 2.46788
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.63444

Cumulative Model Updates: 77,228
Cumulative Timesteps: 644,007,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 644007802...
Checkpoint 644007802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,900.38499
Policy Entropy: 3.70851
Value Function Loss: 0.06986

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.59501
Value Function Update Magnitude: 0.74646

Collected Steps per Second: 22,691.18755
Overall Steps per Second: 10,641.77184

Timestep Collection Time: 2.20350
Timestep Consumption Time: 2.49497
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.69847

Cumulative Model Updates: 77,234
Cumulative Timesteps: 644,057,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,457.07306
Policy Entropy: 3.71167
Value Function Loss: 0.06733

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.59710
Value Function Update Magnitude: 0.75421

Collected Steps per Second: 22,616.41875
Overall Steps per Second: 10,604.26506

Timestep Collection Time: 2.21202
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.71772

Cumulative Model Updates: 77,240
Cumulative Timesteps: 644,107,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 644107830...
Checkpoint 644107830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,526.72882
Policy Entropy: 3.70713
Value Function Loss: 0.06390

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.60028
Value Function Update Magnitude: 0.76610

Collected Steps per Second: 22,797.92633
Overall Steps per Second: 10,794.65237

Timestep Collection Time: 2.19406
Timestep Consumption Time: 2.43972
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.63378

Cumulative Model Updates: 77,246
Cumulative Timesteps: 644,157,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,360.88630
Policy Entropy: 3.70417
Value Function Loss: 0.06428

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.61755
Value Function Update Magnitude: 0.77676

Collected Steps per Second: 22,516.82120
Overall Steps per Second: 10,583.87305

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.72492

Cumulative Model Updates: 77,252
Cumulative Timesteps: 644,207,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 644207858...
Checkpoint 644207858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,387.80350
Policy Entropy: 3.69231
Value Function Loss: 0.06553

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.57498
Value Function Update Magnitude: 0.76051

Collected Steps per Second: 22,375.68219
Overall Steps per Second: 10,672.52798

Timestep Collection Time: 2.23582
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.68755

Cumulative Model Updates: 77,258
Cumulative Timesteps: 644,257,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,994.36951
Policy Entropy: 3.69519
Value Function Loss: 0.06727

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.52630
Value Function Update Magnitude: 0.79351

Collected Steps per Second: 22,564.66502
Overall Steps per Second: 10,636.24592

Timestep Collection Time: 2.21701
Timestep Consumption Time: 2.48635
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.70335

Cumulative Model Updates: 77,264
Cumulative Timesteps: 644,307,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 644307912...
Checkpoint 644307912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,790.29648
Policy Entropy: 3.68885
Value Function Loss: 0.07120

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.50263
Value Function Update Magnitude: 0.70770

Collected Steps per Second: 22,743.76796
Overall Steps per Second: 10,822.80359

Timestep Collection Time: 2.19884
Timestep Consumption Time: 2.42195
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.62080

Cumulative Model Updates: 77,270
Cumulative Timesteps: 644,357,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,043.07097
Policy Entropy: 3.68691
Value Function Loss: 0.07074

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.49838
Value Function Update Magnitude: 0.66110

Collected Steps per Second: 22,529.54283
Overall Steps per Second: 10,590.41377

Timestep Collection Time: 2.21975
Timestep Consumption Time: 2.50244
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.72220

Cumulative Model Updates: 77,276
Cumulative Timesteps: 644,407,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 644407932...
Checkpoint 644407932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,931.14321
Policy Entropy: 3.67681
Value Function Loss: 0.06610

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.51752
Value Function Update Magnitude: 0.72287

Collected Steps per Second: 22,662.86282
Overall Steps per Second: 10,654.29218

Timestep Collection Time: 2.20714
Timestep Consumption Time: 2.48769
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.69482

Cumulative Model Updates: 77,282
Cumulative Timesteps: 644,457,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,258.44515
Policy Entropy: 3.68196
Value Function Loss: 0.06378

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.55066
Value Function Update Magnitude: 0.79244

Collected Steps per Second: 22,834.56675
Overall Steps per Second: 10,801.41412

Timestep Collection Time: 2.18993
Timestep Consumption Time: 2.43965
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.62958

Cumulative Model Updates: 77,288
Cumulative Timesteps: 644,507,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 644507958...
Checkpoint 644507958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,814.99965
Policy Entropy: 3.69067
Value Function Loss: 0.06535

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.81572

Collected Steps per Second: 22,811.58691
Overall Steps per Second: 10,633.56293

Timestep Collection Time: 2.19310
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.70473

Cumulative Model Updates: 77,294
Cumulative Timesteps: 644,557,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,679.49528
Policy Entropy: 3.68617
Value Function Loss: 0.06828

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08216
Policy Update Magnitude: 0.59322
Value Function Update Magnitude: 0.74939

Collected Steps per Second: 22,592.84032
Overall Steps per Second: 10,606.24628

Timestep Collection Time: 2.21389
Timestep Consumption Time: 2.50201
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.71590

Cumulative Model Updates: 77,300
Cumulative Timesteps: 644,608,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 644608004...
Checkpoint 644608004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,647.52177
Policy Entropy: 3.68968
Value Function Loss: 0.07054

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07081
Policy Update Magnitude: 0.60634
Value Function Update Magnitude: 0.67286

Collected Steps per Second: 22,847.32256
Overall Steps per Second: 10,715.65303

Timestep Collection Time: 2.18905
Timestep Consumption Time: 2.47832
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.66738

Cumulative Model Updates: 77,306
Cumulative Timesteps: 644,658,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,438.25868
Policy Entropy: 3.67181
Value Function Loss: 0.07184

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.56549
Value Function Update Magnitude: 0.65562

Collected Steps per Second: 21,611.30301
Overall Steps per Second: 10,708.22494

Timestep Collection Time: 2.31416
Timestep Consumption Time: 2.35627
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.67043

Cumulative Model Updates: 77,312
Cumulative Timesteps: 644,708,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 644708030...
Checkpoint 644708030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,125.89342
Policy Entropy: 3.67535
Value Function Loss: 0.06957

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.16375
Policy Update Magnitude: 0.44828
Value Function Update Magnitude: 0.62850

Collected Steps per Second: 21,939.35535
Overall Steps per Second: 10,617.75888

Timestep Collection Time: 2.28047
Timestep Consumption Time: 2.43164
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.71211

Cumulative Model Updates: 77,318
Cumulative Timesteps: 644,758,062

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,164.97469
Policy Entropy: 3.68738
Value Function Loss: 0.06387

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.51184
Value Function Update Magnitude: 0.66478

Collected Steps per Second: 22,005.95408
Overall Steps per Second: 10,713.83266

Timestep Collection Time: 2.27357
Timestep Consumption Time: 2.39628
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.66985

Cumulative Model Updates: 77,324
Cumulative Timesteps: 644,808,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 644808094...
Checkpoint 644808094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,450.27878
Policy Entropy: 3.70174
Value Function Loss: 0.05878

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.65567
Value Function Update Magnitude: 0.73207

Collected Steps per Second: 21,859.85843
Overall Steps per Second: 10,791.19753

Timestep Collection Time: 2.28867
Timestep Consumption Time: 2.34752
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.63619

Cumulative Model Updates: 77,330
Cumulative Timesteps: 644,858,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,287.30830
Policy Entropy: 3.71416
Value Function Loss: 0.05803

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.69187
Value Function Update Magnitude: 0.77774

Collected Steps per Second: 21,993.68762
Overall Steps per Second: 10,661.45431

Timestep Collection Time: 2.27347
Timestep Consumption Time: 2.41651
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.68998

Cumulative Model Updates: 77,336
Cumulative Timesteps: 644,908,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 644908126...
Checkpoint 644908126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,138.08402
Policy Entropy: 3.71665
Value Function Loss: 0.05888

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.67541
Value Function Update Magnitude: 0.75776

Collected Steps per Second: 21,944.87436
Overall Steps per Second: 10,707.19673

Timestep Collection Time: 2.27898
Timestep Consumption Time: 2.39189
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.67088

Cumulative Model Updates: 77,342
Cumulative Timesteps: 644,958,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,115.75952
Policy Entropy: 3.71283
Value Function Loss: 0.06030

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.53783
Value Function Update Magnitude: 0.78717

Collected Steps per Second: 22,545.30406
Overall Steps per Second: 10,786.44163

Timestep Collection Time: 2.21829
Timestep Consumption Time: 2.41827
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.63656

Cumulative Model Updates: 77,348
Cumulative Timesteps: 645,008,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 645008150...
Checkpoint 645008150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,004.39524
Policy Entropy: 3.69535
Value Function Loss: 0.06006

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.50342
Value Function Update Magnitude: 0.77750

Collected Steps per Second: 22,199.87099
Overall Steps per Second: 10,580.77007

Timestep Collection Time: 2.25362
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.72839

Cumulative Model Updates: 77,354
Cumulative Timesteps: 645,058,180

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,003.73062
Policy Entropy: 3.69204
Value Function Loss: 0.05946

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.48730
Value Function Update Magnitude: 0.76022

Collected Steps per Second: 22,865.68576
Overall Steps per Second: 10,887.82899

Timestep Collection Time: 2.18808
Timestep Consumption Time: 2.40714
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.59522

Cumulative Model Updates: 77,360
Cumulative Timesteps: 645,108,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 645108212...
Checkpoint 645108212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,819.49754
Policy Entropy: 3.69256
Value Function Loss: 0.06256

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.52552
Value Function Update Magnitude: 0.79233

Collected Steps per Second: 22,762.57239
Overall Steps per Second: 10,726.91652

Timestep Collection Time: 2.19729
Timestep Consumption Time: 2.46537
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.66266

Cumulative Model Updates: 77,366
Cumulative Timesteps: 645,158,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,907.13323
Policy Entropy: 3.71304
Value Function Loss: 0.06247

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.52360
Value Function Update Magnitude: 0.81773

Collected Steps per Second: 23,087.37307
Overall Steps per Second: 10,807.93099

Timestep Collection Time: 2.16577
Timestep Consumption Time: 2.46064
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.62642

Cumulative Model Updates: 77,372
Cumulative Timesteps: 645,208,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 645208230...
Checkpoint 645208230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,320.50393
Policy Entropy: 3.70453
Value Function Loss: 0.06458

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.51884
Value Function Update Magnitude: 0.82909

Collected Steps per Second: 22,756.87808
Overall Steps per Second: 10,712.14291

Timestep Collection Time: 2.19793
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.66928

Cumulative Model Updates: 77,378
Cumulative Timesteps: 645,258,248

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,366.58595
Policy Entropy: 3.70604
Value Function Loss: 0.06431

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.52061
Value Function Update Magnitude: 0.85701

Collected Steps per Second: 23,211.45625
Overall Steps per Second: 10,816.08375

Timestep Collection Time: 2.15437
Timestep Consumption Time: 2.46893
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.62330

Cumulative Model Updates: 77,384
Cumulative Timesteps: 645,308,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 645308254...
Checkpoint 645308254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,282.61692
Policy Entropy: 3.69645
Value Function Loss: 0.06385

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07228
Policy Update Magnitude: 0.62881
Value Function Update Magnitude: 0.87646

Collected Steps per Second: 22,565.05485
Overall Steps per Second: 10,662.33711

Timestep Collection Time: 2.21697
Timestep Consumption Time: 2.47487
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.69184

Cumulative Model Updates: 77,390
Cumulative Timesteps: 645,358,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,663.01820
Policy Entropy: 3.69606
Value Function Loss: 0.06407

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.67601
Value Function Update Magnitude: 0.86777

Collected Steps per Second: 22,844.40323
Overall Steps per Second: 10,812.72094

Timestep Collection Time: 2.18889
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.62455

Cumulative Model Updates: 77,396
Cumulative Timesteps: 645,408,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 645408284...
Checkpoint 645408284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,998.22052
Policy Entropy: 3.69349
Value Function Loss: 0.06221

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.58689
Value Function Update Magnitude: 0.85537

Collected Steps per Second: 22,602.83290
Overall Steps per Second: 10,710.08745

Timestep Collection Time: 2.21264
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.66962

Cumulative Model Updates: 77,402
Cumulative Timesteps: 645,458,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,248.40203
Policy Entropy: 3.69279
Value Function Loss: 0.06133

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.54362
Value Function Update Magnitude: 0.83509

Collected Steps per Second: 22,605.53828
Overall Steps per Second: 10,632.99560

Timestep Collection Time: 2.21202
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.70272

Cumulative Model Updates: 77,408
Cumulative Timesteps: 645,508,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 645508300...
Checkpoint 645508300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,918.05793
Policy Entropy: 3.69091
Value Function Loss: 0.06366

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.51825
Value Function Update Magnitude: 0.81527

Collected Steps per Second: 22,929.28703
Overall Steps per Second: 10,850.74172

Timestep Collection Time: 2.18097
Timestep Consumption Time: 2.42775
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.60872

Cumulative Model Updates: 77,414
Cumulative Timesteps: 645,558,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,244.28271
Policy Entropy: 3.69479
Value Function Loss: 0.06541

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.50587
Value Function Update Magnitude: 0.83669

Collected Steps per Second: 22,558.31653
Overall Steps per Second: 10,614.31786

Timestep Collection Time: 2.21790
Timestep Consumption Time: 2.49574
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.71363

Cumulative Model Updates: 77,420
Cumulative Timesteps: 645,608,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 645608340...
Checkpoint 645608340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,685.38154
Policy Entropy: 3.68581
Value Function Loss: 0.06699

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.53395
Value Function Update Magnitude: 0.83950

Collected Steps per Second: 22,704.37477
Overall Steps per Second: 10,690.52573

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.67966

Cumulative Model Updates: 77,426
Cumulative Timesteps: 645,658,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,093.54990
Policy Entropy: 3.68169
Value Function Loss: 0.06361

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.83466

Collected Steps per Second: 22,764.44305
Overall Steps per Second: 10,759.25519

Timestep Collection Time: 2.19658
Timestep Consumption Time: 2.45095
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.64753

Cumulative Model Updates: 77,432
Cumulative Timesteps: 645,708,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 645708372...
Checkpoint 645708372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.42984
Policy Entropy: 3.68076
Value Function Loss: 0.06245

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06918
Policy Update Magnitude: 0.62288
Value Function Update Magnitude: 0.79729

Collected Steps per Second: 22,746.89905
Overall Steps per Second: 10,625.68987

Timestep Collection Time: 2.19916
Timestep Consumption Time: 2.50868
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70784

Cumulative Model Updates: 77,438
Cumulative Timesteps: 645,758,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,097.45415
Policy Entropy: 3.67598
Value Function Loss: 0.06355

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07138
Policy Update Magnitude: 0.68601
Value Function Update Magnitude: 0.78245

Collected Steps per Second: 22,915.70230
Overall Steps per Second: 10,823.78929

Timestep Collection Time: 2.18191
Timestep Consumption Time: 2.43754
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61945

Cumulative Model Updates: 77,444
Cumulative Timesteps: 645,808,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 645808396...
Checkpoint 645808396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,255.20988
Policy Entropy: 3.68513
Value Function Loss: 0.06361

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.72938
Value Function Update Magnitude: 0.78838

Collected Steps per Second: 22,379.56184
Overall Steps per Second: 10,733.01883

Timestep Collection Time: 2.23463
Timestep Consumption Time: 2.42483
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.65945

Cumulative Model Updates: 77,450
Cumulative Timesteps: 645,858,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,718.28492
Policy Entropy: 3.67014
Value Function Loss: 0.06565

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.65103
Value Function Update Magnitude: 0.67160

Collected Steps per Second: 22,807.79773
Overall Steps per Second: 10,796.41341

Timestep Collection Time: 2.19223
Timestep Consumption Time: 2.43893
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.63117

Cumulative Model Updates: 77,456
Cumulative Timesteps: 645,908,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 645908406...
Checkpoint 645908406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,711.74846
Policy Entropy: 3.68576
Value Function Loss: 0.06735

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.54197
Value Function Update Magnitude: 0.74240

Collected Steps per Second: 22,555.14491
Overall Steps per Second: 10,749.29248

Timestep Collection Time: 2.21750
Timestep Consumption Time: 2.43546
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.65296

Cumulative Model Updates: 77,462
Cumulative Timesteps: 645,958,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,218.63346
Policy Entropy: 3.68549
Value Function Loss: 0.06709

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.52163
Value Function Update Magnitude: 0.79526

Collected Steps per Second: 23,004.71376
Overall Steps per Second: 10,831.52819

Timestep Collection Time: 2.17347
Timestep Consumption Time: 2.44269
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.61615

Cumulative Model Updates: 77,468
Cumulative Timesteps: 646,008,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 646008422...
Checkpoint 646008422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,314.87287
Policy Entropy: 3.68094
Value Function Loss: 0.06833

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.82212

Collected Steps per Second: 22,804.51603
Overall Steps per Second: 10,709.40782

Timestep Collection Time: 2.19369
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.67122

Cumulative Model Updates: 77,474
Cumulative Timesteps: 646,058,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,529.19737
Policy Entropy: 3.67066
Value Function Loss: 0.07047

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.55018
Value Function Update Magnitude: 0.85280

Collected Steps per Second: 23,085.79619
Overall Steps per Second: 10,938.88637

Timestep Collection Time: 2.16609
Timestep Consumption Time: 2.40530
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57140

Cumulative Model Updates: 77,480
Cumulative Timesteps: 646,108,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 646108454...
Checkpoint 646108454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,542.51959
Policy Entropy: 3.67041
Value Function Loss: 0.06967

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.64201
Value Function Update Magnitude: 0.83862

Collected Steps per Second: 22,884.11201
Overall Steps per Second: 10,643.14581

Timestep Collection Time: 2.18518
Timestep Consumption Time: 2.51324
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.69842

Cumulative Model Updates: 77,486
Cumulative Timesteps: 646,158,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,059.50324
Policy Entropy: 3.66806
Value Function Loss: 0.06865

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.62529
Value Function Update Magnitude: 0.82235

Collected Steps per Second: 22,806.53911
Overall Steps per Second: 10,818.14620

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.62445

Cumulative Model Updates: 77,492
Cumulative Timesteps: 646,208,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 646208488...
Checkpoint 646208488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,294.92303
Policy Entropy: 3.66199
Value Function Loss: 0.06940

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.58626
Value Function Update Magnitude: 0.81916

Collected Steps per Second: 22,259.76245
Overall Steps per Second: 10,729.31703

Timestep Collection Time: 2.24683
Timestep Consumption Time: 2.41460
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.66143

Cumulative Model Updates: 77,498
Cumulative Timesteps: 646,258,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,878.15895
Policy Entropy: 3.67025
Value Function Loss: 0.07040

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.56071
Value Function Update Magnitude: 0.82188

Collected Steps per Second: 22,969.43531
Overall Steps per Second: 10,831.96042

Timestep Collection Time: 2.17681
Timestep Consumption Time: 2.43916
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.61597

Cumulative Model Updates: 77,504
Cumulative Timesteps: 646,308,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 646308502...
Checkpoint 646308502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,234.92795
Policy Entropy: 3.66477
Value Function Loss: 0.07458

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.54903
Value Function Update Magnitude: 0.76224

Collected Steps per Second: 22,825.72652
Overall Steps per Second: 10,648.44612

Timestep Collection Time: 2.19060
Timestep Consumption Time: 2.50511
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.69571

Cumulative Model Updates: 77,510
Cumulative Timesteps: 646,358,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.05947
Policy Entropy: 3.66240
Value Function Loss: 0.07463

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.51802
Value Function Update Magnitude: 0.64773

Collected Steps per Second: 22,495.95949
Overall Steps per Second: 10,600.96794

Timestep Collection Time: 2.22342
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.71825

Cumulative Model Updates: 77,516
Cumulative Timesteps: 646,408,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 646408522...
Checkpoint 646408522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,789.07844
Policy Entropy: 3.65766
Value Function Loss: 0.07591

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.55088
Value Function Update Magnitude: 0.71721

Collected Steps per Second: 22,721.57969
Overall Steps per Second: 10,669.22123

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.68788

Cumulative Model Updates: 77,522
Cumulative Timesteps: 646,458,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,847.37852
Policy Entropy: 3.66157
Value Function Loss: 0.07227

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.53410
Value Function Update Magnitude: 0.79245

Collected Steps per Second: 22,861.60213
Overall Steps per Second: 10,710.72477

Timestep Collection Time: 2.18716
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.66840

Cumulative Model Updates: 77,528
Cumulative Timesteps: 646,508,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 646508540...
Checkpoint 646508540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,203.90626
Policy Entropy: 3.66415
Value Function Loss: 0.07130

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.55680
Value Function Update Magnitude: 0.82005

Collected Steps per Second: 22,616.51697
Overall Steps per Second: 10,682.42916

Timestep Collection Time: 2.21175
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.68264

Cumulative Model Updates: 77,534
Cumulative Timesteps: 646,558,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,334.09031
Policy Entropy: 3.66697
Value Function Loss: 0.07021

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.59023
Value Function Update Magnitude: 0.85452

Collected Steps per Second: 22,448.01979
Overall Steps per Second: 10,613.77864

Timestep Collection Time: 2.22835
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.71293

Cumulative Model Updates: 77,540
Cumulative Timesteps: 646,608,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 646608584...
Checkpoint 646608584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,258.04952
Policy Entropy: 3.65525
Value Function Loss: 0.06884

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.61988
Value Function Update Magnitude: 0.84551

Collected Steps per Second: 22,673.65271
Overall Steps per Second: 10,683.88829

Timestep Collection Time: 2.20529
Timestep Consumption Time: 2.47484
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.68013

Cumulative Model Updates: 77,546
Cumulative Timesteps: 646,658,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,351.96886
Policy Entropy: 3.66281
Value Function Loss: 0.07004

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.79095

Collected Steps per Second: 23,060.75402
Overall Steps per Second: 10,683.77894

Timestep Collection Time: 2.16905
Timestep Consumption Time: 2.51281
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.68186

Cumulative Model Updates: 77,552
Cumulative Timesteps: 646,708,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 646708606...
Checkpoint 646708606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,860.54780
Policy Entropy: 3.64833
Value Function Loss: 0.07091

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.48830
Value Function Update Magnitude: 0.80746

Collected Steps per Second: 22,514.50703
Overall Steps per Second: 10,629.09622

Timestep Collection Time: 2.22177
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.70614

Cumulative Model Updates: 77,558
Cumulative Timesteps: 646,758,628

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,873.36691
Policy Entropy: 3.65590
Value Function Loss: 0.07318

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.47235
Value Function Update Magnitude: 0.75720

Collected Steps per Second: 22,590.62983
Overall Steps per Second: 10,638.94717

Timestep Collection Time: 2.21375
Timestep Consumption Time: 2.48690
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.70065

Cumulative Model Updates: 77,564
Cumulative Timesteps: 646,808,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 646808638...
Checkpoint 646808638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,100.42439
Policy Entropy: 3.64675
Value Function Loss: 0.07388

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.73030

Collected Steps per Second: 22,675.36067
Overall Steps per Second: 10,726.78816

Timestep Collection Time: 2.20557
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.66235

Cumulative Model Updates: 77,570
Cumulative Timesteps: 646,858,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,950.28764
Policy Entropy: 3.65632
Value Function Loss: 0.07213

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.67390

Collected Steps per Second: 22,718.17397
Overall Steps per Second: 10,642.93434

Timestep Collection Time: 2.20185
Timestep Consumption Time: 2.49817
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.70002

Cumulative Model Updates: 77,576
Cumulative Timesteps: 646,908,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 646908672...
Checkpoint 646908672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,261.50795
Policy Entropy: 3.65508
Value Function Loss: 0.07068

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.53032
Value Function Update Magnitude: 0.68938

Collected Steps per Second: 22,901.70656
Overall Steps per Second: 10,694.41482

Timestep Collection Time: 2.18438
Timestep Consumption Time: 2.49339
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.67777

Cumulative Model Updates: 77,582
Cumulative Timesteps: 646,958,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,858.24062
Policy Entropy: 3.66070
Value Function Loss: 0.07151

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.49343
Value Function Update Magnitude: 0.63931

Collected Steps per Second: 22,769.73808
Overall Steps per Second: 10,831.92216

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.42057
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.61691

Cumulative Model Updates: 77,588
Cumulative Timesteps: 647,008,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 647008708...
Checkpoint 647008708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,207.34012
Policy Entropy: 3.66477
Value Function Loss: 0.07112

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.49216
Value Function Update Magnitude: 0.63826

Collected Steps per Second: 22,108.04760
Overall Steps per Second: 10,667.21425

Timestep Collection Time: 2.26234
Timestep Consumption Time: 2.42642
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.68876

Cumulative Model Updates: 77,594
Cumulative Timesteps: 647,058,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,170.68241
Policy Entropy: 3.67092
Value Function Loss: 0.06982

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.50974
Value Function Update Magnitude: 0.67226

Collected Steps per Second: 22,463.89657
Overall Steps per Second: 10,932.20099

Timestep Collection Time: 2.22713
Timestep Consumption Time: 2.34926
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.57639

Cumulative Model Updates: 77,600
Cumulative Timesteps: 647,108,754

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 647108754...
Checkpoint 647108754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,012.38515
Policy Entropy: 3.67232
Value Function Loss: 0.06873

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.56773
Value Function Update Magnitude: 0.67580

Collected Steps per Second: 22,145.60859
Overall Steps per Second: 10,687.14294

Timestep Collection Time: 2.25805
Timestep Consumption Time: 2.42103
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.67908

Cumulative Model Updates: 77,606
Cumulative Timesteps: 647,158,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,903.97220
Policy Entropy: 3.66909
Value Function Loss: 0.06838

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.54998
Value Function Update Magnitude: 0.71989

Collected Steps per Second: 22,311.85554
Overall Steps per Second: 10,908.24648

Timestep Collection Time: 2.24240
Timestep Consumption Time: 2.34423
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.58662

Cumulative Model Updates: 77,612
Cumulative Timesteps: 647,208,792

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 647208792...
Checkpoint 647208792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,524.31216
Policy Entropy: 3.66945
Value Function Loss: 0.06836

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.51548
Value Function Update Magnitude: 0.76277

Collected Steps per Second: 22,099.06775
Overall Steps per Second: 10,598.09068

Timestep Collection Time: 2.26372
Timestep Consumption Time: 2.45657
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.72028

Cumulative Model Updates: 77,618
Cumulative Timesteps: 647,258,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,173.35522
Policy Entropy: 3.67022
Value Function Loss: 0.06908

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.51477
Value Function Update Magnitude: 0.69996

Collected Steps per Second: 22,857.80738
Overall Steps per Second: 10,871.41108

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.41198
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.59959

Cumulative Model Updates: 77,624
Cumulative Timesteps: 647,308,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 647308822...
Checkpoint 647308822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,955.08551
Policy Entropy: 3.68070
Value Function Loss: 0.06852

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07066
Policy Update Magnitude: 0.58455
Value Function Update Magnitude: 0.63291

Collected Steps per Second: 22,571.91385
Overall Steps per Second: 10,638.62823

Timestep Collection Time: 2.21594
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.70155

Cumulative Model Updates: 77,630
Cumulative Timesteps: 647,358,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,278.01563
Policy Entropy: 3.68724
Value Function Loss: 0.06501

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.62676
Value Function Update Magnitude: 0.69931

Collected Steps per Second: 22,734.64614
Overall Steps per Second: 10,867.36050

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.40261
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.60277

Cumulative Model Updates: 77,636
Cumulative Timesteps: 647,408,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 647408860...
Checkpoint 647408860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,064.57974
Policy Entropy: 3.69491
Value Function Loss: 0.06360

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.55543
Value Function Update Magnitude: 0.78062

Collected Steps per Second: 22,447.95466
Overall Steps per Second: 10,696.98763

Timestep Collection Time: 2.22773
Timestep Consumption Time: 2.44723
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.67496

Cumulative Model Updates: 77,642
Cumulative Timesteps: 647,458,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,573.42136
Policy Entropy: 3.68570
Value Function Loss: 0.06630

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.62503
Value Function Update Magnitude: 0.81324

Collected Steps per Second: 22,758.53666
Overall Steps per Second: 10,814.48931

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.42742
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.62528

Cumulative Model Updates: 77,648
Cumulative Timesteps: 647,508,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 647508888...
Checkpoint 647508888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,581.78083
Policy Entropy: 3.68269
Value Function Loss: 0.06574

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.66948
Value Function Update Magnitude: 0.83579

Collected Steps per Second: 22,539.25513
Overall Steps per Second: 10,781.82152

Timestep Collection Time: 2.21933
Timestep Consumption Time: 2.42015
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.63948

Cumulative Model Updates: 77,654
Cumulative Timesteps: 647,558,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,003.19998
Policy Entropy: 3.67613
Value Function Loss: 0.06591

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.57505
Value Function Update Magnitude: 0.80691

Collected Steps per Second: 22,908.01572
Overall Steps per Second: 10,824.47570

Timestep Collection Time: 2.18386
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.62175

Cumulative Model Updates: 77,660
Cumulative Timesteps: 647,608,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 647608938...
Checkpoint 647608938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,225.40323
Policy Entropy: 3.68453
Value Function Loss: 0.06676

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.42789
Value Function Update Magnitude: 0.79638

Collected Steps per Second: 22,345.71389
Overall Steps per Second: 10,738.14024

Timestep Collection Time: 2.23864
Timestep Consumption Time: 2.41990
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.65853

Cumulative Model Updates: 77,666
Cumulative Timesteps: 647,658,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,812.73839
Policy Entropy: 3.68025
Value Function Loss: 0.07286

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06889
Policy Update Magnitude: 0.52705
Value Function Update Magnitude: 0.77986

Collected Steps per Second: 22,883.44798
Overall Steps per Second: 10,821.97458

Timestep Collection Time: 2.18665
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62374

Cumulative Model Updates: 77,672
Cumulative Timesteps: 647,709,000

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 647709000...
Checkpoint 647709000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,052.32643
Policy Entropy: 3.67938
Value Function Loss: 0.07641

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.60599
Value Function Update Magnitude: 0.71147

Collected Steps per Second: 22,663.47315
Overall Steps per Second: 10,664.75328

Timestep Collection Time: 2.20752
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.69115

Cumulative Model Updates: 77,678
Cumulative Timesteps: 647,759,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,391.18564
Policy Entropy: 3.68001
Value Function Loss: 0.07374

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.51584
Value Function Update Magnitude: 0.68228

Collected Steps per Second: 22,664.26539
Overall Steps per Second: 10,695.24710

Timestep Collection Time: 2.20638
Timestep Consumption Time: 2.46915
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.67553

Cumulative Model Updates: 77,684
Cumulative Timesteps: 647,809,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 647809036...
Checkpoint 647809036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,328.15651
Policy Entropy: 3.68779
Value Function Loss: 0.07092

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.49066
Value Function Update Magnitude: 0.74850

Collected Steps per Second: 23,040.14130
Overall Steps per Second: 10,903.79600

Timestep Collection Time: 2.17047
Timestep Consumption Time: 2.41582
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.58629

Cumulative Model Updates: 77,690
Cumulative Timesteps: 647,859,044

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,691.88661
Policy Entropy: 3.68798
Value Function Loss: 0.06702

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.46672
Value Function Update Magnitude: 0.81252

Collected Steps per Second: 23,022.33535
Overall Steps per Second: 10,851.32909

Timestep Collection Time: 2.17180
Timestep Consumption Time: 2.43593
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.60773

Cumulative Model Updates: 77,696
Cumulative Timesteps: 647,909,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 647909044...
Checkpoint 647909044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,132.06160
Policy Entropy: 3.68671
Value Function Loss: 0.07196

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.48314
Value Function Update Magnitude: 0.74858

Collected Steps per Second: 22,521.20830
Overall Steps per Second: 10,651.05477

Timestep Collection Time: 2.22102
Timestep Consumption Time: 2.47523
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.69625

Cumulative Model Updates: 77,702
Cumulative Timesteps: 647,959,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,565.25985
Policy Entropy: 3.67637
Value Function Loss: 0.07225

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.46113
Value Function Update Magnitude: 0.62503

Collected Steps per Second: 22,717.56510
Overall Steps per Second: 10,797.13219

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.42992
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.63086

Cumulative Model Updates: 77,708
Cumulative Timesteps: 648,009,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 648009064...
Checkpoint 648009064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,273.45748
Policy Entropy: 3.66709
Value Function Loss: 0.07419

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.46518
Value Function Update Magnitude: 0.58937

Collected Steps per Second: 22,562.96252
Overall Steps per Second: 10,735.23687

Timestep Collection Time: 2.21655
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.65868

Cumulative Model Updates: 77,714
Cumulative Timesteps: 648,059,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,569.30947
Policy Entropy: 3.67027
Value Function Loss: 0.07142

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.51973
Value Function Update Magnitude: 0.60881

Collected Steps per Second: 23,195.41142
Overall Steps per Second: 10,891.40648

Timestep Collection Time: 2.15612
Timestep Consumption Time: 2.43576
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.59188

Cumulative Model Updates: 77,720
Cumulative Timesteps: 648,109,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 648109088...
Checkpoint 648109088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,848.15574
Policy Entropy: 3.66603
Value Function Loss: 0.06800

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.16453
Policy Update Magnitude: 0.46498
Value Function Update Magnitude: 0.63685

Collected Steps per Second: 22,410.41983
Overall Steps per Second: 10,629.53983

Timestep Collection Time: 2.23128
Timestep Consumption Time: 2.47297
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.70425

Cumulative Model Updates: 77,726
Cumulative Timesteps: 648,159,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,746.42761
Policy Entropy: 3.67142
Value Function Loss: 0.06894

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.53279
Value Function Update Magnitude: 0.72978

Collected Steps per Second: 21,851.90170
Overall Steps per Second: 10,650.25063

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.40746
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.69642

Cumulative Model Updates: 77,732
Cumulative Timesteps: 648,209,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 648209110...
Checkpoint 648209110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,966.26866
Policy Entropy: 3.65587
Value Function Loss: 0.06906

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.58548
Value Function Update Magnitude: 0.73682

Collected Steps per Second: 21,784.33983
Overall Steps per Second: 10,651.54091

Timestep Collection Time: 2.29550
Timestep Consumption Time: 2.39922
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.69472

Cumulative Model Updates: 77,738
Cumulative Timesteps: 648,259,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,636.30589
Policy Entropy: 3.66743
Value Function Loss: 0.07133

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.50959
Value Function Update Magnitude: 0.74007

Collected Steps per Second: 22,375.95278
Overall Steps per Second: 10,719.69404

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.43094
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.66655

Cumulative Model Updates: 77,744
Cumulative Timesteps: 648,309,140

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 648309140...
Checkpoint 648309140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,221.49610
Policy Entropy: 3.67006
Value Function Loss: 0.06971

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.47804
Value Function Update Magnitude: 0.75248

Collected Steps per Second: 21,752.65586
Overall Steps per Second: 10,618.49348

Timestep Collection Time: 2.29857
Timestep Consumption Time: 2.41020
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.70877

Cumulative Model Updates: 77,750
Cumulative Timesteps: 648,359,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,106.37767
Policy Entropy: 3.66516
Value Function Loss: 0.06984

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.51384
Value Function Update Magnitude: 0.77166

Collected Steps per Second: 22,573.39400
Overall Steps per Second: 10,824.82978

Timestep Collection Time: 2.21562
Timestep Consumption Time: 2.40469
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62030

Cumulative Model Updates: 77,756
Cumulative Timesteps: 648,409,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 648409154...
Checkpoint 648409154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,044.77327
Policy Entropy: 3.66404
Value Function Loss: 0.07005

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.54880
Value Function Update Magnitude: 0.78259

Collected Steps per Second: 22,506.52037
Overall Steps per Second: 10,727.05459

Timestep Collection Time: 2.22211
Timestep Consumption Time: 2.44012
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.66223

Cumulative Model Updates: 77,762
Cumulative Timesteps: 648,459,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,582.84562
Policy Entropy: 3.66564
Value Function Loss: 0.06887

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.59045
Value Function Update Magnitude: 0.77470

Collected Steps per Second: 23,012.53796
Overall Steps per Second: 10,957.01854

Timestep Collection Time: 2.17342
Timestep Consumption Time: 2.39132
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.56475

Cumulative Model Updates: 77,768
Cumulative Timesteps: 648,509,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 648509182...
Checkpoint 648509182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,436.22145
Policy Entropy: 3.67234
Value Function Loss: 0.06662

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.67801
Value Function Update Magnitude: 0.78016

Collected Steps per Second: 22,575.15140
Overall Steps per Second: 10,662.17931

Timestep Collection Time: 2.21571
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.69135

Cumulative Model Updates: 77,774
Cumulative Timesteps: 648,559,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,486.37576
Policy Entropy: 3.67572
Value Function Loss: 0.06605

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.65030
Value Function Update Magnitude: 0.75311

Collected Steps per Second: 22,827.49321
Overall Steps per Second: 10,804.62021

Timestep Collection Time: 2.19131
Timestep Consumption Time: 2.43838
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62969

Cumulative Model Updates: 77,780
Cumulative Timesteps: 648,609,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 648609224...
Checkpoint 648609224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,014.63579
Policy Entropy: 3.68034
Value Function Loss: 0.06739

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.52951
Value Function Update Magnitude: 0.69568

Collected Steps per Second: 22,813.34207
Overall Steps per Second: 10,687.19086

Timestep Collection Time: 2.19258
Timestep Consumption Time: 2.48779
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.68037

Cumulative Model Updates: 77,786
Cumulative Timesteps: 648,659,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,641.14488
Policy Entropy: 3.67824
Value Function Loss: 0.07017

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.47639
Value Function Update Magnitude: 0.75281

Collected Steps per Second: 22,696.09491
Overall Steps per Second: 10,775.96912

Timestep Collection Time: 2.20320
Timestep Consumption Time: 2.43713
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.64033

Cumulative Model Updates: 77,792
Cumulative Timesteps: 648,709,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 648709248...
Checkpoint 648709248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,537.38451
Policy Entropy: 3.68048
Value Function Loss: 0.07010

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.48960
Value Function Update Magnitude: 0.78568

Collected Steps per Second: 22,707.27229
Overall Steps per Second: 10,766.98692

Timestep Collection Time: 2.20291
Timestep Consumption Time: 2.44296
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.64587

Cumulative Model Updates: 77,798
Cumulative Timesteps: 648,759,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,834.05583
Policy Entropy: 3.68230
Value Function Loss: 0.07066

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.48454
Value Function Update Magnitude: 0.79272

Collected Steps per Second: 22,670.95620
Overall Steps per Second: 10,652.20502

Timestep Collection Time: 2.20555
Timestep Consumption Time: 2.48850
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.69405

Cumulative Model Updates: 77,804
Cumulative Timesteps: 648,809,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 648809272...
Checkpoint 648809272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,563.11083
Policy Entropy: 3.66729
Value Function Loss: 0.07206

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.48015
Value Function Update Magnitude: 0.78141

Collected Steps per Second: 22,725.14972
Overall Steps per Second: 10,811.34756

Timestep Collection Time: 2.20100
Timestep Consumption Time: 2.42544
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62644

Cumulative Model Updates: 77,810
Cumulative Timesteps: 648,859,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,727.45378
Policy Entropy: 3.66774
Value Function Loss: 0.07395

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.48258
Value Function Update Magnitude: 0.77124

Collected Steps per Second: 22,733.53842
Overall Steps per Second: 10,646.39188

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.69680

Cumulative Model Updates: 77,816
Cumulative Timesteps: 648,909,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 648909294...
Checkpoint 648909294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,998.12962
Policy Entropy: 3.67038
Value Function Loss: 0.07185

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.51442
Value Function Update Magnitude: 0.76149

Collected Steps per Second: 22,471.00770
Overall Steps per Second: 10,573.22673

Timestep Collection Time: 2.22625
Timestep Consumption Time: 2.50514
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.73138

Cumulative Model Updates: 77,822
Cumulative Timesteps: 648,959,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,404.82981
Policy Entropy: 3.68016
Value Function Loss: 0.06881

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.50043
Value Function Update Magnitude: 0.71083

Collected Steps per Second: 22,837.67703
Overall Steps per Second: 10,827.34014

Timestep Collection Time: 2.19015
Timestep Consumption Time: 2.42945
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61960

Cumulative Model Updates: 77,828
Cumulative Timesteps: 649,009,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 649009338...
Checkpoint 649009338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,191.43562
Policy Entropy: 3.67605
Value Function Loss: 0.06636

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10294
Policy Update Magnitude: 0.48898
Value Function Update Magnitude: 0.68985

Collected Steps per Second: 22,787.74482
Overall Steps per Second: 10,649.17318

Timestep Collection Time: 2.19530
Timestep Consumption Time: 2.50234
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.69764

Cumulative Model Updates: 77,834
Cumulative Timesteps: 649,059,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.97342
Policy Entropy: 3.67299
Value Function Loss: 0.06524

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.54826
Value Function Update Magnitude: 0.70460

Collected Steps per Second: 22,822.27740
Overall Steps per Second: 10,815.60275

Timestep Collection Time: 2.19154
Timestep Consumption Time: 2.43289
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.62443

Cumulative Model Updates: 77,840
Cumulative Timesteps: 649,109,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 649109380...
Checkpoint 649109380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,757.66573
Policy Entropy: 3.69214
Value Function Loss: 0.06616

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.63661
Value Function Update Magnitude: 0.70866

Collected Steps per Second: 22,376.94103
Overall Steps per Second: 10,763.79977

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.41134
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.64631

Cumulative Model Updates: 77,846
Cumulative Timesteps: 649,159,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,193.85877
Policy Entropy: 3.69730
Value Function Loss: 0.06659

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.70006
Value Function Update Magnitude: 0.72692

Collected Steps per Second: 22,986.37608
Overall Steps per Second: 10,877.51105

Timestep Collection Time: 2.17616
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.59866

Cumulative Model Updates: 77,852
Cumulative Timesteps: 649,209,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 649209414...
Checkpoint 649209414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,051.73186
Policy Entropy: 3.69259
Value Function Loss: 0.06901

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.72899
Value Function Update Magnitude: 0.71924

Collected Steps per Second: 22,875.67097
Overall Steps per Second: 10,617.74908

Timestep Collection Time: 2.18652
Timestep Consumption Time: 2.52428
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.71079

Cumulative Model Updates: 77,858
Cumulative Timesteps: 649,259,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,859.61140
Policy Entropy: 3.68687
Value Function Loss: 0.06976

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.16511
Policy Update Magnitude: 0.63396
Value Function Update Magnitude: 0.73787

Collected Steps per Second: 23,074.55208
Overall Steps per Second: 10,859.45601

Timestep Collection Time: 2.16689
Timestep Consumption Time: 2.43739
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.60428

Cumulative Model Updates: 77,864
Cumulative Timesteps: 649,309,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 649309432...
Checkpoint 649309432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,408.10260
Policy Entropy: 3.68224
Value Function Loss: 0.07003

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.47898
Value Function Update Magnitude: 0.69348

Collected Steps per Second: 22,649.10081
Overall Steps per Second: 10,706.79464

Timestep Collection Time: 2.20856
Timestep Consumption Time: 2.46342
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.67199

Cumulative Model Updates: 77,870
Cumulative Timesteps: 649,359,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,957.20571
Policy Entropy: 3.67558
Value Function Loss: 0.07200

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11314
Policy Update Magnitude: 0.50735
Value Function Update Magnitude: 0.64269

Collected Steps per Second: 22,757.32571
Overall Steps per Second: 10,632.66549

Timestep Collection Time: 2.19771
Timestep Consumption Time: 2.50610
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.70381

Cumulative Model Updates: 77,876
Cumulative Timesteps: 649,409,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 649409468...
Checkpoint 649409468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,123.20419
Policy Entropy: 3.67367
Value Function Loss: 0.07288

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.54103
Value Function Update Magnitude: 0.62857

Collected Steps per Second: 22,468.71893
Overall Steps per Second: 10,593.85938

Timestep Collection Time: 2.22594
Timestep Consumption Time: 2.49510
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.72104

Cumulative Model Updates: 77,882
Cumulative Timesteps: 649,459,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,381.45961
Policy Entropy: 3.67752
Value Function Loss: 0.07381

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.50587
Value Function Update Magnitude: 0.57756

Collected Steps per Second: 23,139.39364
Overall Steps per Second: 10,806.54659

Timestep Collection Time: 2.16211
Timestep Consumption Time: 2.46749
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.62960

Cumulative Model Updates: 77,888
Cumulative Timesteps: 649,509,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 649509512...
Checkpoint 649509512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,934.91827
Policy Entropy: 3.68183
Value Function Loss: 0.07028

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.51694
Value Function Update Magnitude: 0.56818

Collected Steps per Second: 22,789.36113
Overall Steps per Second: 10,654.97444

Timestep Collection Time: 2.19515
Timestep Consumption Time: 2.49994
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.69508

Cumulative Model Updates: 77,894
Cumulative Timesteps: 649,559,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,131.47402
Policy Entropy: 3.68867
Value Function Loss: 0.06718

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.52125
Value Function Update Magnitude: 0.56474

Collected Steps per Second: 22,866.65272
Overall Steps per Second: 10,823.15956

Timestep Collection Time: 2.18720
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62102

Cumulative Model Updates: 77,900
Cumulative Timesteps: 649,609,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 649609552...
Checkpoint 649609552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,960.30519
Policy Entropy: 3.68335
Value Function Loss: 0.06555

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.48232
Value Function Update Magnitude: 0.58643

Collected Steps per Second: 22,142.05918
Overall Steps per Second: 10,701.12456

Timestep Collection Time: 2.25887
Timestep Consumption Time: 2.41503
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.67390

Cumulative Model Updates: 77,906
Cumulative Timesteps: 649,659,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,171.08325
Policy Entropy: 3.69344
Value Function Loss: 0.06682

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09392
Policy Update Magnitude: 0.50329
Value Function Update Magnitude: 0.61760

Collected Steps per Second: 23,056.01113
Overall Steps per Second: 10,872.44385

Timestep Collection Time: 2.16950
Timestep Consumption Time: 2.43112
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.60062

Cumulative Model Updates: 77,912
Cumulative Timesteps: 649,709,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 649709588...
Checkpoint 649709588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,481.70998
Policy Entropy: 3.69315
Value Function Loss: 0.06856

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.55503
Value Function Update Magnitude: 0.64079

Collected Steps per Second: 22,448.28934
Overall Steps per Second: 10,681.73063

Timestep Collection Time: 2.22752
Timestep Consumption Time: 2.45374
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.68126

Cumulative Model Updates: 77,918
Cumulative Timesteps: 649,759,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,347.37978
Policy Entropy: 3.69309
Value Function Loss: 0.06750

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.65738

Collected Steps per Second: 22,680.86912
Overall Steps per Second: 10,817.61360

Timestep Collection Time: 2.20565
Timestep Consumption Time: 2.41885
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.62450

Cumulative Model Updates: 77,924
Cumulative Timesteps: 649,809,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 649809618...
Checkpoint 649809618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,794.14415
Policy Entropy: 3.67793
Value Function Loss: 0.06726

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.56552
Value Function Update Magnitude: 0.67137

Collected Steps per Second: 22,389.65011
Overall Steps per Second: 10,752.29237

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.41738
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.65092

Cumulative Model Updates: 77,930
Cumulative Timesteps: 649,859,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,596.69853
Policy Entropy: 3.67387
Value Function Loss: 0.06633

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.57483
Value Function Update Magnitude: 0.63871

Collected Steps per Second: 23,132.99079
Overall Steps per Second: 10,889.99199

Timestep Collection Time: 2.16219
Timestep Consumption Time: 2.43083
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.59302

Cumulative Model Updates: 77,936
Cumulative Timesteps: 649,909,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 649909644...
Checkpoint 649909644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.73181
Policy Entropy: 3.66986
Value Function Loss: 0.06868

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.55538
Value Function Update Magnitude: 0.60920

Collected Steps per Second: 22,342.28163
Overall Steps per Second: 10,623.67971

Timestep Collection Time: 2.24006
Timestep Consumption Time: 2.47093
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.71099

Cumulative Model Updates: 77,942
Cumulative Timesteps: 649,959,692

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,230.85794
Policy Entropy: 3.67182
Value Function Loss: 0.07055

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.63660
Value Function Update Magnitude: 0.61222

Collected Steps per Second: 23,023.83397
Overall Steps per Second: 10,872.66626

Timestep Collection Time: 2.17383
Timestep Consumption Time: 2.42945
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.60329

Cumulative Model Updates: 77,948
Cumulative Timesteps: 650,009,742

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 650009742...
Checkpoint 650009742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,320.48814
Policy Entropy: 3.68323
Value Function Loss: 0.07029

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.57234
Value Function Update Magnitude: 0.63938

Collected Steps per Second: 21,983.81999
Overall Steps per Second: 10,701.98619

Timestep Collection Time: 2.27513
Timestep Consumption Time: 2.39840
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.67353

Cumulative Model Updates: 77,954
Cumulative Timesteps: 650,059,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.24017
Policy Entropy: 3.69798
Value Function Loss: 0.06984

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.55551
Value Function Update Magnitude: 0.67645

Collected Steps per Second: 22,306.21216
Overall Steps per Second: 10,866.01666

Timestep Collection Time: 2.24162
Timestep Consumption Time: 2.36007
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60169

Cumulative Model Updates: 77,960
Cumulative Timesteps: 650,109,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 650109760...
Checkpoint 650109760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,259.92770
Policy Entropy: 3.70496
Value Function Loss: 0.06853

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.56102
Value Function Update Magnitude: 0.69556

Collected Steps per Second: 21,896.11435
Overall Steps per Second: 10,666.68623

Timestep Collection Time: 2.28378
Timestep Consumption Time: 2.40427
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.68805

Cumulative Model Updates: 77,966
Cumulative Timesteps: 650,159,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,797.95501
Policy Entropy: 3.70086
Value Function Loss: 0.07067

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.59475
Value Function Update Magnitude: 0.68159

Collected Steps per Second: 22,203.39751
Overall Steps per Second: 10,860.58154

Timestep Collection Time: 2.25236
Timestep Consumption Time: 2.35237
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.60473

Cumulative Model Updates: 77,972
Cumulative Timesteps: 650,209,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 650209776...
Checkpoint 650209776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,835.66943
Policy Entropy: 3.68447
Value Function Loss: 0.07175

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.61022
Value Function Update Magnitude: 0.69193

Collected Steps per Second: 21,622.29745
Overall Steps per Second: 10,649.15924

Timestep Collection Time: 2.31308
Timestep Consumption Time: 2.38345
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.69652

Cumulative Model Updates: 77,978
Cumulative Timesteps: 650,259,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,682.86924
Policy Entropy: 3.67627
Value Function Loss: 0.07307

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.58143
Value Function Update Magnitude: 0.69409

Collected Steps per Second: 22,351.53725
Overall Steps per Second: 10,624.61610

Timestep Collection Time: 2.23743
Timestep Consumption Time: 2.46956
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.70699

Cumulative Model Updates: 77,984
Cumulative Timesteps: 650,309,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 650309800...
Checkpoint 650309800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,858.45002
Policy Entropy: 3.69450
Value Function Loss: 0.07049

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.15706
Policy Update Magnitude: 0.54472
Value Function Update Magnitude: 0.72353

Collected Steps per Second: 22,578.12300
Overall Steps per Second: 10,719.68366

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.66600

Cumulative Model Updates: 77,990
Cumulative Timesteps: 650,359,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,208.74962
Policy Entropy: 3.70742
Value Function Loss: 0.06750

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11774
Policy Update Magnitude: 0.56211
Value Function Update Magnitude: 0.73653

Collected Steps per Second: 22,431.02742
Overall Steps per Second: 10,703.02940

Timestep Collection Time: 2.22923
Timestep Consumption Time: 2.44271
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.67195

Cumulative Model Updates: 77,996
Cumulative Timesteps: 650,409,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 650409822...
Checkpoint 650409822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,348.12061
Policy Entropy: 3.72195
Value Function Loss: 0.06635

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.66384

Collected Steps per Second: 22,438.59845
Overall Steps per Second: 10,615.66888

Timestep Collection Time: 2.22839
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.71021

Cumulative Model Updates: 78,002
Cumulative Timesteps: 650,459,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,671.26438
Policy Entropy: 3.72131
Value Function Loss: 0.06711

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.72990

Collected Steps per Second: 22,681.11673
Overall Steps per Second: 10,789.20717

Timestep Collection Time: 2.20571
Timestep Consumption Time: 2.43114
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.63686

Cumulative Model Updates: 78,008
Cumulative Timesteps: 650,509,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 650509852...
Checkpoint 650509852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,388.18502
Policy Entropy: 3.71514
Value Function Loss: 0.06718

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.54306
Value Function Update Magnitude: 0.72289

Collected Steps per Second: 22,677.96049
Overall Steps per Second: 10,729.25565

Timestep Collection Time: 2.20584
Timestep Consumption Time: 2.45655
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.66239

Cumulative Model Updates: 78,014
Cumulative Timesteps: 650,559,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,356.85319
Policy Entropy: 3.70532
Value Function Loss: 0.06665

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.71342

Collected Steps per Second: 22,518.51564
Overall Steps per Second: 10,606.57656

Timestep Collection Time: 2.22084
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.71500

Cumulative Model Updates: 78,020
Cumulative Timesteps: 650,609,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 650609886...
Checkpoint 650609886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,823.31597
Policy Entropy: 3.70709
Value Function Loss: 0.06603

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.57127
Value Function Update Magnitude: 0.76278

Collected Steps per Second: 22,952.05422
Overall Steps per Second: 10,886.99298

Timestep Collection Time: 2.17880
Timestep Consumption Time: 2.41457
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59337

Cumulative Model Updates: 78,026
Cumulative Timesteps: 650,659,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,416.57301
Policy Entropy: 3.70060
Value Function Loss: 0.06513

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.61475
Value Function Update Magnitude: 0.83979

Collected Steps per Second: 22,537.14145
Overall Steps per Second: 10,565.55034

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.51481
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.73425

Cumulative Model Updates: 78,032
Cumulative Timesteps: 650,709,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 650709914...
Checkpoint 650709914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,411.67836
Policy Entropy: 3.69609
Value Function Loss: 0.06748

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.60600
Value Function Update Magnitude: 0.83646

Collected Steps per Second: 22,948.97337
Overall Steps per Second: 10,711.59051

Timestep Collection Time: 2.17892
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.66821

Cumulative Model Updates: 78,038
Cumulative Timesteps: 650,759,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,158.04036
Policy Entropy: 3.70435
Value Function Loss: 0.06778

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.57350
Value Function Update Magnitude: 0.76586

Collected Steps per Second: 22,989.92720
Overall Steps per Second: 10,821.36305

Timestep Collection Time: 2.17521
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.62123

Cumulative Model Updates: 78,044
Cumulative Timesteps: 650,809,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 650809926...
Checkpoint 650809926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,297.76741
Policy Entropy: 3.71269
Value Function Loss: 0.06710

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.53950
Value Function Update Magnitude: 0.82198

Collected Steps per Second: 22,426.97688
Overall Steps per Second: 10,629.20737

Timestep Collection Time: 2.22973
Timestep Consumption Time: 2.47486
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.70458

Cumulative Model Updates: 78,050
Cumulative Timesteps: 650,859,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,664.38441
Policy Entropy: 3.71479
Value Function Loss: 0.06454

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.85133

Collected Steps per Second: 22,987.15898
Overall Steps per Second: 10,841.03486

Timestep Collection Time: 2.17635
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.61469

Cumulative Model Updates: 78,056
Cumulative Timesteps: 650,909,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 650909960...
Checkpoint 650909960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,653.29002
Policy Entropy: 3.71204
Value Function Loss: 0.06541

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.61561
Value Function Update Magnitude: 0.86218

Collected Steps per Second: 22,481.81374
Overall Steps per Second: 10,669.16828

Timestep Collection Time: 2.22527
Timestep Consumption Time: 2.46376
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.68903

Cumulative Model Updates: 78,062
Cumulative Timesteps: 650,959,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,081.84626
Policy Entropy: 3.70809
Value Function Loss: 0.06676

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.86577

Collected Steps per Second: 22,806.36066
Overall Steps per Second: 10,696.89682

Timestep Collection Time: 2.19298
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.67556

Cumulative Model Updates: 78,068
Cumulative Timesteps: 651,010,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 651010002...
Checkpoint 651010002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,741.67419
Policy Entropy: 3.70254
Value Function Loss: 0.06462

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.56129
Value Function Update Magnitude: 0.85747

Collected Steps per Second: 22,494.37551
Overall Steps per Second: 10,672.37340

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.46251
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.68556

Cumulative Model Updates: 78,074
Cumulative Timesteps: 651,060,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,424.48735
Policy Entropy: 3.69544
Value Function Loss: 0.06699

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.62986
Value Function Update Magnitude: 0.83546

Collected Steps per Second: 22,554.73501
Overall Steps per Second: 10,627.96334

Timestep Collection Time: 2.21754
Timestep Consumption Time: 2.48854
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.70608

Cumulative Model Updates: 78,080
Cumulative Timesteps: 651,110,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 651110024...
Checkpoint 651110024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,601.70986
Policy Entropy: 3.70020
Value Function Loss: 0.06654

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.62195
Value Function Update Magnitude: 0.82289

Collected Steps per Second: 22,872.57701
Overall Steps per Second: 10,667.25880

Timestep Collection Time: 2.18602
Timestep Consumption Time: 2.50122
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.68724

Cumulative Model Updates: 78,086
Cumulative Timesteps: 651,160,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,756.69171
Policy Entropy: 3.69981
Value Function Loss: 0.06504

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.58511
Value Function Update Magnitude: 0.84515

Collected Steps per Second: 22,909.94817
Overall Steps per Second: 10,861.93698

Timestep Collection Time: 2.18324
Timestep Consumption Time: 2.42164
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.60489

Cumulative Model Updates: 78,092
Cumulative Timesteps: 651,210,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 651210042...
Checkpoint 651210042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,242.40694
Policy Entropy: 3.68949
Value Function Loss: 0.06631

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.80361

Collected Steps per Second: 22,562.98374
Overall Steps per Second: 10,687.97956

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.68059

Cumulative Model Updates: 78,098
Cumulative Timesteps: 651,260,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,334.95919
Policy Entropy: 3.66559
Value Function Loss: 0.07010

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.48930
Value Function Update Magnitude: 0.75849

Collected Steps per Second: 23,098.92935
Overall Steps per Second: 10,870.52987

Timestep Collection Time: 2.16564
Timestep Consumption Time: 2.43616
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.60180

Cumulative Model Updates: 78,104
Cumulative Timesteps: 651,310,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 651310092...
Checkpoint 651310092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,583.28268
Policy Entropy: 3.65129
Value Function Loss: 0.07496

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.52037
Value Function Update Magnitude: 0.74169

Collected Steps per Second: 22,474.18269
Overall Steps per Second: 10,650.34497

Timestep Collection Time: 2.22486
Timestep Consumption Time: 2.47001
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.69487

Cumulative Model Updates: 78,110
Cumulative Timesteps: 651,360,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,507.71044
Policy Entropy: 3.65328
Value Function Loss: 0.07627

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.66878
Value Function Update Magnitude: 0.72997

Collected Steps per Second: 22,174.32311
Overall Steps per Second: 10,832.51477

Timestep Collection Time: 2.25585
Timestep Consumption Time: 2.36191
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61776

Cumulative Model Updates: 78,116
Cumulative Timesteps: 651,410,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 651410116...
Checkpoint 651410116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,916.71445
Policy Entropy: 3.66713
Value Function Loss: 0.07584

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.70562
Value Function Update Magnitude: 0.69938

Collected Steps per Second: 21,979.47548
Overall Steps per Second: 10,733.14979

Timestep Collection Time: 2.27567
Timestep Consumption Time: 2.38447
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.66014

Cumulative Model Updates: 78,122
Cumulative Timesteps: 651,460,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,742.16476
Policy Entropy: 3.66654
Value Function Loss: 0.07766

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.74158
Value Function Update Magnitude: 0.74766

Collected Steps per Second: 22,363.58255
Overall Steps per Second: 10,856.33641

Timestep Collection Time: 2.23596
Timestep Consumption Time: 2.37002
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.60597

Cumulative Model Updates: 78,128
Cumulative Timesteps: 651,510,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 651510138...
Checkpoint 651510138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,734.55463
Policy Entropy: 3.66622
Value Function Loss: 0.07923

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.58141
Value Function Update Magnitude: 0.74317

Collected Steps per Second: 21,978.79184
Overall Steps per Second: 10,651.66085

Timestep Collection Time: 2.27528
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.69485

Cumulative Model Updates: 78,134
Cumulative Timesteps: 651,560,146

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,449.39978
Policy Entropy: 3.68648
Value Function Loss: 0.07617

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.53044
Value Function Update Magnitude: 0.73721

Collected Steps per Second: 22,201.73491
Overall Steps per Second: 10,584.03881

Timestep Collection Time: 2.25343
Timestep Consumption Time: 2.47350
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.72693

Cumulative Model Updates: 78,140
Cumulative Timesteps: 651,610,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 651610176...
Checkpoint 651610176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,541.76706
Policy Entropy: 3.69108
Value Function Loss: 0.07250

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.55692
Value Function Update Magnitude: 0.74137

Collected Steps per Second: 22,607.63097
Overall Steps per Second: 10,725.90863

Timestep Collection Time: 2.21270
Timestep Consumption Time: 2.45114
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.66385

Cumulative Model Updates: 78,146
Cumulative Timesteps: 651,660,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,067.69995
Policy Entropy: 3.69965
Value Function Loss: 0.06994

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.60240
Value Function Update Magnitude: 0.79640

Collected Steps per Second: 23,169.71765
Overall Steps per Second: 10,779.26669

Timestep Collection Time: 2.15808
Timestep Consumption Time: 2.48064
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.63872

Cumulative Model Updates: 78,152
Cumulative Timesteps: 651,710,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 651710202...
Checkpoint 651710202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,329.52897
Policy Entropy: 3.70335
Value Function Loss: 0.07116

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.58124
Value Function Update Magnitude: 0.82439

Collected Steps per Second: 22,787.24570
Overall Steps per Second: 10,783.87115

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.44264
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.63711

Cumulative Model Updates: 78,158
Cumulative Timesteps: 651,760,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,400.51325
Policy Entropy: 3.70327
Value Function Loss: 0.06965

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.86035

Collected Steps per Second: 22,894.33361
Overall Steps per Second: 10,687.07324

Timestep Collection Time: 2.18438
Timestep Consumption Time: 2.49510
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.67949

Cumulative Model Updates: 78,164
Cumulative Timesteps: 651,810,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 651810218...
Checkpoint 651810218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,968.51055
Policy Entropy: 3.71846
Value Function Loss: 0.06536

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.16708
Policy Update Magnitude: 0.49533
Value Function Update Magnitude: 0.82923

Collected Steps per Second: 22,605.97937
Overall Steps per Second: 10,611.23191

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.71331

Cumulative Model Updates: 78,170
Cumulative Timesteps: 651,860,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,408.09018
Policy Entropy: 3.73115
Value Function Loss: 0.06545

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.46254
Value Function Update Magnitude: 0.70113

Collected Steps per Second: 22,913.01842
Overall Steps per Second: 10,884.49642

Timestep Collection Time: 2.18330
Timestep Consumption Time: 2.41278
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.59608

Cumulative Model Updates: 78,176
Cumulative Timesteps: 651,910,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 651910258...
Checkpoint 651910258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,056.10661
Policy Entropy: 3.72501
Value Function Loss: 0.06636

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.54314
Value Function Update Magnitude: 0.62442

Collected Steps per Second: 22,653.99513
Overall Steps per Second: 10,654.84032

Timestep Collection Time: 2.20720
Timestep Consumption Time: 2.48569
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.69289

Cumulative Model Updates: 78,182
Cumulative Timesteps: 651,960,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,093.59729
Policy Entropy: 3.72188
Value Function Loss: 0.06561

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.58528
Value Function Update Magnitude: 0.72549

Collected Steps per Second: 22,526.48299
Overall Steps per Second: 10,596.47079

Timestep Collection Time: 2.22014
Timestep Consumption Time: 2.49954
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.71968

Cumulative Model Updates: 78,188
Cumulative Timesteps: 652,010,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 652010272...
Checkpoint 652010272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,783.02554
Policy Entropy: 3.70234
Value Function Loss: 0.06351

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06150
Policy Update Magnitude: 0.66979
Value Function Update Magnitude: 0.78230

Collected Steps per Second: 22,475.73553
Overall Steps per Second: 10,591.14631

Timestep Collection Time: 2.22462
Timestep Consumption Time: 2.49630
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.72092

Cumulative Model Updates: 78,194
Cumulative Timesteps: 652,060,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,586.77702
Policy Entropy: 3.69109
Value Function Loss: 0.06472

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.74463
Value Function Update Magnitude: 0.80727

Collected Steps per Second: 22,881.93241
Overall Steps per Second: 10,807.19806

Timestep Collection Time: 2.18627
Timestep Consumption Time: 2.44269
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62895

Cumulative Model Updates: 78,200
Cumulative Timesteps: 652,110,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 652110298...
Checkpoint 652110298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,547.07167
Policy Entropy: 3.69048
Value Function Loss: 0.06833

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07721
Policy Update Magnitude: 0.74380
Value Function Update Magnitude: 0.78365

Collected Steps per Second: 22,433.16653
Overall Steps per Second: 10,631.76501

Timestep Collection Time: 2.22947
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.70420

Cumulative Model Updates: 78,206
Cumulative Timesteps: 652,160,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,802.79588
Policy Entropy: 3.68718
Value Function Loss: 0.07247

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.71630
Value Function Update Magnitude: 0.71654

Collected Steps per Second: 22,909.38256
Overall Steps per Second: 10,861.00974

Timestep Collection Time: 2.18304
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.60473

Cumulative Model Updates: 78,212
Cumulative Timesteps: 652,210,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 652210324...
Checkpoint 652210324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,747.52387
Policy Entropy: 3.68304
Value Function Loss: 0.07211

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07317
Policy Update Magnitude: 0.71360
Value Function Update Magnitude: 0.66291

Collected Steps per Second: 22,424.18735
Overall Steps per Second: 10,771.72566

Timestep Collection Time: 2.23063
Timestep Consumption Time: 2.41301
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.64364

Cumulative Model Updates: 78,218
Cumulative Timesteps: 652,260,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,079.07254
Policy Entropy: 3.67881
Value Function Loss: 0.07057

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.59438
Value Function Update Magnitude: 0.68159

Collected Steps per Second: 23,168.07493
Overall Steps per Second: 10,838.26026

Timestep Collection Time: 2.15918
Timestep Consumption Time: 2.45632
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.61550

Cumulative Model Updates: 78,224
Cumulative Timesteps: 652,310,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 652310368...
Checkpoint 652310368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,419.46146
Policy Entropy: 3.67074
Value Function Loss: 0.06825

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.44646
Value Function Update Magnitude: 0.76492

Collected Steps per Second: 22,647.56880
Overall Steps per Second: 10,638.39539

Timestep Collection Time: 2.20871
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.70202

Cumulative Model Updates: 78,230
Cumulative Timesteps: 652,360,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,358.83782
Policy Entropy: 3.68071
Value Function Loss: 0.06912

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.42688
Value Function Update Magnitude: 0.81038

Collected Steps per Second: 22,769.90706
Overall Steps per Second: 10,813.74244

Timestep Collection Time: 2.19632
Timestep Consumption Time: 2.42835
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.62467

Cumulative Model Updates: 78,236
Cumulative Timesteps: 652,410,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 652410400...
Checkpoint 652410400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,096.66245
Policy Entropy: 3.67738
Value Function Loss: 0.06955

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.43498
Value Function Update Magnitude: 0.84028

Collected Steps per Second: 21,938.66896
Overall Steps per Second: 10,745.32942

Timestep Collection Time: 2.27917
Timestep Consumption Time: 2.37420
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.65337

Cumulative Model Updates: 78,242
Cumulative Timesteps: 652,460,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,368.22741
Policy Entropy: 3.68210
Value Function Loss: 0.07002

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.45473
Value Function Update Magnitude: 0.87799

Collected Steps per Second: 22,307.90196
Overall Steps per Second: 10,870.84462

Timestep Collection Time: 2.24145
Timestep Consumption Time: 2.35819
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.59964

Cumulative Model Updates: 78,248
Cumulative Timesteps: 652,510,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 652510404...
Checkpoint 652510404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.98521
Policy Entropy: 3.68614
Value Function Loss: 0.06949

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.45652
Value Function Update Magnitude: 0.88770

Collected Steps per Second: 22,097.66052
Overall Steps per Second: 10,639.65065

Timestep Collection Time: 2.26314
Timestep Consumption Time: 2.43721
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.70034

Cumulative Model Updates: 78,254
Cumulative Timesteps: 652,560,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,238.14904
Policy Entropy: 3.68755
Value Function Loss: 0.06975

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.45993
Value Function Update Magnitude: 0.88663

Collected Steps per Second: 21,797.78498
Overall Steps per Second: 10,621.01907

Timestep Collection Time: 2.29390
Timestep Consumption Time: 2.41393
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.70783

Cumulative Model Updates: 78,260
Cumulative Timesteps: 652,610,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 652610416...
Checkpoint 652610416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,181.27616
Policy Entropy: 3.69959
Value Function Loss: 0.06866

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07312
Policy Update Magnitude: 0.49530
Value Function Update Magnitude: 0.88911

Collected Steps per Second: 22,157.29536
Overall Steps per Second: 10,862.67246

Timestep Collection Time: 2.25786
Timestep Consumption Time: 2.34764
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.60550

Cumulative Model Updates: 78,266
Cumulative Timesteps: 652,660,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,746.72264
Policy Entropy: 3.68930
Value Function Loss: 0.06845

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.58896
Value Function Update Magnitude: 0.86734

Collected Steps per Second: 22,211.72501
Overall Steps per Second: 10,517.76767

Timestep Collection Time: 2.25160
Timestep Consumption Time: 2.50340
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.75500

Cumulative Model Updates: 78,272
Cumulative Timesteps: 652,710,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 652710456...
Checkpoint 652710456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,840.61380
Policy Entropy: 3.68516
Value Function Loss: 0.06864

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.55606
Value Function Update Magnitude: 0.79925

Collected Steps per Second: 22,547.63184
Overall Steps per Second: 10,643.46844

Timestep Collection Time: 2.21904
Timestep Consumption Time: 2.48188
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.70091

Cumulative Model Updates: 78,278
Cumulative Timesteps: 652,760,490

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,873.37599
Policy Entropy: 3.67597
Value Function Loss: 0.07070

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.51925
Value Function Update Magnitude: 0.70859

Collected Steps per Second: 22,733.97190
Overall Steps per Second: 10,876.74752

Timestep Collection Time: 2.20041
Timestep Consumption Time: 2.39876
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.59917

Cumulative Model Updates: 78,284
Cumulative Timesteps: 652,810,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 652810514...
Checkpoint 652810514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,124.48260
Policy Entropy: 3.67568
Value Function Loss: 0.07344

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11190
Policy Update Magnitude: 0.45524
Value Function Update Magnitude: 0.71086

Collected Steps per Second: 22,511.02503
Overall Steps per Second: 10,686.82730

Timestep Collection Time: 2.22140
Timestep Consumption Time: 2.45782
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.67922

Cumulative Model Updates: 78,290
Cumulative Timesteps: 652,860,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,187.91450
Policy Entropy: 3.67354
Value Function Loss: 0.07520

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.45560
Value Function Update Magnitude: 0.73784

Collected Steps per Second: 22,784.92480
Overall Steps per Second: 10,797.30263

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.43635
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.63079

Cumulative Model Updates: 78,296
Cumulative Timesteps: 652,910,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 652910520...
Checkpoint 652910520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,810.11623
Policy Entropy: 3.67665
Value Function Loss: 0.07525

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.48310
Value Function Update Magnitude: 0.76780

Collected Steps per Second: 22,335.24021
Overall Steps per Second: 10,719.15572

Timestep Collection Time: 2.23996
Timestep Consumption Time: 2.42739
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.66735

Cumulative Model Updates: 78,302
Cumulative Timesteps: 652,960,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,663.10205
Policy Entropy: 3.67307
Value Function Loss: 0.07088

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.55020
Value Function Update Magnitude: 0.78701

Collected Steps per Second: 22,571.70789
Overall Steps per Second: 10,625.87739

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.49093
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.70662

Cumulative Model Updates: 78,308
Cumulative Timesteps: 653,010,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 653010562...
Checkpoint 653010562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,838.20596
Policy Entropy: 3.66857
Value Function Loss: 0.07004

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07007
Policy Update Magnitude: 0.65811
Value Function Update Magnitude: 0.81510

Collected Steps per Second: 22,529.20335
Overall Steps per Second: 10,624.67235

Timestep Collection Time: 2.21961
Timestep Consumption Time: 2.48698
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.70659

Cumulative Model Updates: 78,314
Cumulative Timesteps: 653,060,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,905.07600
Policy Entropy: 3.65885
Value Function Loss: 0.07043

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.67877
Value Function Update Magnitude: 0.80426

Collected Steps per Second: 22,970.44528
Overall Steps per Second: 10,778.90847

Timestep Collection Time: 2.17723
Timestep Consumption Time: 2.46257
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.63980

Cumulative Model Updates: 78,320
Cumulative Timesteps: 653,110,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 653110580...
Checkpoint 653110580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,238.82797
Policy Entropy: 3.67060
Value Function Loss: 0.07290

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.65514
Value Function Update Magnitude: 0.76270

Collected Steps per Second: 22,580.38190
Overall Steps per Second: 10,654.08600

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.47991
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.69529

Cumulative Model Updates: 78,326
Cumulative Timesteps: 653,160,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,004.13256
Policy Entropy: 3.67291
Value Function Loss: 0.07224

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.84174

Collected Steps per Second: 22,792.74734
Overall Steps per Second: 10,835.86911

Timestep Collection Time: 2.19412
Timestep Consumption Time: 2.42111
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.61523

Cumulative Model Updates: 78,332
Cumulative Timesteps: 653,210,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 653210614...
Checkpoint 653210614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,561.81404
Policy Entropy: 3.68268
Value Function Loss: 0.07054

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.48295
Value Function Update Magnitude: 0.84305

Collected Steps per Second: 22,514.37168
Overall Steps per Second: 10,764.64707

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.42432
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.64539

Cumulative Model Updates: 78,338
Cumulative Timesteps: 653,260,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,420.92073
Policy Entropy: 3.67365
Value Function Loss: 0.07254

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.49870
Value Function Update Magnitude: 0.81908

Collected Steps per Second: 23,082.95837
Overall Steps per Second: 10,824.51804

Timestep Collection Time: 2.16636
Timestep Consumption Time: 2.45334
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.61970

Cumulative Model Updates: 78,344
Cumulative Timesteps: 653,310,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 653310626...
Checkpoint 653310626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,820.19898
Policy Entropy: 3.66371
Value Function Loss: 0.07511

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.51815
Value Function Update Magnitude: 0.72959

Collected Steps per Second: 22,601.83605
Overall Steps per Second: 10,653.30129

Timestep Collection Time: 2.21265
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.69432

Cumulative Model Updates: 78,350
Cumulative Timesteps: 653,360,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,073.49724
Policy Entropy: 3.66245
Value Function Loss: 0.07517

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.76654

Collected Steps per Second: 22,111.68004
Overall Steps per Second: 10,831.15478

Timestep Collection Time: 2.26152
Timestep Consumption Time: 2.35535
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.61687

Cumulative Model Updates: 78,356
Cumulative Timesteps: 653,410,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 653410642...
Checkpoint 653410642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,106.15697
Policy Entropy: 3.66565
Value Function Loss: 0.07144

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.62356
Value Function Update Magnitude: 0.83723

Collected Steps per Second: 21,681.29733
Overall Steps per Second: 10,790.18665

Timestep Collection Time: 2.30641
Timestep Consumption Time: 2.32798
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.63440

Cumulative Model Updates: 78,362
Cumulative Timesteps: 653,460,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,566.40930
Policy Entropy: 3.65581
Value Function Loss: 0.06940

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.56178
Value Function Update Magnitude: 0.78899

Collected Steps per Second: 22,094.40172
Overall Steps per Second: 10,861.53661

Timestep Collection Time: 2.26347
Timestep Consumption Time: 2.34085
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.60432

Cumulative Model Updates: 78,368
Cumulative Timesteps: 653,510,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 653510658...
Checkpoint 653510658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,980.86895
Policy Entropy: 3.66528
Value Function Loss: 0.07442

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.59003
Value Function Update Magnitude: 0.78097

Collected Steps per Second: 22,032.39284
Overall Steps per Second: 10,644.84963

Timestep Collection Time: 2.26948
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.69730

Cumulative Model Updates: 78,374
Cumulative Timesteps: 653,560,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,997.68550
Policy Entropy: 3.65846
Value Function Loss: 0.07562

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.66292
Value Function Update Magnitude: 0.78314

Collected Steps per Second: 22,225.87159
Overall Steps per Second: 10,845.35959

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.36167
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.61230

Cumulative Model Updates: 78,380
Cumulative Timesteps: 653,610,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 653610682...
Checkpoint 653610682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,348.12687
Policy Entropy: 3.67034
Value Function Loss: 0.07781

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.66697
Value Function Update Magnitude: 0.81569

Collected Steps per Second: 21,947.34682
Overall Steps per Second: 10,677.49382

Timestep Collection Time: 2.27818
Timestep Consumption Time: 2.40457
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.68275

Cumulative Model Updates: 78,386
Cumulative Timesteps: 653,660,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,598.90288
Policy Entropy: 3.67259
Value Function Loss: 0.07774

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.67218
Value Function Update Magnitude: 0.82308

Collected Steps per Second: 22,981.18434
Overall Steps per Second: 10,891.19443

Timestep Collection Time: 2.17595
Timestep Consumption Time: 2.41546
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.59142

Cumulative Model Updates: 78,392
Cumulative Timesteps: 653,710,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 653710688...
Checkpoint 653710688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,014.35855
Policy Entropy: 3.66694
Value Function Loss: 0.08072

Mean KL Divergence: 0.02192
SB3 Clip Fraction: 0.17667
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.80603

Collected Steps per Second: 22,982.02740
Overall Steps per Second: 10,783.04306

Timestep Collection Time: 2.17666
Timestep Consumption Time: 2.46248
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.63914

Cumulative Model Updates: 78,398
Cumulative Timesteps: 653,760,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,798.64160
Policy Entropy: 3.65730
Value Function Loss: 0.08202

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.44975
Value Function Update Magnitude: 0.73401

Collected Steps per Second: 22,986.44288
Overall Steps per Second: 10,780.51298

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.46418
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.64060

Cumulative Model Updates: 78,404
Cumulative Timesteps: 653,810,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 653810740...
Checkpoint 653810740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,114.52916
Policy Entropy: 3.64319
Value Function Loss: 0.07918

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.16850
Policy Update Magnitude: 0.40600
Value Function Update Magnitude: 0.82037

Collected Steps per Second: 22,638.70631
Overall Steps per Second: 10,700.79146

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.46513
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.67479

Cumulative Model Updates: 78,410
Cumulative Timesteps: 653,860,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,012.97371
Policy Entropy: 3.65195
Value Function Loss: 0.07497

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.40335
Value Function Update Magnitude: 0.85997

Collected Steps per Second: 22,707.58129
Overall Steps per Second: 10,770.05182

Timestep Collection Time: 2.20296
Timestep Consumption Time: 2.44177
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.64473

Cumulative Model Updates: 78,416
Cumulative Timesteps: 653,910,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 653910788...
Checkpoint 653910788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,402.28147
Policy Entropy: 3.67526
Value Function Loss: 0.07056

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15259
Policy Update Magnitude: 0.41634
Value Function Update Magnitude: 0.75577

Collected Steps per Second: 22,778.02003
Overall Steps per Second: 10,729.42649

Timestep Collection Time: 2.19721
Timestep Consumption Time: 2.46735
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.66455

Cumulative Model Updates: 78,422
Cumulative Timesteps: 653,960,836

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.29244
Policy Entropy: 3.69623
Value Function Loss: 0.06820

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.43025
Value Function Update Magnitude: 0.71174

Collected Steps per Second: 22,532.70425
Overall Steps per Second: 10,791.19591

Timestep Collection Time: 2.21935
Timestep Consumption Time: 2.41480
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.63415

Cumulative Model Updates: 78,428
Cumulative Timesteps: 654,010,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 654010844...
Checkpoint 654010844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,227.96015
Policy Entropy: 3.68644
Value Function Loss: 0.06551

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.49875
Value Function Update Magnitude: 0.68667

Collected Steps per Second: 22,609.60371
Overall Steps per Second: 10,808.24506

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.41658
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.62980

Cumulative Model Updates: 78,434
Cumulative Timesteps: 654,060,884

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,606.36079
Policy Entropy: 3.69101
Value Function Loss: 0.06388

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.53463
Value Function Update Magnitude: 0.67119

Collected Steps per Second: 22,838.71675
Overall Steps per Second: 10,838.45052

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.61357

Cumulative Model Updates: 78,440
Cumulative Timesteps: 654,110,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 654110888...
Checkpoint 654110888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,873.40725
Policy Entropy: 3.67938
Value Function Loss: 0.06187

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.63204

Collected Steps per Second: 22,527.72901
Overall Steps per Second: 10,646.36359

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.69851

Cumulative Model Updates: 78,446
Cumulative Timesteps: 654,160,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,430.40553
Policy Entropy: 3.68695
Value Function Loss: 0.06257

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08633
Policy Update Magnitude: 0.60492
Value Function Update Magnitude: 0.63480

Collected Steps per Second: 22,804.27284
Overall Steps per Second: 10,828.21190

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.42645
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.62034

Cumulative Model Updates: 78,452
Cumulative Timesteps: 654,210,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 654210940...
Checkpoint 654210940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,584.47696
Policy Entropy: 3.68801
Value Function Loss: 0.06127

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.55629
Value Function Update Magnitude: 0.70693

Collected Steps per Second: 22,561.44530
Overall Steps per Second: 10,781.12341

Timestep Collection Time: 2.21697
Timestep Consumption Time: 2.42244
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.63941

Cumulative Model Updates: 78,458
Cumulative Timesteps: 654,260,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,255.05920
Policy Entropy: 3.69997
Value Function Loss: 0.06235

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.63060
Value Function Update Magnitude: 0.76934

Collected Steps per Second: 22,979.91670
Overall Steps per Second: 10,809.66893

Timestep Collection Time: 2.17599
Timestep Consumption Time: 2.44987
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.62586

Cumulative Model Updates: 78,464
Cumulative Timesteps: 654,310,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 654310962...
Checkpoint 654310962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,362.78035
Policy Entropy: 3.69973
Value Function Loss: 0.06318

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.68482
Value Function Update Magnitude: 0.76926

Collected Steps per Second: 22,591.75088
Overall Steps per Second: 10,660.21820

Timestep Collection Time: 2.21444
Timestep Consumption Time: 2.47853
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.69296

Cumulative Model Updates: 78,470
Cumulative Timesteps: 654,360,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,038.98669
Policy Entropy: 3.70199
Value Function Loss: 0.06444

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14824
Policy Update Magnitude: 0.58830
Value Function Update Magnitude: 0.75164

Collected Steps per Second: 22,035.23770
Overall Steps per Second: 10,451.19626

Timestep Collection Time: 2.26918
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.78433

Cumulative Model Updates: 78,476
Cumulative Timesteps: 654,410,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 654410992...
Checkpoint 654410992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,145.05839
Policy Entropy: 3.70953
Value Function Loss: 0.06864

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.43422
Value Function Update Magnitude: 0.72984

Collected Steps per Second: 22,762.62232
Overall Steps per Second: 10,645.38577

Timestep Collection Time: 2.19676
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.69725

Cumulative Model Updates: 78,482
Cumulative Timesteps: 654,460,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,326.83991
Policy Entropy: 3.71312
Value Function Loss: 0.06901

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.50188
Value Function Update Magnitude: 0.78164

Collected Steps per Second: 22,921.16973
Overall Steps per Second: 10,848.91655

Timestep Collection Time: 2.18148
Timestep Consumption Time: 2.42746
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.60894

Cumulative Model Updates: 78,488
Cumulative Timesteps: 654,510,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 654510998...
Checkpoint 654510998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,856.09240
Policy Entropy: 3.70919
Value Function Loss: 0.07014

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.82587

Collected Steps per Second: 22,439.75750
Overall Steps per Second: 10,683.25804

Timestep Collection Time: 2.22828
Timestep Consumption Time: 2.45213
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.68041

Cumulative Model Updates: 78,494
Cumulative Timesteps: 654,561,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,390.38283
Policy Entropy: 3.70775
Value Function Loss: 0.07011

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.51040
Value Function Update Magnitude: 0.77795

Collected Steps per Second: 22,857.70696
Overall Steps per Second: 10,821.45169

Timestep Collection Time: 2.18806
Timestep Consumption Time: 2.43369
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62175

Cumulative Model Updates: 78,500
Cumulative Timesteps: 654,611,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 654611014...
Checkpoint 654611014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,776.29455
Policy Entropy: 3.70773
Value Function Loss: 0.06842

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.54940
Value Function Update Magnitude: 0.83314

Collected Steps per Second: 22,527.40795
Overall Steps per Second: 10,780.89573

Timestep Collection Time: 2.21978
Timestep Consumption Time: 2.41861
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.63839

Cumulative Model Updates: 78,506
Cumulative Timesteps: 654,661,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,697.13709
Policy Entropy: 3.71197
Value Function Loss: 0.06692

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.51328
Value Function Update Magnitude: 0.87958

Collected Steps per Second: 22,452.33649
Overall Steps per Second: 10,555.71216

Timestep Collection Time: 2.22703
Timestep Consumption Time: 2.50993
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.73696

Cumulative Model Updates: 78,512
Cumulative Timesteps: 654,711,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 654711022...
Checkpoint 654711022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,626.14816
Policy Entropy: 3.72182
Value Function Loss: 0.06611

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.45043
Value Function Update Magnitude: 0.81381

Collected Steps per Second: 22,753.13063
Overall Steps per Second: 10,679.89396

Timestep Collection Time: 2.19838
Timestep Consumption Time: 2.48519
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.68357

Cumulative Model Updates: 78,518
Cumulative Timesteps: 654,761,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,015.68342
Policy Entropy: 3.72272
Value Function Loss: 0.06774

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.53607
Value Function Update Magnitude: 0.77338

Collected Steps per Second: 22,835.36463
Overall Steps per Second: 10,708.98957

Timestep Collection Time: 2.19081
Timestep Consumption Time: 2.48078
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.67159

Cumulative Model Updates: 78,524
Cumulative Timesteps: 654,811,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 654811070...
Checkpoint 654811070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,144.02434
Policy Entropy: 3.72289
Value Function Loss: 0.06949

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.51927
Value Function Update Magnitude: 0.73898

Collected Steps per Second: 22,458.98639
Overall Steps per Second: 10,661.57270

Timestep Collection Time: 2.22655
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.69030

Cumulative Model Updates: 78,530
Cumulative Timesteps: 654,861,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,179.46707
Policy Entropy: 3.72237
Value Function Loss: 0.07088

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.47759
Value Function Update Magnitude: 0.72575

Collected Steps per Second: 22,653.05974
Overall Steps per Second: 10,789.19816

Timestep Collection Time: 2.20836
Timestep Consumption Time: 2.42832
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.63667

Cumulative Model Updates: 78,536
Cumulative Timesteps: 654,911,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 654911102...
Checkpoint 654911102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,615.79973
Policy Entropy: 3.72570
Value Function Loss: 0.06850

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.44851
Value Function Update Magnitude: 0.77442

Collected Steps per Second: 22,387.96420
Overall Steps per Second: 10,694.78182

Timestep Collection Time: 2.23477
Timestep Consumption Time: 2.44340
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.67817

Cumulative Model Updates: 78,542
Cumulative Timesteps: 654,961,134

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,011.71021
Policy Entropy: 3.71195
Value Function Loss: 0.06743

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.48539
Value Function Update Magnitude: 0.84181

Collected Steps per Second: 22,652.19973
Overall Steps per Second: 10,644.34490

Timestep Collection Time: 2.20782
Timestep Consumption Time: 2.49064
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.69846

Cumulative Model Updates: 78,548
Cumulative Timesteps: 655,011,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 655011146...
Checkpoint 655011146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,707.12980
Policy Entropy: 3.70262
Value Function Loss: 0.06925

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.50087
Value Function Update Magnitude: 0.78028

Collected Steps per Second: 22,436.97235
Overall Steps per Second: 10,586.81266

Timestep Collection Time: 2.22855
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.72305

Cumulative Model Updates: 78,554
Cumulative Timesteps: 655,061,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,147.91197
Policy Entropy: 3.69793
Value Function Loss: 0.07107

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.48296
Value Function Update Magnitude: 0.72476

Collected Steps per Second: 22,783.86766
Overall Steps per Second: 10,780.53608

Timestep Collection Time: 2.19462
Timestep Consumption Time: 2.44355
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.63817

Cumulative Model Updates: 78,560
Cumulative Timesteps: 655,111,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 655111150...
Checkpoint 655111150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,418.79059
Policy Entropy: 3.70258
Value Function Loss: 0.07344

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.46676
Value Function Update Magnitude: 0.68291

Collected Steps per Second: 22,665.65665
Overall Steps per Second: 10,645.55045

Timestep Collection Time: 2.20722
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.69943

Cumulative Model Updates: 78,566
Cumulative Timesteps: 655,161,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,737.36302
Policy Entropy: 3.70918
Value Function Loss: 0.07196

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.46782
Value Function Update Magnitude: 0.64521

Collected Steps per Second: 22,774.74927
Overall Steps per Second: 10,844.31648

Timestep Collection Time: 2.19620
Timestep Consumption Time: 2.41617
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.61237

Cumulative Model Updates: 78,572
Cumulative Timesteps: 655,211,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 655211196...
Checkpoint 655211196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,615.74317
Policy Entropy: 3.69097
Value Function Loss: 0.07522

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.51251
Value Function Update Magnitude: 0.59715

Collected Steps per Second: 22,662.96706
Overall Steps per Second: 10,700.14417

Timestep Collection Time: 2.20668
Timestep Consumption Time: 2.46709
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.67377

Cumulative Model Updates: 78,578
Cumulative Timesteps: 655,261,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,340.49932
Policy Entropy: 3.69997
Value Function Loss: 0.07270

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.51359
Value Function Update Magnitude: 0.66547

Collected Steps per Second: 22,580.85490
Overall Steps per Second: 10,630.50117

Timestep Collection Time: 2.21471
Timestep Consumption Time: 2.48968
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.70439

Cumulative Model Updates: 78,584
Cumulative Timesteps: 655,311,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 655311216...
Checkpoint 655311216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,562.54743
Policy Entropy: 3.68860
Value Function Loss: 0.07428

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.48502
Value Function Update Magnitude: 0.68113

Collected Steps per Second: 22,684.72562
Overall Steps per Second: 10,669.15789

Timestep Collection Time: 2.20510
Timestep Consumption Time: 2.48337
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.68847

Cumulative Model Updates: 78,590
Cumulative Timesteps: 655,361,238

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,691.16339
Policy Entropy: 3.69500
Value Function Loss: 0.07193

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.50348
Value Function Update Magnitude: 0.73116

Collected Steps per Second: 22,861.18097
Overall Steps per Second: 10,754.89080

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.65035

Cumulative Model Updates: 78,596
Cumulative Timesteps: 655,411,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 655411252...
Checkpoint 655411252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,334.70623
Policy Entropy: 3.69170
Value Function Loss: 0.07326

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.50401
Value Function Update Magnitude: 0.82756

Collected Steps per Second: 22,521.64412
Overall Steps per Second: 10,629.12256

Timestep Collection Time: 2.22044
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.70481

Cumulative Model Updates: 78,602
Cumulative Timesteps: 655,461,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,404.03491
Policy Entropy: 3.69382
Value Function Loss: 0.07217

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.47272
Value Function Update Magnitude: 0.85362

Collected Steps per Second: 22,707.05614
Overall Steps per Second: 10,773.22478

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.43967
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.64206

Cumulative Model Updates: 78,608
Cumulative Timesteps: 655,511,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 655511270...
Checkpoint 655511270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,912.89163
Policy Entropy: 3.70047
Value Function Loss: 0.07222

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.47349
Value Function Update Magnitude: 0.84167

Collected Steps per Second: 22,583.64521
Overall Steps per Second: 10,781.35748

Timestep Collection Time: 2.21523
Timestep Consumption Time: 2.42500
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.64023

Cumulative Model Updates: 78,614
Cumulative Timesteps: 655,561,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,714.87803
Policy Entropy: 3.70306
Value Function Loss: 0.07061

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.46567
Value Function Update Magnitude: 0.83354

Collected Steps per Second: 22,597.24097
Overall Steps per Second: 10,625.63655

Timestep Collection Time: 2.21399
Timestep Consumption Time: 2.49444
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.70842

Cumulative Model Updates: 78,620
Cumulative Timesteps: 655,611,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 655611328...
Checkpoint 655611328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,447.67226
Policy Entropy: 3.67907
Value Function Loss: 0.07204

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.49146
Value Function Update Magnitude: 0.82105

Collected Steps per Second: 22,621.33452
Overall Steps per Second: 10,805.98859

Timestep Collection Time: 2.21145
Timestep Consumption Time: 2.41802
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.62947

Cumulative Model Updates: 78,626
Cumulative Timesteps: 655,661,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,976.00783
Policy Entropy: 3.67204
Value Function Loss: 0.07509

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.47608
Value Function Update Magnitude: 0.82342

Collected Steps per Second: 22,972.57283
Overall Steps per Second: 10,682.41766

Timestep Collection Time: 2.17694
Timestep Consumption Time: 2.50458
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.68152

Cumulative Model Updates: 78,632
Cumulative Timesteps: 655,711,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 655711364...
Checkpoint 655711364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,857.82349
Policy Entropy: 3.67354
Value Function Loss: 0.07438

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.49890
Value Function Update Magnitude: 0.81462

Collected Steps per Second: 22,787.23363
Overall Steps per Second: 10,727.70983

Timestep Collection Time: 2.19465
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.66176

Cumulative Model Updates: 78,638
Cumulative Timesteps: 655,761,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,056.14119
Policy Entropy: 3.67542
Value Function Loss: 0.07517

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.53294
Value Function Update Magnitude: 0.85777

Collected Steps per Second: 23,015.85242
Overall Steps per Second: 10,680.64755

Timestep Collection Time: 2.17337
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.68342

Cumulative Model Updates: 78,644
Cumulative Timesteps: 655,811,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 655811396...
Checkpoint 655811396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,659.84077
Policy Entropy: 3.67137
Value Function Loss: 0.07239

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.52541
Value Function Update Magnitude: 0.82432

Collected Steps per Second: 22,062.88213
Overall Steps per Second: 10,659.21252

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.42472
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.69115

Cumulative Model Updates: 78,650
Cumulative Timesteps: 655,861,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,931.70796
Policy Entropy: 3.65260
Value Function Loss: 0.07447

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.48402
Value Function Update Magnitude: 0.67985

Collected Steps per Second: 22,364.42940
Overall Steps per Second: 10,907.84329

Timestep Collection Time: 2.23641
Timestep Consumption Time: 2.34892
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.58532

Cumulative Model Updates: 78,656
Cumulative Timesteps: 655,911,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 655911416...
Checkpoint 655911416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,516.79552
Policy Entropy: 3.66342
Value Function Loss: 0.07232

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.47479
Value Function Update Magnitude: 0.71234

Collected Steps per Second: 22,050.52217
Overall Steps per Second: 10,649.59279

Timestep Collection Time: 2.26770
Timestep Consumption Time: 2.42769
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.69539

Cumulative Model Updates: 78,662
Cumulative Timesteps: 655,961,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,780.00299
Policy Entropy: 3.65330
Value Function Loss: 0.07141

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.42390
Value Function Update Magnitude: 0.79177

Collected Steps per Second: 22,004.03972
Overall Steps per Second: 10,804.62453

Timestep Collection Time: 2.27258
Timestep Consumption Time: 2.35562
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.62820

Cumulative Model Updates: 78,668
Cumulative Timesteps: 656,011,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 656011426...
Checkpoint 656011426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,842.46715
Policy Entropy: 3.65796
Value Function Loss: 0.07080

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.44063
Value Function Update Magnitude: 0.83395

Collected Steps per Second: 21,802.04902
Overall Steps per Second: 10,770.11907

Timestep Collection Time: 2.29410
Timestep Consumption Time: 2.34986
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.64396

Cumulative Model Updates: 78,674
Cumulative Timesteps: 656,061,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,077.61102
Policy Entropy: 3.63904
Value Function Loss: 0.07375

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.47632
Value Function Update Magnitude: 0.77367

Collected Steps per Second: 22,140.19593
Overall Steps per Second: 10,578.71495

Timestep Collection Time: 2.25987
Timestep Consumption Time: 2.46981
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.72969

Cumulative Model Updates: 78,680
Cumulative Timesteps: 656,111,476

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 656111476...
Checkpoint 656111476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,447.36320
Policy Entropy: 3.65366
Value Function Loss: 0.07597

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.52637
Value Function Update Magnitude: 0.70498

Collected Steps per Second: 22,405.86866
Overall Steps per Second: 10,670.17039

Timestep Collection Time: 2.23299
Timestep Consumption Time: 2.45597
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.68896

Cumulative Model Updates: 78,686
Cumulative Timesteps: 656,161,508

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,292.90716
Policy Entropy: 3.65614
Value Function Loss: 0.07540

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.56980
Value Function Update Magnitude: 0.80232

Collected Steps per Second: 22,805.40812
Overall Steps per Second: 10,709.59103

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.66965

Cumulative Model Updates: 78,692
Cumulative Timesteps: 656,211,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 656211518...
Checkpoint 656211518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,194.84483
Policy Entropy: 3.65225
Value Function Loss: 0.07537

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.57461
Value Function Update Magnitude: 0.86141

Collected Steps per Second: 22,508.80381
Overall Steps per Second: 10,652.27465

Timestep Collection Time: 2.22242
Timestep Consumption Time: 2.47367
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.69609

Cumulative Model Updates: 78,698
Cumulative Timesteps: 656,261,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,272.67555
Policy Entropy: 3.65359
Value Function Loss: 0.07591

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.49379
Value Function Update Magnitude: 0.84330

Collected Steps per Second: 22,692.11785
Overall Steps per Second: 10,847.06977

Timestep Collection Time: 2.20350
Timestep Consumption Time: 2.40623
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.60972

Cumulative Model Updates: 78,704
Cumulative Timesteps: 656,311,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 656311544...
Checkpoint 656311544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,607.23415
Policy Entropy: 3.64197
Value Function Loss: 0.07618

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11231
Policy Update Magnitude: 0.49268
Value Function Update Magnitude: 0.72229

Collected Steps per Second: 22,489.85093
Overall Steps per Second: 10,681.13023

Timestep Collection Time: 2.22429
Timestep Consumption Time: 2.45911
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.68340

Cumulative Model Updates: 78,710
Cumulative Timesteps: 656,361,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,095.08142
Policy Entropy: 3.65496
Value Function Loss: 0.07447

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.68253

Collected Steps per Second: 23,002.25452
Overall Steps per Second: 10,848.18883

Timestep Collection Time: 2.17466
Timestep Consumption Time: 2.43644
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.61109

Cumulative Model Updates: 78,716
Cumulative Timesteps: 656,411,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 656411590...
Checkpoint 656411590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,800.39422
Policy Entropy: 3.66827
Value Function Loss: 0.07336

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.58292
Value Function Update Magnitude: 0.70095

Collected Steps per Second: 22,538.51509
Overall Steps per Second: 10,718.20528

Timestep Collection Time: 2.21851
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.66515

Cumulative Model Updates: 78,722
Cumulative Timesteps: 656,461,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,549.11395
Policy Entropy: 3.68232
Value Function Loss: 0.07010

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.58042
Value Function Update Magnitude: 0.70636

Collected Steps per Second: 22,550.80150
Overall Steps per Second: 10,794.33946

Timestep Collection Time: 2.21872
Timestep Consumption Time: 2.41648
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.63521

Cumulative Model Updates: 78,728
Cumulative Timesteps: 656,511,626

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 656511626...
Checkpoint 656511626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,288.45044
Policy Entropy: 3.68034
Value Function Loss: 0.06621

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.62845
Value Function Update Magnitude: 0.68305

Collected Steps per Second: 22,457.03130
Overall Steps per Second: 10,707.21053

Timestep Collection Time: 2.22683
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.67050

Cumulative Model Updates: 78,734
Cumulative Timesteps: 656,561,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,905.76924
Policy Entropy: 3.66347
Value Function Loss: 0.06608

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.60292
Value Function Update Magnitude: 0.64515

Collected Steps per Second: 22,792.48337
Overall Steps per Second: 10,712.90344

Timestep Collection Time: 2.19467
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.66932

Cumulative Model Updates: 78,740
Cumulative Timesteps: 656,611,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 656611656...
Checkpoint 656611656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,610.86987
Policy Entropy: 3.66650
Value Function Loss: 0.06790

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.58507
Value Function Update Magnitude: 0.66838

Collected Steps per Second: 22,525.05923
Overall Steps per Second: 10,788.46290

Timestep Collection Time: 2.22144
Timestep Consumption Time: 2.41667
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.63810

Cumulative Model Updates: 78,746
Cumulative Timesteps: 656,661,694

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,553.24403
Policy Entropy: 3.68689
Value Function Loss: 0.06791

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.53377
Value Function Update Magnitude: 0.75005

Collected Steps per Second: 22,690.46452
Overall Steps per Second: 10,659.89150

Timestep Collection Time: 2.20375
Timestep Consumption Time: 2.48711
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.69085

Cumulative Model Updates: 78,752
Cumulative Timesteps: 656,711,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 656711698...
Checkpoint 656711698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,382.83090
Policy Entropy: 3.68159
Value Function Loss: 0.06906

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.55187
Value Function Update Magnitude: 0.80561

Collected Steps per Second: 22,593.23855
Overall Steps per Second: 10,627.75461

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.49261
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.70654

Cumulative Model Updates: 78,758
Cumulative Timesteps: 656,761,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,935.69781
Policy Entropy: 3.68027
Value Function Loss: 0.06903

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.83396

Collected Steps per Second: 22,619.84463
Overall Steps per Second: 10,803.38558

Timestep Collection Time: 2.21080
Timestep Consumption Time: 2.41812
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.62892

Cumulative Model Updates: 78,764
Cumulative Timesteps: 656,811,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 656811726...
Checkpoint 656811726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,312.24112
Policy Entropy: 3.66763
Value Function Loss: 0.06919

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.10096
Policy Update Magnitude: 0.49485
Value Function Update Magnitude: 0.83006

Collected Steps per Second: 22,616.19279
Overall Steps per Second: 10,631.71871

Timestep Collection Time: 2.21204
Timestep Consumption Time: 2.49350
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.70554

Cumulative Model Updates: 78,770
Cumulative Timesteps: 656,861,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,734.79740
Policy Entropy: 3.67956
Value Function Loss: 0.06874

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.46050
Value Function Update Magnitude: 0.81258

Collected Steps per Second: 22,960.15975
Overall Steps per Second: 10,842.62131

Timestep Collection Time: 2.17890
Timestep Consumption Time: 2.43511
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61401

Cumulative Model Updates: 78,776
Cumulative Timesteps: 656,911,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 656911782...
Checkpoint 656911782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212.97012
Policy Entropy: 3.68012
Value Function Loss: 0.06696

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.45420
Value Function Update Magnitude: 0.80709

Collected Steps per Second: 22,597.99076
Overall Steps per Second: 10,652.75873

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.48133
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.69418

Cumulative Model Updates: 78,782
Cumulative Timesteps: 656,961,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,717.09304
Policy Entropy: 3.67456
Value Function Loss: 0.06760

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.41699
Value Function Update Magnitude: 0.73839

Collected Steps per Second: 22,610.02524
Overall Steps per Second: 10,628.70756

Timestep Collection Time: 2.21265
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70688

Cumulative Model Updates: 78,788
Cumulative Timesteps: 657,011,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 657011816...
Checkpoint 657011816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,238.43298
Policy Entropy: 3.67895
Value Function Loss: 0.06900

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.38403
Value Function Update Magnitude: 0.67237

Collected Steps per Second: 22,591.30540
Overall Steps per Second: 10,618.03030

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.70991

Cumulative Model Updates: 78,794
Cumulative Timesteps: 657,061,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,456.71370
Policy Entropy: 3.69170
Value Function Loss: 0.06533

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.38960
Value Function Update Magnitude: 0.69642

Collected Steps per Second: 22,842.71075
Overall Steps per Second: 10,786.16132

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.44816
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.63835

Cumulative Model Updates: 78,800
Cumulative Timesteps: 657,111,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 657111856...
Checkpoint 657111856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,599.29089
Policy Entropy: 3.70875
Value Function Loss: 0.06532

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.37542
Value Function Update Magnitude: 0.72004

Collected Steps per Second: 22,580.77869
Overall Steps per Second: 10,663.81991

Timestep Collection Time: 2.21525
Timestep Consumption Time: 2.47557
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.69081

Cumulative Model Updates: 78,806
Cumulative Timesteps: 657,161,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,522.97502
Policy Entropy: 3.70821
Value Function Loss: 0.06361

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.44295
Value Function Update Magnitude: 0.72758

Collected Steps per Second: 21,805.94722
Overall Steps per Second: 10,463.70847

Timestep Collection Time: 2.29323
Timestep Consumption Time: 2.48577
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.77899

Cumulative Model Updates: 78,812
Cumulative Timesteps: 657,211,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 657211884...
Checkpoint 657211884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,263.62643
Policy Entropy: 3.70522
Value Function Loss: 0.06448

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.42357
Value Function Update Magnitude: 0.78078

Collected Steps per Second: 22,544.75208
Overall Steps per Second: 10,632.85336

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.48509
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.70335

Cumulative Model Updates: 78,818
Cumulative Timesteps: 657,261,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,277.58501
Policy Entropy: 3.69297
Value Function Loss: 0.06285

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.48224
Value Function Update Magnitude: 0.79313

Collected Steps per Second: 22,954.44565
Overall Steps per Second: 10,822.17861

Timestep Collection Time: 2.17945
Timestep Consumption Time: 2.44328
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.62273

Cumulative Model Updates: 78,824
Cumulative Timesteps: 657,311,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 657311922...
Checkpoint 657311922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,865.74789
Policy Entropy: 3.70794
Value Function Loss: 0.06100

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.48207
Value Function Update Magnitude: 0.77175

Collected Steps per Second: 22,313.08509
Overall Steps per Second: 10,677.94992

Timestep Collection Time: 2.24191
Timestep Consumption Time: 2.44288
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.68479

Cumulative Model Updates: 78,830
Cumulative Timesteps: 657,361,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,271.30975
Policy Entropy: 3.71097
Value Function Loss: 0.06063

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06266
Policy Update Magnitude: 0.61861
Value Function Update Magnitude: 0.79542

Collected Steps per Second: 22,575.01040
Overall Steps per Second: 10,600.36540

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.50358
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.71984

Cumulative Model Updates: 78,836
Cumulative Timesteps: 657,411,978

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 657411978...
Checkpoint 657411978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,591.24332
Policy Entropy: 3.71674
Value Function Loss: 0.06159

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.64002
Value Function Update Magnitude: 0.79335

Collected Steps per Second: 22,721.03858
Overall Steps per Second: 10,651.60661

Timestep Collection Time: 2.20122
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.69544

Cumulative Model Updates: 78,842
Cumulative Timesteps: 657,461,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,650.90308
Policy Entropy: 3.71868
Value Function Loss: 0.06239

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.53280
Value Function Update Magnitude: 0.76800

Collected Steps per Second: 22,896.06016
Overall Steps per Second: 10,829.17197

Timestep Collection Time: 2.18562
Timestep Consumption Time: 2.43542
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.62104

Cumulative Model Updates: 78,848
Cumulative Timesteps: 657,512,034

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 657512034...
Checkpoint 657512034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,938.55861
Policy Entropy: 3.72629
Value Function Loss: 0.06214

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.53604
Value Function Update Magnitude: 0.76173

Collected Steps per Second: 22,868.15010
Overall Steps per Second: 10,666.23107

Timestep Collection Time: 2.18723
Timestep Consumption Time: 2.50214
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.68938

Cumulative Model Updates: 78,854
Cumulative Timesteps: 657,562,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,799.03724
Policy Entropy: 3.72867
Value Function Loss: 0.06046

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.53073
Value Function Update Magnitude: 0.75475

Collected Steps per Second: 22,604.60143
Overall Steps per Second: 10,772.48930

Timestep Collection Time: 2.21203
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.64164

Cumulative Model Updates: 78,860
Cumulative Timesteps: 657,612,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 657612054...
Checkpoint 657612054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,116.47738
Policy Entropy: 3.71941
Value Function Loss: 0.06093

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.54390
Value Function Update Magnitude: 0.74540

Collected Steps per Second: 22,084.21306
Overall Steps per Second: 10,716.19504

Timestep Collection Time: 2.26515
Timestep Consumption Time: 2.40293
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.66807

Cumulative Model Updates: 78,866
Cumulative Timesteps: 657,662,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,506.60912
Policy Entropy: 3.72275
Value Function Loss: 0.06145

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.57594
Value Function Update Magnitude: 0.77314

Collected Steps per Second: 23,031.47787
Overall Steps per Second: 10,790.84871

Timestep Collection Time: 2.17190
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.63559

Cumulative Model Updates: 78,872
Cumulative Timesteps: 657,712,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 657712100...
Checkpoint 657712100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,298.25690
Policy Entropy: 3.71681
Value Function Loss: 0.06269

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.65532
Value Function Update Magnitude: 0.80397

Collected Steps per Second: 22,650.85242
Overall Steps per Second: 10,773.32874

Timestep Collection Time: 2.20866
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.64369

Cumulative Model Updates: 78,878
Cumulative Timesteps: 657,762,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,461.16133
Policy Entropy: 3.70777
Value Function Loss: 0.06636

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.67915
Value Function Update Magnitude: 0.82389

Collected Steps per Second: 22,764.44164
Overall Steps per Second: 10,827.51134

Timestep Collection Time: 2.19746
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.62008

Cumulative Model Updates: 78,884
Cumulative Timesteps: 657,812,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 657812152...
Checkpoint 657812152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,815.21151
Policy Entropy: 3.69466
Value Function Loss: 0.07101

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09945
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.84093

Collected Steps per Second: 22,203.99024
Overall Steps per Second: 10,663.65971

Timestep Collection Time: 2.25221
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.68957

Cumulative Model Updates: 78,890
Cumulative Timesteps: 657,862,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,038.80160
Policy Entropy: 3.67933
Value Function Loss: 0.07153

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.49089
Value Function Update Magnitude: 0.83381

Collected Steps per Second: 22,561.13890
Overall Steps per Second: 10,570.45933

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.51527
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.73262

Cumulative Model Updates: 78,896
Cumulative Timesteps: 657,912,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 657912186...
Checkpoint 657912186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,189.15649
Policy Entropy: 3.68489
Value Function Loss: 0.07045

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.48409
Value Function Update Magnitude: 0.82124

Collected Steps per Second: 22,754.32606
Overall Steps per Second: 10,661.56751

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.49345
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.69181

Cumulative Model Updates: 78,902
Cumulative Timesteps: 657,962,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,471.01130
Policy Entropy: 3.69800
Value Function Loss: 0.07002

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.53747
Value Function Update Magnitude: 0.78459

Collected Steps per Second: 22,818.39378
Overall Steps per Second: 10,835.65598

Timestep Collection Time: 2.19157
Timestep Consumption Time: 2.42357
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.61513

Cumulative Model Updates: 78,908
Cumulative Timesteps: 658,012,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 658012216...
Checkpoint 658012216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,365.57921
Policy Entropy: 3.69839
Value Function Loss: 0.06990

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.53542
Value Function Update Magnitude: 0.71819

Collected Steps per Second: 22,600.47169
Overall Steps per Second: 10,594.15515

Timestep Collection Time: 2.21243
Timestep Consumption Time: 2.50734
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.71977

Cumulative Model Updates: 78,914
Cumulative Timesteps: 658,062,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,098.56757
Policy Entropy: 3.70174
Value Function Loss: 0.06917

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.52966
Value Function Update Magnitude: 0.72968

Collected Steps per Second: 22,976.49363
Overall Steps per Second: 10,906.95479

Timestep Collection Time: 2.17692
Timestep Consumption Time: 2.40896
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.58588

Cumulative Model Updates: 78,920
Cumulative Timesteps: 658,112,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 658112236...
Checkpoint 658112236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,634.05215
Policy Entropy: 3.70674
Value Function Loss: 0.06563

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.76879

Collected Steps per Second: 22,646.63335
Overall Steps per Second: 10,631.67189

Timestep Collection Time: 2.20792
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.70312

Cumulative Model Updates: 78,926
Cumulative Timesteps: 658,162,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,958.31662
Policy Entropy: 3.69624
Value Function Loss: 0.06699

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.53641
Value Function Update Magnitude: 0.83171

Collected Steps per Second: 22,730.67558
Overall Steps per Second: 10,671.57560

Timestep Collection Time: 2.20002
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.68609

Cumulative Model Updates: 78,932
Cumulative Timesteps: 658,212,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 658212246...
Checkpoint 658212246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,037.48049
Policy Entropy: 3.70419
Value Function Loss: 0.06942

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.52914
Value Function Update Magnitude: 0.87026

Collected Steps per Second: 22,771.28880
Overall Steps per Second: 10,811.57767

Timestep Collection Time: 2.19610
Timestep Consumption Time: 2.42931
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.62541

Cumulative Model Updates: 78,938
Cumulative Timesteps: 658,262,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,128.22020
Policy Entropy: 3.69372
Value Function Loss: 0.07164

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.52553
Value Function Update Magnitude: 0.88708

Collected Steps per Second: 22,857.34232
Overall Steps per Second: 10,704.79962

Timestep Collection Time: 2.18871
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.67342

Cumulative Model Updates: 78,944
Cumulative Timesteps: 658,312,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 658312282...
Checkpoint 658312282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,739.50588
Policy Entropy: 3.69243
Value Function Loss: 0.07185

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08218
Policy Update Magnitude: 0.57228
Value Function Update Magnitude: 0.86831

Collected Steps per Second: 22,777.71813
Overall Steps per Second: 10,648.60051

Timestep Collection Time: 2.19513
Timestep Consumption Time: 2.50033
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.69545

Cumulative Model Updates: 78,950
Cumulative Timesteps: 658,362,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,283.34645
Policy Entropy: 3.69191
Value Function Loss: 0.07367

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11507
Policy Update Magnitude: 0.52992
Value Function Update Magnitude: 0.83367

Collected Steps per Second: 23,069.62572
Overall Steps per Second: 10,723.36550

Timestep Collection Time: 2.16770
Timestep Consumption Time: 2.49576
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.66346

Cumulative Model Updates: 78,956
Cumulative Timesteps: 658,412,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 658412290...
Checkpoint 658412290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,517.95470
Policy Entropy: 3.70044
Value Function Loss: 0.07682

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.70367

Collected Steps per Second: 22,461.25936
Overall Steps per Second: 10,616.60675

Timestep Collection Time: 2.22614
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.70979

Cumulative Model Updates: 78,962
Cumulative Timesteps: 658,462,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,837.27770
Policy Entropy: 3.70039
Value Function Loss: 0.07626

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.65322
Value Function Update Magnitude: 0.68244

Collected Steps per Second: 22,703.14022
Overall Steps per Second: 10,660.96014

Timestep Collection Time: 2.20384
Timestep Consumption Time: 2.48936
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.69320

Cumulative Model Updates: 78,968
Cumulative Timesteps: 658,512,326

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 658512326...
Checkpoint 658512326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,891.70709
Policy Entropy: 3.69682
Value Function Loss: 0.07502

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.60996
Value Function Update Magnitude: 0.73752

Collected Steps per Second: 22,919.95519
Overall Steps per Second: 10,860.63910

Timestep Collection Time: 2.18247
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.60581

Cumulative Model Updates: 78,974
Cumulative Timesteps: 658,562,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,925.36035
Policy Entropy: 3.68807
Value Function Loss: 0.07732

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.55971
Value Function Update Magnitude: 0.74450

Collected Steps per Second: 22,499.26813
Overall Steps per Second: 10,579.42371

Timestep Collection Time: 2.22238
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.72634

Cumulative Model Updates: 78,980
Cumulative Timesteps: 658,612,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 658612350...
Checkpoint 658612350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,303.71146
Policy Entropy: 3.68873
Value Function Loss: 0.07870

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.56767
Value Function Update Magnitude: 0.81279

Collected Steps per Second: 22,702.48621
Overall Steps per Second: 10,683.20515

Timestep Collection Time: 2.20364
Timestep Consumption Time: 2.47923
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.68286

Cumulative Model Updates: 78,986
Cumulative Timesteps: 658,662,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,890.22101
Policy Entropy: 3.66662
Value Function Loss: 0.08097

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.82723

Collected Steps per Second: 22,986.14465
Overall Steps per Second: 10,768.06224

Timestep Collection Time: 2.17705
Timestep Consumption Time: 2.47021
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.64726

Cumulative Model Updates: 78,992
Cumulative Timesteps: 658,712,420

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 658712420...
Checkpoint 658712420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,959.91994
Policy Entropy: 3.65808
Value Function Loss: 0.07738

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.56918
Value Function Update Magnitude: 0.78944

Collected Steps per Second: 22,713.52629
Overall Steps per Second: 10,638.82096

Timestep Collection Time: 2.20239
Timestep Consumption Time: 2.49964
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.70202

Cumulative Model Updates: 78,998
Cumulative Timesteps: 658,762,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,450.63916
Policy Entropy: 3.66032
Value Function Loss: 0.08039

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.58484
Value Function Update Magnitude: 0.70162

Collected Steps per Second: 22,458.14921
Overall Steps per Second: 10,586.69281

Timestep Collection Time: 2.22663
Timestep Consumption Time: 2.49685
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.72348

Cumulative Model Updates: 79,004
Cumulative Timesteps: 658,812,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 658812450...
Checkpoint 658812450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,411.56092
Policy Entropy: 3.65820
Value Function Loss: 0.08139

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.59668
Value Function Update Magnitude: 0.67060

Collected Steps per Second: 22,851.03515
Overall Steps per Second: 10,731.52476

Timestep Collection Time: 2.18852
Timestep Consumption Time: 2.47158
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.66010

Cumulative Model Updates: 79,010
Cumulative Timesteps: 658,862,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,093.90555
Policy Entropy: 3.65568
Value Function Loss: 0.08246

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.59146
Value Function Update Magnitude: 0.65909

Collected Steps per Second: 22,787.24259
Overall Steps per Second: 10,700.90683

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.47859
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.67306

Cumulative Model Updates: 79,016
Cumulative Timesteps: 658,912,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 658912466...
Checkpoint 658912466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,541.01961
Policy Entropy: 3.65395
Value Function Loss: 0.07597

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.60456
Value Function Update Magnitude: 0.64722

Collected Steps per Second: 22,554.40292
Overall Steps per Second: 10,612.94916

Timestep Collection Time: 2.21775
Timestep Consumption Time: 2.49536
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.71311

Cumulative Model Updates: 79,022
Cumulative Timesteps: 658,962,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,214.18817
Policy Entropy: 3.65845
Value Function Loss: 0.07346

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.59449
Value Function Update Magnitude: 0.61518

Collected Steps per Second: 22,504.85695
Overall Steps per Second: 10,599.39866

Timestep Collection Time: 2.22388
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.72178

Cumulative Model Updates: 79,028
Cumulative Timesteps: 659,012,534

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 659012534...
Checkpoint 659012534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,313.87599
Policy Entropy: 3.68067
Value Function Loss: 0.07120

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.55277
Value Function Update Magnitude: 0.60521

Collected Steps per Second: 22,619.11020
Overall Steps per Second: 10,870.21861

Timestep Collection Time: 2.21052
Timestep Consumption Time: 2.38920
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.59972

Cumulative Model Updates: 79,034
Cumulative Timesteps: 659,062,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,100.19883
Policy Entropy: 3.69341
Value Function Loss: 0.07153

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.58754
Value Function Update Magnitude: 0.65120

Collected Steps per Second: 22,628.33329
Overall Steps per Second: 10,723.18802

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.45455
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.66540

Cumulative Model Updates: 79,040
Cumulative Timesteps: 659,112,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 659112562...
Checkpoint 659112562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,860.99550
Policy Entropy: 3.69524
Value Function Loss: 0.07120

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.59941
Value Function Update Magnitude: 0.66386

Collected Steps per Second: 22,643.47874
Overall Steps per Second: 10,672.56793

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.47687
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.68510

Cumulative Model Updates: 79,046
Cumulative Timesteps: 659,162,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,291.58003
Policy Entropy: 3.68095
Value Function Loss: 0.07127

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.61301
Value Function Update Magnitude: 0.65402

Collected Steps per Second: 22,894.44457
Overall Steps per Second: 10,686.00773

Timestep Collection Time: 2.18481
Timestep Consumption Time: 2.49608
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.68089

Cumulative Model Updates: 79,052
Cumulative Timesteps: 659,212,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 659212584...
Checkpoint 659212584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,380.85333
Policy Entropy: 3.67299
Value Function Loss: 0.07158

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.64530
Value Function Update Magnitude: 0.63636

Collected Steps per Second: 22,760.40438
Overall Steps per Second: 10,630.52108

Timestep Collection Time: 2.19750
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.70494

Cumulative Model Updates: 79,058
Cumulative Timesteps: 659,262,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,329.48131
Policy Entropy: 3.67449
Value Function Loss: 0.07143

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.61479
Value Function Update Magnitude: 0.59768

Collected Steps per Second: 23,205.37808
Overall Steps per Second: 10,877.06266

Timestep Collection Time: 2.15553
Timestep Consumption Time: 2.44313
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.59867

Cumulative Model Updates: 79,064
Cumulative Timesteps: 659,312,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 659312620...
Checkpoint 659312620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,546.67050
Policy Entropy: 3.66267
Value Function Loss: 0.07041

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.60381
Value Function Update Magnitude: 0.68957

Collected Steps per Second: 22,788.00264
Overall Steps per Second: 10,649.39757

Timestep Collection Time: 2.19493
Timestep Consumption Time: 2.50186
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.69679

Cumulative Model Updates: 79,070
Cumulative Timesteps: 659,362,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,139.96575
Policy Entropy: 3.66163
Value Function Loss: 0.06973

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.76132

Collected Steps per Second: 22,600.88657
Overall Steps per Second: 10,843.78729

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.39978
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.61315

Cumulative Model Updates: 79,076
Cumulative Timesteps: 659,412,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 659412662...
Checkpoint 659412662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,245.67082
Policy Entropy: 3.65189
Value Function Loss: 0.07564

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.51502
Value Function Update Magnitude: 0.67408

Collected Steps per Second: 22,455.20946
Overall Steps per Second: 10,776.47971

Timestep Collection Time: 2.22719
Timestep Consumption Time: 2.41366
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.64085

Cumulative Model Updates: 79,082
Cumulative Timesteps: 659,462,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,991.45732
Policy Entropy: 3.64877
Value Function Loss: 0.07631

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.51670
Value Function Update Magnitude: 0.65519

Collected Steps per Second: 23,018.85263
Overall Steps per Second: 10,870.51755

Timestep Collection Time: 2.17326
Timestep Consumption Time: 2.42873
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.60199

Cumulative Model Updates: 79,088
Cumulative Timesteps: 659,512,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 659512700...
Checkpoint 659512700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,351.78420
Policy Entropy: 3.64300
Value Function Loss: 0.07601

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.51568
Value Function Update Magnitude: 0.60768

Collected Steps per Second: 22,537.68436
Overall Steps per Second: 10,613.74813

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.71539

Cumulative Model Updates: 79,094
Cumulative Timesteps: 659,562,748

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,590.82253
Policy Entropy: 3.64267
Value Function Loss: 0.07182

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.51683
Value Function Update Magnitude: 0.61175

Collected Steps per Second: 22,784.50135
Overall Steps per Second: 10,827.42831

Timestep Collection Time: 2.19483
Timestep Consumption Time: 2.42382
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.61864

Cumulative Model Updates: 79,100
Cumulative Timesteps: 659,612,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 659612756...
Checkpoint 659612756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,436.88473
Policy Entropy: 3.65683
Value Function Loss: 0.07043

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07011
Policy Update Magnitude: 0.60980
Value Function Update Magnitude: 0.68873

Collected Steps per Second: 22,394.66790
Overall Steps per Second: 10,759.28638

Timestep Collection Time: 2.23366
Timestep Consumption Time: 2.41554
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.64919

Cumulative Model Updates: 79,106
Cumulative Timesteps: 659,662,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,918.11659
Policy Entropy: 3.66114
Value Function Loss: 0.06930

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.59797
Value Function Update Magnitude: 0.77518

Collected Steps per Second: 23,046.77754
Overall Steps per Second: 10,880.42281

Timestep Collection Time: 2.17080
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.59817

Cumulative Model Updates: 79,112
Cumulative Timesteps: 659,712,808

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 659712808...
Checkpoint 659712808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,720.03041
Policy Entropy: 3.65859
Value Function Loss: 0.06767

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.49756
Value Function Update Magnitude: 0.79240

Collected Steps per Second: 22,546.08725
Overall Steps per Second: 10,614.45983

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.49288
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.71056

Cumulative Model Updates: 79,118
Cumulative Timesteps: 659,762,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,640.74444
Policy Entropy: 3.67788
Value Function Loss: 0.06518

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.51874
Value Function Update Magnitude: 0.82022

Collected Steps per Second: 22,654.86815
Overall Steps per Second: 10,659.62605

Timestep Collection Time: 2.20827
Timestep Consumption Time: 2.48496
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.69322

Cumulative Model Updates: 79,124
Cumulative Timesteps: 659,812,836

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 659812836...
Checkpoint 659812836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,802.88477
Policy Entropy: 3.68210
Value Function Loss: 0.06390

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.61146
Value Function Update Magnitude: 0.84115

Collected Steps per Second: 22,824.39736
Overall Steps per Second: 10,849.02795

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.41942
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61129

Cumulative Model Updates: 79,130
Cumulative Timesteps: 659,862,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,954.51863
Policy Entropy: 3.67103
Value Function Loss: 0.06462

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.60872
Value Function Update Magnitude: 0.85773

Collected Steps per Second: 22,829.52004
Overall Steps per Second: 10,729.61258

Timestep Collection Time: 2.19032
Timestep Consumption Time: 2.47005
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.66037

Cumulative Model Updates: 79,136
Cumulative Timesteps: 659,912,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 659912868...
Checkpoint 659912868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,646.65148
Policy Entropy: 3.68181
Value Function Loss: 0.06294

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.54025
Value Function Update Magnitude: 0.86077

Collected Steps per Second: 23,045.35939
Overall Steps per Second: 10,931.35670

Timestep Collection Time: 2.17085
Timestep Consumption Time: 2.40571
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.57656

Cumulative Model Updates: 79,142
Cumulative Timesteps: 659,962,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,885.03679
Policy Entropy: 3.66160
Value Function Loss: 0.06409

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.49593
Value Function Update Magnitude: 0.86957

Collected Steps per Second: 22,735.22910
Overall Steps per Second: 10,777.99558

Timestep Collection Time: 2.19949
Timestep Consumption Time: 2.44014
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.63964

Cumulative Model Updates: 79,148
Cumulative Timesteps: 660,012,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 660012902...
Checkpoint 660012902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,721.47640
Policy Entropy: 3.65448
Value Function Loss: 0.06589

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.52543
Value Function Update Magnitude: 0.86751

Collected Steps per Second: 22,818.08192
Overall Steps per Second: 10,726.10564

Timestep Collection Time: 2.19238
Timestep Consumption Time: 2.47156
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.66395

Cumulative Model Updates: 79,154
Cumulative Timesteps: 660,062,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,917.93443
Policy Entropy: 3.63309
Value Function Loss: 0.06817

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.50459
Value Function Update Magnitude: 0.84549

Collected Steps per Second: 22,947.41602
Overall Steps per Second: 10,833.04186

Timestep Collection Time: 2.18020
Timestep Consumption Time: 2.43808
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.61828

Cumulative Model Updates: 79,160
Cumulative Timesteps: 660,112,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 660112958...
Checkpoint 660112958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,587.26465
Policy Entropy: 3.62888
Value Function Loss: 0.07163

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.49559
Value Function Update Magnitude: 0.76351

Collected Steps per Second: 21,988.03572
Overall Steps per Second: 10,695.90548

Timestep Collection Time: 2.27424
Timestep Consumption Time: 2.40101
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.67525

Cumulative Model Updates: 79,166
Cumulative Timesteps: 660,162,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,470.52328
Policy Entropy: 3.63177
Value Function Loss: 0.07045

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.51396
Value Function Update Magnitude: 0.70269

Collected Steps per Second: 21,972.60573
Overall Steps per Second: 10,686.48976

Timestep Collection Time: 2.27602
Timestep Consumption Time: 2.40372
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.67974

Cumulative Model Updates: 79,172
Cumulative Timesteps: 660,212,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 660212974...
Checkpoint 660212974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,030.34410
Policy Entropy: 3.63752
Value Function Loss: 0.07109

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.70111

Collected Steps per Second: 22,146.32571
Overall Steps per Second: 10,860.09387

Timestep Collection Time: 2.25925
Timestep Consumption Time: 2.34790
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.60714

Cumulative Model Updates: 79,178
Cumulative Timesteps: 660,263,008

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,715.80523
Policy Entropy: 3.64013
Value Function Loss: 0.07021

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.57138
Value Function Update Magnitude: 0.66128

Collected Steps per Second: 22,345.25038
Overall Steps per Second: 10,889.55026

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.35432
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.59229

Cumulative Model Updates: 79,184
Cumulative Timesteps: 660,313,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 660313016...
Checkpoint 660313016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,292.88307
Policy Entropy: 3.65683
Value Function Loss: 0.07286

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.50500
Value Function Update Magnitude: 0.67103

Collected Steps per Second: 21,911.42130
Overall Steps per Second: 10,668.59379

Timestep Collection Time: 2.28292
Timestep Consumption Time: 2.40580
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.68872

Cumulative Model Updates: 79,190
Cumulative Timesteps: 660,363,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,956.64644
Policy Entropy: 3.65583
Value Function Loss: 0.07470

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.45010
Value Function Update Magnitude: 0.65678

Collected Steps per Second: 21,879.98058
Overall Steps per Second: 10,678.27983

Timestep Collection Time: 2.28538
Timestep Consumption Time: 2.39740
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.68278

Cumulative Model Updates: 79,196
Cumulative Timesteps: 660,413,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 660413042...
Checkpoint 660413042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,516.33455
Policy Entropy: 3.66136
Value Function Loss: 0.07575

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.43826
Value Function Update Magnitude: 0.64623

Collected Steps per Second: 22,274.92888
Overall Steps per Second: 10,936.34769

Timestep Collection Time: 2.24521
Timestep Consumption Time: 2.32779
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.57301

Cumulative Model Updates: 79,202
Cumulative Timesteps: 660,463,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,856.65759
Policy Entropy: 3.66300
Value Function Loss: 0.07505

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.44556
Value Function Update Magnitude: 0.75654

Collected Steps per Second: 22,462.92457
Overall Steps per Second: 10,817.84004

Timestep Collection Time: 2.22705
Timestep Consumption Time: 2.39735
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.62440

Cumulative Model Updates: 79,208
Cumulative Timesteps: 660,513,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 660513080...
Checkpoint 660513080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,406.81534
Policy Entropy: 3.66137
Value Function Loss: 0.07331

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.45360
Value Function Update Magnitude: 0.83294

Collected Steps per Second: 21,920.51709
Overall Steps per Second: 10,630.71020

Timestep Collection Time: 2.28170
Timestep Consumption Time: 2.42316
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.70486

Cumulative Model Updates: 79,214
Cumulative Timesteps: 660,563,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,791.58629
Policy Entropy: 3.64509
Value Function Loss: 0.07388

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.45481
Value Function Update Magnitude: 0.79831

Collected Steps per Second: 22,714.62685
Overall Steps per Second: 10,855.90062

Timestep Collection Time: 2.20140
Timestep Consumption Time: 2.40476
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.60616

Cumulative Model Updates: 79,220
Cumulative Timesteps: 660,613,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 660613100...
Checkpoint 660613100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,091.32375
Policy Entropy: 3.64242
Value Function Loss: 0.07687

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.43829
Value Function Update Magnitude: 0.65724

Collected Steps per Second: 22,512.32831
Overall Steps per Second: 10,746.90564

Timestep Collection Time: 2.22172
Timestep Consumption Time: 2.43227
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.65399

Cumulative Model Updates: 79,226
Cumulative Timesteps: 660,663,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,419.99718
Policy Entropy: 3.63010
Value Function Loss: 0.08016

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.43331
Value Function Update Magnitude: 0.61137

Collected Steps per Second: 22,896.35608
Overall Steps per Second: 10,787.98569

Timestep Collection Time: 2.18410
Timestep Consumption Time: 2.45142
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.63553

Cumulative Model Updates: 79,232
Cumulative Timesteps: 660,713,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 660713124...
Checkpoint 660713124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,704.81020
Policy Entropy: 3.64301
Value Function Loss: 0.07973

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.45846
Value Function Update Magnitude: 0.66195

Collected Steps per Second: 22,834.65066
Overall Steps per Second: 10,733.05951

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.47023
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.66111

Cumulative Model Updates: 79,238
Cumulative Timesteps: 660,763,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,007.24674
Policy Entropy: 3.63441
Value Function Loss: 0.07894

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.49063
Value Function Update Magnitude: 0.75001

Collected Steps per Second: 22,670.42213
Overall Steps per Second: 10,664.54880

Timestep Collection Time: 2.20578
Timestep Consumption Time: 2.48321
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.68899

Cumulative Model Updates: 79,244
Cumulative Timesteps: 660,813,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 660813158...
Checkpoint 660813158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,364.60009
Policy Entropy: 3.64381
Value Function Loss: 0.08048

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 0.52829
Value Function Update Magnitude: 0.75206

Collected Steps per Second: 22,978.19346
Overall Steps per Second: 10,001.16587

Timestep Collection Time: 2.17685
Timestep Consumption Time: 2.82457
PPO Batch Consumption Time: 0.34431
Total Iteration Time: 5.00142

Cumulative Model Updates: 79,250
Cumulative Timesteps: 660,863,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,422.28858
Policy Entropy: 3.63209
Value Function Loss: 0.08618

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.17377
Policy Update Magnitude: 0.50553
Value Function Update Magnitude: 0.64373

Collected Steps per Second: 11,418.87554
Overall Steps per Second: 6,792.75830

Timestep Collection Time: 4.37994
Timestep Consumption Time: 2.98290
PPO Batch Consumption Time: 0.33396
Total Iteration Time: 7.36284

Cumulative Model Updates: 79,256
Cumulative Timesteps: 660,913,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 660913192...
Checkpoint 660913192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,568.29803
Policy Entropy: 3.63318
Value Function Loss: 0.08566

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.16989
Policy Update Magnitude: 0.41722
Value Function Update Magnitude: 0.61499

Collected Steps per Second: 17,951.43408
Overall Steps per Second: 9,167.65759

Timestep Collection Time: 2.78630
Timestep Consumption Time: 2.66962
PPO Batch Consumption Time: 0.30040
Total Iteration Time: 5.45592

Cumulative Model Updates: 79,262
Cumulative Timesteps: 660,963,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,452.75090
Policy Entropy: 3.63518
Value Function Loss: 0.08031

Mean KL Divergence: 0.02576
SB3 Clip Fraction: 0.19159
Policy Update Magnitude: 0.43663
Value Function Update Magnitude: 0.61665

Collected Steps per Second: 21,249.17686
Overall Steps per Second: 10,095.62897

Timestep Collection Time: 2.35426
Timestep Consumption Time: 2.60096
PPO Batch Consumption Time: 0.31107
Total Iteration Time: 4.95521

Cumulative Model Updates: 79,268
Cumulative Timesteps: 661,013,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 661013236...
Checkpoint 661013236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,584.04109
Policy Entropy: 3.66442
Value Function Loss: 0.07262

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11747
Policy Update Magnitude: 0.47653
Value Function Update Magnitude: 0.63957

Collected Steps per Second: 19,244.68978
Overall Steps per Second: 9,523.11415

Timestep Collection Time: 2.59978
Timestep Consumption Time: 2.65396
PPO Batch Consumption Time: 0.31128
Total Iteration Time: 5.25374

Cumulative Model Updates: 79,274
Cumulative Timesteps: 661,063,268

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,455.78647
Policy Entropy: 3.66861
Value Function Loss: 0.06841

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.59019
Value Function Update Magnitude: 0.63407

Collected Steps per Second: 22,348.46247
Overall Steps per Second: 10,714.20646

Timestep Collection Time: 2.23810
Timestep Consumption Time: 2.43029
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.66838

Cumulative Model Updates: 79,280
Cumulative Timesteps: 661,113,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 661113286...
Checkpoint 661113286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,929.69515
Policy Entropy: 3.66837
Value Function Loss: 0.06805

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.71325
Value Function Update Magnitude: 0.62458

Collected Steps per Second: 22,151.35097
Overall Steps per Second: 10,552.24855

Timestep Collection Time: 2.25774
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.73946

Cumulative Model Updates: 79,286
Cumulative Timesteps: 661,163,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,739.33841
Policy Entropy: 3.65824
Value Function Loss: 0.06985

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.72722
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 22,426.41224
Overall Steps per Second: 10,555.60941

Timestep Collection Time: 2.22996
Timestep Consumption Time: 2.50781
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.73777

Cumulative Model Updates: 79,292
Cumulative Timesteps: 661,213,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 661213308...
Checkpoint 661213308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,205.43189
Policy Entropy: 3.64243
Value Function Loss: 0.07190

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07063
Policy Update Magnitude: 0.75133
Value Function Update Magnitude: 0.63158

Collected Steps per Second: 22,399.31851
Overall Steps per Second: 10,576.68927

Timestep Collection Time: 2.23275
Timestep Consumption Time: 2.49577
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.72851

Cumulative Model Updates: 79,298
Cumulative Timesteps: 661,263,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,268.05393
Policy Entropy: 3.63674
Value Function Loss: 0.07105

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.66016
Value Function Update Magnitude: 0.66138

Collected Steps per Second: 22,915.51877
Overall Steps per Second: 10,823.16716

Timestep Collection Time: 2.18297
Timestep Consumption Time: 2.43896
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.62194

Cumulative Model Updates: 79,304
Cumulative Timesteps: 661,313,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 661313344...
Checkpoint 661313344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,854.21102
Policy Entropy: 3.65359
Value Function Loss: 0.06731

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.14803
Policy Update Magnitude: 0.48626
Value Function Update Magnitude: 0.65601

Collected Steps per Second: 21,957.37624
Overall Steps per Second: 10,477.79359

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.49556
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.77333

Cumulative Model Updates: 79,310
Cumulative Timesteps: 661,363,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,150.49847
Policy Entropy: 3.67851
Value Function Loss: 0.06155

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.49566
Value Function Update Magnitude: 0.63475

Collected Steps per Second: 22,917.05434
Overall Steps per Second: 10,721.54594

Timestep Collection Time: 2.18292
Timestep Consumption Time: 2.48302
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.66593

Cumulative Model Updates: 79,316
Cumulative Timesteps: 661,413,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 661413384...
Checkpoint 661413384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,415.34766
Policy Entropy: 3.67221
Value Function Loss: 0.06125

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.58907
Value Function Update Magnitude: 0.61791

Collected Steps per Second: 21,629.06546
Overall Steps per Second: 10,623.68208

Timestep Collection Time: 2.31180
Timestep Consumption Time: 2.39486
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.70665

Cumulative Model Updates: 79,322
Cumulative Timesteps: 661,463,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,930.33009
Policy Entropy: 3.67650
Value Function Loss: 0.06002

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07187
Policy Update Magnitude: 0.69298
Value Function Update Magnitude: 0.69245

Collected Steps per Second: 22,106.72891
Overall Steps per Second: 10,809.24956

Timestep Collection Time: 2.26203
Timestep Consumption Time: 2.36420
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.62622

Cumulative Model Updates: 79,328
Cumulative Timesteps: 661,513,392

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 661513392...
Checkpoint 661513392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.50646
Policy Entropy: 3.66902
Value Function Loss: 0.06005

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.73731
Value Function Update Magnitude: 0.74904

Collected Steps per Second: 21,630.37152
Overall Steps per Second: 10,682.93882

Timestep Collection Time: 2.31193
Timestep Consumption Time: 2.36917
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.68111

Cumulative Model Updates: 79,334
Cumulative Timesteps: 661,563,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,646.18006
Policy Entropy: 3.67746
Value Function Loss: 0.06067

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.75741
Value Function Update Magnitude: 0.74911

Collected Steps per Second: 19,877.87545
Overall Steps per Second: 10,130.40173

Timestep Collection Time: 2.51566
Timestep Consumption Time: 2.42057
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.93623

Cumulative Model Updates: 79,340
Cumulative Timesteps: 661,613,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 661613406...
Checkpoint 661613406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,056.56478
Policy Entropy: 3.67246
Value Function Loss: 0.06153

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07146
Policy Update Magnitude: 0.73291
Value Function Update Magnitude: 0.76081

Collected Steps per Second: 21,500.60294
Overall Steps per Second: 10,712.23440

Timestep Collection Time: 2.32561
Timestep Consumption Time: 2.34214
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.66775

Cumulative Model Updates: 79,346
Cumulative Timesteps: 661,663,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,535.11355
Policy Entropy: 3.67544
Value Function Loss: 0.06302

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08396
Policy Update Magnitude: 0.71288
Value Function Update Magnitude: 0.73865

Collected Steps per Second: 22,421.54075
Overall Steps per Second: 10,835.27959

Timestep Collection Time: 2.23044
Timestep Consumption Time: 2.38503
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.61548

Cumulative Model Updates: 79,352
Cumulative Timesteps: 661,713,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 661713418...
Checkpoint 661713418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,064.74561
Policy Entropy: 3.66946
Value Function Loss: 0.06290

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.58109
Value Function Update Magnitude: 0.75782

Collected Steps per Second: 21,588.60395
Overall Steps per Second: 10,645.24888

Timestep Collection Time: 2.31706
Timestep Consumption Time: 2.38194
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.69900

Cumulative Model Updates: 79,358
Cumulative Timesteps: 661,763,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,192.62462
Policy Entropy: 3.65990
Value Function Loss: 0.06639

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.79400

Collected Steps per Second: 22,119.20781
Overall Steps per Second: 10,526.23293

Timestep Collection Time: 2.26102
Timestep Consumption Time: 2.49016
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.75118

Cumulative Model Updates: 79,364
Cumulative Timesteps: 661,813,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 661813452...
Checkpoint 661813452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,823.24395
Policy Entropy: 3.66351
Value Function Loss: 0.06470

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.53987
Value Function Update Magnitude: 0.82307

Collected Steps per Second: 22,247.34864
Overall Steps per Second: 10,616.57137

Timestep Collection Time: 2.24872
Timestep Consumption Time: 2.46354
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.71226

Cumulative Model Updates: 79,370
Cumulative Timesteps: 661,863,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,176.00250
Policy Entropy: 3.66179
Value Function Loss: 0.06250

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.83910

Collected Steps per Second: 22,854.81940
Overall Steps per Second: 10,875.94230

Timestep Collection Time: 2.18886
Timestep Consumption Time: 2.41083
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.59969

Cumulative Model Updates: 79,376
Cumulative Timesteps: 661,913,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 661913506...
Checkpoint 661913506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,502.12792
Policy Entropy: 3.66391
Value Function Loss: 0.06156

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.59868
Value Function Update Magnitude: 0.83168

Collected Steps per Second: 22,361.88203
Overall Steps per Second: 10,668.12292

Timestep Collection Time: 2.23675
Timestep Consumption Time: 2.45179
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.68855

Cumulative Model Updates: 79,382
Cumulative Timesteps: 661,963,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,641.23158
Policy Entropy: 3.66305
Value Function Loss: 0.06042

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.66459
Value Function Update Magnitude: 0.83619

Collected Steps per Second: 22,921.53605
Overall Steps per Second: 10,943.96897

Timestep Collection Time: 2.18170
Timestep Consumption Time: 2.38775
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.56946

Cumulative Model Updates: 79,388
Cumulative Timesteps: 662,013,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 662013532...
Checkpoint 662013532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,036.21778
Policy Entropy: 3.66130
Value Function Loss: 0.06006

Mean KL Divergence: 0.02373
SB3 Clip Fraction: 0.18278
Policy Update Magnitude: 0.55491
Value Function Update Magnitude: 0.83771

Collected Steps per Second: 22,323.86220
Overall Steps per Second: 10,605.64977

Timestep Collection Time: 2.24074
Timestep Consumption Time: 2.47580
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.71654

Cumulative Model Updates: 79,394
Cumulative Timesteps: 662,063,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.99747
Policy Entropy: 3.67549
Value Function Loss: 0.05783

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.49119
Value Function Update Magnitude: 0.84514

Collected Steps per Second: 22,846.50208
Overall Steps per Second: 10,805.48651

Timestep Collection Time: 2.18974
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.62987

Cumulative Model Updates: 79,400
Cumulative Timesteps: 662,113,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 662113582...
Checkpoint 662113582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,403.25555
Policy Entropy: 3.68234
Value Function Loss: 0.05813

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.57181
Value Function Update Magnitude: 0.85617

Collected Steps per Second: 22,709.26200
Overall Steps per Second: 10,746.63474

Timestep Collection Time: 2.20210
Timestep Consumption Time: 2.45127
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.65336

Cumulative Model Updates: 79,406
Cumulative Timesteps: 662,163,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,753.79824
Policy Entropy: 3.68591
Value Function Loss: 0.05930

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.65294
Value Function Update Magnitude: 0.85780

Collected Steps per Second: 23,028.39404
Overall Steps per Second: 10,835.33134

Timestep Collection Time: 2.17193
Timestep Consumption Time: 2.44408
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.61601

Cumulative Model Updates: 79,412
Cumulative Timesteps: 662,213,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 662213606...
Checkpoint 662213606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,593.13425
Policy Entropy: 3.69361
Value Function Loss: 0.06022

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.67505
Value Function Update Magnitude: 0.86115

Collected Steps per Second: 22,473.51299
Overall Steps per Second: 10,727.56959

Timestep Collection Time: 2.22493
Timestep Consumption Time: 2.43614
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.66107

Cumulative Model Updates: 79,418
Cumulative Timesteps: 662,263,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,053.12020
Policy Entropy: 3.69190
Value Function Loss: 0.06484

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.66083
Value Function Update Magnitude: 0.87043

Collected Steps per Second: 22,669.37848
Overall Steps per Second: 10,791.34470

Timestep Collection Time: 2.20571
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.63353

Cumulative Model Updates: 79,424
Cumulative Timesteps: 662,313,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 662313610...
Checkpoint 662313610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,513.85237
Policy Entropy: 3.68211
Value Function Loss: 0.06767

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.59556
Value Function Update Magnitude: 0.85638

Collected Steps per Second: 22,362.17816
Overall Steps per Second: 10,643.56214

Timestep Collection Time: 2.23726
Timestep Consumption Time: 2.46323
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.70049

Cumulative Model Updates: 79,430
Cumulative Timesteps: 662,363,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,931.68797
Policy Entropy: 3.67340
Value Function Loss: 0.06712

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.58006
Value Function Update Magnitude: 0.82836

Collected Steps per Second: 19,834.95307
Overall Steps per Second: 9,833.07430

Timestep Collection Time: 2.52100
Timestep Consumption Time: 2.56428
PPO Batch Consumption Time: 0.30167
Total Iteration Time: 5.08529

Cumulative Model Updates: 79,436
Cumulative Timesteps: 662,413,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 662413644...
Checkpoint 662413644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,985.37499
Policy Entropy: 3.68596
Value Function Loss: 0.06481

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.77520

Collected Steps per Second: 19,400.47112
Overall Steps per Second: 9,831.34350

Timestep Collection Time: 2.57726
Timestep Consumption Time: 2.50852
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 5.08577

Cumulative Model Updates: 79,442
Cumulative Timesteps: 662,463,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,770.19784
Policy Entropy: 3.69475
Value Function Loss: 0.06461

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.49441
Value Function Update Magnitude: 0.71720

Collected Steps per Second: 21,484.82023
Overall Steps per Second: 9,996.61856

Timestep Collection Time: 2.32806
Timestep Consumption Time: 2.67543
PPO Batch Consumption Time: 0.32345
Total Iteration Time: 5.00349

Cumulative Model Updates: 79,448
Cumulative Timesteps: 662,513,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 662513662...
Checkpoint 662513662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,243.52904
Policy Entropy: 3.70011
Value Function Loss: 0.06663

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.44501
Value Function Update Magnitude: 0.70478

Collected Steps per Second: 22,285.37581
Overall Steps per Second: 10,441.19891

Timestep Collection Time: 2.24398
Timestep Consumption Time: 2.54551
PPO Batch Consumption Time: 0.30917
Total Iteration Time: 4.78949

Cumulative Model Updates: 79,454
Cumulative Timesteps: 662,563,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,710.42713
Policy Entropy: 3.69437
Value Function Loss: 0.06416

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.44187
Value Function Update Magnitude: 0.76001

Collected Steps per Second: 19,361.39900
Overall Steps per Second: 9,764.49596

Timestep Collection Time: 2.58328
Timestep Consumption Time: 2.53895
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 5.12223

Cumulative Model Updates: 79,460
Cumulative Timesteps: 662,613,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 662613686...
Checkpoint 662613686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,206.81923
Policy Entropy: 3.68877
Value Function Loss: 0.06836

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.45536
Value Function Update Magnitude: 0.72680

Collected Steps per Second: 17,620.74794
Overall Steps per Second: 9,237.10065

Timestep Collection Time: 2.83756
Timestep Consumption Time: 2.57539
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 5.41295

Cumulative Model Updates: 79,466
Cumulative Timesteps: 662,663,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,568.21972
Policy Entropy: 3.69138
Value Function Loss: 0.06976

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 0.48094
Value Function Update Magnitude: 0.69652

Collected Steps per Second: 20,723.20856
Overall Steps per Second: 10,130.68733

Timestep Collection Time: 2.41285
Timestep Consumption Time: 2.52285
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.93570

Cumulative Model Updates: 79,472
Cumulative Timesteps: 662,713,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 662713688...
Checkpoint 662713688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,401.99515
Policy Entropy: 3.68991
Value Function Loss: 0.07057

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.51056
Value Function Update Magnitude: 0.68777

Collected Steps per Second: 21,634.80579
Overall Steps per Second: 10,229.32178

Timestep Collection Time: 2.31285
Timestep Consumption Time: 2.57878
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.89162

Cumulative Model Updates: 79,478
Cumulative Timesteps: 662,763,726

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,565.51276
Policy Entropy: 3.67729
Value Function Loss: 0.07007

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.49972
Value Function Update Magnitude: 0.66815

Collected Steps per Second: 17,623.26313
Overall Steps per Second: 9,186.21534

Timestep Collection Time: 2.83818
Timestep Consumption Time: 2.60672
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 5.44490

Cumulative Model Updates: 79,484
Cumulative Timesteps: 662,813,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 662813744...
Checkpoint 662813744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,224.22895
Policy Entropy: 3.68258
Value Function Loss: 0.07333

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.49373
Value Function Update Magnitude: 0.66007

Collected Steps per Second: 17,503.54041
Overall Steps per Second: 7,692.05240

Timestep Collection Time: 2.85885
Timestep Consumption Time: 3.64657
PPO Batch Consumption Time: 0.46419
Total Iteration Time: 6.50542

Cumulative Model Updates: 79,490
Cumulative Timesteps: 662,863,784

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,810.01571
Policy Entropy: 3.68319
Value Function Loss: 0.07487

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.51953
Value Function Update Magnitude: 0.68043

Collected Steps per Second: 15,754.18905
Overall Steps per Second: 7,520.50219

Timestep Collection Time: 3.17541
Timestep Consumption Time: 3.47654
PPO Batch Consumption Time: 0.43916
Total Iteration Time: 6.65195

Cumulative Model Updates: 79,496
Cumulative Timesteps: 662,913,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 662913810...
Checkpoint 662913810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,470.91653
Policy Entropy: 3.68952
Value Function Loss: 0.07688

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05925
Policy Update Magnitude: 0.67479
Value Function Update Magnitude: 0.67251

Collected Steps per Second: 15,894.78567
Overall Steps per Second: 7,438.40451

Timestep Collection Time: 3.14569
Timestep Consumption Time: 3.57619
PPO Batch Consumption Time: 0.46576
Total Iteration Time: 6.72187

Cumulative Model Updates: 79,502
Cumulative Timesteps: 662,963,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.66018
Policy Entropy: 3.68863
Value Function Loss: 0.07559

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.69750
Value Function Update Magnitude: 0.73707

Collected Steps per Second: 15,993.17590
Overall Steps per Second: 7,643.78326

Timestep Collection Time: 3.12821
Timestep Consumption Time: 3.41698
PPO Batch Consumption Time: 0.44170
Total Iteration Time: 6.54519

Cumulative Model Updates: 79,508
Cumulative Timesteps: 663,013,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 663013840...
Checkpoint 663013840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,492.07141
Policy Entropy: 3.69818
Value Function Loss: 0.07029

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.15496
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.79061

Collected Steps per Second: 16,054.14888
Overall Steps per Second: 7,629.81820

Timestep Collection Time: 3.11745
Timestep Consumption Time: 3.44208
PPO Batch Consumption Time: 0.44494
Total Iteration Time: 6.55953

Cumulative Model Updates: 79,514
Cumulative Timesteps: 663,063,888

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.28541
Policy Entropy: 3.71107
Value Function Loss: 0.06717

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.62009
Value Function Update Magnitude: 0.79778

Collected Steps per Second: 16,085.34942
Overall Steps per Second: 7,645.48936

Timestep Collection Time: 3.10929
Timestep Consumption Time: 3.43235
PPO Batch Consumption Time: 0.44100
Total Iteration Time: 6.54163

Cumulative Model Updates: 79,520
Cumulative Timesteps: 663,113,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 663113902...
Checkpoint 663113902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,444.21281
Policy Entropy: 3.71371
Value Function Loss: 0.06690

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.65261
Value Function Update Magnitude: 0.68973

Collected Steps per Second: 15,939.91471
Overall Steps per Second: 7,592.53845

Timestep Collection Time: 3.13741
Timestep Consumption Time: 3.44932
PPO Batch Consumption Time: 0.44546
Total Iteration Time: 6.58673

Cumulative Model Updates: 79,526
Cumulative Timesteps: 663,163,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.67477
Policy Entropy: 3.71633
Value Function Loss: 0.06788

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.58319
Value Function Update Magnitude: 0.64391

Collected Steps per Second: 16,161.48276
Overall Steps per Second: 7,670.69583

Timestep Collection Time: 3.09538
Timestep Consumption Time: 3.42632
PPO Batch Consumption Time: 0.44742
Total Iteration Time: 6.52170

Cumulative Model Updates: 79,532
Cumulative Timesteps: 663,213,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 663213938...
Checkpoint 663213938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,253.40938
Policy Entropy: 3.70329
Value Function Loss: 0.06719

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.16021
Policy Update Magnitude: 0.47525
Value Function Update Magnitude: 0.60096

Collected Steps per Second: 15,939.94873
Overall Steps per Second: 8,560.17934

Timestep Collection Time: 3.13828
Timestep Consumption Time: 2.70552
PPO Batch Consumption Time: 0.32398
Total Iteration Time: 5.84380

Cumulative Model Updates: 79,538
Cumulative Timesteps: 663,263,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,446.39605
Policy Entropy: 3.71627
Value Function Loss: 0.06458

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.49578
Value Function Update Magnitude: 0.65257

Collected Steps per Second: 16,928.28031
Overall Steps per Second: 8,845.60238

Timestep Collection Time: 2.95470
Timestep Consumption Time: 2.69986
PPO Batch Consumption Time: 0.30499
Total Iteration Time: 5.65456

Cumulative Model Updates: 79,544
Cumulative Timesteps: 663,313,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 663313980...
Checkpoint 663313980 saved!
