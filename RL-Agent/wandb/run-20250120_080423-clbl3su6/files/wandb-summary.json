{"Collected Steps per Second":16095.933254797801,"PPO Batch Consumption Time":0.30011630058288574,"Value Function Loss":0.03223409969359636,"Policy Update Magnitude":0.30515438318252563,"Timesteps Collected":50036,"Policy Reward":28506.664923047694,"Mean KL Divergence":0.009763513458892703,"Overall Steps per Second":8753.658124095928,"_runtime":188771.0359531,"_step":72782,"Total Iteration Time":5.716010299998743,"Cumulative Model Updates":218202,"_wandb":{"runtime":188771},"Timestep Consumption Time":2.6073989999931655,"z_vel":3.8915335665312183,"_timestamp":1.7374295255790126e+09,"y_vel":-8.86895115763854,"Value Function Update Magnitude":0.3560492694377899,"Policy Entropy":1.9873170256614685,"x_vel":4.809955010861951,"Cumulative Timesteps":1820381420,"SB3 Clip Fraction":0.08576999790966511,"Timestep Collection Time":3.1086113000055775}