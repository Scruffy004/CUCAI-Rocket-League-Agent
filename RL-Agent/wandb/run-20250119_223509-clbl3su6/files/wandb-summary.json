{"_timestamp":1.7373442147656102e+09,"Overall Steps per Second":9797.496539517408,"Timesteps Collected":50036,"Value Function Loss":0.06171742950876554,"Policy Update Magnitude":0.3467913269996643,"x_vel":16.897371742382436,"Collected Steps per Second":18482.796456412518,"PPO Batch Consumption Time":0.2853246529897054,"Mean KL Divergence":0.006721114972606301,"Value Function Update Magnitude":0.3369303047657013,"Cumulative Timesteps":971804776,"z_vel":4.057589886804563,"_step":38852,"_wandb":{"runtime":105795},"Policy Reward":16017.551064385945,"Total Iteration Time":5.1070189,"SB3 Clip Fraction":0.07781333103775978,"_runtime":105792.2791194,"Timestep Consumption Time":2.399852800000005,"Timestep Collection Time":2.707166099999995,"Cumulative Model Updates":116498,"y_vel":-4.156359710065447,"Policy Entropy":1.953792651494344}