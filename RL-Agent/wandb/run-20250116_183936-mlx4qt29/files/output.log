Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.19578
Policy Entropy: 0.57227
Value Function Loss: 1.34711

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.01159
Value Function Update Magnitude: 0.00895

Collected Steps per Second: 21,868.60111
Overall Steps per Second: 15,993.12782

Timestep Collection Time: 2.28638
Timestep Consumption Time: 0.83996
PPO Batch Consumption Time: 0.23222
Total Iteration Time: 3.12634

Cumulative Model Updates: 8,172
Cumulative Timesteps: 136,393,896

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.18702
Policy Entropy: 0.60645
Value Function Loss: 1.29413

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.00973
Value Function Update Magnitude: 0.01472

Collected Steps per Second: 21,201.69480
Overall Steps per Second: 15,746.24921

Timestep Collection Time: 2.35849
Timestep Consumption Time: 0.81712
PPO Batch Consumption Time: 0.19844
Total Iteration Time: 3.17561

Cumulative Model Updates: 8,173
Cumulative Timesteps: 136,443,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 136443900...
Checkpoint 136443900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,399.30411
Policy Entropy: 0.61458
Value Function Loss: 1.19818

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03919
Policy Update Magnitude: 0.01992
Value Function Update Magnitude: 0.04438

Collected Steps per Second: 23,930.58609
Overall Steps per Second: 17,712.78221

Timestep Collection Time: 2.09046
Timestep Consumption Time: 0.73383
PPO Batch Consumption Time: 0.06484
Total Iteration Time: 2.82429

Cumulative Model Updates: 8,175
Cumulative Timesteps: 136,493,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.53457
Policy Entropy: 0.63564
Value Function Loss: 1.09610

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.04029
Policy Update Magnitude: 0.02432
Value Function Update Magnitude: 0.07725

Collected Steps per Second: 21,858.39811
Overall Steps per Second: 15,737.15627

Timestep Collection Time: 2.28891
Timestep Consumption Time: 0.89031
PPO Batch Consumption Time: 0.08022
Total Iteration Time: 3.17923

Cumulative Model Updates: 8,178
Cumulative Timesteps: 136,543,958

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 136543958...
Checkpoint 136543958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.88607
Policy Entropy: 0.64767
Value Function Loss: 1.06328

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03093
Policy Update Magnitude: 0.02552
Value Function Update Magnitude: 0.07342

Collected Steps per Second: 24,041.00186
Overall Steps per Second: 17,425.84532

Timestep Collection Time: 2.08086
Timestep Consumption Time: 0.78993
PPO Batch Consumption Time: 0.06188
Total Iteration Time: 2.87079

Cumulative Model Updates: 8,181
Cumulative Timesteps: 136,593,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.97686
Policy Entropy: 0.64765
Value Function Loss: 1.12079

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.02947
Value Function Update Magnitude: 0.05944

Collected Steps per Second: 21,902.51176
Overall Steps per Second: 15,279.65285

Timestep Collection Time: 2.28485
Timestep Consumption Time: 0.99035
PPO Batch Consumption Time: 0.12306
Total Iteration Time: 3.27521

Cumulative Model Updates: 8,184
Cumulative Timesteps: 136,644,028

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 136644028...
Checkpoint 136644028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,008.58350
Policy Entropy: 0.64728
Value Function Loss: 1.17118

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01502
Policy Update Magnitude: 0.03203
Value Function Update Magnitude: 0.05419

Collected Steps per Second: 24,304.01724
Overall Steps per Second: 17,541.54051

Timestep Collection Time: 2.05785
Timestep Consumption Time: 0.79333
PPO Batch Consumption Time: 0.06078
Total Iteration Time: 2.85117

Cumulative Model Updates: 8,187
Cumulative Timesteps: 136,694,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,658.09106
Policy Entropy: 0.63225
Value Function Loss: 1.20283

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01955
Policy Update Magnitude: 0.03494
Value Function Update Magnitude: 0.05835

Collected Steps per Second: 20,905.42494
Overall Steps per Second: 14,968.72019

Timestep Collection Time: 2.39230
Timestep Consumption Time: 0.94880
PPO Batch Consumption Time: 0.11524
Total Iteration Time: 3.34110

Cumulative Model Updates: 8,190
Cumulative Timesteps: 136,744,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 136744054...
Checkpoint 136744054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.01139
Policy Entropy: 0.64755
Value Function Loss: 1.13922

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.03232
Value Function Update Magnitude: 0.05977

Collected Steps per Second: 24,004.38978
Overall Steps per Second: 16,707.87783

Timestep Collection Time: 2.08320
Timestep Consumption Time: 0.90976
PPO Batch Consumption Time: 0.09852
Total Iteration Time: 2.99296

Cumulative Model Updates: 8,193
Cumulative Timesteps: 136,794,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,839.90048
Policy Entropy: 0.65262
Value Function Loss: 1.17533

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 0.03027
Value Function Update Magnitude: 0.05414

Collected Steps per Second: 23,926.62311
Overall Steps per Second: 16,758.20645

Timestep Collection Time: 2.09039
Timestep Consumption Time: 0.89418
PPO Batch Consumption Time: 0.09807
Total Iteration Time: 2.98457

Cumulative Model Updates: 8,196
Cumulative Timesteps: 136,844,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 136844076...
Checkpoint 136844076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,488.74574
Policy Entropy: 0.66726
Value Function Loss: 1.17179

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 0.02706
Value Function Update Magnitude: 0.05886

Collected Steps per Second: 23,270.73015
Overall Steps per Second: 16,462.55299

Timestep Collection Time: 2.15000
Timestep Consumption Time: 0.88914
PPO Batch Consumption Time: 0.08498
Total Iteration Time: 3.03914

Cumulative Model Updates: 8,199
Cumulative Timesteps: 136,894,108

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,216.13357
Policy Entropy: 0.66426
Value Function Loss: 1.16774

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03529
Policy Update Magnitude: 0.02704
Value Function Update Magnitude: 0.05409

Collected Steps per Second: 22,809.27885
Overall Steps per Second: 15,942.63685

Timestep Collection Time: 2.19288
Timestep Consumption Time: 0.94449
PPO Batch Consumption Time: 0.10709
Total Iteration Time: 3.13737

Cumulative Model Updates: 8,202
Cumulative Timesteps: 136,944,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 136944126...
Checkpoint 136944126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.40222
Policy Entropy: 0.67051
Value Function Loss: 1.16266

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.04031
Policy Update Magnitude: 0.02544
Value Function Update Magnitude: 0.06256

Collected Steps per Second: 23,242.93547
Overall Steps per Second: 17,072.47207

Timestep Collection Time: 2.15214
Timestep Consumption Time: 0.77784
PPO Batch Consumption Time: 0.05952
Total Iteration Time: 2.92998

Cumulative Model Updates: 8,205
Cumulative Timesteps: 136,994,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,525.89261
Policy Entropy: 0.66590
Value Function Loss: 1.13039

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.01879
Policy Update Magnitude: 0.02683
Value Function Update Magnitude: 0.06202

Collected Steps per Second: 24,276.87379
Overall Steps per Second: 17,754.21999

Timestep Collection Time: 2.06081
Timestep Consumption Time: 0.75711
PPO Batch Consumption Time: 0.06226
Total Iteration Time: 2.81792

Cumulative Model Updates: 8,208
Cumulative Timesteps: 137,044,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 137044178...
Checkpoint 137044178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,385.17760
Policy Entropy: 0.66719
Value Function Loss: 1.15870

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03181
Policy Update Magnitude: 0.02808
Value Function Update Magnitude: 0.06107

Collected Steps per Second: 22,044.67489
Overall Steps per Second: 15,648.53121

Timestep Collection Time: 2.26867
Timestep Consumption Time: 0.92729
PPO Batch Consumption Time: 0.10993
Total Iteration Time: 3.19595

Cumulative Model Updates: 8,211
Cumulative Timesteps: 137,094,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,484.60292
Policy Entropy: 0.66822
Value Function Loss: 1.17648

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03058
Policy Update Magnitude: 0.02614
Value Function Update Magnitude: 0.05420

Collected Steps per Second: 24,436.20447
Overall Steps per Second: 17,779.91899

Timestep Collection Time: 2.04672
Timestep Consumption Time: 0.76623
PPO Batch Consumption Time: 0.05781
Total Iteration Time: 2.81295

Cumulative Model Updates: 8,214
Cumulative Timesteps: 137,144,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 137144204...
Checkpoint 137144204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,313.51338
Policy Entropy: 0.65723
Value Function Loss: 1.21055

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.02861
Value Function Update Magnitude: 0.04660

Collected Steps per Second: 20,976.77316
Overall Steps per Second: 15,635.80359

Timestep Collection Time: 2.38397
Timestep Consumption Time: 0.81433
PPO Batch Consumption Time: 0.07455
Total Iteration Time: 3.19830

Cumulative Model Updates: 8,217
Cumulative Timesteps: 137,194,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,028.11147
Policy Entropy: 0.65665
Value Function Loss: 1.22969

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03525
Policy Update Magnitude: 0.03330
Value Function Update Magnitude: 0.04357

Collected Steps per Second: 24,023.60113
Overall Steps per Second: 17,572.88763

Timestep Collection Time: 2.08204
Timestep Consumption Time: 0.76428
PPO Batch Consumption Time: 0.05910
Total Iteration Time: 2.84632

Cumulative Model Updates: 8,220
Cumulative Timesteps: 137,244,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 137244230...
Checkpoint 137244230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,452.61159
Policy Entropy: 0.65582
Value Function Loss: 1.19157

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04373
Policy Update Magnitude: 0.02866
Value Function Update Magnitude: 0.04407

Collected Steps per Second: 20,883.28305
Overall Steps per Second: 15,126.79059

Timestep Collection Time: 2.39541
Timestep Consumption Time: 0.91157
PPO Batch Consumption Time: 0.10826
Total Iteration Time: 3.30698

Cumulative Model Updates: 8,223
Cumulative Timesteps: 137,294,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.12157
Policy Entropy: 0.66417
Value Function Loss: 1.15858

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.02957
Value Function Update Magnitude: 0.04123

Collected Steps per Second: 23,467.33348
Overall Steps per Second: 17,323.94005

Timestep Collection Time: 2.13105
Timestep Consumption Time: 0.75571
PPO Batch Consumption Time: 0.07091
Total Iteration Time: 2.88676

Cumulative Model Updates: 8,226
Cumulative Timesteps: 137,344,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 137344264...
Checkpoint 137344264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,625.40485
Policy Entropy: 0.67547
Value Function Loss: 1.12641

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04177
Policy Update Magnitude: 0.02698
Value Function Update Magnitude: 0.04925

Collected Steps per Second: 20,331.88285
Overall Steps per Second: 15,175.08037

Timestep Collection Time: 2.46047
Timestep Consumption Time: 0.83612
PPO Batch Consumption Time: 0.08772
Total Iteration Time: 3.29659

Cumulative Model Updates: 8,229
Cumulative Timesteps: 137,394,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,879.46234
Policy Entropy: 0.67517
Value Function Loss: 1.12374

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03221
Policy Update Magnitude: 0.02502
Value Function Update Magnitude: 0.06055

Collected Steps per Second: 23,316.09950
Overall Steps per Second: 16,755.27935

Timestep Collection Time: 2.14487
Timestep Consumption Time: 0.83986
PPO Batch Consumption Time: 0.09893
Total Iteration Time: 2.98473

Cumulative Model Updates: 8,232
Cumulative Timesteps: 137,444,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 137444300...
Checkpoint 137444300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,684.58933
Policy Entropy: 0.67315
Value Function Loss: 1.13435

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.02706
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 22,582.12659
Overall Steps per Second: 16,546.05650

Timestep Collection Time: 2.21582
Timestep Consumption Time: 0.80834
PPO Batch Consumption Time: 0.08273
Total Iteration Time: 3.02416

Cumulative Model Updates: 8,235
Cumulative Timesteps: 137,494,338

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.46329
Policy Entropy: 0.68031
Value Function Loss: 1.12124

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.03301
Value Function Update Magnitude: 0.06446

Collected Steps per Second: 22,316.50338
Overall Steps per Second: 15,823.60781

Timestep Collection Time: 2.24112
Timestep Consumption Time: 0.91960
PPO Batch Consumption Time: 0.09059
Total Iteration Time: 3.16072

Cumulative Model Updates: 8,238
Cumulative Timesteps: 137,544,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 137544352...
Checkpoint 137544352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,423.48067
Policy Entropy: 0.68237
Value Function Loss: 1.09997

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03623
Policy Update Magnitude: 0.02769
Value Function Update Magnitude: 0.05803

Collected Steps per Second: 23,602.61937
Overall Steps per Second: 17,089.36016

Timestep Collection Time: 2.11900
Timestep Consumption Time: 0.80761
PPO Batch Consumption Time: 0.06243
Total Iteration Time: 2.92662

Cumulative Model Updates: 8,241
Cumulative Timesteps: 137,594,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,130.57878
Policy Entropy: 0.68746
Value Function Loss: 1.09986

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01171
Policy Update Magnitude: 0.02878
Value Function Update Magnitude: 0.04820

Collected Steps per Second: 24,404.33363
Overall Steps per Second: 17,684.54535

Timestep Collection Time: 2.04906
Timestep Consumption Time: 0.77860
PPO Batch Consumption Time: 0.06012
Total Iteration Time: 2.82767

Cumulative Model Updates: 8,244
Cumulative Timesteps: 137,644,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 137644372...
Checkpoint 137644372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,219.61522
Policy Entropy: 0.68234
Value Function Loss: 1.11080

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.02887
Value Function Update Magnitude: 0.04219

Collected Steps per Second: 21,032.12886
Overall Steps per Second: 14,724.90038

Timestep Collection Time: 2.37884
Timestep Consumption Time: 1.01895
PPO Batch Consumption Time: 0.13091
Total Iteration Time: 3.39778

Cumulative Model Updates: 8,247
Cumulative Timesteps: 137,694,404

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,837.35994
Policy Entropy: 0.68175
Value Function Loss: 1.11384

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.02920
Value Function Update Magnitude: 0.03951

Collected Steps per Second: 23,740.72985
Overall Steps per Second: 17,264.32784

Timestep Collection Time: 2.10684
Timestep Consumption Time: 0.79034
PPO Batch Consumption Time: 0.06320
Total Iteration Time: 2.89719

Cumulative Model Updates: 8,250
Cumulative Timesteps: 137,744,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 137744422...
Checkpoint 137744422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,392.70100
Policy Entropy: 0.67631
Value Function Loss: 1.11606

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03198
Policy Update Magnitude: 0.02838
Value Function Update Magnitude: 0.03868

Collected Steps per Second: 21,953.77729
Overall Steps per Second: 15,330.90559

Timestep Collection Time: 2.27760
Timestep Consumption Time: 0.98391
PPO Batch Consumption Time: 0.12311
Total Iteration Time: 3.26152

Cumulative Model Updates: 8,253
Cumulative Timesteps: 137,794,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,423.40906
Policy Entropy: 0.68334
Value Function Loss: 1.08755

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04703
Policy Update Magnitude: 0.02705
Value Function Update Magnitude: 0.04620

Collected Steps per Second: 22,497.68162
Overall Steps per Second: 15,653.09962

Timestep Collection Time: 2.22343
Timestep Consumption Time: 0.97223
PPO Batch Consumption Time: 0.11696
Total Iteration Time: 3.19566

Cumulative Model Updates: 8,256
Cumulative Timesteps: 137,844,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 137844446...
Checkpoint 137844446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,078.50815
Policy Entropy: 0.68066
Value Function Loss: 1.09766

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.05428
Policy Update Magnitude: 0.02467
Value Function Update Magnitude: 0.04131

Collected Steps per Second: 23,639.12294
Overall Steps per Second: 17,213.35827

Timestep Collection Time: 2.11522
Timestep Consumption Time: 0.78961
PPO Batch Consumption Time: 0.06209
Total Iteration Time: 2.90484

Cumulative Model Updates: 8,259
Cumulative Timesteps: 137,894,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,542.73794
Policy Entropy: 0.68559
Value Function Loss: 1.07634

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04597
Policy Update Magnitude: 0.02379
Value Function Update Magnitude: 0.03950

Collected Steps per Second: 23,833.39915
Overall Steps per Second: 17,433.41458

Timestep Collection Time: 2.09840
Timestep Consumption Time: 0.77034
PPO Batch Consumption Time: 0.05645
Total Iteration Time: 2.86874

Cumulative Model Updates: 8,262
Cumulative Timesteps: 137,944,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 137944460...
Checkpoint 137944460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,338.55998
Policy Entropy: 0.67808
Value Function Loss: 1.06910

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03937
Policy Update Magnitude: 0.02212
Value Function Update Magnitude: 0.03840

Collected Steps per Second: 20,836.92628
Overall Steps per Second: 14,718.08200

Timestep Collection Time: 2.40170
Timestep Consumption Time: 0.99847
PPO Batch Consumption Time: 0.11486
Total Iteration Time: 3.40017

Cumulative Model Updates: 8,265
Cumulative Timesteps: 137,994,504

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,127.76328
Policy Entropy: 0.67790
Value Function Loss: 1.05789

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04303
Policy Update Magnitude: 0.02492
Value Function Update Magnitude: 0.03567

Collected Steps per Second: 24,199.21788
Overall Steps per Second: 17,553.68231

Timestep Collection Time: 2.06709
Timestep Consumption Time: 0.78257
PPO Batch Consumption Time: 0.06080
Total Iteration Time: 2.84966

Cumulative Model Updates: 8,268
Cumulative Timesteps: 138,044,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 138044526...
Checkpoint 138044526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,495.02116
Policy Entropy: 0.67416
Value Function Loss: 1.05115

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04504
Policy Update Magnitude: 0.02318
Value Function Update Magnitude: 0.04113

Collected Steps per Second: 20,788.05962
Overall Steps per Second: 15,031.88978

Timestep Collection Time: 2.40532
Timestep Consumption Time: 0.92107
PPO Batch Consumption Time: 0.10311
Total Iteration Time: 3.32639

Cumulative Model Updates: 8,271
Cumulative Timesteps: 138,094,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,796.76580
Policy Entropy: 0.68019
Value Function Loss: 1.06202

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 0.02401
Value Function Update Magnitude: 0.03590

Collected Steps per Second: 24,321.79598
Overall Steps per Second: 16,725.21025

Timestep Collection Time: 2.05593
Timestep Consumption Time: 0.93380
PPO Batch Consumption Time: 0.10821
Total Iteration Time: 2.98974

Cumulative Model Updates: 8,274
Cumulative Timesteps: 138,144,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 138144532...
Checkpoint 138144532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,051.58496
Policy Entropy: 0.67873
Value Function Loss: 1.02558

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03678
Policy Update Magnitude: 0.02284
Value Function Update Magnitude: 0.03685

Collected Steps per Second: 23,738.61320
Overall Steps per Second: 16,737.78036

Timestep Collection Time: 2.10644
Timestep Consumption Time: 0.88105
PPO Batch Consumption Time: 0.09309
Total Iteration Time: 2.98749

Cumulative Model Updates: 8,277
Cumulative Timesteps: 138,194,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,751.80926
Policy Entropy: 0.67878
Value Function Loss: 0.99959

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02245
Policy Update Magnitude: 0.02535
Value Function Update Magnitude: 0.03605

Collected Steps per Second: 24,274.69449
Overall Steps per Second: 16,736.22021

Timestep Collection Time: 2.06025
Timestep Consumption Time: 0.92800
PPO Batch Consumption Time: 0.10225
Total Iteration Time: 2.98825

Cumulative Model Updates: 8,280
Cumulative Timesteps: 138,244,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 138244548...
Checkpoint 138244548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,591.20142
Policy Entropy: 0.67112
Value Function Loss: 1.02490

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03419
Policy Update Magnitude: 0.02885
Value Function Update Magnitude: 0.03045

Collected Steps per Second: 23,219.52349
Overall Steps per Second: 16,727.62150

Timestep Collection Time: 2.15362
Timestep Consumption Time: 0.83581
PPO Batch Consumption Time: 0.07852
Total Iteration Time: 2.98943

Cumulative Model Updates: 8,283
Cumulative Timesteps: 138,294,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.29989
Policy Entropy: 0.68286
Value Function Loss: 1.03631

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03583
Policy Update Magnitude: 0.02559
Value Function Update Magnitude: 0.03803

Collected Steps per Second: 23,724.85319
Overall Steps per Second: 16,715.15347

Timestep Collection Time: 2.10783
Timestep Consumption Time: 0.88394
PPO Batch Consumption Time: 0.09367
Total Iteration Time: 2.99178

Cumulative Model Updates: 8,286
Cumulative Timesteps: 138,344,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 138344562...
Checkpoint 138344562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,386.29835
Policy Entropy: 0.68737
Value Function Loss: 1.04911

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.02851
Value Function Update Magnitude: 0.04433

Collected Steps per Second: 24,178.46776
Overall Steps per Second: 16,816.29409

Timestep Collection Time: 2.06845
Timestep Consumption Time: 0.90557
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 2.97402

Cumulative Model Updates: 8,289
Cumulative Timesteps: 138,394,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,850.21030
Policy Entropy: 0.69096
Value Function Loss: 1.06556

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.03024
Value Function Update Magnitude: 0.05029

Collected Steps per Second: 23,779.26210
Overall Steps per Second: 16,685.08145

Timestep Collection Time: 2.10292
Timestep Consumption Time: 0.89412
PPO Batch Consumption Time: 0.10033
Total Iteration Time: 2.99705

Cumulative Model Updates: 8,292
Cumulative Timesteps: 138,444,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 138444580...
Checkpoint 138444580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.05564
Policy Entropy: 0.68471
Value Function Loss: 1.12664

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02725
Policy Update Magnitude: 0.02761
Value Function Update Magnitude: 0.05611

Collected Steps per Second: 23,714.04740
Overall Steps per Second: 16,733.08613

Timestep Collection Time: 2.10862
Timestep Consumption Time: 0.87971
PPO Batch Consumption Time: 0.09324
Total Iteration Time: 2.98833

Cumulative Model Updates: 8,295
Cumulative Timesteps: 138,494,584

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.07164
Policy Entropy: 0.67955
Value Function Loss: 1.17201

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01742
Policy Update Magnitude: 0.02813
Value Function Update Magnitude: 0.05184

Collected Steps per Second: 23,486.63638
Overall Steps per Second: 16,721.33540

Timestep Collection Time: 2.12998
Timestep Consumption Time: 0.86177
PPO Batch Consumption Time: 0.08648
Total Iteration Time: 2.99175

Cumulative Model Updates: 8,298
Cumulative Timesteps: 138,544,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 138544610...
Checkpoint 138544610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,233.51958
Policy Entropy: 0.67501
Value Function Loss: 1.19774

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.02834
Value Function Update Magnitude: 0.04705

Collected Steps per Second: 23,920.02791
Overall Steps per Second: 16,768.57214

Timestep Collection Time: 2.09055
Timestep Consumption Time: 0.89158
PPO Batch Consumption Time: 0.09425
Total Iteration Time: 2.98213

Cumulative Model Updates: 8,301
Cumulative Timesteps: 138,594,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.04830
Policy Entropy: 0.67077
Value Function Loss: 1.15793

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.03026
Value Function Update Magnitude: 0.04549

Collected Steps per Second: 23,944.19097
Overall Steps per Second: 16,726.60545

Timestep Collection Time: 2.08953
Timestep Consumption Time: 0.90164
PPO Batch Consumption Time: 0.10395
Total Iteration Time: 2.99116

Cumulative Model Updates: 8,304
Cumulative Timesteps: 138,644,648

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 138644648...
Checkpoint 138644648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,950.57122
Policy Entropy: 0.66583
Value Function Loss: 1.13817

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01618
Policy Update Magnitude: 0.03006
Value Function Update Magnitude: 0.04335

Collected Steps per Second: 23,764.77537
Overall Steps per Second: 16,857.54939

Timestep Collection Time: 2.10505
Timestep Consumption Time: 0.86252
PPO Batch Consumption Time: 0.08477
Total Iteration Time: 2.96757

Cumulative Model Updates: 8,307
Cumulative Timesteps: 138,694,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,143.07288
Policy Entropy: 0.67212
Value Function Loss: 1.08720

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01657
Policy Update Magnitude: 0.03352
Value Function Update Magnitude: 0.04386

Collected Steps per Second: 24,007.34984
Overall Steps per Second: 16,746.06148

Timestep Collection Time: 2.08353
Timestep Consumption Time: 0.90344
PPO Batch Consumption Time: 0.09941
Total Iteration Time: 2.98697

Cumulative Model Updates: 8,310
Cumulative Timesteps: 138,744,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 138744694...
Checkpoint 138744694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,051.81533
Policy Entropy: 0.67879
Value Function Loss: 1.11038

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04193
Policy Update Magnitude: 0.02860
Value Function Update Magnitude: 0.03909

Collected Steps per Second: 23,139.44940
Overall Steps per Second: 16,730.52891

Timestep Collection Time: 2.16107
Timestep Consumption Time: 0.82784
PPO Batch Consumption Time: 0.09317
Total Iteration Time: 2.98891

Cumulative Model Updates: 8,313
Cumulative Timesteps: 138,794,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,614.54027
Policy Entropy: 0.69022
Value Function Loss: 1.05349

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.02663
Value Function Update Magnitude: 0.03063

Collected Steps per Second: 23,173.39162
Overall Steps per Second: 16,730.67638

Timestep Collection Time: 2.15842
Timestep Consumption Time: 0.83117
PPO Batch Consumption Time: 0.10030
Total Iteration Time: 2.98960

Cumulative Model Updates: 8,316
Cumulative Timesteps: 138,844,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 138844718...
Checkpoint 138844718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.37003
Policy Entropy: 0.68656
Value Function Loss: 1.06598

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02013
Policy Update Magnitude: 0.02907
Value Function Update Magnitude: 0.02504

Collected Steps per Second: 22,370.76538
Overall Steps per Second: 16,483.75348

Timestep Collection Time: 2.23613
Timestep Consumption Time: 0.79861
PPO Batch Consumption Time: 0.08379
Total Iteration Time: 3.03475

Cumulative Model Updates: 8,319
Cumulative Timesteps: 138,894,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.72555
Policy Entropy: 0.68367
Value Function Loss: 1.04604

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02582
Policy Update Magnitude: 0.02880
Value Function Update Magnitude: 0.02281

Collected Steps per Second: 22,120.00370
Overall Steps per Second: 15,936.54650

Timestep Collection Time: 2.26067
Timestep Consumption Time: 0.87715
PPO Batch Consumption Time: 0.11118
Total Iteration Time: 3.13782

Cumulative Model Updates: 8,322
Cumulative Timesteps: 138,944,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 138944748...
Checkpoint 138944748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,407.97919
Policy Entropy: 0.67711
Value Function Loss: 1.04716

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04838
Policy Update Magnitude: 0.02688
Value Function Update Magnitude: 0.02222

Collected Steps per Second: 22,266.70677
Overall Steps per Second: 16,887.13231

Timestep Collection Time: 2.24667
Timestep Consumption Time: 0.71570
PPO Batch Consumption Time: 0.05993
Total Iteration Time: 2.96237

Cumulative Model Updates: 8,325
Cumulative Timesteps: 138,994,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.66228
Policy Entropy: 0.67946
Value Function Loss: 1.06756

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04631
Policy Update Magnitude: 0.02303
Value Function Update Magnitude: 0.02246

Collected Steps per Second: 21,293.47855
Overall Steps per Second: 15,514.04826

Timestep Collection Time: 2.34861
Timestep Consumption Time: 0.87492
PPO Batch Consumption Time: 0.08688
Total Iteration Time: 3.22353

Cumulative Model Updates: 8,328
Cumulative Timesteps: 139,044,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 139044784...
Checkpoint 139044784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,666.47171
Policy Entropy: 0.67545
Value Function Loss: 1.09735

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03863
Policy Update Magnitude: 0.02380
Value Function Update Magnitude: 0.02782

Collected Steps per Second: 24,471.74289
Overall Steps per Second: 17,713.52359

Timestep Collection Time: 2.04432
Timestep Consumption Time: 0.77997
PPO Batch Consumption Time: 0.05927
Total Iteration Time: 2.82428

Cumulative Model Updates: 8,331
Cumulative Timesteps: 139,094,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.06322
Policy Entropy: 0.68169
Value Function Loss: 1.09174

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03846
Policy Update Magnitude: 0.02536
Value Function Update Magnitude: 0.02638

Collected Steps per Second: 20,966.54718
Overall Steps per Second: 14,983.75452

Timestep Collection Time: 2.38542
Timestep Consumption Time: 0.95246
PPO Batch Consumption Time: 0.11336
Total Iteration Time: 3.33788

Cumulative Model Updates: 8,334
Cumulative Timesteps: 139,144,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 139144826...
Checkpoint 139144826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,162.44861
Policy Entropy: 0.67759
Value Function Loss: 1.09059

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.02385
Value Function Update Magnitude: 0.03589

Collected Steps per Second: 24,215.34740
Overall Steps per Second: 16,705.16690

Timestep Collection Time: 2.06505
Timestep Consumption Time: 0.92839
PPO Batch Consumption Time: 0.09765
Total Iteration Time: 2.99345

Cumulative Model Updates: 8,337
Cumulative Timesteps: 139,194,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,516.05221
Policy Entropy: 0.67779
Value Function Loss: 1.04621

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05741
Policy Update Magnitude: 0.01878
Value Function Update Magnitude: 0.03545

Collected Steps per Second: 24,133.78418
Overall Steps per Second: 16,717.66970

Timestep Collection Time: 2.07236
Timestep Consumption Time: 0.91932
PPO Batch Consumption Time: 0.10668
Total Iteration Time: 2.99168

Cumulative Model Updates: 8,340
Cumulative Timesteps: 139,244,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 139244846...
Checkpoint 139244846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,012.29512
Policy Entropy: 0.67646
Value Function Loss: 1.05497

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03483
Policy Update Magnitude: 0.02028
Value Function Update Magnitude: 0.04225

Collected Steps per Second: 23,396.94972
Overall Steps per Second: 16,725.03757

Timestep Collection Time: 2.13797
Timestep Consumption Time: 0.85287
PPO Batch Consumption Time: 0.07501
Total Iteration Time: 2.99085

Cumulative Model Updates: 8,343
Cumulative Timesteps: 139,294,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,038.34855
Policy Entropy: 0.67616
Value Function Loss: 1.00835

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03017
Policy Update Magnitude: 0.02345
Value Function Update Magnitude: 0.05006

Collected Steps per Second: 24,363.78932
Overall Steps per Second: 16,772.98547

Timestep Collection Time: 2.05239
Timestep Consumption Time: 0.92883
PPO Batch Consumption Time: 0.10513
Total Iteration Time: 2.98122

Cumulative Model Updates: 8,346
Cumulative Timesteps: 139,344,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 139344872...
Checkpoint 139344872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,036.88704
Policy Entropy: 0.67724
Value Function Loss: 1.03027

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.04204
Policy Update Magnitude: 0.02467
Value Function Update Magnitude: 0.04535

Collected Steps per Second: 23,521.51738
Overall Steps per Second: 16,692.63421

Timestep Collection Time: 2.12690
Timestep Consumption Time: 0.87011
PPO Batch Consumption Time: 0.08592
Total Iteration Time: 2.99701

Cumulative Model Updates: 8,349
Cumulative Timesteps: 139,394,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,665.16985
Policy Entropy: 0.67906
Value Function Loss: 0.99790

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03537
Policy Update Magnitude: 0.02345
Value Function Update Magnitude: 0.04180

Collected Steps per Second: 23,974.64132
Overall Steps per Second: 16,713.66319

Timestep Collection Time: 2.08579
Timestep Consumption Time: 0.90614
PPO Batch Consumption Time: 0.09443
Total Iteration Time: 2.99192

Cumulative Model Updates: 8,352
Cumulative Timesteps: 139,444,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 139444906...
Checkpoint 139444906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,058.56172
Policy Entropy: 0.68948
Value Function Loss: 0.99988

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 0.02374
Value Function Update Magnitude: 0.04078

Collected Steps per Second: 23,924.11904
Overall Steps per Second: 16,788.45559

Timestep Collection Time: 2.09044
Timestep Consumption Time: 0.88851
PPO Batch Consumption Time: 0.09375
Total Iteration Time: 2.97895

Cumulative Model Updates: 8,355
Cumulative Timesteps: 139,494,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,966.82743
Policy Entropy: 0.69415
Value Function Loss: 1.00344

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02841
Policy Update Magnitude: 0.02342
Value Function Update Magnitude: 0.03640

Collected Steps per Second: 24,103.09000
Overall Steps per Second: 16,726.01525

Timestep Collection Time: 2.07558
Timestep Consumption Time: 0.91544
PPO Batch Consumption Time: 0.09773
Total Iteration Time: 2.99103

Cumulative Model Updates: 8,358
Cumulative Timesteps: 139,544,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 139544946...
Checkpoint 139544946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.20918
Policy Entropy: 0.70094
Value Function Loss: 1.00770

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03631
Policy Update Magnitude: 0.02310
Value Function Update Magnitude: 0.03663

Collected Steps per Second: 23,823.49459
Overall Steps per Second: 16,732.12665

Timestep Collection Time: 2.09877
Timestep Consumption Time: 0.88949
PPO Batch Consumption Time: 0.08895
Total Iteration Time: 2.98826

Cumulative Model Updates: 8,361
Cumulative Timesteps: 139,594,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.18995
Policy Entropy: 0.68842
Value Function Loss: 1.06677

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.02595
Value Function Update Magnitude: 0.05314

Collected Steps per Second: 23,617.14019
Overall Steps per Second: 16,723.97017

Timestep Collection Time: 2.11795
Timestep Consumption Time: 0.87296
PPO Batch Consumption Time: 0.09464
Total Iteration Time: 2.99092

Cumulative Model Updates: 8,364
Cumulative Timesteps: 139,644,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 139644966...
Checkpoint 139644966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,907.01647
Policy Entropy: 0.68298
Value Function Loss: 1.06907

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02113
Policy Update Magnitude: 0.02843
Value Function Update Magnitude: 0.05062

Collected Steps per Second: 24,033.18737
Overall Steps per Second: 16,779.47050

Timestep Collection Time: 2.08062
Timestep Consumption Time: 0.89945
PPO Batch Consumption Time: 0.10143
Total Iteration Time: 2.98007

Cumulative Model Updates: 8,367
Cumulative Timesteps: 139,694,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,668.74626
Policy Entropy: 0.67766
Value Function Loss: 1.05343

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01134
Policy Update Magnitude: 0.02993
Value Function Update Magnitude: 0.06351

Collected Steps per Second: 23,688.45819
Overall Steps per Second: 16,706.10840

Timestep Collection Time: 2.11200
Timestep Consumption Time: 0.88271
PPO Batch Consumption Time: 0.10020
Total Iteration Time: 2.99471

Cumulative Model Updates: 8,370
Cumulative Timesteps: 139,745,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 139745000...
Checkpoint 139745000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,880.40293
Policy Entropy: 0.68668
Value Function Loss: 0.98780

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03537
Policy Update Magnitude: 0.02793
Value Function Update Magnitude: 0.06587

Collected Steps per Second: 23,626.29409
Overall Steps per Second: 16,720.63559

Timestep Collection Time: 2.11662
Timestep Consumption Time: 0.87417
PPO Batch Consumption Time: 0.08167
Total Iteration Time: 2.99080

Cumulative Model Updates: 8,373
Cumulative Timesteps: 139,795,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,431.16039
Policy Entropy: 0.68564
Value Function Loss: 1.03127

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03882
Policy Update Magnitude: 0.02403
Value Function Update Magnitude: 0.05730

Collected Steps per Second: 24,422.35319
Overall Steps per Second: 16,838.58638

Timestep Collection Time: 2.04796
Timestep Consumption Time: 0.92236
PPO Batch Consumption Time: 0.11269
Total Iteration Time: 2.97032

Cumulative Model Updates: 8,376
Cumulative Timesteps: 139,845,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 139845024...
Checkpoint 139845024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,428.30383
Policy Entropy: 0.69420
Value Function Loss: 0.98108

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03499
Policy Update Magnitude: 0.02380
Value Function Update Magnitude: 0.04857

Collected Steps per Second: 23,458.30486
Overall Steps per Second: 16,635.52494

Timestep Collection Time: 2.13246
Timestep Consumption Time: 0.87459
PPO Batch Consumption Time: 0.09220
Total Iteration Time: 3.00706

Cumulative Model Updates: 8,379
Cumulative Timesteps: 139,895,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,747.30366
Policy Entropy: 0.70559
Value Function Loss: 1.00849

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03481
Policy Update Magnitude: 0.02286
Value Function Update Magnitude: 0.04666

Collected Steps per Second: 23,830.28962
Overall Steps per Second: 16,744.05989

Timestep Collection Time: 2.09926
Timestep Consumption Time: 0.88843
PPO Batch Consumption Time: 0.10180
Total Iteration Time: 2.98769

Cumulative Model Updates: 8,382
Cumulative Timesteps: 139,945,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 139945074...
Checkpoint 139945074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,907.49500
Policy Entropy: 0.71674
Value Function Loss: 0.93121

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02142
Policy Update Magnitude: 0.02369
Value Function Update Magnitude: 0.03817

Collected Steps per Second: 23,226.12901
Overall Steps per Second: 16,656.96643

Timestep Collection Time: 2.15292
Timestep Consumption Time: 0.84907
PPO Batch Consumption Time: 0.08323
Total Iteration Time: 3.00199

Cumulative Model Updates: 8,385
Cumulative Timesteps: 139,995,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.04525
Policy Entropy: 0.70253
Value Function Loss: 0.99099

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.01893
Policy Update Magnitude: 0.02559
Value Function Update Magnitude: 0.03537

Collected Steps per Second: 23,900.17312
Overall Steps per Second: 16,837.82847

Timestep Collection Time: 2.09229
Timestep Consumption Time: 0.87757
PPO Batch Consumption Time: 0.11068
Total Iteration Time: 2.96986

Cumulative Model Updates: 8,388
Cumulative Timesteps: 140,045,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 140045084...
Checkpoint 140045084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,138.10669
Policy Entropy: 0.69504
Value Function Loss: 0.98421

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01465
Policy Update Magnitude: 0.02854
Value Function Update Magnitude: 0.03586

Collected Steps per Second: 23,090.21045
Overall Steps per Second: 16,756.36609

Timestep Collection Time: 2.16672
Timestep Consumption Time: 0.81901
PPO Batch Consumption Time: 0.09474
Total Iteration Time: 2.98573

Cumulative Model Updates: 8,391
Cumulative Timesteps: 140,095,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,014.16157
Policy Entropy: 0.69454
Value Function Loss: 1.00939

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03169
Policy Update Magnitude: 0.03078
Value Function Update Magnitude: 0.03939

Collected Steps per Second: 23,341.05316
Overall Steps per Second: 16,726.76352

Timestep Collection Time: 2.14223
Timestep Consumption Time: 0.84711
PPO Batch Consumption Time: 0.09736
Total Iteration Time: 2.98934

Cumulative Model Updates: 8,394
Cumulative Timesteps: 140,145,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 140145116...
Checkpoint 140145116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,517.93801
Policy Entropy: 0.70580
Value Function Loss: 1.02655

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.04059
Policy Update Magnitude: 0.02613
Value Function Update Magnitude: 0.03556

Collected Steps per Second: 23,403.74193
Overall Steps per Second: 16,735.26284

Timestep Collection Time: 2.13641
Timestep Consumption Time: 0.85129
PPO Batch Consumption Time: 0.10476
Total Iteration Time: 2.98770

Cumulative Model Updates: 8,397
Cumulative Timesteps: 140,195,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,831.90488
Policy Entropy: 0.70609
Value Function Loss: 0.99159

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04791
Policy Update Magnitude: 0.02515
Value Function Update Magnitude: 0.03291

Collected Steps per Second: 20,131.92695
Overall Steps per Second: 14,758.08025

Timestep Collection Time: 2.48451
Timestep Consumption Time: 0.90468
PPO Batch Consumption Time: 0.10350
Total Iteration Time: 3.38919

Cumulative Model Updates: 8,400
Cumulative Timesteps: 140,245,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 140245134...
Checkpoint 140245134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,441.78895
Policy Entropy: 0.70341
Value Function Loss: 0.99626

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03030
Policy Update Magnitude: 0.02341
Value Function Update Magnitude: 0.03478

Collected Steps per Second: 22,411.62868
Overall Steps per Second: 16,143.80063

Timestep Collection Time: 2.23241
Timestep Consumption Time: 0.86673
PPO Batch Consumption Time: 0.06761
Total Iteration Time: 3.09915

Cumulative Model Updates: 8,403
Cumulative Timesteps: 140,295,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,433.46947
Policy Entropy: 0.70415
Value Function Loss: 0.95259

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.05289
Policy Update Magnitude: 0.02193
Value Function Update Magnitude: 0.02948

Collected Steps per Second: 24,166.37924
Overall Steps per Second: 17,090.39523

Timestep Collection Time: 2.07007
Timestep Consumption Time: 0.85708
PPO Batch Consumption Time: 0.08294
Total Iteration Time: 2.92714

Cumulative Model Updates: 8,406
Cumulative Timesteps: 140,345,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 140345192...
Checkpoint 140345192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,893.17382
Policy Entropy: 0.70368
Value Function Loss: 0.97950

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04864
Policy Update Magnitude: 0.02094
Value Function Update Magnitude: 0.03375

Collected Steps per Second: 23,021.52206
Overall Steps per Second: 15,982.69305

Timestep Collection Time: 2.17232
Timestep Consumption Time: 0.95669
PPO Batch Consumption Time: 0.10376
Total Iteration Time: 3.12901

Cumulative Model Updates: 8,409
Cumulative Timesteps: 140,395,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,352.47336
Policy Entropy: 0.69549
Value Function Loss: 0.94216

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01906
Policy Update Magnitude: 0.02362
Value Function Update Magnitude: 0.03412

Collected Steps per Second: 24,397.63907
Overall Steps per Second: 16,700.71249

Timestep Collection Time: 2.04946
Timestep Consumption Time: 0.94454
PPO Batch Consumption Time: 0.10795
Total Iteration Time: 2.99400

Cumulative Model Updates: 8,412
Cumulative Timesteps: 140,445,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 140445204...
Checkpoint 140445204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,055.54819
Policy Entropy: 0.69194
Value Function Loss: 0.97476

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03865
Policy Update Magnitude: 0.02749
Value Function Update Magnitude: 0.03404

Collected Steps per Second: 23,295.40806
Overall Steps per Second: 16,720.07467

Timestep Collection Time: 2.14755
Timestep Consumption Time: 0.84454
PPO Batch Consumption Time: 0.07993
Total Iteration Time: 2.99209

Cumulative Model Updates: 8,415
Cumulative Timesteps: 140,495,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,405.63652
Policy Entropy: 0.67827
Value Function Loss: 0.98966

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 0.02479
Value Function Update Magnitude: 0.03058

Collected Steps per Second: 24,063.12778
Overall Steps per Second: 16,749.92065

Timestep Collection Time: 2.07862
Timestep Consumption Time: 0.90755
PPO Batch Consumption Time: 0.09958
Total Iteration Time: 2.98616

Cumulative Model Updates: 8,418
Cumulative Timesteps: 140,545,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 140545250...
Checkpoint 140545250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,076.57474
Policy Entropy: 0.67719
Value Function Loss: 0.98630

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.02596
Value Function Update Magnitude: 0.02796

Collected Steps per Second: 23,655.26284
Overall Steps per Second: 16,756.10175

Timestep Collection Time: 2.11539
Timestep Consumption Time: 0.87099
PPO Batch Consumption Time: 0.08419
Total Iteration Time: 2.98637

Cumulative Model Updates: 8,421
Cumulative Timesteps: 140,595,290

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,510.55980
Policy Entropy: 0.68451
Value Function Loss: 0.96674

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 0.02537
Value Function Update Magnitude: 0.03053

Collected Steps per Second: 23,964.06761
Overall Steps per Second: 16,695.00475

Timestep Collection Time: 2.08654
Timestep Consumption Time: 0.90849
PPO Batch Consumption Time: 0.09004
Total Iteration Time: 2.99503

Cumulative Model Updates: 8,424
Cumulative Timesteps: 140,645,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 140645292...
Checkpoint 140645292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,953.52478
Policy Entropy: 0.69358
Value Function Loss: 0.93412

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.05073
Policy Update Magnitude: 0.02412
Value Function Update Magnitude: 0.02414

Collected Steps per Second: 24,155.17614
Overall Steps per Second: 16,786.59594

Timestep Collection Time: 2.07061
Timestep Consumption Time: 0.90891
PPO Batch Consumption Time: 0.09555
Total Iteration Time: 2.97952

Cumulative Model Updates: 8,427
Cumulative Timesteps: 140,695,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,617.34717
Policy Entropy: 0.69897
Value Function Loss: 0.92078

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05617
Policy Update Magnitude: 0.02099
Value Function Update Magnitude: 0.02318

Collected Steps per Second: 23,282.80038
Overall Steps per Second: 16,685.90539

Timestep Collection Time: 2.14845
Timestep Consumption Time: 0.84941
PPO Batch Consumption Time: 0.08338
Total Iteration Time: 2.99786

Cumulative Model Updates: 8,430
Cumulative Timesteps: 140,745,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 140745330...
Checkpoint 140745330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,458.29386
Policy Entropy: 0.70127
Value Function Loss: 0.94344

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04134
Policy Update Magnitude: 0.01973
Value Function Update Magnitude: 0.02433

Collected Steps per Second: 23,595.27075
Overall Steps per Second: 16,754.53534

Timestep Collection Time: 2.11932
Timestep Consumption Time: 0.86530
PPO Batch Consumption Time: 0.09093
Total Iteration Time: 2.98462

Cumulative Model Updates: 8,433
Cumulative Timesteps: 140,795,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,970.50149
Policy Entropy: 0.69625
Value Function Loss: 0.93343

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04558
Policy Update Magnitude: 0.02502
Value Function Update Magnitude: 0.02135

Collected Steps per Second: 22,639.75179
Overall Steps per Second: 15,796.88938

Timestep Collection Time: 2.20965
Timestep Consumption Time: 0.95717
PPO Batch Consumption Time: 0.12200
Total Iteration Time: 3.16683

Cumulative Model Updates: 8,436
Cumulative Timesteps: 140,845,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 140845362...
Checkpoint 140845362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,304.99259
Policy Entropy: 0.69627
Value Function Loss: 0.91647

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06163
Policy Update Magnitude: 0.02761
Value Function Update Magnitude: 0.02018

Collected Steps per Second: 24,170.84234
Overall Steps per Second: 17,735.34402

Timestep Collection Time: 2.06919
Timestep Consumption Time: 0.75083
PPO Batch Consumption Time: 0.05692
Total Iteration Time: 2.82002

Cumulative Model Updates: 8,439
Cumulative Timesteps: 140,895,376

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,778.43640
Policy Entropy: 0.69772
Value Function Loss: 0.89368

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07379
Policy Update Magnitude: 0.02827
Value Function Update Magnitude: 0.01869

Collected Steps per Second: 20,606.30730
Overall Steps per Second: 14,865.74861

Timestep Collection Time: 2.42722
Timestep Consumption Time: 0.93729
PPO Batch Consumption Time: 0.11636
Total Iteration Time: 3.36451

Cumulative Model Updates: 8,442
Cumulative Timesteps: 140,945,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 140945392...
Checkpoint 140945392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,812.60045
Policy Entropy: 0.70499
Value Function Loss: 0.85393

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.02326
Value Function Update Magnitude: 0.02021

Collected Steps per Second: 23,843.97000
Overall Steps per Second: 17,415.71559

Timestep Collection Time: 2.09789
Timestep Consumption Time: 0.77434
PPO Batch Consumption Time: 0.06217
Total Iteration Time: 2.87223

Cumulative Model Updates: 8,445
Cumulative Timesteps: 140,995,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,338.21302
Policy Entropy: 0.69422
Value Function Loss: 0.89291

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.01773
Value Function Update Magnitude: 0.02094

Collected Steps per Second: 21,571.19845
Overall Steps per Second: 15,165.91644

Timestep Collection Time: 2.31893
Timestep Consumption Time: 0.97939
PPO Batch Consumption Time: 0.12476
Total Iteration Time: 3.29832

Cumulative Model Updates: 8,448
Cumulative Timesteps: 141,045,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 141045436...
Checkpoint 141045436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,373.61571
Policy Entropy: 0.68854
Value Function Loss: 0.90104

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05466
Policy Update Magnitude: 0.01788
Value Function Update Magnitude: 0.02156

Collected Steps per Second: 23,741.84233
Overall Steps per Second: 16,684.97942

Timestep Collection Time: 2.10658
Timestep Consumption Time: 0.89097
PPO Batch Consumption Time: 0.10262
Total Iteration Time: 2.99755

Cumulative Model Updates: 8,451
Cumulative Timesteps: 141,095,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,826.52363
Policy Entropy: 0.67552
Value Function Loss: 0.97163

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03847
Policy Update Magnitude: 0.02001
Value Function Update Magnitude: 0.01833

Collected Steps per Second: 24,250.73950
Overall Steps per Second: 16,727.59236

Timestep Collection Time: 2.06295
Timestep Consumption Time: 0.92780
PPO Batch Consumption Time: 0.10946
Total Iteration Time: 2.99075

Cumulative Model Updates: 8,454
Cumulative Timesteps: 141,145,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 141145478...
Checkpoint 141145478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.12507
Policy Entropy: 0.67846
Value Function Loss: 0.94607

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.02400
Value Function Update Magnitude: 0.02161

Collected Steps per Second: 23,024.65023
Overall Steps per Second: 16,479.69259

Timestep Collection Time: 2.17289
Timestep Consumption Time: 0.86297
PPO Batch Consumption Time: 0.08148
Total Iteration Time: 3.03586

Cumulative Model Updates: 8,457
Cumulative Timesteps: 141,195,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.91782
Policy Entropy: 0.68036
Value Function Loss: 0.95553

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04097
Policy Update Magnitude: 0.02433
Value Function Update Magnitude: 0.01960

Collected Steps per Second: 22,463.38988
Overall Steps per Second: 15,922.35078

Timestep Collection Time: 2.22656
Timestep Consumption Time: 0.91469
PPO Batch Consumption Time: 0.11390
Total Iteration Time: 3.14124

Cumulative Model Updates: 8,460
Cumulative Timesteps: 141,245,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 141245524...
Checkpoint 141245524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.90489
Policy Entropy: 0.69058
Value Function Loss: 0.91942

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03967
Policy Update Magnitude: 0.02584
Value Function Update Magnitude: 0.02011

Collected Steps per Second: 22,229.27730
Overall Steps per Second: 17,490.18930

Timestep Collection Time: 2.25055
Timestep Consumption Time: 0.60980
PPO Batch Consumption Time: 0.02972
Total Iteration Time: 2.86035

Cumulative Model Updates: 8,463
Cumulative Timesteps: 141,295,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.95665
Policy Entropy: 0.68955
Value Function Loss: 0.96093

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02373
Policy Update Magnitude: 0.02392
Value Function Update Magnitude: 0.01934

Collected Steps per Second: 23,474.41415
Overall Steps per Second: 17,440.74211

Timestep Collection Time: 2.13092
Timestep Consumption Time: 0.73720
PPO Batch Consumption Time: 0.06894
Total Iteration Time: 2.86811

Cumulative Model Updates: 8,466
Cumulative Timesteps: 141,345,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 141345574...
Checkpoint 141345574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,386.91563
Policy Entropy: 0.69049
Value Function Loss: 0.91428

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02871
Policy Update Magnitude: 0.02574
Value Function Update Magnitude: 0.01618

Collected Steps per Second: 21,426.20358
Overall Steps per Second: 15,524.17832

Timestep Collection Time: 2.33424
Timestep Consumption Time: 0.88744
PPO Batch Consumption Time: 0.11571
Total Iteration Time: 3.22168

Cumulative Model Updates: 8,469
Cumulative Timesteps: 141,395,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,998.96105
Policy Entropy: 0.68227
Value Function Loss: 0.92555

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.02808
Value Function Update Magnitude: 0.01897

Collected Steps per Second: 22,673.02162
Overall Steps per Second: 16,639.60480

Timestep Collection Time: 2.20632
Timestep Consumption Time: 0.80000
PPO Batch Consumption Time: 0.05534
Total Iteration Time: 3.00632

Cumulative Model Updates: 8,472
Cumulative Timesteps: 141,445,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 141445612...
Checkpoint 141445612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,798.46239
Policy Entropy: 0.69047
Value Function Loss: 0.88918

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03561
Policy Update Magnitude: 0.02486
Value Function Update Magnitude: 0.01868

Collected Steps per Second: 20,119.28713
Overall Steps per Second: 14,793.49743

Timestep Collection Time: 2.48637
Timestep Consumption Time: 0.89512
PPO Batch Consumption Time: 0.11193
Total Iteration Time: 3.38149

Cumulative Model Updates: 8,475
Cumulative Timesteps: 141,495,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,221.96545
Policy Entropy: 0.68374
Value Function Loss: 0.93385

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03478
Policy Update Magnitude: 0.02193
Value Function Update Magnitude: 0.01957

Collected Steps per Second: 23,817.06701
Overall Steps per Second: 16,709.83206

Timestep Collection Time: 2.09933
Timestep Consumption Time: 0.89292
PPO Batch Consumption Time: 0.09103
Total Iteration Time: 2.99225

Cumulative Model Updates: 8,478
Cumulative Timesteps: 141,545,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 141545636...
Checkpoint 141545636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,701.44006
Policy Entropy: 0.68632
Value Function Loss: 0.92354

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03223
Policy Update Magnitude: 0.02280
Value Function Update Magnitude: 0.02054

Collected Steps per Second: 23,971.95304
Overall Steps per Second: 16,778.90551

Timestep Collection Time: 2.08736
Timestep Consumption Time: 0.89484
PPO Batch Consumption Time: 0.09587
Total Iteration Time: 2.98220

Cumulative Model Updates: 8,481
Cumulative Timesteps: 141,595,674

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,116.17997
Policy Entropy: 0.68470
Value Function Loss: 0.95202

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04819
Policy Update Magnitude: 0.02651
Value Function Update Magnitude: 0.02070

Collected Steps per Second: 23,830.06399
Overall Steps per Second: 17,636.59971

Timestep Collection Time: 2.09844
Timestep Consumption Time: 0.73691
PPO Batch Consumption Time: 0.02845
Total Iteration Time: 2.83535

Cumulative Model Updates: 8,484
Cumulative Timesteps: 141,645,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 141645680...
Checkpoint 141645680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,952.53596
Policy Entropy: 0.69636
Value Function Loss: 0.93295

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.06209
Policy Update Magnitude: 0.02157
Value Function Update Magnitude: 0.02227

Collected Steps per Second: 24,093.19260
Overall Steps per Second: 18,098.93889

Timestep Collection Time: 2.07536
Timestep Consumption Time: 0.68735
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 2.76270

Cumulative Model Updates: 8,487
Cumulative Timesteps: 141,695,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,752.72585
Policy Entropy: 0.70015
Value Function Loss: 0.90473

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04717
Policy Update Magnitude: 0.02030
Value Function Update Magnitude: 0.02353

Collected Steps per Second: 23,345.62326
Overall Steps per Second: 16,711.25485

Timestep Collection Time: 2.14276
Timestep Consumption Time: 0.85067
PPO Batch Consumption Time: 0.07856
Total Iteration Time: 2.99343

Cumulative Model Updates: 8,490
Cumulative Timesteps: 141,745,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 141745706...
Checkpoint 141745706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,051.01972
Policy Entropy: 0.70168
Value Function Loss: 0.90160

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03255
Policy Update Magnitude: 0.02435
Value Function Update Magnitude: 0.01994

Collected Steps per Second: 23,962.42131
Overall Steps per Second: 17,392.79390

Timestep Collection Time: 2.08727
Timestep Consumption Time: 0.78841
PPO Batch Consumption Time: 0.06189
Total Iteration Time: 2.87567

Cumulative Model Updates: 8,493
Cumulative Timesteps: 141,795,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,885.40801
Policy Entropy: 0.70104
Value Function Loss: 0.89692

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01655
Policy Update Magnitude: 0.02832
Value Function Update Magnitude: 0.02351

Collected Steps per Second: 24,349.62060
Overall Steps per Second: 17,609.87640

Timestep Collection Time: 2.05457
Timestep Consumption Time: 0.78634
PPO Batch Consumption Time: 0.06298
Total Iteration Time: 2.84091

Cumulative Model Updates: 8,496
Cumulative Timesteps: 141,845,750

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 141845750...
Checkpoint 141845750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,130.41766
Policy Entropy: 0.69532
Value Function Loss: 0.89451

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04078
Policy Update Magnitude: 0.02686
Value Function Update Magnitude: 0.02317

Collected Steps per Second: 24,200.10700
Overall Steps per Second: 16,642.56835

Timestep Collection Time: 2.06635
Timestep Consumption Time: 0.93835
PPO Batch Consumption Time: 0.11434
Total Iteration Time: 3.00470

Cumulative Model Updates: 8,499
Cumulative Timesteps: 141,895,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,366.57028
Policy Entropy: 0.70197
Value Function Loss: 0.86416

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.05522
Policy Update Magnitude: 0.02323
Value Function Update Magnitude: 0.02157

Collected Steps per Second: 24,578.37896
Overall Steps per Second: 16,696.50498

Timestep Collection Time: 2.03545
Timestep Consumption Time: 0.96087
PPO Batch Consumption Time: 0.11516
Total Iteration Time: 2.99632

Cumulative Model Updates: 8,502
Cumulative Timesteps: 141,945,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 141945784...
Checkpoint 141945784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,614.72778
Policy Entropy: 0.69261
Value Function Loss: 0.88103

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.02323
Value Function Update Magnitude: 0.02230

Collected Steps per Second: 24,063.63323
Overall Steps per Second: 16,749.89815

Timestep Collection Time: 2.07832
Timestep Consumption Time: 0.90749
PPO Batch Consumption Time: 0.09980
Total Iteration Time: 2.98581

Cumulative Model Updates: 8,505
Cumulative Timesteps: 141,995,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.77074
Policy Entropy: 0.69388
Value Function Loss: 0.88997

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.08118
Policy Update Magnitude: 0.02326
Value Function Update Magnitude: 0.02170

Collected Steps per Second: 23,754.13229
Overall Steps per Second: 16,700.16249

Timestep Collection Time: 2.10540
Timestep Consumption Time: 0.88930
PPO Batch Consumption Time: 0.09295
Total Iteration Time: 2.99470

Cumulative Model Updates: 8,508
Cumulative Timesteps: 142,045,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 142045808...
Checkpoint 142045808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,934.54972
Policy Entropy: 0.69118
Value Function Loss: 0.90588

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.07100
Policy Update Magnitude: 0.01983
Value Function Update Magnitude: 0.02119

Collected Steps per Second: 24,142.07498
Overall Steps per Second: 16,760.61019

Timestep Collection Time: 2.07124
Timestep Consumption Time: 0.91218
PPO Batch Consumption Time: 0.09952
Total Iteration Time: 2.98342

Cumulative Model Updates: 8,511
Cumulative Timesteps: 142,095,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,699.64199
Policy Entropy: 0.68802
Value Function Loss: 0.97115

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.01736
Value Function Update Magnitude: 0.02105

Collected Steps per Second: 24,023.32377
Overall Steps per Second: 16,749.55119

Timestep Collection Time: 2.08248
Timestep Consumption Time: 0.90435
PPO Batch Consumption Time: 0.10484
Total Iteration Time: 2.98683

Cumulative Model Updates: 8,514
Cumulative Timesteps: 142,145,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 142145840...
Checkpoint 142145840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,616.34259
Policy Entropy: 0.69386
Value Function Loss: 0.95567

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.01835
Value Function Update Magnitude: 0.01908

Collected Steps per Second: 24,001.29466
Overall Steps per Second: 16,752.36187

Timestep Collection Time: 2.08364
Timestep Consumption Time: 0.90161
PPO Batch Consumption Time: 0.10262
Total Iteration Time: 2.98525

Cumulative Model Updates: 8,517
Cumulative Timesteps: 142,195,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,285.17110
Policy Entropy: 0.69001
Value Function Loss: 0.93791

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.01839
Value Function Update Magnitude: 0.02165

Collected Steps per Second: 24,084.86354
Overall Steps per Second: 16,706.16047

Timestep Collection Time: 2.07691
Timestep Consumption Time: 0.91732
PPO Batch Consumption Time: 0.09993
Total Iteration Time: 2.99422

Cumulative Model Updates: 8,520
Cumulative Timesteps: 142,245,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 142245872...
Checkpoint 142245872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,221.11239
Policy Entropy: 0.70109
Value Function Loss: 0.88804

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.01825
Value Function Update Magnitude: 0.01979

Collected Steps per Second: 23,683.08644
Overall Steps per Second: 16,751.00836

Timestep Collection Time: 2.11189
Timestep Consumption Time: 0.87396
PPO Batch Consumption Time: 0.09381
Total Iteration Time: 2.98585

Cumulative Model Updates: 8,523
Cumulative Timesteps: 142,295,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,464.50015
Policy Entropy: 0.69265
Value Function Loss: 0.88190

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.01841
Value Function Update Magnitude: 0.02086

Collected Steps per Second: 23,959.70286
Overall Steps per Second: 16,728.00883

Timestep Collection Time: 2.08725
Timestep Consumption Time: 0.90234
PPO Batch Consumption Time: 0.10235
Total Iteration Time: 2.98960

Cumulative Model Updates: 8,526
Cumulative Timesteps: 142,345,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 142345898...
Checkpoint 142345898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,259.94478
Policy Entropy: 0.69869
Value Function Loss: 0.86396

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.07115
Policy Update Magnitude: 0.02077
Value Function Update Magnitude: 0.02084

Collected Steps per Second: 23,999.14039
Overall Steps per Second: 16,708.60580

Timestep Collection Time: 2.08374
Timestep Consumption Time: 0.90921
PPO Batch Consumption Time: 0.10302
Total Iteration Time: 2.99295

Cumulative Model Updates: 8,529
Cumulative Timesteps: 142,395,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,308.24165
Policy Entropy: 0.68653
Value Function Loss: 0.83546

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.01920
Value Function Update Magnitude: 0.01877

Collected Steps per Second: 22,166.42213
Overall Steps per Second: 15,656.47349

Timestep Collection Time: 2.25675
Timestep Consumption Time: 0.93835
PPO Batch Consumption Time: 0.09054
Total Iteration Time: 3.19510

Cumulative Model Updates: 8,532
Cumulative Timesteps: 142,445,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 142445930...
Checkpoint 142445930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,262.39053
Policy Entropy: 0.69814
Value Function Loss: 0.84388

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05917
Policy Update Magnitude: 0.01748
Value Function Update Magnitude: 0.01946

Collected Steps per Second: 23,171.71123
Overall Steps per Second: 17,068.20154

Timestep Collection Time: 2.15910
Timestep Consumption Time: 0.77208
PPO Batch Consumption Time: 0.06069
Total Iteration Time: 2.93118

Cumulative Model Updates: 8,535
Cumulative Timesteps: 142,495,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,982.72065
Policy Entropy: 0.68672
Value Function Loss: 0.84788

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06684
Policy Update Magnitude: 0.01946
Value Function Update Magnitude: 0.01774

Collected Steps per Second: 24,054.66267
Overall Steps per Second: 17,679.20851

Timestep Collection Time: 2.07918
Timestep Consumption Time: 0.74979
PPO Batch Consumption Time: 0.05860
Total Iteration Time: 2.82897

Cumulative Model Updates: 8,538
Cumulative Timesteps: 142,545,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 142545974...
Checkpoint 142545974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,308.38033
Policy Entropy: 0.68952
Value Function Loss: 0.86635

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.05147
Policy Update Magnitude: 0.02090
Value Function Update Magnitude: 0.01995

Collected Steps per Second: 20,841.64529
Overall Steps per Second: 14,769.96746

Timestep Collection Time: 2.39991
Timestep Consumption Time: 0.98656
PPO Batch Consumption Time: 0.12758
Total Iteration Time: 3.38647

Cumulative Model Updates: 8,541
Cumulative Timesteps: 142,595,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,769.66127
Policy Entropy: 0.67476
Value Function Loss: 0.88533

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01404
Policy Update Magnitude: 0.02291
Value Function Update Magnitude: 0.02115

Collected Steps per Second: 23,920.98649
Overall Steps per Second: 17,665.86694

Timestep Collection Time: 2.09021
Timestep Consumption Time: 0.74010
PPO Batch Consumption Time: 0.05855
Total Iteration Time: 2.83032

Cumulative Model Updates: 8,544
Cumulative Timesteps: 142,645,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 142645992...
Checkpoint 142645992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.89848
Policy Entropy: 0.66908
Value Function Loss: 0.88831

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02141
Policy Update Magnitude: 0.02574
Value Function Update Magnitude: 0.02270

Collected Steps per Second: 21,696.95547
Overall Steps per Second: 15,868.80199

Timestep Collection Time: 2.30484
Timestep Consumption Time: 0.84650
PPO Batch Consumption Time: 0.08391
Total Iteration Time: 3.15134

Cumulative Model Updates: 8,547
Cumulative Timesteps: 142,696,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,858.83131
Policy Entropy: 0.67421
Value Function Loss: 0.87577

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02255
Policy Update Magnitude: 0.02781
Value Function Update Magnitude: 0.02146

Collected Steps per Second: 24,164.60022
Overall Steps per Second: 17,589.26695

Timestep Collection Time: 2.07022
Timestep Consumption Time: 0.77390
PPO Batch Consumption Time: 0.06228
Total Iteration Time: 2.84412

Cumulative Model Updates: 8,550
Cumulative Timesteps: 142,746,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 142746026...
Checkpoint 142746026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.09330
Policy Entropy: 0.67606
Value Function Loss: 0.90867

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.02710
Value Function Update Magnitude: 0.02101

Collected Steps per Second: 20,363.06244
Overall Steps per Second: 15,040.00540

Timestep Collection Time: 2.45631
Timestep Consumption Time: 0.86935
PPO Batch Consumption Time: 0.09415
Total Iteration Time: 3.32566

Cumulative Model Updates: 8,553
Cumulative Timesteps: 142,796,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,958.79443
Policy Entropy: 0.68233
Value Function Loss: 0.89741

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.02595
Value Function Update Magnitude: 0.02212

Collected Steps per Second: 23,103.09852
Overall Steps per Second: 16,683.72350

Timestep Collection Time: 2.16577
Timestep Consumption Time: 0.83332
PPO Batch Consumption Time: 0.09660
Total Iteration Time: 2.99909

Cumulative Model Updates: 8,556
Cumulative Timesteps: 142,846,080

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 142846080...
Checkpoint 142846080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,588.89444
Policy Entropy: 0.67026
Value Function Loss: 0.93708

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03551
Policy Update Magnitude: 0.02750
Value Function Update Magnitude: 0.02379

Collected Steps per Second: 22,670.21107
Overall Steps per Second: 16,605.30101

Timestep Collection Time: 2.20607
Timestep Consumption Time: 0.80574
PPO Batch Consumption Time: 0.08337
Total Iteration Time: 3.01181

Cumulative Model Updates: 8,559
Cumulative Timesteps: 142,896,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,784.57113
Policy Entropy: 0.68286
Value Function Loss: 0.85182

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.05076
Policy Update Magnitude: 0.02452
Value Function Update Magnitude: 0.02422

Collected Steps per Second: 23,065.72917
Overall Steps per Second: 17,404.60385

Timestep Collection Time: 2.16911
Timestep Consumption Time: 0.70554
PPO Batch Consumption Time: 0.06021
Total Iteration Time: 2.87464

Cumulative Model Updates: 8,562
Cumulative Timesteps: 142,946,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 142946124...
Checkpoint 142946124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,386.07196
Policy Entropy: 0.68652
Value Function Loss: 0.82788

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.05058
Policy Update Magnitude: 0.02187
Value Function Update Magnitude: 0.02475

Collected Steps per Second: 23,513.27023
Overall Steps per Second: 17,285.70125

Timestep Collection Time: 2.12765
Timestep Consumption Time: 0.76653
PPO Batch Consumption Time: 0.07956
Total Iteration Time: 2.89418

Cumulative Model Updates: 8,565
Cumulative Timesteps: 142,996,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,645.83058
Policy Entropy: 0.68688
Value Function Loss: 0.80715

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.02162
Value Function Update Magnitude: 0.02497

Collected Steps per Second: 22,294.86253
Overall Steps per Second: 15,901.94989

Timestep Collection Time: 2.24357
Timestep Consumption Time: 0.90196
PPO Batch Consumption Time: 0.12180
Total Iteration Time: 3.14553

Cumulative Model Updates: 8,568
Cumulative Timesteps: 143,046,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 143046172...
Checkpoint 143046172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,310.29834
Policy Entropy: 0.67596
Value Function Loss: 0.81835

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.02408
Value Function Update Magnitude: 0.02466

Collected Steps per Second: 22,908.35011
Overall Steps per Second: 16,681.54514

Timestep Collection Time: 2.18340
Timestep Consumption Time: 0.81501
PPO Batch Consumption Time: 0.09437
Total Iteration Time: 2.99840

Cumulative Model Updates: 8,571
Cumulative Timesteps: 143,096,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,853.43704
Policy Entropy: 0.67148
Value Function Loss: 0.84188

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03950
Policy Update Magnitude: 0.02306
Value Function Update Magnitude: 0.02688

Collected Steps per Second: 23,846.90446
Overall Steps per Second: 16,677.35001

Timestep Collection Time: 2.09696
Timestep Consumption Time: 0.90148
PPO Batch Consumption Time: 0.09264
Total Iteration Time: 2.99844

Cumulative Model Updates: 8,574
Cumulative Timesteps: 143,146,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 143146196...
Checkpoint 143146196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,044.69053
Policy Entropy: 0.66583
Value Function Loss: 0.81000

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 0.02038
Value Function Update Magnitude: 0.02804

Collected Steps per Second: 23,995.66196
Overall Steps per Second: 16,784.58299

Timestep Collection Time: 2.08463
Timestep Consumption Time: 0.89561
PPO Batch Consumption Time: 0.09699
Total Iteration Time: 2.98023

Cumulative Model Updates: 8,577
Cumulative Timesteps: 143,196,218

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,154.59171
Policy Entropy: 0.66747
Value Function Loss: 0.80717

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00995
Policy Update Magnitude: 0.02515
Value Function Update Magnitude: 0.03117

Collected Steps per Second: 24,439.71707
Overall Steps per Second: 16,706.74021

Timestep Collection Time: 2.04610
Timestep Consumption Time: 0.94707
PPO Batch Consumption Time: 0.10742
Total Iteration Time: 2.99316

Cumulative Model Updates: 8,580
Cumulative Timesteps: 143,246,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 143246224...
Checkpoint 143246224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,013.24389
Policy Entropy: 0.66580
Value Function Loss: 0.80974

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.02593
Value Function Update Magnitude: 0.02813

Collected Steps per Second: 23,624.63758
Overall Steps per Second: 16,751.24789

Timestep Collection Time: 2.11720
Timestep Consumption Time: 0.86873
PPO Batch Consumption Time: 0.08311
Total Iteration Time: 2.98593

Cumulative Model Updates: 8,583
Cumulative Timesteps: 143,296,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,737.68602
Policy Entropy: 0.67532
Value Function Loss: 0.83797

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.02695
Value Function Update Magnitude: 0.02814

Collected Steps per Second: 23,486.91401
Overall Steps per Second: 16,565.08214

Timestep Collection Time: 2.12944
Timestep Consumption Time: 0.88980
PPO Batch Consumption Time: 0.07866
Total Iteration Time: 3.01924

Cumulative Model Updates: 8,586
Cumulative Timesteps: 143,346,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 143346256...
Checkpoint 143346256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,017.58325
Policy Entropy: 0.67266
Value Function Loss: 0.83418

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03141
Policy Update Magnitude: 0.02592
Value Function Update Magnitude: 0.02522

Collected Steps per Second: 22,906.32968
Overall Steps per Second: 16,916.64823

Timestep Collection Time: 2.18298
Timestep Consumption Time: 0.77293
PPO Batch Consumption Time: 0.05467
Total Iteration Time: 2.95590

Cumulative Model Updates: 8,589
Cumulative Timesteps: 143,396,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,324.03087
Policy Entropy: 0.67486
Value Function Loss: 0.82876

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 0.02695
Value Function Update Magnitude: 0.02694

Collected Steps per Second: 21,116.00100
Overall Steps per Second: 14,763.88061

Timestep Collection Time: 2.36920
Timestep Consumption Time: 1.01934
PPO Batch Consumption Time: 0.13136
Total Iteration Time: 3.38854

Cumulative Model Updates: 8,592
Cumulative Timesteps: 143,446,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 143446288...
Checkpoint 143446288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,948.05729
Policy Entropy: 0.66520
Value Function Loss: 0.79743

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04771
Policy Update Magnitude: 0.02469
Value Function Update Magnitude: 0.02672

Collected Steps per Second: 24,457.01786
Overall Steps per Second: 17,703.42414

Timestep Collection Time: 2.04465
Timestep Consumption Time: 0.78000
PPO Batch Consumption Time: 0.05959
Total Iteration Time: 2.82465

Cumulative Model Updates: 8,595
Cumulative Timesteps: 143,496,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,780.01249
Policy Entropy: 0.66961
Value Function Loss: 0.81357

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04223
Policy Update Magnitude: 0.02113
Value Function Update Magnitude: 0.02877

Collected Steps per Second: 21,783.67901
Overall Steps per Second: 15,829.20616

Timestep Collection Time: 2.29530
Timestep Consumption Time: 0.86342
PPO Batch Consumption Time: 0.08282
Total Iteration Time: 3.15872

Cumulative Model Updates: 8,598
Cumulative Timesteps: 143,546,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 143546294...
Checkpoint 143546294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,291.74267
Policy Entropy: 0.66413
Value Function Loss: 0.81916

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03296
Policy Update Magnitude: 0.02181
Value Function Update Magnitude: 0.02857

Collected Steps per Second: 23,555.70084
Overall Steps per Second: 17,223.50681

Timestep Collection Time: 2.12399
Timestep Consumption Time: 0.78088
PPO Batch Consumption Time: 0.05937
Total Iteration Time: 2.90487

Cumulative Model Updates: 8,601
Cumulative Timesteps: 143,596,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,839.14838
Policy Entropy: 0.66566
Value Function Loss: 0.82581

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03940
Policy Update Magnitude: 0.02267
Value Function Update Magnitude: 0.03250

Collected Steps per Second: 24,443.46986
Overall Steps per Second: 17,390.85067

Timestep Collection Time: 2.04554
Timestep Consumption Time: 0.82954
PPO Batch Consumption Time: 0.07691
Total Iteration Time: 2.87508

Cumulative Model Updates: 8,604
Cumulative Timesteps: 143,646,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 143646326...
Checkpoint 143646326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,323.58284
Policy Entropy: 0.65915
Value Function Loss: 0.83113

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04699
Policy Update Magnitude: 0.02238
Value Function Update Magnitude: 0.03426

Collected Steps per Second: 23,755.77354
Overall Steps per Second: 17,111.42687

Timestep Collection Time: 2.10475
Timestep Consumption Time: 0.81727
PPO Batch Consumption Time: 0.06296
Total Iteration Time: 2.92202

Cumulative Model Updates: 8,607
Cumulative Timesteps: 143,696,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,010.85023
Policy Entropy: 0.67059
Value Function Loss: 0.83493

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05983
Policy Update Magnitude: 0.02150
Value Function Update Magnitude: 0.04203

Collected Steps per Second: 23,583.89426
Overall Steps per Second: 17,303.71319

Timestep Collection Time: 2.12204
Timestep Consumption Time: 0.77017
PPO Batch Consumption Time: 0.05676
Total Iteration Time: 2.89221

Cumulative Model Updates: 8,610
Cumulative Timesteps: 143,746,372

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 143746372...
Checkpoint 143746372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.07075
Policy Entropy: 0.66644
Value Function Loss: 0.81847

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03066
Policy Update Magnitude: 0.02124
Value Function Update Magnitude: 0.04736

Collected Steps per Second: 20,883.08105
Overall Steps per Second: 14,849.10747

Timestep Collection Time: 2.39467
Timestep Consumption Time: 0.97308
PPO Batch Consumption Time: 0.12024
Total Iteration Time: 3.36774

Cumulative Model Updates: 8,613
Cumulative Timesteps: 143,796,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.00030
Policy Entropy: 0.66554
Value Function Loss: 0.80589

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04637
Policy Update Magnitude: 0.02505
Value Function Update Magnitude: 0.04708

Collected Steps per Second: 23,973.76170
Overall Steps per Second: 17,373.87617

Timestep Collection Time: 2.08678
Timestep Consumption Time: 0.79271
PPO Batch Consumption Time: 0.06059
Total Iteration Time: 2.87950

Cumulative Model Updates: 8,616
Cumulative Timesteps: 143,846,408

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 143846408...
Checkpoint 143846408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,416.41750
Policy Entropy: 0.66900
Value Function Loss: 0.78642

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.05025
Policy Update Magnitude: 0.02563
Value Function Update Magnitude: 0.04271

Collected Steps per Second: 22,730.16634
Overall Steps per Second: 16,271.63286

Timestep Collection Time: 2.19998
Timestep Consumption Time: 0.87322
PPO Batch Consumption Time: 0.07914
Total Iteration Time: 3.07320

Cumulative Model Updates: 8,619
Cumulative Timesteps: 143,896,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,149.60096
Policy Entropy: 0.68075
Value Function Loss: 0.77620

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.06058
Policy Update Magnitude: 0.02529
Value Function Update Magnitude: 0.04853

Collected Steps per Second: 23,808.83255
Overall Steps per Second: 17,250.17863

Timestep Collection Time: 2.10107
Timestep Consumption Time: 0.79884
PPO Batch Consumption Time: 0.06303
Total Iteration Time: 2.89991

Cumulative Model Updates: 8,622
Cumulative Timesteps: 143,946,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 143946438...
Checkpoint 143946438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,077.40601
Policy Entropy: 0.67861
Value Function Loss: 0.79218

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06641
Policy Update Magnitude: 0.02584
Value Function Update Magnitude: 0.03937

Collected Steps per Second: 22,710.73465
Overall Steps per Second: 16,321.52710

Timestep Collection Time: 2.20222
Timestep Consumption Time: 0.86208
PPO Batch Consumption Time: 0.08984
Total Iteration Time: 3.06430

Cumulative Model Updates: 8,625
Cumulative Timesteps: 143,996,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,167.81103
Policy Entropy: 0.67826
Value Function Loss: 0.81950

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07121
Policy Update Magnitude: 0.02531
Value Function Update Magnitude: 0.03890

Collected Steps per Second: 24,203.43074
Overall Steps per Second: 17,757.20042

Timestep Collection Time: 2.06698
Timestep Consumption Time: 0.75036
PPO Batch Consumption Time: 0.05716
Total Iteration Time: 2.81734

Cumulative Model Updates: 8,628
Cumulative Timesteps: 144,046,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 144046480...
Checkpoint 144046480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,225.13486
Policy Entropy: 0.67786
Value Function Loss: 0.81148

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.02554
Value Function Update Magnitude: 0.03398

Collected Steps per Second: 20,896.44844
Overall Steps per Second: 14,957.72647

Timestep Collection Time: 2.39275
Timestep Consumption Time: 0.95000
PPO Batch Consumption Time: 0.11748
Total Iteration Time: 3.34275

Cumulative Model Updates: 8,631
Cumulative Timesteps: 144,096,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,188.80579
Policy Entropy: 0.68526
Value Function Loss: 0.78112

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.02541
Value Function Update Magnitude: 0.03272

Collected Steps per Second: 24,142.69195
Overall Steps per Second: 16,677.76851

Timestep Collection Time: 2.07226
Timestep Consumption Time: 0.92754
PPO Batch Consumption Time: 0.11541
Total Iteration Time: 2.99980

Cumulative Model Updates: 8,634
Cumulative Timesteps: 144,146,510

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 144146510...
Checkpoint 144146510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,336.08656
Policy Entropy: 0.67381
Value Function Loss: 0.79429

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.02297
Value Function Update Magnitude: 0.02830

Collected Steps per Second: 23,006.27918
Overall Steps per Second: 16,641.80341

Timestep Collection Time: 2.17488
Timestep Consumption Time: 0.83176
PPO Batch Consumption Time: 0.07378
Total Iteration Time: 3.00665

Cumulative Model Updates: 8,637
Cumulative Timesteps: 144,196,546

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,465.81852
Policy Entropy: 0.66545
Value Function Loss: 0.81501

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.07429
Policy Update Magnitude: 0.02024
Value Function Update Magnitude: 0.03249

Collected Steps per Second: 24,292.12482
Overall Steps per Second: 16,801.38375

Timestep Collection Time: 2.05902
Timestep Consumption Time: 0.91800
PPO Batch Consumption Time: 0.10684
Total Iteration Time: 2.97702

Cumulative Model Updates: 8,640
Cumulative Timesteps: 144,246,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 144246564...
Checkpoint 144246564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,772.04335
Policy Entropy: 0.65166
Value Function Loss: 0.80833

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04843
Policy Update Magnitude: 0.02079
Value Function Update Magnitude: 0.03204

Collected Steps per Second: 23,755.56197
Overall Steps per Second: 16,748.03972

Timestep Collection Time: 2.10519
Timestep Consumption Time: 0.88083
PPO Batch Consumption Time: 0.09176
Total Iteration Time: 2.98602

Cumulative Model Updates: 8,643
Cumulative Timesteps: 144,296,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,502.31314
Policy Entropy: 0.65802
Value Function Loss: 0.75787

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 0.02214
Value Function Update Magnitude: 0.03387

Collected Steps per Second: 23,438.96269
Overall Steps per Second: 16,557.05269

Timestep Collection Time: 2.13380
Timestep Consumption Time: 0.88691
PPO Batch Consumption Time: 0.08835
Total Iteration Time: 3.02071

Cumulative Model Updates: 8,646
Cumulative Timesteps: 144,346,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 144346588...
Checkpoint 144346588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,057.81190
Policy Entropy: 0.65717
Value Function Loss: 0.75723

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03117
Policy Update Magnitude: 0.02479
Value Function Update Magnitude: 0.03069

Collected Steps per Second: 23,410.39794
Overall Steps per Second: 17,249.54281

Timestep Collection Time: 2.13666
Timestep Consumption Time: 0.76313
PPO Batch Consumption Time: 0.06364
Total Iteration Time: 2.89979

Cumulative Model Updates: 8,649
Cumulative Timesteps: 144,396,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,457.94228
Policy Entropy: 0.66095
Value Function Loss: 0.78545

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03339
Policy Update Magnitude: 0.02681
Value Function Update Magnitude: 0.03461

Collected Steps per Second: 23,178.32115
Overall Steps per Second: 16,253.22611

Timestep Collection Time: 2.15762
Timestep Consumption Time: 0.91931
PPO Batch Consumption Time: 0.09671
Total Iteration Time: 3.07693

Cumulative Model Updates: 8,652
Cumulative Timesteps: 144,446,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 144446618...
Checkpoint 144446618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,543.88999
Policy Entropy: 0.65357
Value Function Loss: 0.77141

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04353
Policy Update Magnitude: 0.02217
Value Function Update Magnitude: 0.03257

Collected Steps per Second: 24,162.16808
Overall Steps per Second: 17,759.79025

Timestep Collection Time: 2.07134
Timestep Consumption Time: 0.74671
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 2.81805

Cumulative Model Updates: 8,655
Cumulative Timesteps: 144,496,666

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,835.00773
Policy Entropy: 0.65763
Value Function Loss: 0.76504

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.02312
Value Function Update Magnitude: 0.03455

Collected Steps per Second: 21,121.36977
Overall Steps per Second: 15,086.45308

Timestep Collection Time: 2.36737
Timestep Consumption Time: 0.94700
PPO Batch Consumption Time: 0.12038
Total Iteration Time: 3.31436

Cumulative Model Updates: 8,658
Cumulative Timesteps: 144,546,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 144546668...
Checkpoint 144546668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,678.39047
Policy Entropy: 0.66422
Value Function Loss: 0.76004

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 0.02460
Value Function Update Magnitude: 0.03150

Collected Steps per Second: 23,768.51598
Overall Steps per Second: 17,413.21612

Timestep Collection Time: 2.10413
Timestep Consumption Time: 0.76794
PPO Batch Consumption Time: 0.06202
Total Iteration Time: 2.87207

Cumulative Model Updates: 8,661
Cumulative Timesteps: 144,596,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,794.41553
Policy Entropy: 0.67198
Value Function Loss: 0.77891

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03067
Policy Update Magnitude: 0.02335
Value Function Update Magnitude: 0.02893

Collected Steps per Second: 21,477.08880
Overall Steps per Second: 15,927.74209

Timestep Collection Time: 2.32862
Timestep Consumption Time: 0.81131
PPO Batch Consumption Time: 0.07486
Total Iteration Time: 3.13993

Cumulative Model Updates: 8,664
Cumulative Timesteps: 144,646,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 144646692...
Checkpoint 144646692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,041.51577
Policy Entropy: 0.66520
Value Function Loss: 0.78354

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02125
Policy Update Magnitude: 0.02391
Value Function Update Magnitude: 0.03152

Collected Steps per Second: 24,032.80640
Overall Steps per Second: 17,601.29498

Timestep Collection Time: 2.08116
Timestep Consumption Time: 0.76045
PPO Batch Consumption Time: 0.06078
Total Iteration Time: 2.84161

Cumulative Model Updates: 8,667
Cumulative Timesteps: 144,696,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,338.40991
Policy Entropy: 0.65622
Value Function Loss: 0.76377

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01377
Policy Update Magnitude: 0.02716
Value Function Update Magnitude: 0.03252

Collected Steps per Second: 20,970.89596
Overall Steps per Second: 15,128.12676

Timestep Collection Time: 2.38502
Timestep Consumption Time: 0.92114
PPO Batch Consumption Time: 0.11320
Total Iteration Time: 3.30616

Cumulative Model Updates: 8,670
Cumulative Timesteps: 144,746,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 144746724...
Checkpoint 144746724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,670.54701
Policy Entropy: 0.66127
Value Function Loss: 0.76356

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.02746
Value Function Update Magnitude: 0.03183

Collected Steps per Second: 23,427.32924
Overall Steps per Second: 17,263.93017

Timestep Collection Time: 2.13426
Timestep Consumption Time: 0.76195
PPO Batch Consumption Time: 0.06281
Total Iteration Time: 2.89621

Cumulative Model Updates: 8,673
Cumulative Timesteps: 144,796,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,393.30949
Policy Entropy: 0.67004
Value Function Loss: 0.78402

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.02550
Value Function Update Magnitude: 0.03258

Collected Steps per Second: 23,936.68433
Overall Steps per Second: 17,289.94808

Timestep Collection Time: 2.08943
Timestep Consumption Time: 0.80323
PPO Batch Consumption Time: 0.08977
Total Iteration Time: 2.89266

Cumulative Model Updates: 8,676
Cumulative Timesteps: 144,846,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 144846738...
Checkpoint 144846738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,047.41231
Policy Entropy: 0.67453
Value Function Loss: 0.76977

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02993
Policy Update Magnitude: 0.02580
Value Function Update Magnitude: 0.02908

Collected Steps per Second: 22,473.54049
Overall Steps per Second: 17,090.72979

Timestep Collection Time: 2.22600
Timestep Consumption Time: 0.70109
PPO Batch Consumption Time: 0.06075
Total Iteration Time: 2.92708

Cumulative Model Updates: 8,679
Cumulative Timesteps: 144,896,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,558.99244
Policy Entropy: 0.66229
Value Function Loss: 0.75316

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04134
Policy Update Magnitude: 0.02259
Value Function Update Magnitude: 0.03015

Collected Steps per Second: 23,101.44873
Overall Steps per Second: 17,436.96615

Timestep Collection Time: 2.16445
Timestep Consumption Time: 0.70313
PPO Batch Consumption Time: 0.05991
Total Iteration Time: 2.86759

Cumulative Model Updates: 8,682
Cumulative Timesteps: 144,946,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 144946766...
Checkpoint 144946766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,517.07258
Policy Entropy: 0.66275
Value Function Loss: 0.72240

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04703
Policy Update Magnitude: 0.02162
Value Function Update Magnitude: 0.02983

Collected Steps per Second: 19,716.67921
Overall Steps per Second: 14,621.58590

Timestep Collection Time: 2.53592
Timestep Consumption Time: 0.88368
PPO Batch Consumption Time: 0.10796
Total Iteration Time: 3.41960

Cumulative Model Updates: 8,685
Cumulative Timesteps: 144,996,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,366.57297
Policy Entropy: 0.65939
Value Function Loss: 0.72193

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05671
Policy Update Magnitude: 0.02045
Value Function Update Magnitude: 0.03391

Collected Steps per Second: 22,792.81565
Overall Steps per Second: 17,047.41650

Timestep Collection Time: 2.19481
Timestep Consumption Time: 0.73971
PPO Batch Consumption Time: 0.06030
Total Iteration Time: 2.93452

Cumulative Model Updates: 8,688
Cumulative Timesteps: 145,046,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 145046792...
Checkpoint 145046792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,195.65877
Policy Entropy: 0.66996
Value Function Loss: 0.72565

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03921
Policy Update Magnitude: 0.02057
Value Function Update Magnitude: 0.03412

Collected Steps per Second: 21,183.90041
Overall Steps per Second: 15,703.50427

Timestep Collection Time: 2.36028
Timestep Consumption Time: 0.82372
PPO Batch Consumption Time: 0.09728
Total Iteration Time: 3.18400

Cumulative Model Updates: 8,691
Cumulative Timesteps: 145,096,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,112.83413
Policy Entropy: 0.66933
Value Function Loss: 0.73237

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.02339
Value Function Update Magnitude: 0.04101

Collected Steps per Second: 23,271.99808
Overall Steps per Second: 16,724.83895

Timestep Collection Time: 2.14954
Timestep Consumption Time: 0.84146
PPO Batch Consumption Time: 0.09813
Total Iteration Time: 2.99100

Cumulative Model Updates: 8,694
Cumulative Timesteps: 145,146,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 145146816...
Checkpoint 145146816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,749.31708
Policy Entropy: 0.66318
Value Function Loss: 0.77865

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03323
Policy Update Magnitude: 0.02387
Value Function Update Magnitude: 0.03587

Collected Steps per Second: 24,189.35694
Overall Steps per Second: 16,769.00235

Timestep Collection Time: 2.06777
Timestep Consumption Time: 0.91500
PPO Batch Consumption Time: 0.09468
Total Iteration Time: 2.98277

Cumulative Model Updates: 8,697
Cumulative Timesteps: 145,196,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,068.98706
Policy Entropy: 0.65613
Value Function Loss: 0.84477

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01579
Policy Update Magnitude: 0.02671
Value Function Update Magnitude: 0.03674

Collected Steps per Second: 24,409.62858
Overall Steps per Second: 16,802.87628

Timestep Collection Time: 2.04952
Timestep Consumption Time: 0.92783
PPO Batch Consumption Time: 0.10556
Total Iteration Time: 2.97735

Cumulative Model Updates: 8,700
Cumulative Timesteps: 145,246,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 145246862...
Checkpoint 145246862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,540.08625
Policy Entropy: 0.65417
Value Function Loss: 0.84144

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.02680
Value Function Update Magnitude: 0.02885

Collected Steps per Second: 24,152.30269
Overall Steps per Second: 16,704.64416

Timestep Collection Time: 2.07144
Timestep Consumption Time: 0.92354
PPO Batch Consumption Time: 0.10738
Total Iteration Time: 2.99498

Cumulative Model Updates: 8,703
Cumulative Timesteps: 145,296,892

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,955.97837
Policy Entropy: 0.65644
Value Function Loss: 0.82495

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.02892
Value Function Update Magnitude: 0.02574

Collected Steps per Second: 24,308.21727
Overall Steps per Second: 16,682.85174

Timestep Collection Time: 2.05799
Timestep Consumption Time: 0.94066
PPO Batch Consumption Time: 0.11258
Total Iteration Time: 2.99865

Cumulative Model Updates: 8,706
Cumulative Timesteps: 145,346,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 145346918...
Checkpoint 145346918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,234.56678
Policy Entropy: 0.65792
Value Function Loss: 0.80410

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03764
Policy Update Magnitude: 0.02469
Value Function Update Magnitude: 0.02267

Collected Steps per Second: 23,159.95844
Overall Steps per Second: 16,548.46750

Timestep Collection Time: 2.15933
Timestep Consumption Time: 0.86270
PPO Batch Consumption Time: 0.08107
Total Iteration Time: 3.02203

Cumulative Model Updates: 8,709
Cumulative Timesteps: 145,396,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,748.42621
Policy Entropy: 0.65939
Value Function Loss: 0.76738

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03083
Policy Update Magnitude: 0.02332
Value Function Update Magnitude: 0.02615

Collected Steps per Second: 21,778.77688
Overall Steps per Second: 15,704.31508

Timestep Collection Time: 2.29682
Timestep Consumption Time: 0.88842
PPO Batch Consumption Time: 0.08401
Total Iteration Time: 3.18524

Cumulative Model Updates: 8,712
Cumulative Timesteps: 145,446,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 145446950...
Checkpoint 145446950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,829.87380
Policy Entropy: 0.65995
Value Function Loss: 0.76277

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 0.02225
Value Function Update Magnitude: 0.02570

Collected Steps per Second: 23,637.52097
Overall Steps per Second: 17,131.77077

Timestep Collection Time: 2.11647
Timestep Consumption Time: 0.80372
PPO Batch Consumption Time: 0.06411
Total Iteration Time: 2.92019

Cumulative Model Updates: 8,715
Cumulative Timesteps: 145,496,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,650.09724
Policy Entropy: 0.65969
Value Function Loss: 0.77983

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03426
Policy Update Magnitude: 0.02456
Value Function Update Magnitude: 0.02798

Collected Steps per Second: 23,930.83085
Overall Steps per Second: 17,541.76868

Timestep Collection Time: 2.08986
Timestep Consumption Time: 0.76117
PPO Batch Consumption Time: 0.05910
Total Iteration Time: 2.85102

Cumulative Model Updates: 8,718
Cumulative Timesteps: 145,546,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 145546990...
Checkpoint 145546990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,065.13843
Policy Entropy: 0.66481
Value Function Loss: 0.75637

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03128
Policy Update Magnitude: 0.02216
Value Function Update Magnitude: 0.02750

Collected Steps per Second: 19,431.99164
Overall Steps per Second: 14,095.70999

Timestep Collection Time: 2.57421
Timestep Consumption Time: 0.97453
PPO Batch Consumption Time: 0.11775
Total Iteration Time: 3.54874

Cumulative Model Updates: 8,721
Cumulative Timesteps: 145,597,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,489.17724
Policy Entropy: 0.67030
Value Function Loss: 0.75261

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.02274
Value Function Update Magnitude: 0.02718

Collected Steps per Second: 24,285.94942
Overall Steps per Second: 16,691.30217

Timestep Collection Time: 2.05897
Timestep Consumption Time: 0.93684
PPO Batch Consumption Time: 0.11221
Total Iteration Time: 2.99581

Cumulative Model Updates: 8,724
Cumulative Timesteps: 145,647,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 145647016...
Checkpoint 145647016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,167.29118
Policy Entropy: 0.67563
Value Function Loss: 0.74415

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02141
Policy Update Magnitude: 0.02415
Value Function Update Magnitude: 0.02561

Collected Steps per Second: 24,016.48606
Overall Steps per Second: 16,722.83006

Timestep Collection Time: 2.08307
Timestep Consumption Time: 0.90853
PPO Batch Consumption Time: 0.09282
Total Iteration Time: 2.99160

Cumulative Model Updates: 8,727
Cumulative Timesteps: 145,697,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,357.51997
Policy Entropy: 0.67302
Value Function Loss: 0.77315

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03311
Policy Update Magnitude: 0.02586
Value Function Update Magnitude: 0.02299

Collected Steps per Second: 23,615.89569
Overall Steps per Second: 16,701.92395

Timestep Collection Time: 2.11815
Timestep Consumption Time: 0.87683
PPO Batch Consumption Time: 0.08901
Total Iteration Time: 2.99498

Cumulative Model Updates: 8,730
Cumulative Timesteps: 145,747,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 145747066...
Checkpoint 145747066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,802.72988
Policy Entropy: 0.67270
Value Function Loss: 0.79008

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02948
Policy Update Magnitude: 0.02680
Value Function Update Magnitude: 0.02420

Collected Steps per Second: 24,025.83051
Overall Steps per Second: 16,806.51086

Timestep Collection Time: 2.08126
Timestep Consumption Time: 0.89402
PPO Batch Consumption Time: 0.09713
Total Iteration Time: 2.97528

Cumulative Model Updates: 8,733
Cumulative Timesteps: 145,797,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,487.94347
Policy Entropy: 0.66514
Value Function Loss: 0.79119

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03765
Policy Update Magnitude: 0.02629
Value Function Update Magnitude: 0.02353

Collected Steps per Second: 24,352.68682
Overall Steps per Second: 16,724.20643

Timestep Collection Time: 2.05365
Timestep Consumption Time: 0.93674
PPO Batch Consumption Time: 0.11080
Total Iteration Time: 2.99040

Cumulative Model Updates: 8,736
Cumulative Timesteps: 145,847,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 145847082...
Checkpoint 145847082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,438.34628
Policy Entropy: 0.65315
Value Function Loss: 0.81046

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03566
Policy Update Magnitude: 0.02315
Value Function Update Magnitude: 0.02103

Collected Steps per Second: 24,420.51798
Overall Steps per Second: 16,770.36756

Timestep Collection Time: 2.04836
Timestep Consumption Time: 0.93440
PPO Batch Consumption Time: 0.10729
Total Iteration Time: 2.98276

Cumulative Model Updates: 8,739
Cumulative Timesteps: 145,897,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,887.19845
Policy Entropy: 0.65078
Value Function Loss: 0.77902

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.02379
Value Function Update Magnitude: 0.02448

Collected Steps per Second: 24,137.01253
Overall Steps per Second: 16,699.55999

Timestep Collection Time: 2.07234
Timestep Consumption Time: 0.92295
PPO Batch Consumption Time: 0.10593
Total Iteration Time: 2.99529

Cumulative Model Updates: 8,742
Cumulative Timesteps: 145,947,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 145947124...
Checkpoint 145947124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,316.22011
Policy Entropy: 0.65442
Value Function Loss: 0.73481

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04165
Policy Update Magnitude: 0.02447
Value Function Update Magnitude: 0.02187

Collected Steps per Second: 24,127.41893
Overall Steps per Second: 16,752.45510

Timestep Collection Time: 2.07324
Timestep Consumption Time: 0.91271
PPO Batch Consumption Time: 0.09712
Total Iteration Time: 2.98595

Cumulative Model Updates: 8,745
Cumulative Timesteps: 145,997,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,288.31599
Policy Entropy: 0.67369
Value Function Loss: 0.67764

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03955
Policy Update Magnitude: 0.02134
Value Function Update Magnitude: 0.02562

Collected Steps per Second: 24,621.43582
Overall Steps per Second: 16,767.00168

Timestep Collection Time: 2.03108
Timestep Consumption Time: 0.95145
PPO Batch Consumption Time: 0.11312
Total Iteration Time: 2.98252

Cumulative Model Updates: 8,748
Cumulative Timesteps: 146,047,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 146047154...
Checkpoint 146047154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,129.16421
Policy Entropy: 0.67755
Value Function Loss: 0.71958

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03929
Policy Update Magnitude: 0.02194
Value Function Update Magnitude: 0.02308

Collected Steps per Second: 23,985.59177
Overall Steps per Second: 16,692.29763

Timestep Collection Time: 2.08559
Timestep Consumption Time: 0.91125
PPO Batch Consumption Time: 0.10007
Total Iteration Time: 2.99683

Cumulative Model Updates: 8,751
Cumulative Timesteps: 146,097,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.75552
Policy Entropy: 0.66402
Value Function Loss: 0.76209

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03761
Policy Update Magnitude: 0.02171
Value Function Update Magnitude: 0.02050

Collected Steps per Second: 24,432.34500
Overall Steps per Second: 16,791.76814

Timestep Collection Time: 2.04647
Timestep Consumption Time: 0.93118
PPO Batch Consumption Time: 0.10624
Total Iteration Time: 2.97765

Cumulative Model Updates: 8,754
Cumulative Timesteps: 146,147,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 146147178...
Checkpoint 146147178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,558.86464
Policy Entropy: 0.64958
Value Function Loss: 0.80326

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03228
Policy Update Magnitude: 0.02267
Value Function Update Magnitude: 0.03125

Collected Steps per Second: 24,271.47358
Overall Steps per Second: 16,709.53815

Timestep Collection Time: 2.06036
Timestep Consumption Time: 0.93242
PPO Batch Consumption Time: 0.10517
Total Iteration Time: 2.99278

Cumulative Model Updates: 8,757
Cumulative Timesteps: 146,197,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,530.78843
Policy Entropy: 0.66193
Value Function Loss: 0.79361

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03579
Policy Update Magnitude: 0.02416
Value Function Update Magnitude: 0.02843

Collected Steps per Second: 24,294.04477
Overall Steps per Second: 16,701.73403

Timestep Collection Time: 2.05927
Timestep Consumption Time: 0.93611
PPO Batch Consumption Time: 0.10555
Total Iteration Time: 2.99538

Cumulative Model Updates: 8,760
Cumulative Timesteps: 146,247,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 146247214...
Checkpoint 146247214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,987.50154
Policy Entropy: 0.66925
Value Function Loss: 0.76117

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.05170
Policy Update Magnitude: 0.02471
Value Function Update Magnitude: 0.02271

Collected Steps per Second: 23,263.30096
Overall Steps per Second: 16,687.55586

Timestep Collection Time: 2.15008
Timestep Consumption Time: 0.84724
PPO Batch Consumption Time: 0.07609
Total Iteration Time: 2.99732

Cumulative Model Updates: 8,763
Cumulative Timesteps: 146,297,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,130.24743
Policy Entropy: 0.67939
Value Function Loss: 0.78923

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04999
Policy Update Magnitude: 0.02010
Value Function Update Magnitude: 0.02551

Collected Steps per Second: 24,119.56357
Overall Steps per Second: 16,771.81026

Timestep Collection Time: 2.07301
Timestep Consumption Time: 0.90819
PPO Batch Consumption Time: 0.09289
Total Iteration Time: 2.98119

Cumulative Model Updates: 8,766
Cumulative Timesteps: 146,347,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 146347232...
Checkpoint 146347232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.75806
Policy Entropy: 0.67235
Value Function Loss: 0.75760

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02834
Policy Update Magnitude: 0.02241
Value Function Update Magnitude: 0.02231

Collected Steps per Second: 24,113.42607
Overall Steps per Second: 16,712.37773

Timestep Collection Time: 2.07387
Timestep Consumption Time: 0.91841
PPO Batch Consumption Time: 0.09788
Total Iteration Time: 2.99227

Cumulative Model Updates: 8,769
Cumulative Timesteps: 146,397,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,682.20948
Policy Entropy: 0.67504
Value Function Loss: 0.76188

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.02390
Value Function Update Magnitude: 0.02040

Collected Steps per Second: 24,244.42952
Overall Steps per Second: 16,854.82362

Timestep Collection Time: 2.06365
Timestep Consumption Time: 0.90476
PPO Batch Consumption Time: 0.11112
Total Iteration Time: 2.96841

Cumulative Model Updates: 8,772
Cumulative Timesteps: 146,447,272

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 146447272...
Checkpoint 146447272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,100.84097
Policy Entropy: 0.67232
Value Function Loss: 0.73491

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02399
Policy Update Magnitude: 0.02364
Value Function Update Magnitude: 0.02201

Collected Steps per Second: 23,992.29116
Overall Steps per Second: 16,706.12104

Timestep Collection Time: 2.08509
Timestep Consumption Time: 0.90938
PPO Batch Consumption Time: 0.10446
Total Iteration Time: 2.99447

Cumulative Model Updates: 8,775
Cumulative Timesteps: 146,497,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.42715
Policy Entropy: 0.67104
Value Function Loss: 0.75503

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03597
Policy Update Magnitude: 0.02226
Value Function Update Magnitude: 0.02223

Collected Steps per Second: 24,373.65334
Overall Steps per Second: 16,784.38362

Timestep Collection Time: 2.05230
Timestep Consumption Time: 0.92797
PPO Batch Consumption Time: 0.11441
Total Iteration Time: 2.98027

Cumulative Model Updates: 8,778
Cumulative Timesteps: 146,547,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 146547320...
Checkpoint 146547320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,714.73456
Policy Entropy: 0.67384
Value Function Loss: 0.72782

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02955
Policy Update Magnitude: 0.01938
Value Function Update Magnitude: 0.02192

Collected Steps per Second: 24,126.40321
Overall Steps per Second: 16,681.72888

Timestep Collection Time: 2.07292
Timestep Consumption Time: 0.92509
PPO Batch Consumption Time: 0.11106
Total Iteration Time: 2.99801

Cumulative Model Updates: 8,781
Cumulative Timesteps: 146,597,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,905.47945
Policy Entropy: 0.67569
Value Function Loss: 0.71944

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.02173
Value Function Update Magnitude: 0.02629

Collected Steps per Second: 23,978.81916
Overall Steps per Second: 16,681.19366

Timestep Collection Time: 2.08551
Timestep Consumption Time: 0.91236
PPO Batch Consumption Time: 0.09608
Total Iteration Time: 2.99787

Cumulative Model Updates: 8,784
Cumulative Timesteps: 146,647,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 146647340...
Checkpoint 146647340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.58340
Policy Entropy: 0.67409
Value Function Loss: 0.72847

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02016
Policy Update Magnitude: 0.02264
Value Function Update Magnitude: 0.02530

Collected Steps per Second: 23,881.85070
Overall Steps per Second: 16,784.66920

Timestep Collection Time: 2.09531
Timestep Consumption Time: 0.88598
PPO Batch Consumption Time: 0.10115
Total Iteration Time: 2.98129

Cumulative Model Updates: 8,787
Cumulative Timesteps: 146,697,380

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,210.89776
Policy Entropy: 0.66677
Value Function Loss: 0.72831

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02443
Policy Update Magnitude: 0.02331
Value Function Update Magnitude: 0.02112

Collected Steps per Second: 24,397.28971
Overall Steps per Second: 16,771.64850

Timestep Collection Time: 2.04965
Timestep Consumption Time: 0.93193
PPO Batch Consumption Time: 0.11481
Total Iteration Time: 2.98158

Cumulative Model Updates: 8,790
Cumulative Timesteps: 146,747,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 146747386...
Checkpoint 146747386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,846.09842
Policy Entropy: 0.66723
Value Function Loss: 0.74252

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03069
Policy Update Magnitude: 0.02484
Value Function Update Magnitude: 0.02518

Collected Steps per Second: 24,159.80757
Overall Steps per Second: 16,705.85756

Timestep Collection Time: 2.07005
Timestep Consumption Time: 0.92363
PPO Batch Consumption Time: 0.11339
Total Iteration Time: 2.99368

Cumulative Model Updates: 8,793
Cumulative Timesteps: 146,797,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,996.70858
Policy Entropy: 0.66889
Value Function Loss: 0.72928

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03818
Policy Update Magnitude: 0.02253
Value Function Update Magnitude: 0.02350

Collected Steps per Second: 24,132.54050
Overall Steps per Second: 16,752.12380

Timestep Collection Time: 2.07247
Timestep Consumption Time: 0.91306
PPO Batch Consumption Time: 0.10687
Total Iteration Time: 2.98553

Cumulative Model Updates: 8,796
Cumulative Timesteps: 146,847,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 146847412...
Checkpoint 146847412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,558.21372
Policy Entropy: 0.67133
Value Function Loss: 0.71456

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.02231
Value Function Update Magnitude: 0.02284

Collected Steps per Second: 24,039.39497
Overall Steps per Second: 16,801.56984

Timestep Collection Time: 2.08083
Timestep Consumption Time: 0.89639
PPO Batch Consumption Time: 0.12040
Total Iteration Time: 2.97722

Cumulative Model Updates: 8,799
Cumulative Timesteps: 146,897,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,439.02134
Policy Entropy: 0.67647
Value Function Loss: 0.67869

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.02314
Value Function Update Magnitude: 0.02426

Collected Steps per Second: 23,652.21596
Overall Steps per Second: 16,642.88660

Timestep Collection Time: 2.11464
Timestep Consumption Time: 0.89060
PPO Batch Consumption Time: 0.11062
Total Iteration Time: 3.00525

Cumulative Model Updates: 8,802
Cumulative Timesteps: 146,947,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 146947450...
Checkpoint 146947450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,376.68869
Policy Entropy: 0.68115
Value Function Loss: 0.63731

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03889
Policy Update Magnitude: 0.02192
Value Function Update Magnitude: 0.02099

Collected Steps per Second: 23,549.14020
Overall Steps per Second: 16,741.18888

Timestep Collection Time: 2.12449
Timestep Consumption Time: 0.86394
PPO Batch Consumption Time: 0.10158
Total Iteration Time: 2.98844

Cumulative Model Updates: 8,805
Cumulative Timesteps: 146,997,480

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.06140
Policy Entropy: 0.67345
Value Function Loss: 0.65016

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03635
Policy Update Magnitude: 0.02354
Value Function Update Magnitude: 0.02586

Collected Steps per Second: 23,568.33529
Overall Steps per Second: 16,786.83654

Timestep Collection Time: 2.12259
Timestep Consumption Time: 0.85748
PPO Batch Consumption Time: 0.10823
Total Iteration Time: 2.98007

Cumulative Model Updates: 8,808
Cumulative Timesteps: 147,047,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 147047506...
Checkpoint 147047506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,301.70104
Policy Entropy: 0.66156
Value Function Loss: 0.68634

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04477
Policy Update Magnitude: 0.02080
Value Function Update Magnitude: 0.02211

Collected Steps per Second: 23,368.38311
Overall Steps per Second: 16,727.60501

Timestep Collection Time: 2.14093
Timestep Consumption Time: 0.84994
PPO Batch Consumption Time: 0.10009
Total Iteration Time: 2.99086

Cumulative Model Updates: 8,811
Cumulative Timesteps: 147,097,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,152.42111
Policy Entropy: 0.65316
Value Function Loss: 0.70343

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04016
Policy Update Magnitude: 0.02119
Value Function Update Magnitude: 0.02113

Collected Steps per Second: 23,392.46481
Overall Steps per Second: 16,700.08475

Timestep Collection Time: 2.13847
Timestep Consumption Time: 0.85697
PPO Batch Consumption Time: 0.10719
Total Iteration Time: 2.99543

Cumulative Model Updates: 8,814
Cumulative Timesteps: 147,147,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 147147560...
Checkpoint 147147560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,727.15903
Policy Entropy: 0.65474
Value Function Loss: 0.69192

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.02215
Value Function Update Magnitude: 0.02258

Collected Steps per Second: 23,429.83509
Overall Steps per Second: 16,763.01719

Timestep Collection Time: 2.13412
Timestep Consumption Time: 0.84876
PPO Batch Consumption Time: 0.10047
Total Iteration Time: 2.98288

Cumulative Model Updates: 8,817
Cumulative Timesteps: 147,197,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,183.98043
Policy Entropy: 0.65221
Value Function Loss: 0.69578

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03394
Policy Update Magnitude: 0.02446
Value Function Update Magnitude: 0.02237

Collected Steps per Second: 24,453.75755
Overall Steps per Second: 16,718.32865

Timestep Collection Time: 2.04558
Timestep Consumption Time: 0.94647
PPO Batch Consumption Time: 0.11170
Total Iteration Time: 2.99205

Cumulative Model Updates: 8,820
Cumulative Timesteps: 147,247,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 147247584...
Checkpoint 147247584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,621.08863
Policy Entropy: 0.65336
Value Function Loss: 0.70053

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.04103
Policy Update Magnitude: 0.02245
Value Function Update Magnitude: 0.02074

Collected Steps per Second: 23,775.26050
Overall Steps per Second: 16,710.50614

Timestep Collection Time: 2.10471
Timestep Consumption Time: 0.88981
PPO Batch Consumption Time: 0.09066
Total Iteration Time: 2.99452

Cumulative Model Updates: 8,823
Cumulative Timesteps: 147,297,624

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,424.40527
Policy Entropy: 0.64803
Value Function Loss: 0.75361

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 0.02259
Value Function Update Magnitude: 0.01939

Collected Steps per Second: 24,246.62044
Overall Steps per Second: 16,755.79733

Timestep Collection Time: 2.06305
Timestep Consumption Time: 0.92230
PPO Batch Consumption Time: 0.09996
Total Iteration Time: 2.98535

Cumulative Model Updates: 8,826
Cumulative Timesteps: 147,347,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 147347646...
Checkpoint 147347646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,023.20011
Policy Entropy: 0.65405
Value Function Loss: 0.78913

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.02380
Value Function Update Magnitude: 0.02348

Collected Steps per Second: 24,104.90662
Overall Steps per Second: 16,744.17789

Timestep Collection Time: 2.07452
Timestep Consumption Time: 0.91196
PPO Batch Consumption Time: 0.10120
Total Iteration Time: 2.98647

Cumulative Model Updates: 8,829
Cumulative Timesteps: 147,397,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,027.99490
Policy Entropy: 0.64494
Value Function Loss: 0.80615

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 0.02373
Value Function Update Magnitude: 0.02269

Collected Steps per Second: 24,070.39144
Overall Steps per Second: 16,661.90828

Timestep Collection Time: 2.07832
Timestep Consumption Time: 0.92410
PPO Batch Consumption Time: 0.09774
Total Iteration Time: 3.00242

Cumulative Model Updates: 8,832
Cumulative Timesteps: 147,447,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 147447678...
Checkpoint 147447678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,359.95405
Policy Entropy: 0.64709
Value Function Loss: 0.75955

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03507
Policy Update Magnitude: 0.02429
Value Function Update Magnitude: 0.02667

Collected Steps per Second: 24,355.13924
Overall Steps per Second: 16,822.57757

Timestep Collection Time: 2.05386
Timestep Consumption Time: 0.91965
PPO Batch Consumption Time: 0.10500
Total Iteration Time: 2.97350

Cumulative Model Updates: 8,835
Cumulative Timesteps: 147,497,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,552.55268
Policy Entropy: 0.65084
Value Function Loss: 0.71678

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.02351
Value Function Update Magnitude: 0.02314

Collected Steps per Second: 24,156.04381
Overall Steps per Second: 16,687.58536

Timestep Collection Time: 2.07095
Timestep Consumption Time: 0.92685
PPO Batch Consumption Time: 0.09831
Total Iteration Time: 2.99780

Cumulative Model Updates: 8,838
Cumulative Timesteps: 147,547,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 147547726...
Checkpoint 147547726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,711.18232
Policy Entropy: 0.65955
Value Function Loss: 0.69869

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02041
Policy Update Magnitude: 0.02511
Value Function Update Magnitude: 0.02057

Collected Steps per Second: 24,015.18048
Overall Steps per Second: 16,771.87318

Timestep Collection Time: 2.08252
Timestep Consumption Time: 0.89938
PPO Batch Consumption Time: 0.09460
Total Iteration Time: 2.98190

Cumulative Model Updates: 8,841
Cumulative Timesteps: 147,597,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,775.61692
Policy Entropy: 0.66766
Value Function Loss: 0.70698

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03547
Policy Update Magnitude: 0.02379
Value Function Update Magnitude: 0.02452

Collected Steps per Second: 24,073.88833
Overall Steps per Second: 16,716.54425

Timestep Collection Time: 2.07769
Timestep Consumption Time: 0.91444
PPO Batch Consumption Time: 0.09806
Total Iteration Time: 2.99213

Cumulative Model Updates: 8,844
Cumulative Timesteps: 147,647,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 147647756...
Checkpoint 147647756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,398.95875
Policy Entropy: 0.67361
Value Function Loss: 0.68808

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03206
Policy Update Magnitude: 0.02137
Value Function Update Magnitude: 0.02130

Collected Steps per Second: 24,192.36769
Overall Steps per Second: 16,781.50800

Timestep Collection Time: 2.06685
Timestep Consumption Time: 0.91274
PPO Batch Consumption Time: 0.09973
Total Iteration Time: 2.97959

Cumulative Model Updates: 8,847
Cumulative Timesteps: 147,697,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,611.25602
Policy Entropy: 0.67839
Value Function Loss: 0.69971

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 0.02086
Value Function Update Magnitude: 0.02341

Collected Steps per Second: 24,291.13384
Overall Steps per Second: 16,716.59789

Timestep Collection Time: 2.05911
Timestep Consumption Time: 0.93301
PPO Batch Consumption Time: 0.10614
Total Iteration Time: 2.99212

Cumulative Model Updates: 8,850
Cumulative Timesteps: 147,747,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 147747776...
Checkpoint 147747776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,916.90950
Policy Entropy: 0.67532
Value Function Loss: 0.73850

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.01966
Value Function Update Magnitude: 0.02658

Collected Steps per Second: 24,140.01615
Overall Steps per Second: 16,747.54573

Timestep Collection Time: 2.07216
Timestep Consumption Time: 0.91466
PPO Batch Consumption Time: 0.09738
Total Iteration Time: 2.98683

Cumulative Model Updates: 8,853
Cumulative Timesteps: 147,797,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,530.13563
Policy Entropy: 0.67048
Value Function Loss: 0.73173

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.01647
Policy Update Magnitude: 0.02289
Value Function Update Magnitude: 0.02344

Collected Steps per Second: 24,582.38264
Overall Steps per Second: 16,717.57245

Timestep Collection Time: 2.03430
Timestep Consumption Time: 0.95704
PPO Batch Consumption Time: 0.11283
Total Iteration Time: 2.99134

Cumulative Model Updates: 8,856
Cumulative Timesteps: 147,847,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 147847806...
Checkpoint 147847806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,986.23960
Policy Entropy: 0.66280
Value Function Loss: 0.73661

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02850
Policy Update Magnitude: 0.02268
Value Function Update Magnitude: 0.02451

Collected Steps per Second: 23,820.67561
Overall Steps per Second: 16,743.25821

Timestep Collection Time: 2.10002
Timestep Consumption Time: 0.88769
PPO Batch Consumption Time: 0.09347
Total Iteration Time: 2.98771

Cumulative Model Updates: 8,859
Cumulative Timesteps: 147,897,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,919.28159
Policy Entropy: 0.65887
Value Function Loss: 0.72307

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02274
Policy Update Magnitude: 0.02374
Value Function Update Magnitude: 0.02186

Collected Steps per Second: 24,186.40933
Overall Steps per Second: 16,735.77952

Timestep Collection Time: 2.06802
Timestep Consumption Time: 0.92067
PPO Batch Consumption Time: 0.10378
Total Iteration Time: 2.98869

Cumulative Model Updates: 8,862
Cumulative Timesteps: 147,947,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 147947848...
Checkpoint 147947848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.91237
Policy Entropy: 0.65628
Value Function Loss: 0.76468

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.02539
Value Function Update Magnitude: 0.02409

Collected Steps per Second: 23,988.86590
Overall Steps per Second: 16,766.51268

Timestep Collection Time: 2.08455
Timestep Consumption Time: 0.89794
PPO Batch Consumption Time: 0.10301
Total Iteration Time: 2.98249

Cumulative Model Updates: 8,865
Cumulative Timesteps: 147,997,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,401.10430
Policy Entropy: 0.65458
Value Function Loss: 0.79878

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.02463
Value Function Update Magnitude: 0.02267

Collected Steps per Second: 24,112.31466
Overall Steps per Second: 16,704.74766

Timestep Collection Time: 2.07380
Timestep Consumption Time: 0.91961
PPO Batch Consumption Time: 0.10847
Total Iteration Time: 2.99340

Cumulative Model Updates: 8,868
Cumulative Timesteps: 148,047,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 148047858...
Checkpoint 148047858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,840.12142
Policy Entropy: 0.66409
Value Function Loss: 0.77777

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.02347
Value Function Update Magnitude: 0.02606

Collected Steps per Second: 24,122.77603
Overall Steps per Second: 16,750.68916

Timestep Collection Time: 2.07331
Timestep Consumption Time: 0.91248
PPO Batch Consumption Time: 0.10576
Total Iteration Time: 2.98579

Cumulative Model Updates: 8,871
Cumulative Timesteps: 148,097,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,461.16763
Policy Entropy: 0.65390
Value Function Loss: 0.77980

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01939
Policy Update Magnitude: 0.02372
Value Function Update Magnitude: 0.02381

Collected Steps per Second: 24,421.60337
Overall Steps per Second: 16,807.65699

Timestep Collection Time: 2.04770
Timestep Consumption Time: 0.92762
PPO Batch Consumption Time: 0.11473
Total Iteration Time: 2.97531

Cumulative Model Updates: 8,874
Cumulative Timesteps: 148,147,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 148147880...
Checkpoint 148147880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,454.78142
Policy Entropy: 0.66078
Value Function Loss: 0.73871

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.01264
Policy Update Magnitude: 0.02565
Value Function Update Magnitude: 0.02524

Collected Steps per Second: 23,945.92714
Overall Steps per Second: 16,712.68694

Timestep Collection Time: 2.08820
Timestep Consumption Time: 0.90377
PPO Batch Consumption Time: 0.10475
Total Iteration Time: 2.99198

Cumulative Model Updates: 8,877
Cumulative Timesteps: 148,197,884

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.29457
Policy Entropy: 0.65430
Value Function Loss: 0.77370

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.02561
Value Function Update Magnitude: 0.02753

Collected Steps per Second: 24,337.03577
Overall Steps per Second: 16,732.08707

Timestep Collection Time: 2.05456
Timestep Consumption Time: 0.93383
PPO Batch Consumption Time: 0.11705
Total Iteration Time: 2.98839

Cumulative Model Updates: 8,880
Cumulative Timesteps: 148,247,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 148247886...
Checkpoint 148247886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,449.93561
Policy Entropy: 0.67161
Value Function Loss: 0.72902

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03449
Policy Update Magnitude: 0.02514
Value Function Update Magnitude: 0.02359

Collected Steps per Second: 24,115.39446
Overall Steps per Second: 16,713.79087

Timestep Collection Time: 2.07436
Timestep Consumption Time: 0.91862
PPO Batch Consumption Time: 0.10509
Total Iteration Time: 2.99298

Cumulative Model Updates: 8,883
Cumulative Timesteps: 148,297,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,557.43739
Policy Entropy: 0.67073
Value Function Loss: 0.74561

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03692
Policy Update Magnitude: 0.02201
Value Function Update Magnitude: 0.02363

Collected Steps per Second: 24,413.69422
Overall Steps per Second: 16,764.97807

Timestep Collection Time: 2.04844
Timestep Consumption Time: 0.93456
PPO Batch Consumption Time: 0.11680
Total Iteration Time: 2.98300

Cumulative Model Updates: 8,886
Cumulative Timesteps: 148,347,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 148347920...
Checkpoint 148347920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,032.38508
Policy Entropy: 0.66733
Value Function Loss: 0.72851

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02308
Policy Update Magnitude: 0.02268
Value Function Update Magnitude: 0.02294

Collected Steps per Second: 24,385.02634
Overall Steps per Second: 17,582.65435

Timestep Collection Time: 2.05077
Timestep Consumption Time: 0.79340
PPO Batch Consumption Time: 0.08185
Total Iteration Time: 2.84417

Cumulative Model Updates: 8,889
Cumulative Timesteps: 148,397,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,579.59347
Policy Entropy: 0.66579
Value Function Loss: 0.74167

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.01031
Policy Update Magnitude: 0.02555
Value Function Update Magnitude: 0.02219

Collected Steps per Second: 22,949.81584
Overall Steps per Second: 16,918.90994

Timestep Collection Time: 2.17919
Timestep Consumption Time: 0.77679
PPO Batch Consumption Time: 0.08026
Total Iteration Time: 2.95598

Cumulative Model Updates: 8,892
Cumulative Timesteps: 148,447,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 148447940...
Checkpoint 148447940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.39603
Policy Entropy: 0.66305
Value Function Loss: 0.77838

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03340
Policy Update Magnitude: 0.02455
Value Function Update Magnitude: 0.02409

Collected Steps per Second: 23,106.97579
Overall Steps per Second: 17,241.15654

Timestep Collection Time: 2.16558
Timestep Consumption Time: 0.73678
PPO Batch Consumption Time: 0.06740
Total Iteration Time: 2.90236

Cumulative Model Updates: 8,895
Cumulative Timesteps: 148,497,980

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,894.72093
Policy Entropy: 0.67074
Value Function Loss: 0.77286

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03992
Policy Update Magnitude: 0.02196
Value Function Update Magnitude: 0.02499

Collected Steps per Second: 24,065.69545
Overall Steps per Second: 16,417.28544

Timestep Collection Time: 2.07806
Timestep Consumption Time: 0.96812
PPO Batch Consumption Time: 0.12398
Total Iteration Time: 3.04618

Cumulative Model Updates: 8,898
Cumulative Timesteps: 148,547,990

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 148547990...
Checkpoint 148547990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,295.42056
Policy Entropy: 0.66464
Value Function Loss: 0.79660

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04519
Policy Update Magnitude: 0.02270
Value Function Update Magnitude: 0.02524

Collected Steps per Second: 24,330.33932
Overall Steps per Second: 17,561.10254

Timestep Collection Time: 2.05603
Timestep Consumption Time: 0.79253
PPO Batch Consumption Time: 0.06176
Total Iteration Time: 2.84857

Cumulative Model Updates: 8,901
Cumulative Timesteps: 148,598,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,284.71197
Policy Entropy: 0.67378
Value Function Loss: 0.72583

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03679
Policy Update Magnitude: 0.01934
Value Function Update Magnitude: 0.02704

Collected Steps per Second: 21,429.33731
Overall Steps per Second: 15,794.22696

Timestep Collection Time: 2.33437
Timestep Consumption Time: 0.83286
PPO Batch Consumption Time: 0.07468
Total Iteration Time: 3.16723

Cumulative Model Updates: 8,904
Cumulative Timesteps: 148,648,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 148648038...
Checkpoint 148648038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,563.27419
Policy Entropy: 0.67169
Value Function Loss: 0.72405

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.02291
Value Function Update Magnitude: 0.02523

Collected Steps per Second: 24,194.69970
Overall Steps per Second: 17,571.02348

Timestep Collection Time: 2.06706
Timestep Consumption Time: 0.77921
PPO Batch Consumption Time: 0.06074
Total Iteration Time: 2.84628

Cumulative Model Updates: 8,907
Cumulative Timesteps: 148,698,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,035.48730
Policy Entropy: 0.66516
Value Function Loss: 0.76574

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02263
Policy Update Magnitude: 0.02557
Value Function Update Magnitude: 0.02288

Collected Steps per Second: 21,570.46210
Overall Steps per Second: 15,184.13764

Timestep Collection Time: 2.31919
Timestep Consumption Time: 0.97543
PPO Batch Consumption Time: 0.11960
Total Iteration Time: 3.29462

Cumulative Model Updates: 8,910
Cumulative Timesteps: 148,748,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 148748076...
Checkpoint 148748076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,567.67437
Policy Entropy: 0.65669
Value Function Loss: 0.78365

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.02486
Value Function Update Magnitude: 0.02129

Collected Steps per Second: 24,218.75204
Overall Steps per Second: 16,693.80823

Timestep Collection Time: 2.06518
Timestep Consumption Time: 0.93090
PPO Batch Consumption Time: 0.10209
Total Iteration Time: 2.99608

Cumulative Model Updates: 8,913
Cumulative Timesteps: 148,798,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,487.61475
Policy Entropy: 0.66169
Value Function Loss: 0.77532

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03117
Policy Update Magnitude: 0.02299
Value Function Update Magnitude: 0.02281

Collected Steps per Second: 24,038.86583
Overall Steps per Second: 16,726.22007

Timestep Collection Time: 2.08105
Timestep Consumption Time: 0.90983
PPO Batch Consumption Time: 0.10416
Total Iteration Time: 2.99087

Cumulative Model Updates: 8,916
Cumulative Timesteps: 148,848,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 148848118...
Checkpoint 148848118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,291.26973
Policy Entropy: 0.67287
Value Function Loss: 0.71344

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01546
Policy Update Magnitude: 0.02338
Value Function Update Magnitude: 0.02191

Collected Steps per Second: 24,091.13193
Overall Steps per Second: 16,725.68492

Timestep Collection Time: 2.07545
Timestep Consumption Time: 0.91396
PPO Batch Consumption Time: 0.10188
Total Iteration Time: 2.98941

Cumulative Model Updates: 8,919
Cumulative Timesteps: 148,898,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,578.80098
Policy Entropy: 0.67952
Value Function Loss: 0.69281

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04349
Policy Update Magnitude: 0.02582
Value Function Update Magnitude: 0.02100

Collected Steps per Second: 24,045.90239
Overall Steps per Second: 16,699.33531

Timestep Collection Time: 2.08019
Timestep Consumption Time: 0.91514
PPO Batch Consumption Time: 0.10013
Total Iteration Time: 2.99533

Cumulative Model Updates: 8,922
Cumulative Timesteps: 148,948,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 148948138...
Checkpoint 148948138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,070.53483
Policy Entropy: 0.68096
Value Function Loss: 0.67779

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.02117
Value Function Update Magnitude: 0.02395

Collected Steps per Second: 23,900.76276
Overall Steps per Second: 16,743.31564

Timestep Collection Time: 2.09257
Timestep Consumption Time: 0.89453
PPO Batch Consumption Time: 0.08756
Total Iteration Time: 2.98710

Cumulative Model Updates: 8,925
Cumulative Timesteps: 148,998,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,574.91237
Policy Entropy: 0.68292
Value Function Loss: 0.67597

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.07106
Policy Update Magnitude: 0.01946
Value Function Update Magnitude: 0.02073

Collected Steps per Second: 23,664.23825
Overall Steps per Second: 16,675.12625

Timestep Collection Time: 2.11365
Timestep Consumption Time: 0.88590
PPO Batch Consumption Time: 0.08541
Total Iteration Time: 2.99956

Cumulative Model Updates: 8,928
Cumulative Timesteps: 149,048,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 149048170...
Checkpoint 149048170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,345.77600
Policy Entropy: 0.69124
Value Function Loss: 0.66786

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03991
Policy Update Magnitude: 0.01890
Value Function Update Magnitude: 0.02271

Collected Steps per Second: 23,797.57063
Overall Steps per Second: 16,802.76684

Timestep Collection Time: 2.10105
Timestep Consumption Time: 0.87465
PPO Batch Consumption Time: 0.08874
Total Iteration Time: 2.97570

Cumulative Model Updates: 8,931
Cumulative Timesteps: 149,098,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936.02215
Policy Entropy: 0.68977
Value Function Loss: 0.68914

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.01895
Value Function Update Magnitude: 0.02146

Collected Steps per Second: 24,199.86979
Overall Steps per Second: 16,798.00437

Timestep Collection Time: 2.06646
Timestep Consumption Time: 0.91056
PPO Batch Consumption Time: 0.10539
Total Iteration Time: 2.97702

Cumulative Model Updates: 8,934
Cumulative Timesteps: 149,148,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 149148178...
Checkpoint 149148178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,614.12620
Policy Entropy: 0.69005
Value Function Loss: 0.66542

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03605
Policy Update Magnitude: 0.02051
Value Function Update Magnitude: 0.02331

Collected Steps per Second: 23,733.68197
Overall Steps per Second: 16,682.69395

Timestep Collection Time: 2.10705
Timestep Consumption Time: 0.89055
PPO Batch Consumption Time: 0.10150
Total Iteration Time: 2.99760

Cumulative Model Updates: 8,937
Cumulative Timesteps: 149,198,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,484.69650
Policy Entropy: 0.68535
Value Function Loss: 0.68152

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 0.01862
Value Function Update Magnitude: 0.02526

Collected Steps per Second: 24,367.90301
Overall Steps per Second: 16,798.04434

Timestep Collection Time: 2.05245
Timestep Consumption Time: 0.92492
PPO Batch Consumption Time: 0.11506
Total Iteration Time: 2.97737

Cumulative Model Updates: 8,940
Cumulative Timesteps: 149,248,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 149248200...
Checkpoint 149248200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,565.03826
Policy Entropy: 0.68440
Value Function Loss: 0.68478

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03370
Policy Update Magnitude: 0.02024
Value Function Update Magnitude: 0.02209

Collected Steps per Second: 24,352.48145
Overall Steps per Second: 16,757.26348

Timestep Collection Time: 2.05392
Timestep Consumption Time: 0.93094
PPO Batch Consumption Time: 0.11201
Total Iteration Time: 2.98485

Cumulative Model Updates: 8,943
Cumulative Timesteps: 149,298,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,817.70793
Policy Entropy: 0.68583
Value Function Loss: 0.72682

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.05224
Policy Update Magnitude: 0.02128
Value Function Update Magnitude: 0.01991

Collected Steps per Second: 24,118.98429
Overall Steps per Second: 16,705.32118

Timestep Collection Time: 2.07422
Timestep Consumption Time: 0.92052
PPO Batch Consumption Time: 0.11388
Total Iteration Time: 2.99473

Cumulative Model Updates: 8,946
Cumulative Timesteps: 149,348,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 149348246...
Checkpoint 149348246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,598.73941
Policy Entropy: 0.68976
Value Function Loss: 0.70711

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03759
Policy Update Magnitude: 0.01897
Value Function Update Magnitude: 0.02607

Collected Steps per Second: 24,319.84861
Overall Steps per Second: 16,784.53680

Timestep Collection Time: 2.05626
Timestep Consumption Time: 0.92315
PPO Batch Consumption Time: 0.10966
Total Iteration Time: 2.97941

Cumulative Model Updates: 8,949
Cumulative Timesteps: 149,398,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,602.73947
Policy Entropy: 0.69474
Value Function Loss: 0.67003

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02915
Policy Update Magnitude: 0.02265
Value Function Update Magnitude: 0.02390

Collected Steps per Second: 24,498.75546
Overall Steps per Second: 16,719.59030

Timestep Collection Time: 2.04092
Timestep Consumption Time: 0.94958
PPO Batch Consumption Time: 0.12362
Total Iteration Time: 2.99050

Cumulative Model Updates: 8,952
Cumulative Timesteps: 149,448,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 149448254...
Checkpoint 149448254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,193.04261
Policy Entropy: 0.69322
Value Function Loss: 0.66339

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.02222
Value Function Update Magnitude: 0.02205

Collected Steps per Second: 24,294.09728
Overall Steps per Second: 16,719.93589

Timestep Collection Time: 2.05910
Timestep Consumption Time: 0.93278
PPO Batch Consumption Time: 0.11044
Total Iteration Time: 2.99188

Cumulative Model Updates: 8,955
Cumulative Timesteps: 149,498,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,377.60673
Policy Entropy: 0.68876
Value Function Loss: 0.65538

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02260
Policy Update Magnitude: 0.02196
Value Function Update Magnitude: 0.02045

Collected Steps per Second: 24,346.77557
Overall Steps per Second: 16,723.97520

Timestep Collection Time: 2.05448
Timestep Consumption Time: 0.93643
PPO Batch Consumption Time: 0.11413
Total Iteration Time: 2.99092

Cumulative Model Updates: 8,958
Cumulative Timesteps: 149,548,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 149548298...
Checkpoint 149548298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.50798
Policy Entropy: 0.67638
Value Function Loss: 0.66469

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.02346
Value Function Update Magnitude: 0.02012

Collected Steps per Second: 24,002.38411
Overall Steps per Second: 16,705.68614

Timestep Collection Time: 2.08313
Timestep Consumption Time: 0.90987
PPO Batch Consumption Time: 0.10149
Total Iteration Time: 2.99299

Cumulative Model Updates: 8,961
Cumulative Timesteps: 149,598,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,484.88636
Policy Entropy: 0.67204
Value Function Loss: 0.64428

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 0.02235
Value Function Update Magnitude: 0.02285

Collected Steps per Second: 24,148.63295
Overall Steps per Second: 16,648.75443

Timestep Collection Time: 2.07059
Timestep Consumption Time: 0.93275
PPO Batch Consumption Time: 0.10527
Total Iteration Time: 3.00335

Cumulative Model Updates: 8,964
Cumulative Timesteps: 149,648,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 149648300...
Checkpoint 149648300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,560.24308
Policy Entropy: 0.67046
Value Function Loss: 0.65204

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02345
Policy Update Magnitude: 0.02258
Value Function Update Magnitude: 0.02030

Collected Steps per Second: 23,983.09887
Overall Steps per Second: 16,770.81875

Timestep Collection Time: 2.08564
Timestep Consumption Time: 0.89693
PPO Batch Consumption Time: 0.09586
Total Iteration Time: 2.98256

Cumulative Model Updates: 8,967
Cumulative Timesteps: 149,698,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.18619
Policy Entropy: 0.66834
Value Function Loss: 0.67153

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03541
Policy Update Magnitude: 0.02320
Value Function Update Magnitude: 0.02042

Collected Steps per Second: 24,137.57598
Overall Steps per Second: 16,822.60089

Timestep Collection Time: 2.07154
Timestep Consumption Time: 0.90077
PPO Batch Consumption Time: 0.11298
Total Iteration Time: 2.97231

Cumulative Model Updates: 8,970
Cumulative Timesteps: 149,748,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 149748322...
Checkpoint 149748322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.15612
Policy Entropy: 0.67244
Value Function Loss: 0.67307

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03606
Policy Update Magnitude: 0.02126
Value Function Update Magnitude: 0.02489

Collected Steps per Second: 23,403.70750
Overall Steps per Second: 16,688.64585

Timestep Collection Time: 2.13650
Timestep Consumption Time: 0.85967
PPO Batch Consumption Time: 0.10112
Total Iteration Time: 2.99617

Cumulative Model Updates: 8,973
Cumulative Timesteps: 149,798,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,156.95862
Policy Entropy: 0.66245
Value Function Loss: 0.70852

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04937
Policy Update Magnitude: 0.02076
Value Function Update Magnitude: 0.02470

Collected Steps per Second: 23,137.20758
Overall Steps per Second: 16,713.36515

Timestep Collection Time: 2.16215
Timestep Consumption Time: 0.83103
PPO Batch Consumption Time: 0.09851
Total Iteration Time: 2.99317

Cumulative Model Updates: 8,976
Cumulative Timesteps: 149,848,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 149848350...
Checkpoint 149848350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,114.96753
Policy Entropy: 0.67511
Value Function Loss: 0.67477

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04395
Policy Update Magnitude: 0.01879
Value Function Update Magnitude: 0.02145

Collected Steps per Second: 23,535.14281
Overall Steps per Second: 16,744.61667

Timestep Collection Time: 2.12465
Timestep Consumption Time: 0.86162
PPO Batch Consumption Time: 0.10421
Total Iteration Time: 2.98627

Cumulative Model Updates: 8,979
Cumulative Timesteps: 149,898,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,205.18739
Policy Entropy: 0.68463
Value Function Loss: 0.66401

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03811
Policy Update Magnitude: 0.01979
Value Function Update Magnitude: 0.02362

Collected Steps per Second: 23,556.18091
Overall Steps per Second: 16,762.04216

Timestep Collection Time: 2.12360
Timestep Consumption Time: 0.86076
PPO Batch Consumption Time: 0.11013
Total Iteration Time: 2.98436

Cumulative Model Updates: 8,982
Cumulative Timesteps: 149,948,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 149948378...
Checkpoint 149948378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,103.26945
Policy Entropy: 0.69965
Value Function Loss: 0.60453

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04210
Policy Update Magnitude: 0.01766
Value Function Update Magnitude: 0.01968

Collected Steps per Second: 23,185.01595
Overall Steps per Second: 16,695.33733

Timestep Collection Time: 2.15717
Timestep Consumption Time: 0.83852
PPO Batch Consumption Time: 0.09357
Total Iteration Time: 2.99569

Cumulative Model Updates: 8,985
Cumulative Timesteps: 149,998,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,777.41518
Policy Entropy: 0.68413
Value Function Loss: 0.64845

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03595
Policy Update Magnitude: 0.01790
Value Function Update Magnitude: 0.02293

Collected Steps per Second: 24,181.44508
Overall Steps per Second: 16,735.00758

Timestep Collection Time: 2.06795
Timestep Consumption Time: 0.92016
PPO Batch Consumption Time: 0.10697
Total Iteration Time: 2.98811

Cumulative Model Updates: 8,988
Cumulative Timesteps: 150,048,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 150048398...
Checkpoint 150048398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.15288
Policy Entropy: 0.67506
Value Function Loss: 0.63712

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.01967
Value Function Update Magnitude: 0.02415

Collected Steps per Second: 24,322.24253
Overall Steps per Second: 16,710.97064

Timestep Collection Time: 2.05631
Timestep Consumption Time: 0.93658
PPO Batch Consumption Time: 0.10712
Total Iteration Time: 2.99288

Cumulative Model Updates: 8,991
Cumulative Timesteps: 150,098,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,523.74635
Policy Entropy: 0.66997
Value Function Loss: 0.63427

Mean KL Divergence: 0.00138
SB3 Clip Fraction: 0.00887
Policy Update Magnitude: 0.02182
Value Function Update Magnitude: 0.02284

Collected Steps per Second: 24,035.23181
Overall Steps per Second: 16,742.54783

Timestep Collection Time: 2.08103
Timestep Consumption Time: 0.90645
PPO Batch Consumption Time: 0.09992
Total Iteration Time: 2.98748

Cumulative Model Updates: 8,994
Cumulative Timesteps: 150,148,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 150148430...
Checkpoint 150148430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,491.88483
Policy Entropy: 0.66972
Value Function Loss: 0.63520

Mean KL Divergence: 0.00130
SB3 Clip Fraction: 0.00953
Policy Update Magnitude: 0.02512
Value Function Update Magnitude: 0.02056

Collected Steps per Second: 24,167.29829
Overall Steps per Second: 16,775.76404

Timestep Collection Time: 2.06899
Timestep Consumption Time: 0.91162
PPO Batch Consumption Time: 0.09897
Total Iteration Time: 2.98061

Cumulative Model Updates: 8,997
Cumulative Timesteps: 150,198,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,528.61902
Policy Entropy: 0.66755
Value Function Loss: 0.66721

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.01965
Policy Update Magnitude: 0.02685
Value Function Update Magnitude: 0.02142

Collected Steps per Second: 24,554.31531
Overall Steps per Second: 16,724.25698

Timestep Collection Time: 2.03655
Timestep Consumption Time: 0.95348
PPO Batch Consumption Time: 0.11085
Total Iteration Time: 2.99003

Cumulative Model Updates: 9,000
Cumulative Timesteps: 150,248,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 150248438...
Checkpoint 150248438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,186.87839
Policy Entropy: 0.65834
Value Function Loss: 0.71039

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03095
Policy Update Magnitude: 0.02764
Value Function Update Magnitude: 0.02543

Collected Steps per Second: 24,475.79529
Overall Steps per Second: 16,763.07344

Timestep Collection Time: 2.04382
Timestep Consumption Time: 0.94036
PPO Batch Consumption Time: 0.10728
Total Iteration Time: 2.98418

Cumulative Model Updates: 9,003
Cumulative Timesteps: 150,298,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,449.44446
Policy Entropy: 0.66212
Value Function Loss: 0.68731

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03131
Policy Update Magnitude: 0.02618
Value Function Update Magnitude: 0.02291

Collected Steps per Second: 24,111.79179
Overall Steps per Second: 16,713.66585

Timestep Collection Time: 2.07442
Timestep Consumption Time: 0.91822
PPO Batch Consumption Time: 0.10610
Total Iteration Time: 2.99264

Cumulative Model Updates: 9,006
Cumulative Timesteps: 150,348,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 150348480...
Checkpoint 150348480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,937.48580
Policy Entropy: 0.65710
Value Function Loss: 0.69009

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03295
Policy Update Magnitude: 0.02611
Value Function Update Magnitude: 0.02166

Collected Steps per Second: 24,209.68846
Overall Steps per Second: 16,722.71336

Timestep Collection Time: 2.06554
Timestep Consumption Time: 0.92477
PPO Batch Consumption Time: 0.10010
Total Iteration Time: 2.99030

Cumulative Model Updates: 9,009
Cumulative Timesteps: 150,398,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.05226
Policy Entropy: 0.66007
Value Function Loss: 0.69060

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04433
Policy Update Magnitude: 0.02295
Value Function Update Magnitude: 0.02206

Collected Steps per Second: 24,236.65841
Overall Steps per Second: 16,738.34978

Timestep Collection Time: 2.06357
Timestep Consumption Time: 0.92442
PPO Batch Consumption Time: 0.10755
Total Iteration Time: 2.98799

Cumulative Model Updates: 9,012
Cumulative Timesteps: 150,448,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 150448500...
Checkpoint 150448500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,822.66075
Policy Entropy: 0.66055
Value Function Loss: 0.68283

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04934
Policy Update Magnitude: 0.02120
Value Function Update Magnitude: 0.02185

Collected Steps per Second: 24,040.53643
Overall Steps per Second: 16,744.50665

Timestep Collection Time: 2.08074
Timestep Consumption Time: 0.90663
PPO Batch Consumption Time: 0.09595
Total Iteration Time: 2.98737

Cumulative Model Updates: 9,015
Cumulative Timesteps: 150,498,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,458.89752
Policy Entropy: 0.65673
Value Function Loss: 0.69154

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03559
Policy Update Magnitude: 0.02060
Value Function Update Magnitude: 0.02121

Collected Steps per Second: 24,298.90373
Overall Steps per Second: 16,716.15876

Timestep Collection Time: 2.05771
Timestep Consumption Time: 0.93341
PPO Batch Consumption Time: 0.09850
Total Iteration Time: 2.99112

Cumulative Model Updates: 9,018
Cumulative Timesteps: 150,548,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 150548522...
Checkpoint 150548522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,377.31124
Policy Entropy: 0.66337
Value Function Loss: 0.67399

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03418
Policy Update Magnitude: 0.01925
Value Function Update Magnitude: 0.02125

Collected Steps per Second: 23,983.20408
Overall Steps per Second: 16,744.94962

Timestep Collection Time: 2.08513
Timestep Consumption Time: 0.90133
PPO Batch Consumption Time: 0.09097
Total Iteration Time: 2.98645

Cumulative Model Updates: 9,021
Cumulative Timesteps: 150,598,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,179.64937
Policy Entropy: 0.67101
Value Function Loss: 0.68182

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03644
Policy Update Magnitude: 0.02201
Value Function Update Magnitude: 0.02275

Collected Steps per Second: 23,602.64003
Overall Steps per Second: 16,702.82617

Timestep Collection Time: 2.11866
Timestep Consumption Time: 0.87520
PPO Batch Consumption Time: 0.09304
Total Iteration Time: 2.99386

Cumulative Model Updates: 9,024
Cumulative Timesteps: 150,648,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 150648536...
Checkpoint 150648536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,584.28303
Policy Entropy: 0.67333
Value Function Loss: 0.69550

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04759
Policy Update Magnitude: 0.02141
Value Function Update Magnitude: 0.02262

Collected Steps per Second: 23,809.12926
Overall Steps per Second: 16,783.55461

Timestep Collection Time: 2.10003
Timestep Consumption Time: 0.87907
PPO Batch Consumption Time: 0.09910
Total Iteration Time: 2.97911

Cumulative Model Updates: 9,027
Cumulative Timesteps: 150,698,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,135.37995
Policy Entropy: 0.66700
Value Function Loss: 0.68261

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03516
Policy Update Magnitude: 0.01942
Value Function Update Magnitude: 0.02070

Collected Steps per Second: 23,868.77966
Overall Steps per Second: 16,698.90094

Timestep Collection Time: 2.09487
Timestep Consumption Time: 0.89946
PPO Batch Consumption Time: 0.10230
Total Iteration Time: 2.99433

Cumulative Model Updates: 9,030
Cumulative Timesteps: 150,748,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 150748538...
Checkpoint 150748538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.39385
Policy Entropy: 0.67013
Value Function Loss: 0.66149

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04083
Policy Update Magnitude: 0.02373
Value Function Update Magnitude: 0.02655

Collected Steps per Second: 23,934.81688
Overall Steps per Second: 16,742.01859

Timestep Collection Time: 2.08901
Timestep Consumption Time: 0.89749
PPO Batch Consumption Time: 0.10245
Total Iteration Time: 2.98650

Cumulative Model Updates: 9,033
Cumulative Timesteps: 150,798,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,688.99151
Policy Entropy: 0.67286
Value Function Loss: 0.64625

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05857
Policy Update Magnitude: 0.02079
Value Function Update Magnitude: 0.02578

Collected Steps per Second: 23,985.28340
Overall Steps per Second: 16,723.26656

Timestep Collection Time: 2.08461
Timestep Consumption Time: 0.90523
PPO Batch Consumption Time: 0.10763
Total Iteration Time: 2.98985

Cumulative Model Updates: 9,036
Cumulative Timesteps: 150,848,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 150848538...
Checkpoint 150848538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,744.42023
Policy Entropy: 0.66261
Value Function Loss: 0.65730

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.05053
Policy Update Magnitude: 0.01971
Value Function Update Magnitude: 0.02163

Collected Steps per Second: 24,034.97772
Overall Steps per Second: 16,755.94427

Timestep Collection Time: 2.08105
Timestep Consumption Time: 0.90404
PPO Batch Consumption Time: 0.10337
Total Iteration Time: 2.98509

Cumulative Model Updates: 9,039
Cumulative Timesteps: 150,898,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,603.19066
Policy Entropy: 0.65645
Value Function Loss: 0.67754

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05806
Policy Update Magnitude: 0.01786
Value Function Update Magnitude: 0.02386

Collected Steps per Second: 24,296.84490
Overall Steps per Second: 16,781.28465

Timestep Collection Time: 2.05862
Timestep Consumption Time: 0.92196
PPO Batch Consumption Time: 0.10865
Total Iteration Time: 2.98058

Cumulative Model Updates: 9,042
Cumulative Timesteps: 150,948,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 150948574...
Checkpoint 150948574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,682.14251
Policy Entropy: 0.65915
Value Function Loss: 0.65209

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03855
Policy Update Magnitude: 0.01850
Value Function Update Magnitude: 0.02394

Collected Steps per Second: 24,098.70826
Overall Steps per Second: 16,692.10835

Timestep Collection Time: 2.07588
Timestep Consumption Time: 0.92111
PPO Batch Consumption Time: 0.10725
Total Iteration Time: 2.99699

Cumulative Model Updates: 9,045
Cumulative Timesteps: 150,998,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,847.04547
Policy Entropy: 0.66558
Value Function Loss: 0.64717

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04751
Policy Update Magnitude: 0.01797
Value Function Update Magnitude: 0.02125

Collected Steps per Second: 24,173.82734
Overall Steps per Second: 16,783.37407

Timestep Collection Time: 2.06943
Timestep Consumption Time: 0.91126
PPO Batch Consumption Time: 0.10616
Total Iteration Time: 2.98069

Cumulative Model Updates: 9,048
Cumulative Timesteps: 151,048,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 151048626...
Checkpoint 151048626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,605.82593
Policy Entropy: 0.66690
Value Function Loss: 0.65532

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03479
Policy Update Magnitude: 0.01866
Value Function Update Magnitude: 0.02211

Collected Steps per Second: 23,684.74609
Overall Steps per Second: 16,676.85660

Timestep Collection Time: 2.11191
Timestep Consumption Time: 0.88746
PPO Batch Consumption Time: 0.10013
Total Iteration Time: 2.99937

Cumulative Model Updates: 9,051
Cumulative Timesteps: 151,098,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.88330
Policy Entropy: 0.65656
Value Function Loss: 0.70711

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03721
Policy Update Magnitude: 0.01833
Value Function Update Magnitude: 0.01920

Collected Steps per Second: 23,916.59297
Overall Steps per Second: 16,681.64285

Timestep Collection Time: 2.09068
Timestep Consumption Time: 0.90674
PPO Batch Consumption Time: 0.10457
Total Iteration Time: 2.99743

Cumulative Model Updates: 9,054
Cumulative Timesteps: 151,148,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 151148648...
Checkpoint 151148648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,521.07417
Policy Entropy: 0.65512
Value Function Loss: 0.71553

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03629
Policy Update Magnitude: 0.01889
Value Function Update Magnitude: 0.02022

Collected Steps per Second: 24,029.22221
Overall Steps per Second: 16,787.38158

Timestep Collection Time: 2.08088
Timestep Consumption Time: 0.89766
PPO Batch Consumption Time: 0.10380
Total Iteration Time: 2.97855

Cumulative Model Updates: 9,057
Cumulative Timesteps: 151,198,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,656.18428
Policy Entropy: 0.66188
Value Function Loss: 0.71025

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04208
Policy Update Magnitude: 0.01778
Value Function Update Magnitude: 0.02099

Collected Steps per Second: 24,144.26430
Overall Steps per Second: 16,744.15054

Timestep Collection Time: 2.07155
Timestep Consumption Time: 0.91553
PPO Batch Consumption Time: 0.11007
Total Iteration Time: 2.98707

Cumulative Model Updates: 9,060
Cumulative Timesteps: 151,248,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 151248666...
Checkpoint 151248666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,477.11691
Policy Entropy: 0.66101
Value Function Loss: 0.64702

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.04053
Policy Update Magnitude: 0.01877
Value Function Update Magnitude: 0.02058

Collected Steps per Second: 24,073.80104
Overall Steps per Second: 16,751.82535

Timestep Collection Time: 2.07745
Timestep Consumption Time: 0.90802
PPO Batch Consumption Time: 0.10729
Total Iteration Time: 2.98547

Cumulative Model Updates: 9,063
Cumulative Timesteps: 151,298,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.81048
Policy Entropy: 0.66331
Value Function Loss: 0.62151

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03556
Policy Update Magnitude: 0.02054
Value Function Update Magnitude: 0.02232

Collected Steps per Second: 23,652.22556
Overall Steps per Second: 16,699.30484

Timestep Collection Time: 2.11473
Timestep Consumption Time: 0.88049
PPO Batch Consumption Time: 0.09601
Total Iteration Time: 2.99521

Cumulative Model Updates: 9,066
Cumulative Timesteps: 151,348,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 151348696...
Checkpoint 151348696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,246.15447
Policy Entropy: 0.66034
Value Function Loss: 0.59782

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 0.01949
Value Function Update Magnitude: 0.02000

Collected Steps per Second: 23,434.06357
Overall Steps per Second: 16,716.33042

Timestep Collection Time: 2.13407
Timestep Consumption Time: 0.85761
PPO Batch Consumption Time: 0.08141
Total Iteration Time: 2.99169

Cumulative Model Updates: 9,069
Cumulative Timesteps: 151,398,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,527.83944
Policy Entropy: 0.66402
Value Function Loss: 0.63367

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04478
Policy Update Magnitude: 0.01707
Value Function Update Magnitude: 0.02074

Collected Steps per Second: 23,984.75664
Overall Steps per Second: 16,748.83067

Timestep Collection Time: 2.08516
Timestep Consumption Time: 0.90084
PPO Batch Consumption Time: 0.10244
Total Iteration Time: 2.98600

Cumulative Model Updates: 9,072
Cumulative Timesteps: 151,448,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 151448718...
Checkpoint 151448718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,267.99548
Policy Entropy: 0.65965
Value Function Loss: 0.62632

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01381
Policy Update Magnitude: 0.01987
Value Function Update Magnitude: 0.01976

Collected Steps per Second: 24,035.02826
Overall Steps per Second: 16,864.58916

Timestep Collection Time: 2.08088
Timestep Consumption Time: 0.88474
PPO Batch Consumption Time: 0.11549
Total Iteration Time: 2.96562

Cumulative Model Updates: 9,075
Cumulative Timesteps: 151,498,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,576.46057
Policy Entropy: 0.65370
Value Function Loss: 0.65203

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03340
Policy Update Magnitude: 0.02062
Value Function Update Magnitude: 0.02307

Collected Steps per Second: 23,708.31577
Overall Steps per Second: 16,704.85944

Timestep Collection Time: 2.10989
Timestep Consumption Time: 0.88457
PPO Batch Consumption Time: 0.11766
Total Iteration Time: 2.99446

Cumulative Model Updates: 9,078
Cumulative Timesteps: 151,548,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 151548754...
Checkpoint 151548754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,310.23755
Policy Entropy: 0.65933
Value Function Loss: 0.63934

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03350
Policy Update Magnitude: 0.01921
Value Function Update Magnitude: 0.02368

Collected Steps per Second: 23,566.93116
Overall Steps per Second: 16,753.52663

Timestep Collection Time: 2.12264
Timestep Consumption Time: 0.86324
PPO Batch Consumption Time: 0.10943
Total Iteration Time: 2.98588

Cumulative Model Updates: 9,081
Cumulative Timesteps: 151,598,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,504.63672
Policy Entropy: 0.66114
Value Function Loss: 0.64127

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.01989
Value Function Update Magnitude: 0.02075

Collected Steps per Second: 23,752.62514
Overall Steps per Second: 16,735.15930

Timestep Collection Time: 2.10613
Timestep Consumption Time: 0.88315
PPO Batch Consumption Time: 0.11579
Total Iteration Time: 2.98928

Cumulative Model Updates: 9,084
Cumulative Timesteps: 151,648,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 151648804...
Checkpoint 151648804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,244.96169
Policy Entropy: 0.67271
Value Function Loss: 0.63409

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02894
Policy Update Magnitude: 0.02198
Value Function Update Magnitude: 0.02083

Collected Steps per Second: 23,208.72338
Overall Steps per Second: 16,674.15695

Timestep Collection Time: 2.15557
Timestep Consumption Time: 0.84476
PPO Batch Consumption Time: 0.09806
Total Iteration Time: 3.00033

Cumulative Model Updates: 9,087
Cumulative Timesteps: 151,698,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.31145
Policy Entropy: 0.67663
Value Function Loss: 0.63266

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01335
Policy Update Magnitude: 0.02111
Value Function Update Magnitude: 0.02232

Collected Steps per Second: 23,372.10932
Overall Steps per Second: 16,706.45364

Timestep Collection Time: 2.14050
Timestep Consumption Time: 0.85403
PPO Batch Consumption Time: 0.10038
Total Iteration Time: 2.99453

Cumulative Model Updates: 9,090
Cumulative Timesteps: 151,748,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 151748860...
Checkpoint 151748860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,701.50226
Policy Entropy: 0.67563
Value Function Loss: 0.65402

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04227
Policy Update Magnitude: 0.02260
Value Function Update Magnitude: 0.02337

Collected Steps per Second: 24,305.88751
Overall Steps per Second: 16,768.50844

Timestep Collection Time: 2.05744
Timestep Consumption Time: 0.92481
PPO Batch Consumption Time: 0.10394
Total Iteration Time: 2.98226

Cumulative Model Updates: 9,093
Cumulative Timesteps: 151,798,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,993.31216
Policy Entropy: 0.66957
Value Function Loss: 0.64948

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03561
Policy Update Magnitude: 0.01959
Value Function Update Magnitude: 0.02303

Collected Steps per Second: 24,356.49536
Overall Steps per Second: 16,711.64972

Timestep Collection Time: 2.05407
Timestep Consumption Time: 0.93965
PPO Batch Consumption Time: 0.10713
Total Iteration Time: 2.99372

Cumulative Model Updates: 9,096
Cumulative Timesteps: 151,848,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 151848898...
Checkpoint 151848898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,513.19202
Policy Entropy: 0.65720
Value Function Loss: 0.66329

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03249
Policy Update Magnitude: 0.02012
Value Function Update Magnitude: 0.02509

Collected Steps per Second: 24,251.82288
Overall Steps per Second: 16,759.34595

Timestep Collection Time: 2.06220
Timestep Consumption Time: 0.92193
PPO Batch Consumption Time: 0.10155
Total Iteration Time: 2.98413

Cumulative Model Updates: 9,099
Cumulative Timesteps: 151,898,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,893.10891
Policy Entropy: 0.65932
Value Function Loss: 0.64915

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04328
Policy Update Magnitude: 0.01926
Value Function Update Magnitude: 0.02802

Collected Steps per Second: 24,195.15438
Overall Steps per Second: 16,721.35987

Timestep Collection Time: 2.06736
Timestep Consumption Time: 0.92403
PPO Batch Consumption Time: 0.10324
Total Iteration Time: 2.99138

Cumulative Model Updates: 9,102
Cumulative Timesteps: 151,948,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 151948930...
Checkpoint 151948930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,303.28984
Policy Entropy: 0.65620
Value Function Loss: 0.61853

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01180
Policy Update Magnitude: 0.02134
Value Function Update Magnitude: 0.02575

Collected Steps per Second: 23,966.91042
Overall Steps per Second: 16,745.07150

Timestep Collection Time: 2.08663
Timestep Consumption Time: 0.89992
PPO Batch Consumption Time: 0.09666
Total Iteration Time: 2.98655

Cumulative Model Updates: 9,105
Cumulative Timesteps: 151,998,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,423.96255
Policy Entropy: 0.66697
Value Function Loss: 0.58870

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.04213
Policy Update Magnitude: 0.02274
Value Function Update Magnitude: 0.02286

Collected Steps per Second: 23,875.10760
Overall Steps per Second: 16,716.09609

Timestep Collection Time: 2.09532
Timestep Consumption Time: 0.89736
PPO Batch Consumption Time: 0.09664
Total Iteration Time: 2.99268

Cumulative Model Updates: 9,108
Cumulative Timesteps: 152,048,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 152048966...
Checkpoint 152048966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,369.73931
Policy Entropy: 0.67498
Value Function Loss: 0.55380

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.06167
Policy Update Magnitude: 0.02186
Value Function Update Magnitude: 0.02149

Collected Steps per Second: 24,182.50501
Overall Steps per Second: 16,777.24498

Timestep Collection Time: 2.06860
Timestep Consumption Time: 0.91305
PPO Batch Consumption Time: 0.09895
Total Iteration Time: 2.98166

Cumulative Model Updates: 9,111
Cumulative Timesteps: 152,098,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,832.00031
Policy Entropy: 0.67607
Value Function Loss: 0.55801

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.06243
Policy Update Magnitude: 0.01677
Value Function Update Magnitude: 0.02134

Collected Steps per Second: 24,163.21183
Overall Steps per Second: 16,723.20981

Timestep Collection Time: 2.06992
Timestep Consumption Time: 0.92089
PPO Batch Consumption Time: 0.10206
Total Iteration Time: 2.99081

Cumulative Model Updates: 9,114
Cumulative Timesteps: 152,149,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 152149006...
Checkpoint 152149006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,755.63498
Policy Entropy: 0.67292
Value Function Loss: 0.59375

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04763
Policy Update Magnitude: 0.01934
Value Function Update Magnitude: 0.02148

Collected Steps per Second: 24,167.94081
Overall Steps per Second: 16,715.55011

Timestep Collection Time: 2.07002
Timestep Consumption Time: 0.92289
PPO Batch Consumption Time: 0.10337
Total Iteration Time: 2.99290

Cumulative Model Updates: 9,117
Cumulative Timesteps: 152,199,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.68738
Policy Entropy: 0.66213
Value Function Loss: 0.62807

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03987
Policy Update Magnitude: 0.02116
Value Function Update Magnitude: 0.02142

Collected Steps per Second: 24,105.76732
Overall Steps per Second: 16,741.87074

Timestep Collection Time: 2.07477
Timestep Consumption Time: 0.91259
PPO Batch Consumption Time: 0.10148
Total Iteration Time: 2.98736

Cumulative Model Updates: 9,120
Cumulative Timesteps: 152,249,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 152249048...
Checkpoint 152249048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,000.70070
Policy Entropy: 0.66511
Value Function Loss: 0.60586

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 0.02067
Value Function Update Magnitude: 0.02195

Collected Steps per Second: 24,141.09424
Overall Steps per Second: 16,775.54159

Timestep Collection Time: 2.07232
Timestep Consumption Time: 0.90988
PPO Batch Consumption Time: 0.10276
Total Iteration Time: 2.98220

Cumulative Model Updates: 9,123
Cumulative Timesteps: 152,299,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,570.97527
Policy Entropy: 0.67457
Value Function Loss: 0.56568

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02860
Policy Update Magnitude: 0.02177
Value Function Update Magnitude: 0.02320

Collected Steps per Second: 24,272.40658
Overall Steps per Second: 16,711.94419

Timestep Collection Time: 2.06036
Timestep Consumption Time: 0.93211
PPO Batch Consumption Time: 0.10141
Total Iteration Time: 2.99247

Cumulative Model Updates: 9,126
Cumulative Timesteps: 152,349,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 152349086...
Checkpoint 152349086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,609.87717
Policy Entropy: 0.67665
Value Function Loss: 0.56198

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03663
Policy Update Magnitude: 0.02023
Value Function Update Magnitude: 0.02154

Collected Steps per Second: 24,046.20494
Overall Steps per Second: 16,760.05169

Timestep Collection Time: 2.08025
Timestep Consumption Time: 0.90435
PPO Batch Consumption Time: 0.09992
Total Iteration Time: 2.98460

Cumulative Model Updates: 9,129
Cumulative Timesteps: 152,399,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,167.07781
Policy Entropy: 0.67252
Value Function Loss: 0.57404

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01915
Policy Update Magnitude: 0.02157
Value Function Update Magnitude: 0.02130

Collected Steps per Second: 24,260.08158
Overall Steps per Second: 16,719.94069

Timestep Collection Time: 2.06133
Timestep Consumption Time: 0.92959
PPO Batch Consumption Time: 0.10596
Total Iteration Time: 2.99092

Cumulative Model Updates: 9,132
Cumulative Timesteps: 152,449,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 152449116...
Checkpoint 152449116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,317.55766
Policy Entropy: 0.67333
Value Function Loss: 0.57372

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03455
Policy Update Magnitude: 0.02099
Value Function Update Magnitude: 0.02140

Collected Steps per Second: 23,986.47735
Overall Steps per Second: 16,743.16799

Timestep Collection Time: 2.08551
Timestep Consumption Time: 0.90222
PPO Batch Consumption Time: 0.09069
Total Iteration Time: 2.98773

Cumulative Model Updates: 9,135
Cumulative Timesteps: 152,499,140

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,170.08288
Policy Entropy: 0.67581
Value Function Loss: 0.58477

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03748
Policy Update Magnitude: 0.02079
Value Function Update Magnitude: 0.02359

Collected Steps per Second: 24,035.52506
Overall Steps per Second: 16,734.98099

Timestep Collection Time: 2.08092
Timestep Consumption Time: 0.90779
PPO Batch Consumption Time: 0.10565
Total Iteration Time: 2.98871

Cumulative Model Updates: 9,138
Cumulative Timesteps: 152,549,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 152549156...
Checkpoint 152549156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.05690
Policy Entropy: 0.66355
Value Function Loss: 0.61370

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03173
Policy Update Magnitude: 0.01939
Value Function Update Magnitude: 0.02249

Collected Steps per Second: 23,995.87365
Overall Steps per Second: 16,760.56334

Timestep Collection Time: 2.08494
Timestep Consumption Time: 0.90004
PPO Batch Consumption Time: 0.10411
Total Iteration Time: 2.98498

Cumulative Model Updates: 9,141
Cumulative Timesteps: 152,599,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,194.46124
Policy Entropy: 0.66248
Value Function Loss: 0.62400

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.02139
Value Function Update Magnitude: 0.02327

Collected Steps per Second: 24,229.04842
Overall Steps per Second: 16,793.09452

Timestep Collection Time: 2.06397
Timestep Consumption Time: 0.91392
PPO Batch Consumption Time: 0.10610
Total Iteration Time: 2.97789

Cumulative Model Updates: 9,144
Cumulative Timesteps: 152,649,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 152649194...
Checkpoint 152649194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,465.47848
Policy Entropy: 0.66216
Value Function Loss: 0.61871

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.02358
Value Function Update Magnitude: 0.02301

Collected Steps per Second: 23,852.24028
Overall Steps per Second: 16,679.55429

Timestep Collection Time: 2.09716
Timestep Consumption Time: 0.90184
PPO Batch Consumption Time: 0.10326
Total Iteration Time: 2.99900

Cumulative Model Updates: 9,147
Cumulative Timesteps: 152,699,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,517.36937
Policy Entropy: 0.66986
Value Function Loss: 0.60452

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.05103
Policy Update Magnitude: 0.02190
Value Function Update Magnitude: 0.02125

Collected Steps per Second: 23,926.59285
Overall Steps per Second: 16,720.46849

Timestep Collection Time: 2.09073
Timestep Consumption Time: 0.90105
PPO Batch Consumption Time: 0.10425
Total Iteration Time: 2.99178

Cumulative Model Updates: 9,150
Cumulative Timesteps: 152,749,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 152749240...
Checkpoint 152749240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,658.61206
Policy Entropy: 0.66545
Value Function Loss: 0.60506

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04564
Policy Update Magnitude: 0.01948
Value Function Update Magnitude: 0.02050

Collected Steps per Second: 23,830.12336
Overall Steps per Second: 16,756.27550

Timestep Collection Time: 2.09852
Timestep Consumption Time: 0.88591
PPO Batch Consumption Time: 0.10022
Total Iteration Time: 2.98443

Cumulative Model Updates: 9,153
Cumulative Timesteps: 152,799,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,971.73118
Policy Entropy: 0.66814
Value Function Loss: 0.60044

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04843
Policy Update Magnitude: 0.01847
Value Function Update Magnitude: 0.02210

Collected Steps per Second: 23,998.72995
Overall Steps per Second: 16,715.72813

Timestep Collection Time: 2.08369
Timestep Consumption Time: 0.90786
PPO Batch Consumption Time: 0.09895
Total Iteration Time: 2.99155

Cumulative Model Updates: 9,156
Cumulative Timesteps: 152,849,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 152849254...
Checkpoint 152849254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,342.95841
Policy Entropy: 0.66733
Value Function Loss: 0.58849

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03154
Policy Update Magnitude: 0.01958
Value Function Update Magnitude: 0.02153

Collected Steps per Second: 24,105.32582
Overall Steps per Second: 16,767.14021

Timestep Collection Time: 2.07481
Timestep Consumption Time: 0.90805
PPO Batch Consumption Time: 0.10502
Total Iteration Time: 2.98286

Cumulative Model Updates: 9,159
Cumulative Timesteps: 152,899,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,512.59791
Policy Entropy: 0.67831
Value Function Loss: 0.59810

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.02142
Value Function Update Magnitude: 0.01985

Collected Steps per Second: 24,369.68375
Overall Steps per Second: 16,773.61796

Timestep Collection Time: 2.05263
Timestep Consumption Time: 0.92955
PPO Batch Consumption Time: 0.11074
Total Iteration Time: 2.98218

Cumulative Model Updates: 9,162
Cumulative Timesteps: 152,949,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 152949290...
Checkpoint 152949290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.99296
Policy Entropy: 0.66725
Value Function Loss: 0.63057

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03465
Policy Update Magnitude: 0.02016
Value Function Update Magnitude: 0.02343

Collected Steps per Second: 24,052.76372
Overall Steps per Second: 16,789.56251

Timestep Collection Time: 2.07926
Timestep Consumption Time: 0.89949
PPO Batch Consumption Time: 0.12090
Total Iteration Time: 2.97876

Cumulative Model Updates: 9,165
Cumulative Timesteps: 152,999,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,549.87052
Policy Entropy: 0.67206
Value Function Loss: 0.63201

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.02108
Value Function Update Magnitude: 0.02299

Collected Steps per Second: 23,828.97934
Overall Steps per Second: 16,591.01477

Timestep Collection Time: 2.09929
Timestep Consumption Time: 0.91583
PPO Batch Consumption Time: 0.11350
Total Iteration Time: 3.01513

Cumulative Model Updates: 9,168
Cumulative Timesteps: 153,049,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 153049326...
Checkpoint 153049326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,923.72847
Policy Entropy: 0.66828
Value Function Loss: 0.63635

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.04121
Policy Update Magnitude: 0.01884
Value Function Update Magnitude: 0.02489

Collected Steps per Second: 22,442.15754
Overall Steps per Second: 16,480.64933

Timestep Collection Time: 2.22804
Timestep Consumption Time: 0.80594
PPO Batch Consumption Time: 0.07752
Total Iteration Time: 3.03398

Cumulative Model Updates: 9,171
Cumulative Timesteps: 153,099,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,118.36491
Policy Entropy: 0.67847
Value Function Loss: 0.60579

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.01934
Value Function Update Magnitude: 0.03082

Collected Steps per Second: 22,372.43726
Overall Steps per Second: 15,990.14775

Timestep Collection Time: 2.23588
Timestep Consumption Time: 0.89243
PPO Batch Consumption Time: 0.11697
Total Iteration Time: 3.12830

Cumulative Model Updates: 9,174
Cumulative Timesteps: 153,149,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 153149350...
Checkpoint 153149350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,247.61457
Policy Entropy: 0.68181
Value Function Loss: 0.59458

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01718
Policy Update Magnitude: 0.02205
Value Function Update Magnitude: 0.02909

Collected Steps per Second: 22,313.87814
Overall Steps per Second: 16,947.96254

Timestep Collection Time: 2.24148
Timestep Consumption Time: 0.70968
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 2.95115

Cumulative Model Updates: 9,177
Cumulative Timesteps: 153,199,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,578.17445
Policy Entropy: 0.68146
Value Function Loss: 0.58181

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02105
Policy Update Magnitude: 0.02363
Value Function Update Magnitude: 0.02678

Collected Steps per Second: 23,890.23862
Overall Steps per Second: 17,270.18287

Timestep Collection Time: 2.09391
Timestep Consumption Time: 0.80264
PPO Batch Consumption Time: 0.06460
Total Iteration Time: 2.89655

Cumulative Model Updates: 9,180
Cumulative Timesteps: 153,249,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 153249390...
Checkpoint 153249390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,197.31038
Policy Entropy: 0.67779
Value Function Loss: 0.59272

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04616
Policy Update Magnitude: 0.02086
Value Function Update Magnitude: 0.02233

Collected Steps per Second: 20,672.03926
Overall Steps per Second: 14,910.73489

Timestep Collection Time: 2.41940
Timestep Consumption Time: 0.93482
PPO Batch Consumption Time: 0.10814
Total Iteration Time: 3.35423

Cumulative Model Updates: 9,183
Cumulative Timesteps: 153,299,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,533.15767
Policy Entropy: 0.67636
Value Function Loss: 0.61147

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.04012
Policy Update Magnitude: 0.01933
Value Function Update Magnitude: 0.02096

Collected Steps per Second: 22,695.54213
Overall Steps per Second: 16,551.67067

Timestep Collection Time: 2.20493
Timestep Consumption Time: 0.81845
PPO Batch Consumption Time: 0.06679
Total Iteration Time: 3.02338

Cumulative Model Updates: 9,186
Cumulative Timesteps: 153,349,446

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 153349446...
Checkpoint 153349446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,524.28272
Policy Entropy: 0.67565
Value Function Loss: 0.62248

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03355
Policy Update Magnitude: 0.02086
Value Function Update Magnitude: 0.02181

Collected Steps per Second: 20,140.06072
Overall Steps per Second: 14,132.65093

Timestep Collection Time: 2.48341
Timestep Consumption Time: 1.05563
PPO Batch Consumption Time: 0.13840
Total Iteration Time: 3.53904

Cumulative Model Updates: 9,189
Cumulative Timesteps: 153,399,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,425.27592
Policy Entropy: 0.67207
Value Function Loss: 0.60255

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02100
Policy Update Magnitude: 0.02037
Value Function Update Magnitude: 0.02312

Collected Steps per Second: 23,354.19395
Overall Steps per Second: 17,102.96114

Timestep Collection Time: 2.14257
Timestep Consumption Time: 0.78312
PPO Batch Consumption Time: 0.06381
Total Iteration Time: 2.92569

Cumulative Model Updates: 9,192
Cumulative Timesteps: 153,449,500

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 153449500...
Checkpoint 153449500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,579.58769
Policy Entropy: 0.67480
Value Function Loss: 0.56644

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02002
Policy Update Magnitude: 0.02299
Value Function Update Magnitude: 0.02371

Collected Steps per Second: 23,546.97544
Overall Steps per Second: 16,456.79497

Timestep Collection Time: 2.12350
Timestep Consumption Time: 0.91488
PPO Batch Consumption Time: 0.10129
Total Iteration Time: 3.03838

Cumulative Model Updates: 9,195
Cumulative Timesteps: 153,499,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,256.75492
Policy Entropy: 0.68016
Value Function Loss: 0.55801

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01538
Policy Update Magnitude: 0.02343
Value Function Update Magnitude: 0.02285

Collected Steps per Second: 23,856.26846
Overall Steps per Second: 17,105.49620

Timestep Collection Time: 2.09589
Timestep Consumption Time: 0.82715
PPO Batch Consumption Time: 0.07514
Total Iteration Time: 2.92304

Cumulative Model Updates: 9,198
Cumulative Timesteps: 153,549,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 153549502...
Checkpoint 153549502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,534.19212
Policy Entropy: 0.67744
Value Function Loss: 0.57657

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.02243
Value Function Update Magnitude: 0.02402

Collected Steps per Second: 23,662.90044
Overall Steps per Second: 16,401.82491

Timestep Collection Time: 2.11420
Timestep Consumption Time: 0.93595
PPO Batch Consumption Time: 0.10172
Total Iteration Time: 3.05015

Cumulative Model Updates: 9,201
Cumulative Timesteps: 153,599,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,396.20312
Policy Entropy: 0.67392
Value Function Loss: 0.57559

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03293
Policy Update Magnitude: 0.02228
Value Function Update Magnitude: 0.02283

Collected Steps per Second: 23,056.88702
Overall Steps per Second: 17,540.12388

Timestep Collection Time: 2.16924
Timestep Consumption Time: 0.68228
PPO Batch Consumption Time: 0.03146
Total Iteration Time: 2.85152

Cumulative Model Updates: 9,204
Cumulative Timesteps: 153,649,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 153649546...
Checkpoint 153649546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,271.72109
Policy Entropy: 0.66883
Value Function Loss: 0.57875

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01717
Policy Update Magnitude: 0.02314
Value Function Update Magnitude: 0.02274

Collected Steps per Second: 24,363.22870
Overall Steps per Second: 17,150.12924

Timestep Collection Time: 2.05359
Timestep Consumption Time: 0.86371
PPO Batch Consumption Time: 0.09163
Total Iteration Time: 2.91730

Cumulative Model Updates: 9,207
Cumulative Timesteps: 153,699,578

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,177.04372
Policy Entropy: 0.67041
Value Function Loss: 0.59383

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04737
Policy Update Magnitude: 0.02319
Value Function Update Magnitude: 0.02546

Collected Steps per Second: 23,464.91547
Overall Steps per Second: 17,002.10726

Timestep Collection Time: 2.13127
Timestep Consumption Time: 0.81013
PPO Batch Consumption Time: 0.06492
Total Iteration Time: 2.94140

Cumulative Model Updates: 9,210
Cumulative Timesteps: 153,749,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 153749588...
Checkpoint 153749588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,374.61789
Policy Entropy: 0.66997
Value Function Loss: 0.59999

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04640
Policy Update Magnitude: 0.02028
Value Function Update Magnitude: 0.02756

Collected Steps per Second: 21,371.33396
Overall Steps per Second: 16,318.88999

Timestep Collection Time: 2.34042
Timestep Consumption Time: 0.72461
PPO Batch Consumption Time: 0.02869
Total Iteration Time: 3.06504

Cumulative Model Updates: 9,213
Cumulative Timesteps: 153,799,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,212.52590
Policy Entropy: 0.67814
Value Function Loss: 0.56275

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03169
Policy Update Magnitude: 0.02015
Value Function Update Magnitude: 0.02907

Collected Steps per Second: 22,907.31608
Overall Steps per Second: 15,849.84330

Timestep Collection Time: 2.18393
Timestep Consumption Time: 0.97244
PPO Batch Consumption Time: 0.09354
Total Iteration Time: 3.15637

Cumulative Model Updates: 9,216
Cumulative Timesteps: 153,849,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 153849634...
Checkpoint 153849634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,789.52214
Policy Entropy: 0.68574
Value Function Loss: 0.52313

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01077
Policy Update Magnitude: 0.02244
Value Function Update Magnitude: 0.03005

Collected Steps per Second: 23,376.69743
Overall Steps per Second: 17,640.99161

Timestep Collection Time: 2.13948
Timestep Consumption Time: 0.69562
PPO Batch Consumption Time: 0.02971
Total Iteration Time: 2.83510

Cumulative Model Updates: 9,219
Cumulative Timesteps: 153,899,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,510.26878
Policy Entropy: 0.68314
Value Function Loss: 0.53416

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01703
Policy Update Magnitude: 0.02328
Value Function Update Magnitude: 0.02421

Collected Steps per Second: 24,074.90514
Overall Steps per Second: 17,016.21688

Timestep Collection Time: 2.07743
Timestep Consumption Time: 0.86176
PPO Batch Consumption Time: 0.09480
Total Iteration Time: 2.93920

Cumulative Model Updates: 9,222
Cumulative Timesteps: 153,949,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 153949662...
Checkpoint 153949662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,132.45473
Policy Entropy: 0.67783
Value Function Loss: 0.59273

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03309
Policy Update Magnitude: 0.02446
Value Function Update Magnitude: 0.02499

Collected Steps per Second: 23,274.75343
Overall Steps per Second: 17,843.52178

Timestep Collection Time: 2.14834
Timestep Consumption Time: 0.65391
PPO Batch Consumption Time: 0.03030
Total Iteration Time: 2.80225

Cumulative Model Updates: 9,225
Cumulative Timesteps: 153,999,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,481.48461
Policy Entropy: 0.67837
Value Function Loss: 0.58492

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.02295
Value Function Update Magnitude: 0.02550

Collected Steps per Second: 23,162.82465
Overall Steps per Second: 17,240.83485

Timestep Collection Time: 2.15906
Timestep Consumption Time: 0.74161
PPO Batch Consumption Time: 0.05303
Total Iteration Time: 2.90067

Cumulative Model Updates: 9,228
Cumulative Timesteps: 154,049,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 154049674...
Checkpoint 154049674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.29566
Policy Entropy: 0.67901
Value Function Loss: 0.58180

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.02305
Value Function Update Magnitude: 0.02636

Collected Steps per Second: 22,477.65103
Overall Steps per Second: 16,285.96702

Timestep Collection Time: 2.22452
Timestep Consumption Time: 0.84573
PPO Batch Consumption Time: 0.08624
Total Iteration Time: 3.07025

Cumulative Model Updates: 9,231
Cumulative Timesteps: 154,099,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,709.57667
Policy Entropy: 0.68647
Value Function Loss: 0.55180

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05353
Policy Update Magnitude: 0.02153
Value Function Update Magnitude: 0.02742

Collected Steps per Second: 22,705.12771
Overall Steps per Second: 15,680.01432

Timestep Collection Time: 2.20232
Timestep Consumption Time: 0.98671
PPO Batch Consumption Time: 0.12225
Total Iteration Time: 3.18903

Cumulative Model Updates: 9,234
Cumulative Timesteps: 154,149,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 154149680...
Checkpoint 154149680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,553.56874
Policy Entropy: 0.68872
Value Function Loss: 0.56674

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03947
Policy Update Magnitude: 0.01976
Value Function Update Magnitude: 0.02483

Collected Steps per Second: 23,934.04043
Overall Steps per Second: 17,583.85834

Timestep Collection Time: 2.08991
Timestep Consumption Time: 0.75474
PPO Batch Consumption Time: 0.05978
Total Iteration Time: 2.84465

Cumulative Model Updates: 9,237
Cumulative Timesteps: 154,199,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,113.06521
Policy Entropy: 0.68969
Value Function Loss: 0.55883

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04552
Policy Update Magnitude: 0.02003
Value Function Update Magnitude: 0.02239

Collected Steps per Second: 21,043.34033
Overall Steps per Second: 15,062.08986

Timestep Collection Time: 2.37643
Timestep Consumption Time: 0.94369
PPO Batch Consumption Time: 0.10918
Total Iteration Time: 3.32012

Cumulative Model Updates: 9,240
Cumulative Timesteps: 154,249,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 154249708...
Checkpoint 154249708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,001.43174
Policy Entropy: 0.68992
Value Function Loss: 0.56667

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04792
Policy Update Magnitude: 0.02007
Value Function Update Magnitude: 0.02394

Collected Steps per Second: 22,797.51191
Overall Steps per Second: 16,896.80976

Timestep Collection Time: 2.19445
Timestep Consumption Time: 0.76635
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 2.96080

Cumulative Model Updates: 9,243
Cumulative Timesteps: 154,299,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,740.13652
Policy Entropy: 0.69085
Value Function Loss: 0.55191

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.06058
Policy Update Magnitude: 0.01790
Value Function Update Magnitude: 0.02096

Collected Steps per Second: 19,916.85224
Overall Steps per Second: 14,600.23366

Timestep Collection Time: 2.51124
Timestep Consumption Time: 0.91446
PPO Batch Consumption Time: 0.09435
Total Iteration Time: 3.42570

Cumulative Model Updates: 9,246
Cumulative Timesteps: 154,349,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 154349752...
Checkpoint 154349752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,278.65805
Policy Entropy: 0.68672
Value Function Loss: 0.55645

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03427
Policy Update Magnitude: 0.01798
Value Function Update Magnitude: 0.02438

Collected Steps per Second: 21,596.70269
Overall Steps per Second: 16,123.49163

Timestep Collection Time: 2.31609
Timestep Consumption Time: 0.78621
PPO Batch Consumption Time: 0.06504
Total Iteration Time: 3.10231

Cumulative Model Updates: 9,249
Cumulative Timesteps: 154,399,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,580.63540
Policy Entropy: 0.68118
Value Function Loss: 0.55318

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05909
Policy Update Magnitude: 0.01999
Value Function Update Magnitude: 0.02507

Collected Steps per Second: 22,847.36914
Overall Steps per Second: 17,517.44538

Timestep Collection Time: 2.18896
Timestep Consumption Time: 0.66602
PPO Batch Consumption Time: 0.02916
Total Iteration Time: 2.85498

Cumulative Model Updates: 9,252
Cumulative Timesteps: 154,449,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 154449784...
Checkpoint 154449784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,777.41036
Policy Entropy: 0.67775
Value Function Loss: 0.54813

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.05061
Policy Update Magnitude: 0.01856
Value Function Update Magnitude: 0.02774

Collected Steps per Second: 23,309.00358
Overall Steps per Second: 16,707.89765

Timestep Collection Time: 2.14647
Timestep Consumption Time: 0.84805
PPO Batch Consumption Time: 0.09150
Total Iteration Time: 2.99451

Cumulative Model Updates: 9,255
Cumulative Timesteps: 154,499,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,613.38451
Policy Entropy: 0.67818
Value Function Loss: 0.53941

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.06227
Policy Update Magnitude: 0.01874
Value Function Update Magnitude: 0.02466

Collected Steps per Second: 23,393.51875
Overall Steps per Second: 17,072.26525

Timestep Collection Time: 2.13777
Timestep Consumption Time: 0.79154
PPO Batch Consumption Time: 0.07129
Total Iteration Time: 2.92931

Cumulative Model Updates: 9,258
Cumulative Timesteps: 154,549,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 154549826...
Checkpoint 154549826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,340.89731
Policy Entropy: 0.67878
Value Function Loss: 0.53010

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.01595
Value Function Update Magnitude: 0.02350

Collected Steps per Second: 23,631.04385
Overall Steps per Second: 17,317.29869

Timestep Collection Time: 2.11628
Timestep Consumption Time: 0.77158
PPO Batch Consumption Time: 0.06242
Total Iteration Time: 2.88786

Cumulative Model Updates: 9,261
Cumulative Timesteps: 154,599,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,765.68294
Policy Entropy: 0.67127
Value Function Loss: 0.53920

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04585
Policy Update Magnitude: 0.01594
Value Function Update Magnitude: 0.02297

Collected Steps per Second: 20,935.56250
Overall Steps per Second: 14,897.54919

Timestep Collection Time: 2.38857
Timestep Consumption Time: 0.96809
PPO Batch Consumption Time: 0.12694
Total Iteration Time: 3.35666

Cumulative Model Updates: 9,264
Cumulative Timesteps: 154,649,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 154649842...
Checkpoint 154649842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,467.81408
Policy Entropy: 0.66702
Value Function Loss: 0.53791

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04160
Policy Update Magnitude: 0.01830
Value Function Update Magnitude: 0.02315

Collected Steps per Second: 24,027.52009
Overall Steps per Second: 17,629.79759

Timestep Collection Time: 2.08145
Timestep Consumption Time: 0.75534
PPO Batch Consumption Time: 0.06088
Total Iteration Time: 2.83679

Cumulative Model Updates: 9,267
Cumulative Timesteps: 154,699,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,708.39825
Policy Entropy: 0.66283
Value Function Loss: 0.57000

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03943
Policy Update Magnitude: 0.01725
Value Function Update Magnitude: 0.02225

Collected Steps per Second: 21,365.62973
Overall Steps per Second: 15,161.67519

Timestep Collection Time: 2.34161
Timestep Consumption Time: 0.95816
PPO Batch Consumption Time: 0.12012
Total Iteration Time: 3.29977

Cumulative Model Updates: 9,270
Cumulative Timesteps: 154,749,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 154749884...
Checkpoint 154749884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,990.76343
Policy Entropy: 0.66642
Value Function Loss: 0.57332

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.02023
Value Function Update Magnitude: 0.02239

Collected Steps per Second: 23,048.45683
Overall Steps per Second: 17,794.80297

Timestep Collection Time: 2.16978
Timestep Consumption Time: 0.64059
PPO Batch Consumption Time: 0.02919
Total Iteration Time: 2.81037

Cumulative Model Updates: 9,273
Cumulative Timesteps: 154,799,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,977.90277
Policy Entropy: 0.66339
Value Function Loss: 0.57207

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01841
Policy Update Magnitude: 0.02316
Value Function Update Magnitude: 0.02099

Collected Steps per Second: 23,096.19223
Overall Steps per Second: 16,766.22711

Timestep Collection Time: 2.16512
Timestep Consumption Time: 0.81742
PPO Batch Consumption Time: 0.09936
Total Iteration Time: 2.98254

Cumulative Model Updates: 9,276
Cumulative Timesteps: 154,849,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 154849900...
Checkpoint 154849900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,243.93392
Policy Entropy: 0.66544
Value Function Loss: 0.57939

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03097
Policy Update Magnitude: 0.02454
Value Function Update Magnitude: 0.02501

Collected Steps per Second: 22,312.34291
Overall Steps per Second: 16,958.53290

Timestep Collection Time: 2.24181
Timestep Consumption Time: 0.70774
PPO Batch Consumption Time: 0.05909
Total Iteration Time: 2.94955

Cumulative Model Updates: 9,279
Cumulative Timesteps: 154,899,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,325.68941
Policy Entropy: 0.67055
Value Function Loss: 0.58241

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 0.02596
Value Function Update Magnitude: 0.02464

Collected Steps per Second: 21,253.54428
Overall Steps per Second: 15,556.83201

Timestep Collection Time: 2.35274
Timestep Consumption Time: 0.86154
PPO Batch Consumption Time: 0.10861
Total Iteration Time: 3.21428

Cumulative Model Updates: 9,282
Cumulative Timesteps: 154,949,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 154949924...
Checkpoint 154949924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,371.85655
Policy Entropy: 0.68140
Value Function Loss: 0.56722

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04629
Policy Update Magnitude: 0.02227
Value Function Update Magnitude: 0.02335

Collected Steps per Second: 23,329.62384
Overall Steps per Second: 16,708.76592

Timestep Collection Time: 2.14423
Timestep Consumption Time: 0.84965
PPO Batch Consumption Time: 0.10721
Total Iteration Time: 2.99388

Cumulative Model Updates: 9,285
Cumulative Timesteps: 154,999,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,397.20177
Policy Entropy: 0.67737
Value Function Loss: 0.59763

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03743
Policy Update Magnitude: 0.01939
Value Function Update Magnitude: 0.02484

Collected Steps per Second: 23,082.75287
Overall Steps per Second: 17,817.27610

Timestep Collection Time: 2.16699
Timestep Consumption Time: 0.64040
PPO Batch Consumption Time: 0.03124
Total Iteration Time: 2.80739

Cumulative Model Updates: 9,288
Cumulative Timesteps: 155,049,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 155049968...
Checkpoint 155049968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,971.26180
Policy Entropy: 0.66832
Value Function Loss: 0.58837

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04287
Policy Update Magnitude: 0.01923
Value Function Update Magnitude: 0.02331

Collected Steps per Second: 24,382.67340
Overall Steps per Second: 17,934.31918

Timestep Collection Time: 2.05096
Timestep Consumption Time: 0.73743
PPO Batch Consumption Time: 0.04909
Total Iteration Time: 2.78840

Cumulative Model Updates: 9,291
Cumulative Timesteps: 155,099,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,198.13185
Policy Entropy: 0.66985
Value Function Loss: 0.59619

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01851
Policy Update Magnitude: 0.01939
Value Function Update Magnitude: 0.02254

Collected Steps per Second: 22,282.48664
Overall Steps per Second: 15,710.91761

Timestep Collection Time: 2.24418
Timestep Consumption Time: 0.93870
PPO Batch Consumption Time: 0.10843
Total Iteration Time: 3.18288

Cumulative Model Updates: 9,294
Cumulative Timesteps: 155,149,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 155149982...
Checkpoint 155149982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,760.99929
Policy Entropy: 0.67004
Value Function Loss: 0.55047

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04121
Policy Update Magnitude: 0.01891
Value Function Update Magnitude: 0.02161

Collected Steps per Second: 23,151.69851
Overall Steps per Second: 16,963.94835

Timestep Collection Time: 2.16071
Timestep Consumption Time: 0.78814
PPO Batch Consumption Time: 0.05890
Total Iteration Time: 2.94884

Cumulative Model Updates: 9,297
Cumulative Timesteps: 155,200,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,088.25585
Policy Entropy: 0.67359
Value Function Loss: 0.57142

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01355
Policy Update Magnitude: 0.02124
Value Function Update Magnitude: 0.02103

Collected Steps per Second: 20,861.48949
Overall Steps per Second: 15,464.74455

Timestep Collection Time: 2.39705
Timestep Consumption Time: 0.83650
PPO Batch Consumption Time: 0.07556
Total Iteration Time: 3.23355

Cumulative Model Updates: 9,300
Cumulative Timesteps: 155,250,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 155250012...
Checkpoint 155250012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,791.62694
Policy Entropy: 0.67030
Value Function Loss: 0.54877

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02120
Policy Update Magnitude: 0.02217
Value Function Update Magnitude: 0.02121

Collected Steps per Second: 24,017.12480
Overall Steps per Second: 16,825.88385

Timestep Collection Time: 2.08301
Timestep Consumption Time: 0.89026
PPO Batch Consumption Time: 0.09356
Total Iteration Time: 2.97328

Cumulative Model Updates: 9,303
Cumulative Timesteps: 155,300,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,113.33007
Policy Entropy: 0.66977
Value Function Loss: 0.59514

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02748
Policy Update Magnitude: 0.02291
Value Function Update Magnitude: 0.01987

Collected Steps per Second: 24,047.63664
Overall Steps per Second: 16,712.95934

Timestep Collection Time: 2.07921
Timestep Consumption Time: 0.91248
PPO Batch Consumption Time: 0.09697
Total Iteration Time: 2.99169

Cumulative Model Updates: 9,306
Cumulative Timesteps: 155,350,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 155350040...
Checkpoint 155350040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,518.09627
Policy Entropy: 0.67024
Value Function Loss: 0.60309

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04047
Policy Update Magnitude: 0.02371
Value Function Update Magnitude: 0.02396

Collected Steps per Second: 24,071.51077
Overall Steps per Second: 16,786.60542

Timestep Collection Time: 2.07856
Timestep Consumption Time: 0.90203
PPO Batch Consumption Time: 0.09343
Total Iteration Time: 2.98059

Cumulative Model Updates: 9,309
Cumulative Timesteps: 155,400,074

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,838.17604
Policy Entropy: 0.66817
Value Function Loss: 0.61320

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03479
Policy Update Magnitude: 0.02255
Value Function Update Magnitude: 0.02236

Collected Steps per Second: 23,673.78200
Overall Steps per Second: 17,731.91918

Timestep Collection Time: 2.11331
Timestep Consumption Time: 0.70816
PPO Batch Consumption Time: 0.02922
Total Iteration Time: 2.82147

Cumulative Model Updates: 9,312
Cumulative Timesteps: 155,450,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 155450104...
Checkpoint 155450104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,454.46467
Policy Entropy: 0.67550
Value Function Loss: 0.58551

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.02151
Value Function Update Magnitude: 0.02439

Collected Steps per Second: 23,693.85919
Overall Steps per Second: 16,781.66820

Timestep Collection Time: 2.11093
Timestep Consumption Time: 0.86947
PPO Batch Consumption Time: 0.08793
Total Iteration Time: 2.98040

Cumulative Model Updates: 9,315
Cumulative Timesteps: 155,500,120

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,246.79158
Policy Entropy: 0.67313
Value Function Loss: 0.56468

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01967
Policy Update Magnitude: 0.02291
Value Function Update Magnitude: 0.02412

Collected Steps per Second: 24,042.67428
Overall Steps per Second: 17,527.92161

Timestep Collection Time: 2.07989
Timestep Consumption Time: 0.77305
PPO Batch Consumption Time: 0.05851
Total Iteration Time: 2.85293

Cumulative Model Updates: 9,318
Cumulative Timesteps: 155,550,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 155550126...
Checkpoint 155550126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,109.10236
Policy Entropy: 0.67624
Value Function Loss: 0.54039

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01919
Policy Update Magnitude: 0.02254
Value Function Update Magnitude: 0.02083

Collected Steps per Second: 21,192.99883
Overall Steps per Second: 16,177.10697

Timestep Collection Time: 2.35927
Timestep Consumption Time: 0.73152
PPO Batch Consumption Time: 0.03006
Total Iteration Time: 3.09079

Cumulative Model Updates: 9,321
Cumulative Timesteps: 155,600,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,245.26072
Policy Entropy: 0.66563
Value Function Loss: 0.53878

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04211
Policy Update Magnitude: 0.02417
Value Function Update Magnitude: 0.03494

Collected Steps per Second: 23,395.49849
Overall Steps per Second: 16,672.80103

Timestep Collection Time: 2.13759
Timestep Consumption Time: 0.86191
PPO Batch Consumption Time: 0.09159
Total Iteration Time: 2.99950

Cumulative Model Updates: 9,324
Cumulative Timesteps: 155,650,136

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 155650136...
Checkpoint 155650136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,912.95786
Policy Entropy: 0.66513
Value Function Loss: 0.56115

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.04105
Policy Update Magnitude: 0.02014
Value Function Update Magnitude: 0.02873

Collected Steps per Second: 24,316.87649
Overall Steps per Second: 17,924.30153

Timestep Collection Time: 2.05734
Timestep Consumption Time: 0.73373
PPO Batch Consumption Time: 0.05691
Total Iteration Time: 2.79107

Cumulative Model Updates: 9,327
Cumulative Timesteps: 155,700,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,065.79329
Policy Entropy: 0.66530
Value Function Loss: 0.55069

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.02155
Value Function Update Magnitude: 0.02421

Collected Steps per Second: 21,128.64182
Overall Steps per Second: 15,631.92134

Timestep Collection Time: 2.36769
Timestep Consumption Time: 0.83256
PPO Batch Consumption Time: 0.08347
Total Iteration Time: 3.20025

Cumulative Model Updates: 9,330
Cumulative Timesteps: 155,750,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 155750190...
Checkpoint 155750190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.58151
Policy Entropy: 0.66683
Value Function Loss: 0.55870

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.02295
Value Function Update Magnitude: 0.03175

Collected Steps per Second: 24,188.93946
Overall Steps per Second: 17,717.44626

Timestep Collection Time: 2.06822
Timestep Consumption Time: 0.75544
PPO Batch Consumption Time: 0.05925
Total Iteration Time: 2.82366

Cumulative Model Updates: 9,333
Cumulative Timesteps: 155,800,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.04120
Policy Entropy: 0.66734
Value Function Loss: 0.51881

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02819
Policy Update Magnitude: 0.02198
Value Function Update Magnitude: 0.03251

Collected Steps per Second: 21,161.03655
Overall Steps per Second: 15,067.82963

Timestep Collection Time: 2.36416
Timestep Consumption Time: 0.95603
PPO Batch Consumption Time: 0.12150
Total Iteration Time: 3.32019

Cumulative Model Updates: 9,336
Cumulative Timesteps: 155,850,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 155850246...
Checkpoint 155850246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,270.40243
Policy Entropy: 0.66498
Value Function Loss: 0.52784

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.02188
Value Function Update Magnitude: 0.02764

Collected Steps per Second: 23,690.10332
Overall Steps per Second: 16,664.58679

Timestep Collection Time: 2.11101
Timestep Consumption Time: 0.88997
PPO Batch Consumption Time: 0.09738
Total Iteration Time: 3.00097

Cumulative Model Updates: 9,339
Cumulative Timesteps: 155,900,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,150.86241
Policy Entropy: 0.67109
Value Function Loss: 0.49183

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03188
Policy Update Magnitude: 0.02244
Value Function Update Magnitude: 0.04416

Collected Steps per Second: 23,947.43264
Overall Steps per Second: 16,704.06711

Timestep Collection Time: 2.08899
Timestep Consumption Time: 0.90585
PPO Batch Consumption Time: 0.09838
Total Iteration Time: 2.99484

Cumulative Model Updates: 9,342
Cumulative Timesteps: 155,950,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 155950282...
Checkpoint 155950282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,857.08827
Policy Entropy: 0.66590
Value Function Loss: 0.53130

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03206
Policy Update Magnitude: 0.02309
Value Function Update Magnitude: 0.04509

Collected Steps per Second: 23,794.43232
Overall Steps per Second: 16,775.33308

Timestep Collection Time: 2.10226
Timestep Consumption Time: 0.87962
PPO Batch Consumption Time: 0.09372
Total Iteration Time: 2.98188

Cumulative Model Updates: 9,345
Cumulative Timesteps: 156,000,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,536.10558
Policy Entropy: 0.67380
Value Function Loss: 0.52314

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04369
Policy Update Magnitude: 0.02471
Value Function Update Magnitude: 0.05149

Collected Steps per Second: 23,594.28508
Overall Steps per Second: 16,688.53897

Timestep Collection Time: 2.12026
Timestep Consumption Time: 0.87737
PPO Batch Consumption Time: 0.09510
Total Iteration Time: 2.99763

Cumulative Model Updates: 9,348
Cumulative Timesteps: 156,050,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 156050330...
Checkpoint 156050330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.87254
Policy Entropy: 0.67166
Value Function Loss: 0.54520

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05479
Policy Update Magnitude: 0.02157
Value Function Update Magnitude: 0.05074

Collected Steps per Second: 24,050.97013
Overall Steps per Second: 16,807.12756

Timestep Collection Time: 2.07992
Timestep Consumption Time: 0.89644
PPO Batch Consumption Time: 0.09972
Total Iteration Time: 2.97636

Cumulative Model Updates: 9,351
Cumulative Timesteps: 156,100,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,672.80488
Policy Entropy: 0.66720
Value Function Loss: 0.54348

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.05255
Policy Update Magnitude: 0.02141
Value Function Update Magnitude: 0.05428

Collected Steps per Second: 24,263.62220
Overall Steps per Second: 16,744.34859

Timestep Collection Time: 2.06160
Timestep Consumption Time: 0.92579
PPO Batch Consumption Time: 0.10819
Total Iteration Time: 2.98740

Cumulative Model Updates: 9,354
Cumulative Timesteps: 156,150,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 156150376...
Checkpoint 156150376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,698.02214
Policy Entropy: 0.65829
Value Function Loss: 0.55557

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03503
Policy Update Magnitude: 0.02197
Value Function Update Magnitude: 0.04889

Collected Steps per Second: 23,930.81367
Overall Steps per Second: 16,784.05808

Timestep Collection Time: 2.08986
Timestep Consumption Time: 0.88987
PPO Batch Consumption Time: 0.11103
Total Iteration Time: 2.97973

Cumulative Model Updates: 9,357
Cumulative Timesteps: 156,200,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,333.58577
Policy Entropy: 0.65196
Value Function Loss: 0.55573

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03742
Policy Update Magnitude: 0.02130
Value Function Update Magnitude: 0.04142

Collected Steps per Second: 23,038.79484
Overall Steps per Second: 16,651.47323

Timestep Collection Time: 2.17103
Timestep Consumption Time: 0.83278
PPO Batch Consumption Time: 0.09763
Total Iteration Time: 3.00382

Cumulative Model Updates: 9,360
Cumulative Timesteps: 156,250,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 156250406...
Checkpoint 156250406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,076.94517
Policy Entropy: 0.65676
Value Function Loss: 0.50319

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03156
Policy Update Magnitude: 0.02121
Value Function Update Magnitude: 0.03768

Collected Steps per Second: 23,094.59010
Overall Steps per Second: 16,746.50850

Timestep Collection Time: 2.16536
Timestep Consumption Time: 0.82082
PPO Batch Consumption Time: 0.09612
Total Iteration Time: 2.98617

Cumulative Model Updates: 9,363
Cumulative Timesteps: 156,300,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,960.53391
Policy Entropy: 0.65217
Value Function Loss: 0.49000

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03714
Policy Update Magnitude: 0.02086
Value Function Update Magnitude: 0.03401

Collected Steps per Second: 23,611.22740
Overall Steps per Second: 16,590.63152

Timestep Collection Time: 2.11874
Timestep Consumption Time: 0.89658
PPO Batch Consumption Time: 0.11384
Total Iteration Time: 3.01532

Cumulative Model Updates: 9,366
Cumulative Timesteps: 156,350,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 156350440...
Checkpoint 156350440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,571.32724
Policy Entropy: 0.65778
Value Function Loss: 0.48677

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03616
Policy Update Magnitude: 0.01850
Value Function Update Magnitude: 0.03238

Collected Steps per Second: 22,676.32813
Overall Steps per Second: 16,088.40846

Timestep Collection Time: 2.20556
Timestep Consumption Time: 0.90314
PPO Batch Consumption Time: 0.09837
Total Iteration Time: 3.10870

Cumulative Model Updates: 9,369
Cumulative Timesteps: 156,400,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,893.89727
Policy Entropy: 0.65357
Value Function Loss: 0.50069

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.02168
Value Function Update Magnitude: 0.03328

Collected Steps per Second: 23,554.91692
Overall Steps per Second: 17,293.20922

Timestep Collection Time: 2.12312
Timestep Consumption Time: 0.76876
PPO Batch Consumption Time: 0.05533
Total Iteration Time: 2.89189

Cumulative Model Updates: 9,372
Cumulative Timesteps: 156,450,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 156450464...
Checkpoint 156450464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,872.28936
Policy Entropy: 0.64982
Value Function Loss: 0.53342

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05581
Policy Update Magnitude: 0.02017
Value Function Update Magnitude: 0.03186

Collected Steps per Second: 20,912.84322
Overall Steps per Second: 15,084.90272

Timestep Collection Time: 2.39174
Timestep Consumption Time: 0.92403
PPO Batch Consumption Time: 0.12542
Total Iteration Time: 3.31577

Cumulative Model Updates: 9,375
Cumulative Timesteps: 156,500,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,630.20425
Policy Entropy: 0.64228
Value Function Loss: 0.51955

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03506
Policy Update Magnitude: 0.01978
Value Function Update Magnitude: 0.04022

Collected Steps per Second: 24,009.40909
Overall Steps per Second: 17,159.67281

Timestep Collection Time: 2.08352
Timestep Consumption Time: 0.83169
PPO Batch Consumption Time: 0.06929
Total Iteration Time: 2.91521

Cumulative Model Updates: 9,378
Cumulative Timesteps: 156,550,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 156550506...
Checkpoint 156550506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,705.65671
Policy Entropy: 0.64165
Value Function Loss: 0.51757

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04359
Policy Update Magnitude: 0.01999
Value Function Update Magnitude: 0.04134

Collected Steps per Second: 20,922.16665
Overall Steps per Second: 15,236.65405

Timestep Collection Time: 2.39048
Timestep Consumption Time: 0.89200
PPO Batch Consumption Time: 0.09128
Total Iteration Time: 3.28248

Cumulative Model Updates: 9,381
Cumulative Timesteps: 156,600,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,072.52873
Policy Entropy: 0.64572
Value Function Loss: 0.51960

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04478
Policy Update Magnitude: 0.01860
Value Function Update Magnitude: 0.03799

Collected Steps per Second: 21,918.65237
Overall Steps per Second: 15,762.78533

Timestep Collection Time: 2.28226
Timestep Consumption Time: 0.89129
PPO Batch Consumption Time: 0.11128
Total Iteration Time: 3.17355

Cumulative Model Updates: 9,384
Cumulative Timesteps: 156,650,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 156650544...
Checkpoint 156650544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,091.80011
Policy Entropy: 0.64603
Value Function Loss: 0.54575

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.05621
Policy Update Magnitude: 0.01886
Value Function Update Magnitude: 0.03773

Collected Steps per Second: 23,771.26524
Overall Steps per Second: 17,231.57606

Timestep Collection Time: 2.10473
Timestep Consumption Time: 0.79878
PPO Batch Consumption Time: 0.06312
Total Iteration Time: 2.90351

Cumulative Model Updates: 9,387
Cumulative Timesteps: 156,700,576

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,518.36218
Policy Entropy: 0.65009
Value Function Loss: 0.56344

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.05025
Policy Update Magnitude: 0.01835
Value Function Update Magnitude: 0.03628

Collected Steps per Second: 24,114.05562
Overall Steps per Second: 17,455.50296

Timestep Collection Time: 2.07348
Timestep Consumption Time: 0.79095
PPO Batch Consumption Time: 0.06160
Total Iteration Time: 2.86443

Cumulative Model Updates: 9,390
Cumulative Timesteps: 156,750,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 156750576...
Checkpoint 156750576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,445.94114
Policy Entropy: 0.64190
Value Function Loss: 0.55680

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04747
Policy Update Magnitude: 0.01810
Value Function Update Magnitude: 0.03824

Collected Steps per Second: 21,103.54043
Overall Steps per Second: 14,563.01532

Timestep Collection Time: 2.36927
Timestep Consumption Time: 1.06408
PPO Batch Consumption Time: 0.11156
Total Iteration Time: 3.43335

Cumulative Model Updates: 9,393
Cumulative Timesteps: 156,800,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,374.47803
Policy Entropy: 0.64014
Value Function Loss: 0.54110

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05362
Policy Update Magnitude: 0.01908
Value Function Update Magnitude: 0.03594

Collected Steps per Second: 23,770.77656
Overall Steps per Second: 17,356.15314

Timestep Collection Time: 2.10393
Timestep Consumption Time: 0.77759
PPO Batch Consumption Time: 0.06049
Total Iteration Time: 2.88151

Cumulative Model Updates: 9,396
Cumulative Timesteps: 156,850,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 156850588...
Checkpoint 156850588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,168.49470
Policy Entropy: 0.63147
Value Function Loss: 0.54827

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04723
Policy Update Magnitude: 0.01706
Value Function Update Magnitude: 0.03233

Collected Steps per Second: 24,343.61712
Overall Steps per Second: 17,428.82475

Timestep Collection Time: 2.05524
Timestep Consumption Time: 0.81541
PPO Batch Consumption Time: 0.07401
Total Iteration Time: 2.87065

Cumulative Model Updates: 9,399
Cumulative Timesteps: 156,900,620

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,136.89308
Policy Entropy: 0.63056
Value Function Loss: 0.52719

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05245
Policy Update Magnitude: 0.01769
Value Function Update Magnitude: 0.03202

Collected Steps per Second: 24,451.12088
Overall Steps per Second: 17,830.11678

Timestep Collection Time: 2.04547
Timestep Consumption Time: 0.75956
PPO Batch Consumption Time: 0.05651
Total Iteration Time: 2.80503

Cumulative Model Updates: 9,402
Cumulative Timesteps: 156,950,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 156950634...
Checkpoint 156950634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,663.22966
Policy Entropy: 0.63676
Value Function Loss: 0.52125

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03077
Policy Update Magnitude: 0.01892
Value Function Update Magnitude: 0.03065

Collected Steps per Second: 20,965.38352
Overall Steps per Second: 14,928.57765

Timestep Collection Time: 2.38555
Timestep Consumption Time: 0.96467
PPO Batch Consumption Time: 0.11330
Total Iteration Time: 3.35022

Cumulative Model Updates: 9,405
Cumulative Timesteps: 157,000,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,283.15498
Policy Entropy: 0.63162
Value Function Loss: 0.51180

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.05117
Policy Update Magnitude: 0.01985
Value Function Update Magnitude: 0.03699

Collected Steps per Second: 24,365.01681
Overall Steps per Second: 17,687.71540

Timestep Collection Time: 2.05393
Timestep Consumption Time: 0.77538
PPO Batch Consumption Time: 0.05879
Total Iteration Time: 2.82931

Cumulative Model Updates: 9,408
Cumulative Timesteps: 157,050,692

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 157050692...
Checkpoint 157050692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,056.16165
Policy Entropy: 0.63996
Value Function Loss: 0.49838

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05295
Policy Update Magnitude: 0.01968
Value Function Update Magnitude: 0.03492

Collected Steps per Second: 20,880.51399
Overall Steps per Second: 14,891.86783

Timestep Collection Time: 2.39553
Timestep Consumption Time: 0.96335
PPO Batch Consumption Time: 0.10996
Total Iteration Time: 3.35888

Cumulative Model Updates: 9,411
Cumulative Timesteps: 157,100,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,355.22196
Policy Entropy: 0.63936
Value Function Loss: 0.51903

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05893
Policy Update Magnitude: 0.01672
Value Function Update Magnitude: 0.04974

Collected Steps per Second: 23,509.75851
Overall Steps per Second: 16,687.95168

Timestep Collection Time: 2.12771
Timestep Consumption Time: 0.86978
PPO Batch Consumption Time: 0.08497
Total Iteration Time: 2.99749

Cumulative Model Updates: 9,414
Cumulative Timesteps: 157,150,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 157150734...
Checkpoint 157150734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,990.95692
Policy Entropy: 0.64686
Value Function Loss: 0.51571

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03191
Policy Update Magnitude: 0.01925
Value Function Update Magnitude: 0.05149

Collected Steps per Second: 23,984.33221
Overall Steps per Second: 16,758.63778

Timestep Collection Time: 2.08519
Timestep Consumption Time: 0.89906
PPO Batch Consumption Time: 0.08925
Total Iteration Time: 2.98425

Cumulative Model Updates: 9,417
Cumulative Timesteps: 157,200,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,533.40753
Policy Entropy: 0.63556
Value Function Loss: 0.53735

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02256
Policy Update Magnitude: 0.02035
Value Function Update Magnitude: 0.04511

Collected Steps per Second: 23,661.83701
Overall Steps per Second: 16,737.05702

Timestep Collection Time: 2.11353
Timestep Consumption Time: 0.87445
PPO Batch Consumption Time: 0.09714
Total Iteration Time: 2.98798

Cumulative Model Updates: 9,420
Cumulative Timesteps: 157,250,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 157250756...
Checkpoint 157250756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,022.20088
Policy Entropy: 0.63624
Value Function Loss: 0.52611

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.02051
Value Function Update Magnitude: 0.04068

Collected Steps per Second: 22,983.08412
Overall Steps per Second: 16,604.18935

Timestep Collection Time: 2.17647
Timestep Consumption Time: 0.83614
PPO Batch Consumption Time: 0.07830
Total Iteration Time: 3.01261

Cumulative Model Updates: 9,423
Cumulative Timesteps: 157,300,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,540.77334
Policy Entropy: 0.63208
Value Function Loss: 0.51650

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04748
Policy Update Magnitude: 0.01827
Value Function Update Magnitude: 0.03867

Collected Steps per Second: 21,624.55531
Overall Steps per Second: 15,775.32246

Timestep Collection Time: 2.31274
Timestep Consumption Time: 0.85753
PPO Batch Consumption Time: 0.08073
Total Iteration Time: 3.17027

Cumulative Model Updates: 9,426
Cumulative Timesteps: 157,350,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 157350790...
Checkpoint 157350790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,879.99278
Policy Entropy: 0.64288
Value Function Loss: 0.51769

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02513
Policy Update Magnitude: 0.02091
Value Function Update Magnitude: 0.03801

Collected Steps per Second: 23,652.49494
Overall Steps per Second: 17,021.41736

Timestep Collection Time: 2.11453
Timestep Consumption Time: 0.82376
PPO Batch Consumption Time: 0.07482
Total Iteration Time: 2.93830

Cumulative Model Updates: 9,429
Cumulative Timesteps: 157,400,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,827.73953
Policy Entropy: 0.64542
Value Function Loss: 0.51272

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 0.02089
Value Function Update Magnitude: 0.03467

Collected Steps per Second: 22,639.28660
Overall Steps per Second: 17,336.40471

Timestep Collection Time: 2.20864
Timestep Consumption Time: 0.67558
PPO Batch Consumption Time: 0.02873
Total Iteration Time: 2.88422

Cumulative Model Updates: 9,432
Cumulative Timesteps: 157,450,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 157450806...
Checkpoint 157450806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,273.73954
Policy Entropy: 0.65029
Value Function Loss: 0.52526

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05541
Policy Update Magnitude: 0.01999
Value Function Update Magnitude: 0.04831

Collected Steps per Second: 23,235.01218
Overall Steps per Second: 16,779.90969

Timestep Collection Time: 2.15210
Timestep Consumption Time: 0.82790
PPO Batch Consumption Time: 0.07556
Total Iteration Time: 2.97999

Cumulative Model Updates: 9,435
Cumulative Timesteps: 157,500,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.27987
Policy Entropy: 0.64312
Value Function Loss: 0.52457

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05640
Policy Update Magnitude: 0.01794
Value Function Update Magnitude: 0.04053

Collected Steps per Second: 21,815.64705
Overall Steps per Second: 15,880.62969

Timestep Collection Time: 2.29248
Timestep Consumption Time: 0.85676
PPO Batch Consumption Time: 0.08849
Total Iteration Time: 3.14925

Cumulative Model Updates: 9,438
Cumulative Timesteps: 157,550,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 157550822...
Checkpoint 157550822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,776.53740
Policy Entropy: 0.64447
Value Function Loss: 0.51132

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02278
Policy Update Magnitude: 0.01889
Value Function Update Magnitude: 0.03354

Collected Steps per Second: 23,140.99238
Overall Steps per Second: 16,924.10455

Timestep Collection Time: 2.16188
Timestep Consumption Time: 0.79414
PPO Batch Consumption Time: 0.05820
Total Iteration Time: 2.95602

Cumulative Model Updates: 9,441
Cumulative Timesteps: 157,600,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,559.30510
Policy Entropy: 0.64833
Value Function Loss: 0.51490

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03283
Policy Update Magnitude: 0.02319
Value Function Update Magnitude: 0.02767

Collected Steps per Second: 21,524.86645
Overall Steps per Second: 15,504.85692

Timestep Collection Time: 2.32475
Timestep Consumption Time: 0.90262
PPO Batch Consumption Time: 0.09663
Total Iteration Time: 3.22738

Cumulative Model Updates: 9,444
Cumulative Timesteps: 157,650,890

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 157650890...
Checkpoint 157650890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,288.00263
Policy Entropy: 0.65495
Value Function Loss: 0.50291

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03539
Policy Update Magnitude: 0.02147
Value Function Update Magnitude: 0.02616

Collected Steps per Second: 22,604.34516
Overall Steps per Second: 16,811.94824

Timestep Collection Time: 2.21196
Timestep Consumption Time: 0.76211
PPO Batch Consumption Time: 0.05526
Total Iteration Time: 2.97408

Cumulative Model Updates: 9,447
Cumulative Timesteps: 157,700,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,005.51605
Policy Entropy: 0.64630
Value Function Loss: 0.50516

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03019
Policy Update Magnitude: 0.02005
Value Function Update Magnitude: 0.02379

Collected Steps per Second: 20,671.05488
Overall Steps per Second: 14,991.53560

Timestep Collection Time: 2.41913
Timestep Consumption Time: 0.91648
PPO Batch Consumption Time: 0.10261
Total Iteration Time: 3.33562

Cumulative Model Updates: 9,450
Cumulative Timesteps: 157,750,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 157750896...
Checkpoint 157750896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,345.41238
Policy Entropy: 0.64244
Value Function Loss: 0.50802

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.02077
Value Function Update Magnitude: 0.02619

Collected Steps per Second: 22,815.22595
Overall Steps per Second: 17,407.78074

Timestep Collection Time: 2.19275
Timestep Consumption Time: 0.68114
PPO Batch Consumption Time: 0.02982
Total Iteration Time: 2.87389

Cumulative Model Updates: 9,453
Cumulative Timesteps: 157,800,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,329.11125
Policy Entropy: 0.64288
Value Function Loss: 0.51628

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01501
Policy Update Magnitude: 0.02374
Value Function Update Magnitude: 0.02824

Collected Steps per Second: 22,957.73973
Overall Steps per Second: 16,736.58144

Timestep Collection Time: 2.17870
Timestep Consumption Time: 0.80984
PPO Batch Consumption Time: 0.07814
Total Iteration Time: 2.98854

Cumulative Model Updates: 9,456
Cumulative Timesteps: 157,850,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 157850942...
Checkpoint 157850942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,077.69919
Policy Entropy: 0.63419
Value Function Loss: 0.54647

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.02312
Value Function Update Magnitude: 0.03624

Collected Steps per Second: 23,055.82440
Overall Steps per Second: 16,948.23444

Timestep Collection Time: 2.16995
Timestep Consumption Time: 0.78198
PPO Batch Consumption Time: 0.08466
Total Iteration Time: 2.95193

Cumulative Model Updates: 9,459
Cumulative Timesteps: 157,900,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,129.04422
Policy Entropy: 0.63447
Value Function Loss: 0.52584

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01993
Policy Update Magnitude: 0.02234
Value Function Update Magnitude: 0.04258

Collected Steps per Second: 23,442.29458
Overall Steps per Second: 16,756.91351

Timestep Collection Time: 2.13392
Timestep Consumption Time: 0.85135
PPO Batch Consumption Time: 0.10455
Total Iteration Time: 2.98528

Cumulative Model Updates: 9,462
Cumulative Timesteps: 157,950,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 157950996...
Checkpoint 157950996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,082.57626
Policy Entropy: 0.63237
Value Function Loss: 0.51726

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01419
Policy Update Magnitude: 0.02516
Value Function Update Magnitude: 0.04036

Collected Steps per Second: 23,248.73488
Overall Steps per Second: 16,765.92184

Timestep Collection Time: 2.15177
Timestep Consumption Time: 0.83202
PPO Batch Consumption Time: 0.09737
Total Iteration Time: 2.98379

Cumulative Model Updates: 9,465
Cumulative Timesteps: 158,001,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,000.80201
Policy Entropy: 0.63737
Value Function Loss: 0.48738

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01745
Policy Update Magnitude: 0.02640
Value Function Update Magnitude: 0.03337

Collected Steps per Second: 23,453.23628
Overall Steps per Second: 16,701.20817

Timestep Collection Time: 2.13241
Timestep Consumption Time: 0.86210
PPO Batch Consumption Time: 0.11107
Total Iteration Time: 2.99451

Cumulative Model Updates: 9,468
Cumulative Timesteps: 158,051,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 158051034...
Checkpoint 158051034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,002.61544
Policy Entropy: 0.63859
Value Function Loss: 0.50190

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04680
Policy Update Magnitude: 0.02382
Value Function Update Magnitude: 0.03123

Collected Steps per Second: 24,271.36634
Overall Steps per Second: 16,755.15641

Timestep Collection Time: 2.06021
Timestep Consumption Time: 0.92419
PPO Batch Consumption Time: 0.10345
Total Iteration Time: 2.98439

Cumulative Model Updates: 9,471
Cumulative Timesteps: 158,101,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,260.06174
Policy Entropy: 0.63412
Value Function Loss: 0.49248

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.02165
Value Function Update Magnitude: 0.03237

Collected Steps per Second: 24,082.51976
Overall Steps per Second: 16,706.80657

Timestep Collection Time: 2.07636
Timestep Consumption Time: 0.91667
PPO Batch Consumption Time: 0.10356
Total Iteration Time: 2.99303

Cumulative Model Updates: 9,474
Cumulative Timesteps: 158,151,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 158151042...
Checkpoint 158151042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,032.29830
Policy Entropy: 0.64544
Value Function Loss: 0.48578

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05826
Policy Update Magnitude: 0.01833
Value Function Update Magnitude: 0.03108

Collected Steps per Second: 24,371.21980
Overall Steps per Second: 16,774.46249

Timestep Collection Time: 2.05234
Timestep Consumption Time: 0.92946
PPO Batch Consumption Time: 0.10776
Total Iteration Time: 2.98179

Cumulative Model Updates: 9,477
Cumulative Timesteps: 158,201,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,060.75456
Policy Entropy: 0.64261
Value Function Loss: 0.47365

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02051
Policy Update Magnitude: 0.01898
Value Function Update Magnitude: 0.03301

Collected Steps per Second: 23,324.36713
Overall Steps per Second: 16,721.54164

Timestep Collection Time: 2.14480
Timestep Consumption Time: 0.84691
PPO Batch Consumption Time: 0.10586
Total Iteration Time: 2.99171

Cumulative Model Updates: 9,480
Cumulative Timesteps: 158,251,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 158251086...
Checkpoint 158251086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,111.85148
Policy Entropy: 0.65760
Value Function Loss: 0.44678

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02321
Policy Update Magnitude: 0.02021
Value Function Update Magnitude: 0.03135

Collected Steps per Second: 23,347.59768
Overall Steps per Second: 16,716.38718

Timestep Collection Time: 2.14189
Timestep Consumption Time: 0.84966
PPO Batch Consumption Time: 0.09601
Total Iteration Time: 2.99156

Cumulative Model Updates: 9,483
Cumulative Timesteps: 158,301,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,864.12288
Policy Entropy: 0.65202
Value Function Loss: 0.46066

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04170
Policy Update Magnitude: 0.01986
Value Function Update Magnitude: 0.03997

Collected Steps per Second: 23,611.47302
Overall Steps per Second: 16,689.03331

Timestep Collection Time: 2.11761
Timestep Consumption Time: 0.87836
PPO Batch Consumption Time: 0.11309
Total Iteration Time: 2.99598

Cumulative Model Updates: 9,486
Cumulative Timesteps: 158,351,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 158351094...
Checkpoint 158351094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,464.18082
Policy Entropy: 0.64571
Value Function Loss: 0.47136

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04953
Policy Update Magnitude: 0.01807
Value Function Update Magnitude: 0.03256

Collected Steps per Second: 24,090.74399
Overall Steps per Second: 16,783.85067

Timestep Collection Time: 2.07582
Timestep Consumption Time: 0.90371
PPO Batch Consumption Time: 0.09939
Total Iteration Time: 2.97953

Cumulative Model Updates: 9,489
Cumulative Timesteps: 158,401,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,712.81949
Policy Entropy: 0.62889
Value Function Loss: 0.48960

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.02000
Value Function Update Magnitude: 0.03021

Collected Steps per Second: 24,096.48655
Overall Steps per Second: 16,676.07027

Timestep Collection Time: 2.07549
Timestep Consumption Time: 0.92354
PPO Batch Consumption Time: 0.10420
Total Iteration Time: 2.99903

Cumulative Model Updates: 9,492
Cumulative Timesteps: 158,451,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 158451114...
Checkpoint 158451114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,560.76764
Policy Entropy: 0.63304
Value Function Loss: 0.49204

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04611
Policy Update Magnitude: 0.01962
Value Function Update Magnitude: 0.02952

Collected Steps per Second: 24,136.58426
Overall Steps per Second: 16,801.96242

Timestep Collection Time: 2.07188
Timestep Consumption Time: 0.90444
PPO Batch Consumption Time: 0.09970
Total Iteration Time: 2.97632

Cumulative Model Updates: 9,495
Cumulative Timesteps: 158,501,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,126.70806
Policy Entropy: 0.62650
Value Function Loss: 0.50067

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.05347
Policy Update Magnitude: 0.01793
Value Function Update Magnitude: 0.03011

Collected Steps per Second: 24,394.03178
Overall Steps per Second: 16,737.29364

Timestep Collection Time: 2.05083
Timestep Consumption Time: 0.93818
PPO Batch Consumption Time: 0.11106
Total Iteration Time: 2.98901

Cumulative Model Updates: 9,498
Cumulative Timesteps: 158,551,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 158551150...
Checkpoint 158551150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,520.25905
Policy Entropy: 0.63592
Value Function Loss: 0.50325

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 0.01874
Value Function Update Magnitude: 0.03187

Collected Steps per Second: 24,481.22329
Overall Steps per Second: 16,752.36114

Timestep Collection Time: 2.04238
Timestep Consumption Time: 0.94227
PPO Batch Consumption Time: 0.11224
Total Iteration Time: 2.98465

Cumulative Model Updates: 9,501
Cumulative Timesteps: 158,601,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,319.48775
Policy Entropy: 0.64362
Value Function Loss: 0.49041

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03807
Policy Update Magnitude: 0.02034
Value Function Update Magnitude: 0.03051

Collected Steps per Second: 24,204.18170
Overall Steps per Second: 16,771.71589

Timestep Collection Time: 2.06700
Timestep Consumption Time: 0.91600
PPO Batch Consumption Time: 0.10675
Total Iteration Time: 2.98300

Cumulative Model Updates: 9,504
Cumulative Timesteps: 158,651,180

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 158651180...
Checkpoint 158651180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,620.34472
Policy Entropy: 0.64898
Value Function Loss: 0.46887

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04347
Policy Update Magnitude: 0.02066
Value Function Update Magnitude: 0.03351

Collected Steps per Second: 24,254.75129
Overall Steps per Second: 16,717.53734

Timestep Collection Time: 2.06277
Timestep Consumption Time: 0.93001
PPO Batch Consumption Time: 0.10620
Total Iteration Time: 2.99279

Cumulative Model Updates: 9,507
Cumulative Timesteps: 158,701,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,633.10979
Policy Entropy: 0.65089
Value Function Loss: 0.44936

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04795
Policy Update Magnitude: 0.01990
Value Function Update Magnitude: 0.03111

Collected Steps per Second: 24,082.22503
Overall Steps per Second: 16,699.21618

Timestep Collection Time: 2.07722
Timestep Consumption Time: 0.91837
PPO Batch Consumption Time: 0.10120
Total Iteration Time: 2.99559

Cumulative Model Updates: 9,510
Cumulative Timesteps: 158,751,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 158751236...
Checkpoint 158751236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,195.61409
Policy Entropy: 0.63941
Value Function Loss: 0.47464

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03085
Policy Update Magnitude: 0.02106
Value Function Update Magnitude: 0.04067

Collected Steps per Second: 24,173.55843
Overall Steps per Second: 16,746.68976

Timestep Collection Time: 2.06846
Timestep Consumption Time: 0.91733
PPO Batch Consumption Time: 0.09559
Total Iteration Time: 2.98578

Cumulative Model Updates: 9,513
Cumulative Timesteps: 158,801,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,051.45320
Policy Entropy: 0.64056
Value Function Loss: 0.47650

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 0.01863
Value Function Update Magnitude: 0.03915

Collected Steps per Second: 24,416.84303
Overall Steps per Second: 16,773.24597

Timestep Collection Time: 2.04793
Timestep Consumption Time: 0.93325
PPO Batch Consumption Time: 0.10467
Total Iteration Time: 2.98118

Cumulative Model Updates: 9,516
Cumulative Timesteps: 158,851,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 158851242...
Checkpoint 158851242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,361.69284
Policy Entropy: 0.63818
Value Function Loss: 0.52818

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04993
Policy Update Magnitude: 0.01885
Value Function Update Magnitude: 0.03843

Collected Steps per Second: 23,988.23264
Overall Steps per Second: 16,698.10303

Timestep Collection Time: 2.08502
Timestep Consumption Time: 0.91029
PPO Batch Consumption Time: 0.09685
Total Iteration Time: 2.99531

Cumulative Model Updates: 9,519
Cumulative Timesteps: 158,901,258

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,024.26238
Policy Entropy: 0.64482
Value Function Loss: 0.49814

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.01913
Value Function Update Magnitude: 0.03063

Collected Steps per Second: 24,194.89412
Overall Steps per Second: 16,736.77910

Timestep Collection Time: 2.06746
Timestep Consumption Time: 0.92129
PPO Batch Consumption Time: 0.10657
Total Iteration Time: 2.98875

Cumulative Model Updates: 9,522
Cumulative Timesteps: 158,951,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 158951280...
Checkpoint 158951280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,800.95251
Policy Entropy: 0.64255
Value Function Loss: 0.49321

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.02113
Value Function Update Magnitude: 0.02703

Collected Steps per Second: 24,110.74628
Overall Steps per Second: 16,759.28545

Timestep Collection Time: 2.07410
Timestep Consumption Time: 0.90980
PPO Batch Consumption Time: 0.10066
Total Iteration Time: 2.98390

Cumulative Model Updates: 9,525
Cumulative Timesteps: 159,001,288

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,828.09251
Policy Entropy: 0.64567
Value Function Loss: 0.47950

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05778
Policy Update Magnitude: 0.02014
Value Function Update Magnitude: 0.02944

Collected Steps per Second: 24,298.98497
Overall Steps per Second: 16,694.77332

Timestep Collection Time: 2.05852
Timestep Consumption Time: 0.93763
PPO Batch Consumption Time: 0.10787
Total Iteration Time: 2.99615

Cumulative Model Updates: 9,528
Cumulative Timesteps: 159,051,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 159051308...
Checkpoint 159051308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,832.98898
Policy Entropy: 0.64999
Value Function Loss: 0.47239

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03753
Policy Update Magnitude: 0.01872
Value Function Update Magnitude: 0.02915

Collected Steps per Second: 23,923.23328
Overall Steps per Second: 16,736.08638

Timestep Collection Time: 2.09069
Timestep Consumption Time: 0.89783
PPO Batch Consumption Time: 0.09519
Total Iteration Time: 2.98851

Cumulative Model Updates: 9,531
Cumulative Timesteps: 159,101,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,055.05511
Policy Entropy: 0.65471
Value Function Loss: 0.45815

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02931
Policy Update Magnitude: 0.01712
Value Function Update Magnitude: 0.03485

Collected Steps per Second: 24,243.24329
Overall Steps per Second: 16,727.80921

Timestep Collection Time: 2.06301
Timestep Consumption Time: 0.92686
PPO Batch Consumption Time: 0.10357
Total Iteration Time: 2.98987

Cumulative Model Updates: 9,534
Cumulative Timesteps: 159,151,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 159151338...
Checkpoint 159151338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,495.23185
Policy Entropy: 0.65790
Value Function Loss: 0.44273

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01469
Policy Update Magnitude: 0.01904
Value Function Update Magnitude: 0.03208

Collected Steps per Second: 24,227.32411
Overall Steps per Second: 16,764.33459

Timestep Collection Time: 2.06428
Timestep Consumption Time: 0.91896
PPO Batch Consumption Time: 0.09760
Total Iteration Time: 2.98324

Cumulative Model Updates: 9,537
Cumulative Timesteps: 159,201,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,329.12515
Policy Entropy: 0.65788
Value Function Loss: 0.42708

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02723
Policy Update Magnitude: 0.02106
Value Function Update Magnitude: 0.03100

Collected Steps per Second: 24,215.77574
Overall Steps per Second: 16,726.94892

Timestep Collection Time: 2.06477
Timestep Consumption Time: 0.92442
PPO Batch Consumption Time: 0.10388
Total Iteration Time: 2.98919

Cumulative Model Updates: 9,540
Cumulative Timesteps: 159,251,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 159251350...
Checkpoint 159251350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,020.99057
Policy Entropy: 0.64702
Value Function Loss: 0.43246

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.02198
Value Function Update Magnitude: 0.04015

Collected Steps per Second: 24,169.21934
Overall Steps per Second: 16,743.43251

Timestep Collection Time: 2.06891
Timestep Consumption Time: 0.91757
PPO Batch Consumption Time: 0.10075
Total Iteration Time: 2.98648

Cumulative Model Updates: 9,543
Cumulative Timesteps: 159,301,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,548.22900
Policy Entropy: 0.63643
Value Function Loss: 0.44327

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 0.02097
Value Function Update Magnitude: 0.03623

Collected Steps per Second: 23,845.92261
Overall Steps per Second: 16,688.27051

Timestep Collection Time: 2.09747
Timestep Consumption Time: 0.89961
PPO Batch Consumption Time: 0.09491
Total Iteration Time: 2.99708

Cumulative Model Updates: 9,546
Cumulative Timesteps: 159,351,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 159351370...
Checkpoint 159351370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,136.24092
Policy Entropy: 0.62707
Value Function Loss: 0.47936

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.01319
Policy Update Magnitude: 0.02309
Value Function Update Magnitude: 0.03285

Collected Steps per Second: 23,803.02783
Overall Steps per Second: 16,676.53126

Timestep Collection Time: 2.10167
Timestep Consumption Time: 0.89812
PPO Batch Consumption Time: 0.08756
Total Iteration Time: 2.99978

Cumulative Model Updates: 9,549
Cumulative Timesteps: 159,401,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,182.04895
Policy Entropy: 0.63528
Value Function Loss: 0.47452

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 0.02272
Value Function Update Magnitude: 0.02664

Collected Steps per Second: 24,066.38812
Overall Steps per Second: 16,825.35187

Timestep Collection Time: 2.07825
Timestep Consumption Time: 0.89441
PPO Batch Consumption Time: 0.10682
Total Iteration Time: 2.97266

Cumulative Model Updates: 9,552
Cumulative Timesteps: 159,451,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 159451412...
Checkpoint 159451412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,122.69268
Policy Entropy: 0.63989
Value Function Loss: 0.48177

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03211
Policy Update Magnitude: 0.02007
Value Function Update Magnitude: 0.03370

Collected Steps per Second: 23,930.44582
Overall Steps per Second: 16,723.27918

Timestep Collection Time: 2.08997
Timestep Consumption Time: 0.90071
PPO Batch Consumption Time: 0.10610
Total Iteration Time: 2.99068

Cumulative Model Updates: 9,555
Cumulative Timesteps: 159,501,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,768.46882
Policy Entropy: 0.64533
Value Function Loss: 0.48343

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02079
Policy Update Magnitude: 0.02220
Value Function Update Magnitude: 0.03359

Collected Steps per Second: 24,409.31822
Overall Steps per Second: 16,815.56259

Timestep Collection Time: 2.04873
Timestep Consumption Time: 0.92519
PPO Batch Consumption Time: 0.11343
Total Iteration Time: 2.97391

Cumulative Model Updates: 9,558
Cumulative Timesteps: 159,551,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 159551434...
Checkpoint 159551434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,671.10699
Policy Entropy: 0.63515
Value Function Loss: 0.49641

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.02192
Value Function Update Magnitude: 0.02873

Collected Steps per Second: 23,915.38598
Overall Steps per Second: 16,709.70509

Timestep Collection Time: 2.09104
Timestep Consumption Time: 0.90171
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 2.99275

Cumulative Model Updates: 9,561
Cumulative Timesteps: 159,601,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,776.61271
Policy Entropy: 0.63671
Value Function Loss: 0.50191

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01799
Policy Update Magnitude: 0.02149
Value Function Update Magnitude: 0.02542

Collected Steps per Second: 24,168.13366
Overall Steps per Second: 16,770.04787

Timestep Collection Time: 2.06925
Timestep Consumption Time: 0.91285
PPO Batch Consumption Time: 0.10894
Total Iteration Time: 2.98210

Cumulative Model Updates: 9,564
Cumulative Timesteps: 159,651,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 159651452...
Checkpoint 159651452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,169.42618
Policy Entropy: 0.63310
Value Function Loss: 0.52407

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03314
Policy Update Magnitude: 0.02189
Value Function Update Magnitude: 0.02419

Collected Steps per Second: 23,759.93122
Overall Steps per Second: 16,681.15842

Timestep Collection Time: 2.10539
Timestep Consumption Time: 0.89344
PPO Batch Consumption Time: 0.10345
Total Iteration Time: 2.99883

Cumulative Model Updates: 9,567
Cumulative Timesteps: 159,701,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,166.73871
Policy Entropy: 0.63907
Value Function Loss: 0.48751

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03264
Policy Update Magnitude: 0.02048
Value Function Update Magnitude: 0.02416

Collected Steps per Second: 24,025.91202
Overall Steps per Second: 16,726.17832

Timestep Collection Time: 2.08175
Timestep Consumption Time: 0.90853
PPO Batch Consumption Time: 0.10873
Total Iteration Time: 2.99028

Cumulative Model Updates: 9,570
Cumulative Timesteps: 159,751,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 159751492...
Checkpoint 159751492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,272.44085
Policy Entropy: 0.64723
Value Function Loss: 0.47201

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04290
Policy Update Magnitude: 0.02307
Value Function Update Magnitude: 0.02515

Collected Steps per Second: 23,882.57982
Overall Steps per Second: 16,751.15101

Timestep Collection Time: 2.09383
Timestep Consumption Time: 0.89140
PPO Batch Consumption Time: 0.10369
Total Iteration Time: 2.98523

Cumulative Model Updates: 9,573
Cumulative Timesteps: 159,801,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,741.75726
Policy Entropy: 0.65731
Value Function Loss: 0.46669

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05362
Policy Update Magnitude: 0.01800
Value Function Update Magnitude: 0.02268

Collected Steps per Second: 23,857.49105
Overall Steps per Second: 16,724.91099

Timestep Collection Time: 2.09687
Timestep Consumption Time: 0.89424
PPO Batch Consumption Time: 0.10098
Total Iteration Time: 2.99111

Cumulative Model Updates: 9,576
Cumulative Timesteps: 159,851,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 159851524...
Checkpoint 159851524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,859.79824
Policy Entropy: 0.65595
Value Function Loss: 0.46159

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02152
Policy Update Magnitude: 0.02000
Value Function Update Magnitude: 0.02292

Collected Steps per Second: 24,130.18084
Overall Steps per Second: 16,783.03715

Timestep Collection Time: 2.07301
Timestep Consumption Time: 0.90750
PPO Batch Consumption Time: 0.10581
Total Iteration Time: 2.98051

Cumulative Model Updates: 9,579
Cumulative Timesteps: 159,901,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,207.48084
Policy Entropy: 0.64956
Value Function Loss: 0.47197

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04345
Policy Update Magnitude: 0.02114
Value Function Update Magnitude: 0.02106

Collected Steps per Second: 24,149.05502
Overall Steps per Second: 16,725.54870

Timestep Collection Time: 2.07139
Timestep Consumption Time: 0.91937
PPO Batch Consumption Time: 0.10761
Total Iteration Time: 2.99075

Cumulative Model Updates: 9,582
Cumulative Timesteps: 159,951,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 159951568...
Checkpoint 159951568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,847.11891
Policy Entropy: 0.64129
Value Function Loss: 0.48701

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05719
Policy Update Magnitude: 0.01906
Value Function Update Magnitude: 0.02659

Collected Steps per Second: 24,147.76610
Overall Steps per Second: 16,756.98802

Timestep Collection Time: 2.07092
Timestep Consumption Time: 0.91339
PPO Batch Consumption Time: 0.11081
Total Iteration Time: 2.98431

Cumulative Model Updates: 9,585
Cumulative Timesteps: 160,001,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,060.22832
Policy Entropy: 0.63626
Value Function Loss: 0.51556

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03846
Policy Update Magnitude: 0.01915
Value Function Update Magnitude: 0.02385

Collected Steps per Second: 24,148.52040
Overall Steps per Second: 16,731.98337

Timestep Collection Time: 2.07160
Timestep Consumption Time: 0.91825
PPO Batch Consumption Time: 0.10600
Total Iteration Time: 2.98984

Cumulative Model Updates: 9,588
Cumulative Timesteps: 160,051,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 160051602...
Checkpoint 160051602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,803.25930
Policy Entropy: 0.63498
Value Function Loss: 0.52400

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04740
Policy Update Magnitude: 0.01897
Value Function Update Magnitude: 0.02281

Collected Steps per Second: 23,993.10240
Overall Steps per Second: 16,738.71336

Timestep Collection Time: 2.08502
Timestep Consumption Time: 0.90362
PPO Batch Consumption Time: 0.10714
Total Iteration Time: 2.98864

Cumulative Model Updates: 9,591
Cumulative Timesteps: 160,101,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,793.50781
Policy Entropy: 0.63304
Value Function Loss: 0.53853

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03141
Policy Update Magnitude: 0.01895
Value Function Update Magnitude: 0.02265

Collected Steps per Second: 24,255.76961
Overall Steps per Second: 16,726.16258

Timestep Collection Time: 2.06268
Timestep Consumption Time: 0.92856
PPO Batch Consumption Time: 0.11036
Total Iteration Time: 2.99124

Cumulative Model Updates: 9,594
Cumulative Timesteps: 160,151,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 160151660...
Checkpoint 160151660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,615.36136
Policy Entropy: 0.64199
Value Function Loss: 0.52509

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03059
Policy Update Magnitude: 0.02081
Value Function Update Magnitude: 0.02094

Collected Steps per Second: 23,795.59478
Overall Steps per Second: 16,744.86427

Timestep Collection Time: 2.10215
Timestep Consumption Time: 0.88515
PPO Batch Consumption Time: 0.09637
Total Iteration Time: 2.98730

Cumulative Model Updates: 9,597
Cumulative Timesteps: 160,201,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,629.74452
Policy Entropy: 0.64797
Value Function Loss: 0.53033

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.01965
Value Function Update Magnitude: 0.02241

Collected Steps per Second: 24,143.74375
Overall Steps per Second: 16,735.27836

Timestep Collection Time: 2.07168
Timestep Consumption Time: 0.91710
PPO Batch Consumption Time: 0.10698
Total Iteration Time: 2.98878

Cumulative Model Updates: 9,600
Cumulative Timesteps: 160,251,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 160251700...
Checkpoint 160251700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.75485
Policy Entropy: 0.64749
Value Function Loss: 0.52911

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01721
Policy Update Magnitude: 0.02252
Value Function Update Magnitude: 0.02157

Collected Steps per Second: 24,157.68920
Overall Steps per Second: 16,766.56960

Timestep Collection Time: 2.07040
Timestep Consumption Time: 0.91268
PPO Batch Consumption Time: 0.10632
Total Iteration Time: 2.98308

Cumulative Model Updates: 9,603
Cumulative Timesteps: 160,301,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,992.27471
Policy Entropy: 0.64469
Value Function Loss: 0.49951

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.02297
Value Function Update Magnitude: 0.02309

Collected Steps per Second: 23,994.58160
Overall Steps per Second: 16,690.57853

Timestep Collection Time: 2.08430
Timestep Consumption Time: 0.91212
PPO Batch Consumption Time: 0.10836
Total Iteration Time: 2.99642

Cumulative Model Updates: 9,606
Cumulative Timesteps: 160,351,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 160351728...
Checkpoint 160351728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,321.03663
Policy Entropy: 0.63570
Value Function Loss: 0.50496

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04406
Policy Update Magnitude: 0.02394
Value Function Update Magnitude: 0.02131

Collected Steps per Second: 23,765.22234
Overall Steps per Second: 16,781.21143

Timestep Collection Time: 2.10425
Timestep Consumption Time: 0.87575
PPO Batch Consumption Time: 0.10865
Total Iteration Time: 2.98000

Cumulative Model Updates: 9,609
Cumulative Timesteps: 160,401,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,550.20123
Policy Entropy: 0.63804
Value Function Loss: 0.47599

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.06163
Policy Update Magnitude: 0.01982
Value Function Update Magnitude: 0.02049

Collected Steps per Second: 23,700.86445
Overall Steps per Second: 16,676.52960

Timestep Collection Time: 2.11072
Timestep Consumption Time: 0.88906
PPO Batch Consumption Time: 0.11979
Total Iteration Time: 2.99978

Cumulative Model Updates: 9,612
Cumulative Timesteps: 160,451,762

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 160451762...
Checkpoint 160451762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,983.28620
Policy Entropy: 0.63417
Value Function Loss: 0.50371

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.04438
Policy Update Magnitude: 0.01814
Value Function Update Magnitude: 0.02300

Collected Steps per Second: 23,158.45424
Overall Steps per Second: 16,777.73837

Timestep Collection Time: 2.15982
Timestep Consumption Time: 0.82140
PPO Batch Consumption Time: 0.09141
Total Iteration Time: 2.98121

Cumulative Model Updates: 9,615
Cumulative Timesteps: 160,501,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,591.63337
Policy Entropy: 0.63339
Value Function Loss: 0.46761

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.04154
Policy Update Magnitude: 0.01883
Value Function Update Magnitude: 0.02300

Collected Steps per Second: 21,351.52070
Overall Steps per Second: 16,709.32222

Timestep Collection Time: 2.34325
Timestep Consumption Time: 0.65100
PPO Batch Consumption Time: 0.03044
Total Iteration Time: 2.99426

Cumulative Model Updates: 9,618
Cumulative Timesteps: 160,551,812

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 160551812...
Checkpoint 160551812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,894.30387
Policy Entropy: 0.62566
Value Function Loss: 0.47324

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03967
Policy Update Magnitude: 0.01882
Value Function Update Magnitude: 0.02422

Collected Steps per Second: 23,285.03983
Overall Steps per Second: 18,139.84713

Timestep Collection Time: 2.14902
Timestep Consumption Time: 0.60955
PPO Batch Consumption Time: 0.02943
Total Iteration Time: 2.75857

Cumulative Model Updates: 9,621
Cumulative Timesteps: 160,601,852

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,520.38225
Policy Entropy: 0.62507
Value Function Loss: 0.47397

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03305
Policy Update Magnitude: 0.01924
Value Function Update Magnitude: 0.02403

Collected Steps per Second: 21,730.55596
Overall Steps per Second: 16,649.41866

Timestep Collection Time: 2.30183
Timestep Consumption Time: 0.70248
PPO Batch Consumption Time: 0.02894
Total Iteration Time: 3.00431

Cumulative Model Updates: 9,624
Cumulative Timesteps: 160,651,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 160651872...
Checkpoint 160651872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,729.80429
Policy Entropy: 0.61862
Value Function Loss: 0.46887

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04245
Policy Update Magnitude: 0.02071
Value Function Update Magnitude: 0.02441

Collected Steps per Second: 24,052.90137
Overall Steps per Second: 18,160.57625

Timestep Collection Time: 2.07875
Timestep Consumption Time: 0.67447
PPO Batch Consumption Time: 0.02907
Total Iteration Time: 2.75322

Cumulative Model Updates: 9,627
Cumulative Timesteps: 160,701,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 160701872...
Checkpoint 160701872 saved!
