{"Overall Steps per Second":18160.57625106518,"_runtime":10682.2750629,"PPO Batch Consumption Time":0.029070456822713215,"_step":6425,"Policy Update Magnitude":0.020713798701763153,"Mean KL Divergence":0.0034124445325384536,"Timestep Collection Time":2.0787513000000217,"_wandb":{"runtime":10682},"Cumulative Timesteps":160701872,"Policy Reward":3729.804293847425,"_timestamp":1.737072247652706e+09,"SB3 Clip Fraction":0.042453331562379994,"Cumulative Model Updates":9627,"Policy Entropy":0.6186162630716959,"z_vel":0.5352105359276174,"Timesteps Collected":50000,"Collected Steps per Second":24052.90137401212,"y_vel":78.33309669360877,"Timestep Consumption Time":0.6744653000000653,"Total Iteration Time":2.753216600000087,"Value Function Update Magnitude":0.024405937641859055,"x_vel":-12.395313496940837,"Value Function Loss":0.4688723683357239}